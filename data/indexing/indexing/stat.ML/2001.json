[{"id": "2001.00006", "submitter": "Travis LaCroix", "authors": "Travis LaCroix and Yoshua Bengio", "title": "Learning from Learning Machines: Optimisation, Rules, and Social Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an analogy between machine learning systems and economic entities in\nthat they are both adaptive, and their behaviour is specified in a more-or-less\nexplicit way. It appears that the area of AI that is most analogous to the\nbehaviour of economic entities is that of morally good decision-making, but it\nis an open question as to how precisely moral behaviour can be achieved in an\nAI system. This paper explores the analogy between these two complex systems,\nand we suggest that a clearer understanding of this apparent analogy may help\nus forward in both the socio-economic domain and the AI domain: known results\nin economics may help inform feasible solutions in AI safety, but also known\nresults in AI may inform economic policy. If this claim is correct, then the\nrecent successes of deep learning for AI suggest that more implicit\nspecifications work better than explicit ones for solving such problems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 17:42:06 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["LaCroix", "Travis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.00008", "submitter": "Maxime Bassenne", "authors": "Maxime Bassenne and Adri\\'an Lozano-Dur\\'an", "title": "Computational model discovery with reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motivation of this study is to leverage recent breakthroughs in\nartificial intelligence research to unlock novel solutions to important\nscientific problems encountered in computational science. To address the human\nintelligence limitations in discovering reduced-order models, we propose to\nsupplement human thinking with artificial intelligence. Our three-pronged\nstrategy consists of learning (i) models expressed in analytical form, (ii)\nwhich are evaluated a posteriori, and iii) using exclusively integral\nquantities from the reference solution as prior knowledge. In point (i), we\npursue interpretable models expressed symbolically as opposed to black-box\nneural networks, the latter only being used during learning to efficiently\nparameterize the large search space of possible models. In point (ii), learned\nmodels are dynamically evaluated a posteriori in the computational solver\ninstead of based on a priori information from preprocessed high-fidelity data,\nthereby accounting for the specificity of the solver at hand such as its\nnumerics. Finally in point (iii), the exploration of new models is solely\nguided by predefined integral quantities, e.g., averaged quantities of\nengineering interest in Reynolds-averaged or large-eddy simulations (LES). We\nuse a coupled deep reinforcement learning framework and computational solver to\nconcurrently achieve these objectives. The combination of reinforcement\nlearning with objectives (i), (ii) and (iii) differentiate our work from\nprevious modeling attempts based on machine learning. In this report, we\nprovide a high-level description of the model discovery framework with\nreinforcement learning. The method is detailed for the application of\ndiscovering missing terms in differential equations. An elementary\ninstantiation of the method is described that discovers missing terms in the\nBurgers' equation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 22:56:40 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Bassenne", "Maxime", ""], ["Lozano-Dur\u00e1n", "Adri\u00e1n", ""]]}, {"id": "2001.00012", "submitter": "Kenneth Choi", "authors": "Kenneth Choi and Tony Lee", "title": "Differentially Private M-band Wavelet-Based Mechanisms in Machine\n  Learning Environments", "comments": "Part-Time Research Assistant/Helper: Tony Lee; 49 pages, 20 figures,\n  1 table, to be published by International Press of Boston", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the post-industrial world, data science and analytics have gained\nparamount importance regarding digital data privacy. Improper methods of\nestablishing privacy for accessible datasets can compromise large amounts of\nuser data even if the adversary has a small amount of preliminary knowledge of\na user. Many researchers have been developing high-level privacy-preserving\nmechanisms that also retain the statistical integrity of the data to apply to\nmachine learning. Recent developments of differential privacy, such as the\nLaplace and Privelet mechanisms, drastically decrease the probability that an\nadversary can distinguish the elements in a data set and thus extract user\ninformation. In this paper, we develop three privacy-preserving mechanisms with\nthe discrete M-band wavelet transform that embed noise into data. The first two\nmethods (LS and LS+) add noise through a Laplace-Sigmoid distribution that\nmultiplies Laplace-distributed values with the sigmoid function, and the third\nmethod utilizes pseudo-quantum steganography to embed noise into the data. We\nthen show that our mechanisms successfully retain both differential privacy and\nlearnability through statistical analysis in various machine learning\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:07:37 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:28:25 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Choi", "Kenneth", ""], ["Lee", "Tony", ""]]}, {"id": "2001.00051", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Yulong Pei, Katia Sycara", "title": "Simultaneous Identification of Tweet Purpose and Position", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tweet classification has attracted considerable attention recently. Most of\nthe existing work on tweet classification focuses on topic classification,\nwhich classifies tweets into several predefined categories, and sentiment\nclassification, which classifies tweets into positive, negative and neutral.\nSince tweets are different from conventional text in that they generally are of\nlimited length and contain informal, irregular or new words, so it is difficult\nto determine user intention to publish a tweet and user attitude towards\ncertain topic. In this paper, we aim to simultaneously classify tweet purpose,\ni.e., the intention for user to publish a tweet, and position, i.e.,\nsupporting, opposing or being neutral to a given topic. By transforming this\nproblem to a multi-label classification problem, a multi-label classification\nmethod with post-processing is proposed. Experiments on real-world data sets\ndemonstrate the effectiveness of this method and the results outperform the\nindividual classification methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 17:09:54 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Pei", "Yulong", ""], ["Sycara", "Katia", ""]]}, {"id": "2001.00056", "submitter": "Dhanajit Brahma", "authors": "Pawan Kumar, Dhanajit Brahma, Harish Karnick, Piyush Rai", "title": "Deep Attentive Ranking Networks for Learning to Order Sentences", "comments": "Accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an attention-based ranking framework for learning to order\nsentences given a paragraph. Our framework is built on a bidirectional sentence\nencoder and a self-attention based transformer network to obtain an input order\ninvariant representation of paragraphs. Moreover, it allows seamless training\nusing a variety of ranking based loss functions, such as pointwise, pairwise,\nand listwise ranking. We apply our framework on two tasks: Sentence Ordering\nand Order Discrimination. Our framework outperforms various state-of-the-art\nmethods on these tasks on a variety of evaluation metrics. We also show that it\nachieves better results when using pairwise and listwise ranking losses, rather\nthan the pointwise ranking loss, which suggests that incorporating relative\npositions of two or more sentences in the loss function contributes to better\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:54:27 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kumar", "Pawan", ""], ["Brahma", "Dhanajit", ""], ["Karnick", "Harish", ""], ["Rai", "Piyush", ""]]}, {"id": "2001.00060", "submitter": "Issam Hammad", "authors": "Issam Hammad, Kamal El-Sankary, and Jason Gu", "title": "Deep Learning Training with Simulated Approximate Multipliers", "comments": "Presented at: IEEE International Conference on Robotics and\n  Biomimetics (ROBIO) 2019, Dali, China, December 2019. WINNER OF THE MOZI BEST\n  PAPER IN AI AWARD", "journal-ref": "2019 IEEE International Conference on Robotics and Biomimetics\n  (ROBIO)", "doi": "10.1109/ROBIO49542.2019.8961780", "report-no": null, "categories": "cs.LG cs.CV cs.PF eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents by simulation how approximate multipliers can be utilized\nto enhance the training performance of convolutional neural networks (CNNs).\nApproximate multipliers have significantly better performance in terms of\nspeed, power, and area compared to exact multipliers. However, approximate\nmultipliers have an inaccuracy which is defined in terms of the Mean Relative\nError (MRE). To assess the applicability of approximate multipliers in\nenhancing CNN training performance, a simulation for the impact of approximate\nmultipliers error on CNN training is presented. The paper demonstrates that\nusing approximate multipliers for CNN training can significantly enhance the\nperformance in terms of speed, power, and area at the cost of a small negative\nimpact on the achieved accuracy. Additionally, the paper proposes a hybrid\ntraining method which mitigates this negative impact on the accuracy. Using the\nproposed hybrid method, the training can start using approximate multipliers\nthen switches to exact multipliers for the last few epochs. Using this method,\nthe performance benefits of approximate multipliers in terms of speed, power,\nand area can be attained for a large portion of the training stage. On the\nother hand, the negative impact on the accuracy is diminished by using the\nexact multipliers for the last epochs of training.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 12:50:06 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 13:22:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hammad", "Issam", ""], ["El-Sankary", "Kamal", ""], ["Gu", "Jason", ""]]}, {"id": "2001.00071", "submitter": "Sumit Mukherjee", "authors": "Sumit Mukherjee, Yixi Xu, Anusua Trivedi, Juan Lavista Ferres", "title": "privGAN: Protecting GANs from membership inference attacks at low cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have made releasing of synthetic\nimages a viable approach to share data without releasing the original dataset.\nIt has been shown that such synthetic data can be used for a variety of\ndownstream tasks such as training classifiers that would otherwise require the\noriginal dataset to be shared. However, recent work has shown that the GAN\nmodels and their synthetically generated data can be used to infer the training\nset membership by an adversary who has access to the entire dataset and some\nauxiliary information. Current approaches to mitigate this problem (such as\nDPGAN) lead to dramatically poorer generated sample quality than the original\nnon--private GANs. Here we develop a new GAN architecture (privGAN), where the\ngenerator is trained not only to cheat the discriminator but also to defend\nmembership inference attacks. The new mechanism provides protection against\nthis mode of attack while leading to negligible loss in downstream\nperformances. In addition, our algorithm has been shown to explicitly prevent\noverfitting to the training set, which explains why our protection is so\neffective. The main contributions of this paper are: i) we propose a novel GAN\narchitecture that can generate synthetic data in a privacy preserving manner\nwithout additional hyperparameter tuning and architecture selection, ii) we\nprovide a theoretical understanding of the optimal solution of the privGAN loss\nfunction, iii) we demonstrate the effectiveness of our model against several\nwhite and black--box attacks on several benchmark datasets, iv) we demonstrate\non three common benchmark datasets that synthetic images generated by privGAN\nlead to negligible loss in downstream performance when compared against\nnon--private GANs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:47:21 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 17:44:07 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 06:53:47 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2020 18:27:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mukherjee", "Sumit", ""], ["Xu", "Yixi", ""], ["Trivedi", "Anusua", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "2001.00076", "submitter": "Ari Kobren", "authors": "Nicholas Monath, Ari Kobren, Akshay Krishnamurthy, Michael Glass,\n  Andrew McCallum", "title": "Scalable Hierarchical Clustering with Tree Grafting", "comments": "23 pages (appendix included), published at KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330929", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Grinch, a new algorithm for large-scale, non-greedy hierarchical\nclustering with general linkage functions that compute arbitrary similarity\nbetween two point sets. The key components of Grinch are its rotate and graft\nsubroutines that efficiently reconfigure the hierarchy as new points arrive,\nsupporting discovery of clusters with complex structure. Grinch is motivated by\na new notion of separability for clustering with linkage functions: we prove\nthat when the model is consistent with a ground-truth clustering, Grinch is\nguaranteed to produce a cluster tree containing the ground-truth, independent\nof data arrival order. Our empirical results on benchmark and author\ncoreference datasets (with standard and learned linkage functions) show that\nGrinch is more accurate than other scalable methods, and orders of magnitude\nfaster than hierarchical agglomerative clustering.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:56:15 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Monath", "Nicholas", ""], ["Kobren", "Ari", ""], ["Krishnamurthy", "Akshay", ""], ["Glass", "Michael", ""], ["McCallum", "Andrew", ""]]}, {"id": "2001.00098", "submitter": "Brett Larsen", "authors": "Abbas Kazemipour, Brett W. Larsen and Shaul Druckmann", "title": "Avoiding Spurious Local Minima in Deep Quadratic Networks", "comments": "36 pages; added deep network experiments, results for population loss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their practical success, a theoretical understanding of the loss\nlandscape of neural networks has proven challenging due to the\nhigh-dimensional, non-convex, and highly nonlinear structure of such models. In\nthis paper, we characterize the training landscape of the mean squared error\nloss for neural networks with quadratic activation functions. We prove\nexistence of spurious local minima and saddle points which can be escaped\neasily with probability one when the number of neurons is greater than or equal\nto the input dimension and the norm of the training samples is used as a\nregressor. We prove that deep overparameterized neural networks with quadratic\nactivations benefit from similar nice landscape properties. Our theoretical\nresults are independent of data distribution and fill the existing gap in\ntheory for two-layer quadratic neural networks. Finally, we empirically\ndemonstrate convergence to a global minimum for these problems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:31:11 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:40:15 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kazemipour", "Abbas", ""], ["Larsen", "Brett W.", ""], ["Druckmann", "Shaul", ""]]}, {"id": "2001.00102", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang, Shuai Li, Jiajin Li, Siu On Chan", "title": "The Gambler's Problem and Beyond", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Gambler's problem, a simple reinforcement learning problem\nwhere the gambler has the chance to double or lose the bets until the target is\nreached. This is an early example introduced in the reinforcement learning\ntextbook by Sutton and Barto (2018), where they mention an interesting pattern\nof the optimal value function with high-frequency components and repeating\nnon-smooth points. It is however without further investigation. We provide the\nexact formula for the optimal value function for both the discrete and the\ncontinuous cases. Though simple as it might seem, the value function is\npathological: fractal, self-similar, derivative taking either zero or infinity,\nand not written as elementary functions. It is in fact one of the generalized\nCantor functions, where it holds a complexity that has been uncharted thus far.\nOur analyses could provide insights into improving value function\napproximation, gradient-based algorithms, and Q-learning, in real applications\nand implementations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:48:15 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 11:44:17 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 12:43:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Wang", "Baoxiang", ""], ["Li", "Shuai", ""], ["Li", "Jiajin", ""], ["Chan", "Siu On", ""]]}, {"id": "2001.00106", "submitter": "Sangdon Park", "authors": "Sangdon Park, Osbert Bastani, Nikolai Matni, Insup Lee", "title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm combining calibrated prediction and generalization\nbounds from learning theory to construct confidence sets for deep neural\nnetworks with PAC guarantees---i.e., the confidence set for a given input\ncontains the true label with high probability. We demonstrate how our approach\ncan be used to construct PAC confidence sets on ResNet for ImageNet, a visual\nobject tracking model, and a dynamics model for the half-cheetah reinforcement\nlearning problem.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:02:01 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 19:50:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Park", "Sangdon", ""], ["Bastani", "Osbert", ""], ["Matni", "Nikolai", ""], ["Lee", "Insup", ""]]}, {"id": "2001.00111", "submitter": "Yoh'ichi Mototake", "authors": "Yoh-ichi Mototake", "title": "Interpretable Conservation Law Estimation by Deriving the Symmetries of\n  Dynamics from Trained Deep Neural Networks", "comments": "38 pages, 8 figures", "journal-ref": "Phys. Rev. E 103, 033303 (2021)", "doi": "10.1103/PhysRevE.103.033303", "report-no": null, "categories": "physics.data-an cs.LG nlin.PS physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding complex systems with their reduced model is one of the central\nroles in scientific activities. Although physics has greatly been developed\nwith the physical insights of physicists, it is sometimes challenging to build\na reduced model of such complex systems on the basis of insights alone. We\npropose a novel framework that can infer the hidden conservation laws of a\ncomplex system from deep neural networks (DNNs) that have been trained with\nphysical data of the system. The purpose of the proposed framework is not to\nanalyze physical data with deep learning, but to extract interpretable physical\ninformation from trained DNNs. With Noether's theorem and by an efficient\nsampling method, the proposed framework infers conservation laws by extracting\nsymmetries of dynamics from trained DNNs. The proposed framework is developed\nby deriving the relationship between a manifold structure of time-series\ndataset and the necessary conditions for Noether's theorem. The feasibility of\nthe proposed framework has been verified in some primitive cases for which the\nconservation law is well known. We also apply the proposed framework to\nconservation law estimation for a more practical case that is a large-scale\ncollective motion system in the metastable state, and we obtain a result\nconsistent with that of a previous study.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:55:44 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 00:08:18 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Mototake", "Yoh-ichi", ""]]}, {"id": "2001.00119", "submitter": "Simone Parisi", "authors": "Simone Parisi, Davide Tateo, Maximilian Hensel, Carlo D'Eramo, Jan\n  Peters, Joni Pajarinen", "title": "Long-Term Visitation Value for Deep Exploration in Sparse Reward\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning with sparse rewards is still an open challenge.\nClassic methods rely on getting feedback via extrinsic rewards to train the\nagent, and in situations where this occurs very rarely the agent learns slowly\nor cannot learn at all. Similarly, if the agent receives also rewards that\ncreate suboptimal modes of the objective function, it will likely prematurely\nstop exploring. More recent methods add auxiliary intrinsic rewards to\nencourage exploration. However, auxiliary rewards lead to a non-stationary\ntarget for the Q-function. In this paper, we present a novel approach that (1)\nplans exploration actions far into the future by using a long-term visitation\ncount, and (2) decouples exploration and exploitation by learning a separate\nfunction assessing the exploration value of the actions. Contrary to existing\nmethods which use models of reward and dynamics, our approach is off-policy and\nmodel-free. We further propose new tabular environments for benchmarking\nexploration in reinforcement learning. Empirical results on classic and novel\nbenchmarks show that the proposed approach outperforms existing methods in\nenvironments with sparse rewards, especially in the presence of rewards that\ncreate suboptimal modes of the objective function. Results also suggest that\nour approach scales gracefully with the size of the environment. Source code is\navailable at https://github.com/sparisi/visit-value-explore\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 01:01:15 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Parisi", "Simone", ""], ["Tateo", "Davide", ""], ["Hensel", "Maximilian", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2001.00127", "submitter": "Kai Jiang", "authors": "Kai Jiang, XiaoLong Qin", "title": "Reinforcement Learning with Goal-Distance Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning usually uses the feedback rewards of environmental to\ntrain agents. But the rewards in the actual environment are sparse, and even\nsome environments will not rewards. Most of the current methods are difficult\nto get good performance in sparse reward or non-reward environments. Although\nusing shaped rewards is effective when solving sparse reward tasks, it is\nlimited to specific problems and learning is also susceptible to local optima.\nWe propose a model-free method that does not rely on environmental rewards to\nsolve the problem of sparse rewards in the general environment. Our method use\nthe minimum number of transitions between states as the distance to replace the\nrewards of environmental, and proposes a goal-distance gradient to achieve\npolicy improvement. We also introduce a bridge point planning method based on\nthe characteristics of our method to improve exploration efficiency, thereby\nsolving more complex tasks. Experiments show that our method performs better on\nsparse reward and local optimal problems in complex environments than previous\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 02:37:34 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 12:26:33 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Jiang", "Kai", ""], ["Qin", "XiaoLong", ""]]}, {"id": "2001.00153", "submitter": "Yuntao Du", "authors": "Yuntao Du, Zhiwen Tan, Qian Chen, Xiaowen Zhang, Yirong Yao, Chongjun\n  Wang", "title": "Dual Adversarial Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unsupervised domain adaptation aims at transferring knowledge from the\nlabeled source domain to the unlabeled target domain. Previous adversarial\ndomain adaptation methods mostly adopt the discriminator with binary or\n$K$-dimensional output to perform marginal or conditional alignment\nindependently. Recent experiments have shown that when the discriminator is\nprovided with domain information in both domains and label information in the\nsource domain, it is able to preserve the complex multimodal information and\nhigh semantic information in both domains. Following this idea, we adopt a\ndiscriminator with $2K$-dimensional output to perform both domain-level and\nclass-level alignments simultaneously in a single discriminator. However, a\nsingle discriminator can not capture all the useful information across domains\nand the relationships between the examples and the decision boundary are rarely\nexplored before. Inspired by multi-view learning and latest advances in domain\nadaptation, besides the adversarial process between the discriminator and the\nfeature extractor, we also design a novel mechanism to make two discriminators\npit against each other, so that they can provide diverse information for each\nother and avoid generating target features outside the support of the source\ndomain. To the best of our knowledge, it is the first time to explore a dual\nadversarial strategy in domain adaptation. Moreover, we also use the\nsemi-supervised learning regularization to make the representations more\ndiscriminative. Comprehensive experiments on two real-world datasets verify\nthat our method outperforms several state-of-the-art domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 07:10:09 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Du", "Yuntao", ""], ["Tan", "Zhiwen", ""], ["Chen", "Qian", ""], ["Zhang", "Xiaowen", ""], ["Yao", "Yirong", ""], ["Wang", "Chongjun", ""]]}, {"id": "2001.00155", "submitter": "Jessica Torres Soto", "authors": "Jessica Torres Soto, Euan Ashley", "title": "DeepBeat: A multi-task deep learning approach to assess signal quality\n  and arrhythmia detection in wearable devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices enable theoretically continuous, longitudinal monitoring of\nphysiological measurements like step count, energy expenditure, and heart rate.\nAlthough the classification of abnormal cardiac rhythms such as atrial\nfibrillation from wearable devices has great potential, commercial algorithms\nremain proprietary and tend to focus on heart rate variability derived from\ngreen spectrum LED sensors placed on the wrist where noise remains an unsolved\nproblem. Here, we develop a multi-task deep learning method to assess signal\nquality and arrhythmia event detection in wearable photoplethysmography devices\nfor real-time detection of atrial fibrillation (AF). We train our algorithm on\nover one million simulated unlabeled physiological signals and fine-tune on a\ncurated dataset of over 500K labeled signals from over 100 individuals from 3\ndifferent wearable devices. We demonstrate that in comparison with a\ntraditional random forest-based approach (precision:0.24, recall:0.58, f1:0.34,\nauPRC:0.44) and a single task CNN (precision:0.59, recall:0.69, f1:0.64,\nauPRC:0.68) our architecture using unsupervised transfer learning through\nconvolutional denoising autoencoders dramatically improves the performance of\nAF detection in participants at rest (pr:0.94, rc:0.98, f1:0.96, auPRC:0.96).\nIn addition, we validate algorithm performance on a prospectively derived\nreplication cohort of ambulatory subjects using data derived from an\nindependently engineered device. We show that two-stage training can help\naddress the unbalanced data problem common to biomedical applications where\nlarge well-annotated datasets are scarce. In conclusion, though a combination\nof simulation and transfer learning and we develop and apply a multitask\narchitecture to the problem of AF detection from wearable wrist sensors\ndemonstrating high levels of accuracy and a solution for the vexing challenge\nof mechanical noise.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 07:41:28 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 05:02:52 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Soto", "Jessica Torres", ""], ["Ashley", "Euan", ""]]}, {"id": "2001.00191", "submitter": "Jing Zhang", "authors": "Jing Zhang, Yong Zhang, Suhua Zhan, Cheng Cheng", "title": "Ensemble emotion recognizing with multiple modal physiological signals", "comments": "under review for Multimedia tools and applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physiological signals that provide the objective repression of human\naffective states are attracted increasing attention in the emotion recognition\nfield. However, the single signal is difficult to obtain completely and\naccurately description for emotion. Multiple physiological signals fusing\nmodels, building the uniform classification model by means of consistent and\ncomplementary information from different emotions to improve recognition\nperformance. Original fusing models usually choose the particular\nclassification method to recognition, which is ignoring different distribution\nof multiple signals. Aiming above problems, in this work, we propose an emotion\nclassification model through multiple modal physiological signals for different\nemotions. Features are extracted from EEG, EMG, EOG signals for characterizing\nemotional state on valence and arousal levels. For characterization, four bands\nfiltering theta, beta, alpha, gamma for signal preprocessing are adopted and\nthree Hjorth parameters are computing as features. To improve classification\nperformance, an ensemble classifier is built. Experiments are conducted on the\nbenchmark DEAP datasets. For the two-class task, the best result on arousal is\n94.42\\%, the best result on valence is 94.02\\%, respectively. For the\nfour-class task, the highest average classification accuracy is 90.74, and it\nshows good stability. The influence of different peripheral physiological\nsignals for results is also analyzed in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 11:44:43 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zhang", "Jing", ""], ["Zhang", "Yong", ""], ["Zhan", "Suhua", ""], ["Cheng", "Cheng", ""]]}, {"id": "2001.00215", "submitter": "Joshua Peeples", "authors": "Joshua Peeples, Weihuang Xu, and Alina Zare", "title": "Histogram Layers for Texture Analysis", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a histogram layer for artificial neural networks (ANNs). An\nessential aspect of texture analysis is the extraction of features that\ndescribe the distribution of values in local spatial regions. The proposed\nhistogram layer directly computes the spatial distribution of features for\ntexture analysis and parameters for the layer are estimated during\nbackpropagation. We compare our method with state-of-the-art texture encoding\nmethods such as the Deep Encoding Network Pooling (DEP), Deep Texture Encoding\nNetwork (DeepTEN), Fisher Vector convolutional neural network (FV-CNN), and\nMulti-level Texture Encoding and Representation (MuLTER) on three\nmaterial/texture datasets: (1) the Describable Texture Dataset (DTD); (2) an\nextension of the ground terrain in outdoor scenes (GTOS-mobile); (3) and a\nsubset of the Materials in Context (MINC-2500) dataset. Results indicate that\nthe inclusion of the proposed histogram layer improves performance. The source\ncode for the histogram layer is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 14:41:54 GMT"}, {"version": "v10", "created": "Thu, 22 Apr 2021 21:24:34 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 02:05:44 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 19:59:16 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 00:09:51 GMT"}, {"version": "v5", "created": "Fri, 27 Mar 2020 16:56:22 GMT"}, {"version": "v6", "created": "Mon, 30 Mar 2020 17:03:11 GMT"}, {"version": "v7", "created": "Fri, 17 Apr 2020 14:20:41 GMT"}, {"version": "v8", "created": "Wed, 22 Apr 2020 15:45:35 GMT"}, {"version": "v9", "created": "Wed, 6 Jan 2021 01:40:47 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Peeples", "Joshua", ""], ["Xu", "Weihuang", ""], ["Zare", "Alina", ""]]}, {"id": "2001.00218", "submitter": "Thiago Serra", "authors": "Thiago Serra, Abhinav Kumar, Srikumar Ramalingam", "title": "Lossless Compression of Deep Neural Networks", "comments": "CPAIOR 2020 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successful in many predictive modeling tasks,\nsuch as image and language recognition, where large neural networks are often\nused to obtain good accuracy. Consequently, it is challenging to deploy these\nnetworks under limited computational resources, such as in mobile devices. In\nthis work, we introduce an algorithm that removes units and layers of a neural\nnetwork while not changing the output that is produced, which thus implies a\nlossless compression. This algorithm, which we denote as LEO (Lossless\nExpressiveness Optimization), relies on Mixed-Integer Linear Programming (MILP)\nto identify Rectified Linear Units (ReLUs) with linear behavior over the input\ndomain. By using L1 regularization to induce such behavior, we can benefit from\ntraining over a larger architecture than we would later use in the environment\nwhere the trained neural network is deployed.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 15:04:43 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 11:19:36 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 16:09:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Serra", "Thiago", ""], ["Kumar", "Abhinav", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "2001.00248", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Hyunjae Woo, Jongwook Choi, Honglak Lee", "title": "Meta Reinforcement Learning with Autonomous Inference of Subtask\n  Dependencies", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and address a novel few-shot RL problem, where a task is\ncharacterized by a subtask graph which describes a set of subtasks and their\ndependencies that are unknown to the agent. The agent needs to quickly adapt to\nthe task over few episodes during adaptation phase to maximize the return in\nthe test phase. Instead of directly learning a meta-policy, we develop a\nMeta-learner with Subtask Graph Inference(MSGI), which infers the latent\nparameter of the task by interacting with the environment and maximizes the\nreturn given the latent parameter. To facilitate learning, we adopt an\nintrinsic reward inspired by upper confidence bound (UCB) that encourages\nefficient exploration. Our experiment results on two grid-world domains and\nStarCraft II environments show that the proposed method is able to accurately\ninfer the latent task parameter, and to adapt more efficiently than existing\nmeta RL and hierarchical RL methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:34:00 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 01:44:03 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sohn", "Sungryull", ""], ["Woo", "Hyunjae", ""], ["Choi", "Jongwook", ""], ["Lee", "Honglak", ""]]}, {"id": "2001.00254", "submitter": "Zhaodong Chen", "authors": "Zhaodong Chen, Lei Deng, Bangyan Wang, Guoqi Li, Yuan Xie", "title": "A Comprehensive and Modularized Statistical Framework for Gradient Norm\n  Equality in Deep Neural Networks", "comments": "Under review as a regular paper in TPAMI", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  2020", "doi": "10.1109/TPAMI.2020.3010201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, plenty of metrics have been proposed to identify networks\nthat are free of gradient explosion and vanishing. However, due to the\ndiversity of network components and complex serial-parallel hybrid connections\nin modern DNNs, the evaluation of existing metrics usually requires strong\nassumptions, complex statistical analysis, or has limited application fields,\nwhich constraints their spread in the community. In this paper, inspired by the\nGradient Norm Equality and dynamical isometry, we first propose a novel metric\ncalled Block Dynamical Isometry, which measures the change of gradient norm in\nindividual block. Because our Block Dynamical Isometry is norm-based, its\nevaluation needs weaker assumptions compared with the original dynamical\nisometry. To mitigate the challenging derivation, we propose a highly\nmodularized statistical framework based on free probability. Our framework\nincludes several key theorems to handle complex serial-parallel hybrid\nconnections and a library to cover the diversity of network components.\nBesides, several sufficient prerequisites are provided. Powered by our metric\nand framework, we analyze extensive initialization, normalization, and network\nstructures. We find that Gradient Norm Equality is a universal philosophy\nbehind them. Then, we improve some existing methods based on our analysis,\nincluding an activation function selection strategy for initialization\ntechniques, a new configuration for weight normalization, and a depth-aware way\nto derive coefficients in SeLU. Moreover, we propose a novel normalization\ntechnique named second moment normalization, which is theoretically 30% faster\nthan batch normalization without accuracy loss. Last but not least, our\nconclusions and methods are evidenced by extensive experiments on multiple\nmodels over CIFAR10 and ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:56:49 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Chen", "Zhaodong", ""], ["Deng", "Lei", ""], ["Wang", "Bangyan", ""], ["Li", "Guoqi", ""], ["Xie", "Yuan", ""]]}, {"id": "2001.00265", "submitter": "Kan Li PhD", "authors": "Kan Li and Jose C. Principe", "title": "Fast Estimation of Information Theoretic Learning Descriptors using\n  Explicit Inner Product Spaces", "comments": "10 pages, 3 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:1912.04530", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods form a theoretically-grounded, powerful and versatile\nframework to solve nonlinear problems in signal processing and machine\nlearning. The standard approach relies on the \\emph{kernel trick} to perform\npairwise evaluations of a kernel function, leading to scalability issues for\nlarge datasets due to its linear and superlinear growth with respect to the\ntraining data. Recently, we proposed \\emph{no-trick} (NT) kernel adaptive\nfiltering (KAF) that leverages explicit feature space mappings using\ndata-independent basis with constant complexity. The inner product defined by\nthe feature mapping corresponds to a positive-definite finite-rank kernel that\ninduces a finite-dimensional reproducing kernel Hilbert space (RKHS).\nInformation theoretic learning (ITL) is a framework where information theory\ndescriptors based on non-parametric estimator of Renyi entropy replace\nconventional second-order statistics for the design of adaptive systems. An\nRKHS for ITL defined on a space of probability density functions simplifies\nstatistical inference for supervised or unsupervised learning. ITL criteria\ntake into account the higher-order statistical behavior of the systems and\nsignals as desired. However, this comes at a cost of increased computational\ncomplexity. In this paper, we extend the NT kernel concept to ITL for improved\ninformation extraction from the signal without compromising scalability.\nSpecifically, we focus on a family of fast, scalable, and accurate estimators\nfor ITL using explicit inner product space (EIPS) kernels. We demonstrate the\nsuperior performance of EIPS-ITL estimators and combined NT-KAF using EIPS-ITL\ncost functions through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 20:21:12 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Li", "Kan", ""], ["Principe", "Jose C.", ""]]}, {"id": "2001.00271", "submitter": "Khimya Khetarpal", "authors": "Khimya Khetarpal, Martin Klissarov, Maxime Chevalier-Boisvert,\n  Pierre-Luc Bacon, Doina Precup", "title": "Options of Interest: Temporal Abstraction with Interest Functions", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal abstraction refers to the ability of an agent to use behaviours of\ncontrollers which act for a limited, variable amount of time. The options\nframework describes such behaviours as consisting of a subset of states in\nwhich they can initiate, an internal policy and a stochastic termination\ncondition. However, much of the subsequent work on option discovery has ignored\nthe initiation set, because of difficulty in learning it from data. We provide\na generalization of initiation sets suitable for general function\napproximation, by defining an interest function associated with an option. We\nderive a gradient-based learning algorithm for interest functions, leading to a\nnew interest-option-critic architecture. We investigate how interest functions\ncan be leveraged to learn interpretable and reusable temporal abstractions. We\ndemonstrate the efficacy of the proposed approach through quantitative and\nqualitative results, in both discrete and continuous environments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 21:24:39 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Klissarov", "Martin", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""]]}, {"id": "2001.00278", "submitter": "Guilherme Vituri Fernandes Pinto", "authors": "Facundo M\\'emoli, Guilherme Vituri F. Pinto", "title": "Motivic clustering schemes for directed graphs", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the concept of network motifs we construct certain clustering\nmethods (functors) which are parametrized by a given collection of motifs (or\nrepresenters).\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 23:30:00 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 16:37:03 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["M\u00e9moli", "Facundo", ""], ["Pinto", "Guilherme Vituri F.", ""]]}, {"id": "2001.00288", "submitter": "Chandresh Maurya", "authors": "Chandresh Kumar Maurya, Neelamadhav Gantayat, Sampath Dechu, Tomas\n  Horvath", "title": "Online Similarity Learning with Feedback for Invoice Line Item Matching", "comments": null, "journal-ref": "published as workshop paper in AAAI workshop on intelligent\n  processing automation, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The procure to pay process (P2P) in large enterprises is a back-end business\nprocess which deals with the procurement of products and services for\nenterprise operations. Procurement is done by issuing purchase orders to\nimpaneled vendors and invoices submitted by vendors are paid after they go\nthrough a rigorous validation process. Agents orchestrating P2P process often\nencounter the problem of matching a product or service descriptions in the\ninvoice to those in purchase order and verify if the ordered items are what\nhave been supplied or serviced. For example, the description in the invoice and\npurchase order could be TRES 739mL CD KER Smooth and TRES 0.739L CD KER Smth\nwhich look different at word level but refer to the same item. In a typical P2P\nprocess, agents are asked to manually select the products which are similar\nbefore invoices are posted for payment. This step in the business process is\nmanual, repetitive, cumbersome, and costly. Since descriptions are not\nwell-formed sentences, we cannot apply existing semantic and syntactic text\nsimilarity approaches directly. In this paper, we present two approaches to\nsolve the above problem using various types of available agent's recorded\nfeedback data. If the agent's feedback is in the form of a relative ranking\nbetween descriptions, we use similarity ranking algorithm. If the agent's\nfeedback is absolute such as match or no-match, we use classification\nsimilarity algorithm. We also present the threats to the validity of our\napproach and present a possible remedy making use of product taxonomy and\ncatalog. We showcase the comparative effectiveness and efficiency of the\nproposed approaches over many benchmarks and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 01:28:56 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:26:30 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Maurya", "Chandresh Kumar", ""], ["Gantayat", "Neelamadhav", ""], ["Dechu", "Sampath", ""], ["Horvath", "Tomas", ""]]}, {"id": "2001.00293", "submitter": "Xin Wang", "authors": "Wenwu Zhu, Xin Wang, Peng Cui", "title": "Deep Learning for Learning Graph Representations", "comments": "51 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-030-31756-0_6", "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining graph data has become a popular research topic in computer science and\nhas been widely studied in both academia and industry given the increasing\namount of network data in the recent years. However, the huge amount of network\ndata has posed great challenges for efficient analysis. This motivates the\nadvent of graph representation which maps the graph into a low-dimension vector\nspace, keeping original graph structure and supporting graph inference. The\ninvestigation on efficient representation of a graph has profound theoretical\nsignificance and important realistic meaning, we therefore introduce some basic\nideas in graph representation/network embedding as well as some representative\nmodels in this chapter.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 02:13:28 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zhu", "Wenwu", ""], ["Wang", "Xin", ""], ["Cui", "Peng", ""]]}, {"id": "2001.00308", "submitter": "Pooyan Jamshidi", "authors": "Ying Meng, Jianhai Su, Jason O'Kane, Pooyan Jamshidi", "title": "ATHENA: A Framework based on Diverse Weak Defenses for Building\n  Adversarial Defense", "comments": "18 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been extensive research on developing defense techniques against\nadversarial attacks; however, they have been mainly designed for specific model\nfamilies or application domains, therefore, they cannot be easily extended.\nBased on the design philosophy of ensemble of diverse weak defenses, we propose\nATHENA---a flexible and extensible framework for building generic yet effective\ndefenses against adversarial attacks. We have conducted a comprehensive\nempirical study to evaluate several realizations of ATHENA with four threat\nmodels including zero-knowledge, black-box, gray-box, and white-box. We also\nexplain (i) why diversity matters, (ii) the generality of the defense\nframework, and (iii) the overhead costs incurred by ATHENA.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 03:20:57 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:11:24 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Meng", "Ying", ""], ["Su", "Jianhai", ""], ["O'Kane", "Jason", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2001.00329", "submitter": "Dallas Card", "authors": "Dallas Card and Noah A. Smith", "title": "On Consequentialism and Fairness", "comments": "Updating to published version", "journal-ref": "Front. Artif. Intell., 08 May 2020", "doi": "10.3389/frai.2020.00034", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on fairness in machine learning has primarily emphasized how to\ndefine, quantify, and encourage \"fair\" outcomes. Less attention has been paid,\nhowever, to the ethical foundations which underlie such efforts. Among the\nethical perspectives that should be taken into consideration is\nconsequentialism, the position that, roughly speaking, outcomes are all that\nmatter. Although consequentialism is not free from difficulties, and although\nit does not necessarily provide a tractable way of choosing actions (because of\nthe combined problems of uncertainty, subjectivity, and aggregation), it\nnevertheless provides a powerful foundation from which to critique the existing\nliterature on machine learning fairness. Moreover, it brings to the fore some\nof the tradeoffs involved, including the problem of who counts, the pros and\ncons of using a policy, and the relative value of the distant future. In this\npaper we provide a consequentialist critique of common definitions of fairness\nwithin machine learning, as well as a machine learning perspective on\nconsequentialism. We conclude with a broader discussion of the issues of\nlearning and randomization, which have important implications for the ethics of\nautomated decision making systems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 05:39:48 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 04:36:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Card", "Dallas", ""], ["Smith", "Noah A.", ""]]}, {"id": "2001.00345", "submitter": "Kisor Sahu Dr.", "authors": "Raj Kishore, S. Swayamjyoti, Shreeja Das, Ajay K. Gogineni, Zohar\n  Nussinov, D. Solenov, Kisor K. Sahu", "title": "Visual Machine Learning: Insight through Eigenvectors, Chladni patterns\n  and community detection in 2D particulate structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.soft stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is quickly emerging as a powerful tool with diverse\napplications across an extremely broad spectrum of disciplines and commercial\nendeavors. Typically, ML is used as a black box that provides little\nilluminating rationalization of its output. In the current work, we aim to\nbetter understand the generic intuition underlying unsupervised ML with a focus\non physical systems. The systems that are studied here as test cases comprise\nof six different 2-dimensional (2-D) particulate systems of different\ncomplexities. It is noted that the findings of this study are generic to any\nunsupervised ML problem and are not restricted to materials systems alone.\nThree rudimentary unsupervised ML techniques are employed on the adjacency\n(connectivity) matrix of the six studied systems: (i) using principal\neigenvalue and eigenvectors of the adjacency matrix, (ii) spectral\ndecomposition, and (iii) a Potts model based community detection technique in\nwhich a modularity function is maximized. We demonstrate that, while solving a\ncompletely classical problem, ML technique produces features that are\ndistinctly connected to quantum mechanical solutions. Dissecting these features\nhelp us to understand the deep connection between the classical non-linear\nworld and the quantum mechanical linear world through the kaleidoscope of ML\ntechnique, which might have far reaching consequences both in the arena of\nphysical sciences and ML.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 07:20:28 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kishore", "Raj", ""], ["Swayamjyoti", "S.", ""], ["Das", "Shreeja", ""], ["Gogineni", "Ajay K.", ""], ["Nussinov", "Zohar", ""], ["Solenov", "D.", ""], ["Sahu", "Kisor K.", ""]]}, {"id": "2001.00360", "submitter": "Cong Chen", "authors": "Cong Chen, Kim Batselier, Wenjian Yu, Ngai Wong", "title": "Kernelized Support Tensor Train Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor, a multi-dimensional data structure, has been exploited recently in\nthe machine learning community. Traditional machine learning approaches are\nvector- or matrix-based, and cannot handle tensorial data directly. In this\npaper, we propose a tensor train (TT)-based kernel technique for the first\ntime, and apply it to the conventional support vector machine (SVM) for image\nclassification. Specifically, we propose a kernelized support tensor train\nmachine that accepts tensorial input and preserves the intrinsic kernel\nproperty. The main contributions are threefold. First, we propose a TT-based\nfeature mapping procedure that maintains the TT structure in the feature space.\nSecond, we demonstrate two ways to construct the TT-based kernel function while\nconsidering consistency with the TT inner product and preservation of\ninformation. Third, we show that it is possible to apply different kernel\nfunctions on different data modes. In principle, our method tensorizes the\nstandard SVM on its input structure and kernel mapping scheme. Extensive\nexperiments are performed on real-world tensor data, which demonstrates the\nsuperiority of the proposed scheme under few-sample high-dimensional inputs.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 08:40:15 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chen", "Cong", ""], ["Batselier", "Kim", ""], ["Yu", "Wenjian", ""], ["Wong", "Ngai", ""]]}, {"id": "2001.00396", "submitter": "Leon Sixt", "authors": "Karl Schulz, Leon Sixt, Federico Tombari, Tim Landgraf", "title": "Restricting the Flow: Information Bottlenecks for Attribution", "comments": "18 pages, 12 figures, accepted at ICLR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods provide insights into the decision-making of machine\nlearning models like artificial neural networks. For a given input sample, they\nassign a relevance score to each individual input variable, such as the pixels\nof an image. In this work we adapt the information bottleneck concept for\nattribution. By adding noise to intermediate feature maps we restrict the flow\nof information and can quantify (in bits) how much information image regions\nprovide. We compare our method against ten baselines using three different\nmetrics on VGG-16 and ResNet-50, and find that our methods outperform all\nbaselines in five out of six settings. The method's information-theoretic\nfoundation provides an absolute frame of reference for attribution values\n(bits) and a guarantee that regions scored close to zero are not necessary for\nthe network's decision. For reviews: https://openreview.net/forum?id=S1xWh1rYwB\nFor code: https://github.com/BioroboticsLab/IBA\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 11:24:35 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 18:37:23 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 17:31:52 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 14:21:37 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Schulz", "Karl", ""], ["Sixt", "Leon", ""], ["Tombari", "Federico", ""], ["Landgraf", "Tim", ""]]}, {"id": "2001.00448", "submitter": "Nishai Kooverjee", "authors": "Nishai Kooverjee, Steven James, Terence van Zyl", "title": "Inter- and Intra-domain Knowledge Transfer for Related Tasks in Deep\n  Character Recognition", "comments": "To be published in SAUPEC/RobMech/PRASA 2020. Consists of 6 pages,\n  with 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training a deep neural network on the ImageNet dataset is a common\npractice for training deep learning models, and generally yields improved\nperformance and faster training times. The technique of pre-training on one\ntask and then retraining on a new one is called transfer learning. In this\npaper we analyse the effectiveness of using deep transfer learning for\ncharacter recognition tasks. We perform three sets of experiments with varying\nlevels of similarity between source and target tasks to investigate the\nbehaviour of different types of knowledge transfer. We transfer both parameters\nand features and analyse their behaviour. Our results demonstrate that no\nsignificant advantage is gained by using a transfer learning approach over a\ntraditional machine learning approach for our character recognition tasks. This\nsuggests that using transfer learning does not necessarily presuppose a better\nperforming model in all cases.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 14:18:25 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kooverjee", "Nishai", ""], ["James", "Steven", ""], ["van Zyl", "Terence", ""]]}, {"id": "2001.00449", "submitter": "Michael Neunert", "authors": "Michael Neunert, Abbas Abdolmaleki, Markus Wulfmeier, Thomas Lampe,\n  Jost Tobias Springenberg, Roland Hafner, Francesco Romano, Jonas Buchli,\n  Nicolas Heess, Martin Riedmiller", "title": "Continuous-Discrete Reinforcement Learning for Hybrid Control in\n  Robotics", "comments": "Presented at the 3rd Conference on Robot Learning (CoRL 2019), Osaka,\n  Japan. Video: https://youtu.be/eUqQDLQXb7I", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world control problems involve both discrete decision variables -\nsuch as the choice of control modes, gear switching or digital outputs - as\nwell as continuous decision variables - such as velocity setpoints, control\ngains or analogue outputs. However, when defining the corresponding optimal\ncontrol or reinforcement learning problem, it is commonly approximated with\nfully continuous or fully discrete action spaces. These simplifications aim at\ntailoring the problem to a particular algorithm or solver which may only\nsupport one type of action space. Alternatively, expert heuristics are used to\nremove discrete actions from an otherwise continuous space. In contrast, we\npropose to treat hybrid problems in their 'native' form by solving them with\nhybrid reinforcement learning, which optimizes for discrete and continuous\nactions simultaneously. In our experiments, we first demonstrate that the\nproposed approach efficiently solves such natively hybrid reinforcement\nlearning problems. We then show, both in simulation and on robotic hardware,\nthe benefits of removing possibly imperfect expert-designed heuristics. Lastly,\nhybrid reinforcement learning encourages us to rethink problem definitions. We\npropose reformulating control problems, e.g. by adding meta actions, to improve\nexploration or reduce mechanical wear and tear.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 14:19:33 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Neunert", "Michael", ""], ["Abdolmaleki", "Abbas", ""], ["Wulfmeier", "Markus", ""], ["Lampe", "Thomas", ""], ["Springenberg", "Jost Tobias", ""], ["Hafner", "Roland", ""], ["Romano", "Francesco", ""], ["Buchli", "Jonas", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2001.00461", "submitter": "Marcel Hildebrandt", "authors": "Marcel Hildebrandt, Jorge Andres Quintero Serna, Yunpu Ma, Martin\n  Ringsquandl, Mitchell Joblin, Volker Tresp", "title": "Reasoning on Knowledge Graphs with Debate Dynamics", "comments": "AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for automatic reasoning on knowledge graphs based\non debate dynamics. The main idea is to frame the task of triple classification\nas a debate game between two reinforcement learning agents which extract\narguments -- paths in the knowledge graph -- with the goal to promote the fact\nbeing true (thesis) or the fact being false (antithesis), respectively. Based\non these arguments, a binary classifier, called the judge, decides whether the\nfact is true or false. The two agents can be considered as sparse, adversarial\nfeature generators that present interpretable evidence for either the thesis or\nthe antithesis. In contrast to other black-box methods, the arguments allow\nusers to get an understanding of the decision of the judge. Since the focus of\nthis work is to create an explainable method that maintains a competitive\npredictive accuracy, we benchmark our method on the triple classification and\nlink prediction task. Thereby, we find that our method outperforms several\nbaselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also\nconduct a survey and find that the extracted arguments are informative for\nusers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 14:44:23 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Hildebrandt", "Marcel", ""], ["Serna", "Jorge Andres Quintero", ""], ["Ma", "Yunpu", ""], ["Ringsquandl", "Martin", ""], ["Joblin", "Mitchell", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.00479", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli and Lenka Zdeborova", "title": "Thresholds of descending algorithms in inference problems", "comments": "8 pages, 4 figures", "journal-ref": "J. Stat. Mech. (2020) 034004", "doi": "10.1088/1742-5468/ab7123", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review recent works on analyzing the dynamics of gradient-based algorithms\nin a prototypical statistical inference problem. Using methods and insights\nfrom the physics of glassy systems, these works showed how to understand\nquantitatively and qualitatively the performance of gradient-based algorithms.\nHere we review the key results and their interpretation in non-technical terms\naccessible to a wide audience of physicists in the context of related works.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:08:40 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 08:53:20 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Zdeborova", "Lenka", ""]]}, {"id": "2001.00483", "submitter": "Xin Wang", "authors": "Xin Wang", "title": "Reject Illegal Inputs with Generative Classifier Derived from Any\n  Discriminative Classifier", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative classifiers have been shown promising to detect illegal inputs\nincluding adversarial examples and out-of-distribution samples. Supervised Deep\nInfomax~(SDIM) is a scalable end-to-end framework to learn generative\nclassifiers. In this paper, we propose a modification of SDIM termed\nSDIM-\\emph{logit}. Instead of training generative classifier from scratch,\nSDIM-\\emph{logit} first takes as input the logits produced any given\ndiscriminative classifier, and generate logit representations; then a\ngenerative classifier is derived by imposing statistical constraints on logit\nrepresentations. SDIM-\\emph{logit} could inherit the performance of the\ndiscriminative classifier without loss. SDIM-\\emph{logit} incurs a negligible\nnumber of additional parameters, and can be efficiently trained with base\nclassifiers fixed. We perform \\emph{classification with rejection}, where test\nsamples whose class conditionals are smaller than pre-chosen thresholds will be\nrejected without predictions. Experiments on illegal inputs, including\nadversarial examples, samples with common corruptions, and\nout-of-distribution~(OOD) samples show that allowed to reject a portion of test\nsamples, SDIM-\\emph{logit} significantly improves the performance on the left\ntest sets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:11:58 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Wang", "Xin", ""]]}, {"id": "2001.00496", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier, Thomas Gabor, Thomy Phan, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Uncertainty-Based Out-of-Distribution Classification in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1901.02219", "journal-ref": "Proceedings of the 12th International Conference on Agents and\n  Artificial Intelligence - Volume 2: ICAART, 2020, ISBN 978-989-758-395-7,\n  pages 522-529", "doi": "10.5220/0008949905220529", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to out-of-distribution (OOD) data is an important goal in building\nreliable machine learning systems. Especially in autonomous systems, wrong\npredictions for OOD inputs can cause safety critical situations. As a first\nstep towards a solution, we consider the problem of detecting such data in a\nvalue-based deep reinforcement learning (RL) setting. Modelling this problem as\na one-class classification problem, we propose a framework for\nuncertainty-based OOD classification: UBOOD. It is based on the effect that an\nagent's epistemic uncertainty is reduced for situations encountered during\ntraining (in-distribution), and thus lower than for unencountered (OOD)\nsituations. Being agnostic towards the approach used for estimating epistemic\nuncertainty, combinations with different uncertainty estimation methods, e.g.\napproximate Bayesian inference methods or ensembling techniques are possible.\nWe further present a first viable solution for calculating a dynamic\nclassification threshold, based on the uncertainty distribution of the training\ndata. Evaluation shows that the framework produces reliable classification\nresults when combined with ensemble-based estimators, while the combination\nwith concrete dropout-based estimators fails to reliably detect OOD situations.\nIn summary, UBOOD presents a viable approach for OOD classification in deep RL\nsettings by leveraging the epistemic uncertainty of the agent's value function.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:52:49 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["Gabor", "Thomas", ""], ["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2001.00501", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed H Tewfik", "title": "EEG based Continuous Speech Recognition using Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate continuous speech recognition using\nelectroencephalography (EEG) features using recently introduced end-to-end\ntransformer based automatic speech recognition (ASR) model. Our results\ndemonstrate that transformer based model demonstrate faster training compared\nto recurrent neural network (RNN) based sequence-to-sequence EEG models and\nbetter performance during inference time for smaller test set vocabulary but as\nwe increase the vocabulary size, the performance of the RNN based models were\nbetter than transformer based model on a limited English vocabulary.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 08:36:59 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 17:09:18 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 05:50:08 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "2001.00503", "submitter": "Letian Chen", "authors": "Letian Chen, Rohan Paleja, Muyleng Ghuy, Matthew Gombolay", "title": "Joint Goal and Strategy Inference across Heterogeneous Demonstrators via\n  Reward Network Distillation", "comments": "In Proceedings of the 2020 ACM/IEEE In-ternational Conference on\n  Human-Robot Interaction (HRI '20), March 23 to 26, 2020, Cambridge, United\n  Kingdom.ACM, New York, NY, USA, 10 pages", "journal-ref": null, "doi": "10.1145/3319502.3374791", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has achieved tremendous success as a general\nframework for learning how to make decisions. However, this success relies on\nthe interactive hand-tuning of a reward function by RL experts. On the other\nhand, inverse reinforcement learning (IRL) seeks to learn a reward function\nfrom readily-obtained human demonstrations. Yet, IRL suffers from two major\nlimitations: 1) reward ambiguity - there are an infinite number of possible\nreward functions that could explain an expert's demonstration and 2)\nheterogeneity - human experts adopt varying strategies and preferences, which\nmakes learning from multiple demonstrators difficult due to the common\nassumption that demonstrators seeks to maximize the same reward. In this work,\nwe propose a method to jointly infer a task goal and humans' strategic\npreferences via network distillation. This approach enables us to distill a\nrobust task reward (addressing reward ambiguity) and to model each strategy's\nobjective (handling heterogeneity). We demonstrate our algorithm can better\nrecover task reward and strategy rewards and imitate the strategies in two\nsimulated tasks and a real-world table tennis task.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 16:04:21 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 18:45:39 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 16:04:47 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Letian", ""], ["Paleja", "Rohan", ""], ["Ghuy", "Muyleng", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2001.00528", "submitter": "Devendra Singh Dhami", "authors": "Devendra Singh Dhami, Siwen Yan, Gautam Kunapuli, Sriraam Natarajan", "title": "Non-Parametric Learning of Gaifman Models", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of structure learning for Gaifman models and learn\nrelational features that can be used to derive feature representations from a\nknowledge base. These relational features are first-order rules that are then\npartially grounded and counted over local neighborhoods of a Gaifman model to\nobtain the feature representations. We propose a method for learning these\nrelational features for a Gaifman model by using relational tree distances. Our\nempirical evaluation on real data sets demonstrates the superiority of our\napproach over classical rule-learning.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 17:20:53 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 19:01:20 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Dhami", "Devendra Singh", ""], ["Yan", "Siwen", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2001.00543", "submitter": "S. Rasoul Etesami", "authors": "S. Rasoul Etesami, Negar Kiyavash, Vincent Leon, H. Vincent Poor", "title": "Toward Optimal Adversarial Policies in the Multiplicative Learning\n  System with a Malicious Expert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a learning system based on the conventional multiplicative weight\n(MW) rule that combines experts' advice to predict a sequence of true outcomes.\nIt is assumed that one of the experts is malicious and aims to impose the\nmaximum loss on the system. The loss of the system is naturally defined to be\nthe aggregate absolute difference between the sequence of predicted outcomes\nand the true outcomes. We consider this problem under both offline and online\nsettings. In the offline setting where the malicious expert must choose its\nentire sequence of decisions a priori, we show somewhat surprisingly that a\nsimple greedy policy of always reporting false prediction is asymptotically\noptimal with an approximation ratio of $1+O(\\sqrt{\\frac{\\ln N}{N}})$, where $N$\nis the total number of prediction stages. In particular, we describe a policy\nthat closely resembles the structure of the optimal offline policy. For the\nonline setting where the malicious expert can adaptively make its decisions, we\nshow that the optimal online policy can be efficiently computed by solving a\ndynamic program in $O(N^3)$. Our results provide a new direction for\nvulnerability assessment of commonly used learning algorithms to adversarial\nattacks where the threat is an integral part of the system.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:04:46 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 02:43:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Etesami", "S. Rasoul", ""], ["Kiyavash", "Negar", ""], ["Leon", "Vincent", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2001.00559", "submitter": "Changwei Hu", "authors": "Changwei Hu, Yifan Hu, Sungyong Seo", "title": "A Deep Structural Model for Analyzing Correlated Multivariate Time\n  Series", "comments": null, "journal-ref": "IEEE ICMLA 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series are routinely encountered in real-world\napplications, and in many cases, these time series are strongly correlated. In\nthis paper, we present a deep learning structural time series model which can\n(i) handle correlated multivariate time series input, and (ii) forecast the\ntargeted temporal sequence by explicitly learning/extracting the trend,\nseasonality, and event components. The trend is learned via a 1D and 2D\ntemporal CNN and LSTM hierarchical neural net. The CNN-LSTM architecture can\n(i) seamlessly leverage the dependency among multiple correlated time series in\na natural way, (ii) extract the weighted differencing feature for better trend\nlearning, and (iii) memorize the long-term sequential pattern. The seasonality\ncomponent is approximated via a non-liner function of a set of Fourier terms,\nand the event components are learned by a simple linear function of regressor\nencoding the event dates. We compare our model with several state-of-the-art\nmethods through a comprehensive set of experiments on a variety of time series\ndata sets, such as forecasts of Amazon AWS Simple Storage Service (S3) and\nElastic Compute Cloud (EC2) billings, and the closing prices for corporate\nstocks in the same category.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:48:29 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Hu", "Changwei", ""], ["Hu", "Yifan", ""], ["Seo", "Sungyong", ""]]}, {"id": "2001.00563", "submitter": "Bin Ren Dr.", "authors": "Bin Ren, Laurent Pueyo, Christine Chen, \\'Elodie Choquet, John H.\n  Debes, Gaspard Duch\\^ene, Fran\\c{c}ois M\\'enard, Marshall D. Perrin", "title": "Using Data Imputation for Signal Separation in High Contrast Imaging", "comments": "18 pages, 9 figures, ApJ published. Modified AASTeX template at\n  https://github.com/seawander/aastex_pwned", "journal-ref": "ApJ 892 (2020) 74", "doi": "10.3847/1538-4357/ab7024", "report-no": null, "categories": "astro-ph.IM astro-ph.EP astro-ph.SR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To characterize circumstellar systems in high contrast imaging, the\nfundamental step is to construct a best point spread function (PSF) template\nfor the non-circumstellar signals (i.e., star light and speckles) and separate\nit from the observation. With existing PSF construction methods, the\ncircumstellar signals (e.g., planets, circumstellar disks) are unavoidably\naltered by over-fitting and/or self-subtraction, making forward modeling a\nnecessity to recover these signals. We present a forward modeling--free\nsolution to these problems with data imputation using sequential non-negative\nmatrix factorization (DI-sNMF). DI-sNMF first converts this signal separation\nproblem to a \"missing data\" problem in statistics by flagging the regions which\nhost circumstellar signals as missing data, then attributes PSF signals to\nthese regions. We mathematically prove it to have negligible alteration to\ncircumstellar signals when the imputation region is relatively small, which\nthus enables precise measurement for these circumstellar objects. We apply it\nto simulated point source and circumstellar disk observations to demonstrate\nits proper recovery of them. We apply it to Gemini Planet Imager (GPI) K1-band\nobservations of the debris disk surrounding HR 4796A, finding a tentative trend\nthat the dust is more forward scattering as the wavelength increases. We expect\nDI-sNMF to be applicable to other general scenarios where the separation of\nsignals is needed.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:55:18 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 17:09:12 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 17:37:02 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Ren", "Bin", ""], ["Pueyo", "Laurent", ""], ["Chen", "Christine", ""], ["Choquet", "\u00c9lodie", ""], ["Debes", "John H.", ""], ["Duch\u00eane", "Gaspard", ""], ["M\u00e9nard", "Fran\u00e7ois", ""], ["Perrin", "Marshall D.", ""]]}, {"id": "2001.00564", "submitter": "Yuting Ng", "authors": "Yuting Ng (1), Jo\\~ao M. Pereira (1), Denis Garagic (2), Vahid Tarokh\n  (1) ((1) Duke University, (2) BAE Systems FAST Labs)", "title": "Robust Marine Buoy Placement for Ship Detection Using Dropout K-Means", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marine buoys aid in the battle against Illegal, Unreported and Unregulated\n(IUU) fishing by detecting fishing vessels in their vicinity. Marine buoys,\nhowever, may be disrupted by natural causes and buoy vandalism. In this paper,\nwe formulate marine buoy placement as a clustering problem, and propose dropout\nk-means and dropout k-median to improve placement robustness to buoy\ndisruption.\n  We simulated the passage of ships in the Gabonese waters near West Africa\nusing historical Automatic Identification System (AIS) data, then compared the\nship detection probability of dropout k-means to classic k-means and dropout\nk-median to classic k-median. With 5 buoys, the buoy arrangement computed by\nclassic k-means, dropout k-means, classic k-median and dropout k-median have\nship detection probabilities of 38%, 45%, 48% and 52%.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:55:56 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 19:44:57 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ng", "Yuting", "", "Duke University"], ["Pereira", "Jo\u00e3o M.", "", "Duke University"], ["Garagic", "Denis", "", "BAE Systems FAST Labs"], ["Tarokh", "Vahid", "", "Duke University"]]}, {"id": "2001.00570", "submitter": "Yaoshiang Ho", "authors": "Yaoshiang Ho, Samuel Wookey", "title": "The Real-World-Weight Cross-Entropy Loss Function: Modeling the Costs of\n  Mislabeling", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2962617", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new metric to measure goodness-of-fit for\nclassifiers, the Real World Cost function. This metric factors in information\nabout a real world problem, such as financial impact, that other measures like\naccuracy or F1 do not. This metric is also more directly interpretable for\nusers. To optimize for this metric, we introduce the Real-World- Weight\nCrossentropy loss function, in both binary and single-label classification\nvariants. Both variants allow direct input of real world costs as weights. For\nsingle-label, multicategory classification, our loss function also allows\ndirect penalization of probabilistic false positives, weighted by label, during\nthe training of a machine learning model. We compare the design of our loss\nfunction to the binary crossentropy and categorical crossentropy functions, as\nwell as their weighted variants, to discuss the potential for improvement in\nhandling a variety of known shortcomings of machine learning, ranging from\nimbalanced classes to medical diagnostic error to reinforcement of social bias.\nWe create scenarios that emulate those issues using the MNIST data set and\ndemonstrate empirical results of our new loss function. Finally, we sketch a\nproof of this function based on Maximum Likelihood Estimation and discuss\nfuture directions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 08:54:42 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ho", "Yaoshiang", ""], ["Wookey", "Samuel", ""]]}, {"id": "2001.00576", "submitter": "Weixin Liang", "authors": "Weixin Liang, Zixuan Liu and Can Liu", "title": "DAWSON: A Domain Adaptive Few Shot Generation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a Generative Adversarial Networks (GAN) for a new domain from\nscratch requires an enormous amount of training data and days of training time.\nTo this end, we propose DAWSON, a Domain Adaptive FewShot Generation\nFrameworkFor GANs based on meta-learning. A major challenge of applying\nmeta-learning GANs is to obtain gradients for the generator from evaluating it\non development sets due to the likelihood-free nature of GANs. To address this\nchallenge, we propose an alternative GAN training procedure that naturally\ncombines the two-step training procedure of GANs and the two-step training\nprocedure of meta-learning algorithms. DAWSON is a plug-and-play framework that\nsupports a broad family of meta-learning algorithms and various GANs with\narchitectural-variants. Based on DAWSON, We also propose MUSIC MATINEE, which\nis the first few-shot music generation model. Our experiments show that MUSIC\nMATINEE could quickly adapt to new domains with only tens of songs from the\ntarget domains. We also show that DAWSON can learn to generate new digits with\nonly four samples in the MNIST dataset. We release source codes implementation\nof DAWSON in both PyTorch and Tensorflow, generated music samples on two genres\nand the lightning video.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 00:59:10 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Liang", "Weixin", ""], ["Liu", "Zixuan", ""], ["Liu", "Can", ""]]}, {"id": "2001.00585", "submitter": "Masoud Mohseni", "authors": "Gavin S. Hartnett, Masoud Mohseni", "title": "Self-Supervised Learning of Generative Spin-Glasses with Normalizing\n  Flows", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin-glasses are universal models that can capture complex behavior of\nmany-body systems at the interface of statistical physics and computer science\nincluding discrete optimization, inference in graphical models, and automated\nreasoning. Computing the underlying structure and dynamics of such complex\nsystems is extremely difficult due to the combinatorial explosion of their\nstate space. Here, we develop deep generative continuous spin-glass\ndistributions with normalizing flows to model correlations in generic discrete\nproblems. We use a self-supervised learning paradigm by automatically\ngenerating the data from the spin-glass itself. We demonstrate that key\nphysical and computational properties of the spin-glass phase can be\nsuccessfully learned, including multi-modal steady-state distributions and\ntopological structures among metastable states. Remarkably, we observe that the\nlearning itself corresponds to a spin-glass phase transition within the layers\nof the trained normalizing flows. The inverse normalizing flows learns to\nperform reversible multi-scale coarse-graining operations which are very\ndifferent from the typical irreversible renormalization group techniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:00:01 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 19:00:01 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hartnett", "Gavin S.", ""], ["Mohseni", "Masoud", ""]]}, {"id": "2001.00594", "submitter": "Changwei Hu", "authors": "Yao Zhan, Changwei Hu, Yifan Hu, Tejaswi Kasturi, Shanmugam Ramasamy,\n  Matt Gillingham, Keith Yamamoto", "title": "Large-scale Gender/Age Prediction of Tumblr Users", "comments": null, "journal-ref": "IEEE ICMLA 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tumblr, as a leading content provider and social media, attracts 371 million\nmonthly visits, 280 million blogs and 53.3 million daily posts. The popularity\nof Tumblr provides great opportunities for advertisers to promote their\nproducts through sponsored posts. However, it is a challenging task to target\nspecific demographic groups for ads, since Tumblr does not require user\ninformation like gender and ages during their registration. Hence, to promote\nad targeting, it is essential to predict user's demography using rich content\nsuch as posts, images and social connections. In this paper, we propose graph\nbased and deep learning models for age and gender predictions, which take into\naccount user activities and content features. For graph based models, we come\nup with two approaches, network embedding and label propagation, to generate\nconnection features as well as directly infer user's demography. For deep\nlearning models, we leverage convolutional neural network (CNN) and multilayer\nperceptron (MLP) to prediction users' age and gender. Experimental results on\nreal Tumblr daily dataset, with hundreds of millions of active users and\nbillions of following relations, demonstrate that our approaches significantly\noutperform the baseline model, by improving the accuracy relatively by 81% for\nage, and the AUC and accuracy by 5\\% for gender.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:01:45 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zhan", "Yao", ""], ["Hu", "Changwei", ""], ["Hu", "Yifan", ""], ["Kasturi", "Tejaswi", ""], ["Ramasamy", "Shanmugam", ""], ["Gillingham", "Matt", ""], ["Yamamoto", "Keith", ""]]}, {"id": "2001.00602", "submitter": "Wa\\\"iss Azizian", "authors": "Wa\\\"iss Azizian, Damien Scieur, Ioannis Mitliagkas, Simon\n  Lacoste-Julien, Gauthier Gidel", "title": "Accelerating Smooth Games by Manipulating Spectral Shapes", "comments": "Appears in: Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020). 34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use matrix iteration theory to characterize acceleration in smooth games.\nWe define the spectral shape of a family of games as the set containing all\neigenvalues of the Jacobians of standard gradient dynamics in the family.\nShapes restricted to the real line represent well-understood classes of\nproblems, like minimization. Shapes spanning the complex plane capture the\nadded numerical challenges in solving smooth games. In this framework, we\ndescribe gradient-based methods, such as extragradient, as transformations on\nthe spectral shape. Using this perspective, we propose an optimal algorithm for\nbilinear games. For smooth and strongly monotone operators, we identify a\ncontinuum between convex minimization, where acceleration is possible using\nPolyak's momentum, and the worst case where gradient descent is optimal.\nFinally, going beyond first-order methods, we propose an accelerated version of\nconsensus optimization.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:21:48 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 14:51:46 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Azizian", "Wa\u00efss", ""], ["Scieur", "Damien", ""], ["Mitliagkas", "Ioannis", ""], ["Lacoste-Julien", "Simon", ""], ["Gidel", "Gauthier", ""]]}, {"id": "2001.00621", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Alan Colman, Jun Han, Asif Irshad Khan, Yoosef B.\n  Abushark and Khaled Salah", "title": "BehavDT: A Behavioral Decision Tree Learning to Build User-Centric\n  Context-Aware Predictive Model", "comments": null, "journal-ref": "Journal: Mobile Networks and Applications, Springer, 2019", "doi": "10.1007/s11036-019-01443-z", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates the problem of building a context-aware predictive\nmodel based on user diverse behavioral activities with smartphones. In the area\nof machine learning and data science, a tree-like model as that of decision\ntree is considered as one of the most popular classification techniques, which\ncan be used to build a data-driven predictive model. The traditional decision\ntree model typically creates a number of leaf nodes as decision nodes that\nrepresent context-specific rigid decisions, and consequently may cause\noverfitting problem in behavior modeling. However, in many practical scenarios\nwithin the context-aware environment, the generalized outcomes could play an\nimportant role to effectively capture user behavior. In this paper, we propose\na behavioral decision tree, \"BehavDT\" context-aware model that takes into\naccount user behavior-oriented generalization according to individual\npreference level. The BehavDT model outputs not only the generalized decisions\nbut also the context-specific decisions in relevant exceptional cases. The\neffectiveness of our BehavDT model is studied by conducting experiments on\nindividual user real smartphone datasets. Our experimental results show that\nthe proposed BehavDT context-aware model is more effective when compared with\nthe traditional machine learning approaches, in predicting user diverse\nbehaviors considering multi-dimensional contexts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 08:58:24 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""], ["Khan", "Asif Irshad", ""], ["Abushark", "Yoosef B.", ""], ["Salah", "Khaled", ""]]}, {"id": "2001.00629", "submitter": "I-Sheng Yang", "authors": "I-Sheng Yang", "title": "A Loss-Function for Causal Machine-Learning", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal machine-learning is about predicting the net-effect (true-lift) of\ntreatments. Given the data of a treatment group and a control group, it is\nsimilar to a standard supervised-learning problem. Unfortunately, there is no\nsimilarly well-defined loss function due to the lack of point-wise true values\nin the data. Many advances in modern machine-learning are not directly\napplicable due to the absence of such loss function.\n  We propose a novel method to define a loss function in this context, which is\nequal to mean-square-error (MSE) in a standard regression problem. Our loss\nfunction is universally applicable, thus providing a general standard to\nevaluate the quality of any model/strategy that predicts the true-lift. We\ndemonstrate that despite its novel definition, one can still perform gradient\ndescent directly on this loss function to find the best fit. This leads to a\nnew way to train any parameter-based model, such as deep neural networks, to\nsolve causal machine-learning problems without going through the meta-learner\nstrategy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:22:18 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yang", "I-Sheng", ""]]}, {"id": "2001.00631", "submitter": "Elena Sizikova", "authors": "Miju Ahn, Nicole Eikmeier, Jamie Haddock, Lara Kassab, Alona\n  Kryshchenko, Kathryn Leonard, Deanna Needell, R. W. M. A. Madushani, Elena\n  Sizikova, Chuntian Wang", "title": "On Large-Scale Dynamic Topic Modeling with Nonnegative CP Tensor\n  Decomposition", "comments": "23 pages, 29 figures, submitted to Women in Data Science and\n  Mathematics (WiSDM) Workshop Proceedings, \"Advances in Data Science\",\n  AWM-Springer series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is currently an unprecedented demand for large-scale temporal data\nanalysis due to the explosive growth of data. Dynamic topic modeling has been\nwidely used in social and data sciences with the goal of learning latent topics\nthat emerge, evolve, and fade over time. Previous work on dynamic topic\nmodeling primarily employ the method of nonnegative matrix factorization (NMF),\nwhere slices of the data tensor are each factorized into the product of\nlower-dimensional nonnegative matrices. With this approach, however,\ninformation contained in the temporal dimension of the data is often neglected\nor underutilized. To overcome this issue, we propose instead adopting the\nmethod of nonnegative CANDECOMP/PARAPAC (CP) tensor decomposition (NNCPD),\nwhere the data tensor is directly decomposed into a minimal sum of outer\nproducts of nonnegative vectors, thereby preserving the temporal information.\nThe viability of NNCPD is demonstrated through application to both synthetic\nand real data, where significantly improved results are obtained compared to\nthose of typical NMF-based methods. The advantages of NNCPD over such\napproaches are studied and discussed. To the best of our knowledge, this is the\nfirst time that NNCPD has been utilized for the purpose of dynamic topic\nmodeling, and our findings will be transformative for both applications and\nfurther developments.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:28:10 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 00:02:25 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ahn", "Miju", ""], ["Eikmeier", "Nicole", ""], ["Haddock", "Jamie", ""], ["Kassab", "Lara", ""], ["Kryshchenko", "Alona", ""], ["Leonard", "Kathryn", ""], ["Needell", "Deanna", ""], ["Madushani", "R. W. M. A.", ""], ["Sizikova", "Elena", ""], ["Wang", "Chuntian", ""]]}, {"id": "2001.00636", "submitter": "David Cortes", "authors": "David Cortes", "title": "Explainable outlier detection through decision tree conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes an outlier detection procedure (named \"OutlierTree\")\nloosely based on the GritBot software developed by RuleQuest research, which\nworks by evaluating and following supervised decision tree splits on variables,\nin whose branches 1-d confidence intervals are constructed for the target\nvariable and potential outliers flagged according to these confidence\nintervals. Under this logic, it's possible to produce human-readable\nexplanations for why a given value of a variable in an observation can be\nconsidered as outlier, by considering the decision tree branch conditions along\nwith general distribution statistics among the non-outlier observations that\nfell into the same branch, which can then be contrasted against the value which\nlies outside the CI. The supervised splits help to ensure that the generated\nconditions are not spurious, but rather related to the target variable and\nhaving logical breakpoints.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:45:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "2001.00637", "submitter": "Steven Atkinson", "authors": "Steven Atkinson and Sayan Ghosh and Natarajan Chennimalai-Kumar and\n  Genghis Khan and Liping Wang", "title": "Bayesian task embedding for few-shot Bayesian optimization", "comments": "To appear in proceedings of the AIAA SciTech 2020 Forum. 17 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for Bayesian optimization by which one may incorporate\ndata from multiple systems whose quantitative interrelationships are unknown a\npriori. All general (nonreal-valued) features of the systems are associated\nwith continuous latent variables that enter as inputs into a single metamodel\nthat simultaneously learns the response surfaces of all of the systems.\nBayesian inference is used to determine appropriate beliefs regarding the\nlatent variables. We explain how the resulting probabilistic metamodel may be\nused for Bayesian optimization tasks and demonstrate its implementation on a\nvariety of synthetic and real-world examples, comparing its performance under\nzero-, one-, and few-shot settings against traditional Bayesian optimization,\nwhich usually requires substantially more data from the system of interest.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:46:48 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Atkinson", "Steven", ""], ["Ghosh", "Sayan", ""], ["Chennimalai-Kumar", "Natarajan", ""], ["Khan", "Genghis", ""], ["Wang", "Liping", ""]]}, {"id": "2001.00677", "submitter": "Huan Song", "authors": "Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, Liu Ren", "title": "Improve Unsupervised Domain Adaptation with Mixup Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation studies the problem of utilizing a relevant\nsource domain with abundant labels to build predictive modeling for an\nunannotated target domain. Recent work observe that the popular adversarial\napproach of learning domain-invariant features is insufficient to achieve\ndesirable target domain performance and thus introduce additional training\nconstraints, e.g. cluster assumption. However, these approaches impose the\nconstraints on source and target domains individually, ignoring the important\ninterplay between them. In this work, we propose to enforce training\nconstraints across domains using mixup formulation to directly address the\ngeneralization performance for target data. In order to tackle potentially huge\ndomain discrepancy, we further propose a feature-level consistency regularizer\nto facilitate the inter-domain constraint. When adding intra-domain mixup and\ndomain adversarial learning, our general framework significantly improves\nstate-of-the-art performance on several important tasks from both image\nclassification and human activity recognition.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 01:21:27 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yan", "Shen", ""], ["Song", "Huan", ""], ["Li", "Nanxiang", ""], ["Zou", "Lincan", ""], ["Ren", "Liu", ""]]}, {"id": "2001.00682", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh and Dianne P. O'Leary", "title": "Auditing and Debugging Deep Learning Models via Decision Boundaries:\n  Individual-level and Group-level Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been criticized for their lack of easy\ninterpretation, which undermines confidence in their use for important\napplications. Nevertheless, they are consistently utilized in many\napplications, consequential to humans' lives, mostly because of their better\nperformance. Therefore, there is a great need for computational methods that\ncan explain, audit, and debug such models. Here, we use flip points to\naccomplish these goals for deep learning models with continuous output scores\n(e.g., computed by softmax), used in social applications. A flip point is any\npoint that lies on the boundary between two output classes: e.g. for a model\nwith a binary yes/no output, a flip point is any input that generates equal\nscores for \"yes\" and \"no\". The flip point closest to a given input is of\nparticular importance because it reveals the least changes in the input that\nwould change a model's classification, and we show that it is the solution to a\nwell-posed optimization problem. Flip points also enable us to systematically\nstudy the decision boundaries of a deep learning classifier. The resulting\ninsight into the decision boundaries of a deep model can clearly explain the\nmodel's output on the individual-level, via an explanation report that is\nunderstandable by non-experts. We also develop a procedure to understand and\naudit model behavior towards groups of people. Flip points can also be used to\nalter the decision boundaries in order to improve undesirable behaviors. We\ndemonstrate our methods by investigating several models trained on standard\ndatasets used in social applications of machine learning. We also identify the\nfeatures that are most responsible for particular classifications and\nmisclassifications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 01:45:36 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P.", ""]]}, {"id": "2001.00689", "submitter": "Soochan Lee", "authors": "Soochan Lee, Junsoo Ha, Dongsu Zhang, Gunhee Kim", "title": "A Neural Dirichlet Process Mixture Model for Task-Free Continual\n  Learning", "comments": "Accepted as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing interest in continual learning, most of its contemporary\nworks have been studied in a rather restricted setting where tasks are clearly\ndistinguishable, and task boundaries are known during training. However, if our\ngoal is to develop an algorithm that learns as humans do, this setting is far\nfrom realistic, and it is essential to develop a methodology that works in a\ntask-free manner. Meanwhile, among several branches of continual learning,\nexpansion-based methods have the advantage of eliminating catastrophic\nforgetting by allocating new resources to learn new data. In this work, we\npropose an expansion-based approach for task-free continual learning. Our\nmodel, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a\nset of neural network experts that are in charge of a subset of the data.\nCN-DPM expands the number of experts in a principled way under the Bayesian\nnonparametric framework. With extensive experiments, we show that our model\nsuccessfully performs task-free continual learning for both discriminative and\ngenerative tasks such as image classification and image generation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 02:07:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 23:32:01 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Lee", "Soochan", ""], ["Ha", "Junsoo", ""], ["Zhang", "Dongsu", ""], ["Kim", "Gunhee", ""]]}, {"id": "2001.00705", "submitter": "Jianghao Shen", "authors": "Jianghao Shen, Yonggan Fu, Yue Wang, Pengfei Xu, Zhangyang Wang,\n  Yingyan Lin", "title": "Fractional Skipping: Towards Finer-Grained Dynamic CNN Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While increasingly deep networks are still in general desired for achieving\nstate-of-the-art performance, for many specific inputs a simpler network might\nalready suffice. Existing works exploited this observation by learning to skip\nconvolutional layers in an input-dependent manner. However, we argue their\nbinary decision scheme, i.e., either fully executing or completely bypassing\none layer for a specific input, can be enhanced by introducing finer-grained,\n\"softer\" decisions. We therefore propose a Dynamic Fractional Skipping (DFS)\nframework. The core idea of DFS is to hypothesize layer-wise quantization (to\ndifferent bitwidths) as intermediate \"soft\" choices to be made between fully\nutilizing and skipping a layer. For each input, DFS dynamically assigns a\nbitwidth to both weights and activations of each layer, where fully executing\nand skipping could be viewed as two \"extremes\" (i.e., full bitwidth and zero\nbitwidth). In this way, DFS can \"fractionally\" exploit a layer's expressive\npower during input-adaptive inference, enabling finer-grained\naccuracy-computational cost trade-offs. It presents a unified view to link\ninput-adaptive layer skipping and input-adaptive hybrid quantization. Extensive\nexperimental results demonstrate the superior tradeoff between computational\ncost and model expressive power (accuracy) achieved by DFS. More visualizations\nalso indicate a smooth and consistent transition in the DFS behaviors,\nespecially the learned choices between layer skipping and different\nquantizations when the total computational budgets vary, validating our\nhypothesis that layer quantization could be viewed as intermediate variants of\nlayer skipping. Our source code and supplementary material are available at\n\\link{https://github.com/Torment123/DFS}.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 03:12:17 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Shen", "Jianghao", ""], ["Fu", "Yonggan", ""], ["Wang", "Yue", ""], ["Xu", "Pengfei", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "2001.00706", "submitter": "Patrick Kidger", "authors": "Patrick Kidger, Terry Lyons", "title": "Signatory: differentiable computations of the signature and logsignature\n  transforms, on both CPU and GPU", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signatory is a library for calculating and performing functionality related\nto the signature and logsignature transforms. The focus is on machine learning,\nand as such includes features such as CPU parallelism, GPU support, and\nbackpropagation. To our knowledge it is the first GPU-capable library for these\noperations. Signatory implements new features not available in previous\nlibraries, such as efficient precomputation strategies. Furthermore, several\nnovel algorithmic improvements are introduced, producing substantial real-world\nspeedups even on the CPU without parallelism. The library operates as a Python\nwrapper around C++, and is compatible with the PyTorch ecosystem. It may be\ninstalled directly via \\texttt{pip}. Source code, documentation, examples,\nbenchmarks and tests may be found at\n\\texttt{\\url{https://github.com/patrick-kidger/signatory}}. The license is\nApache-2.0.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 03:15:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 19:28:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kidger", "Patrick", ""], ["Lyons", "Terry", ""]]}, {"id": "2001.00742", "submitter": "George Monta\\~nez", "authors": "Tyler Sam, Jake Williams, Abel Tadesse, Huey Sun, George Montanez", "title": "Decomposable Probability-of-Success Metrics in Algorithmic Search", "comments": "Accepted to 12th International Conference on Agents and Artificial\n  Intelligence (ICAART 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have used a specific success metric within an algorithmic\nsearch framework to prove machine learning impossibility results. However, this\nspecific success metric prevents us from applying these results on other forms\nof machine learning, e.g. transfer learning. We define decomposable metrics as\na category of success metrics for search problems which can be expressed as a\nlinear operation on a probability distribution to solve this issue. Using an\narbitrary decomposable metric to measure the success of a search, we\ndemonstrate theorems which bound success in various ways, generalizing several\nexisting results in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 06:26:57 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Sam", "Tyler", ""], ["Williams", "Jake", ""], ["Tadesse", "Abel", ""], ["Sun", "Huey", ""], ["Montanez", "George", ""]]}, {"id": "2001.00745", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Xian Wu, Zhiqiang Tao, Yaliang Li, Bolin Ding, Ruirui Li,\n  Zhenhui Li", "title": "Automated Relational Meta-learning", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to efficiently learn with small amount of data on new tasks,\nmeta-learning transfers knowledge learned from previous tasks to the new ones.\nHowever, a critical challenge in meta-learning is the task heterogeneity which\ncannot be well handled by traditional globally shared meta-learning methods. In\naddition, current task-specific meta-learning methods may either suffer from\nhand-crafted structure design or lack the capability to capture complex\nrelations between tasks. In this paper, motivated by the way of knowledge\norganization in knowledge bases, we propose an automated relational\nmeta-learning (ARML) framework that automatically extracts the cross-task\nrelations and constructs the meta-knowledge graph. When a new task arrives, it\ncan quickly find the most relevant structure and tailor the learned structure\nknowledge to the meta-learner. As a result, the proposed framework not only\naddresses the challenge of task heterogeneity by a learned meta-knowledge\ngraph, but also increases the model interpretability. We conduct extensive\nexperiments on 2D toy regression and few-shot image classification and the\nresults demonstrate the superiority of ARML over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 07:02:25 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yao", "Huaxiu", ""], ["Wu", "Xian", ""], ["Tao", "Zhiqiang", ""], ["Li", "Yaliang", ""], ["Ding", "Bolin", ""], ["Li", "Ruirui", ""], ["Li", "Zhenhui", ""]]}, {"id": "2001.00766", "submitter": "G Manjunath", "authors": "G Manjunath", "title": "Stability and Memory-loss go Hand-in-Hand: Three Results in Dynamics &\n  Computation", "comments": "To appear in the Proceedings of the Royal Society of London, Series A", "journal-ref": null, "doi": "10.1098/rspa.2020.0563", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for universal laws that help establish a relationship between\ndynamics and computation is driven by recent expansionist initiatives in\nbiologically inspired computing. A general setting to understand both such\ndynamics and computation is a driven dynamical system that responds to a\ntemporal input. Surprisingly, we find memory-loss a feature of driven systems\nto forget their internal states helps provide unambiguous answers to the\nfollowing fundamental stability questions that have been unanswered for\ndecades: what is necessary and sufficient so that slightly different inputs\nstill lead to mostly similar responses? How does changing the driven system's\nparameters affect stability? What is the mathematical definition of the\nedge-of-criticality? We anticipate our results to be timely in understanding\nand designing biologically inspired computers that are entering an era of\ndedicated hardware implementations for neuromorphic computing and\nstate-of-the-art reservoir computing applications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 09:28:00 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 12:24:10 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Manjunath", "G", ""]]}, {"id": "2001.00781", "submitter": "Matthias A{\\ss}enmacher", "authors": "Matthias A{\\ss}enmacher, Christian Heumann", "title": "On the comparability of Pre-trained Language Models", "comments": null, "journal-ref": "Proceedings of the 5th Swiss Text Analytics Conference (SwissText)\n  & 16th Conference on Natural Language Processing (KONVENS), Zurich,\n  Switzerland, June 23-25, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in unsupervised representation learning have successfully\nestablished the concept of transfer learning in NLP. Mainly three forces are\ndriving the improvements in this area of research: More elaborated\narchitectures are making better use of contextual information. Instead of\nsimply plugging in static pre-trained representations, these are learned based\non surrounding context in end-to-end trainable models with more intelligently\ndesigned language modelling objectives. Along with this, larger corpora are\nused as resources for pre-training large language models in a self-supervised\nfashion which are afterwards fine-tuned on supervised tasks. Advances in\nparallel computing as well as in cloud computing, made it possible to train\nthese models with growing capacities in the same or even in shorter time than\npreviously established models. These three developments agglomerate in new\nstate-of-the-art (SOTA) results being revealed in a higher and higher\nfrequency. It is not always obvious where these improvements originate from, as\nit is not possible to completely disentangle the contributions of the three\ndriving forces. We set ourselves to providing a clear and concise overview on\nseveral large pre-trained language models, which achieved SOTA results in the\nlast two years, with respect to their use of new architectures and resources.\nWe want to clarify for the reader where the differences between the models are\nand we furthermore attempt to gain some insight into the single contributions\nof lexical/computational improvements as well as of architectural changes. We\nexplicitly do not intend to quantify these contributions, but rather see our\nwork as an overview in order to identify potential starting points for\nbenchmark comparisons. Furthermore, we tentatively want to point at potential\npossibilities for improvement in the field of open-sourcing and reproducible\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 10:53:35 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["A\u00dfenmacher", "Matthias", ""], ["Heumann", "Christian", ""]]}, {"id": "2001.00784", "submitter": "Dong Liu", "authors": "Dong Liu, Chengjian Sun, Chenyang Yang, Lajos Hanzo", "title": "Optimizing Wireless Systems Using Unsupervised and\n  Reinforced-Unsupervised Deep Learning", "comments": "To appear in IEEE Network Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation and transceivers in wireless networks are usually\ndesigned by solving optimization problems subject to specific constraints,\nwhich can be formulated as variable or functional optimization. If the\nobjective and constraint functions of a variable optimization problem can be\nderived, standard numerical algorithms can be applied for finding the optimal\nsolution, which however incur high computational cost when the dimension of the\nvariable is high. To reduce the on-line computational complexity, learning the\noptimal solution as a function of the environment's status by deep neural\nnetworks (DNNs) is an effective approach. DNNs can be trained under the\nsupervision of optimal solutions, which however, is not applicable to the\nscenarios without models or for functional optimization where the optimal\nsolutions are hard to obtain. If the objective and constraint functions are\nunavailable, reinforcement learning can be applied to find the solution of a\nfunctional optimization problem, which is however not tailored to optimization\nproblems in wireless networks. In this article, we introduce unsupervised and\nreinforced-unsupervised learning frameworks for solving both variable and\nfunctional optimization problems without the supervision of the optimal\nsolutions. When the mathematical model of the environment is completely known\nand the distribution of environment's status is known or unknown, we can invoke\nunsupervised learning algorithm. When the mathematical model of the environment\nis incomplete, we introduce reinforced-unsupervised learning algorithms that\nlearn the model by interacting with the environment. Our simulation results\nconfirm the applicability of these learning frameworks by taking a user\nassociation problem as an example.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:01:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Liu", "Dong", ""], ["Sun", "Chengjian", ""], ["Yang", "Chenyang", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2001.00811", "submitter": "Georgia Papacharalampous", "authors": "Georgia Papacharalampous, Hristos Tyralis", "title": "Hydrological time series forecasting using simple combinations: Big data\n  testing and investigations on one-year ahead river flow predictability", "comments": null, "journal-ref": "Journal of Hydrology 590 (2020) 125205", "doi": "10.1016/j.jhydrol.2020.125205", "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delivering useful hydrological forecasts is critical for urban and\nagricultural water management, hydropower generation, flood protection and\nmanagement, drought mitigation and alleviation, and river basin planning and\nmanagement, among others. In this work, we present and appraise a new simple\nand flexible methodology for hydrological time series forecasting. This\nmethodology relies on (a) at least two individual forecasting methods and (b)\nthe median combiner of forecasts. The appraisal is made by using a big dataset\nconsisted of 90-year-long mean annual river flow time series from approximately\n600 stations. Covering large parts of North America and Europe, these stations\nrepresent various climate and catchment characteristics, and thus can\ncollectively support benchmarking. Five individual forecasting methods and 26\nvariants of the introduced methodology are applied to each time series. The\napplication is made in one-step ahead forecasting mode. The individual methods\nare the last-observation benchmark, simple exponential smoothing, complex\nexponential smoothing, automatic autoregressive fractionally integrated moving\naverage (ARFIMA) and Facebook's Prophet, while the 26 variants are defined by\nall the possible combinations (per two, three, four or five) of the five\nafore-mentioned methods. The new methodology is identified as well-performing\nin the long run, especially when more than two individual forecasting methods\nare combined within its framework. Moreover, the possibility of case-informed\nintegrations of diverse hydrological forecasting methods within systematic\nframeworks is algorithmically investigated and discussed. The related\ninvestigations encompass linear regression analyses, which aim at finding\ninterpretable relationships between the values of a representative forecasting\nperformance metric and the values of selected river flow statistics...\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:45:43 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 16:58:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Papacharalampous", "Georgia", ""], ["Tyralis", "Hristos", ""]]}, {"id": "2001.00818", "submitter": "Soma Dhavala", "authors": "Shakkeel Ahmed, Ravi S. Mula, Soma S. Dhavala", "title": "A Framework for Democratizing AI", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning and Artificial Intelligence are considered an integral part\nof the Fourth Industrial Revolution. Their impact, and far-reaching\nconsequences, while acknowledged, are yet to be comprehended. These\ntechnologies are very specialized, and few organizations and select highly\ntrained professionals have the wherewithal, in terms of money, manpower, and\nmight, to chart the future. However, concentration of power can lead to\nmarginalization, causing severe inequalities. Regulatory agencies and\ngovernments across the globe are creating national policies, and laws around\nthese technologies to protect the rights of the digital citizens, as well as to\nempower them. Even private, not-for-profit organizations are also contributing\nto democratizing the technologies by making them \\emph{accessible} and\n\\emph{affordable}. However, accessibility and affordability are all but a few\nof the facets of democratizing the field. Others include, but not limited to,\n\\emph{portability}, \\emph{explainability}, \\emph{credibility}, \\emph{fairness},\namong others. As one can imagine, democratizing AI is a multi-faceted problem,\nand it requires advancements in science, technology and policy. At\n\\texttt{mlsquare}, we are developing scientific tools in this space.\nSpecifically, we introduce an opinionated, extensible, \\texttt{Python}\nframework that provides a single point of interface to a variety of solutions\nin each of the categories mentioned above. We present the design details, APIs\nof the framework, reference implementations, road map for development, and\nguidelines for contributions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:30:14 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Ahmed", "Shakkeel", ""], ["Mula", "Ravi S.", ""], ["Dhavala", "Soma S.", ""]]}, {"id": "2001.00846", "submitter": "Diego Antognini", "authors": "Nikola Milojkovic, Diego Antognini, Giancarlo Bergamin, Boi Faltings\n  and Claudiu Musat", "title": "Multi-Gradient Descent for Multi-Objective Recommender Systems", "comments": "9 pages, 4 figures, Accepted at AAAI 2020 - Workshop on Interactive\n  and Conversational Recommendation Systems (WICRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems need to mirror the complexity of the environment they are\napplied in. The more we know about what might benefit the user, the more\nobjectives the recommender system has. In addition there may be multiple\nstakeholders - sellers, buyers, shareholders - in addition to legal and ethical\nconstraints. Simultaneously optimizing for a multitude of objectives,\ncorrelated and not correlated, having the same scale or not, has proven\ndifficult so far.\n  We introduce a stochastic multi-gradient descent approach to recommender\nsystems (MGDRec) to solve this problem. We show that this exceeds\nstate-of-the-art methods in traditional objective mixtures, like revenue and\nrecall. Not only that, but through gradient normalization we can combine\nfundamentally different objectives, having diverse scales, into a single\ncoherent framework. We show that uncorrelated objectives, like the proportion\nof quality products, can be improved alongside accuracy. Through the use of\nstochasticity, we avoid the pitfalls of calculating full gradients and provide\na clear setting for its applicability.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 19:56:08 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 08:04:23 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:35:21 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Milojkovic", "Nikola", ""], ["Antognini", "Diego", ""], ["Bergamin", "Giancarlo", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2001.00893", "submitter": "Eyke H\\\"ullermeier", "authors": "Mohammad Hossein Shaker and Eyke H\\\"ullermeier", "title": "Aleatoric and Epistemic Uncertainty with Random Forests", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the steadily increasing relevance of machine learning for practical\napplications, many of which are coming with safety requirements, the notion of\nuncertainty has received increasing attention in machine learning research in\nthe last couple of years. In particular, the idea of distinguishing between two\nimportant types of uncertainty, often refereed to as aleatoric and epistemic,\nhas recently been studied in the setting of supervised learning. In this paper,\nwe propose to quantify these uncertainties with random forests. More\nspecifically, we show how two general approaches for measuring the learner's\naleatoric and epistemic uncertainty in a prediction can be instantiated with\ndecision trees and random forests as learning algorithms in a classification\nsetting. In this regard, we also compare random forests with deep neural\nnetworks, which have been used for a similar purpose.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:08:44 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Shaker", "Mohammad Hossein", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2001.00916", "submitter": "Zakaria El Mrabet", "authors": "Zakaria El Mrabet, Mehdi Ezzari, Hassan Elghazi, Badr Abou El Majd", "title": "Deep Learning-Based Intrusion Detection System for Advanced Metering\n  Infrastructure", "comments": "7 pages, 6 figures. 2019 NISS19: Proceedings of the 2nd International\n  Conference on Networking, Information Systems & Security", "journal-ref": null, "doi": "10.1145/3320326.3320391", "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid is an alternative solution of the conventional power grid which\nharnesses the power of the information technology to save the energy and meet\ntoday's environment requirements. Due to the inherent vulnerabilities in the\ninformation technology, the smart grid is exposed to a wide variety of threats\nthat could be translated into cyber-attacks. In this paper, we develop a deep\nlearning-based intrusion detection system to defend against cyber-attacks in\nthe advanced metering infrastructure network. The proposed machine learning\napproach is trained and tested extensively on an empirical industrial dataset\nwhich is composed of several attack categories including the scanning, buffer\noverflow, and denial of service attacks. Then, an experimental comparison in\nterms of detection accuracy is conducted to evaluate the performance of the\nproposed approach with Naive Bayes, Support Vector Machine, and Random Forest.\nThe obtained results suggest that the proposed approaches produce optimal\nresults comparing to the other algorithms. Finally, we propose a network\narchitecture to deploy the proposed anomaly-based intrusion detection system\nacross the Advanced Metering Infrastructure network. In addition, we propose a\nnetwork security architecture composed of two types of Intrusion detection\nsystem types, Host and Network-based, deployed across the Advanced Metering\nInfrastructure network to inspect the traffic and detect the malicious one at\nall the levels.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 21:06:20 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mrabet", "Zakaria El", ""], ["Ezzari", "Mehdi", ""], ["Elghazi", "Hassan", ""], ["Majd", "Badr Abou El", ""]]}, {"id": "2001.00917", "submitter": "Zakaria El Mrabet", "authors": "Zakaria El Mrabet, Hassan El Ghazi, Naima Kaabouch", "title": "A Performance Comparison of Data Mining Algorithms Based Intrusion\n  Detection System for Smart Grid", "comments": "6 pages, 6 Figures", "journal-ref": "2019 IEEE International Conference on Electro Information\n  Technology (EIT)", "doi": "10.1109/EIT.2019.8834255", "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid is an emerging and promising technology. It uses the power of\ninformation technologies to deliver intelligently the electrical power to\ncustomers, and it allows the integration of the green technology to meet the\nenvironmental requirements. Unfortunately, information technologies have its\ninherent vulnerabilities and weaknesses that expose the smart grid to a wide\nvariety of security risks. The Intrusion detection system (IDS) plays an\nimportant role in securing smart grid networks and detecting malicious\nactivity, yet it suffers from several limitations. Many research papers have\nbeen published to address these issues using several algorithms and techniques.\nTherefore, a detailed comparison between these algorithms is needed. This paper\npresents an overview of four data mining algorithms used by IDS in Smart Grid.\nAn evaluation of performance of these algorithms is conducted based on several\nmetrics including the probability of detection, probability of false alarm,\nprobability of miss detection, efficiency, and processing time. Results show\nthat Random Forest outperforms the other three algorithms in detecting attacks\nwith higher probability of detection, lower probability of false alarm, lower\nprobability of miss detection, and higher accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:48:13 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mrabet", "Zakaria El", ""], ["Ghazi", "Hassan El", ""], ["Kaabouch", "Naima", ""]]}, {"id": "2001.00920", "submitter": "Javier Trejos", "authors": "Andres Quiros-Granados, JAvier Trejos-Zelaya", "title": "Estimation of the yield curve for Costa Rica using combinatorial\n  optimization metaheuristics applied to nonlinear regression", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The term structure of interest rates or yield curve is a function relating\nthe interest rate with its own term. Nonlinear regression models of\nNelson-Siegel and Svensson were used to estimate the yield curve using a sample\nof historical data supplied by the National Stock Exchange of Costa Rica. The\noptimization problem involved in the estimation process of model parameters is\naddressed by the use of four well known combinatorial optimization\nmetaheuristics: Ant colony optimization, Genetic algorithm, Particle swarm\noptimization and Simulated annealing. The aim of the study is to improve the\nlocal minima obtained by a classical quasi-Newton optimization method using a\ndescent direction. Good results with at least two metaheuristics are achieved,\nParticle swarm optimization and Simulated annealing. Keywords: Yield curve,\nnonlinear regression, Nelson-\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:55:44 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Quiros-Granados", "Andres", ""], ["Trejos-Zelaya", "JAvier", ""]]}, {"id": "2001.00921", "submitter": "Theodore Papamarkou", "authors": "Devanshu Agrawal, Theodore Papamarkou, Jacob Hinkle", "title": "Wide Neural Networks with Bottlenecks are Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been much work on the \"wide limit\" of neural networks,\nwhere Bayesian neural networks (BNNs) are shown to converge to a Gaussian\nprocess (GP) as all hidden layers are sent to infinite width. However, these\nresults do not apply to architectures that require one or more of the hidden\nlayers to remain narrow. In this paper, we consider the wide limit of BNNs\nwhere some hidden layers, called \"bottlenecks\", are held at finite width. The\nresult is a composition of GPs that we term a \"bottleneck neural network\nGaussian process\" (bottleneck NNGP). Although intuitive, the subtlety of the\nproof is in showing that the wide limit of a composition of networks is in fact\nthe composition of the limiting GPs. We also analyze theoretically a\nsingle-bottleneck NNGP, finding that the bottleneck induces dependence between\nthe outputs of a multi-output network that persists through extreme\npost-bottleneck depths, and prevents the kernel of the network from losing\ndiscriminative power at extreme post-bottleneck depths.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:13:45 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:12:18 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 16:17:13 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Agrawal", "Devanshu", ""], ["Papamarkou", "Theodore", ""], ["Hinkle", "Jacob", ""]]}, {"id": "2001.00926", "submitter": "Ephrem Wu", "authors": "Ephrem Wu", "title": "Learning Accurate Integer Transformer Machine-Translation Models", "comments": null, "journal-ref": null, "doi": "10.1007/s42979-021-00688-4", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for training accurate Transformer machine-translation\nmodels to run inference using 8-bit integer (INT8) hardware matrix multipliers,\nas opposed to the more costly single-precision floating-point (FP32) hardware.\nUnlike previous work, which converted only 85 Transformer matrix\nmultiplications to INT8, leaving 48 out of 133 of them in FP32 because of\nunacceptable accuracy loss, we convert them all to INT8 without compromising\naccuracy. Tested on the newstest2014 English-to-German translation task, our\nINT8 Transformer Base and Transformer Big models yield BLEU scores that are\n99.3% to 100% relative to those of the corresponding FP32 models. Our approach\nconverts all matrix-multiplication tensors from an existing FP32 model into\nINT8 tensors by automatically making range-precision trade-offs during\ntraining. To demonstrate the robustness of this approach, we also include\nresults from INT6 Transformer models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:40:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wu", "Ephrem", ""]]}, {"id": "2001.00939", "submitter": "Henning Petzka", "authors": "Henning Petzka, Michael Kamp, Linara Adilova, Mario Boley, Cristian\n  Sminchisescu", "title": "Relative Flatness and Generalization in the Interpolation Regime", "comments": "arXiv admin note: substantial text overlap with arXiv:1912.00058", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional generalization bounds are based on analyzing the limits of the\nmodel capacity. Therefore, they become vacuous in the \\emph{interpolation}\n(over-parameterized) regime of modern machine learning models where training\ndata can be fitted perfectly. This paper proposes a new approach to meaningful\ngeneralization bounds in the interpolation regime by decomposing the\ngeneralization gap into a notion of \\emph{representativeness} and \\emph{feature\nrobustness}. Representativeness captures properties of the data distribution\nand mitigates the dependence on the data dimension by exploiting the\nlow-dimensional feature representation used implicitly by the model, and\nfeature robustness captures the expected change in loss resulting from\nperturbations of these implicit features. We show that feature robustness can\nbe bounded by a relative flatness measure of the empirical loss surface for\nmodels that locally minimize the training loss. This yields an\nalgorithm-agnostic bound potentially explaining the abundance of empirical\nobservations that flatness of the loss surface is correlated with\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:39:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:06:48 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 08:56:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Petzka", "Henning", ""], ["Kamp", "Michael", ""], ["Adilova", "Linara", ""], ["Boley", "Mario", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "2001.00994", "submitter": "Guruprasad Nayak", "authors": "Guruprasad Nayak, Rahul Ghosh, Xiaowei Jia, Varun Mithal, Vipin Kumar", "title": "Semi-supervised Classification using Attention-based Regularization on\n  Coarse-resolution Data", "comments": "To appear in the proceedings of the SIAM International Conference on\n  Data Mining (SDM20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world phenomena are observed at multiple resolutions. Predictive\nmodels designed to predict these phenomena typically consider different\nresolutions separately. This approach might be limiting in applications where\npredictions are desired at fine resolutions but available training data is\nscarce. In this paper, we propose classification algorithms that leverage\nsupervision from coarser resolutions to help train models on finer resolutions.\nThe different resolutions are modeled as different views of the data in a\nmulti-view framework that exploits the complementarity of features across\ndifferent views to improve models on both views. Unlike traditional multi-view\nlearning problems, the key challenge in our case is that there is no one-to-one\ncorrespondence between instances across different views in our case, which\nrequires explicit modeling of the correspondence of instances across\nresolutions. We propose to use the features of instances at different\nresolutions to learn the correspondence between instances across resolutions\nusing an attention mechanism.Experiments on the real-world application of\nmapping urban areas using satellite observations and sentiment classification\non text data show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 21:29:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Nayak", "Guruprasad", ""], ["Ghosh", "Rahul", ""], ["Jia", "Xiaowei", ""], ["Mithal", "Varun", ""], ["Kumar", "Vipin", ""]]}, {"id": "2001.01006", "submitter": "Shixiong Zhang", "authors": "Shixiong Zhang, Xiangtao Li, Qiuzhen Lin, and Ka-Chun Wong", "title": "Review of Single-cell RNA-seq Data Clustering for Cell Type\n  Identification and Characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the advances in single-cell RNA-seq techniques have enabled\nus to perform large-scale transcriptomic profiling at single-cell resolution in\na high-throughput manner. Unsupervised learning such as data clustering has\nbecome the central component to identify and characterize novel cell types and\ngene expression patterns. In this study, we review the existing single-cell\nRNA-seq data clustering methods with critical insights into the related\nadvantages and limitations. In addition, we also review the upstream\nsingle-cell RNA-seq data processing techniques such as quality control,\nnormalization, and dimension reduction. We conduct performance comparison\nexperiments to evaluate several popular single-cell RNA-seq clustering\napproaches on two single-cell transcriptomic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 22:48:10 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Shixiong", ""], ["Li", "Xiangtao", ""], ["Lin", "Qiuzhen", ""], ["Wong", "Ka-Chun", ""]]}, {"id": "2001.01017", "submitter": "Waheed Bajwa", "authors": "Haroon Raja and Waheed U. Bajwa", "title": "Distributed Stochastic Algorithms for High-rate Streaming Principal\n  Component Analysis", "comments": "37 pages, 11 figures; preprint of a journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating the principal eigenvector of a\ncovariance matrix from independent and identically distributed data samples in\nstreaming settings. The streaming rate of data in many contemporary\napplications can be high enough that a single processor cannot finish an\niteration of existing methods for eigenvector estimation before a new sample\narrives. This paper formulates and analyzes a distributed variant of the\nclassical Krasulina's method (D-Krasulina) that can keep up with the high\nstreaming rate of data by distributing the computational load across multiple\nprocessing nodes. The analysis shows that---under appropriate\nconditions---D-Krasulina converges to the principal eigenvector in an\norder-wise optimal manner; i.e., after receiving $M$ samples across all nodes,\nits estimation error can be $O(1/M)$. In order to reduce the network\ncommunication overhead, the paper also develops and analyzes a mini-batch\nextension of D-Krasulina, which is termed DM-Krasulina. The analysis of\nDM-Krasulina shows that it can also achieve order-optimal estimation error\nrates under appropriate conditions, even when some samples have to be discarded\nwithin the network due to communication latency. Finally, experiments are\nperformed over synthetic and real-world data to validate the convergence\nbehaviors of D-Krasulina and DM-Krasulina in high-rate streaming settings.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 00:46:47 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2001.01034", "submitter": "Yiming Sun", "authors": "Yifei Li and Zheng Wang and Xiaoyu Lu and Kuangyan Song and Yiming Sun", "title": "FrequentNet : A New Interpretable Deep Learning Baseline for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has proposed a new baseline deep learning model of more benefits\nfor image classification. Different from the convolutional neural network(CNN)\npractice where filters are trained by back propagation to represent different\npatterns of an image, we are inspired by a method called \"PCANet\" in \"PCANet: A\nSimple Deep Learning Baseline for Image Classification?\" to choose filter\nvectors from basis vectors in frequency domain like Fourier coefficients or\nwavelets without back propagation. Researchers have demonstrated that those\nbasis in frequency domain can usually provide physical insights, which adds to\nthe interpretability of the model by analyzing the frequencies selected.\nBesides, the training process will also be more time efficient, mathematically\nclear and interpretable compared with the \"black-box\" training process of CNN.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 04:31:32 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 07:21:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Yifei", ""], ["Wang", "Zheng", ""], ["Lu", "Xiaoyu", ""], ["Song", "Kuangyan", ""], ["Sun", "Yiming", ""]]}, {"id": "2001.01051", "submitter": "Yuya Ong", "authors": "Yuya Jeremy Ong, Mu Qiao and Divyesh Jadav", "title": "Temporal Tensor Transformation Network for Multivariate Time Series\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series prediction has applications in a wide variety of\ndomains and is considered to be a very challenging task, especially when the\nvariables have correlations and exhibit complex temporal patterns, such as\nseasonality and trend. Many existing methods suffer from strong statistical\nassumptions, numerical issues with high dimensionality, manual feature\nengineering efforts, and scalability. In this work, we present a novel deep\nlearning architecture, known as Temporal Tensor Transformation Network, which\ntransforms the original multivariate time series into a higher order of tensor\nthrough the proposed Temporal-Slicing Stack Transformation. This yields a new\nrepresentation of the original multivariate time series, which enables the\nconvolution kernel to extract complex and non-linear features as well as\nvariable interactional signals from a relatively large temporal region.\nExperimental results show that Temporal Tensor Transformation Network\noutperforms several state-of-the-art methods on window-based predictions across\nvarious tasks. The proposed architecture also demonstrates robust prediction\nperformance through an extensive sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 07:28:55 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ong", "Yuya Jeremy", ""], ["Qiao", "Mu", ""], ["Jadav", "Divyesh", ""]]}, {"id": "2001.01056", "submitter": "Sayan Chakraborty", "authors": "Sayan Chakraborty, Smit Shah, Kiumars Soltani, Anna Swigart", "title": "Root Cause Detection Among Anomalous Time Series Using Temporal State\n  Alignment", "comments": "6 pages, 7 figures, 2019 18th IEEE International Conference on\n  Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent increase in the scale and complexity of software systems has\nintroduced new challenges to the time series monitoring and anomaly detection\nprocess. A major drawback of existing anomaly detection methods is that they\nlack contextual information to help stakeholders identify the cause of\nanomalies. This problem, known as root cause detection, is particularly\nchallenging to undertake in today's complex distributed software systems since\nthe metrics under consideration generally have multiple internal and external\ndependencies. Significant manual analysis and strong domain expertise is\nrequired to isolate the correct cause of the problem. In this paper, we propose\na method that isolates the root cause of an anomaly by analyzing the patterns\nin time series fluctuations. Our method considers the time series as\nobservations from an underlying process passing through a sequence of\ndiscretized hidden states. The idea is to track the propagation of the effect\nwhen a given problem causes unaligned but homogeneous shifts of the underlying\nstates. We evaluate our approach by finding the root cause of anomalies in\nZillows clickstream data by identifying causal patterns among a set of observed\nfluctuations.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 08:31:34 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chakraborty", "Sayan", ""], ["Shah", "Smit", ""], ["Soltani", "Kiumars", ""], ["Swigart", "Anna", ""]]}, {"id": "2001.01072", "submitter": "Dongrui Wu", "authors": "Xiao Zhang and Dongrui Wu", "title": "Empirical Studies on the Properties of Linear Regions in Deep Neural\n  Networks", "comments": "Int'l. Conf. on Learning Representations (ICLR), Addis Ababa,\n  Ethiopia, April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN) with piecewise linear activations can partition\nthe input space into numerous small linear regions, where different linear\nfunctions are fitted. It is believed that the number of these regions\nrepresents the expressivity of the DNN. This paper provides a novel and\nmeticulous perspective to look into DNNs: Instead of just counting the number\nof the linear regions, we study their local properties, such as the inspheres,\nthe directions of the corresponding hyperplanes, the decision boundaries, and\nthe relevance of the surrounding regions. We empirically observed that\ndifferent optimization techniques lead to completely different linear regions,\neven though they result in similar classification accuracies. We hope our study\ncan inspire the design of novel optimization techniques, and help discover and\nanalyze the behaviors of DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 12:47:58 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 08:06:47 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 19:08:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""]]}, {"id": "2001.01095", "submitter": "Cencheng Shen", "authors": "Cencheng Shen", "title": "High-Dimensional Independence Testing and Maximum Marginal Correlation", "comments": "20 pages, 5 page appendix, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of universally consistent dependence measures have been recently\nproposed for testing independence, such as distance correlation, kernel\ncorrelation, multiscale graph correlation, etc. They provide a satisfactory\nsolution for dependence testing in low-dimensions, but often exhibit decreasing\npower for high-dimensional data, a phenomenon that has been recognized but\nremains mostly unchartered. In this paper, we aim to better understand the\nhigh-dimensional testing scenarios and explore a procedure that is robust\nagainst increasing dimension. To that end, we propose the maximum marginal\ncorrelation method and characterize high-dimensional dependence structures via\nthe notion of dependent dimensions. We prove that the maximum method can be\nvalid and universally consistent for testing high-dimensional dependence under\nregularity conditions, and demonstrate when and how the maximum method may\noutperform other methods. The methodology can be implemented by most existing\ndependence measures, has a superior testing power in a variety of common\nhigh-dimensional settings, and is computationally efficient for big data\nanalysis when using the distance correlation chi-square test.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 16:21:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shen", "Cencheng", ""]]}, {"id": "2001.01102", "submitter": "Carlo D'Eramo", "authors": "Carlo D'Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli and\n  Jan Peters", "title": "MushroomRL: Simplifying Reinforcement Learning Research", "comments": "Under revision to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MushroomRL is an open-source Python library developed to simplify the process\nof implementing and running Reinforcement Learning (RL) experiments. Compared\nto other available libraries, MushroomRL has been created with the purpose of\nproviding a comprehensive and flexible framework to minimize the effort in\nimplementing and testing novel RL methodologies. Indeed, the architecture of\nMushroomRL is built in such a way that every component of an RL problem is\nalready provided, and most of the time users can only focus on the\nimplementation of their own algorithms and experiments. The result is a library\nfrom which RL researchers can significantly benefit in the critical phase of\nthe empirical analysis of their works. MushroomRL stable code, tutorials and\ndocumentation can be found at https://github.com/MushroomRL/mushroom-rl.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 17:23:34 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:11:21 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["D'Eramo", "Carlo", ""], ["Tateo", "Davide", ""], ["Bonarini", "Andrea", ""], ["Restelli", "Marcello", ""], ["Peters", "Jan", ""]]}, {"id": "2001.01127", "submitter": "Roberto Tonelli", "authors": "Nicola Uras and Lodovica Marchesi and Michele Marchesi and Roberto\n  Tonelli", "title": "Forecasting Bitcoin closing price series using linear regression and\n  neural networks models", "comments": "25 pages, 4 figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to forecast daily closing price series of Bitcoin,\nusing data on prices and volumes of prior days. Bitcoin price behaviour is\nstill largely unexplored, presenting new opportunities. We compared our results\nwith two modern works on Bitcoin prices forecasting and with a well-known\nrecent paper that uses Intel, National Bank shares and Microsoft daily NASDAQ\nclosing prices spanning a 3-year interval. We followed different approaches in\nparallel, implementing both statistical techniques and machine learning\nalgorithms. The SLR model for univariate series forecast uses only closing\nprices, whereas the MLR model for multivariate series uses both price and\nvolume data. We applied the ADF -Test to these series, which resulted to be\nindistinguishable from a random walk. We also used two artificial neural\nnetworks: MLP and LSTM. We then partitioned the dataset into shorter sequences,\nrepresenting different price regimes, obtaining best result using more than one\nprevious price, thus confirming our regime hypothesis. All the models were\nevaluated in terms of MAPE and relativeRMSE. They performed well, and were\noverall better than those obtained in the benchmarks. Based on the results, it\nwas possible to demonstrate the efficacy of the proposed methodology and its\ncontribution to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 21:04:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Uras", "Nicola", ""], ["Marchesi", "Lodovica", ""], ["Marchesi", "Michele", ""], ["Tonelli", "Roberto", ""]]}, {"id": "2001.01128", "submitter": "Ilan Ben-Bassat", "authors": "Ilan Ben-Bassat and Erez Rokah", "title": "Locality-Sensitive Hashing for Efficient Web Application Security\n  Testing", "comments": null, "journal-ref": "In Proceedings of the 5th International Conference on Information\n  Systems Security and Privacy (ICISSP), pages 193-204 (2019)", "doi": "10.5220/0007255301930204", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Web application security has become a major concern in recent years, as more\nand more content and services are available online. A useful method for\nidentifying security vulnerabilities is black-box testing, which relies on an\nautomated crawling of web applications. However, crawling Rich Internet\nApplications (RIAs) is a very challenging task. One of the key obstacles\ncrawlers face is the state similarity problem: how to determine if two\nclient-side states are equivalent. As current methods do not completely solve\nthis problem, a successful scan of many real-world RIAs is still not possible.\nWe present a novel approach to detect redundant content for security testing\npurposes. The algorithm applies locality-sensitive hashing using MinHash\nsketches in order to analyze the Document Object Model (DOM) structure of web\npages, and to efficiently estimate similarity between them. Our experimental\nresults show that this approach allows a successful scan of RIAs that cannot be\ncrawled otherwise.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 21:05:15 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ben-Bassat", "Ilan", ""], ["Rokah", "Erez", ""]]}, {"id": "2001.01177", "submitter": "Golnoosh Farnadi", "authors": "Golnoosh Farnadi, Lise Getoor, Marie-Francine Moens, Martine De Cock", "title": "User Profiling Using Hinge-loss Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of approaches have been proposed to automatically infer the\nprofiles of users from their digital footprint in social media. Most of the\nproposed approaches focus on mining a single type of information, while\nignoring other sources of available user-generated content (UGC). In this\npaper, we propose a mechanism to infer a variety of user characteristics, such\nas, age, gender and personality traits, which can then be compiled into a user\nprofile. To this end, we model social media users by incorporating and\nreasoning over multiple sources of UGC as well as social relations. Our model\nis based on a statistical relational learning framework using Hinge-loss Markov\nRandom Fields (HL-MRFs), a class of probabilistic graphical models that can be\ndefined using a set of first-order logical rules. We validate our approach on\ndata from Facebook with more than 5k users and almost 725k relations. We show\nhow HL-MRFs can be used to develop a generic and extensible user profiling\nframework by leveraging textual, visual, and relational content in the form of\nstatus updates, profile pictures and Facebook page likes. Our experimental\nresults demonstrate that our proposed model successfully incorporates multiple\nsources of information and outperforms competing methods that use only one\nsource of information or an ensemble method across the different sources for\nmodeling of users in social media.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 06:55:51 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Farnadi", "Golnoosh", ""], ["Getoor", "Lise", ""], ["Moens", "Marie-Francine", ""], ["De Cock", "Martine", ""]]}, {"id": "2001.01185", "submitter": "Xucheng Luo", "authors": "Xucheng Luo, Shengyang Li, Yuxiang Peng", "title": "CNNTOP: a CNN-based Trajectory Owner Prediction Method", "comments": "9pages, 11figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory owner prediction is the basis for many applications such as\npersonalized recommendation, urban planning. Although much effort has been put\non this topic, the results archived are still not good enough. Existing methods\nmainly employ RNNs to model trajectories semantically due to the inherent\nsequential attribute of trajectories. However, these approaches are weak at\nPoint of Interest (POI) representation learning and trajectory feature\ndetection. Thus, the performance of existing solutions is far from the\nrequirements of practical applications. In this paper, we propose a novel\nCNN-based Trajectory Owner Prediction (CNNTOP) method. Firstly, we connect all\nPOI according to trajectories from all users. The result is a connected graph\nthat can be used to generate more informative POI sequences than other\napproaches. Secondly, we employ the Node2Vec algorithm to encode each POI into\na low-dimensional real value vector. Then, we transform each trajectory into a\nfixed-dimensional matrix, which is similar to an image. Finally, a CNN is\ndesigned to detect features and predict the owner of a given trajectory. The\nCNN can extract informative features from the matrix representations of\ntrajectories by convolutional operations, Batch normalization, and $K$-max\npooling operations. Extensive experiments on real datasets demonstrate that\nCNNTOP substantially outperforms existing solutions in terms of\nmacro-Precision, macro-Recall, macro-F1, and accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 07:58:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Luo", "Xucheng", ""], ["Li", "Shengyang", ""], ["Peng", "Yuxiang", ""]]}, {"id": "2001.01194", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen and Yun Yang", "title": "Cutoff for exact recovery of Gaussian mixture models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT math.IT math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the information-theoretic cutoff value on separation of cluster\ncenters for exact recovery of cluster labels in a $K$-component Gaussian\nmixture model with equal cluster sizes. Moreover, we show that a semidefinite\nprogramming (SDP) relaxation of the $K$-means clustering method achieves such\nsharp threshold for exact recovery without assuming the symmetry of cluster\ncenters.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 08:57:04 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 19:44:07 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 11:14:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chen", "Xiaohui", ""], ["Yang", "Yun", ""]]}, {"id": "2001.01199", "submitter": "Vrettos Moulos", "authors": "Vrettos Moulos", "title": "A Hoeffding Inequality for Finite State Markov Chains and its\n  Applications to Markovian Bandits", "comments": "International Symposium on Information Theory (ISIT), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a Hoeffding inequality for the partial sums $\\sum_{k=1}^n\nf (X_k)$, where $\\{X_k\\}_{k \\in \\mathbb{Z}_{> 0}}$ is an irreducible Markov\nchain on a finite state space $S$, and $f : S \\to [a, b]$ is a real-valued\nfunction. Our bound is simple, general, since it only assumes irreducibility\nand finiteness of the state space, and powerful. In order to demonstrate its\nusefulness we provide two applications in multi-armed bandit problems. The\nfirst is about identifying an approximately best Markovian arm, while the\nsecond is concerned with regret minimization in the context of Markovian\nbandits.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 09:28:10 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 16:56:28 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Moulos", "Vrettos", ""]]}, {"id": "2001.01213", "submitter": "Nadine Kuhnert", "authors": "Nadine Kuhnert, Lea Pfl\\\"uger, Andreas Maier", "title": "Prediction of MRI Hardware Failures based on Image Features using\n  Ensemble Learning", "comments": null, "journal-ref": "Bildverarbeitung f\\\"ur die Medizin 2020. Springer Vieweg,\n  Wiesbaden, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to ensure trouble-free operation, prediction of hardware failures is\nessential. This applies especially to medical systems. Our goal is to determine\nhardware which needs to be exchanged before failing. In this work, we focus on\npredicting failures of 20-channel Head/Neck coils using image-related\nmeasurements. Thus, we aim to solve a classification problem with two classes,\nnormal and broken coil. To solve this problem, we use data of two different\nlevels. One level refers to one-dimensional features per individual coil\nchannel on which we found a fully connected neural network to perform best. The\nother data level uses matrices which represent the overall coil condition and\nfeeds a different neural network. We stack the predictions of those two\nnetworks and train a Random Forest classifier as the ensemble learner. Thus,\ncombining insights of both trained models improves the prediction results and\nallows us to determine the coil's condition with an F-score of 94.14% and an\naccuracy of 99.09%.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:21:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kuhnert", "Nadine", ""], ["Pfl\u00fcger", "Lea", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.01215", "submitter": "Shital Shah", "authors": "Shital Shah, Roland Fernandez, Steven Drucker", "title": "A System for Real-Time Interactive Analysis of Deep Learning Training", "comments": "Accepted at ACM SIGCHI Symposium on Engineering Interactive Computing\n  Systems (EICS 2019). Code available as TensorWatch project at\n  https://github.com/microsoft/tensorwatch", "journal-ref": null, "doi": "10.1145/3319499.3328231", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing diagnosis or exploratory analysis during the training of deep\nlearning models is challenging but often necessary for making a sequence of\ndecisions guided by the incremental observations. Currently available systems\nfor this purpose are limited to monitoring only the logged data that must be\nspecified before the training process starts. Each time a new information is\ndesired, a cycle of stop-change-restart is required in the training process.\nThese limitations make interactive exploration and diagnosis tasks difficult,\nimposing long tedious iterations during the model development. We present a new\nsystem that enables users to perform interactive queries on live processes\ngenerating real-time information that can be rendered in multiple formats on\nmultiple surfaces in the form of several desired visualizations simultaneously.\nTo achieve this, we model various exploratory inspection and diagnostic tasks\nfor deep learning training processes as specifications for streams using a\nmap-reduce paradigm with which many data scientists are already familiar. Our\ndesign achieves generality and extensibility by defining composable primitives\nwhich is a fundamentally different approach than is used by currently available\nsystems. The open source implementation of our system is available as\nTensorWatch project at https://github.com/microsoft/tensorwatch.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:33:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:57:16 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Shah", "Shital", ""], ["Fernandez", "Roland", ""], ["Drucker", "Steven", ""]]}, {"id": "2001.01216", "submitter": "Nadine Kuhnert", "authors": "Nadine Kuhnert, Andreas Maier", "title": "Flexible Log File Parsing using Hidden Markov Models", "comments": null, "journal-ref": "Computer Science Conference Proceedings in Computer Science &\n  Information Technology (CS & IT) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to model unknown file processing. As the content of log files often\nevolves over time, we established a dynamic statistical model which learns and\nadapts processing and parsing rules. First, we limit the amount of unstructured\ntext by focusing only on those frequent patterns which lead to the desired\noutput table similar to Vaarandi [10]. Second, we transform the found frequent\npatterns and the output stating the parsed table into a Hidden Markov Model\n(HMM). We use this HMM as a specific, however, flexible representation of a\npattern for log file processing. With changes in the raw log file distorting\nlearned patterns, we aim the model to adapt automatically in order to maintain\nhigh quality output. After training our model on one system type, applying the\nmodel and the resulting parsing rule to a different system with slightly\ndifferent log file patterns, we achieve an accuracy over 99%.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:44:09 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kuhnert", "Nadine", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.01227", "submitter": "Sangwoo Park", "authors": "Osvaldo Simeone, Sangwoo Park, Joonhyuk Kang", "title": "From Learning to Meta-Learning: Reduced Training Overhead and Complexity\n  for Communication Systems", "comments": "Invited to the 6G Wireless Summit 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods adapt the parameters of a model, constrained to lie\nin a given model class, by using a fixed learning procedure based on data or\nactive observations. Adaptation is done on a per-task basis, and retraining is\nneeded when the system configuration changes. The resulting inefficiency in\nterms of data and training time requirements can be mitigated, if domain\nknowledge is available, by selecting a suitable model class and learning\nprocedure, collectively known as inductive bias. However, it is generally\ndifficult to encode prior knowledge into an inductive bias, particularly with\nblack-box model classes such as neural networks. Meta-learning provides a way\nto automatize the selection of an inductive bias. Meta-learning leverages data\nor active observations from tasks that are expected to be related to future,\nand a priori unknown, tasks of interest. With a meta-trained inductive bias,\ntraining of a machine learning model can be potentially carried out with\nreduced training data and/or time complexity. This paper provides a high-level\nintroduction to meta-learning with applications to communication systems.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 12:54:41 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Simeone", "Osvaldo", ""], ["Park", "Sangwoo", ""], ["Kang", "Joonhyuk", ""]]}, {"id": "2001.01249", "submitter": "Eleni Nisioti", "authors": "Eleni Nisioti and Nikolaos Thomos", "title": "Design of Capacity-Approaching Low-Density Parity-Check Codes using\n  Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we model Density Evolution (DE) using Recurrent Neural\nNetworks (RNNs) with the aim of designing capacity-approaching Irregular\nLow-Density Parity-Check (LDPC) codes for binary erasure channels. In\nparticular, we present a method for determining the coefficients of the degree\ndistributions, characterizing the structure of an LDPC code. We refer to our\nRNN architecture as Neural Density Evolution (NDE) and determine the weights of\nthe RNN that correspond to optimal designs by minimizing a loss function that\nenforces the properties of asymptotically optimal design, as well as the\ndesired structural characteristics of the code. This renders the LDPC design\nprocess highly configurable, as constraints can be added to meet applications'\nrequirements by means of modifying the loss function. In order to train the\nRNN, we generate data corresponding to the expected channel noise. We analyze\nthe complexity and optimality of NDE theoretically, and compare it with\ntraditional design methods that employ differential evolution. Simulations\nillustrate that NDE improves upon differential evolution both in terms of\nasymptotic performance and complexity. Although we focus on asymptotic\nsettings, we evaluate designs found by NDE for finite codeword lengths and\nobserve that performance remains satisfactory across a variety of channels.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 14:46:47 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Nisioti", "Eleni", ""], ["Thomos", "Nikolaos", ""]]}, {"id": "2001.01328", "submitter": "Xuechen Li", "authors": "Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud", "title": "Scalable Gradients for Stochastic Differential Equations", "comments": "AISTATS 2020; 25 pages, 6 figures in main text; clarify notation in\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adjoint sensitivity method scalably computes gradients of solutions to\nordinary differential equations. We generalize this method to stochastic\ndifferential equations, allowing time-efficient and constant-memory computation\nof gradients with high-order adaptive solvers. Specifically, we derive a\nstochastic differential equation whose solution is the gradient, a\nmemory-efficient algorithm for caching noise, and conditions under which\nnumerical solutions converge. In addition, we combine our method with\ngradient-based stochastic variational inference for latent stochastic\ndifferential equations. We use our method to fit stochastic dynamics defined by\nneural networks, achieving competitive performance on a 50-dimensional motion\ncapture dataset.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 23:05:55 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:00:00 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 18:15:19 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 17:27:17 GMT"}, {"version": "v5", "created": "Tue, 7 Jul 2020 05:40:07 GMT"}, {"version": "v6", "created": "Sun, 18 Oct 2020 21:16:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Xuechen", ""], ["Wong", "Ting-Kam Leonard", ""], ["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""]]}, {"id": "2001.01347", "submitter": "Xing Zhao", "authors": "Xing Zhao, Manos Papagelis, Aijun An, Bao Xin Chen, Junfeng Liu,\n  Yonggang Hu", "title": "Elastic Bulk Synchronous Parallel Model for Distributed Deep Learning", "comments": "The paper was accepted in the proceedings of the IEEE International\n  Conference on Data Mining 2019 (ICDM'19), 1504-1509", "journal-ref": "ICDM 2019, 1504-1509", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bulk synchronous parallel (BSP) is a celebrated synchronization model for\ngeneral-purpose parallel computing that has successfully been employed for\ndistributed training of machine learning models. A prevalent shortcoming of the\nBSP is that it requires workers to wait for the straggler at every iteration.\nTo ameliorate this shortcoming of classic BSP, we propose ELASTICBSP a model\nthat aims to relax its strict synchronization requirement. The proposed model\noffers more flexibility and adaptability during the training phase, without\nsacrificing on the accuracy of the trained model. We also propose an efficient\nmethod that materializes the model, named ZIPLINE. The algorithm is tunable and\ncan effectively balance the trade-off between quality of convergence and\niteration throughput, in order to accommodate different environments or\napplications. A thorough experimental evaluation demonstrates that our proposed\nELASTICBSP model converges faster and to a higher accuracy than the classic\nBSP. It also achieves comparable (if not higher) accuracy than the other\nsensible synchronization models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 01:05:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhao", "Xing", ""], ["Papagelis", "Manos", ""], ["An", "Aijun", ""], ["Chen", "Bao Xin", ""], ["Liu", "Junfeng", ""], ["Hu", "Yonggang", ""]]}, {"id": "2001.01383", "submitter": "Xueyan Liu", "authors": "Xueyan Liu, Bo Yang, Wenzhuo Song, Katarzyna Musial, Wanli Zuo, Hongxu\n  Chen, Hongzhi Yin", "title": "A Block-based Generative Model for Attributed Networks Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributed network embedding has attracted plenty of interest in recent\nyears. It aims to learn task-independent, low-dimensional, and continuous\nvectors for nodes preserving both topology and attribute information. Most of\nthe existing methods, such as random-walk based methods and GCNs, mainly focus\non the local information, i.e., the attributes of the neighbours. Thus, they\nhave been well studied for assortative networks (i.e., networks with\ncommunities) but ignored disassortative networks (i.e., networks with\nmultipartite, hubs, and hybrid structures), which are common in the real world.\nTo enable model both assortative and disassortative networks, we propose a\nblock-based generative model for attributed network embedding from a\nprobability perspective. Specifically, the nodes are assigned to several blocks\nwherein the nodes in the same block share the similar linkage patterns. These\npatterns can define assortative networks containing communities or\ndisassortative networks with the multipartite, hub, or any hybrid structures.\nTo preserve the attribute information, we assume that each node has a hidden\nembedding related to its assigned block. We use a neural network to\ncharacterize the nonlinearity between node embeddings and node attributes. We\nperform extensive experiments on real-world and synthetic attributed networks.\nThe results show that our proposed method consistently outperforms\nstate-of-the-art embedding methods for both clustering and classification\ntasks, especially on disassortative networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 03:44:15 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 09:57:06 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Xueyan", ""], ["Yang", "Bo", ""], ["Song", "Wenzhuo", ""], ["Musial", "Katarzyna", ""], ["Zuo", "Wanli", ""], ["Chen", "Hongxu", ""], ["Yin", "Hongzhi", ""]]}, {"id": "2001.01385", "submitter": "Wei-Lun Chao", "authors": "Han-Jia Ye, Hong-You Chen, De-Chuan Zhan, Wei-Lun Chao", "title": "Identifying and Compensating for Feature Deviation in Imbalanced Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate learning a ConvNet classifier with class-imbalanced data. We\nfound that a ConvNet significantly over-fits the minor classes that do not have\nsufficient training instances, which is quite opposite to a traditional machine\nlearning model like logistic regression that often under-fits minor classes. We\nconduct a series of analysis and argue that feature deviation between the\ntraining and test instances serves as the main cause. We propose to incorporate\nclass-dependent temperatures (CDT) in learning a ConvNet: CDT forces the\nminor-class instances to have larger decision values in the training phase, so\nas to compensate for the effect of feature deviation in the test data. We\nvalidate our approach on several benchmark datasets and achieve promising\nperformance. We hope that our insights can inspire new ways of thinking in\nresolving class-imbalanced deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 03:52:11 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:10:52 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 00:13:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ye", "Han-Jia", ""], ["Chen", "Hong-You", ""], ["Zhan", "De-Chuan", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2001.01394", "submitter": "Geraud Nangue Tasse", "authors": "Geraud Nangue Tasse, Steven James, Benjamin Rosman", "title": "A Boolean Task Algebra for Reinforcement Learning", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compose learned skills to solve new tasks is an important\nproperty of lifelong-learning agents. In this work, we formalise the logical\ncomposition of tasks as a Boolean algebra. This allows us to formulate new\ntasks in terms of the negation, disjunction and conjunction of a set of base\ntasks. We then show that by learning goal-oriented value functions and\nrestricting the transition dynamics of the tasks, an agent can solve these new\ntasks with no further learning. We prove that by composing these value\nfunctions in specific ways, we immediately recover the optimal policies for all\ntasks expressible under the Boolean algebra. We verify our approach in two\ndomains---including a high-dimensional video game environment requiring\nfunction approximation---where an agent first learns a set of base skills, and\nthen composes them to solve a super-exponential number of new tasks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 04:46:25 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:45:49 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Tasse", "Geraud Nangue", ""], ["James", "Steven", ""], ["Rosman", "Benjamin", ""]]}, {"id": "2001.01401", "submitter": "Yeongtae Hwang", "authors": "Yeongtae Hwang, Hyemin Cho, Hongsun Yang, Dong-Ok Won, Insoo Oh, and\n  Seong-Whan Lee", "title": "Mel-spectrogram augmentation for sequence to sequence voice conversion", "comments": "5pages, 1 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For training the sequence-to-sequence voice conversion model, we need to\nhandle an issue of insufficient data about the number of speech pairs which\nconsist of the same utterance. This study experimentally investigated the\neffects of Mel-spectrogram augmentation on training the sequence-to-sequence\nvoice conversion (VC) model from scratch. For Mel-spectrogram augmentation, we\nadopted the policies proposed in SpecAugment. In addition, we proposed new\npolicies (i.e., frequency warping, loudness and time length control) for more\ndata variations. Moreover, to find the appropriate hyperparameters of\naugmentation policies without training the VC model, we proposed hyperparameter\nsearch strategy and the new metric for reducing experimental cost, namely\ndeformation per deteriorating ratio. We compared the effect of these\nMel-spectrogram augmentation methods based on various sizes of training set and\naugmentation policies. In the experimental results, the time axis warping based\npolicies (i.e., time length control and time warping.) showed better\nperformance than other policies. These results indicate that the use of the\nMel-spectrogram augmentation is more beneficial for training the VC model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:14:09 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 09:39:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hwang", "Yeongtae", ""], ["Cho", "Hyemin", ""], ["Yang", "Hongsun", ""], ["Won", "Dong-Ok", ""], ["Oh", "Insoo", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2001.01404", "submitter": "Prateek Jaiswal", "authors": "Prateek Jaiswal, Harsha Honnappa and Vinayak A. Rao", "title": "Variational Bayesian Methods for Stochastically Constrained System\n  Design Problems", "comments": null, "journal-ref": "2nd Symposium on Advances in Approximate Bayesian Inference, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study system design problems stated as parameterized stochastic programs\nwith a chance-constraint set. We adopt a Bayesian approach that requires the\ncomputation of a posterior predictive integral which is usually intractable. In\naddition, for the problem to be a well-defined convex program, we must retain\nthe convexity of the feasible set. Consequently, we propose a variational\nBayes-based method to approximately compute the posterior predictive integral\nthat ensures tractability and retains the convexity of the feasible set. Under\ncertain regularity conditions, we also show that the solution set obtained\nusing variational Bayes converges to the true solution set as the number of\nobservations tends to infinity. We also provide bounds on the probability of\nqualifying a true infeasible point (with respect to the true constraints) as\nfeasible under the VB approximation for a given number of samples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:21:39 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Jaiswal", "Prateek", ""], ["Honnappa", "Harsha", ""], ["Rao", "Vinayak A.", ""]]}, {"id": "2001.01408", "submitter": "Hanjun Dai", "authors": "Hanjun Dai, Chengtao Li, Connor W. Coley, Bo Dai, Le Song", "title": "Retrosynthesis Prediction with Conditional Graph Logic Network", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrosynthesis is one of the fundamental problems in organic chemistry. The\ntask is to identify reactants that can be used to synthesize a specified\nproduct molecule. Recently, computer-aided retrosynthesis is finding renewed\ninterest from both chemistry and computer science communities. Most existing\napproaches rely on template-based models that define subgraph matching rules,\nbut whether or not a chemical reaction can proceed is not defined by hard\ndecision rules. In this work, we propose a new approach to this task using the\nConditional Graph Logic Network, a conditional graphical model built upon graph\nneural networks that learns when rules from reaction templates should be\napplied, implicitly considering whether the resulting reaction would be both\nchemically feasible and strategic. We also propose an efficient hierarchical\nsampling to alleviate the computation cost. While achieving a significant\nimprovement of $8.1\\%$ over current state-of-the-art methods on the benchmark\ndataset, our model also offers interpretations for the prediction.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:36:57 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dai", "Hanjun", ""], ["Li", "Chengtao", ""], ["Coley", "Connor W.", ""], ["Dai", "Bo", ""], ["Song", "Le", ""]]}, {"id": "2001.01431", "submitter": "Yuge Zhang", "authors": "Yuge Zhang, Zejun Lin, Junyang Jiang, Quanlu Zhang, Yujing Wang, Hui\n  Xue, Chen Zhang, Yaming Yang", "title": "Deeper Insights into Weight Sharing in Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep neural networks, Neural Architecture Search (NAS) as\na way of automatic model design has attracted wide attention. As training every\nchild model from scratch is very time-consuming, recent works leverage\nweight-sharing to speed up the model evaluation procedure. These approaches\ngreatly reduce computation by maintaining a single copy of weights on the\nsuper-net and share the weights among every child model. However,\nweight-sharing has no theoretical guarantee and its impact has not been well\nstudied before. In this paper, we conduct comprehensive experiments to reveal\nthe impact of weight-sharing: (1) The best-performing models from different\nruns or even from consecutive epochs within the same run have significant\nvariance; (2) Even with high variance, we can extract valuable information from\ntraining the super-net with shared weights; (3) The interference between child\nmodels is a main factor that induces high variance; (4) Properly reducing the\ndegree of weight sharing could effectively reduce variance and improve\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 07:50:08 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Yuge", ""], ["Lin", "Zejun", ""], ["Jiang", "Junyang", ""], ["Zhang", "Quanlu", ""], ["Wang", "Yujing", ""], ["Xue", "Hui", ""], ["Zhang", "Chen", ""], ["Yang", "Yaming", ""]]}, {"id": "2001.01432", "submitter": "Chang Min Hyun", "authors": "Chang Min Hyun, Seong Hyeon Baek, Mingyu Lee, Sung Min Lee, and Jin\n  Keun Seo", "title": "Deep Learning-Based Solvability of Underdetermined Inverse Problems in\n  Medical Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the significant developments in deep learning techniques,\nsolving underdetermined inverse problems has become one of the major concerns\nin the medical imaging domain. Typical examples include undersampled magnetic\nresonance imaging, interior tomography, and sparse-view computed tomography,\nwhere deep learning techniques have achieved excellent performances. Although\ndeep learning methods appear to overcome the limitations of existing\nmathematical methods when handling various underdetermined problems, there is a\nlack of rigorous mathematical foundations that would allow us to elucidate the\nreasons for the remarkable performance of deep learning methods. This study\nfocuses on learning the causal relationship regarding the structure of the\ntraining data suitable for deep learning, to solve highly underdetermined\ninverse problems. We observe that a majority of the problems of solving\nunderdetermined linear systems in medical imaging are highly non-linear.\nFurthermore, we analyze if a desired reconstruction map can be learnable from\nthe training data and underdetermined system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 07:52:37 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 02:35:59 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 00:17:55 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Hyun", "Chang Min", ""], ["Baek", "Seong Hyeon", ""], ["Lee", "Mingyu", ""], ["Lee", "Sung Min", ""], ["Seo", "Jin Keun", ""]]}, {"id": "2001.01433", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Yeo Xian En and Seishirou Ueno", "title": "Consistent Batch Normalization for Weighted Loss in Imbalanced-Data\n  Environment", "comments": null, "journal-ref": null, "doi": "10.1587/nolta.11.454", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, classification problems based on feedforward neural networks\nin a data-imbalanced environment are considered. Learning from an imbalanced\ndataset is one of the most important practical problems in the field of machine\nlearning. A weighted loss function (WLF) based on a cost-sensitive approach is\na well-known and effective method for imbalanced datasets. A combination of WLF\nand batch normalization (BN) is considered in this study. BN is considered as a\npowerful standard technique in the recent developments in deep learning. A\nsimple combination of both methods leads to a size-inconsistency problem due to\na mismatch between the interpretations of the effective size of the dataset in\nboth methods. A simple modification to BN, called weighted BN (WBN), is\nproposed to correct the size mismatch. The idea of WBN is simple and natural.\nThe proposed method in a data-imbalanced environment is validated using\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 08:15:58 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 02:06:22 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 02:51:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Yasuda", "Muneki", ""], ["En", "Yeo Xian", ""], ["Ueno", "Seishirou", ""]]}, {"id": "2001.01458", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "Express Wavenet -- a low parameter optical neural network with random\n  shift wavelet pattern", "comments": "5 pages,4 figures", "journal-ref": null, "doi": "10.1016/j.optcom.2020.126709", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Express Wavenet is an improved optical diffractive neural network. At each\nlayer, it uses wavelet-like pattern to modulate the phase of optical waves. For\ninput image with n2 pixels, express wavenet reduce parameter number from O(n2)\nto O(n). Only need one percent of the parameters, and the accuracy is still\nvery high. In the MNIST dataset, it only needs 1229 parameters to get accuracy\nof 92%, while the standard optical network needs 125440 parameters. The random\nshift wavelets show the characteristics of optical network more vividly.\nEspecially the vanishing gradient phenomenon in the training process. We\npresent a modified expressway structure for this problem. Experiments verified\nthe effect of random shift wavelet and expressway structure. Our work shows\noptical diffractive network would use much fewer parameters than other neural\nnetworks. The source codes are available at\nhttps://github.com/closest-git/ONNet.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 09:45:20 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2001.01520", "submitter": "Julien Brajard", "authors": "Julien Brajard (1 and 2), Alberto Carassi (3 and 4), Marc Bocquet (5),\n  Laurent Bertino (1) ((1) Nansen Center, Bergen, Norway, (2) Sorbonne\n  University, CNRS-IRD-MNHN, LOCEAN, Paris, France, (3) Dept of Meteorology,\n  University of Reading, (4) Mathematical Institute, University of Utrecht, (5)\n  CEREA, joint laboratory \\'Ecole des Ponts ParisTech and EDF R&D, Universit\\'e\n  Paris-Est, Champs-sur-Marne, France)", "title": "Combining data assimilation and machine learning to emulate a dynamical\n  model from sparse and noisy observations: a case study with the Lorenz 96\n  model", "comments": "for associated code, see https://github.com/brajard/GMD-code", "journal-ref": "Journal of Computational Science, Volume 44, 2020", "doi": "10.1016/j.jocs.2020.101171", "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method, based on the combination of data assimilation and machine\nlearning is introduced. The new hybrid approach is designed for a two-fold\nscope: (i) emulating hidden, possibly chaotic, dynamics and (ii) predicting\ntheir future states. The method consists in applying iteratively a data\nassimilation step, here an ensemble Kalman filter, and a neural network. Data\nassimilation is used to optimally combine a surrogate model with sparse noisy\ndata. The output analysis is spatially complete and is used as a training set\nby the neural network to update the surrogate model. The two steps are then\nrepeated iteratively. Numerical experiments have been carried out using the\nchaotic 40-variables Lorenz 96 model, proving both convergence and statistical\nskill of the proposed hybrid approach. The surrogate model shows short-term\nforecast skill up to two Lyapunov times, the retrieval of positive Lyapunov\nexponents as well as the more energetic frequencies of the power density\nspectrum. The sensitivity of the method to critical setup parameters is also\npresented: the forecast skill decreases smoothly with increased observational\nnoise but drops abruptly if less than half of the model domain is observed. The\nsuccessful synergy between data assimilation and machine learning, proven here\nwith a low-dimensional system, encourages further investigation of such hybrids\nwith more sophisticated dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:26:52 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 13:23:48 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Brajard", "Julien", "", "1 and 2"], ["Carassi", "Alberto", "", "3 and 4"], ["Bocquet", "Marc", ""], ["Bertino", "Laurent", ""]]}, {"id": "2001.01523", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B. Allen, Randy P.\n  Auerbach, David Brent, Ruslan Salakhutdinov, Louis-Philippe Morency", "title": "Think Locally, Act Globally: Federated Learning with Local and Global\n  Representations", "comments": "NeurIPS 2019 Workshop on Federated Learning distinguished student\n  paper award. Code: https://github.com/pliang279/LG-FedAvg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a method of training models on private data distributed\nover multiple devices. To keep device data private, the global model is trained\nby only communicating parameters and updates which poses scalability challenges\nfor large models. To this end, we propose a new federated learning algorithm\nthat jointly learns compact local representations on each device and a global\nmodel across all devices. As a result, the global model can be smaller since it\nonly operates on local representations, reducing the number of communicated\nparameters. Theoretically, we provide a generalization analysis which shows\nthat a combination of local and global models reduces both variance in the data\nas well as variance across device distributions. Empirically, we demonstrate\nthat local models enable communication-efficient training while retaining\nperformance. We also evaluate on the task of personalized mood prediction from\nreal-world mobile data where privacy is key. Finally, local models handle\nheterogeneous data from new devices, and learn fair representations that\nobfuscate protected attributes such as race, age, and gender.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:40:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 07:23:45 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 08:12:35 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Terrance", ""], ["Ziyin", "Liu", ""], ["Allen", "Nicholas B.", ""], ["Auerbach", "Randy P.", ""], ["Brent", "David", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2001.01532", "submitter": "Miryam Merk", "authors": "Miryam S. Merk and Philipp Otto", "title": "Estimation of the spatial weighting matrix for regular lattice data --\n  An adaptive lasso approach with cross-sectional resampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial econometric research typically relies on the assumption that the\nspatial dependence structure is known in advance and is represented by a\ndeterministic spatial weights matrix. Contrary to classical approaches, we\ninvestigate the estimation of sparse spatial dependence structures for regular\nlattice data. In particular, an adaptive least absolute shrinkage and selection\noperator (lasso) is used to select and estimate the individual connections of\nthe spatial weights matrix. To recover the spatial dependence structure, we\npropose cross-sectional resampling, assuming that the random process is\nexchangeable. The estimation procedure is based on a two-step approach to\ncircumvent simultaneity issues that typically arise from endogenous spatial\nautoregressive dependencies. The two-step adaptive lasso approach with\ncross-sectional resampling is verified using Monte Carlo simulations.\nEventually, we apply the procedure to model nitrogen dioxide ($\\mathrm{NO_2}$)\nconcentrations and show that estimating the spatial dependence structure\ncontrary to using prespecified weights matrices improves the prediction\naccuracy considerably.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:51:02 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Merk", "Miryam S.", ""], ["Otto", "Philipp", ""]]}, {"id": "2001.01536", "submitter": "Liuyu Xiang", "authors": "Liuyu Xiang, Guiguang Ding and Jungong Han", "title": "Learning From Multiple Experts: Self-paced Knowledge Distillation for\n  Long-tailed Classification", "comments": "ECCV 2020 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, data tends to exhibit a long-tailed distribution,\nwhich increases the difficulty of training deep networks. In this paper, we\npropose a novel self-paced knowledge distillation framework, termed Learning\nFrom Multiple Experts (LFME). Our method is inspired by the observation that\nnetworks trained on less imbalanced subsets of the distribution often yield\nbetter performances than their jointly-trained counterparts. We refer to these\nmodels as 'Experts', and the proposed LFME framework aggregates the knowledge\nfrom multiple 'Experts' to learn a unified student model. Specifically, the\nproposed framework involves two levels of adaptive learning schedules:\nSelf-paced Expert Selection and Curriculum Instance Selection, so that the\nknowledge is adaptively transferred to the 'Student'. We conduct extensive\nexperiments and demonstrate that our method is able to achieve superior\nperformances compared to state-of-the-art methods. We also show that our method\ncan be easily plugged into state-of-the-art long-tailed classification\nalgorithms for further improvements.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:57:36 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 05:21:56 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 02:44:16 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xiang", "Liuyu", ""], ["Ding", "Guiguang", ""], ["Han", "Jungong", ""]]}, {"id": "2001.01558", "submitter": "Amir Mosavi Prof", "authors": "Zohreh Sheikh Khozani, Khabat Khosravi, Mohammadamin Torabi, Amir\n  Mosavi, Bahram Rezaei, Timon Rabczuk", "title": "Shear Stress Distribution Prediction in Symmetric Compound Channels\n  Using Data Mining and Machine Learning Models", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shear stress distribution prediction in open channels is of utmost importance\nin hydraulic structural engineering as it directly affects the design of stable\nchannels. In this study, at first, a series of experimental tests were\nconducted to assess the shear stress distribution in prismatic compound\nchannels. The shear stress values around the whole wetted perimeter were\nmeasured in the compound channel with different floodplain widths also in\ndifferent flow depths in subcritical and supercritical conditions. A set of,\ndata mining and machine learning models including Random Forest (RF), M5P,\nRandom Committee (RC), KStar and Additive Regression Model (AR) implemented on\nattained data to predict the shear stress distribution in the compound channel.\nResults indicated among these five models, RF method indicated the most precise\nresults with the highest R2 value of 0.9. Finally, the most powerful data\nmining method which studied in this research (RF) compared with two well-known\nanalytical models of Shiono and Knight Method (SKM) and Shannon method to\nacquire the proposed model functioning in predicting the shear stress\ndistribution. The results showed that the RF model has the best prediction\nperformance compared to SKM and Shannon models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 08:57:51 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Khozani", "Zohreh Sheikh", ""], ["Khosravi", "Khabat", ""], ["Torabi", "Mohammadamin", ""], ["Mosavi", "Amir", ""], ["Rezaei", "Bahram", ""], ["Rabczuk", "Timon", ""]]}, {"id": "2001.01559", "submitter": "Mehrdad Shafiei Dizaji", "authors": "Mojtaba Farrokh, Mehrdad Shafiei Dizaji, Farzad Shafiei Dizaji,\n  Nazanin Moradinasab", "title": "Universal Hysteresis Identification Using Extended Preisach Neural\n  Network", "comments": "17 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hysteresis phenomena have been observed in different branches of physics and\nengineering sciences. Therefore, several models have been proposed for\nhysteresis simulation in different fields; however, almost neither of them can\nbe utilized universally. In this paper by inspiring of Preisach Neural Network\nwhich was inspired by the Preisach model that basically stemmed from Madelungs\nrules and using the learning capability of the neural networks, an adaptive\nuniversal model for hysteresis is introduced and called Extended Preisach\nNeural Network Model. It is comprised of input, output and, two hidden layers.\nThe input and output layers contain linear neurons while the first hidden layer\nincorporates neurons called Deteriorating Stop neurons, which their activation\nfunction follows Deteriorating Stop operator. Deteriorating Stop operators can\ngenerate non-congruent hysteresis loops. The second hidden layer includes\nSigmoidal neurons. Adding the second hidden layer, helps the neural network\nlearn non-Masing and asymmetric hysteresis loops very smoothly. At the input\nlayer, besides input data the rate at which input data changes, is included as\nwell in order to give the model the capability of learning rate-dependent\nhysteresis loops. Hence, the proposed approach has the capability of the\nsimulation of both rate-independent and rate-dependent hysteresis with either\ncongruent or non-congruent loops as well as symmetric and asymmetric loops. A\nnew hybridized algorithm has been adopted for training the model which is based\non a combination of the Genetic Algorithm and the optimization method of\nsub-gradient with space dilatation. The generality of the proposed model has\nbeen evaluated by applying it to various hysteresis from different areas of\nengineering with different characteristics. The results show that the model is\nsuccessful in the identification of the considered hystereses.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 18:10:48 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Farrokh", "Mojtaba", ""], ["Dizaji", "Mehrdad Shafiei", ""], ["Dizaji", "Farzad Shafiei", ""], ["Moradinasab", "Nazanin", ""]]}, {"id": "2001.01560", "submitter": "Rodrigo de Lamare", "authors": "X. Wang, Z. Yang, J. Huang, and R. C. de Lamare", "title": "Study of Robust Two-Stage Reduced-Dimension Sparsity-Aware STAP with\n  Coprime Arrays", "comments": "13 figures, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-time adaptive processing (STAP) algorithms with coprime arrays can\nprovide good clutter suppression potential with low cost in airborne radar\nsystems as compared with their uniform linear arrays counterparts. However, the\nperformance of these algorithms is limited by the training samples support in\npractical applications. To address this issue, a robust two-stage\nreduced-dimension (RD) sparsity-aware STAP algorithm is proposed in this work.\nIn the first stage, an RD virtual snapshot is constructed using all spatial\nchannels but only $m$ adjacent Doppler channels around the target Doppler\nfrequency to reduce the slow-time dimension of the signal. In the second stage,\nan RD sparse measurement modeling is formulated based on the constructed RD\nvirtual snapshot, where the sparsity of clutter and the prior knowledge of the\nclutter ridge are exploited to formulate an RD overcomplete dictionary.\nMoreover, an orthogonal matching pursuit (OMP)-like method is proposed to\nrecover the clutter subspace. In order to set the stopping parameter of the\nOMP-like method, a robust clutter rank estimation approach is developed.\nCompared with recently developed sparsity-aware STAP algorithms, the size of\nthe proposed sparse representation dictionary is much smaller, resulting in low\ncomplexity. Simulation results show that the proposed algorithm is robust to\nprior knowledge errors and can provide good clutter suppression performance in\nlow sample support.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 19:14:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Wang", "X.", ""], ["Yang", "Z.", ""], ["Huang", "J.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "2001.01569", "submitter": "Amir Mosavi Prof", "authors": "Alireza Hajipour, Arash Mirabdolah Lavasani, Mohammad Eftekhari Yazdi,\n  Amir Mosavi, Shahaboddin Shamshirband, Kwok-Wing Chau", "title": "Simulation of Turbulent Flow around a Generic High-Speed Train using\n  Hybrid Models of RANS Numerical Method with Machine Learning", "comments": "43 pages, 25 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present paper, an aerodynamic investigation of a high-speed train is\nperformed. In the first section of this article, a generic high-speed train\nagainst a turbulent flow is simulated, numerically. The Reynolds-Averaged\nNavier-Stokes (RANS) equations combined with the turbulence model are applied\nto solve incompressible turbulent flow around a high-speed train. Flow\nstructure, velocity and pressure contours and streamlines at some typical wind\ndirections are the most important results of this simulation. The maximum and\nminimum values are specified and discussed. Also, the pressure coefficient for\nsome critical points on the train surface is evaluated. In the following, the\nwind direction influence the aerodynamic key parameters as drag, lift, and side\nforces at the mentioned wind directions are analyzed and compared. Moreover,\nthe effects of velocity changes (50, 60, 70, 80 and 90 m/s) are estimated and\ncompared on the above flow and aerodynamic parameters. In the second section of\nthe paper, various data-driven methods including Gene Expression Programming\n(GEP), Gaussian Process Regression (GPR), and random forest (RF), are applied\nfor predicting output parameters. So, drag, lift, and side forces and also\nminimum and a maximum of pressure coefficients for mentioned wind directions\nand velocity are predicted and compared using statistical parameters. Obtained\nresults indicated that RF in all coefficients of wind direction and most\ncoefficients of free stream velocity provided the most accurate predictions. As\na conclusion, RF may be recommended for the prediction of aerodynamic\ncoefficients.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 23:34:23 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Hajipour", "Alireza", ""], ["Lavasani", "Arash Mirabdolah", ""], ["Yazdi", "Mohammad Eftekhari", ""], ["Mosavi", "Amir", ""], ["Shamshirband", "Shahaboddin", ""], ["Chau", "Kwok-Wing", ""]]}, {"id": "2001.01578", "submitter": "Giang Nguyen", "authors": "Giang Nguyen, Shuan Chen, Thao Do, Tae Joon Jun, Ho-Jin Choi, Daeyoung\n  Kim", "title": "Dissecting Catastrophic Forgetting in Continual Learning by Deep\n  Visualization", "comments": "8 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpreting the behaviors of Deep Neural Networks (usually considered as a\nblack box) is critical especially when they are now being widely adopted over\ndiverse aspects of human life. Taking the advancements from Explainable\nArtificial Intelligent, this paper proposes a novel technique called Auto\nDeepVis to dissect catastrophic forgetting in continual learning. A new method\nto deal with catastrophic forgetting named critical freezing is also introduced\nupon investigating the dilemma by Auto DeepVis. Experiments on a captioning\nmodel meticulously present how catastrophic forgetting happens, particularly\nshowing which components are forgetting or changing. The effectiveness of our\ntechnique is then assessed; and more precisely, critical freezing claims the\nbest performance on both previous and coming tasks over baselines, proving the\ncapability of the investigation. Our techniques could not only be supplementary\nto existing solutions for completely eradicating catastrophic forgetting for\nlife-long learning but also explainable.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 13:49:32 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:07:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Nguyen", "Giang", ""], ["Chen", "Shuan", ""], ["Do", "Thao", ""], ["Jun", "Tae Joon", ""], ["Choi", "Ho-Jin", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2001.01612", "submitter": "Thierry Roncalli", "authors": "Pierre Chen, Edmond Lezmi, Thierry Roncalli, Jiali Xu", "title": "A Note on Portfolio Optimization with Quadratic Transaction Costs", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we consider mean-variance optimized portfolios with\ntransaction costs. We show that introducing quadratic transaction costs makes\nthe optimization problem more difficult than using linear transaction costs.\nThe reason lies in the specification of the budget constraint, which is no\nlonger linear. We provide numerical algorithms for solving this issue and\nillustrate how transaction costs may considerably impact the expected returns\nof optimized portfolios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 14:52:17 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chen", "Pierre", ""], ["Lezmi", "Edmond", ""], ["Roncalli", "Thierry", ""], ["Xu", "Jiali", ""]]}, {"id": "2001.01618", "submitter": "Sudipta Paul Ms.", "authors": "Sudipta Paul and Subhankar Mishra", "title": "ARA : Aggregated RAPPOR and Analysis for Centralized Differential\n  Privacy", "comments": null, "journal-ref": "SN COMPUT. SCI. (2020) 1: 22", "doi": "10.1007/s42979-019-0023-y", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy(DP) has now become a standard in case of sensitive\nstatistical data analysis. The two main approaches in DP is local and central.\nBoth the approaches have a clear gap in terms of data storing,amount of data to\nbe analyzed, analysis, speed etc. Local wins on the speed. We have tested the\nstate of the art standard RAPPOR which is a local approach and supported this\ngap. Our work completely focuses on that part too. Here, we propose a model\nwhich initially collects RAPPOR reports from multiple clients which are then\npushed to a Tf-Idf estimation model. The Tf-Idf estimation model then estimates\nthe reports on the basis of the occurrence of \"on bit\" in a particular position\nand its contribution to that position. Thus it generates a centralized\ndifferential privacy analysis from multiple clients. Our model successfully and\nefficiently analyzed the major truth value every time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:03:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Paul", "Sudipta", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2001.01620", "submitter": "Manuel Del Verme", "authors": "Manuel Del Verme, Bruno Castro da Silva, Gianluca Baldassarre", "title": "Optimal Options for Multi-Task Reinforcement Learning Under Time\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning can greatly benefit from the use of options as a way\nof encoding recurring behaviours and to foster exploration. An important open\nproblem is how can an agent autonomously learn useful options when solving\nparticular distributions of related tasks. We investigate some of the\nconditions that influence optimality of options, in settings where agents have\na limited time budget for learning each task and the task distribution might\ninvolve problems with different levels of similarity. We directly search for\noptimal option sets and show that the discovered options significantly differ\ndepending on factors such as the available learning time budget and that the\nfound options outperform popular option-generation heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:08:46 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Del Verme", "Manuel", ""], ["da Silva", "Bruno Castro", ""], ["Baldassarre", "Gianluca", ""]]}, {"id": "2001.01647", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, Rutuja Patil, Kristin Branson", "title": "Are skip connections necessary for biologically plausible learning\n  rules?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation is the workhorse of deep learning, however, several other\nbiologically-motivated learning rules have been introduced, such as random\nfeedback alignment and difference target propagation. None of these methods\nhave produced a competitive performance against backpropagation. In this paper,\nwe show that biologically-motivated learning rules with skip connections\nbetween intermediate layers can perform as well as backpropagation on the MNIST\ndataset and are robust to various sets of hyper-parameters.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:21:16 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Patil", "Rutuja", ""], ["Branson", "Kristin", ""]]}, {"id": "2001.01666", "submitter": "Mathieu Carri\\`ere", "authors": "Andrew J. Blumberg and Mathieu Carriere and Michael A. Mandell and\n  Raul Rabadan and Soledad Villar", "title": "MREC: a fast and versatile framework for aligning and matching point\n  clouds with applications to single cell molecular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing and aligning large datasets is a pervasive problem occurring across\nmany different knowledge domains. We introduce and study MREC, a recursive\ndecomposition algorithm for computing matchings between data sets. The basic\nidea is to partition the data, match the partitions, and then recursively match\nthe points within each pair of identified partitions. The matching itself is\ndone using black box matching procedures that are too expensive to run on the\nentire data set. Using an absolute measure of the quality of a matching, the\nframework supports optimization over parameters including partitioning\nprocedures and matching algorithms. By design, MREC can be applied to extremely\nlarge data sets. We analyze the procedure to describe when we can expect it to\nwork well and demonstrate its flexibility and power by applying it to a number\nof alignment problems arising in the analysis of single cell molecular data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:02:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 06:26:35 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 22:17:02 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Blumberg", "Andrew J.", ""], ["Carriere", "Mathieu", ""], ["Mandell", "Michael A.", ""], ["Rabadan", "Raul", ""], ["Villar", "Soledad", ""]]}, {"id": "2001.01669", "submitter": "Mi Khine Oo", "authors": "Mi Khine Oo and May Aye Khine", "title": "Topic Extraction of Crawled Documents Collection using Correlated Topic\n  Model in MapReduce Framework", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous increase in the amount of available research documents impels\nresearchers to propose topic models to extract the latent semantic themes of a\ndocuments collection. However, how to extract the hidden topics of the\ndocuments collection has become a crucial task for many topic model\napplications. Moreover, conventional topic modeling approaches suffer from the\nscalability problem when the size of documents collection increases. In this\npaper, the Correlated Topic Model with variational Expectation-Maximization\nalgorithm is implemented in MapReduce framework to solve the scalability\nproblem. The proposed approach utilizes the dataset crawled from the public\ndigital library. In addition, the full-texts of the crawled documents are\nanalysed to enhance the accuracy of MapReduce CTM. The experiments are\nconducted to demonstrate the performance of the proposed algorithm. From the\nevaluation, the proposed approach has a comparable performance in terms of\ntopic coherences with LDA implemented in MapReduce framework.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:09:21 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Oo", "Mi Khine", ""], ["Khine", "May Aye", ""]]}, {"id": "2001.01680", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Lei Bi, Jinman Kim, Shanlin Xiao, and\n  Zhiyi Yu", "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised\n  Feature Learning", "comments": "Published at Neurocomputing", "journal-ref": "Neurocomputing 441(2021), pp. 92-104", "doi": "10.1016/j.neucom.2021.02.027", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine\nlearning algorithms that have been widely recognized in producing\nultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs\nbased on synaptic plasticity, especially Spike-Timing-Dependent Plasticity\n(STDP), are considered to have great potential in imitating the learning\nprocess of the biological brain. Nevertheless, the existing STDP-based SNNs\nhave limitations in constrained learning capability and/or slow learning speed.\nMost STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture\nand used a sub-optimal vote-based scheme for spike decoding. In this paper, we\novercome these limitations with: 1) a design of high-parallelism network\narchitecture, inspired by the Inception module in Artificial Neural Networks\n(ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the\nstandard vote-based spike decoding scheme, to reduce the information loss in\nspike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism\nthat accelerates SNNs' learning by enhancing spiking activities. Our\nexperimental results on two established benchmark datasets (MNIST/EMNIST) show\nthat our network architecture resulted in superior performance compared to the\nwidely used FC architecture and a more advanced Locally-Connected (LC)\narchitecture, and that our SNN achieved competitive results with\nstate-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE\ndataset) while having superior learning efficiency and robustness against\nhardware damage. Our SNN achieved great classification accuracy with only\nhundreds of training iterations, and random destruction of large numbers of\nsynapses or neurons only led to negligible performance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:19:17 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 17:53:25 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 14:25:23 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 16:05:09 GMT"}, {"version": "v5", "created": "Tue, 9 Mar 2021 04:00:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Bi", "Lei", ""], ["Kim", "Jinman", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.01682", "submitter": "Wolfgang Maass Prof.", "authors": "Christoph St\\\"ockl and Wolfgang Maass", "title": "Recognizing Images with at most one Spike per Neuron", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to port the performance of trained artificial neural networks (ANNs)\nto spiking neural networks (SNNs), which can be implemented in neuromorphic\nhardware with a drastically reduced energy consumption, an efficient ANN to SNN\nconversion is needed. Previous conversion schemes focused on the representation\nof the analog output of a rectified linear (ReLU) gate in the ANN by the firing\nrate of a spiking neuron. But this is not possible for other commonly used ANN\ngates, and it reduces the throughput even for ReLU gates. We introduce a new\nconversion method where a gate in the ANN, which can basically be of any type,\nis emulated by a small circuit of spiking neurons, with At Most One Spike\n(AMOS) per neuron. We show that this AMOS conversion improves the accuracy of\nSNNs for ImageNet from 74.60% to 80.97%, thereby bringing it within reach of\nthe best available ANN accuracy (85.0%). The Top5 accuracy of SNNs is raised to\n95.82%, getting even closer to the best Top5 performance of 97.2% for ANNs. In\naddition, AMOS conversion improves latency and throughput of spike-based image\nclassification by several orders of magnitude. Hence these results suggest that\nSNNs provide a viable direction for developing highly energy efficient hardware\nfor AI that combines high performance with versatility of applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:28:11 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 10:08:27 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 10:54:26 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["St\u00f6ckl", "Christoph", ""], ["Maass", "Wolfgang", ""]]}, {"id": "2001.01683", "submitter": "Sebastian Risi", "authors": "Sebastian Risi and Kenneth O. Stanley", "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in\n  Training Heterogeneous Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning approaches have shown impressive results in a\nvariety of different domains, however, more complex heterogeneous architectures\nsuch as world models require the different neural components to be trained\nseparately instead of end-to-end. While a simple genetic algorithm recently\nshowed end-to-end training is possible, it failed to solve a more complex 3D\ntask. This paper presents a method called Deep Innovation Protection (DIP) that\naddresses the credit assignment problem in training complex heterogenous neural\nnetwork models end-to-end for such environments. The main idea behind the\napproach is to employ multiobjective optimization to temporally reduce the\nselection pressure on specific components in multi-component network, allowing\nother components to adapt. We investigate the emergent representations of these\nevolved networks, which learn to predict properties important for the survival\nof the agent, without the need for a specific forward-prediction loss.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 18:35:06 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 11:20:36 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Risi", "Sebastian", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2001.01684", "submitter": "John Raisbeck", "authors": "John C. Raisbeck (1), Matthew Allen (1), Ralph Weissleder (1),\n  Hyungsoon Im (1), Hakho Lee (1) ((1) Massachusetts General Hospital)", "title": "Evolution Strategies Converges to Finite Differences", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the debut of Evolution Strategies (ES) as a tool for Reinforcement\nLearning by Salimans et al. 2017, there has been interest in determining the\nexact relationship between the Evolution Strategies gradient and the gradient\nof a similar class of algorithms, Finite Differences (FD).(Zhang et al. 2017,\nLehman et al. 2018) Several investigations into the subject have been\nperformed, investigating the formal motivational differences(Lehman et al.\n2018) between ES and FD, as well as the differences in a standard benchmark\nproblem in Machine Learning, the MNIST classification problem(Zhang et al.\n2017). This paper proves that while the gradients are different, they converge\nas the dimension of the vector under optimization increases.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 19:24:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raisbeck", "John C.", "", "Massachusetts General Hospital"], ["Allen", "Matthew", "", "Massachusetts General Hospital"], ["Weissleder", "Ralph", "", "Massachusetts General Hospital"], ["Im", "Hyungsoon", "", "Massachusetts General Hospital"], ["Lee", "Hakho", "", "Massachusetts General Hospital"]]}, {"id": "2001.01699", "submitter": "Pavel Bochev B", "authors": "K. Aadithya, P. Kuberry, B. Paskaleva, P. Bochev, K. Leeson, A. Mar,\n  T. Mei, E. Keiter", "title": "Development, Demonstration, and Validation of Data-driven Compact Diode\n  Models for Circuit Simulation and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND2019-15303 R", "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compact semiconductor device models are essential for efficiently designing\nand analyzing large circuits. However, traditional compact model development\nrequires a large amount of manual effort and can span many years. Moreover,\ninclusion of new physics (eg, radiation effects) into an existing compact model\nis not trivial and may require redevelopment from scratch. Machine Learning\n(ML) techniques have the potential to automate and significantly speed up the\ndevelopment of compact models. In addition, ML provides a range of modeling\noptions that can be used to develop hierarchies of compact models tailored to\nspecific circuit design stages. In this paper, we explore three such options:\n(1) table-based interpolation, (2)Generalized Moving Least-Squares, and (3)\nfeed-forward Deep Neural Networks, to develop compact models for a p-n junction\ndiode. We evaluate the performance of these \"data-driven\" compact models by (1)\ncomparing their voltage-current characteristics against laboratory data, and\n(2) building a bridge rectifier circuit using these devices, predicting the\ncircuit's behavior using SPICE-like circuit simulations, and then comparing\nthese predictions against laboratory measurements of the same circuit.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:25:32 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Aadithya", "K.", ""], ["Kuberry", "P.", ""], ["Paskaleva", "B.", ""], ["Bochev", "P.", ""], ["Leeson", "K.", ""], ["Mar", "A.", ""], ["Mei", "T.", ""], ["Keiter", "E.", ""]]}, {"id": "2001.01707", "submitter": "Haleh Falakshahi", "authors": "Haleh Falakshahi, Victor M. Vergara, Jingyu Liu, Daniel H. Mathalon,\n  Judith M. Ford, James Voyvodic, Bryon A. Mueller, Aysenil Belger, Sarah\n  McEwen, Steven G. Potkin, Adrian Preda, Hooman Rokham, Jing Sui, Jessica A.\n  Turner, Sergey Plis, and Vince D. Calhoun", "title": "Meta-modal Information Flow: A Method for Capturing Multimodal Modular\n  Disconnectivity in Schizophrenia", "comments": null, "journal-ref": "IEEE Transactions on Biomedical Engineering, 2019", "doi": "10.1109/TBME.2020.2964724", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Multimodal measurements of the same phenomena provide\ncomplementary information and highlight different perspectives, albeit each\nwith their own limitations. A focus on a single modality may lead to incorrect\ninferences, which is especially important when a studied phenomenon is a\ndisease. In this paper, we introduce a method that takes advantage of\nmultimodal data in addressing the hypotheses of disconnectivity and dysfunction\nwithin schizophrenia (SZ). Methods: We start with estimating and visualizing\nlinks within and among extracted multimodal data features using a Gaussian\ngraphical model (GGM). We then propose a modularity-based method that can be\napplied to the GGM to identify links that are associated with mental illness\nacross a multimodal data set. Through simulation and real data, we show our\napproach reveals important information about disease-related network\ndisruptions that are missed with a focus on a single modality. We use\nfunctional MRI (fMRI), diffusion MRI (dMRI), and structural MRI (sMRI) to\ncompute the fractional amplitude of low frequency fluctuations (fALFF),\nfractional anisotropy (FA), and gray matter (GM) concentration maps. These\nthree modalities are analyzed using our modularity method. Results: Our results\nshow missing links that are only captured by the cross-modal information that\nmay play an important role in disconnectivity between the components.\nConclusion: We identified multimodal (fALFF, FA and GM) disconnectivity in the\ndefault mode network area in patients with SZ, which would not have been\ndetectable in a single modality. Significance: The proposed approach provides\nan important new tool for capturing information that is distributed among\nmultiple imaging modalities.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:46:41 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Falakshahi", "Haleh", ""], ["Vergara", "Victor M.", ""], ["Liu", "Jingyu", ""], ["Mathalon", "Daniel H.", ""], ["Ford", "Judith M.", ""], ["Voyvodic", "James", ""], ["Mueller", "Bryon A.", ""], ["Belger", "Aysenil", ""], ["McEwen", "Sarah", ""], ["Potkin", "Steven G.", ""], ["Preda", "Adrian", ""], ["Rokham", "Hooman", ""], ["Sui", "Jing", ""], ["Turner", "Jessica A.", ""], ["Plis", "Sergey", ""], ["Calhoun", "Vince D.", ""]]}, {"id": "2001.01755", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra and Horacio Franco", "title": "Investigation and Analysis of Hyper and Hypo neuron pruning to\n  selectively update neurons during Unsupervised Adaptation", "comments": "DSP, 29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen or out-of-domain data can seriously degrade the performance of a\nneural network model, indicating the model's failure to generalize to unseen\ndata. Neural net pruning can not only help to reduce a model's size but can\nimprove the model's generalization capacity as well. Pruning approaches look\nfor low-salient neurons that are less contributive to a model's decision and\nhence can be removed from the model. This work investigates if pruning\napproaches are successful in detecting neurons that are either high-salient\n(mostly active or hyper) or low-salient (barely active or hypo), and whether\nremoval of such neurons can help to improve the model's generalization\ncapacity. Traditional blind adaptation techniques update either the whole or a\nsubset of layers, but have never explored selectively updating individual\nneurons across one or more layers. Focusing on the fully connected layers of a\nconvolutional neural network (CNN), this work shows that it may be possible to\nselectively adapt certain neurons (consisting of the hyper and the hypo\nneurons) first, followed by a full-network fine tuning. Using the task of\nautomatic speech recognition, this work demonstrates how the removal of hyper\nand hypo neurons from a model can improve the model's performance on\nout-of-domain speech data and how selective neuron adaptation can ensure\nimproved performance when compared to traditional blind model adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 19:46:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Franco", "Horacio", ""]]}, {"id": "2001.01765", "submitter": "Rendani Mbuvha", "authors": "Rendani Mbuvha, Illyes Boulkaibet and Tshilidzi Marwala", "title": "An Automatic Relevance Determination Prior Bayesian Neural Network for\n  Controlled Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an Automatic Relevance Determination prior Bayesian Neural\nNetwork(BNN-ARD) weight l2-norm measure as a feature importance statistic for\nthe model-x knockoff filter. We show on both simulated data and the Norwegian\nwind farm dataset that the proposed feature importance statistic yields\nstatistically significant improvements relative to similar feature importance\nmeasures in both variable selection power and predictive performance on a real\nworld dataset.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 20:12:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mbuvha", "Rendani", ""], ["Boulkaibet", "Illyes", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "2001.01793", "submitter": "Ian Char", "authors": "Youngseog Chung, Ian Char, Willie Neiswanger, Kirthevasan Kandasamy,\n  Andrew Oakleigh Nelson, Mark D Boyer, Egemen Kolemen, Jeff Schneider", "title": "Offline Contextual Bayesian Optimization for Nuclear Fusion", "comments": "6 pages, 2 figures, Machine Learning and Physical Sciences workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear fusion is regarded as the energy of the future since it presents the\npossibility of unlimited clean energy. One obstacle in utilizing fusion as a\nfeasible energy source is the stability of the reaction. Ideally, one would\nhave a controller for the reactor that makes actions in response to the current\nstate of the plasma in order to prolong the reaction as long as possible. In\nthis work, we make preliminary steps to learning such a controller. Since\nlearning on a real world reactor is infeasible, we tackle this problem by\nattempting to learn optimal controls offline via a simulator, where the state\nof the plasma can be explicitly set. In particular, we introduce a\ntheoretically grounded Bayesian optimization algorithm that recommends a state\nand action pair to evaluate at every iteration and show that this results in\nmore efficient use of the simulator.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:12:18 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Chung", "Youngseog", ""], ["Char", "Ian", ""], ["Neiswanger", "Willie", ""], ["Kandasamy", "Kirthevasan", ""], ["Nelson", "Andrew Oakleigh", ""], ["Boyer", "Mark D", ""], ["Kolemen", "Egemen", ""], ["Schneider", "Jeff", ""]]}, {"id": "2001.01796", "submitter": "Hadis Anahideh", "authors": "Hadis Anahideh and Abolfazl Asudeh and Saravanan Thirumuruganathan", "title": "Fair Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is increasingly being used in high-stakes applications\nimpacting society. Therefore, it is of critical importance that ML models do\nnot propagate discrimination. Collecting accurate labeled data in societal\napplications is challenging and costly. Active learning is a promising approach\nto build an accurate classifier by interactively querying an oracle within a\nlabeling budget. We design algorithms for fair active learning that carefully\nselects data points to be labeled so as to balance model accuracy and fairness.\nWe demonstrate the effectiveness and efficiency of our proposed algorithms over\nwidely used benchmark datasets using demographic parity and equalized odds\nnotions of fairness.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:20:02 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 04:03:05 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 23:53:05 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 12:06:48 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 14:39:26 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Anahideh", "Hadis", ""], ["Asudeh", "Abolfazl", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "2001.01799", "submitter": "Charles Thornton", "authors": "Charles E. Thornton, R. Michael Buehrer, Anthony F. Martone, Kelly D.\n  Sherbondy", "title": "Experimental Analysis of Reinforcement Learning Techniques for Spectrum\n  Sharing Radar", "comments": "Accepted for publication at IEEE Intl. Radar Conference, Washington\n  DC, Apr. 2020. This is the author's version of the work", "journal-ref": null, "doi": "10.1109/RADAR42522.2020.9114698", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first describe a framework for the application of\nReinforcement Learning (RL) control to a radar system that operates in a\ncongested spectral setting. We then compare the utility of several RL\nalgorithms through a discussion of experiments performed on Commercial\noff-the-shelf (COTS) hardware. Each RL technique is evaluated in terms of\nconvergence, radar detection performance achieved in a congested spectral\nenvironment, and the ability to share 100MHz spectrum with an uncooperative\ncommunications system. We examine policy iteration, which solves an environment\nposed as a Markov Decision Process (MDP) by directly solving for a stochastic\nmapping between environmental states and radar waveforms, as well as Deep RL\ntechniques, which utilize a form of Q-Learning to approximate a parameterized\nfunction that is used by the radar to select optimal actions. We show that RL\ntechniques are beneficial over a Sense-and-Avoid (SAA) scheme and discuss the\nconditions under which each approach is most effective.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:32:32 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 23:24:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Thornton", "Charles E.", ""], ["Buehrer", "R. Michael", ""], ["Martone", "Anthony F.", ""], ["Sherbondy", "Kelly D.", ""]]}, {"id": "2001.01809", "submitter": "Javier Trejos", "authors": "Javier Trejos-Zelaya, Luis Eduardo Amaya-Brice\\~no, Alejandra\n  Jim\\'enez-Romero, Alex Murillo-Fern\\'andez, Eduardo Piza-Volio, Mario\n  Villalobos-Arias", "title": "Clustering Binary Data by Application of Combinatorial Optimization\n  Heuristics", "comments": "9 pages. Submitted to Springer Series \"Studies in Classification,\n  Data Analysis, and Knowledge Organization\". Presented in Conference of the\n  International Federation of Classification Societies (IFCS), Thessaloniki,\n  August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study clustering methods for binary data, first defining aggregation\ncriteria that measure the compactness of clusters. Five new and original\nmethods are introduced, using neighborhoods and population behavior\ncombinatorial optimization metaheuristics: first ones are simulated annealing,\nthreshold accepting and tabu search, and the others are a genetic algorithm and\nant colony optimization. The methods are implemented, performing the proper\ncalibration of parameters in the case of heuristics, to ensure good results.\nFrom a set of 16 data tables generated by a quasi-Monte Carlo experiment, a\ncomparison is performed for one of the aggregations using L1 dissimilarity,\nwith hierarchical clustering, and a version of k-means: partitioning around\nmedoids or PAM. Simulated annealing perform very well, especially compared to\nclassical methods.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 23:33:31 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Trejos-Zelaya", "Javier", ""], ["Amaya-Brice\u00f1o", "Luis Eduardo", ""], ["Jim\u00e9nez-Romero", "Alejandra", ""], ["Murillo-Fern\u00e1ndez", "Alex", ""], ["Piza-Volio", "Eduardo", ""], ["Villalobos-Arias", "Mario", ""]]}, {"id": "2001.01828", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Diego Klabjan", "title": "Listwise Learning to Rank by Exploring Unique Ratings", "comments": null, "journal-ref": "WSDM 2020", "doi": "10.1145/3336191.3371814", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose new listwise learning-to-rank models that mitigate\nthe shortcomings of existing ones. Existing listwise learning-to-rank models\nare generally derived from the classical Plackett-Luce model, which has three\nmajor limitations. (1) Its permutation probabilities overlook ties, i.e., a\nsituation when more than one document has the same rating with respect to a\nquery. This can lead to imprecise permutation probabilities and inefficient\ntraining because of selecting documents one by one. (2) It does not favor\ndocuments having high relevance. (3) It has a loose assumption that sampling\ndocuments at different steps is independent. To overcome the first two\nlimitations, we model ranking as selecting documents from a candidate set based\non unique rating levels in decreasing order. The number of steps in training is\ndetermined by the number of unique rating levels. We propose a new loss\nfunction and associated four models for the entire sequence of weighted\nclassification tasks by assigning high weights to the selected documents with\nhigh ratings for optimizing Normalized Discounted Cumulative Gain (NDCG). To\novercome the final limitation, we further propose a novel and efficient way of\nrefining prediction scores by combining an adapted Vanilla Recurrent Neural\nNetwork (RNN) model with pooling given selected documents at previous steps. We\nencode all of the documents already selected by an RNN model. In a single step,\nwe rank all of the documents with the same ratings using the last cell of the\nRNN multiple times. We have implemented our models using three settings: neural\nnetworks, neural networks with gradient boosting, and regression trees with\ngradient boosting. We have conducted experiments on four public datasets. The\nexperiments demonstrate that the models notably outperform state-of-the-art\nlearning-to-rank models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:50:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 03:51:49 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 01:55:15 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Klabjan", "Diego", ""]]}, {"id": "2001.01829", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Feng Liu, Goce Trajcevski, Dingding Wang", "title": "Frosting Weights for Better Continual Training", "comments": null, "journal-ref": "ICMLA 2019", "doi": "10.1109/ICMLA.2019.00094", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network model can be a lifelong learning process and is a\ncomputationally intensive one. A severe adverse effect that may occur in deep\nneural network models is that they can suffer from catastrophic forgetting\nduring retraining on new data. To avoid such disruptions in the continuous\nlearning, one appealing property is the additive nature of ensemble models. In\nthis paper, we propose two generic ensemble approaches, gradient boosting and\nmeta-learning, to solve the catastrophic forgetting problem in tuning\npre-trained neural network models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:53:46 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Liu", "Feng", ""], ["Trajcevski", "Goce", ""], ["Wang", "Dingding", ""]]}, {"id": "2001.01861", "submitter": "Subru Krishnan", "authors": "Mohammad Hossein Namaki, Avrilia Floratou, Fotis Psallidas, Subru\n  Krishnan, Ashvin Agrawal, Yinghui Wu, Yiwen Zhu and Markus Weimer", "title": "Vamsa: Automated Provenance Tracking in Data Science Scripts", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403205", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has recently been a lot of ongoing research in the areas of fairness,\nbias and explainability of machine learning (ML) models due to the self-evident\nor regulatory requirements of various ML applications. We make the following\nobservation: All of these approaches require a robust understanding of the\nrelationship between ML models and the data used to train them. In this work,\nwe introduce the ML provenance tracking problem: the fundamental idea is to\nautomatically track which columns in a dataset have been used to derive the\nfeatures/labels of an ML model. We discuss the challenges in capturing such\ninformation in the context of Python, the most common language used by data\nscientists. We then present Vamsa, a modular system that extracts provenance\nfrom Python scripts without requiring any changes to the users' code. Using 26K\nreal data science scripts, we verify the effectiveness of Vamsa in terms of\ncoverage, and performance. We also evaluate Vamsa's accuracy on a smaller\nsubset of manually labeled data. Our analysis shows that Vamsa's precision and\nrecall range from 90.4% to 99.1% and its latency is in the order of\nmilliseconds for average size scripts. Drawing from our experience in deploying\nML models in production, we also present an example in which Vamsa helps\nautomatically identify models that are affected by data corruption issues.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:39:02 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 16:58:22 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Namaki", "Mohammad Hossein", ""], ["Floratou", "Avrilia", ""], ["Psallidas", "Fotis", ""], ["Krishnan", "Subru", ""], ["Agrawal", "Ashvin", ""], ["Wu", "Yinghui", ""], ["Zhu", "Yiwen", ""], ["Weimer", "Markus", ""]]}, {"id": "2001.01866", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Bo Dai", "title": "Reinforcement Learning via Fenchel-Rockafellar Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review basic concepts of convex duality, focusing on the very general and\nsupremely useful Fenchel-Rockafellar duality. We summarize how this duality may\nbe applied to a variety of reinforcement learning (RL) settings, including\npolicy evaluation or optimization, online or offline learning, and discounted\nor undiscounted rewards. The derivations yield a number of intriguing results,\nincluding the ability to perform policy evaluation and on-policy policy\ngradient with behavior-agnostic offline data and methods to learn a policy via\nmax-likelihood optimization. Although many of these results have appeared\npreviously in various forms, we provide a unified treatment and perspective on\nthese results, which we hope will enable researchers to better use and apply\nthe tools of convex duality to make further progress in RL.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:59:59 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:08:09 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Nachum", "Ofir", ""], ["Dai", "Bo", ""]]}, {"id": "2001.01878", "submitter": "Tailin Wu", "authors": "Tailin Wu and Ian Fischer", "title": "Phase Transitions for the Information Bottleneck in Representation\n  Learning", "comments": "ICLR 2020; 27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Information Bottleneck (IB), when tuning the relative strength between\ncompression and prediction terms, how do the two terms behave, and what's their\nrelationship with the dataset and the learned representation? In this paper, we\nset out to answer these questions by studying multiple phase transitions in the\nIB objective: $\\text{IB}_\\beta[p(z|x)] = I(X; Z) - \\beta I(Y; Z)$ defined on\nthe encoding distribution p(z|x) for input $X$, target $Y$ and representation\n$Z$, where sudden jumps of $dI(Y; Z)/d \\beta$ and prediction accuracy are\nobserved with increasing $\\beta$. We introduce a definition for IB phase\ntransitions as a qualitative change of the IB loss landscape, and show that the\ntransitions correspond to the onset of learning new classes. Using second-order\ncalculus of variations, we derive a formula that provides a practical condition\nfor IB phase transitions, and draw its connection with the Fisher information\nmatrix for parameterized models. We provide two perspectives to understand the\nformula, revealing that each IB phase transition is finding a component of\nmaximum (nonlinear) correlation between $X$ and $Y$ orthogonal to the learned\nrepresentation, in close analogy with canonical-correlation analysis (CCA) in\nlinear settings. Based on the theory, we present an algorithm for discovering\nphase transition points. Finally, we verify that our theory and algorithm\naccurately predict phase transitions in categorical datasets, predict the onset\nof learning new classes and class difficulty in MNIST, and predict prominent\nphase transitions in CIFAR10.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 03:55:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wu", "Tailin", ""], ["Fischer", "Ian", ""]]}, {"id": "2001.01885", "submitter": "Tailin Wu", "authors": "Tailin Wu, Thomas Breuel, Michael Skuhersky and Jan Kautz", "title": "Discovering Nonlinear Relations with Minimum Predictive Information\n  Regularization", "comments": "26 pages, 11 figures; ICML'19 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the underlying directional relations from observational time\nseries with nonlinear interactions and complex relational structures is key to\na wide range of applications, yet remains a hard problem. In this work, we\nintroduce a novel minimum predictive information regularization method to infer\ndirectional relations from time series, allowing deep learning models to\ndiscover nonlinear relations. Our method substantially outperforms other\nmethods for learning nonlinear relations in synthetic datasets, and discovers\nthe directional relations in a video game environment and a heart-rate vs.\nbreath-rate dataset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 04:28:00 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wu", "Tailin", ""], ["Breuel", "Thomas", ""], ["Skuhersky", "Michael", ""], ["Kautz", "Jan", ""]]}, {"id": "2001.01894", "submitter": "Pengzhou Wu", "authors": "Pengzhou Wu and Kenji Fukumizu", "title": "Causal Mosaic: Cause-Effect Inference via Nonlinear ICA and Ensemble\n  Method", "comments": "Accepted to AISTATS 2020. Camera-ready version in preparation", "journal-ref": "An updated version at AISTATS 2020:\n  http://proceedings.mlr.press/v108/wu20b/wu20b.pdf. Main changes: a correction\n  in Theorem 3 and additional explanations in Sec. 4", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of distinguishing cause from effect in bivariate\nsetting. Based on recent developments in nonlinear independent component\nanalysis (ICA), we train nonparametrically general nonlinear causal models that\nallow non-additive noise. Further, we build an ensemble framework, namely\nCausal Mosaic, which models a causal pair by a mixture of nonlinear models. We\ncompare this method with other recent methods on artificial and real world\nbenchmark datasets, and our method shows state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:16:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wu", "Pengzhou", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2001.01898", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhe Wang, Yi Zhou, Yingbin Liang", "title": "Reanalysis of Variance Reduced Temporal Difference Learning", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is a popular algorithm for policy\nevaluation in reinforcement learning, but the vanilla TD can substantially\nsuffer from the inherent optimization variance. A variance reduced TD (VRTD)\nalgorithm was proposed by Korda and La (2015), which applies the variance\nreduction technique directly to the online TD learning with Markovian samples.\nIn this work, we first point out the technical errors in the analysis of VRTD\nin Korda and La (2015), and then provide a mathematically solid analysis of the\nnon-asymptotic convergence of VRTD and its variance reduction performance. We\nshow that VRTD is guaranteed to converge to a neighborhood of the fixed-point\nsolution of TD at a linear convergence rate. Furthermore, the variance error\n(for both i.i.d.\\ and Markovian sampling) and the bias error (for Markovian\nsampling) of VRTD are significantly reduced by the batch size of variance\nreduction in comparison to those of vanilla TD. As a result, the overall\ncomputational complexity of VRTD to attain a given accurate solution\noutperforms that of TD under Markov sampling and outperforms that of TD under\ni.i.d.\\ sampling for a sufficiently small conditional number.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:32:43 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 07:22:15 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Xu", "Tengyu", ""], ["Wang", "Zhe", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "2001.01900", "submitter": "Weizhi Li", "authors": "Weizhi Li, Gautam Dasarathy and Visar Berisha", "title": "Regularization via Structural Label Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is an effective way to promote the generalization performance\nof machine learning models. In this paper, we focus on label smoothing, a form\nof output distribution regularization that prevents overfitting of a neural\nnetwork by softening the ground-truth labels in the training data in an attempt\nto penalize overconfident outputs. Existing approaches typically use\ncross-validation to impose this smoothing, which is uniform across all training\ndata. In this paper, we show that such label smoothing imposes a quantifiable\nbias in the Bayes error rate of the training data, with regions of the feature\nspace with high overlap and low marginal likelihood having a lower bias and\nregions of low overlap and high marginal likelihood having a higher bias. These\ntheoretical results motivate a simple objective function for data-dependent\nsmoothing to mitigate the potential negative consequences of the operation\nwhile maintaining its desirable properties as a regularizer. We call this\napproach Structural Label Smoothing (SLS). We implement SLS and empirically\nvalidate on synthetic, Higgs, SVHN, CIFAR-10, and CIFAR-100 datasets. The\nresults confirm our theoretical insights and demonstrate the effectiveness of\nthe proposed method in comparison to traditional label smoothing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:45:18 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 23:22:56 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Li", "Weizhi", ""], ["Dasarathy", "Gautam", ""], ["Berisha", "Visar", ""]]}, {"id": "2001.01917", "submitter": "Yohan Jung", "authors": "Yohan Jung, Jinkyoo Park", "title": "Scalable Hybrid HMM with Gaussian Process Emission for Sequential\n  Time-series Data Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov Model (HMM) combined with Gaussian Process (GP) emission can be\neffectively used to estimate the hidden state with a sequence of complex\ninput-output relational observations. Especially when the spectral mixture (SM)\nkernel is used for GP emission, we call this model as a hybrid HMM-GPSM. This\nmodel can effectively model the sequence of time-series data. However, because\nof a large number of parameters for the SM kernel, this model can not\neffectively be trained with a large volume of data having (1) long sequence for\nstate transition and 2) a large number of time-series dataset in each sequence.\nThis paper proposes a scalable learning method for HMM-GPSM. To effectively\ntrain the model with a long sequence, the proposed method employs a Stochastic\nVariational Inference (SVI) approach. Also, to effectively process a large\nnumber of data point each time-series data, we approximate the SM kernel using\nReparametrized Random Fourier Feature (R-RFF). The combination of these two\ntechniques significantly reduces the training time. We validate the proposed\nlearning method in terms of its hidden-sate estimation accuracy and computation\ntime using large-scale synthetic and real data sets with missing values.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:28:21 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Jung", "Yohan", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2001.01920", "submitter": "Tian Li", "authors": "Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet\n  Talwalkar, Virginia Smith", "title": "FedDANE: A Federated Newton-Type Method", "comments": "Asilomar Conference on Signals, Systems, and Computers 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning aims to jointly learn statistical models over massively\ndistributed remote devices. In this work, we propose FedDANE, an optimization\nmethod that we adapt from DANE, a method for classical distributed\noptimization, to handle the practical constraints of federated learning. We\nprovide convergence guarantees for this method when learning over both convex\nand non-convex functions. Despite encouraging theoretical results, we find that\nthe method has underwhelming performance empirically. In particular, through\nempirical simulations on both synthetic and real-world datasets, FedDANE\nconsistently underperforms baselines of FedAvg and FedProx in realistic\nfederated settings. We identify low device participation and statistical device\nheterogeneity as two underlying causes of this underwhelming performance, and\nconclude by suggesting several directions of future work.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:44:41 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Li", "Tian", ""], ["Sahu", "Anit Kumar", ""], ["Zaheer", "Manzil", ""], ["Sanjabi", "Maziar", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""]]}, {"id": "2001.01924", "submitter": "James Watson", "authors": "Oliver P Watson, Isidro Cortes-Ciriano, James A Watson", "title": "A semi-supervised learning framework for quantitative structure-activity\n  regression modelling", "comments": "17 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised learning models, also known as quantitative structure-activity\nregression (QSAR) models, are increasingly used in assisting the process of\npreclinical, small molecule drug discovery. The models are trained on data\nconsisting of a finite dimensional representation of molecular structures and\ntheir corresponding target specific activities. These models can then be used\nto predict the activity of previously unmeasured novel compounds. In this work\nwe address two problems related to this approach. The first is to estimate the\nextent to which the quality of the model predictions degrades for compounds\nvery different from the compounds in the training data. The second is to adjust\nfor the screening dependent selection bias inherent in many training data sets.\nIn the most extreme cases, only compounds which pass an activity-dependent\nscreening are reported. By using a semi-supervised learning framework, we show\nthat it is possible to make predictions which take into account the similarity\nof the testing compounds to those in the training data and adjust for the\nreporting selection bias. We illustrate this approach using publicly available\nstructure-activity data on a large set of compounds reported by GlaxoSmithKline\n(the Tres Cantos AntiMalarial Set) to inhibit in vitro P. falciparum growth.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:56:49 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Watson", "Oliver P", ""], ["Cortes-Ciriano", "Isidro", ""], ["Watson", "James A", ""]]}, {"id": "2001.01969", "submitter": "Md Aamir Raihan", "authors": "Md Aamir Raihan, Tor M. Aamodt", "title": "Sparse Weight Activation Training", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training is computationally and memory intensive. Sparse\ntraining can reduce the burden on emerging hardware platforms designed to\naccelerate sparse computations, but it can affect network convergence. In this\nwork, we propose a novel CNN training algorithm Sparse Weight Activation\nTraining (SWAT). SWAT is more computation and memory-efficient than\nconventional training. SWAT modifies back-propagation based on the empirical\ninsight that convergence during training tends to be robust to the elimination\nof (i) small magnitude weights during the forward pass and (ii) both small\nmagnitude weights and activations during the backward pass. We evaluate SWAT on\nrecent CNN architectures such as ResNet, VGG, DenseNet and WideResNet using\nCIFAR-10, CIFAR-100 and ImageNet datasets. For ResNet-50 on ImageNet SWAT\nreduces total floating-point operations (FLOPS) during training by 80%\nresulting in a 3.3$\\times$ training speedup when run on a simulated sparse\nlearning accelerator representative of emerging platforms while incurring only\n1.63% reduction in validation accuracy. Moreover, SWAT reduces memory footprint\nduring the backward pass by 23% to 50% for activations and 50% to 90% for\nweights.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:08:13 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 00:10:27 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 21:51:29 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Raihan", "Md Aamir", ""], ["Aamodt", "Tor M.", ""]]}, {"id": "2001.01987", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Wouter Duivesteijn, Decebal Mocanu", "title": "Softmax-based Classification is k-means Clustering: Formal Proof,\n  Consequences for Adversarial Attacks, and Improvement through Centroid Based\n  Tailoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally prove the connection between k-means clustering and the\npredictions of neural networks based on the softmax activation layer. In\nexisting work, this connection has been analyzed empirically, but it has never\nbefore been mathematically derived. The softmax function partitions the\ntransformed input space into cones, each of which encompasses a class. This is\nequivalent to putting a number of centroids in this transformed space at equal\ndistance from the origin, and k-means clustering the data points by proximity\nto these centroids. Softmax only cares in which cone a data point falls, and\nnot how far from the centroid it is within that cone. We formally prove that\nnetworks with a small Lipschitz modulus (which corresponds to a low\nsusceptibility to adversarial attacks) map data points closer to the cluster\ncentroids, which results in a mapping to a k-means-friendly space. To leverage\nthis knowledge, we propose Centroid Based Tailoring as an alternative to the\nsoftmax function in the last layer of a neural network. The resulting Gauss\nnetwork has similar predictive accuracy as traditional networks, but is less\nsusceptible to one-pixel attacks; while the main contribution of this paper is\ntheoretical in nature, the Gauss network contributes empirical auxiliary\nbenefits.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:47:45 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Hess", "Sibylle", ""], ["Duivesteijn", "Wouter", ""], ["Mocanu", "Decebal", ""]]}, {"id": "2001.01997", "submitter": "Mehmet Tan", "authors": "I\\c{s}{\\i}ksu Ek\\c{s}io\\u{g}lu, Mehmet Tan", "title": "Prediction of Drug Synergy by Ensemble Learning", "comments": "Appeared in Computational Intelligence Methods for Bioinformatics and\n  Biostatistics (CIBB) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the promising methods for the treatment of complex diseases such as\ncancer is combinational therapy. Due to the combinatorial complexity, machine\nlearning models can be useful in this field, where significant improvements\nhave recently been achieved in determination of synergistic combinations. In\nthis study, we investigate the effectiveness of different compound\nrepresentations in predicting the drug synergy. On a large drug combination\nscreen dataset, we first demonstrate the use of a promising representation that\nhas not been used for this problem before, then we propose an ensemble on\nrepresentation-model combinations that outperform each of the baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:21:37 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ek\u015fio\u011flu", "I\u015f\u0131ksu", ""], ["Tan", "Mehmet", ""]]}, {"id": "2001.02005", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Backtracking Gradient Descent allowing unbounded learning rates", "comments": "Convergence for Two-way Backtracking GD can be proven under more\n  general assumptions, in particular valid for C^2 functions. In statement of\n  Theorem 0.3, need to add the assumption that {f(x_n}) is non-increasing. Some\n  typos corrected. 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unconstrained optimisation on an Euclidean space, to prove convergence in\nGradient Descent processes (GD) $x_{n+1}=x_n-\\delta _n \\nabla f(x_n)$ it\nusually is required that the learning rates $\\delta _n$'s are bounded: $\\delta\n_n\\leq \\delta $ for some positive $\\delta $. Under this assumption, if the\nsequence $x_n$ converges to a critical point $z$, then with large values of $n$\nthe update will be small because $||x_{n+1}-x_n||\\lesssim ||\\nabla f(x_n)||$.\nThis may also force the sequence to converge to a bad minimum. If we can allow,\nat least theoretically, that the learning rates $\\delta _n$'s are not bounded,\nthen we may have better convergence to better minima.\n  A previous joint paper by the author showed convergence for the usual version\nof Backtracking GD under very general assumptions on the cost function $f$. In\nthis paper, we allow the learning rates $\\delta _n$ to be unbounded, in the\nsense that there is a function $h:(0,\\infty)\\rightarrow (0,\\infty )$ such that\n$\\lim _{t\\rightarrow 0}th(t)=0$ and $\\delta _n\\lesssim \\max \\{h(x_n),\\delta \\}$\nsatisfies Armijo's condition for all $n$, and prove convergence under the same\nassumptions as in the mentioned paper. It will be shown that this growth rate\nof $h$ is best possible if one wants convergence of the sequence $\\{x_n\\}$.\n  A specific way for choosing $\\delta _n$ in a discrete way connects to Two-way\nBacktracking GD defined in the mentioned paper. We provide some results which\neither improve or are implicitly contained in those in the mentioned paper and\nanother recent paper on avoidance of saddle points.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:52:00 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 16:50:06 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2001.02050", "submitter": "Reza Rashetnia", "authors": "Reza Rashetnia and Mohammad Pour-Ghaz", "title": "Deep learning surrogate interacting Markov chain Monte Carlo based full\n  wave inversion scheme for properties of materials quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full Wave Inversion (FWI) imaging scheme has many applications in\nengineering, geoscience and medical sciences. In this paper, a surrogate deep\nlearning FWI approach is presented to quantify properties of materials using\nstress waves. Such inverse problems, in general, are ill-posed and nonconvex,\nespecially in cases where the solutions exhibit shocks, heterogeneity,\ndiscontinuities, or large gradients. The proposed approach is proven efficient\nto obtain global minima responses in these cases. This approach is trained\nbased on random sampled set of material properties and sampled trials around\nlocal minima, therefore, it requires a forward simulation can handle high\nheterogeneity, discontinuities and large gradients. High resolution\nKurganov-Tadmor (KT) central finite volume method is used as forward wave\npropagation operator. Using the proposed framework, material properties of 2D\nmedia are quantified for several different situations. The results demonstrate\nthe feasibility of the proposed method for estimating mechanical properties of\nmaterials with high accuracy using deep learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:43:51 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Rashetnia", "Reza", ""], ["Pour-Ghaz", "Mohammad", ""]]}, {"id": "2001.02121", "submitter": "Alexander M\\\"arz", "authors": "Alexander M\\\"arz", "title": "CatBoostLSS -- An extension of CatBoost to probabilistic forecasting", "comments": "CatBoost, Distributional Modelling, Expectile Regression, GAMLSS,\n  Probabilistic Forecast, Statistical Machine Learning, Uncertainty\n  Quantification. arXiv admin note: substantial text overlap with\n  arXiv:1907.03178", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework of CatBoost that predicts the entire conditional\ndistribution of a univariate response variable. In particular, CatBoostLSS\nmodels all moments of a parametric distribution (i.e., mean, location, scale\nand shape [LSS]) instead of the conditional mean only. Choosing from a wide\nrange of continuous, discrete and mixed discrete-continuous distributions,\nmodelling and predicting the entire conditional distribution greatly enhances\nthe flexibility of CatBoost, as it allows to gain insight into the data\ngenerating process, as well as to create probabilistic forecasts from which\nprediction intervals and quantiles of interest can be derived. We present both\na simulation study and real-world examples that demonstrate the benefits of our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 15:42:44 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["M\u00e4rz", "Alexander", ""]]}, {"id": "2001.02127", "submitter": "Nadine Kuhnert", "authors": "Nadine Kuhnert, Lea Pfl\\\"uger, Andreas Maier", "title": "Prediction of MRI Hardware Failures based on Image Features using Time\n  Series Classification", "comments": null, "journal-ref": "Bildverarbeitung f\\\"ur die Medizin 2020. Springer Vieweg,\n  Wiesbaden, 2020", "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Already before systems malfunction one has to know if hardware components\nwill fail in near future in order to counteract in time. Thus, unplanned\ndowntime is ought to be avoided. In medical imaging, maximizing the system's\nuptime is crucial for patients' health and healthcare provider's daily\nbusiness. We aim to predict failures of Head/Neck coils used in Magnetic\nResonance Imaging (MRI) by training a statistical model on sequential data\ncollected over time. As image features depend on the coil's condition, their\ndeviations from the normal range already hint to future failure. Thus, we used\nimage features and their variation over time to predict coil damage. After\ncomparison of different time series classification methods we found Long Short\nTerm Memorys (LSTMs) to achieve the highest F-score of 86.43% and to tell with\n98.33% accuracy if hardware should be replaced.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:25:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kuhnert", "Nadine", ""], ["Pfl\u00fcger", "Lea", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.02152", "submitter": "Iain Whiteside", "authors": "Edward Ayers, Francisco Eiras, Majd Hawasly, Iain Whiteside", "title": "PaRoT: A Practical Framework for Robust Deep Neural Network Training", "comments": "Accepted at 12th NASA Formal Methods Symposium, NFM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are finding important applications in\nsafety-critical systems such as Autonomous Vehicles (AVs), where perceiving the\nenvironment correctly and robustly is necessary for safe operation. Raising\nunique challenges for assurance due to their black-box nature, DNNs pose a\nfundamental problem for regulatory acceptance of these types of systems. Robust\ntraining --- training to minimize excessive sensitivity to small changes in\ninput --- has emerged as one promising technique to address this challenge.\nHowever, existing robust training tools are inconvenient to use or apply to\nexisting codebases and models: they typically only support a small subset of\nmodel elements and require users to extensively rewrite the training code. In\nthis paper we introduce a novel framework, PaRoT, developed on the popular\nTensorFlow platform, that greatly reduces the barrier to entry. Our framework\nenables robust training to be performed on arbitrary DNNs without any rewrites\nto the model. We demonstrate that our framework's performance is comparable to\nprior art, and exemplify its ease of use on off-the-shelf, trained models and\nits testing capabilities on a real-world industrial application: a traffic\nlight detection network.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:21:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 13:31:50 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 11:17:37 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ayers", "Edward", ""], ["Eiras", "Francisco", ""], ["Hawasly", "Majd", ""], ["Whiteside", "Iain", ""]]}, {"id": "2001.02153", "submitter": "Mohak Bhardwaj", "authors": "Mohak Bhardwaj, Ankur Handa, Dieter Fox, Byron Boots", "title": "Information Theoretic Model Predictive Q-Learning", "comments": "Extended version (15 pages) of paper accepted at the 2nd Learning for\n  Dynamics and Control (L4DC) Conference, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free Reinforcement Learning (RL) works well when experience can be\ncollected cheaply and model-based RL is effective when system dynamics can be\nmodeled accurately. However, both assumptions can be violated in real world\nproblems such as robotics, where querying the system can be expensive and\nreal-world dynamics can be difficult to model. In contrast to RL, Model\nPredictive Control (MPC) algorithms use a simulator to optimize a simple policy\nclass online, constructing a closed-loop controller that can effectively\ncontend with real-world dynamics. MPC performance is usually limited by factors\nsuch as model bias and the limited horizon of optimization. In this work, we\npresent a novel theoretical connection between information theoretic MPC and\nentropy regularized RL and develop a Q-learning algorithm that can leverage\nbiased models. We validate the proposed algorithm on sim-to-sim control tasks\nto demonstrate the improvements over optimal control and reinforcement learning\nfrom scratch. Our approach paves the way for deploying reinforcement learning\nalgorithms on real systems in a systematic manner.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 00:29:22 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 21:49:55 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bhardwaj", "Mohak", ""], ["Handa", "Ankur", ""], ["Fox", "Dieter", ""], ["Boots", "Byron", ""]]}, {"id": "2001.02165", "submitter": "Axel Barrau", "authors": "S\\'ebastien Razakarivony and Axel Barrau", "title": "Generalized mean shift with triangular kernel profile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean shift algorithm is a popular way to find modes of some probability\ndensity functions taking a specific kernel-based shape, used for clustering or\nvisual tracking. Since its introduction, it underwent several practical\nimprovements and generalizations, as well as deep theoretical analysis mainly\nfocused on its convergence properties. In spite of encouraging results, this\nquestion has not received a clear general answer yet. In this paper we focus on\na specific class of kernels, adapted in particular to the distributions\nclustering applications which motivated this work. We show that a novel Mean\nShift variant adapted to them can be derived, and proved to converge after a\nfinite number of iterations. In order to situate this new class of methods in\nthe general picture of the Mean Shift theory, we alo give a synthetic exposure\nof existing results of this field.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:46:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Razakarivony", "S\u00e9bastien", ""], ["Barrau", "Axel", ""]]}, {"id": "2001.02297", "submitter": "Shuo Wang", "authors": "Shuo Wang, Shangyu Chen, Tianle Chen, Surya Nepal, Carsten Rudolph,\n  Marthie Grobler", "title": "Generating Semantic Adversarial Examples via Feature Manipulation", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.09064 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks to adversarial attacks has been\nwidely demonstrated (e.g., adversarial example attacks). Traditional attacks\nperform unstructured pixel-wise perturbation to fool the classifier. An\nalternative approach is to have perturbations in the latent space. However,\nsuch perturbations are hard to control due to the lack of interpretability and\ndisentanglement. In this paper, we propose a more practical adversarial attack\nby designing structured perturbation with semantic meanings. Our proposed\ntechnique manipulates the semantic attributes of images via the disentangled\nlatent codes. The intuition behind our technique is that images in similar\ndomains have some commonly shared but theme-independent semantic attributes,\ne.g. thickness of lines in handwritten digits, that can be bidirectionally\nmapped to disentangled latent codes. We generate adversarial perturbation by\nmanipulating a single or a combination of these latent codes and propose two\nunsupervised semantic manipulation approaches: vector-based disentangled\nrepresentation and feature map-based disentangled representation, in terms of\nthe complexity of the latent codes and smoothness of the reconstructed images.\nWe conduct extensive experimental evaluations on real-world image data to\ndemonstrate the power of our attacks for black-box classifiers. We further\ndemonstrate the existence of a universal, image-agnostic semantic adversarial\nexample.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 06:28:31 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Shangyu", ""], ["Chen", "Tianle", ""], ["Nepal", "Surya", ""], ["Rudolph", "Carsten", ""], ["Grobler", "Marthie", ""]]}, {"id": "2001.02312", "submitter": "Santiago Akle Serrano", "authors": "Vipul Gupta, Santiago Akle Serrano, Dennis DeCoste", "title": "Stochastic Weight Averaging in Parallel: Large-Batch Training that\n  Generalizes Well", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Stochastic Weight Averaging in Parallel (SWAP), an algorithm to\naccelerate DNN training. Our algorithm uses large mini-batches to compute an\napproximate solution quickly and then refines it by averaging the weights of\nmultiple models computed independently and in parallel. The resulting models\ngeneralize equally well as those trained with small mini-batches but are\nproduced in a substantially shorter time. We demonstrate the reduction in\ntraining time and the good generalization performance of the resulting models\non the computer vision datasets CIFAR10, CIFAR100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 23:13:35 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Gupta", "Vipul", ""], ["Serrano", "Santiago Akle", ""], ["DeCoste", "Dennis", ""]]}, {"id": "2001.02323", "submitter": "James Grant", "authors": "James A. Grant and David S. Leslie", "title": "On Thompson Sampling for Smoother-than-Lipschitz Bandits", "comments": "Accepted to AISTATS 2020. 26 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling is a well established approach to bandit and reinforcement\nlearning problems. However its use in continuum armed bandit problems has\nreceived relatively little attention. We provide the first bounds on the regret\nof Thompson Sampling for continuum armed bandits under weak conditions on the\nfunction class containing the true function and sub-exponential observation\nnoise. Our bounds are realised by analysis of the eluder dimension, a recently\nproposed measure of the complexity of a function class, which has been\ndemonstrated to be useful in bounding the Bayesian regret of Thompson Sampling\nfor simpler bandit problems under sub-Gaussian observation noise. We derive a\nnew bound on the eluder dimension for classes of functions with Lipschitz\nderivatives, and generalise previous analyses in multiple regards.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 00:46:13 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 12:06:42 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Grant", "James A.", ""], ["Leslie", "David S.", ""]]}, {"id": "2001.02370", "submitter": "Xiao Fu", "authors": "Shahana Ibrahim, Xiao Fu, Xingguo Li", "title": "On Recoverability of Randomly Compressed Tensors with Low CP Rank", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": "10.1109/LSP.2020.3003252", "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our interest lies in the recoverability properties of compressed tensors\nunder the \\textit{canonical polyadic decomposition} (CPD) model. The considered\nproblem is well-motivated in many applications, e.g., hyperspectral image and\nvideo compression. Prior work studied this problem under somewhat special\nassumptions---e.g., the latent factors of the tensor are sparse or drawn from\nabsolutely continuous distributions. We offer an alternative result: We show\nthat if the tensor is compressed by a subgaussian linear mapping, then the\ntensor is recoverable if the number of measurements is on the same order of\nmagnitude as that of the model parameters---without strong assumptions on the\nlatent factors. Our proof is based on deriving a \\textit{restricted isometry\nproperty} (R.I.P.) under the CPD model via set covering techniques, and thus\nexhibits a flavor of classic compressive sensing. The new recoverability result\nenriches the understanding to the compressed CP tensor recovery problem; it\noffers theoretical guarantees for recovering tensors whose elements are not\nnecessarily continuous or sparse.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 04:44:13 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ibrahim", "Shahana", ""], ["Fu", "Xiao", ""], ["Li", "Xingguo", ""]]}, {"id": "2001.02378", "submitter": "Runtian Zhai", "authors": "Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep\n  Ravikumar, Cho-Jui Hsieh, Liwei Wang", "title": "MACER: Attack-free and Scalable Robust Training via Maximizing Certified\n  Radius", "comments": "In ICLR 2020. 20 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is one of the most popular ways to learn robust models\nbut is usually attack-dependent and time costly. In this paper, we propose the\nMACER algorithm, which learns robust models without using adversarial training\nbut performs better than all existing provable l2-defenses. Recent work shows\nthat randomized smoothing can be used to provide a certified l2 radius to\nsmoothed classifiers, and our algorithm trains provably robust smoothed\nclassifiers via MAximizing the CErtified Radius (MACER). The attack-free\ncharacteristic makes MACER faster to train and easier to optimize. In our\nexperiments, we show that our method can be applied to modern deep neural\nnetworks on a wide range of datasets, including Cifar-10, ImageNet, MNIST, and\nSVHN. For all tasks, MACER spends less training time than state-of-the-art\nadversarial training algorithms, and the learned models achieve larger average\ncertified radius.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 05:08:56 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:28:05 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 03:02:26 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhai", "Runtian", ""], ["Dan", "Chen", ""], ["He", "Di", ""], ["Zhang", "Huan", ""], ["Gong", "Boqing", ""], ["Ravikumar", "Pradeep", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Liwei", ""]]}, {"id": "2001.02391", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat, Fang Chen, Bogdan Gabrys", "title": "An improved online learning algorithm for general fuzzy min-max neural\n  network", "comments": "9 pages, 8 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes an improved version of the current online learning\nalgorithm for a general fuzzy min-max neural network (GFMM) to tackle existing\nissues concerning expansion and contraction steps as well as the way of dealing\nwith unseen data located on decision boundaries. These drawbacks lower its\nclassification performance, so an improved algorithm is proposed in this study\nto address the above limitations. The proposed approach does not use the\ncontraction process for overlapping hyperboxes, which is more likely to\nincrease the error rate as shown in the literature. The empirical results\nindicated the improvement in the classification accuracy and stability of the\nproposed method compared to the original version and other fuzzy min-max\nclassifiers. In order to reduce the sensitivity to the training samples\npresentation order of this new on-line learning algorithm, a simple ensemble\nmethod is also proposed.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 06:24:40 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Chen", "Fang", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2001.02394", "submitter": "Gao Huang", "authors": "Gao Huang and Zhuang Liu and Geoff Pleiss and Laurens van der Maaten\n  and Kilian Q. Weinberger", "title": "Convolutional Networks with Dense Connectivity", "comments": "Journal(PAMI) version of DenseNet(CVPR'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that convolutional networks can be substantially\ndeeper, more accurate, and efficient to train if they contain shorter\nconnections between layers close to the input and those close to the output. In\nthis paper, we embrace this observation and introduce the Dense Convolutional\nNetwork (DenseNet), which connects each layer to every other layer in a\nfeed-forward fashion.Whereas traditional convolutional networks with L layers\nhave L connections - one between each layer and its subsequent layer - our\nnetwork has L(L+1)/2 direct connections. For each layer, the feature-maps of\nall preceding layers are used as inputs, and its own feature-maps are used as\ninputs into all subsequent layers. DenseNets have several compelling\nadvantages: they alleviate the vanishing-gradient problem, encourage feature\nreuse and substantially improve parameter efficiency. We evaluate our proposed\narchitecture on four highly competitive object recognition benchmark tasks\n(CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant\nimprovements over the state-of-the-art on most of them, whilst requiring less\nparameters and computation to achieve high performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 06:54:53 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Huang", "Gao", ""], ["Liu", "Zhuang", ""], ["Pleiss", "Geoff", ""], ["van der Maaten", "Laurens", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2001.02399", "submitter": "Yurui Ming", "authors": "Yurui Ming, Dongrui Wu, Yu-Kai Wang, Yuhui Shi, Chin-Teng Lin", "title": "EEG-based Drowsiness Estimation for Driving Safety using Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatigue is the most vital factor of road fatalities and one manifestation of\nfatigue during driving is drowsiness. In this paper, we propose using deep\nQ-learning to analyze an electroencephalogram (EEG) dataset captured during a\nsimulated endurance driving test. By measuring the correlation between\ndrowsiness and driving performance, this experiment represents an important\nbrain-computer interface (BCI) paradigm especially from an application\nperspective. We adapt the terminologies in the driving test to fit the\nreinforcement learning framework, thus formulate the drowsiness estimation\nproblem as an optimization of a Q-learning task. By referring to the latest\ndeep Q-Learning technologies and attending to the characteristics of EEG data,\nwe tailor a deep Q-network for action proposition that can indirectly estimate\ndrowsiness. Our results show that the trained model can trace the variations of\nmind state in a satisfactory way against the testing EEG data, which\ndemonstrates the feasibility and practicability of this new computation\nparadigm. We also show that our method outperforms the supervised learning\ncounterpart and is superior for real applications. To the best of our\nknowledge, we are the first to introduce the deep reinforcement learning method\nto this BCI scenario, and our method can be potentially generalized to other\nBCI cases.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 07:10:03 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 12:37:46 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ming", "Yurui", ""], ["Wu", "Dongrui", ""], ["Wang", "Yu-Kai", ""], ["Shi", "Yuhui", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2001.02407", "submitter": "Yi-Fu Wu", "authors": "Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri, Weihao Sun, Gautam\n  Singh, Fei Deng, Jindong Jiang, Sungjin Ahn", "title": "SPACE: Unsupervised Object-Oriented Scene Representation via Spatial\n  Attention and Decomposition", "comments": "Accepted in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to decompose complex multi-object scenes into meaningful\nabstractions like objects is fundamental to achieve higher-level cognition.\nPrevious approaches for unsupervised object-oriented scene representation\nlearning are either based on spatial-attention or scene-mixture approaches and\nlimited in scalability which is a main obstacle towards modeling real-world\nscenes. In this paper, we propose a generative latent variable model, called\nSPACE, that provides a unified probabilistic modeling framework that combines\nthe best of spatial-attention and scene-mixture approaches. SPACE can\nexplicitly provide factorized object representations for foreground objects\nwhile also decomposing background segments of complex morphology. Previous\nmodels are good at either of these, but not both. SPACE also resolves the\nscalability problems of previous methods by incorporating parallel\nspatial-attention and thus is applicable to scenes with a large number of\nobjects without performance degradations. We show through experiments on Atari\nand 3D-Rooms that SPACE achieves the above properties consistently in\ncomparison to SPAIR, IODINE, and GENESIS. Results of our experiments can be\nfound on our project website: https://sites.google.com/view/space-project-page\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 07:44:32 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:09:05 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2020 20:21:38 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Lin", "Zhixuan", ""], ["Wu", "Yi-Fu", ""], ["Peri", "Skand Vishwanath", ""], ["Sun", "Weihao", ""], ["Singh", "Gautam", ""], ["Deng", "Fei", ""], ["Jiang", "Jindong", ""], ["Ahn", "Sungjin", ""]]}, {"id": "2001.02430", "submitter": "Subhajit Dutta Dr.", "authors": "Sarbojit Roy, Soham Sarkar and Subhajit Dutta", "title": "On a Generalization of the Average Distance Classifier", "comments": "Short version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimension, low sample size (HDLSS)settings, the simple average\ndistance classifier based on the Euclidean distance performs poorly if\ndifferences between the locations get masked by the scale differences. To\nrectify this issue, modifications to the average distance classifier was\nproposed by Chan and Hall (2009). However, the existing classifiers cannot\ndiscriminate when the populations differ in other aspects than locations and\nscales. In this article, we propose some simple transformations of the average\ndistance classifier to tackle this issue. The resulting classifiers perform\nquite well even when the underlying populations have the same location and\nscale. The high-dimensional behaviour of the proposed classifiers is studied\ntheoretically. Numerical experiments with a variety of simulated as well as\nreal data sets exhibit the usefulness of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:00:55 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Roy", "Sarbojit", ""], ["Sarkar", "Soham", ""], ["Dutta", "Subhajit", ""]]}, {"id": "2001.02431", "submitter": "Marco Mamprin Mr.", "authors": "Marco Mamprin, Jo M. Zelis, Pim A.L. Tonino, Svitlana Zinger, Peter\n  H.N. de With", "title": "Gradient Boosting on Decision Trees for Mortality Prediction in\n  Transcatheter Aortic Valve Implantation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current prognostic risk scores in cardiac surgery are based on statistics and\ndo not yet benefit from machine learning. Statistical predictors are not robust\nenough to correctly identify patients who would benefit from Transcatheter\nAortic Valve Implantation (TAVI). This research aims to create a machine\nlearning model to predict one-year mortality of a patient after TAVI. We adopt\na modern gradient boosting on decision trees algorithm, specifically designed\nfor categorical features. In combination with a recent technique for model\ninterpretations, we developed a feature analysis and selection stage, enabling\nto identify the most important features for the prediction. We base our\nprediction model on the most relevant features, after interpreting and\ndiscussing the feature analysis results with clinical experts. We validated our\nmodel on 270 TAVI cases, reaching an AUC of 0.83. Our approach outperforms\nseveral widespread prognostic risk scores, such as logistic EuroSCORE II, the\nSTS risk score and the TAVI2-score, which are broadly adopted by cardiologists\nworldwide.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:04:42 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Mamprin", "Marco", ""], ["Zelis", "Jo M.", ""], ["Tonino", "Pim A. L.", ""], ["Zinger", "Svitlana", ""], ["de With", "Peter H. N.", ""]]}, {"id": "2001.02435", "submitter": "Samuele Tosatto", "authors": "Samuele Tosatto, Joao Carvalho, Hany Abdulsamad, Jan Peters", "title": "A Nonparametric Off-Policy Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms still suffer from high sample\ncomplexity despite outstanding recent successes. The need for intensive\ninteractions with the environment is especially observed in many widely popular\npolicy gradient algorithms that perform updates using on-policy samples. The\nprice of such inefficiency becomes evident in real-world scenarios such as\ninteraction-driven robot learning, where the success of RL has been rather\nlimited. We address this issue by building on the general sample efficiency of\noff-policy algorithms. With nonparametric regression and density estimation\nmethods we construct a nonparametric Bellman equation in a principled manner,\nwhich allows us to obtain closed-form estimates of the value function, and to\nanalytically express the full policy gradient. We provide a theoretical\nanalysis of our estimate to show that it is consistent under mild smoothness\nassumptions and empirically show that our approach has better sample efficiency\nthan state-of-the-art policy gradient methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:13:08 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 15:03:39 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 11:30:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tosatto", "Samuele", ""], ["Carvalho", "Joao", ""], ["Abdulsamad", "Hany", ""], ["Peters", "Jan", ""]]}, {"id": "2001.02438", "submitter": "Shruti Tople", "authors": "Bijeeta Pal and Shruti Tople", "title": "To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, \"can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?\" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:26:55 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Pal", "Bijeeta", ""], ["Tople", "Shruti", ""]]}, {"id": "2001.02463", "submitter": "Hyun-Suk Lee", "authors": "Hyun-Suk Lee, Cong Shen, James Jordon, Mihaela van der Schaar", "title": "Contextual Constrained Learning for Dose-Finding Clinical Trials", "comments": "18 pages, 5 figures, in Proceedings of the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020, Palermo,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials in the medical domain are constrained by budgets. The number\nof patients that can be recruited is therefore limited. When a patient\npopulation is heterogeneous, this creates difficulties in learning subgroup\nspecific responses to a particular drug and especially for a variety of\ndosages. In addition, patient recruitment can be difficult by the fact that\nclinical trials do not aim to provide a benefit to any given patient in the\ntrial. In this paper, we propose C3T-Budget, a contextual constrained clinical\ntrial algorithm for dose-finding under both budget and safety constraints. The\nalgorithm aims to maximize drug efficacy within the clinical trial while also\nlearning about the drug being tested. C3T-Budget recruits patients with\nconsideration of the remaining budget, the remaining time, and the\ncharacteristics of each group, such as the population distribution, estimated\nexpected efficacy, and estimation credibility. In addition, the algorithm aims\nto avoid unsafe dosages. These characteristics are further illustrated in a\nsimulated clinical trial study, which corroborates the theoretical analysis and\ndemonstrates an efficient budget usage as well as a balanced learning-treatment\ntrade-off.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 11:46:48 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 00:24:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lee", "Hyun-Suk", ""], ["Shen", "Cong", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.02466", "submitter": "Zheng Zhao", "authors": "Zheng Zhao, Toni Karvonen, Roland Hostettler, Simo S\\\"arkk\\\"a", "title": "Taylor Moment Expansion for Continuous-Discrete Gaussian Filtering and\n  Smoothing", "comments": "Submitted to IEEE Transactions on Automatic Control. Code is\n  available at (once accepted for publication)\n  https://github.com/zgbkdlm/TME-filter-smoother", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is concerned with non-linear Gaussian filtering and smoothing in\ncontinuous-discrete state-space models, where the dynamic model is formulated\nas an It\\^{o} stochastic differential equation (SDE), and the measurements are\nobtained at discrete time instants. We propose novel Taylor moment expansion\n(TME) Gaussian filter and smoother which approximate the moments of the SDE\nwith a temporal Taylor expansion. Differently from classical linearisation or\nIt\\^{o}--Taylor approaches, the Taylor expansion is formed for the moment\nfunctions directly and in time variable, not by using a Taylor expansion on the\nnon-linear functions in the model. We analyse the theoretical properties,\nincluding the positive definiteness of the covariance estimate and stability of\nthe TME Gaussian filter and smoother. By numerical experiments, we demonstrate\nthat the proposed TME Gaussian filter and smoother significantly outperform the\nstate-of-the-art methods in terms of estimation accuracy and numerical\nstability.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 11:59:59 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Zhao", "Zheng", ""], ["Karvonen", "Toni", ""], ["Hostettler", "Roland", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2001.02469", "submitter": "Yixing Huang", "authors": "Yixing Huang, Shengxiang Wang, Yong Guan, Andreas Maier", "title": "Limited Angle Tomography for Transmission X-Ray Microscopy Using Deep\n  Learning", "comments": null, "journal-ref": "Journal of Synchrotron Radiation 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In transmission X-ray microscopy (TXM) systems, the rotation of a scanned\nsample might be restricted to a limited angular range to avoid collision to\nother system parts or high attenuation at certain tilting angles. Image\nreconstruction from such limited angle data suffers from artifacts due to\nmissing data. In this work, deep learning is applied to limited angle\nreconstruction in TXMs for the first time. With the challenge to obtain\nsufficient real data for training, training a deep neural network from\nsynthetic data is investigated. Particularly, the U-Net, the state-of-the-art\nneural network in biomedical imaging, is trained from synthetic ellipsoid data\nand multi-category data to reduce artifacts in filtered back-projection (FBP)\nreconstruction images. The proposed method is evaluated on synthetic data and\nreal scanned chlorella data in $100^\\circ$ limited angle tomography. For\nsynthetic test data, the U-Net significantly reduces root-mean-square error\n(RMSE) from $2.55 \\times 10^{-3}$ {\\mu}m$^{-1}$ in the FBP reconstruction to\n$1.21 \\times 10^{-3}$ {\\mu}m$^{-1}$ in the U-Net reconstruction, and also\nimproves structural similarity (SSIM) index from 0.625 to 0.920. With penalized\nweighted least square denoising of measured projections, the RMSE and SSIM are\nfurther improved to $1.16 \\times 10^{-3}$ {\\mu}m$^{-1}$ and 0.932,\nrespectively. For real test data, the proposed method remarkably improves the\n3-D visualization of the subcellular structures in the chlorella cell, which\nindicates its important value for nano-scale imaging in biology, nanoscience\nand materials science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:11:19 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Huang", "Yixing", ""], ["Wang", "Shengxiang", ""], ["Guan", "Yong", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.02522", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Jinjun Xiong, Mengzhou Li, and Ge Wang", "title": "On Interpretability of Artificial Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning as represented by the artificial deep neural networks (DNNs)\nhas achieved great success in many important areas that deal with text, images,\nvideos, graphs, and so on. However, the black-box nature of DNNs has become one\nof the primary obstacles for their wide acceptance in mission-critical\napplications such as medical diagnosis and therapy. Due to the huge potential\nof deep learning, interpreting neural networks has recently attracted much\nresearch attention. In this paper, based on our comprehensive taxonomy, we\nsystematically review recent studies in understanding the mechanism of neural\nnetworks, describe applications of interpretability especially in medicine, and\ndiscuss future directions of interpretability research, such as in relation to\nfuzzy logic and brain science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:40:42 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 22:55:52 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 15:59:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fan", "Fenglei", ""], ["Xiong", "Jinjun", ""], ["Li", "Mengzhou", ""], ["Wang", "Ge", ""]]}, {"id": "2001.02568", "submitter": "Xishun Wang", "authors": "Xishun Wang and Zhouwang Yang and Xingye Yue and Hui Wang", "title": "A Group Norm Regularized Factorization Model for Subspace Segmentation", "comments": null, "journal-ref": "IEEE ACCESS,8:106601-106613,2020", "doi": "10.1109/ACCESS.2020.3000816", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace segmentation assumes that data comes from the union of different\nsubspaces and the purpose of segmentation is to partition the data into the\ncorresponding subspace. Low-rank representation (LRR) is a classic\nspectral-type method for solving subspace segmentation problems, that is, one\nfirst obtains an affinity matrix by solving a LRR model and then performs\nspectral clustering for segmentation. This paper proposes a group norm\nregularized factorization model (GNRFM) inspired by the LRR model for subspace\nsegmentation and then designs an Accelerated Augmented Lagrangian Method (AALM)\nalgorithm to solve this model. Specifically, we adopt group norm regularization\nto make the columns of the factor matrix sparse, thereby achieving a purpose of\nlow rank, which means no Singular Value Decompositions (SVD) are required and\nthe computational complexity of each step is greatly reduced. We obtain\naffinity matrices by using different LRR models and then performing cluster\ntesting on different sets of synthetic noisy data and real data, respectively.\nCompared with traditional models and algorithms, the proposed method is faster\nand more robust to noise, so the final clustering results are better. Moreover,\nthe numerical results show that our algorithm converges fast and only requires\napproximately ten iterations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:20:51 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 09:13:40 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Wang", "Xishun", ""], ["Yang", "Zhouwang", ""], ["Yue", "Xingye", ""], ["Wang", "Hui", ""]]}, {"id": "2001.02585", "submitter": "Zhaozhi Qian", "authors": "Zhaozhi Qian, Ahmed M. Alaa, Alexis Bellot, Jem Rashbass, Mihaela van\n  der Schaar", "title": "Learning Dynamic and Personalized Comorbidity Networks from Event Data\n  using Deep Diffusion Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comorbid diseases co-occur and progress via complex temporal patterns that\nvary among individuals. In electronic health records we can observe the\ndifferent diseases a patient has, but can only infer the temporal relationship\nbetween each co-morbid condition. Learning such temporal patterns from event\ndata is crucial for understanding disease pathology and predicting prognoses.\nTo this end, we develop deep diffusion processes (DDP) to model \"dynamic\ncomorbidity networks\", i.e., the temporal relationships between comorbid\ndisease onsets expressed through a dynamic graph. A DDP comprises events\nmodelled as a multi-dimensional point process, with an intensity function\nparameterized by the edges of a dynamic weighted graph. The graph structure is\nmodulated by a neural network that maps patient history to edge weights,\nenabling rich temporal representations for disease trajectories. The DDP\nparameters decouple into clinically meaningful components, which enables\nserving the dual purpose of accurate risk prediction and intelligible\nrepresentation of disease pathology. We illustrate these features in\nexperiments using cancer registry data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:47:08 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 14:44:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Qian", "Zhaozhi", ""], ["Alaa", "Ahmed M.", ""], ["Bellot", "Alexis", ""], ["Rashbass", "Jem", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.02610", "submitter": "Bo Zhao", "authors": "Bo Zhao, Konda Reddy Mopuri, Hakan Bilen", "title": "iDLG: Improved Deep Leakage from Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that sharing gradients will not leak private training\ndata in distributed learning systems such as Collaborative Learning and\nFederated Learning, etc. Recently, Zhu et al. presented an approach which shows\nthe possibility to obtain private training data from the publicly shared\ngradients. In their Deep Leakage from Gradient (DLG) method, they synthesize\nthe dummy data and corresponding labels with the supervision of shared\ngradients. However, DLG has difficulty in convergence and discovering the\nground-truth labels consistently. In this paper, we find that sharing gradients\ndefinitely leaks the ground-truth labels. We propose a simple but reliable\napproach to extract accurate data from the gradients. Particularly, our\napproach can certainly extract the ground-truth labels as opposed to DLG, hence\nwe name it Improved DLG (iDLG). Our approach is valid for any differentiable\nmodel trained with cross-entropy loss over one-hot labels. We mathematically\nillustrate how our method can extract ground-truth labels from the gradients\nand empirically demonstrate the advantages over DLG.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:45:09 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhao", "Bo", ""], ["Mopuri", "Konda Reddy", ""], ["Bilen", "Hakan", ""]]}, {"id": "2001.02652", "submitter": "Rahul Singh", "authors": "Rahul Singh, Keuntaek Lee, Yongxin Chen", "title": "Sample-based Distributional Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional reinforcement learning (DRL) is a recent reinforcement\nlearning framework whose success has been supported by various empirical\nstudies. It relies on the key idea of replacing the expected return with the\nreturn distribution, which captures the intrinsic randomness of the long term\nrewards. Most of the existing literature on DRL focuses on problems with\ndiscrete action space and value based methods. In this work, motivated by\napplications in robotics with continuous action space control settings, we\npropose sample-based distributional policy gradient (SDPG) algorithm. It models\nthe return distribution using samples via a reparameterization technique widely\nused in generative modeling and inference. We compare SDPG with the\nstate-of-art policy gradient method in DRL, distributed distributional\ndeterministic policy gradients (D4PG), which has demonstrated state-of-art\nperformance. We apply SDPG and D4PG to multiple OpenAI Gym environments and\nobserve that our algorithm shows better sample efficiency as well as higher\nreward for most tasks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 17:50:23 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Singh", "Rahul", ""], ["Lee", "Keuntaek", ""], ["Chen", "Yongxin", ""]]}, {"id": "2001.02656", "submitter": "David Tolpin", "authors": "David Tolpin, Tomer Dobkin", "title": "Stochastic Probabilistic Programs", "comments": "7 pages main body, 4 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of a stochastic probabilistic program and present a\nreference implementation of a probabilistic programming facility supporting\nspecification of stochastic probabilistic programs and inference in them.\nStochastic probabilistic programs allow straightforward specification and\nefficient inference in models with nuisance parameters, noise, and\nnondeterminism. We give several examples of stochastic probabilistic programs,\nand compare the programs with corresponding deterministic probabilistic\nprograms in terms of model specification and inference. We conclude with\ndiscussion of open research topics and related work.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 17:54:40 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 07:14:20 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 16:02:56 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Tolpin", "David", ""], ["Dobkin", "Tomer", ""]]}, {"id": "2001.02669", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Manish Sharma, Vijaya Saradhi", "title": "A Correspondence Analysis Framework for Author-Conference\n  Recommendations", "comments": "49 pages including references, 6 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many years, achievements and discoveries made by scientists are made\naware through research papers published in appropriate journals or conferences.\nOften, established scientists and especially newbies are caught up in the\ndilemma of choosing an appropriate conference to get their work through. Every\nscientific conference and journal is inclined towards a particular field of\nresearch and there is a vast multitude of them for any particular field.\nChoosing an appropriate venue is vital as it helps in reaching out to the right\naudience and also to further one's chance of getting their paper published. In\nthis work, we address the problem of recommending appropriate conferences to\nthe authors to increase their chances of acceptance. We present three different\napproaches for the same involving the use of social network of the authors and\nthe content of the paper in the settings of dimensionality reduction and topic\nmodeling. In all these approaches, we apply Correspondence Analysis (CA) to\nderive appropriate relationships between the entities in question, such as\nconferences and papers. Our models show promising results when compared with\nexisting methods such as content-based filtering, collaborative filtering and\nhybrid filtering.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:52:39 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Sharma", "Manish", ""], ["Saradhi", "Vijaya", ""]]}, {"id": "2001.02674", "submitter": "Niko Moritz", "authors": "Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Streaming automatic speech recognition with the transformer model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder based sequence-to-sequence models have demonstrated\nstate-of-the-art results in end-to-end automatic speech recognition (ASR).\nRecently, the transformer architecture, which uses self-attention to model\ntemporal context information, has been shown to achieve significantly lower\nword error rates (WERs) compared to recurrent neural network (RNN) based system\narchitectures. Despite its success, the practical usage is limited to offline\nASR tasks, since encoder-decoder architectures typically require an entire\nspeech utterance as input. In this work, we propose a transformer based\nend-to-end ASR system for streaming ASR, where an output must be generated\nshortly after each spoken word. To achieve this, we apply time-restricted\nself-attention for the encoder and triggered attention for the encoder-decoder\nattention mechanism. Our proposed streaming transformer architecture achieves\n2.8% and 7.2% WER for the \"clean\" and \"other\" test data of LibriSpeech, which\nto our knowledge is the best published streaming end-to-end ASR result for this\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:58:02 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 16:08:51 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 15:10:13 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 21:34:25 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2020 18:29:07 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2001.02712", "submitter": "Md Mahmudul Hasan", "authors": "Md Mahmudul Hasan, Shuangqing Wei, Ali Moharrer", "title": "Latent Factor Analysis of Gaussian Distributions under Graphical\n  Constraints", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the algebraic structure of the solution space of convex\noptimization problem Constrained Minimum Trace Factor Analysis (CMTFA), when\nthe population covariance matrix $\\Sigma_x$ has an additional latent graphical\nconstraint, namely, a latent star topology. In particular, we have shown that\nCMTFA can have either a rank $ 1 $ or a rank $ n-1 $ solution and nothing in\nbetween. The special case of a rank $ 1 $ solution, corresponds to the case\nwhere just one latent variable captures all the dependencies among the\nobservables, giving rise to a star topology. We found explicit conditions for\nboth rank $ 1 $ and rank $n- 1$ solutions for CMTFA solution of $\\Sigma_x$. As\na basic attempt towards building a more general Gaussian tree, we have found a\nnecessary and a sufficient condition for multiple clusters, each having rank $\n1 $ CMTFA solution, to satisfy a minimum probability to combine together to\nbuild a Gaussian tree. To support our analytical findings we have presented\nsome numerical demonstrating the usefulness of the contributions of our work.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 19:36:44 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 05:13:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hasan", "Md Mahmudul", ""], ["Wei", "Shuangqing", ""], ["Moharrer", "Ali", ""]]}, {"id": "2001.02728", "submitter": "Siavash Bigdeli", "authors": "Siavash A. Bigdeli, Geng Lin, Tiziano Portenier, L. Andrea Dunbar,\n  Matthias Zwicker", "title": "Learning Generative Models using Denoising Density Estimators", "comments": "Code and models available at\n  https://drive.google.com/file/d/1EzKRxnFG1Hd8g6Ggvt-jvKkgpDDwK2bY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning probabilistic models that can estimate the density of a given set of\nsamples, and generate samples from that density, is one of the fundamental\nchallenges in unsupervised machine learning. We introduce a new generative\nmodel based on denoising density estimators (DDEs), which are scalar functions\nparameterized by neural networks, that are efficiently trained to represent\nkernel density estimators of the data. Leveraging DDEs, our main contribution\nis a novel technique to obtain generative models by minimizing the\nKL-divergence directly. We prove that our algorithm for obtaining generative\nmodels is guaranteed to converge to the correct solution. Our approach does not\nrequire specific network architecture as in normalizing flows, nor use ordinary\ndifferential equation solvers as in continuous normalizing flows. Experimental\nresults demonstrate substantial improvement in density estimation and\ncompetitive performance in generative model training.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 20:30:40 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:26:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bigdeli", "Siavash A.", ""], ["Lin", "Geng", ""], ["Portenier", "Tiziano", ""], ["Dunbar", "L. Andrea", ""], ["Zwicker", "Matthias", ""]]}, {"id": "2001.02760", "submitter": "Abhaykumar Kumbhar", "authors": "Abhaykumar Kumbhar, Hamidullah Binol, Simran Singh, Ismail Guvenc,\n  Kemal Akkaya", "title": "Heuristic Approach for Jointly Optimizing FeICIC and UAV Locations in\n  Multi-Tier LTE-Advanced Public Safety HetNet", "comments": "Submitted at IET Cyber-Systems and Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UAV enabled communications and networking can enhance wireless connectivity\nand support emerging services. However, this would require system-level\nunderstanding to modify and extend the existing terrestrial network\ninfrastructure. In this paper, we integrate UAVs both as user equipment and\nbase stations into existing LTE-Advanced heterogeneous network (HetNet) and\nprovide system-level insights of this three-tier LTE-Advanced air-ground HetNet\n(AG-HetNet). This AG-HetNet leverages cell range expansion (CRE), ICIC, 3D\nbeamforming, and enhanced support for UAVs. Using system-level understanding\nand through brute-force technique and heuristics algorithms, we evaluate the\nperformance of AG-HetNet in terms of fifth percentile spectral efficiency\n(5pSE) and coverage probability. We compare 5pSE and coverage probability, when\naerial base-stations (UABS) are deployed on a fixed hexagonal grid and when\ntheir locations are optimized using genetic algorithm (GA) and elitist harmony\nsearch algorithm based on genetic algorithm (eHSGA). Our simulation results\nshow the heuristic algorithms outperform the brute-force technique and achieve\nbetter peak values of coverage probability and 5pSE. Simulation results also\nshow that trade-off exists between peak values and computation time when using\nheuristic algorithms. Furthermore, the three-tier hierarchical structuring of\nFeICIC provides considerably better 5pSE and coverage probability than eICIC.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:22:29 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Kumbhar", "Abhaykumar", ""], ["Binol", "Hamidullah", ""], ["Singh", "Simran", ""], ["Guvenc", "Ismail", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2001.02767", "submitter": "Yun-Cheng Tsai", "authors": "Jun-Hao Chen, Samuel Yen-Chi Chen, Yun-Cheng Tsai, Chih-Shiang Shur", "title": "Explainable Deep Convolutional Candlestick Learner", "comments": "Accepted by The 32nd International Conference on Software Engineering\n  & Knowledge Engineering (SEKE 2020), KSIR Virtual Conference Cener,\n  Pittsburgh, USA, July 9--July 19, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Candlesticks are graphical representations of price movements for a given\nperiod. The traders can discovery the trend of the asset by looking at the\ncandlestick patterns. Although deep convolutional neural networks have achieved\ngreat success for recognizing the candlestick patterns, their reasoning hides\ninside a black box. The traders cannot make sure what the model has learned. In\nthis contribution, we provide a framework which is to explain the reasoning of\nthe learned model determining the specific candlestick patterns of time series.\nBased on the local search adversarial attacks, we show that the learned model\nperceives the pattern of the candlesticks in a way similar to the human trader.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 22:11:13 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:12:55 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 09:09:02 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 06:04:54 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chen", "Jun-Hao", ""], ["Chen", "Samuel Yen-Chi", ""], ["Tsai", "Yun-Cheng", ""], ["Shur", "Chih-Shiang", ""]]}, {"id": "2001.02773", "submitter": "Yuqiao Chen", "authors": "Yuqiao Chen, Yibo Yang, Sriraam Natarajan, Nicholas Ruozzi", "title": "Lifted Hybrid Variational Inference", "comments": "AAAI 2020 Workshop on Statistical Relational AI (StarAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of lifted inference algorithms, which exploit model symmetry to\nreduce computational cost, have been proposed to render inference tractable in\nprobabilistic relational models. Most existing lifted inference algorithms\noperate only over discrete domains or continuous domains with restricted\npotential functions, e.g., Gaussian. We investigate two approximate lifted\nvariational approaches that are applicable to hybrid domains and expressive\nenough to capture multi-modality. We demonstrate that the proposed variational\nmethods are both scalable and can take advantage of approximate model\nsymmetries, even in the presence of a large amount of continuous evidence. We\ndemonstrate that our approach compares favorably against existing\nmessage-passing based approaches in a variety of settings. Finally, we present\na sufficient condition for the Bethe approximation to yield a non-trivial\nestimate over the marginal polytope.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 22:29:07 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 03:13:02 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Yuqiao", ""], ["Yang", "Yibo", ""], ["Natarajan", "Sriraam", ""], ["Ruozzi", "Nicholas", ""]]}, {"id": "2001.02792", "submitter": "Yizhou Wang", "authors": "Minshuo Chen, Yizhou Wang, Tianyi Liu, Zhuoran Yang, Xingguo Li,\n  Zhaoran Wang, Tuo Zhao", "title": "On Computation and Generalization of Generative Adversarial Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Imitation Learning (GAIL) is a powerful and practical\napproach for learning sequential decision-making policies. Different from\nReinforcement Learning (RL), GAIL takes advantage of demonstration data by\nexperts (e.g., human), and learns both the policy and reward function of the\nunknown environment. Despite the significant empirical progresses, the theory\nbehind GAIL is still largely unknown. The major difficulty comes from the\nunderlying temporal dependency of the demonstration data and the minimax\ncomputational formulation of GAIL without convex-concave structure. To bridge\nsuch a gap between theory and practice, this paper investigates the theoretical\nproperties of GAIL. Specifically, we show: (1) For GAIL with general reward\nparameterization, the generalization can be guaranteed as long as the class of\nthe reward functions is properly controlled; (2) For GAIL, where the reward is\nparameterized as a reproducing kernel function, GAIL can be efficiently solved\nby stochastic first order optimization algorithms, which attain sublinear\nconvergence to a stationary solution. To the best of our knowledge, these are\nthe first results on statistical and computational guarantees of imitation\nlearning with reward/policy function approximation. Numerical experiments are\nprovided to support our analysis.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 00:40:19 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 03:31:31 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chen", "Minshuo", ""], ["Wang", "Yizhou", ""], ["Liu", "Tianyi", ""], ["Yang", "Zhuoran", ""], ["Li", "Xingguo", ""], ["Wang", "Zhaoran", ""], ["Zhao", "Tuo", ""]]}, {"id": "2001.02798", "submitter": "Parshan Pakiman", "authors": "Parshan Pakiman, Selvaprabu Nadarajah, Negar Soheili and Qihang Lin", "title": "Self-guided Approximate Linear Programs", "comments": "57 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate linear programs (ALPs) are well-known models based on value\nfunction approximations (VFAs) to obtain heuristic policies and lower bounds on\nthe optimal policy cost of Markov decision processes (MDPs). The ALP VFA is a\nlinear combination of predefined basis functions that are chosen using domain\nknowledge and updated heuristically if the ALP optimality gap is large. We\nside-step the need for such basis function engineering in ALP -- an\nimplementation bottleneck -- by proposing a sequence of ALPs that embed\nincreasing numbers of random basis functions obtained via inexpensive sampling.\nWe provide a sampling guarantee and show that the VFAs from this sequence of\nmodels converge to the exact value function. Nevertheless, the performance of\nthe ALP policy can fluctuate significantly as more basis functions are sampled.\nTo mitigate these fluctuations, we \"self-guide\" our convergent sequence of ALPs\nusing past VFA information such that a worst-case measure of policy performance\nis improved. We perform numerical experiments on perishable inventory control\nand generalized joint replenishment applications, which, respectively, give\nrise to challenging discounted-cost MDPs and average-cost semi-MDPs. We find\nthat self-guided ALPs (i) significantly reduce policy cost fluctuations and\nimprove the optimality gaps from an ALP approach that employs basis functions\ntailored to the former application, and (ii) deliver optimality gaps that are\ncomparable to a known adaptive basis function generation approach targeting the\nlatter application. More broadly, our methodology provides application-agnostic\npolicies and lower bounds to benchmark approaches that exploit application\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 01:18:54 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Pakiman", "Parshan", ""], ["Nadarajah", "Selvaprabu", ""], ["Soheili", "Negar", ""], ["Lin", "Qihang", ""]]}, {"id": "2001.02802", "submitter": "Md. Aminur Rab Ratul", "authors": "Md. Aminur Rab Ratul", "title": "A Comparative Study on Crime in Denver City Based on Machine Learning\n  and Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure the security of the general mass, crime prevention is one of the\nmost higher priorities for any government. An accurate crime prediction model\ncan help the government, law enforcement to prevent violence, detect the\ncriminals in advance, allocate the government resources, and recognize problems\ncausing crimes. To construct any future-oriented tools, examine and understand\nthe crime patterns in the earliest possible time is essential. In this paper, I\nanalyzed a real-world crime and accident dataset of Denver county, USA, from\nJanuary 2014 to May 2019, which containing 478,578 incidents. This project aims\nto predict and highlights the trends of occurrence that will, in return,\nsupport the law enforcement agencies and government to discover the preventive\nmeasures from the prediction rates. At first, I apply several statistical\nanalysis supported by several data visualization approaches. Then, I implement\nvarious classification algorithms such as Random Forest, Decision Tree,\nAdaBoost Classifier, Extra Tree Classifier, Linear Discriminant Analysis,\nK-Neighbors Classifiers, and 4 Ensemble Models to classify 15 different classes\nof crimes. The outcomes are captured using two popular test methods: train-test\nsplit, and k-fold cross-validation. Moreover, to evaluate the performance\nflawlessly, I also utilize precision, recall, F1-score, Mean Squared Error\n(MSE), ROC curve, and paired-T-test. Except for the AdaBoost classifier, most\nof the algorithms exhibit satisfactory accuracy. Random Forest, Decision Tree,\nEnsemble Model 1, 3, and 4 even produce me more than 90% accuracy. Among all\nthe approaches, Ensemble Model 4 presented superior results for every\nevaluation basis. This study could be useful to raise the awareness of peoples\nregarding the occurrence locations and to assist security agencies to predict\nfuture outbreaks of violence in a specific area within a particular time.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 01:36:11 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ratul", "Md. Aminur Rab", ""]]}, {"id": "2001.02810", "submitter": "Huyan Huang", "authors": "Huyan Huang, Yipeng Liu, Ce Zhu", "title": "A Unified Framework for Coupled Tensor Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupled tensor decomposition reveals the joint data structure by\nincorporating priori knowledge that come from the latent coupled factors. The\ntensor ring (TR) decomposition is invariant under the permutation of tensors\nwith different mode properties, which ensures the uniformity of decomposed\nfactors and mode attributes. The TR has powerful expression ability and\nachieves success in some multi-dimensional data processing applications. To let\ncoupled tensors help each other for missing component estimation, in this paper\nwe utilize TR for coupled completion by sharing parts of the latent factors.\nThe optimization model for coupled TR completion is developed with a novel\nFrobenius norm. It is solved by the block coordinate descent algorithm which\nefficiently solves a series of quadratic problems resulted from sampling\npattern. The excess risk bound for this optimization model shows the\ntheoretical performance enhancement in comparison with other coupled nuclear\nnorm based methods. The proposed method is validated on numerical experiments\non synthetic data, and experimental results on real-world data demonstrate its\nsuperiority over the state-of-the-art methods in terms of recovery accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 02:15:46 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 03:57:54 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 06:39:35 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 12:36:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "2001.02814", "submitter": "Yuanlong Yu", "authors": "You Huang, Yuanlong Yu", "title": "An Internal Covariate Shift Bounding Algorithm for Deep Neural Networks\n  by Unitizing Layers' Outputs", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) techniques have been proposed to reduce the\nso-called Internal Covariate Shift (ICS) by attempting to keep the\ndistributions of layer outputs unchanged. Experiments have shown their\neffectiveness on training deep neural networks. However, since only the first\ntwo moments are controlled in these BN techniques, it seems that a weak\nconstraint is imposed on layer distributions and furthermore whether such\nconstraint can reduce ICS is unknown. Thus this paper proposes a measure for\nICS by using the Earth Mover (EM) distance and then derives the upper and lower\nbounds for the measure to provide a theoretical analysis of BN. The upper bound\nhas shown that BN techniques can control ICS only for the outputs with low\ndimensions and small noise whereas their control is NOT effective in other\ncases. This paper also proves that such control is just a bounding of ICS\nrather than a reduction of ICS. Meanwhile, the analysis shows that the\nhigh-order moments and noise, which BN cannot control, have great impact on the\nlower bound. Based on such analysis, this paper furthermore proposes an\nalgorithm that unitizes the outputs with an adjustable parameter to further\nbound ICS in order to cope with the problems of BN. The upper bound for the\nproposed unitization is noise-free and only dominated by the parameter. Thus,\nthe parameter can be trained to tune the bound and further to control ICS.\nBesides, the unitization is embedded into the framework of BN to reduce the\ninformation loss. The experiments show that this proposed algorithm outperforms\nexisting BN techniques on CIFAR-10, CIFAR-100 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 02:35:58 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Huang", "You", ""], ["Yu", "Yuanlong", ""]]}, {"id": "2001.02856", "submitter": "Hai Shu", "authors": "Hai Shu, Zhe Qu, Hongtu Zhu", "title": "D-GCCA: Decomposition-based Generalized Canonical Correlation Analysis\n  for Multiple High-dimensional Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern biomedical studies often collect multiple types of high-dimensional\ndata on a common set of objects. A popular model for the joint analysis of\nmulti-type datasets decomposes each data matrix into a low-rank\ncommon-variation matrix generated by latent factors shared across all datasets,\na low-rank distinctive-variation matrix corresponding to each dataset, and an\nadditive noise matrix. We propose decomposition-based generalized canonical\ncorrelation analysis (D-GCCA), a novel decomposition method that appropriately\ndefines those matrices on the L2 space of random variables, whereas most\nexisting methods are developed on its approximation, the Euclidean dot product\nspace. Moreover to well calibrate common latent factors, we impose a desirable\northogonality constraint on distinctive latent factors. Existing methods\ninadequately consider such orthogonality and can thus suffer from substantial\nloss of undetected common variation. Our D-GCCA takes one step further than\nGCCA by separating common and distinctive variations among canonical variables,\nand enjoys an appealing interpretation from the perspective of principal\ncomponent analysis. Consistent estimators of our common-variation and\ndistinctive-variation matrices are established with good finite-sample\nnumerical performance, and have closed-form expressions leading to efficient\ncomputation especially for large-scale datasets. The superiority of D-GCCA over\nstate-of-the-art methods is also corroborated in simulations and real-world\ndata examples.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 06:35:40 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Shu", "Hai", ""], ["Qu", "Zhe", ""], ["Zhu", "Hongtu", ""]]}, {"id": "2001.02879", "submitter": "Shao-Bo Lin", "authors": "Xiangyu Chang, Shao-Bo Lin", "title": "Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms", "comments": "32 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an adaptive stopping rule for kernel-based gradient\ndescent (KGD) algorithms. We introduce the empirical effective dimension to\nquantify the increments of iterations in KGD and derive an implementable early\nstopping strategy. We analyze the performance of the adaptive stopping rule in\nthe framework of learning theory. Using the recently developed integral\noperator approach, we rigorously prove the optimality of the adaptive stopping\nrule in terms of showing the optimal learning rates for KGD equipped with this\nrule. Furthermore, a sharp bound on the number of iterations in KGD equipped\nwith the proposed early stopping rule is also given to demonstrate its\ncomputational advantage.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:12:38 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chang", "Xiangyu", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "2001.02894", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Alessandro Selvitella, Liangxiu Han, Daoqiang\n  Zhang", "title": "Supervised Hyperalignment for multi-subject fMRI data alignment", "comments": "IEEE Transactions on Cognitive and Developmental Systems", "journal-ref": null, "doi": "10.1109/TCDS.2020.2965981", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperalignment has been widely employed in Multivariate Pattern (MVP)\nanalysis to discover the cognitive states in the human brains based on\nmulti-subject functional Magnetic Resonance Imaging (fMRI) datasets. Most of\nthe existing HA methods utilized unsupervised approaches, where they only\nmaximized the correlation between the voxels with the same position in the time\nseries. However, these unsupervised solutions may not be optimum for handling\nthe functional alignment in the supervised MVP problems. This paper proposes a\nSupervised Hyperalignment (SHA) method to ensure better functional alignment\nfor MVP analysis, where the proposed method provides a supervised shared space\nthat can maximize the correlation among the stimuli belonging to the same\ncategory and minimize the correlation between distinct categories of stimuli.\nFurther, SHA employs a generalized optimization solution, which generates the\nshared space and calculates the mapped features in a single iteration, hence\nwith optimum time and space complexities for large datasets. Experiments on\nmulti-subject datasets demonstrate that SHA method achieves up to 19% better\nperformance for multi-class problems over the state-of-the-art HA algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 09:17:49 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Selvitella", "Alessandro", ""], ["Han", "Liangxiu", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2001.02907", "submitter": "Whiyoung Jung", "authors": "Whiyoung Jung, Giseung Park, Youngchul Sung", "title": "Population-Guided Parallel Policy Search for Reinforcement Learning", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new population-guided parallel learning scheme is proposed\nto enhance the performance of off-policy reinforcement learning (RL). In the\nproposed scheme, multiple identical learners with their own value-functions and\npolicies share a common experience replay buffer, and search a good policy in\ncollaboration with the guidance of the best policy information. The key point\nis that the information of the best policy is fused in a soft manner by\nconstructing an augmented loss function for policy update to enlarge the\noverall search region by the multiple learners. The guidance by the previous\nbest policy and the enlarged range enable faster and better policy search.\nMonotone improvement of the expected cumulative return by the proposed scheme\nis proved theoretically. Working algorithms are constructed by applying the\nproposed scheme to the twin delayed deep deterministic (TD3) policy gradient\nalgorithm. Numerical results show that the constructed algorithm outperforms\nmost of the current state-of-the-art RL algorithms, and the gain is significant\nin the case of sparse reward environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 10:13:57 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Jung", "Whiyoung", ""], ["Park", "Giseung", ""], ["Sung", "Youngchul", ""]]}, {"id": "2001.02932", "submitter": "Joohyung Jeon", "authors": "Joohyung Jeon, Junhui Kim, Joongheon Kim, Kwangsoo Kim, Aziz Mohaisen,\n  and Jong-Kook Kim", "title": "Privacy-Preserving Deep Learning Computation for Geo-Distributed Medical\n  Big-Data Platforms", "comments": "2019 IEEE/IFIP International Conference on Dependable Systems and\n  Networks Supplemental", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed deep learning framework for\nprivacy-preserving medical data training. In order to avoid patients' data\nleakage in medical platforms, the hidden layers in the deep learning framework\nare separated and where the first layer is kept in platform and others layers\nare kept in a centralized server. Whereas keeping the original patients' data\nin local platforms maintain their privacy, utilizing the server for subsequent\nlayers improves learning performance by using all data from each platform\nduring training.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 11:46:29 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Jeon", "Joohyung", ""], ["Kim", "Junhui", ""], ["Kim", "Joongheon", ""], ["Kim", "Kwangsoo", ""], ["Mohaisen", "Aziz", ""], ["Kim", "Jong-Kook", ""]]}, {"id": "2001.02992", "submitter": "Emmanuel Abbe", "authors": "Emmanuel Abbe and Colin Sandon", "title": "Poly-time universality and limitations of deep learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1812.06369", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to characterize function distributions that deep\nlearning can or cannot learn in poly-time. A universality result is proved for\nSGD-based deep learning and a non-universality result is proved for GD-based\ndeep learning; this also gives a separation between SGD-based deep learning and\nstatistical query algorithms:\n  (1) {\\it Deep learning with SGD is efficiently universal.} Any function\ndistribution that can be learned from samples in poly-time can also be learned\nby a poly-size neural net trained with SGD on a poly-time initialization with\npoly-steps, poly-rate and possibly poly-noise.\n  Therefore deep learning provides a universal learning paradigm: it was known\nthat the approximation and estimation errors could be controlled with poly-size\nneural nets, using ERM that is NP-hard; this new result shows that the\noptimization error can also be controlled with SGD in poly-time. The picture\nchanges for GD with large enough batches:\n  (2) {\\it Result (1) does not hold for GD:} Neural nets of poly-size trained\nwith GD (full gradients or large enough batches) on any initialization with\npoly-steps, poly-range and at least poly-noise cannot learn any function\ndistribution that has super-polynomial {\\it cross-predictability,} where the\ncross-predictability gives a measure of ``average'' function correlation --\nrelations and distinctions to the statistical dimension are discussed. In\nparticular, GD with these constraints can learn efficiently monomials of degree\n$k$ if and only if $k$ is constant.\n  Thus (1) and (2) point to an interesting contrast: SGD is universal even with\nsome poly-noise while full GD or SQ algorithms are not (e.g., parities).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 08:31:50 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Sandon", "Colin", ""]]}, {"id": "2001.03000", "submitter": "Tom Vander Aa", "authors": "Imen Chakroun and Tom Vander Aa and Thomas J. Ashby", "title": "Guidelines for enhancing data locality in selected machine learning\n  algorithms", "comments": "European Commission Project: EPEEC - European joint Effort toward a\n  Highly Productive Programming Environment for Heterogeneous Exascale\n  Computing (EC-H2020-80151) This an extended version of arXiv:1904.11203", "journal-ref": "Intelligent Data Analysis, vol. 23, no. 5, pp. 1003-1020, 2019", "doi": "10.3233/IDA-184287", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with the complexity of the new bigger and more complex generation of\ndata, machine learning (ML) techniques are probably the first and foremost\nused. For ML algorithms to produce results in a reasonable amount of time, they\nneed to be implemented efficiently. In this paper, we analyze one of the means\nto increase the performances of machine learning algorithms which is exploiting\ndata locality. Data locality and access patterns are often at the heart of\nperformance issues in computing systems due to the use of certain hardware\ntechniques to improve performance. Altering the access patterns to increase\nlocality can dramatically increase performance of a given algorithm. Besides,\nrepeated data access can be seen as redundancy in data movement. Similarly,\nthere can also be redundancy in the repetition of calculations. This work also\nidentifies some of the opportunities for avoiding these redundancies by\ndirectly reusing computation results. We start by motivating why and how a more\nefficient implementation can be achieved by exploiting reuse in the memory\nhierarchy of modern instruction set processors. Next we document the\npossibilities of such reuse in some selected machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:16:40 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chakroun", "Imen", ""], ["Aa", "Tom Vander", ""], ["Ashby", "Thomas J.", ""]]}, {"id": "2001.03017", "submitter": "Chirag Gupta", "authors": "Chirag Gupta", "title": "Shallow Encoder Deep Decoder (SEDD) Networks for Image Encryption and\n  Decryption", "comments": "8 pages, 3 figures, preprint manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new framework for lossy image encryption and decryption\nusing a simple shallow encoder neural network E for encryption, and a complex\ndeep decoder neural network D for decryption. E is kept simple so that encoding\ncan be done on low power and portable devices and can in principle be any\nnonlinear function which outputs an encoded vector. D is trained to decode the\nencodings using the dataset of image - encoded vector pairs obtained from E and\nhappens independently of E. As the encodings come from E which while being a\nsimple neural network, still has thousands of random parameters and therefore\nthe encodings would be practically impossible to crack without D. This approach\ndiffers from autoencoders as D is trained completely independently of E,\nalthough the structure may seem similar. Therefore, this paper also explores\nempirically if a deep neural network can learn to reconstruct the original data\nin any useful form given the output of a neural network or any other nonlinear\nfunction, which can have very useful applications in Cryptanalysis. Experiments\ndemonstrate the potential of the framework through qualitative and quantitative\nevaluation of the decoded images from D along with some limitations.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:33:38 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 09:59:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gupta", "Chirag", ""]]}, {"id": "2001.03019", "submitter": "Burcu Gungor", "authors": "Hilal Hacilar, O.Ufuk Nalbantoglu, Oya Aran, Burcu Bakir-Gungor", "title": "Inflammatory Bowel Disease Biomarkers of Human Gut Microbiota Selected\n  via Ensemble Feature Selection Methods", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous boost in the next generation sequencing and in the omics\ntechnologies makes it possible to characterize human gut microbiome (the\ncollective genomes of the microbial community that reside in our\ngastrointestinal tract). While some of these microorganisms are considered as\nessential regulators of our immune system, some others can cause several\ndiseases such as Inflammatory Bowel Diseases (IBD), diabetes, and cancer. IBD,\nis a gut related disorder where the deviations from the healthy gut microbiome\nare considered to be associated with IBD. Although existing studies attempt to\nunveal the composition of the gut microbiome in relation to IBD diseases, a\ncomprehensive picture is far from being complete. Due to the complexity of\nmetagenomic studies, the applications of the state of the art machine learning\ntechniques became popular to address a wide range of questions in the field of\nmetagenomic data analysis. In this regard, using IBD associated metagenomics\ndataset, this study utilizes both supervised and unsupervised machine learning\nalgorithms, i) to generate a classification model that aids IBD diagnosis, ii)\nto discover IBD associated biomarkers, iii) to find subgroups of IBD patients\nusing k means and hierarchical clustering. To deal with the high dimensionality\nof features, we applied robust feature selection algorithms such as Conditional\nMutual Information Maximization (CMIM), Fast Correlation Based Filter (FCBF),\nmin redundancy max relevance (mRMR) and Extreme Gradient Boosting (XGBoost). In\nour experiments with 10 fold cross validation, XGBoost had a considerable\neffect in terms of minimizing the microbiota used for the diagnosis of IBD and\nthus reducing the cost and time. We observed that compared to the single\nclassifiers, ensemble methods such as kNN and logitboost resulted in better\nperformance measures for the classification of IBD.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:17:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Hacilar", "Hilal", ""], ["Nalbantoglu", "O. Ufuk", ""], ["Aran", "Oya", ""], ["Bakir-Gungor", "Burcu", ""]]}, {"id": "2001.03025", "submitter": "Wenhao Zheng", "authors": "Shu-Ting Shi, Wenhao Zheng, Jun Tang, Qing-Guo Chen, Yao Hu, Jianke\n  Zhu, Ming Li", "title": "Deep Time-Stream Framework for Click-Through Rate Prediction by Tracking\n  Interest Evolution", "comments": "8 pages. arXiv admin note: text overlap with arXiv:1809.03672 by\n  other authors", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is an essential task in industrial\napplications such as video recommendation. Recently, deep learning models have\nbeen proposed to learn the representation of users' overall interests, while\nignoring the fact that interests may dynamically change over time. We argue\nthat it is necessary to consider the continuous-time information in CTR models\nto track user interest trend from rich historical behaviors. In this paper, we\npropose a novel Deep Time-Stream framework (DTS) which introduces the time\ninformation by an ordinary differential equations (ODE). DTS continuously\nmodels the evolution of interests using a neural network, and thus is able to\ntackle the challenge of dynamically representing users' interests based on\ntheir historical behaviors. In addition, our framework can be seamlessly\napplied to any existing deep CTR models by leveraging the additional\nTime-Stream Module, while no changes are made to the original CTR models.\nExperiments on public dataset as well as real industry dataset with billions of\nsamples demonstrate the effectiveness of proposed approaches, which achieve\nsuperior performance compared with existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:33:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Shi", "Shu-Ting", ""], ["Zheng", "Wenhao", ""], ["Tang", "Jun", ""], ["Chen", "Qing-Guo", ""], ["Hu", "Yao", ""], ["Zhu", "Jianke", ""], ["Li", "Ming", ""]]}, {"id": "2001.03040", "submitter": "Shijun Zhang", "authors": "Jianfeng Lu, Zuowei Shen, Haizhao Yang, Shijun Zhang", "title": "Deep Network Approximation for Smooth Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the optimal approximation error characterization of\ndeep ReLU networks for smooth functions in terms of both width and depth\nsimultaneously. To that end, we first prove that multivariate polynomials can\nbe approximated by deep ReLU networks of width $\\mathcal{O}(N)$ and depth\n$\\mathcal{O}(L)$ with an approximation error $\\mathcal{O}(N^{-L})$. Through\nlocal Taylor expansions and their deep ReLU network approximations, we show\nthat deep ReLU networks of width $\\mathcal{O}(N\\ln N)$ and depth\n$\\mathcal{O}(L\\ln L)$ can approximate $f\\in C^s([0,1]^d)$ with a nearly optimal\napproximation error $\\mathcal{O}(\\|f\\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our\nestimate is non-asymptotic in the sense that it is valid for arbitrary width\nand depth specified by $N\\in\\mathbb{N}^+$ and $L\\in\\mathbb{N}^+$, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:06:10 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 23:29:20 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 12:25:46 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 16:12:19 GMT"}, {"version": "v5", "created": "Thu, 24 Jun 2021 21:16:45 GMT"}, {"version": "v6", "created": "Wed, 21 Jul 2021 23:59:26 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lu", "Jianfeng", ""], ["Shen", "Zuowei", ""], ["Yang", "Haizhao", ""], ["Zhang", "Shijun", ""]]}, {"id": "2001.03048", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth, G\\\"unther Schindler, Matthias Z\\\"ohrer, Lukas\n  Pfeifenberger, Robert Peharz, Sebastian Tschiatschek, Holger Fr\\\"oning, Franz\n  Pernkopf, Zoubin Ghahramani", "title": "Resource-Efficient Neural Networks for Embedded Systems", "comments": "arXiv admin note: text overlap with arXiv:1812.02240", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning is traditionally a resource intensive task, embedded\nsystems, autonomous navigation, and the vision of the Internet of Things fuel\nthe interest in resource-efficient approaches. These approaches aim for a\ncarefully chosen trade-off between performance and resource consumption in\nterms of computation and energy. The development of such approaches is among\nthe major challenges in current machine learning research and key to ensure a\nsmooth transition of machine learning technology from a scientific environment\nwith virtually unlimited computing resources into every day's applications. In\nthis article, we provide an overview of the current state of the art of machine\nlearning techniques facilitating these real-world requirements. In particular,\nwe focus on deep neural networks (DNNs), the predominant machine learning\nmodels of the past decade. We give a comprehensive overview of the vast\nliterature that can be mainly split into three non-mutually exclusive\ncategories: (i) quantized neural networks, (ii) network pruning, and (iii)\nstructural efficiency. These techniques can be applied during training or as\npost-processing, and they are widely used to reduce the computational demands\nin terms of memory footprint, inference speed, and energy efficiency. We\nsubstantiate our discussion with experiments on well-known benchmark data sets\nto showcase the difficulty of finding good trade-offs between\nresource-efficiency and predictive performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 14:17:09 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Roth", "Wolfgang", ""], ["Schindler", "G\u00fcnther", ""], ["Z\u00f6hrer", "Matthias", ""], ["Pfeifenberger", "Lukas", ""], ["Peharz", "Robert", ""], ["Tschiatschek", "Sebastian", ""], ["Fr\u00f6ning", "Holger", ""], ["Pernkopf", "Franz", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2001.03076", "submitter": "Yilun Zhou", "authors": "Serena Booth, Ankit Shah, Yilun Zhou, Julie Shah", "title": "Sampling Prediction-Matching Examples in Neural Networks: A\n  Probabilistic Programming Approach", "comments": "AAAI 2020 Workshop on Statistical Relational AI (StarAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though neural network models demonstrate impressive performance, we do not\nunderstand exactly how these black-box models make individual predictions. This\ndrawback has led to substantial research devoted to understand these models in\nareas such as robustness, interpretability, and generalization ability. In this\npaper, we consider the problem of exploring the prediction level sets of a\nclassifier using probabilistic programming. We define a prediction level set to\nbe the set of examples for which the predictor has the same specified\nprediction confidence with respect to some arbitrary data distribution.\nNotably, our sampling-based method does not require the classifier to be\ndifferentiable, making it compatible with arbitrary classifiers. As a specific\ninstantiation, if we take the classifier to be a neural network and the data\ndistribution to be that of the training data, we can obtain examples that will\nresult in specified predictions by the neural network. We demonstrate this\ntechnique with experiments on a synthetic dataset and MNIST. Such level sets in\nclassification may facilitate human understanding of classification behaviors.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:57:51 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Booth", "Serena", ""], ["Shah", "Ankit", ""], ["Zhou", "Yilun", ""], ["Shah", "Julie", ""]]}, {"id": "2001.03103", "submitter": "Dongrui Wu", "authors": "Zhenhua Shi, Dongrui Wu, Jian Huang, Yu-Kai Wang, Chin-Teng Lin", "title": "Supervised Discriminative Sparse PCA with Adaptive Neighbors for\n  Dimensionality Reduction", "comments": "Int'l Joint Conf. on Neural Networks (IJCNN), Glasgow, UK, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is an important operation in information\nvisualization, feature extraction, clustering, regression, and classification,\nespecially for processing noisy high dimensional data. However, most existing\napproaches preserve either the global or the local structure of the data, but\nnot both. Approaches that preserve only the global data structure, such as\nprincipal component analysis (PCA), are usually sensitive to outliers.\nApproaches that preserve only the local data structure, such as locality\npreserving projections, are usually unsupervised (and hence cannot use label\ninformation) and uses a fixed similarity graph. We propose a novel linear\ndimensionality reduction approach, supervised discriminative sparse PCA with\nadaptive neighbors (SDSPCAAN), to integrate neighborhood-free supervised\ndiscriminative sparse PCA and projected clustering with adaptive neighbors. As\na result, both global and local data structures, as well as the label\ninformation, are used for better dimensionality reduction. Classification\nexperiments on nine high-dimensional datasets validated the effectiveness and\nrobustness of our proposed SDSPCAAN.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:02:26 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 15:38:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Shi", "Zhenhua", ""], ["Wu", "Dongrui", ""], ["Huang", "Jian", ""], ["Wang", "Yu-Kai", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2001.03115", "submitter": "Amelia Averitt", "authors": "Amelia J. Averitt, Natnicha Vanitchanant, Rajesh Ranganath, and Adler\n  J. Perotte", "title": "The Counterfactual $\\chi$-GAN", "comments": "9 pages; 3 figures; See peer-reviewed work at Journal of Biomedical\n  Informatics", "journal-ref": "JBI. 2020. PMID: 32771540", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference often relies on the counterfactual framework, which requires\nthat treatment assignment is independent of the outcome, known as strong\nignorability. Approaches to enforcing strong ignorability in causal analyses of\nobservational data include weighting and matching methods. Effect estimates,\nsuch as the average treatment effect (ATE), are then estimated as expectations\nunder the reweighted or matched distribution, P . The choice of P is important\nand can impact the interpretation of the effect estimate and the variance of\neffect estimates. In this work, instead of specifying P, we learn a\ndistribution that simultaneously maximizes coverage and minimizes variance of\nATE estimates. In order to learn this distribution, this research proposes a\ngenerative adversarial network (GAN)-based model called the Counterfactual\n$\\chi$-GAN (cGAN), which also learns feature-balancing weights and supports\nunbiased causal estimation in the absence of unobserved confounding. Our model\nminimizes the Pearson $\\chi^2$ divergence, which we show simultaneously\nmaximizes coverage and minimizes the variance of importance sampling estimates.\nTo our knowledge, this is the first such application of the Pearson $\\chi^2$\ndivergence. We demonstrate the effectiveness of cGAN in achieving feature\nbalance relative to established weighting methods in simulation and with\nreal-world medical data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:23:13 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 14:14:20 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Averitt", "Amelia J.", ""], ["Vanitchanant", "Natnicha", ""], ["Ranganath", "Rajesh", ""], ["Perotte", "Adler J.", ""]]}, {"id": "2001.03136", "submitter": "Romit Maulik", "authors": "Romit Maulik, Rajeev Surendran Array, Prasanna Balaprakash", "title": "Site-specific graph neural network for predicting protonation energy of\n  oxygenate molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-oil molecule assessment is essential for the sustainable development of\nchemicals and transportation fuels. These oxygenated molecules have adequate\ncarbon, hydrogen, and oxygen atoms that can be used for developing new\nvalue-added molecules (chemicals or transportation fuels). One motivation for\nour study stems from the fact that a liquid phase upgrading using mineral acid\nis a cost-effective chemical transformation. In this chemical upgrading\nprocess, adding a proton (positively charged atomic hydrogen) to an oxygen atom\nis a central step. The protonation energies of oxygen atoms in a molecule\ndetermine the thermodynamic feasibility of the reaction and likely chemical\nreaction pathway. A quantum chemical model based on coupled cluster theory is\nused to compute accurate thermochemical properties such as the protonation\nenergies of oxygen atoms and the feasibility of protonation-based chemical\ntransformations. However, this method is too computationally expensive to\nexplore a large space of chemical transformations. We develop a graph neural\nnetwork approach for predicting protonation energies of oxygen atoms of\nhundreds of bioxygenate molecules to predict the feasibility of aqueous acidic\nreactions. Our approach relies on an iterative local nonlinear embedding that\ngradually leads to global influence of distant atoms and a output layer that\npredicts the protonation energy. Our approach is geared to site-specific\npredictions for individual oxygen atoms of a molecule in comparison with\ncommonly used graph convolutional networks that focus on a singular molecular\nproperty prediction. We demonstrate that our approach is effective in learning\nthe location and magnitudes of protonation energies of oxygenated molecules.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:02:04 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Maulik", "Romit", ""], ["Array", "Rajeev Surendran", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2001.03224", "submitter": "Joseph Futoma", "authors": "Joseph Futoma, Muhammad A. Masood, Finale Doshi-Velez", "title": "Identifying Distinct, Effective Treatments for Acute Hypotension with\n  SODA-RL: Safely Optimized Diverse Accurate Reinforcement Learning", "comments": "Accepted for publication at the AMIA 2020 Informatics Summit. This\n  version contains an updated appendix with additional figures not found in the\n  page-constrained AMIA version, so treat this version as the most up-to-date", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypotension in critical care settings is a life-threatening emergency that\nmust be recognized and treated early. While fluid bolus therapy and\nvasopressors are common treatments, it is often unclear which interventions to\ngive, in what amounts, and for how long. Observational data in the form of\nelectronic health records can provide a source for helping inform these choices\nfrom past events, but often it is not possible to identify a single best\nstrategy from observational data alone. In such situations, we argue it is\nimportant to expose the collection of plausible options to a provider. To this\nend, we develop SODA-RL: Safely Optimized, Diverse, and Accurate Reinforcement\nLearning, to identify distinct treatment options that are supported in the\ndata. We demonstrate SODA-RL on a cohort of 10,142 ICU stays where hypotension\npresented. Our learned policies perform comparably to the observed physician\nbehaviors, while providing different, plausible alternatives for treatment\ndecisions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 21:10:43 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Futoma", "Joseph", ""], ["Masood", "Muhammad A.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2001.03229", "submitter": "Sen Lin", "authors": "Sen Lin, Guang Yang and Junshan Zhang", "title": "Real-Time Edge Intelligence in the Making: A Collaborative Learning\n  Framework via Federated Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT applications at the network edge demand intelligent decisions in a\nreal-time manner. The edge device alone, however, often cannot achieve\nreal-time edge intelligence due to its constrained computing resources and\nlimited local data. To tackle these challenges, we propose a platform-aided\ncollaborative learning framework where a model is first trained across a set of\nsource edge nodes by a federated meta-learning approach, and then it is rapidly\nadapted to learn a new task at the target edge node, using a few samples only.\nFurther, we investigate the convergence of the proposed federated meta-learning\nalgorithm under mild conditions on node similarity and the adaptation\nperformance at the target edge. To combat against the vulnerability of\nmeta-learning algorithms to possible adversarial attacks, we further propose a\nrobust version of the federated meta-learning algorithm based on\ndistributionally robust optimization, and establish its convergence under mild\nconditions. Experiments on different datasets demonstrate the effectiveness of\nthe proposed Federated Meta-Learning based framework.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 21:37:42 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 23:54:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lin", "Sen", ""], ["Yang", "Guang", ""], ["Zhang", "Junshan", ""]]}, {"id": "2001.03243", "submitter": "Alon Kipnis", "authors": "Alon Kipnis, Galen Reeves", "title": "Gaussian Approximation of Quantization Error for Estimation from\n  Compressed Data", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the distributional connection between the lossy compressed\nrepresentation of a high-dimensional signal $X$ using a random spherical code\nand the observation of $X$ under an additive white Gaussian noise (AWGN). We\nshow that the Wasserstein distance between a bitrate-$R$ compressed version of\n$X$ and its observation under an AWGN-channel of signal-to-noise ratio\n$2^{2R}-1$ is sub-linear in the problem dimension. We utilize this fact to\nconnect the risk of an estimator based on an AWGN-corrupted version of $X$ to\nthe risk attained by the same estimator when fed with its bitrate-$R$ quantized\nversion. We demonstrate the usefulness of this connection by deriving various\nnovel results for inference problems under compression constraints, including\nnoisy source coding and limited-bitrate parameter estimation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 22:10:10 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 00:15:45 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kipnis", "Alon", ""], ["Reeves", "Galen", ""]]}, {"id": "2001.03253", "submitter": "Ardavan Pedram", "authors": "Noah Gamboa, Kais Kudrolli, Anand Dhoot, Ardavan Pedram", "title": "Campfire: Compressible, Regularization-Free, Structured Sparse Training\n  for Hardware Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies structured sparse training of CNNs with a gradual pruning\ntechnique that leads to fixed, sparse weight matrices after a set number of\nepochs. We simplify the structure of the enforced sparsity so that it reduces\noverhead caused by regularization. The proposed training methodology Campfire\nexplores pruning at granularities within a convolutional kernel and filter.\n  We study various tradeoffs with respect to pruning duration, level of\nsparsity, and learning rate configuration. We show that our method creates a\nsparse version of ResNet-50 and ResNet-50 v1.5 on full ImageNet while remaining\nwithin a negligible <1% margin of accuracy loss. To ensure that this type of\nsparse training does not harm the robustness of the network, we also\ndemonstrate how the network behaves in the presence of adversarial attacks. Our\nresults show that with 70% target sparsity, over 75% top-1 accuracy is\nachievable.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:15:43 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 01:35:41 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gamboa", "Noah", ""], ["Kudrolli", "Kais", ""], ["Dhoot", "Anand", ""], ["Pedram", "Ardavan", ""]]}, {"id": "2001.03260", "submitter": "Hayda Almeida", "authors": "Hayda Almeida, Adrian Tsang, Abdoulaye Banir\\'e Diallo", "title": "Supporting supervised learning in fungal Biosynthetic Gene Cluster\n  discovery: new benchmark datasets", "comments": "Accepted to Machine Learning and Artificial Intelligence in\n  Bioinformatics and Medical Informatics (MABM2019) at IEEE BIBM 2019", "journal-ref": null, "doi": "10.1109/BIBM47256.2019.8983041", "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fungal Biosynthetic Gene Clusters (BGCs) of secondary metabolites are\nclusters of genes capable of producing natural products, compounds that play an\nimportant role in the production of a wide variety of bioactive compounds,\nincluding antibiotics and pharmaceuticals. Identifying BGCs can lead to the\ndiscovery of novel natural products to benefit human health. Previous work has\nbeen focused on developing automatic tools to support BGC discovery in plants,\nfungi, and bacteria. Data-driven methods, as well as probabilistic and\nsupervised learning methods have been explored in identifying BGCs. Most\nmethods applied to identify fungal BGCs were data-driven and presented limited\nscope. Supervised learning methods have been shown to perform well at\nidentifying BGCs in bacteria, and could be well suited to perform the same task\nin fungi. But labeled data instances are needed to perform supervised learning.\nOpenly accessible BGC databases contain only a very small portion of previously\ncurated fungal BGCs. Making new fungal BGC datasets available could motivate\nthe development of supervised learning methods for fungal BGCs and potentially\nimprove prediction performance compared to data-driven methods. In this work we\npropose new publicly available fungal BGC datasets to support the BGC discovery\ntask using supervised learning. These datasets are prepared to perform binary\nclassification and predict candidate BGC regions in fungal genomes. In addition\nwe analyse the performance of a well supported supervised learning tool\ndeveloped to predict BGCs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:47:12 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Almeida", "Hayda", ""], ["Tsang", "Adrian", ""], ["Diallo", "Abdoulaye Banir\u00e9", ""]]}, {"id": "2001.03286", "submitter": "Yujian Li", "authors": "Yujian Li, Bowen Liu, Zhaoying Liu, and Ting Zhang", "title": "Probabilistic K-means Clustering via Nonlinear Programming", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-means is a classical clustering algorithm with wide applications. However,\nsoft K-means, or fuzzy c-means at m=1, remains unsolved since 1981. To address\nthis challenging open problem, we propose a novel clustering model, i.e.\nProbabilistic K-Means (PKM), which is also a nonlinear programming model\nconstrained on linear equalities and linear inequalities. In theory, we can\nsolve the model by active gradient projection, while inefficiently. Thus, we\nfurther propose maximum-step active gradient projection and fast maximum-step\nactive gradient projection to solve it more efficiently. By experiments, we\nevaluate the performance of PKM and how well the proposed methods solve it in\nfive aspects: initialization robustness, clustering performance, descending\nstability, iteration number, and convergence speed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 02:40:41 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 00:59:26 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Li", "Yujian", ""], ["Liu", "Bowen", ""], ["Liu", "Zhaoying", ""], ["Zhang", "Ting", ""]]}, {"id": "2001.03305", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde, Pujan Kandel, Concetto Spampinato, Michael B. Wallace,\n  Ulas Bagci", "title": "Diagnosing Colorectal Polyps in the Wild with Capsule Networks", "comments": "Accepted for publication at ISBI 2020 (IEEE International Symposium\n  on Biomedical Imaging). Code is publicly available at\n  https://github.com/lalonderodney/D-Caps", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal cancer, largely arising from precursor lesions called polyps,\nremains one of the leading causes of cancer-related death worldwide. Current\nclinical standards require the resection and histopathological analysis of\npolyps due to test accuracy and sensitivity of optical biopsy methods falling\nsubstantially below recommended levels. In this study, we design a novel\ncapsule network architecture (D-Caps) to improve the viability of optical\nbiopsy of colorectal polyps. Our proposed method introduces several technical\nnovelties including a novel capsule architecture with a capsule-average pooling\n(CAP) method to improve efficiency in large-scale image classification. We\ndemonstrate improved results over the previous state-of-the-art convolutional\nneural network (CNN) approach by as much as 43%. This work provides an\nimportant benchmark on the new Mayo Polyp dataset, a significantly more\nchallenging and larger dataset than previous polyp studies, with results\nstratified across all available categories, imaging devices and modalities, and\nfocus modes to promote future direction into AI-driven colorectal cancer\nscreening systems. Code is publicly available at\nhttps://github.com/lalonderodney/D-Caps .\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 04:55:01 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["LaLonde", "Rodney", ""], ["Kandel", "Pujan", ""], ["Spampinato", "Concetto", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "2001.03311", "submitter": "Bang An", "authors": "Sicheng Zhu, Bang An, Shiyu Niu", "title": "Guess First to Enable Better Compression and Adversarial Robustness", "comments": "Accepted by NeurIPS 2019 workshop on Information Theory and Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are generally vulnerable to adversarial examples,\nwhich is in contrast to the robustness of humans. In this paper, we try to\nleverage one of the mechanisms in human recognition and propose a bio-inspired\nclassification framework in which model inference is conditioned on label\nhypothesis. We provide a class of training objectives for this framework and an\ninformation bottleneck regularizer which utilizes the advantage that label\ninformation can be discarded during inference. This framework enables better\ncompression of the mutual information between inputs and latent representations\nwithout loss of learning capacity, at the cost of tractable inference\ncomplexity. Better compression and elimination of label information further\nbring better adversarial robustness without loss of natural accuracy, which is\ndemonstrated in the experiment.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:12:22 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zhu", "Sicheng", ""], ["An", "Bang", ""], ["Niu", "Shiyu", ""]]}, {"id": "2001.03314", "submitter": "Van Mao Ngo", "authors": "Mao V. Ngo, Hakima Chaouchi, Tie Luo, Tony Q.S. Quek", "title": "Adaptive Anomaly Detection for IoT Data in Hierarchical Edge Computing", "comments": "To be published in the AAAI Workshop on Artificial Intelligence of\n  Things (AIoT), Feb 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNN) greatly bolster real-time detection of\nanomalous IoT data. However, IoT devices can barely afford complex DNN models\ndue to limited computational power and energy supply. While one can offload\nanomaly detection tasks to the cloud, it incurs long delay and requires large\nbandwidth when thousands of IoT devices stream data to the cloud concurrently.\nIn this paper, we propose an adaptive anomaly detection approach for\nhierarchical edge computing (HEC) systems to solve this problem. Specifically,\nwe first construct three anomaly detection DNN models of increasing complexity,\nand associate them with the three layers of HEC from bottom to top, i.e., IoT\ndevices, edge servers, and cloud. Then, we design an adaptive scheme to select\none of the models based on the contextual information extracted from input\ndata, to perform anomaly detection. The selection is formulated as a contextual\nbandit problem and is characterized by a single-step Markov decision process,\nwith an objective of achieving high detection accuracy and low detection delay\nsimultaneously. We evaluate our proposed approach using a real IoT dataset, and\ndemonstrate that it reduces detection delay by 84% while maintaining almost the\nsame accuracy as compared to offloading detection tasks to the cloud. In\naddition, our evaluation also shows that it outperforms other baseline schemes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:29:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ngo", "Mao V.", ""], ["Chaouchi", "Hakima", ""], ["Luo", "Tie", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2001.03316", "submitter": "Vatsal Shah", "authors": "Vatsal Shah, Xiaoxia Wu, Sujay Sanghavi", "title": "Choosing the Sample with Lowest Loss makes SGD Robust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of outliers can potentially significantly skew the parameters of\nmachine learning models trained via stochastic gradient descent (SGD). In this\npaper we propose a simple variant of the simple SGD method: in each step, first\nchoose a set of k samples, then from these choose the one with the smallest\ncurrent loss, and do an SGD-like update with this chosen sample. Vanilla SGD\ncorresponds to k = 1, i.e. no choice; k >= 2 represents a new algorithm that is\nhowever effectively minimizing a non-convex surrogate loss. Our main\ncontribution is a theoretical analysis of the robustness properties of this\nidea for ML problems which are sums of convex losses; these are backed up with\nlinear regression and small-scale neural network experiments\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:39:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shah", "Vatsal", ""], ["Wu", "Xiaoxia", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "2001.03340", "submitter": "Matthias Weissenbacher", "authors": "Matthias Weissenbacher", "title": "Temporally Folded Convolutional Neural Networks for Sequence Forecasting", "comments": "8 pages, 4 figures, submitted to IJCAI 2020 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel approach to utilize convolutional neural\nnetworks for time series forecasting. The time direction of the sequential data\nwith spatial dimensions $D=1,2$ is considered democratically as the input of a\nspatiotemporal $(D+1)$-dimensional convolutional neural network. Latter then\nreduces the data stream from $D +1 \\to D$ dimensions followed by an\nincriminator cell which uses this information to forecast the subsequent time\nstep. We empirically compare this strategy to convolutional LSTM's and LSTM's\non their performance on the sequential MNIST and the JSB chorals dataset,\nrespectively. We conclude that temporally folded convolutional neural networks\n(TFC's) may outperform the conventional recurrent strategies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 08:18:39 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Weissenbacher", "Matthias", ""]]}, {"id": "2001.03354", "submitter": "Haiping Huang", "authors": "Chan Li and Haiping Huang", "title": "Learning credit assignment", "comments": "5 pages, 4 figures, a generalized BackProp proposed to learn credit\n  assignment from an network ensemble perspective, to appear in Phys Rev Lett\n  (2020)", "journal-ref": "Phys. Rev. Lett. 125, 178301 (2020)", "doi": "10.1103/PhysRevLett.125.178301", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive prediction accuracies in a variety of\nscientific and industrial domains. However, the nested non-linear feature of\ndeep learning makes the learning highly non-transparent, i.e., it is still\nunknown how the learning coordinates a huge number of parameters to achieve a\ndecision making. To explain this hierarchical credit assignment, we propose a\nmean-field learning model by assuming that an ensemble of sub-networks, rather\nthan a single network, are trained for a classification task. Surprisingly, our\nmodel reveals that apart from some deterministic synaptic weights connecting\ntwo neurons at neighboring layers, there exist a large number of connections\nthat can be absent, and other connections can allow for a broad distribution of\ntheir weight values. Therefore, synaptic connections can be classified into\nthree categories: very important ones, unimportant ones, and those of\nvariability that may partially encode nuisance factors. Therefore, our model\nlearns the credit assignment leading to the decision, and predicts an ensemble\nof sub-networks that can accomplish the same task, thereby providing insights\ntoward understanding the macroscopic behavior of deep learning through the lens\nof distinct roles of synaptic weights.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 09:06:46 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 09:35:22 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Li", "Chan", ""], ["Huang", "Haiping", ""]]}, {"id": "2001.03369", "submitter": "Robin Brochier", "authors": "Robin Brochier, Adrien Guille and Julien Velcin", "title": "Inductive Document Network Embedding with Topic-Word Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document network embedding aims at learning representations for a structured\ntext corpus i.e. when documents are linked to each other. Recent algorithms\nextend network embedding approaches by incorporating the text content\nassociated with the nodes in their formulations. In most cases, it is hard to\ninterpret the learned representations. Moreover, little importance is given to\nthe generalization to new documents that are not observed within the network.\nIn this paper, we propose an interpretable and inductive document network\nembedding method. We introduce a novel mechanism, the Topic-Word Attention\n(TWA), that generates document representations based on the interplay between\nword and topic representations. We train these word and topic vectors through\nour general model, Inductive Document Network Embedding (IDNE), by leveraging\nthe connections in the document network. Quantitative evaluations show that our\napproach achieves state-of-the-art performance on various networks and we\nqualitatively show that our model produces meaningful and interpretable\nrepresentations of the words, topics and documents.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:14:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "2001.03371", "submitter": "Yuki Yoshida", "authors": "Yuki Yoshida, Masato Okada", "title": "Data-Dependence of Plateau Phenomenon in Learning with Neural Network\n  --- Statistical Mechanical Analysis", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": "10.1088/1742-5468/abc62f", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The plateau phenomenon, wherein the loss value stops decreasing during the\nprocess of learning, has been reported by various researchers. The phenomenon\nis actively inspected in the 1990s and found to be due to the fundamental\nhierarchical structure of neural network models. Then the phenomenon has been\nthought as inevitable. However, the phenomenon seldom occurs in the context of\nrecent deep learning. There is a gap between theory and reality. In this paper,\nusing statistical mechanical formulation, we clarified the relationship between\nthe plateau phenomenon and the statistical property of the data learned. It is\nshown that the data whose covariance has small and dispersed eigenvalues tend\nto make the plateau phenomenon inconspicuous.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:17:08 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yoshida", "Yuki", ""], ["Okada", "Masato", ""]]}, {"id": "2001.03376", "submitter": "Gon\\c{c}alo Mordido", "authors": "Gon\\c{c}alo Mordido, Haojin Yang, Christoph Meinel", "title": "microbatchGAN: Stimulating Diversity with Multi-Adversarial\n  Discrimination", "comments": "WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to tackle the mode collapse problem in generative adversarial\nnetworks (GANs) by using multiple discriminators and assigning a different\nportion of each minibatch, called microbatch, to each discriminator. We\ngradually change each discriminator's task from distinguishing between real and\nfake samples to discriminating samples coming from inside or outside its\nassigned microbatch by using a diversity parameter $\\alpha$. The generator is\nthen forced to promote variety in each minibatch to make the microbatch\ndiscrimination harder to achieve by each discriminator. Thus, all models in our\nframework benefit from having variety in the generated set to reduce their\nrespective losses. We show evidence that our solution promotes sample diversity\nsince early training stages on multiple datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:31:27 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Mordido", "Gon\u00e7alo", ""], ["Yang", "Haojin", ""], ["Meinel", "Christoph", ""]]}, {"id": "2001.03386", "submitter": "Sahil Manchanda", "authors": "Sahil Manchanda, Arun Rajkumar, Simarjot Kaur, Narayanan Unny", "title": "SUPAID: A Rule mining based method for automatic rollout decision aid\n  for supervisors in fleet management systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision to rollout a vehicle is critical to fleet management companies\nas wrong decisions can lead to additional cost of maintenance and failures\nduring journey. With the availability of large amount of data and advancement\nof machine learning techniques, the rollout decisions of a supervisor can be\neffectively automated and the mistakes in decisions made by the supervisor\nlearnt. In this paper, we propose a novel learning algorithm SUPAID which under\na natural 'one-way efficiency' assumption on the supervisor, uses a rule mining\napproach to rank the vehicles based on their roll-out feasibility thus helping\nprevent the supervisor from makingerroneous decisions. Our experimental results\non real data from a public transit agency from a city in U.S show that the\nproposed method SUPAID can result in significant cost savings.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 11:06:04 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 05:34:11 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Manchanda", "Sahil", ""], ["Rajkumar", "Arun", ""], ["Kaur", "Simarjot", ""], ["Unny", "Narayanan", ""]]}, {"id": "2001.03436", "submitter": "Marcel Hildebrandt", "authors": "Marcel Hildebrandt, Jorge Andres Quintero Serna, Yunpu Ma, Martin\n  Ringsquandl, Mitchell Joblin, Volker Tresp", "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "comments": "AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text\n  overlap with arXiv:2001.00461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:19:45 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hildebrandt", "Marcel", ""], ["Serna", "Jorge Andres Quintero", ""], ["Ma", "Yunpu", ""], ["Ringsquandl", "Martin", ""], ["Joblin", "Mitchell", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.03447", "submitter": "Damien Garreau", "authors": "Damien Garreau, Ulrike von Luxburg", "title": "Explaining the Explainer: A First Theoretical Analysis of LIME", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used more and more often for sensitive applications,\nsometimes replacing humans in critical decision-making processes. As such,\ninterpretability of these algorithms is a pressing need. One popular algorithm\nto provide interpretability is LIME (Local Interpretable Model-Agnostic\nExplanation). In this paper, we provide the first theoretical analysis of LIME.\nWe derive closed-form expressions for the coefficients of the interpretable\nmodel when the function to explain is linear. The good news is that these\ncoefficients are proportional to the gradient of the function to explain: LIME\nindeed discovers meaningful features. However, our analysis also reveals that\npoor choices of parameters can lead LIME to miss important features.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 13:51:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 13:09:25 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Garreau", "Damien", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "2001.03452", "submitter": "Swagatam Das", "authors": "Saptarshi Chakraborty, Debolina Paul, Swagatam Das, Jason Xu", "title": "Entropy Regularized Power k-Means Clustering", "comments": "Accepted (in updated form) for presentation in the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS 2020), Palermo,\n  Italy, June 03, 2020 - June 05, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its well-known shortcomings, $k$-means remains one of the most widely\nused approaches to data clustering. Current research continues to tackle its\nflaws while attempting to preserve its simplicity. Recently, the \\textit{power\n$k$-means} algorithm was proposed to avoid trapping in local minima by\nannealing through a family of smoother surfaces. However, the approach lacks\ntheoretical justification and fails in high dimensions when many features are\nirrelevant. This paper addresses these issues by introducing \\textit{entropy\nregularization} to learn feature relevance while annealing. We prove\nconsistency of the proposed approach and derive a scalable\nmajorization-minimization algorithm that enjoys closed-form updates and\nconvergence guarantees. In particular, our method retains the same\ncomputational complexity of $k$-means and power $k$-means, but yields\nsignificant improvements over both. Its merits are thoroughly assessed on a\nsuite of real and synthetic data experiments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 14:05:44 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Chakraborty", "Saptarshi", ""], ["Paul", "Debolina", ""], ["Das", "Swagatam", ""], ["Xu", "Jason", ""]]}, {"id": "2001.03458", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li and Jelena Bradic", "title": "Censored Quantile Regression Forest", "comments": "arXiv admin note: text overlap with arXiv:1902.03327", "journal-ref": "International Conference on ArtificialIntelligence and Statistics\n  (AISTATS) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are powerful non-parametric regression method but are severely\nlimited in their usage in the presence of randomly censored observations, and\nnaively applied can exhibit poor predictive performance due to the incurred\nbiases. Based on a local adaptive representation of random forests, we develop\nits regression adjustment for randomly censored regression quantile models.\nRegression adjustment is based on a new estimating equation that adapts to\ncensoring and leads to quantile score whenever the data do not exhibit\ncensoring. The proposed procedure named {\\it censored quantile regression\nforest}, allows us to estimate quantiles of time-to-event without any\nparametric modeling assumption. We establish its consistency under mild model\nspecifications. Numerical studies showcase a clear advantage of the proposed\nprocedure.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 23:20:23 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Bradic", "Jelena", ""]]}, {"id": "2001.03464", "submitter": "Netanel Raviv", "authors": "Netanel Raviv, Siddharth Jain, Jehoshua Bruck", "title": "What is the Value of Data? On Mathematical Methods for Data Quality\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is one of the most important assets of the information age, and its\nsocietal impact is undisputed. Yet, rigorous methods of assessing the quality\nof data are lacking. In this paper, we propose a formal definition for the\nquality of a given dataset. We assess a dataset's quality by a quantity we call\nthe expected diameter, which measures the expected disagreement between two\nrandomly chosen hypotheses that explain it, and has recently found applications\nin active learning. We focus on Boolean hyperplanes, and utilize a collection\nof Fourier analytic, algebraic, and probabilistic methods to come up with\ntheoretical guarantees and practical solutions for the computation of the\nexpected diameter. We also study the behaviour of the expected diameter on\nalgebraically structured datasets, conduct experiments that validate this\nnotion of quality, and demonstrate the feasibility of our techniques.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 18:56:48 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:53:08 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Raviv", "Netanel", ""], ["Jain", "Siddharth", ""], ["Bruck", "Jehoshua", ""]]}, {"id": "2001.03507", "submitter": "Stamatis Tsianikas", "authors": "S. Tsianikas, N. Yousefi, J. Zhou, M. Rodgers, D. W. Coit", "title": "A storage expansion planning framework using reinforcement learning and\n  simulation-based optimization", "comments": null, "journal-ref": "Applied Energy; Volume 290; 2021; Pages 116778;", "doi": "10.1016/j.apenergy.2021.116778", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of the highly electrified future ahead of us, the role of energy\nstorage is crucial wherever distributed generation is abundant, such as in\nmicrogrid settings. Given the variety of storage options that are becoming more\nand more economical, determining which type of storage technology to invest in,\nalong with the appropriate timing and capacity becomes a critical research\nquestion. It is inevitable that these problems will continue to become\nincreasingly relevant in the future and require strategic planning and holistic\nand modern frameworks in order to be solved. Reinforcement Learning algorithms\nhave already proven to be successful in problems where sequential\ndecision-making is inherent. In the operations planning area, these algorithms\nare already used but mostly in short-term problems with well-defined\nconstraints. On the contrary, we expand and tailor these techniques to\nlong-term planning by utilizing model-free algorithms combined with\nsimulation-based models. A model and expansion plan have been developed to\noptimally determine microgrid designs as they evolve to dynamically react to\nchanging conditions and to exploit energy storage capabilities. We show that it\nis possible to derive better engineering solutions that would point to the\ntypes of energy storage units which could be at the core of future microgrid\napplications. Another key finding is that the optimal storage capacity\nthreshold for a system depends heavily on the price movements of the available\nstorage units. By utilizing the proposed approaches, it is possible to model\ninherent problem uncertainties and optimize the whole streamline of sequential\ninvestment decision-making.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:23:30 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 23:09:51 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 18:04:14 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Tsianikas", "S.", ""], ["Yousefi", "N.", ""], ["Zhou", "J.", ""], ["Rodgers", "M.", ""], ["Coit", "D. W.", ""]]}, {"id": "2001.03517", "submitter": "Jeppe Johan Waarkj{\\ae}r Olsen", "authors": "Jeppe Johan Waarkj{\\ae}r Olsen, Peter Ebert Christensen, Martin\n  Hangaard Hansen, and Alexander Rosenberg Johansen", "title": "Autoencoding Undirected Molecular Graphs With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete structure rules for validating molecular structures are usually\nlimited to fulfillment of the octet rule or similar simple deterministic\nheuristics. We propose a model, inspired by language modeling from natural\nlanguage processing, with the ability to learn from a collection of undirected\nmolecular graphs, enabling fitting of any underlying structure rule present in\nthe collection. We introduce an adaption to the popular Transformer model,\nwhich can learn relationships between atoms and bonds. To our knowledge, the\nTransformer adaption is the first model that is trained to solve the\nunsupervised task of recovering partially observed molecules. In this work, we\nassess how different degrees of information impact performance w.r.t. to\nfitting the QM9 dataset, which conforms to the octet rule, and to fitting the\nZINC dataset, which contains hypervalent molecules and ions requiring the model\nto learn a more complex structure rule. More specifically, we test a full\ndiscrete graph with bond order information, a full discrete graph with only\nconnectivity, a bag-of-neighbors, a bag-of-atoms, and a count-based unigram\nstatistics. These results provide encouraging evidence that neural networks,\neven when only connectivity is available, can learn arbitrary molecular\nstructure rules specific to a dataset, as the Transformer adaption surpasses a\nstrong octet rule baseline on the ZINC dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:35:33 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 17:14:48 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Olsen", "Jeppe Johan Waarkj\u00e6r", ""], ["Christensen", "Peter Ebert", ""], ["Hansen", "Martin Hangaard", ""], ["Johansen", "Alexander Rosenberg", ""]]}, {"id": "2001.03520", "submitter": "Rick Mukherjee", "authors": "Rick Mukherjee, Frederic Sauvage, Harry Xie, Robert L\\\"ow and Florian\n  Mintert", "title": "Preparation of ordered states in ultra-cold gases using Bayesian\n  optimization", "comments": "29 pages, 10 figures", "journal-ref": "New Journal of Physics 22, 075001 (2020)", "doi": "10.1088/1367-2630/ab8677", "report-no": null, "categories": "quant-ph physics.atom-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-cold atomic gases are unique in terms of the degree of controllability,\nboth for internal and external degrees of freedom. This makes it possible to\nuse them for the study of complex quantum many-body phenomena. However in many\nscenarios, the prerequisite condition of faithfully preparing a desired quantum\nstate despite decoherence and system imperfections is not always adequately\nmet. To path the way to a specific target state, we explore quantum optimal\ncontrol framework based on Bayesian optimization. The probabilistic modeling\nand broad exploration aspects of Bayesian optimization is particularly suitable\nfor quantum experiments where data acquisition can be expensive. Using\nnumerical simulations for the superfluid to Mott-insulator transition for\nbosons in a lattice as well for the formation of Rydberg crystals as explicit\nexamples, we demonstrate that Bayesian optimization is capable of finding\nbetter control solutions with regards to finite and noisy data compared to\nexisting methods of optimal control.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:43:55 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 14:46:05 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 06:56:00 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mukherjee", "Rick", ""], ["Sauvage", "Frederic", ""], ["Xie", "Harry", ""], ["L\u00f6w", "Robert", ""], ["Mintert", "Florian", ""]]}, {"id": "2001.03538", "submitter": "Ricard Delgado-Gonzalo", "authors": "Antonino Faraone, Ricard Delgado-Gonzalo", "title": "Convolutional-Recurrent Neural Networks on Low-Power Wearable Platforms\n  for Cardiac Arrhythmia Detection", "comments": "Accepted for presentation in the 2nd IEEE International Conference on\n  Artificial Intelligence Circuits and Systems (AICAS2020)", "journal-ref": null, "doi": "10.1109/AICAS48895.2020.9073950", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-power sensing technologies, such as wearables, have emerged in the\nhealthcare domain since they enable continuous and non-invasive monitoring of\nphysiological signals. In order to endow such devices with clinical value,\nclassical signal processing has encountered numerous challenges. However,\ndata-driven methods, such as machine learning, offer attractive accuracies at\nthe expense of being resource and memory demanding. In this paper, we focus on\nthe inference of neural networks running in microcontrollers and low-power\nprocessors which wearable sensors and devices are generally equipped with. In\nparticular, we adapted an existing convolutional-recurrent neural network,\ndesigned to detect and classify cardiac arrhythmias from a single-lead\nelectrocardiogram, to the low-power embedded System-on-Chip nRF52 from Nordic\nSemiconductor with an ARM's Cortex-M4 processing core. We show our\nimplementation in fixed-point precision, using the CMSIS-NN libraries, yields a\ndrop of $F_1$ score from 0.8 to 0.784, from the original implementation, with a\nmemory footprint of 195.6KB, and a throughput of 33.98MOps/s.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:35:48 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Faraone", "Antonino", ""], ["Delgado-Gonzalo", "Ricard", ""]]}, {"id": "2001.03560", "submitter": "Justin Kinney", "authors": "Ammar Tareen, Justin B. Kinney", "title": "Biophysical models of cis-regulation as interpretable neural networks", "comments": "Presented at the 14th conference on Machine Learning in Computational\n  Biology (MLCB 2019), Vancouver, Canada. Revised to add a link to code and to\n  correct a typo in the King-Altman diagrams shown in Figure 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG physics.bio-ph q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The adoption of deep learning techniques in genomics has been hindered by the\ndifficulty of mechanistically interpreting the models that these techniques\nproduce. In recent years, a variety of post-hoc attribution methods have been\nproposed for addressing this neural network interpretability problem in the\ncontext of gene regulation. Here we describe a complementary way of approaching\nthis problem. Our strategy is based on the observation that two large classes\nof biophysical models of cis-regulatory mechanisms can be expressed as deep\nneural networks in which nodes and weights have explicit physiochemical\ninterpretations. We also demonstrate how such biophysical networks can be\nrapidly inferred, using modern deep learning frameworks, from the data produced\nby certain types of massively parallel reporter assays (MPRAs). These results\nsuggest a scalable strategy for using MPRAs to systematically characterize the\nbiophysical basis of gene regulation in a wide range of biological contexts.\nThey also highlight gene regulation as a promising venue for the development of\nscientifically interpretable approaches to deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:45:58 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 22:07:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tareen", "Ammar", ""], ["Kinney", "Justin B.", ""]]}, {"id": "2001.03653", "submitter": "Ishaan Gulrajani", "authors": "Ishaan Gulrajani, Colin Raffel, Luke Metz", "title": "Towards GAN Benchmarks Which Require Generalization", "comments": "ICLR 2019 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many evaluation metrics commonly used as benchmarks for unconditional\nimage generation, trivially memorizing the training set attains a better score\nthan models which are considered state-of-the-art; we consider this\nproblematic. We clarify a necessary condition for an evaluation metric not to\nbehave this way: estimating the function must require a large sample from the\nmodel. In search of such a metric, we turn to neural network divergences\n(NNDs), which are defined in terms of a neural network trained to distinguish\nbetween distributions. The resulting benchmarks cannot be \"won\" by training set\nmemorization, while still being perceptually correlated and computable only\nfrom samples. We survey past work on using NNDs for evaluation and implement an\nexample black-box metric based on these ideas. Through experimental validation\nwe show that it can effectively measure diversity, sample quality, and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:18:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gulrajani", "Ishaan", ""], ["Raffel", "Colin", ""], ["Metz", "Luke", ""]]}, {"id": "2001.03662", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Jingbo Wang, Chao Wang", "title": "ReluDiff: Differential Verification of Deep Neural Networks", "comments": "Extended version of ICSE 2020 paper. This version includes an\n  appendix with proofs for some of the content in section 4.3", "journal-ref": null, "doi": "10.1145/3377811.3380337", "report-no": null, "categories": "cs.LG cs.LO cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks are increasingly being deployed in practice, their\nefficiency has become an important issue. While there are compression\ntechniques for reducing the network's size, energy consumption and\ncomputational requirement, they only demonstrate empirically that there is no\nloss of accuracy, but lack formal guarantees of the compressed network, e.g.,\nin the presence of adversarial examples. Existing verification techniques such\nas Reluplex, ReluVal, and DeepPoly provide formal guarantees, but they are\ndesigned for analyzing a single network instead of the relationship between two\nnetworks. To fill the gap, we develop a new method for differential\nverification of two closely related networks. Our method consists of a fast but\napproximate forward interval analysis pass followed by a backward pass that\niteratively refines the approximation until the desired property is verified.\nWe have two main innovations. During the forward pass, we exploit structural\nand behavioral similarities of the two networks to more accurately bound the\ndifference between the output neurons of the two networks. Then in the backward\npass, we leverage the gradient differences to more accurately compute the most\nbeneficial refinement. Our experiments show that, compared to state-of-the-art\nverification tools, our method can achieve orders-of-magnitude speedup and\nprove many more properties than existing tools.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:47:22 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:29:59 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Paulsen", "Brandon", ""], ["Wang", "Jingbo", ""], ["Wang", "Chao", ""]]}, {"id": "2001.03674", "submitter": "Manpreet Singh Minhas", "authors": "Manpreet Singh Minhas, John Zelek", "title": "Semi-supervised Anomaly Detection using AutoEncoders", "comments": null, "journal-ref": "JCVIS, vol. 5, no. 1, p. 3, Jan. 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection refers to the task of finding unusual instances that stand\nout from the normal data. In several applications, these outliers or anomalous\ninstances are of greater interest compared to the normal ones. Specifically in\nthe case of industrial optical inspection and infrastructure asset management,\nfinding these defects (anomalous regions) is of extreme importance.\nTraditionally and even today this process has been carried out manually. Humans\nrely on the saliency of the defects in comparison to the normal texture to\ndetect the defects. However, manual inspection is slow, tedious, subjective and\nsusceptible to human biases. Therefore, the automation of defect detection is\ndesirable. But for defect detection lack of availability of a large number of\nanomalous instances and labelled data is a problem. In this paper, we present a\nconvolutional auto-encoder architecture for anomaly detection that is trained\nonly on the defect-free (normal) instances. For the test images, residual masks\nthat are obtained by subtracting the original image from the auto-encoder\noutput are thresholded to obtain the defect segmentation masks. The approach\nwas tested on two data-sets and achieved an impressive average F1 score of\n0.885. The network learnt to detect the actual shape of the defects even though\nno defected images were used during the training.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 23:06:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Minhas", "Manpreet Singh", ""], ["Zelek", "John", ""]]}, {"id": "2001.03690", "submitter": "Jong Chul Ye", "authors": "Byung-Hoon Kim and Jong Chul Ye", "title": "Understanding Graph Isomorphism Network for rs-fMRI Functional\n  Connectivity Analysis", "comments": "This paper is accepted for Frontiers in Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) rely on graph operations that include neural\nnetwork training for various graph related tasks. Recently, several attempts\nhave been made to apply the GNNs to functional magnetic resonance image (fMRI)\ndata. Despite recent progresses, a common limitation is its difficulty to\nexplain the classification results in a neuroscientifically explainable way.\nHere, we develop a framework for analyzing the fMRI data using the Graph\nIsomorphism Network (GIN), which was recently proposed as a powerful GNN for\ngraph classification. One of the important contributions of this paper is the\nobservation that the GIN is a dual representation of convolutional neural\nnetwork (CNN) in the graph space where the shift operation is defined using the\nadjacency matrix. This understanding enables us to exploit CNN-based saliency\nmap techniques for the GNN, which we tailor to the proposed GIN with one-hot\nencoding, to visualize the important regions of the brain. We validate our\nproposed framework using large-scale resting-state fMRI (rs-fMRI) data for\nclassifying the sex of the subject based on the graph structure of the brain.\nThe experiment was consistent with our expectation such that the obtained\nsaliency map show high correspondence with previous neuroimaging evidences\nrelated to sex differences.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 23:40:09 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 02:53:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kim", "Byung-Hoon", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2001.03724", "submitter": "Luo Luo", "authors": "Luo Luo, Haishan Ye, Zhichao Huang, Tong Zhang", "title": "Stochastic Recursive Gradient Descent Ascent for Stochastic\n  Nonconvex-Strongly-Concave Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider nonconvex-concave minimax optimization problems of the form\n$\\min_{\\bf x}\\max_{\\bf y\\in{\\mathcal Y}} f({\\bf x},{\\bf y})$, where $f$ is\nstrongly-concave in $\\bf y$ but possibly nonconvex in $\\bf x$ and ${\\mathcal\nY}$ is a convex and compact set. We focus on the stochastic setting, where we\ncan only access an unbiased stochastic gradient estimate of $f$ at each\niteration. This formulation includes many machine learning applications as\nspecial cases such as robust optimization and adversary training. We are\ninterested in finding an ${\\mathcal O}(\\varepsilon)$-stationary point of the\nfunction $\\Phi(\\cdot)=\\max_{\\bf y\\in{\\mathcal Y}} f(\\cdot, {\\bf y})$. The most\npopular algorithm to solve this problem is stochastic gradient decent ascent,\nwhich requires $\\mathcal O(\\kappa^3\\varepsilon^{-4})$ stochastic gradient\nevaluations, where $\\kappa$ is the condition number. In this paper, we propose\na novel method called Stochastic Recursive gradiEnt Descent Ascent (SREDA),\nwhich estimates gradients more efficiently using variance reduction. This\nmethod achieves the best known stochastic gradient complexity of ${\\mathcal\nO}(\\kappa^3\\varepsilon^{-3})$, and its dependency on $\\varepsilon$ is optimal\nfor this problem.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 09:05:03 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 09:37:38 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Luo", "Luo", ""], ["Ye", "Haishan", ""], ["Huang", "Zhichao", ""], ["Zhang", "Tong", ""]]}, {"id": "2001.03750", "submitter": "Pengzhan Jin", "authors": "Pengzhan Jin, Zhen Zhang, Aiqing Zhu, Yifa Tang and George Em\n  Karniadakis", "title": "SympNets: Intrinsic structure-preserving symplectic networks for\n  identifying Hamiltonian systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new symplectic networks (SympNets) for identifying Hamiltonian\nsystems from data based on a composition of linear, activation and gradient\nmodules. In particular, we define two classes of SympNets: the LA-SympNets\ncomposed of linear and activation modules, and the G-SympNets composed of\ngradient modules. Correspondingly, we prove two new universal approximation\ntheorems that demonstrate that SympNets can approximate arbitrary symplectic\nmaps based on appropriate activation functions. We then perform several\nexperiments including the pendulum, double pendulum and three-body problems to\ninvestigate the expressivity and the generalization ability of SympNets. The\nsimulation results show that even very small size SympNets can generalize well,\nand are able to handle both separable and non-separable Hamiltonian systems\nwith data points resulting from short or long time steps. In all the test\ncases, SympNets outperform the baseline models, and are much faster in training\nand prediction. We also develop an extended version of SympNets to learn the\ndynamics from irregularly sampled data. This extended version of SympNets can\nbe thought of as a universal model representing the solution to an arbitrary\nHamiltonian system.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 13:04:34 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 15:37:10 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 06:14:49 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Jin", "Pengzhan", ""], ["Zhang", "Zhen", ""], ["Zhu", "Aiqing", ""], ["Tang", "Yifa", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2001.03772", "submitter": "Antonin Berthon", "authors": "Antonin Berthon and Bo Han and Gang Niu and Tongliang Liu and Masashi\n  Sugiyama", "title": "Confidence Scores Make Instance-dependent Label-noise Learning Possible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning with noisy labels, for every instance, its label can randomly\nwalk to other classes following a transition distribution which is named a\nnoise model. Well-studied noise models are all instance-independent, namely,\nthe transition depends only on the original label but not the instance itself,\nand thus they are less practical in the wild. Fortunately, methods based on\ninstance-dependent noise have been studied, but most of them have to rely on\nstrong assumptions on the noise models. To alleviate this issue, we introduce\nconfidence-scored instance-dependent noise (CSIDN), where each instance-label\npair is equipped with a confidence score. We find with the help of confidence\nscores, the transition distribution of each instance can be approximately\nestimated. Similarly to the powerful forward correction for\ninstance-independent noise, we propose a novel instance-level forward\ncorrection for CSIDN. We demonstrate the utility and effectiveness of our\nmethod through multiple experiments under synthetic label noise and real-world\nunknown noise.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 16:15:41 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 23:40:07 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Berthon", "Antonin", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Liu", "Tongliang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2001.03780", "submitter": "Tailin Wu", "authors": "Tailin Wu", "title": "Intelligence, physics and information -- the tradeoff between accuracy\n  and simplicity in machine learning", "comments": "PhD Thesis, 352 pages. Reference improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we enable machines to make sense of the world, and become better at\nlearning? To approach this goal, I believe viewing intelligence in terms of\nmany integral aspects, and also a universal two-term tradeoff between task\nperformance and complexity, provides two feasible perspectives. In this thesis,\nI address several key questions in some aspects of intelligence, and study the\nphase transitions in the two-term tradeoff, using strategies and tools from\nphysics and information. Firstly, how can we make the learning models more\nflexible and efficient, so that agents can learn quickly with fewer examples?\nInspired by how physicists model the world, we introduce a paradigm and an AI\nPhysicist agent for simultaneously learning many small specialized models\n(theories) and the domain they are accurate, which can then be simplified,\nunified and stored, facilitating few-shot learning in a continual way.\nSecondly, for representation learning, when can we learn a good representation,\nand how does learning depend on the structure of the dataset? We approach this\nquestion by studying phase transitions when tuning the tradeoff hyperparameter.\nIn the information bottleneck, we theoretically show that these phase\ntransitions are predictable and reveal structure in the relationships between\nthe data, the model, the learned representation and the loss landscape.\nThirdly, how can agents discover causality from observations? We address part\nof this question by introducing an algorithm that combines prediction and\nminimizing information from the input, for exploratory causal discovery from\nobservational time series. Fourthly, to make models more robust to label noise,\nwe introduce Rank Pruning, a robust algorithm for classification with noisy\nlabels. I believe that building on the work of my thesis we will be one step\ncloser to enable more intelligent machines that can make sense of the world.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 18:34:29 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 17:51:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Tailin", ""]]}, {"id": "2001.03798", "submitter": "Rui Zhu", "authors": "Rui Zhu, Subhashis Ghosal", "title": "Bayesian Semi-supervised learning under nonparanormality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is a classification method which makes use of both\nlabeled data and unlabeled data for training. In this paper, we propose a\nsemi-supervised learning algorithm using a Bayesian semi-supervised model. We\nmake a general assumption that the observations will follow two multivariate\nnormal distributions depending on their true labels after the same unknown\ntransformation. We use B-splines to put a prior on the transformation function\nfor each component. To use unlabeled data in a semi-supervised setting, we\nassume the labels are missing at random. The posterior distributions can then\nbe described using our assumptions, which we compute by the Gibbs sampling\ntechnique. The proposed method is then compared with several other available\nmethods through an extensive simulation study. Finally we apply the proposed\nmethod in real data contexts for diagnosing breast cancer and classify radar\nreturns. We conclude that the proposed method has better prediction accuracy in\na wide variety of cases.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 21:31:25 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhu", "Rui", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "2001.03813", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Fundamental Limits of Prediction, Generalization, and Recursion: An\n  Entropic-Innovations Perspective", "comments": "Note that this is an extended version of the original submission\n  \"Fundamental Limits of Online Learning: An Entropic-Innovations Viewpoint\";\n  arXiv admin note: text overlap with arXiv:1912.05541, arXiv:1912.02628", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the fundamental performance limits of prediction,\nwith or without side information. More specifically, we derive generic lower\nbounds on the $\\mathcal{L}_p$ norms of the prediction errors that are valid for\nany prediction algorithms and for any data distributions. Meanwhile, we combine\nthe entropic analysis from information theory and the innovations approach from\nprediction/estimation theory to characterize the conditions (in terms of, e.g.,\ndirected information or mutual information) to achieve the bounds. We also\ninvestigate the implications of the results in analyzing the fundamental limits\nof generalization in fitting (learning) problems from the perspective of\nprediction with side information, as well as the fundamental limits of\nrecursive algorithms by viewing them as generalized prediction problems.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 00:20:00 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 20:18:27 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 18:43:15 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 22:25:52 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2001.03877", "submitter": "Binyamin Manela", "authors": "Binyamin Manela", "title": "Deep Reinforcement Learning for Complex Manipulation Tasks with Sparse\n  Feedback", "comments": "A thesis submitted in fulfillment of the requirements for the degree\n  of Master of Science in the department of Industrial Engineering and\n  Management at Ben-Gurion University of the Negev", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal policies from sparse feedback is a known challenge in\nreinforcement learning. Hindsight Experience Replay (HER) is a multi-goal\nreinforcement learning algorithm that comes to solve such tasks. The algorithm\ntreats every failure as a success for an alternative (virtual) goal that has\nbeen achieved in the episode and then generalizes from that virtual goal to\nreal goals. HER has known flaws and is limited to relatively simple tasks. In\nthis thesis, we present three algorithms based on the existing HER algorithm\nthat improves its performances. First, we prioritize virtual goals from which\nthe agent will learn more valuable information. We call this property the\n\\textit{instructiveness} of the virtual goal and define it by a heuristic\nmeasure, which expresses how well the agent will be able to generalize from\nthat virtual goal to actual goals. Secondly, we designed a filtering process\nthat detects and removes misleading samples that may induce bias throughout the\nlearning process. Lastly, we enable the learning of complex, sequential, tasks\nusing a form of curriculum learning combined with HER. We call this algorithm\n\\textit{Curriculum HER}. To test our algorithms, we built three challenging\nmanipulation environments with sparse reward functions. Each environment has\nthree levels of complexity. Our empirical results show vast improvement in the\nfinal success rate and sample efficiency when compared to the original HER\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 07:22:15 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Manela", "Binyamin", ""]]}, {"id": "2001.03898", "submitter": "Yao Zhang", "authors": "Yao Zhang, Daniel Jarrett, Mihaela van der Schaar", "title": "Stepwise Model Selection for Sequence Prediction via Deep Kernel\n  Learning", "comments": null, "journal-ref": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential problem in automated machine learning (AutoML) is that of model\nselection. A unique challenge in the sequential setting is the fact that the\noptimal model itself may vary over time, depending on the distribution of\nfeatures and labels available up to each point in time. In this paper, we\npropose a novel Bayesian optimization (BO) algorithm to tackle the challenge of\nmodel selection in this setting. This is accomplished by treating the\nperformance at each time step as its own black-box function. In order to solve\nthe resulting multiple black-box function optimization problem jointly and\nefficiently, we exploit potential correlations among black-box functions using\ndeep kernel learning (DKL). To the best of our knowledge, we are the first to\nformulate the problem of stepwise model selection (SMS) for sequence\nprediction, and to design and demonstrate an efficient joint-learning algorithm\nfor this purpose. Using multiple real-world datasets, we verify that our\nproposed method outperforms both standard BO and multi-objective BO algorithms\non a variety of sequence prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 09:42:19 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:54:16 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 11:46:09 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhang", "Yao", ""], ["Jarrett", "Daniel", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.03952", "submitter": "Zhaohui Yang", "authors": "Guangyu Jia and Zhaohui Yang and Hak-Keung Lam and Jianfeng Shi and\n  Mohammad Shikh-Bahaei", "title": "Channel Assignment in Uplink Wireless Communication using Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This letter investigates a channel assignment problem in uplink wireless\ncommunication systems. Our goal is to maximize the sum rate of all users\nsubject to integer channel assignment constraints. A convex optimization based\nalgorithm is provided to obtain the optimal channel assignment, where the\nclosed-form solution is obtained in each step. Due to high computational\ncomplexity in the convex optimization based algorithm, machine learning\napproaches are employed to obtain computational efficient solutions. More\nspecifically, the data are generated by using convex optimization based\nalgorithm and the original problem is converted to a regression problem which\nis addressed by the integration of convolutional neural networks (CNNs),\nfeed-forward neural networks (FNNs), random forest and gated recurrent unit\nnetworks (GRUs). The results demonstrate that the machine learning method\nlargely reduces the computation time with slightly compromising of prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 15:54:20 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jia", "Guangyu", ""], ["Yang", "Zhaohui", ""], ["Lam", "Hak-Keung", ""], ["Shi", "Jianfeng", ""], ["Shikh-Bahaei", "Mohammad", ""]]}, {"id": "2001.03955", "submitter": "Masoumeh Soflaei", "authors": "Masoumeh Soflaei, Hongyu Guo, Ali Al-Bashabsheh, Yongyi Mao, Richong\n  Zhang", "title": "Aggregated Learning: A Vector-Quantization Approach to Learning Neural\n  Network Classifiers", "comments": "Proof of theoretical results are provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a neural network classifier. Under the\ninformation bottleneck (IB) principle, we associate with this classification\nproblem a representation learning problem, which we call \"IB learning\". We show\nthat IB learning is, in fact, equivalent to a special class of the quantization\nproblem. The classical results in rate-distortion theory then suggest that IB\nlearning can benefit from a \"vector quantization\" approach, namely,\nsimultaneously learning the representations of multiple input objects. Such an\napproach assisted with some variational techniques, result in a novel learning\nframework, \"Aggregated Learning\", for classification with neural network\nmodels. In this framework, several objects are jointly classified by a single\nneural network. The effectiveness of this framework is verified through\nextensive experiments on standard image recognition and text classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 16:22:24 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 01:43:20 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 16:42:00 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Soflaei", "Masoumeh", ""], ["Guo", "Hongyu", ""], ["Al-Bashabsheh", "Ali", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""]]}, {"id": "2001.03956", "submitter": "Sandhya Tripathi", "authors": "Sandhya Tripathi, N. Hemachandra, Prashant Trivedi", "title": "Interpretable feature subset selection: A Shapley value based approach", "comments": "A shorter version of this work appeared in a special session titled\n  Explainable AI at IEEE BigData'20 conference. More experiments and a new\n  notion of interpretable FSS introduced in this version. Earlier plots for\n  sample bias robustness are corrected and updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For feature selection and related problems, we introduce the notion of\nclassification game, a cooperative game, with features as players and hinge\nloss based characteristic function and relate a feature's contribution to\nShapley value based error apportioning (SVEA) of total training error. Our\nmajor contribution is ($\\star$) to show that for any dataset the threshold 0 on\nSVEA value identifies feature subset whose joint interactions for label\nprediction is significant or those features that span a subspace where the data\nis predominantly lying. In addition, our scheme ($\\star$) identifies the\nfeatures on which Bayes classifier doesn't depend but any surrogate loss\nfunction based finite sample classifier does; this contributes to the excess\n$0$-$1$ risk of such a classifier, ($\\star$) estimates unknown true hinge risk\nof a feature, and ($\\star$) relate the stability property of an allocation and\nnegative valued SVEA by designing the analogue of core of classification game.\nDue to Shapley value's computationally expensive nature, we build on a known\nMonte Carlo based approximation algorithm that computes characteristic function\n(Linear Programs) only when needed. We address the potential sample bias\nproblem in feature selection by providing interval estimates for SVEA values\nobtained from multiple sub-samples. We illustrate all the above aspects on\nvarious synthetic and real datasets and show that our scheme achieves better\nresults than existing recursive feature elimination technique and ReliefF in\nmost cases. Our theoretically grounded classification game in terms of well\ndefined characteristic function offers interpretability (which we formalize in\nterms of final task) and explainability of our framework, including\nidentification of important features.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 16:27:08 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:28:58 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 19:24:45 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Tripathi", "Sandhya", ""], ["Hemachandra", "N.", ""], ["Trivedi", "Prashant", ""]]}, {"id": "2001.03985", "submitter": "Luigi Acerbi", "authors": "Bas van Opheusden, Luigi Acerbi and Wei Ji Ma", "title": "Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial\n  Sampling", "comments": "Bas van Opheusden and Luigi Acerbi contributed equally to this work", "journal-ref": null, "doi": "10.1371/journal.pcbi.1008483", "report-no": null, "categories": "cs.LG q-bio.NC q-bio.QM stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fate of scientific hypotheses often relies on the ability of a\ncomputational model to explain the data, quantified in modern statistical\napproaches by the likelihood function. The log-likelihood is the key element\nfor parameter estimation and model evaluation. However, the log-likelihood of\ncomplex models in fields such as computational biology and neuroscience is\noften intractable to compute analytically or numerically. In those cases,\nresearchers can often only estimate the log-likelihood by comparing observed\ndata with synthetic observations generated by model simulations. Standard\ntechniques to approximate the likelihood via simulation either use summary\nstatistics of the data or are at risk of producing severe biases in the\nestimate. Here, we explore another method, inverse binomial sampling (IBS),\nwhich can estimate the log-likelihood of an entire data set efficiently and\nwithout bias. For each observation, IBS draws samples from the simulator model\nuntil one matches the observation. The log-likelihood estimate is then a\nfunction of the number of samples drawn. The variance of this estimator is\nuniformly bounded, achieves the minimum variance for an unbiased estimator, and\nwe can compute calibrated estimates of the variance. We provide theoretical\narguments in favor of IBS and an empirical assessment of the method for\nmaximum-likelihood estimation with simulation-based models. As case studies, we\ntake three model-fitting problems of increasing complexity from computational\nand cognitive neuroscience. In all problems, IBS generally produces lower error\nin the estimated parameters and maximum log-likelihood values than alternative\nsampling methods with the same average number of samples. Our results\ndemonstrate the potential of IBS as a practical, robust, and easy to implement\nmethod for log-likelihood evaluation when exact techniques are not available.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 19:51:35 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 19:24:28 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 20:08:25 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["van Opheusden", "Bas", ""], ["Acerbi", "Luigi", ""], ["Ma", "Wei Ji", ""]]}, {"id": "2001.03988", "submitter": "Meimei Liu", "authors": "Meimei Liu and David B. Dunson", "title": "Domain Adaptive Bootstrap Aggregating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When there is a distributional shift between data used to train a predictive\nalgorithm and current data, performance can suffer. This is known as the domain\nadaptation problem. Bootstrap aggregating, or bagging, is a popular method for\nimproving stability of predictive algorithms, while reducing variance and\nprotecting against over-fitting. This article proposes a domain adaptive\nbagging method coupled with a new iterative nearest neighbor sampler. The key\nidea is to draw bootstrap samples from the training data in such a manner that\ntheir distribution equals that of new testing data. The proposed approach\nprovides a general ensemble framework that can be applied to arbitrary\nclassifiers. We further modify the method to allow anomalous samples in the\ntest data corresponding to outliers in the training data. Theoretical support\nis provided, and the approach is compared to alternatives in simulations and\nreal data applications.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:02:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 04:51:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Liu", "Meimei", ""], ["Dunson", "David B.", ""]]}, {"id": "2001.03992", "submitter": "Muktabh Mayank Srivastava", "authors": "Muktabh Mayank Srivastava", "title": "Bag of Tricks for Retail Product Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Retail Product Image Classification is an important Computer Vision and\nMachine Learning problem for building real world systems like self-checkout\nstores and automated retail execution evaluation. In this work, we present\nvarious tricks to increase accuracy of Deep Learning models on different types\nof retail product image classification datasets. These tricks enable us to\nincrease the accuracy of fine tuned convnets for retail product image\nclassification by a large margin. As the most prominent trick, we introduce a\nnew neural network layer called Local-Concepts-Accumulation (LCA) layer which\ngives consistent gains across multiple datasets. Two other tricks we find to\nincrease accuracy on retail product identification are using an\ninstagram-pretrained Convnet and using Maximum Entropy as an auxiliary loss for\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:20:07 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Srivastava", "Muktabh Mayank", ""]]}, {"id": "2001.03994", "submitter": "Eric Wong", "authors": "Eric Wong, Leslie Rice, J. Zico Kolter", "title": "Fast is better than free: Revisiting adversarial training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, a method for learning robust deep networks, is\ntypically assumed to be more expensive than traditional training due to the\nnecessity of constructing adversarial examples via a first-order method like\nprojected gradient decent (PGD). In this paper, we make the surprising\ndiscovery that it is possible to train empirically robust models using a much\nweaker and cheaper adversary, an approach that was previously believed to be\nineffective, rendering the method no more costly than standard training in\npractice. Specifically, we show that adversarial training with the fast\ngradient sign method (FGSM), when combined with random initialization, is as\neffective as PGD-based training but has significantly lower cost. Furthermore\nwe show that FGSM adversarial training can be further accelerated by using\nstandard techniques for efficient training of deep networks, allowing us to\nlearn a robust CIFAR10 classifier with 45% robust accuracy to PGD attacks with\n$\\epsilon=8/255$ in 6 minutes, and a robust ImageNet classifier with 43% robust\naccuracy at $\\epsilon=2/255$ in 12 hours, in comparison to past work based on\n\"free\" adversarial training which took 10 and 50 hours to reach the same\nrespective thresholds. Finally, we identify a failure mode referred to as\n\"catastrophic overfitting\" which may have caused previous attempts to use FGSM\nadversarial training to fail. All code for reproducing the experiments in this\npaper as well as pretrained model weights are at\nhttps://github.com/locuslab/fast_adversarial.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:30:22 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wong", "Eric", ""], ["Rice", "Leslie", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2001.04025", "submitter": "Chen Ma", "authors": "Chen Ma, Dylan R. Ashley, Junfeng Wen, Yoshua Bengio", "title": "Universal Successor Features for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer in Reinforcement Learning (RL) refers to the idea of applying\nknowledge gained from previous tasks to solving related tasks. Learning a\nuniversal value function (Schaul et al., 2015), which generalizes over goals\nand states, has previously been shown to be useful for transfer. However,\nsuccessor features are believed to be more suitable than values for transfer\n(Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize\nto new goals. In this paper, we propose (1) Universal Successor Features (USFs)\nto capture the underlying dynamics of the environment while allowing\ngeneralization to unseen goals and (2) a flexible end-to-end model of USFs that\ncan be trained by interacting with the environment. We show that learning USFs\nis compatible with any RL algorithm that learns state values using a temporal\ndifference method. Our experiments in a simple gridworld and with two MuJoCo\nenvironments show that USFs can greatly accelerate training when learning\nmultiple tasks and can effectively transfer knowledge to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 03:41:06 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ma", "Chen", ""], ["Ashley", "Dylan R.", ""], ["Wen", "Junfeng", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.04029", "submitter": "Zhengzhi Sun", "authors": "Zheng-zhi Sun, Shi-ju Ran and Gang Su", "title": "Tangent-Space Gradient Optimization of Tensor Network for Machine\n  Learning", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. E 102, 012152 (2020)", "doi": "10.1103/PhysRevE.102.012152", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradient-based optimization method for deep machine learning models\nsuffers from gradient vanishing and exploding problems, particularly when the\ncomputational graph becomes deep. In this work, we propose the tangent-space\ngradient optimization (TSGO) for the probabilistic models to keep the gradients\nfrom vanishing or exploding. The central idea is to guarantee the orthogonality\nbetween the variational parameters and the gradients. The optimization is then\nimplemented by rotating parameter vector towards the direction of gradient. We\nexplain and testify TSGO in tensor network (TN) machine learning, where the TN\ndescribes the joint probability distribution as a normalized state $\\left| \\psi\n\\right\\rangle $ in Hilbert space. We show that the gradient can be restricted\nin the tangent space of $\\left\\langle \\psi \\right.\\left| \\psi \\right\\rangle =\n1$ hyper-sphere. Instead of additional adaptive methods to control the learning\nrate in deep learning, the learning rate of TSGO is naturally determined by the\nangle $\\theta $ as $\\eta = \\tan \\theta $. Our numerical results reveal better\nconvergence of TSGO in comparison to the off-the-shelf Adam.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:40:40 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Sun", "Zheng-zhi", ""], ["Ran", "Shi-ju", ""], ["Su", "Gang", ""]]}, {"id": "2001.04032", "submitter": "Joseph Futoma", "authors": "Joseph Futoma, Michael C. Hughes, Finale Doshi-Velez", "title": "POPCORN: Partially Observed Prediction COnstrained ReiNforcement\n  Learning", "comments": "Accepted to AISTATS 2020, Palermo, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many medical decision-making tasks can be framed as partially observed Markov\ndecision processes (POMDPs). However, prevailing two-stage approaches that\nfirst learn a POMDP and then solve it often fail because the model that best\nfits the data may not be well suited for planning. We introduce a new\noptimization objective that (a) produces both high-performing policies and\nhigh-quality generative models, even when some observations are irrelevant for\nplanning, and (b) does so in batch off-policy settings that are typical in\nhealthcare, when only retrospective data is available. We demonstrate our\napproach on synthetic examples and a challenging medical decision-making\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 01:55:50 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 15:57:08 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Futoma", "Joseph", ""], ["Hughes", "Michael C.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2001.04050", "submitter": "Ling Chen", "authors": "Fan Yang, Ling Chen, Fan Zhou, Yusong Gao, Wei Cao", "title": "Relational State-Space Model for Stochastic Multi-Object Systems", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world dynamical systems often consist of multiple stochastic subsystems\nthat interact with each other. Modeling and forecasting the behavior of such\ndynamics are generally not easy, due to the inherent hardness in understanding\nthe complicated interactions and evolutions of their constituents. This paper\nintroduces the relational state-space model (R-SSM), a sequential hierarchical\nlatent variable model that makes use of graph neural networks (GNNs) to\nsimulate the joint state transitions of multiple correlated objects. By letting\nGNNs cooperate with SSM, R-SSM provides a flexible way to incorporate\nrelational information into the modeling of multi-object dynamics. We further\nsuggest augmenting the model with normalizing flows instantiated for\nvertex-indexed random variables and propose two auxiliary contrastive\nobjectives to facilitate the learning. The utility of R-SSM is empirically\nevaluated on synthetic and real time-series datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 03:45:21 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Yang", "Fan", ""], ["Chen", "Ling", ""], ["Zhou", "Fan", ""], ["Gao", "Yusong", ""], ["Cao", "Wei", ""]]}, {"id": "2001.04051", "submitter": "Joseph Janizek", "authors": "Joseph D. Janizek, Gabriel Erion, Alex J. DeGrave, Su-In Lee", "title": "An Adversarial Approach for the Robust Classification of Pneumonia from\n  Chest Radiographs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has shown promise in the domain of disease classification\nfrom medical images, models based on state-of-the-art convolutional neural\nnetwork architectures often exhibit performance loss due to dataset shift.\nModels trained using data from one hospital system achieve high predictive\nperformance when tested on data from the same hospital, but perform\nsignificantly worse when they are tested in different hospital systems.\nFurthermore, even within a given hospital system, deep learning models have\nbeen shown to depend on hospital- and patient-level confounders rather than\nmeaningful pathology to make classifications. In order for these models to be\nsafely deployed, we would like to ensure that they do not use confounding\nvariables to make their classification, and that they will work well even when\ntested on images from hospitals that were not included in the training data. We\nattempt to address this problem in the context of pneumonia classification from\nchest radiographs. We propose an approach based on adversarial optimization,\nwhich allows us to learn more robust models that do not depend on confounders.\nSpecifically, we demonstrate improved out-of-hospital generalization\nperformance of a pneumonia classifier by training a model that is invariant to\nthe view position of chest radiographs (anterior-posterior vs.\nposterior-anterior). Our approach leads to better predictive performance on\nexternal hospital data than both a standard baseline and previously proposed\nmethods to handle confounding, and also suggests a method for identifying\nmodels that may rely on confounders. Code available at\nhttps://github.com/suinleelab/cxr_adv.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 03:49:05 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Janizek", "Joseph D.", ""], ["Erion", "Gabriel", ""], ["DeGrave", "Alex J.", ""], ["Lee", "Su-In", ""]]}, {"id": "2001.04072", "submitter": "Alfred Ajay Aureate R", "authors": "Mohith Damarapati, Inavamsi B. Enaganti and Alfred Ajay Aureate\n  Rajakumar", "title": "Numerical Sequence Prediction using Bayesian Concept Learning", "comments": "7 pages, 6 figures. Was done as part of the course project at NYU\n  Courant. To be extended for a conference proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people learn mathematical patterns or sequences, they are able to\nidentify the concepts (or rules) underlying those patterns. Having learned the\nunderlying concepts, humans are also able to generalize those concepts to other\nnumbers, so far as to even identify previously unseen combinations of those\nrules. Current state-of-the art RNN architectures like LSTMs perform well in\npredicting successive elements of sequential data, but require vast amounts of\ntraining examples. Even with extensive data, these models struggle to\ngeneralize concepts. From our behavioral study, we also found that humans are\nable to disregard noise and identify the underlying rules generating the\ncorrupted sequences. We therefore propose a Bayesian model that captures these\nhuman-like learning capabilities to predict next number in a given sequence,\nbetter than traditional LSTMs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 06:02:44 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Damarapati", "Mohith", ""], ["Enaganti", "Inavamsi B.", ""], ["Rajakumar", "Alfred Ajay Aureate", ""]]}, {"id": "2001.04092", "submitter": "Tiantian Li", "authors": "Qiuyu Zhu and Tiantian Li", "title": "Semi-supervised learning method based on predefined evenly-distributed\n  class centroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to supervised learning, semi-supervised learning reduces the\ndependence of deep learning on a large number of labeled samples. In this work,\nwe use a small number of labeled samples and perform data augmentation on\nunlabeled samples to achieve image classification. Our method constrains all\nsamples to the predefined evenly-distributed class centroids (PEDCC) by the\ncorresponding loss function. Specifically, the PEDCC-Loss for labeled samples,\nand the maximum mean discrepancy loss for unlabeled samples are used to make\nthe feature distribution closer to the distribution of PEDCC. Our method\nensures that the inter-class distance is large and the intra-class distance is\nsmall enough to make the classification boundaries between different classes\nclearer. Meanwhile, for unlabeled samples, we also use KL divergence to\nconstrain the consistency of the network predictions between unlabeled and\naugmented samples. Our semi-supervised learning method achieves the\nstate-of-the-art results, with 4000 labeled samples on CIFAR10 and 1000 labeled\nsamples on SVHN, and the accuracy is 95.10% and 97.58% respectively.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:03:32 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhu", "Qiuyu", ""], ["Li", "Tiantian", ""]]}, {"id": "2001.04129", "submitter": "Jorge Calvo-Zaragoza", "authors": "Antonio-Javier Gallego, Jorge Calvo-Zaragoza, Robert B. Fisher", "title": "Incremental Unsupervised Domain-Adversarial Training of Neural Networks", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of supervised statistical learning, it is typically assumed\nthat the training set comes from the same distribution that draws the test\nsamples. When this is not the case, the behavior of the learned model is\nunpredictable and becomes dependent upon the degree of similarity between the\ndistribution of the training set and the distribution of the test set. One of\nthe research topics that investigates this scenario is referred to as domain\nadaptation. Deep neural networks brought dramatic advances in pattern\nrecognition and that is why there have been many attempts to provide good\ndomain adaptation algorithms for these models. Here we take a different avenue\nand approach the problem from an incremental point of view, where the model is\nadapted to the new domain iteratively. We make use of an existing unsupervised\ndomain-adaptation algorithm to identify the target samples on which there is\ngreater confidence about their true label. The output of the model is analyzed\nin different ways to determine the candidate samples. The selected set is then\nadded to the source training set by considering the labels provided by the\nnetwork as ground truth, and the process is repeated until all target samples\nare labelled. Our results report a clear improvement with respect to the\nnon-incremental case in several datasets, also outperforming other\nstate-of-the-art domain adaptation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 09:54:35 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gallego", "Antonio-Javier", ""], ["Calvo-Zaragoza", "Jorge", ""], ["Fisher", "Robert B.", ""]]}, {"id": "2001.04147", "submitter": "Przemys{\\l}aw Spurek", "authors": "Andrzej Bedychaj, Przemys{\\l}aw Spurek, Aleksandra Nowak, Jacek Tabor", "title": "WICA: nonlinear weighted ICA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) aims to find a coordinate system in\nwhich the components of the data are independent. In this paper we construct a\nnew nonlinear ICA model, called WICA, which obtains better and more stable\nresults than other algorithms. A crucial tool is given by a new efficient\nmethod of verifying nonlinear dependence with the use of computation of\ncorrelation coefficients for normally weighted data. In addition, authors\npropose a new baseline nonlinear mixing to perform comparable experiments, and\na~reliable measure which allows fair comparison of nonlinear models. Our code\nfor WICA is available on Github https://github.com/gmum/wica.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 10:38:03 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 21:37:54 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Bedychaj", "Andrzej", ""], ["Spurek", "Przemys\u0142aw", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""]]}, {"id": "2001.04168", "submitter": "Nikita Benkovich", "authors": "Nikita Benkovich, Roman Dedenok and Dmitry Golubev", "title": "DeepQuarantine for Suspicious Mail", "comments": "8 pages, 3 figures, presented at M3AAWG 47TH Montreal", "journal-ref": "CEUR Workshop Proceedings 2479 (2019) 68-76", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce DeepQuarantine (DQ), a cloud technology to detect\nand quarantine potential spam messages. Spam attacks are becoming more diverse\nand can potentially be harmful to email users. Despite the high quality and\nperformance of spam filtering systems, detection of a spam campaign can take\nsome time. Unfortunately, in this case some unwanted messages get delivered to\nusers. To solve this problem, we created DQ, which detects potential spam and\nkeeps it in a special Quarantine folder for a while. The time gained allows us\nto double-check the messages to improve the reliability of the anti-spam\nsolution. Due to high precision of the technology, most of the quarantined mail\nis spam, which allows clients to use email without delay. Our solution is based\non applying Convolutional Neural Networks on MIME headers to extract deep\nfeatures from large-scale historical data. We evaluated the proposed method on\nreal-world data and showed that DQ enhances the quality of spam detection.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:32:58 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Benkovich", "Nikita", ""], ["Dedenok", "Roman", ""], ["Golubev", "Dmitry", ""]]}, {"id": "2001.04197", "submitter": "Takashi Nicholas Maeda", "authors": "Takashi Nicholas Maeda and Shohei Shimizu", "title": "Causal discovery of linear non-Gaussian acyclic models in the presence\n  of latent confounders", "comments": "This is an extended version of the AISTATS 2020 paper entitled \"RCD:\n  Repetitive causal discovery of linear non-Gaussian acyclic models with latent\n  confounders\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from data affected by latent confounders is an important and\ndifficult challenge. Causal functional model-based approaches have not been\nused to present variables whose relationships are affected by latent\nconfounders, while some constraint-based methods can present them. This paper\nproposes a causal functional model-based method called repetitive causal\ndiscovery (RCD) to discover the causal structure of observed variables affected\nby latent confounders. RCD repeats inferring the causal directions between a\nsmall number of observed variables and determines whether the relationships are\naffected by latent confounders. RCD finally produces a causal graph where a\nbi-directed arrow indicates the pair of variables that have the same latent\nconfounders, and a directed arrow indicates the causal direction of a pair of\nvariables that are not affected by the same latent confounder. The results of\nexperimental validation using simulated data and real-world data confirmed that\nRCD is effective in identifying latent confounders and causal directions\nbetween observed variables.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:55:47 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:25:51 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 01:11:57 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 11:41:54 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Maeda", "Takashi Nicholas", ""], ["Shimizu", "Shohei", ""]]}, {"id": "2001.04230", "submitter": "Chon Lok Lei", "authors": "Chon Lok Lei, Sanmitra Ghosh, Dominic G. Whittaker, Yasser\n  Aboelkassem, Kylie A. Beattie, Chris D. Cantwell, Tammo Delhaas, Charles\n  Houston, Gustavo Montes Novaes, Alexander V. Panfilov, Pras Pathmanathan,\n  Marina Riabiz, Rodrigo Weber dos Santos, John Walmsley, Keith Worden, Gary R.\n  Mirams and Richard D. Wilkinson", "title": "Considering discrepancy when calibrating a mechanistic electrophysiology\n  model", "comments": "This version is published in Philosophical Transactions of the Royal\n  Society A; Updated in response to reviewer comments, including: added details\n  to the introduction, fixed mathematical notations for clarity, and moved the\n  original Table 3 to the supplement to avoid confusion", "journal-ref": "Phil. Trans. R. Soc. A. 378 (2020): 20190349", "doi": "10.1098/rsta.2019.0349", "report-no": null, "categories": "stat.CO q-bio.QM stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification (UQ) is a vital step in using mathematical models\nand simulations to take decisions. The field of cardiac simulation has begun to\nexplore and adopt UQ methods to characterise uncertainty in model inputs and\nhow that propagates through to outputs or predictions. In this perspective\npiece we draw attention to an important and under-addressed source of\nuncertainty in our predictions -- that of uncertainty in the model structure or\nthe equations themselves. The difference between imperfect models and reality\nis termed model discrepancy, and we are often uncertain as to the size and\nconsequences of this discrepancy. Here we provide two examples of the\nconsequences of discrepancy when calibrating models at the ion channel and\naction potential scales. Furthermore, we attempt to account for this\ndiscrepancy when calibrating and validating an ion channel model using\ndifferent methods, based on modelling the discrepancy using Gaussian processes\n(GPs) and autoregressive-moving-average (ARMA) models, then highlight the\nadvantages and shortcomings of each approach. Finally, suggestions and lines of\nenquiry for future work are provided.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:26:13 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:50:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lei", "Chon Lok", ""], ["Ghosh", "Sanmitra", ""], ["Whittaker", "Dominic G.", ""], ["Aboelkassem", "Yasser", ""], ["Beattie", "Kylie A.", ""], ["Cantwell", "Chris D.", ""], ["Delhaas", "Tammo", ""], ["Houston", "Charles", ""], ["Novaes", "Gustavo Montes", ""], ["Panfilov", "Alexander V.", ""], ["Pathmanathan", "Pras", ""], ["Riabiz", "Marina", ""], ["Santos", "Rodrigo Weber dos", ""], ["Walmsley", "John", ""], ["Worden", "Keith", ""], ["Mirams", "Gary R.", ""], ["Wilkinson", "Richard D.", ""]]}, {"id": "2001.04243", "submitter": "Yitian Xu", "authors": "Yuzhou Cao, Shuqi Liu and Yitian Xu", "title": "Multi-Complementary and Unlabeled Learning for Arbitrary Losses and\n  Models", "comments": "22 pages, 5 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weakly-supervised learning framework named as complementary-label learning\nhas been proposed recently, where each sample is equipped with a single\ncomplementary label that denotes one of the classes the sample does not belong\nto. However, the existing complementary-label learning methods cannot learn\nfrom the easily accessible unlabeled samples and samples with multiple\ncomplementary labels, which are more informative. In this paper, to remove\nthese limitations, we propose the novel multi-complementary and unlabeled\nlearning framework that allows unbiased estimation of classification risk from\nsamples with any number of complementary labels and unlabeled samples, for\narbitrary loss functions and models. We first give an unbiased estimator of the\nclassification risk from samples with multiple complementary labels, and then\nfurther improve the estimator by incorporating unlabeled samples into the risk\nformulation. The estimation error bounds show that the proposed methods are in\nthe optimal parametric convergence rate. Finally, the experiments on both\nlinear and deep models show the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:52:54 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 15:23:10 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 17:18:42 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Cao", "Yuzhou", ""], ["Liu", "Shuqi", ""], ["Xu", "Yitian", ""]]}, {"id": "2001.04251", "submitter": "Rohit Reddy Muthyala", "authors": "Rohit R Muthyala, Davi Geiger, Zvi M. Kedem", "title": "Quantum Interference for Counting Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting the number of clusters, when these clusters overlap significantly is\na challenging problem in machine learning. We argue that a purely mathematical\nquantum theory, formulated using the path integral technique, when applied to\nnon-physics modeling leads to non-physics quantum theories that are statistical\nin nature. We show that a quantum theory can be a more robust statistical\ntheory to separate data to count overlapping clusters. The theory is also\nconfirmed from data simulations.This works identify how quantum theory can be\neffective in counting clusters and hope to inspire the field to further apply\nsuch techniques.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:13:57 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Muthyala", "Rohit R", ""], ["Geiger", "Davi", ""], ["Kedem", "Zvi M.", ""]]}, {"id": "2001.04264", "submitter": "Mohamed Ali Belabbas", "authors": "Mohamed Ali Belabbas", "title": "On implicit regularization: Morse functions and applications to matrix\n  factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit implicit regularization from the ground up using\nnotions from dynamical systems and invariant subspaces of Morse functions. The\nkey contributions are a new criterion for implicit regularization---a leading\ncontender to explain the generalization power of deep models such as neural\nnetworks---and a general blueprint to study it. We apply these techniques to\nsettle a conjecture on implicit regularization in matrix factorization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:17:25 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 22:06:26 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Belabbas", "Mohamed Ali", ""]]}, {"id": "2001.04271", "submitter": "Luigi Tommaso Luppino", "authors": "Luigi Tommaso Luppino, Michael Kampffmeyer, Filippo Maria Bianchi,\n  Gabriele Moser, Sebastiano Bruno Serpico, Robert Jenssen, and Stian Normann\n  Anfinsen", "title": "Deep Image Translation with an Affinity-Based Change Prior for\n  Unsupervised Multimodal Change Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2021.3056196", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image translation with convolutional neural networks has recently been used\nas an approach to multimodal change detection. Existing approaches train the\nnetworks by exploiting supervised information of the change areas, which,\nhowever, is not always available. A main challenge in the unsupervised problem\nsetting is to avoid that change pixels affect the learning of the translation\nfunction. We propose two new network architectures trained with loss functions\nweighted by priors that reduce the impact of change pixels on the learning\nobjective. The change prior is derived in an unsupervised fashion from\nrelational pixel information captured by domain-specific affinity matrices.\nSpecifically, we use the vertex degrees associated with an absolute affinity\ndifference matrix and demonstrate their utility in combination with cycle\nconsistency and adversarial training. The proposed neural networks are compared\nwith state-of-the-art algorithms. Experiments conducted on three real datasets\nshow the effectiveness of our methodology.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:23:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 13:57:53 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Luppino", "Luigi Tommaso", ""], ["Kampffmeyer", "Michael", ""], ["Bianchi", "Filippo Maria", ""], ["Moser", "Gabriele", ""], ["Serpico", "Sebastiano Bruno", ""], ["Jenssen", "Robert", ""], ["Anfinsen", "Stian Normann", ""]]}, {"id": "2001.04279", "submitter": "Amir Mosavi Prof", "authors": "Narjes Nabipour, Amir Mosavi, Eva Hajnal, Laszlo Nadai, Shahab\n  Shamshirband, Kwok-Wing Chau", "title": "Modeling Climate Change Impact on Wind Power Resources Using Adaptive\n  Neuro-Fuzzy Inference System", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate change impacts and adaptations are the subjects to ongoing issues\nthat attract the attention of many researchers. Insight into the wind power\npotential in an area and its probable variation due to climate change impacts\ncan provide useful information for energy policymakers and strategists for\nsustainable development and management of the energy. In this study, spatial\nvariation of wind power density at the turbine hub-height and its variability\nunder future climatic scenarios are taken under consideration. An ANFIS based\npost-processing technique was employed to match the power outputs of the\nregional climate model with those obtained from the reference data. The\nnear-surface wind data obtained from a regional climate model are employed to\ninvestigate climate change impacts on the wind power resources in the Caspian\nSea. Subsequent to converting near-surface wind speed to turbine hub-height\nspeed and computation of wind power density, the results have been investigated\nto reveal mean annual power, seasonal, and monthly variability for a 20-year\nperiod in the present (1981-2000) and in the future (2081-2100). The findings\nof this study indicated that the middle and northern parts of the Caspian Sea\nare placed with the highest values of wind power. However, the results of the\npost-processing technique using adaptive neuro-fuzzy inference system (ANFIS)\nmodel showed that the real potential of the wind power in the area is lower\nthan those of projected from the regional climate model.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:35:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Nabipour", "Narjes", ""], ["Mosavi", "Amir", ""], ["Hajnal", "Eva", ""], ["Nadai", "Laszlo", ""], ["Shamshirband", "Shahab", ""], ["Chau", "Kwok-Wing", ""]]}, {"id": "2001.04295", "submitter": "Erwan Scornet", "authors": "Erwan Scornet (CMAP)", "title": "Trees, forests, and impurity-based variable importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree ensemble methods such as random forests [Breiman, 2001] are very popular\nto handle high-dimensional tabular data sets, notably because of their good\npredictive accuracy. However, when machine learning is used for decision-making\nproblems, settling for the best predictive procedures may not be reasonable\nsince enlightened decisions require an in-depth comprehension of the algorithm\nprediction process. Unfortunately, random forests are not intrinsically\ninterpretable since their prediction results from averaging several hundreds of\ndecision trees. A classic approach to gain knowledge on this so-called\nblack-box algorithm is to compute variable importances, that are employed to\nassess the predictive impact of each input variable. Variable importances are\nthen used to rank or select variables and thus play a great role in data\nanalysis. Nevertheless, there is no justification to use random forest variable\nimportances in such way: we do not even know what these quantities estimate. In\nthis paper, we analyze one of the two well-known random forest variable\nimportances, the Mean Decrease Impurity (MDI). We prove that if input variables\nare independent and in absence of interactions, MDI provides a variance\ndecomposition of the output, where the contribution of each variable is clearly\nidentified. We also study models exhibiting dependence between input variables\nor interaction, for which the variable importance is intrinsically ill-defined.\nOur analysis shows that there may exist some benefits to use a forest compared\nto a single tree.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:38:53 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 16:13:28 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Scornet", "Erwan", "", "CMAP"]]}, {"id": "2001.04297", "submitter": "John Just", "authors": "John Just", "title": "Granular Learning with Deep Generative Models using Highly Contaminated\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to utilize recent advances in deep generative models for anomaly\ndetection in a granular (continuous) sense on a real-world image dataset with\nquality issues is detailed using recent normalizing flow models, with\nimplications in many other applications/domains/data types. The approach is\ncompletely unsupervised (no annotations available) but qualitatively shown to\nprovide accurate semantic labeling for images via heatmaps of the scaled\nlog-likelihood overlaid on the images. When sorted based on the median values\nper image, clear trends in quality are observed. Furthermore, downstream\nclassification is shown to be possible and effective via a weakly supervised\napproach using the log-likelihood output from a normalizing flow model as a\ntraining signal for a feature-extracting convolutional neural network. The\npre-linear dense layer outputs on the CNN are shown to disentangle high level\nrepresentations and efficiently cluster various quality issues. Thus, an\nentirely non-annotated (fully unsupervised) approach is shown possible for\naccurate estimation and classification of quality issues..\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 23:22:17 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Just", "John", ""]]}, {"id": "2001.04298", "submitter": "Han Bao", "authors": "Han Bao, Nam Dinh, Linyu Lin, Robert Youngblood, Jeffrey Lane, Hongbin\n  Zhang", "title": "Using Deep Learning to Explore Local Physical Similarity for\n  Global-scale Bridging in Thermal-hydraulic Simulation", "comments": "24 pages, 10 tables, 12 figures. This manuscript has been submitted\n  to Annuals of Nuclear Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current system thermal-hydraulic codes have limited credibility in simulating\nreal plant conditions, especially when the geometry and boundary conditions are\nextrapolated beyond the range of test facilities. This paper proposes a\ndata-driven approach, Feature Similarity Measurement FFSM), to establish a\ntechnical basis to overcome these difficulties by exploring local patterns\nusing machine learning. The underlying local patterns in multiscale data are\nrepresented by a set of physical features that embody the information from a\nphysical system of interest, empirical correlations, and the effect of mesh\nsize. After performing a limited number of high-fidelity numerical simulations\nand a sufficient amount of fast-running coarse-mesh simulations, an error\ndatabase is built, and deep learning is applied to construct and explore the\nrelationship between the local physical features and simulation errors. Case\nstudies based on mixed convection have been designed for demonstrating the\ncapability of data-driven models in bridging global scale gaps.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 20:14:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Bao", "Han", ""], ["Dinh", "Nam", ""], ["Lin", "Linyu", ""], ["Youngblood", "Robert", ""], ["Lane", "Jeffrey", ""], ["Zhang", "Hongbin", ""]]}, {"id": "2001.04321", "submitter": "Man Shun Ang", "authors": "Andersen Man Shun Ang, Jeremy E. Cohen, Nicolas Gillis, Le Thi Khanh\n  Hien", "title": "Accelerating Block Coordinate Descent for Nonnegative Tensor\n  Factorization", "comments": "32 pages, 24 figures", "journal-ref": "Numerical Linear Algebra with Applications, e2373, 2021", "doi": "10.1002/nla.2373", "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with improving the empirical convergence speed of\nblock-coordinate descent algorithms for approximate nonnegative tensor\nfactorization (NTF). We propose an extrapolation strategy in-between block\nupdates, referred to as heuristic extrapolation with restarts (HER). HER\nsignificantly accelerates the empirical convergence speed of most existing\nblock-coordinate algorithms for dense NTF, in particular for challenging\ncomputational scenarios, while requiring a negligible additional computational\nbudget.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:59:03 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 11:54:54 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ang", "Andersen Man Shun", ""], ["Cohen", "Jeremy E.", ""], ["Gillis", "Nicolas", ""], ["Hien", "Le Thi Khanh", ""]]}, {"id": "2001.04341", "submitter": "Yifei Wang", "authors": "Yifei Wang and Wuchen Li", "title": "Information Newton's flow: second-order optimization method in\n  probability space", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for Newton's flows in probability space with\ninformation metrics, named information Newton's flows. Here two information\nmetrics are considered, including both the Fisher-Rao metric and the\nWasserstein-2 metric. A known fact is that overdamped Langevin dynamics\ncorrespond to Wasserstein gradient flows of Kullback-Leibler (KL) divergence.\nExtending this fact to Wasserstein Newton's flows, we derive Newton's Langevin\ndynamics. We provide examples of Newton's Langevin dynamics in both\none-dimensional space and Gaussian families. For the numerical implementation,\nwe design sampling efficient variational methods in affine models and\nreproducing kernel Hilbert space (RKHS) to approximate Wasserstein Newton's\ndirections. We also establish convergence results of the proposed information\nNewton's method with approximated directions. Several numerical examples from\nBayesian sampling problems are shown to demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:33:46 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 07:24:31 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 15:03:54 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 01:28:44 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wang", "Yifei", ""], ["Li", "Wuchen", ""]]}, {"id": "2001.04343", "submitter": "F. William Townes", "authors": "F. William Townes", "title": "Review of Probability Distributions for Modeling Count Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count data take on non-negative integer values and are challenging to\nproperly analyze using standard linear-Gaussian methods such as linear\nregression and principal components analysis. Generalized linear models enable\ndirect modeling of counts in a regression context using distributions such as\nthe Poisson and negative binomial. When counts contain only relative\ninformation, multinomial or Dirichlet-multinomial models can be more\nappropriate. We review some of the fundamental connections between multinomial\nand count models from probability theory, providing detailed proofs. These\nrelationships are useful for methods development in applications such as topic\nmodeling of text data and genomics.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 18:28:19 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Townes", "F. William", ""]]}, {"id": "2001.04345", "submitter": "Mukul Kumar", "authors": "Mukul Kumar, Youna Hu, Will Headden, Rahul Goutam, Heran Lin, Bing Yin", "title": "Shareable Representations for Search Query Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding search queries is critical for shopping search engines to\ndeliver a satisfying customer experience. Popular shopping search engines\nreceive billions of unique queries yearly, each of which can depict any of\nhundreds of user preferences or intents. In order to get the right results to\ncustomers it must be known queries like \"inexpensive prom dresses\" are intended\nto not only surface results of a certain product type but also products with a\nlow price. Referred to as query intents, examples also include preferences for\nauthor, brand, age group, or simply a need for customer service. Recent works\nsuch as BERT have demonstrated the success of a large transformer encoder\narchitecture with language model pre-training on a variety of NLP tasks. We\nadapt such an architecture to learn intents for search queries and describe\nmethods to account for the noisiness and sparseness of search query data. We\nalso describe cost effective ways of hosting transformer encoder models in\ncontext with low latency requirements. With the right domain-specific training\nwe can build a shareable deep learning model whose internal representation can\nbe reused for a variety of query understanding tasks including query intent\nidentification. Model sharing allows for fewer large models needed to be served\nat inference time and provides a platform to quickly build and roll out new\nsearch query classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 22:12:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kumar", "Mukul", ""], ["Hu", "Youna", ""], ["Headden", "Will", ""], ["Goutam", "Rahul", ""], ["Lin", "Heran", ""], ["Yin", "Bing", ""]]}, {"id": "2001.04362", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Source Domain Adaptation for Text Classification via\n  DistanceNet-Bandits", "comments": "AAAI 2020 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation performance of a learning algorithm on a target domain is a\nfunction of its source domain error and a divergence measure between the data\ndistribution of these two domains. We present a study of various distance-based\nmeasures in the context of NLP tasks, that characterize the dissimilarity\nbetween domains based on sample estimates. We first conduct analysis\nexperiments to show which of these distance measures can best differentiate\nsamples from same versus different domains, and are correlated with empirical\nresults. Next, we develop a DistanceNet model which uses these distance\nmeasures, or a mixture of these distance measures, as an additional loss\nfunction to be minimized jointly with the task's loss function, so as to\nachieve better unsupervised domain adaptation. Finally, we extend this model to\na novel DistanceNet-Bandit model, which employs a multi-armed bandit controller\nto dynamically switch between multiple source domains and allow the model to\nlearn an optimal trajectory and mixture of domains for transfer to the\nlow-resource target domain. We conduct experiments on popular sentiment\nanalysis datasets with several diverse domains and show that our DistanceNet\nmodel, as well as its dynamic bandit variant, can outperform competitive\nbaselines in the context of unsupervised domain adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:53:41 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 17:01:49 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 21:21:22 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.04385", "submitter": "Christopher Rackauckas", "authors": "Christopher Rackauckas, Yingbo Ma, Julius Martensen, Collin Warner,\n  Kirill Zubov, Rohit Supekar, Dominic Skinner, Ali Ramadhan, Alan Edelman", "title": "Universal Differential Equations for Scientific Machine Learning", "comments": "3 figures, 2 tables, 3 supplemental figures, 27 pages, 18\n  supplemental pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of science, the well-known adage \"a picture is worth a\nthousand words\" might well be \"a model is worth a thousand datasets.\"\nScientific models, such as Newtonian physics or biological gene regulatory\nnetworks, are human-driven simplifications of complex phenomena that serve as\nsurrogates for the countless experiments that validated the models. Recently,\nmachine learning has been able to overcome the inaccuracies of approximate\nmodeling by directly learning the entire set of nonlinear interactions from\ndata. However, without any predetermined structure from the scientific basis\nbehind the problem, machine learning approaches are flexible but\ndata-expensive, requiring large databases of homogeneous labeled training data.\nA central challenge is reconciling data that is at odds with simplified models\nwithout requiring \"big data\".\n  In this work we develop a new methodology, universal differential equations\n(UDEs), which augments scientific models with machine-learnable structures for\nscientifically-based learning. We show how UDEs can be utilized to discover\npreviously unknown governing equations, accurately extrapolate beyond the\noriginal data, and accelerate model simulation, all in a time and\ndata-efficient manner. This advance is coupled with open-source software that\nallows for training UDEs which incorporate physical constraints, delayed\ninteractions, implicitly-defined events, and intrinsic stochasticity in the\nmodel. Our examples show how a diverse set of computationally-difficult\nmodeling issues across scientific disciplines, from automatically discovering\nbiological mechanisms to accelerating the training of physics-informed neural\nnetworks and large-eddy simulations, can all be transformed into UDE training\nproblems that are efficiently solved by a single software methodology.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 16:40:35 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 00:09:47 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 00:19:42 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Rackauckas", "Christopher", ""], ["Ma", "Yingbo", ""], ["Martensen", "Julius", ""], ["Warner", "Collin", ""], ["Zubov", "Kirill", ""], ["Supekar", "Rohit", ""], ["Skinner", "Dominic", ""], ["Ramadhan", "Ali", ""], ["Edelman", "Alan", ""]]}, {"id": "2001.04413", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Backward Feature Correction: How Deep Learning Performs Deep Learning", "comments": "V2 adds more experiments, V3 polishes writing and improves\n  experiments, V4 makes minor fixes to the figures, V5 polishes writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does a 110-layer ResNet learn a high-complexity classifier using\nrelatively few training examples and short training time? We present a theory\ntowards explaining this in terms of Hierarchical Learning. We refer\nhierarchical learning as the learner learns to represent a complicated target\nfunction by decomposing it into a sequence of simpler functions to reduce\nsample and time complexity. We formally analyze how multi-layer neural networks\ncan perform such hierarchical learning efficiently and automatically by\napplying SGD.\n  On the conceptual side, we present, to the best of our knowledge, the FIRST\ntheory result indicating how deep neural networks can still be sample and time\nefficient using SGD on certain hierarchical learning tasks, when NO KNOWN\nexisting algorithm is efficient. We establish a new principle called \"backward\nfeature correction\", where training higher-level layers in the network can\nimprove the features of lower-level ones. We believe this is the key to\nunderstand the deep learning process in multi-layer neural networks.\n  On the technical side, we show for regression and even binary classification,\nfor every input dimension $d>0$, there is a concept class of degree $\\omega(1)$\npolynomials so that, using $\\omega(1)$-layer neural networks as learners, SGD\ncan learn any function from this class in $\\mathsf{poly}(d)$ time and sample\ncomplexity to any $\\frac{1}{\\mathsf{poly}(d)}$ error, through learning to\nrepresent it as a composition of $\\omega(1)$ layers of quadratic functions. In\ncontrast, we do not know any other simple algorithm (including layer-wise\ntraining or applying kernel method sequentially) that can learn this concept\nclass in $\\mathsf{poly}(d)$ time even to any $d^{-0.01}$ error. As a side\nresult, we prove $d^{\\omega(1)}$ lower bounds for several non-hierarchical\nlearners, including any kernel methods, neural tangent or neural compositional\nkernels.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:28:29 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:47:15 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 03:28:52 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 17:48:37 GMT"}, {"version": "v5", "created": "Sat, 13 Mar 2021 12:05:09 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2001.04437", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins", "title": "LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured\n  Prediction", "comments": "34 pages, 5 tables, 4 figures. ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction requires manipulating a large number of combinatorial\nstructures, e.g., dependency trees or alignments, either as latent or output\nvariables. Recently, the SparseMAP method has been proposed as a\ndifferentiable, sparse alternative to maximum a posteriori (MAP) and marginal\ninference. SparseMAP returns a combination of a small number of structures, a\ndesirable property in some downstream applications. However, SparseMAP requires\na tractable MAP inference oracle. This excludes, e.g., loopy graphical models\nor factor graphs with logic constraints, which generally require approximate\ninference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP\nthat addresses this limitation via a local polytope relaxation. LP-SparseMAP\nuses the flexible and powerful domain specific language of factor graphs for\ndefining and backpropagating through arbitrary hidden structure, supporting\ncoarse decompositions, hard logic constraints, and higher-order correlations.\nWe derive the forward and backward algorithms needed for using LP-SparseMAP as\na hidden or output layer. Experiments in three structured prediction tasks show\nbenefits compared to SparseMAP and Structured SVM.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:16:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:05:12 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 15:36:49 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "2001.04451", "submitter": "Nikita Kitaev", "authors": "Nikita Kitaev, {\\L}ukasz Kaiser, Anselm Levskaya", "title": "Reformer: The Efficient Transformer", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformer models routinely achieve state-of-the-art results on a\nnumber of tasks but training these models can be prohibitively costly,\nespecially on long sequences. We introduce two techniques to improve the\nefficiency of Transformers. For one, we replace dot-product attention by one\nthat uses locality-sensitive hashing, changing its complexity from O($L^2$) to\nO($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use\nreversible residual layers instead of the standard residuals, which allows\nstoring activations only once in the training process instead of $N$ times,\nwhere $N$ is the number of layers. The resulting model, the Reformer, performs\non par with Transformer models while being much more memory-efficient and much\nfaster on long sequences.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:38:28 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:01:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kitaev", "Nikita", ""], ["Kaiser", "\u0141ukasz", ""], ["Levskaya", "Anselm", ""]]}, {"id": "2001.04465", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Dexter R.R. Scobee, Jaime F. Fisac, S. Shankar Sastry,\n  Anca D. Dragan", "title": "LESS is More: Rethinking Probabilistic Models of Human Behavior", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3319502.3374811", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots need models of human behavior for both inferring human goals and\npreferences, and predicting what people will do. A common model is the\nBoltzmann noisily-rational decision model, which assumes people approximately\noptimize a reward function and choose trajectories in proportion to their\nexponentiated reward. While this model has been successful in a variety of\nrobotics domains, its roots lie in econometrics, and in modeling decisions\namong different discrete options, each with its own utility or reward. In\ncontrast, human trajectories lie in a continuous space, with continuous-valued\nfeatures that influence the reward function. We propose that it is time to\nrethink the Boltzmann model, and design it from the ground up to operate over\nsuch trajectory spaces. We introduce a model that explicitly accounts for\ndistances between trajectories, rather than only their rewards. Rather than\neach trajectory affecting the decision independently, similar trajectories now\naffect the decision together. We start by showing that our model better\nexplains human behavior in a user study. We then analyze the implications this\nhas for robot inference, first in toy environments where we have ground truth\nand find more accurate inference, and finally for a 7DOF robot arm learning\nfrom user demonstrations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:59:01 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Bobu", "Andreea", ""], ["Scobee", "Dexter R. R.", ""], ["Fisac", "Jaime F.", ""], ["Sastry", "S. Shankar", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2001.04488", "submitter": "Pak Lun Kevin Ding", "authors": "Pak Lun Kevin Ding, Zhiqiang Li, Yuxiang Zhou, Baoxin Li", "title": "Deep Residual Dense U-Net for Resolution Enhancement in Accelerated MRI\n  Acquisition", "comments": "SPIE Medical Imaging 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical Magnetic Resonance Imaging (MRI) scan may take 20 to 60 minutes.\nReducing MRI scan time is beneficial for both patient experience and cost\nconsiderations. Accelerated MRI scan may be achieved by acquiring less amount\nof k-space data (down-sampling in the k-space). However, this leads to lower\nresolution and aliasing artifacts for the reconstructed images. There are many\nexisting approaches for attempting to reconstruct high-quality images from\ndown-sampled k-space data, with varying complexity and performance. In recent\nyears, deep-learning approaches have been proposed for this task, and promising\nresults have been reported. Still, the problem remains challenging especially\nbecause of the high fidelity requirement in most medical applications employing\nreconstructed MRI images. In this work, we propose a deep-learning approach,\naiming at reconstructing high-quality images from accelerated MRI acquisition.\nSpecifically, we use Convolutional Neural Network (CNN) to learn the\ndifferences between the aliased images and the original images, employing a\nU-Net-like architecture. Further, a micro-architecture termed Residual Dense\nBlock (RDB) is introduced for learning a better feature representation than the\nplain U-Net. Considering the peculiarity of the down-sampled k-space data, we\nintroduce a new term to the loss function in learning, which effectively\nemploys the given k-space data during training to provide additional\nregularization on the update of the network weights. To evaluate the proposed\napproach, we compare it with other state-of-the-art methods. In both visual\ninspection and evaluation using standard metrics, the proposed approach is able\nto deliver improved performance, demonstrating its potential for providing an\neffective solution.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:01:17 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Ding", "Pak Lun Kevin", ""], ["Li", "Zhiqiang", ""], ["Zhou", "Yuxiang", ""], ["Li", "Baoxin", ""]]}, {"id": "2001.04508", "submitter": "Jones Yirui Liu", "authors": "Jones Yirui Liu and Xinghao Qiao", "title": "Conditional Variational Inference with Adaptive Truncation for Bayesian\n  Nonparametric Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scalable inference for Bayesian nonparametric models with big data is\nstill challenging. Current variational inference methods fail to characterise\nthe correlation structure among latent variables due to the mean-field setting\nand cannot infer the true posterior dimension because of the universal\ntruncation. To overcome these limitations, we build a general framework to\ninfer Bayesian nonparametric models by maximising the proposed nonparametric\nevidence lower bound, and then develop a novel approach by combining Monte\nCarlo sampling and stochastic variational inference framework. Our method has\nseveral advantages over the traditional online variational inference method.\nFirst, it achieves a smaller divergence between variational distributions and\nthe true posterior by factorising variational distributions under the\nconditional setting instead of the mean-field setting to capture the\ncorrelation pattern. Second, it reduces the risk of underfitting or overfitting\nby truncating the dimension adaptively rather than using a prespecified\ntruncated dimension for all latent variables. Third, it reduces the\ncomputational complexity by approximating the posterior functionally instead of\nupdating the stick-breaking parameters individually. We apply the proposed\nmethod on hierarchical Dirichlet process and gamma--Dirichlet process models,\ntwo essential Bayesian nonparametric models in topic analysis. The empirical\nstudy on three large datasets including arXiv, New York Times and Wikipedia\nreveals that our proposed method substantially outperforms its competitor in\nterms of lower perplexity and much clearer topic-words clustering.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:27:11 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Liu", "Jones Yirui", ""], ["Qiao", "Xinghao", ""]]}, {"id": "2001.04515", "submitter": "Chengchun Shi", "authors": "C. Shi, S. Zhang, W. Lu and R. Song", "title": "Statistical Inference of the Value Function for Reinforcement Learning\n  in Infinite Horizon Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a general technique that allows an agent to learn\nan optimal policy and interact with an environment in sequential decision\nmaking problems. The goodness of a policy is measured by its value function\nstarting from some initial state. The focus of this paper is to construct\nconfidence intervals (CIs) for a policy's value in infinite horizon settings\nwhere the number of decision points diverges to infinity. We propose to model\nthe action-value state function (Q-function) associated with a policy based on\nseries/sieve method to derive its confidence interval. When the target policy\ndepends on the observed data as well, we propose a SequentiAl Value Evaluation\n(SAVE) method to recursively update the estimated policy and its value\nestimator. As long as either the number of trajectories or the number of\ndecision points diverges to infinity, we show that the proposed CI achieves\nnominal coverage even in cases where the optimal policy is not unique.\nSimulation studies are conducted to back up our theoretical findings. We apply\nthe proposed method to a dataset from mobile health studies and find that\nreinforcement learning algorithms could help improve patient's health status. A\nPython implementation of the proposed procedure is available at\nhttps://github.com/shengzhang37/SAVE.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:42:40 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 20:28:50 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shi", "C.", ""], ["Zhang", "S.", ""], ["Lu", "W.", ""], ["Song", "R.", ""]]}, {"id": "2001.04533", "submitter": "Arun Sathanur", "authors": "Kelsey Maass, Arun V Sathanur, Arif Khan, Robert Rallo", "title": "Street-level Travel-time Estimation via Aggregated Uber Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating temporal patterns in travel times along road segments in urban\nsettings is of central importance to traffic engineers and city planners. In\nthis work, we propose a methodology to leverage coarse-grained and aggregated\ntravel time data to estimate the street-level travel times of a given\nmetropolitan area. Our main focus is to estimate travel times along the\narterial road segments where relevant data are often unavailable. The central\nidea of our approach is to leverage easy-to-obtain, aggregated data sets with\nbroad spatial coverage, such as the data published by Uber Movement, as the\nfabric over which other expensive, fine-grained datasets, such as loop counter\nand probe data, can be overlaid. Our proposed methodology uses a graph\nrepresentation of the road network and combines several techniques such as\ngraph-based routing, trip sampling, graph sparsification, and least-squares\noptimization to estimate the street-level travel times. Using sampled trips and\nweighted shortest-path routing, we iteratively solve constrained least-squares\nproblems to obtain the travel time estimates. We demonstrate our method on the\nLos Angeles metropolitan-area street network, where aggregated travel time data\nis available for trips between traffic analysis zones. Additionally, we present\ntechniques to scale our approach via a novel graph pseudo-sparsification\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:14:38 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Maass", "Kelsey", ""], ["Sathanur", "Arun V", ""], ["Khan", "Arif", ""], ["Rallo", "Robert", ""]]}, {"id": "2001.04536", "submitter": "Sifan Wang", "authors": "Sifan Wang, Yujun Teng, Paris Perdikaris", "title": "Understanding and mitigating gradient pathologies in physics-informed\n  neural networks", "comments": "28 Pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of neural networks across different scientific domains\noften involves constraining them to satisfy certain symmetries, conservation\nlaws, or other domain knowledge. Such constraints are often imposed as soft\npenalties during model training and effectively act as domain-specific\nregularizers of the empirical risk loss. Physics-informed neural networks is an\nexample of this philosophy in which the outputs of deep neural networks are\nconstrained to approximately satisfy a given set of partial differential\nequations. In this work we review recent advances in scientific machine\nlearning with a specific focus on the effectiveness of physics-informed neural\nnetworks in predicting outcomes of physical systems and discovering hidden\nphysics from noisy data. We will also identify and analyze a fundamental mode\nof failure of such approaches that is related to numerical stiffness leading to\nunbalanced back-propagated gradients during model training. To address this\nlimitation we present a learning rate annealing algorithm that utilizes\ngradient statistics during model training to balance the interplay between\ndifferent terms in composite loss functions. We also propose a novel neural\nnetwork architecture that is more resilient to such gradient pathologies. Taken\ntogether, our developments provide new insights into the training of\nconstrained neural networks and consistently improve the predictive accuracy of\nphysics-informed neural networks by a factor of 50-100x across a range of\nproblems in computational physics. All code and data accompanying this\nmanuscript are publicly available at\n\\url{https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs}.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:23:49 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Sifan", ""], ["Teng", "Yujun", ""], ["Perdikaris", "Paris", ""]]}, {"id": "2001.04561", "submitter": "Merima Kulin", "authors": "Merima Kulin, Tarik Kazaz, Ingrid Moerman, Eli de Poorter", "title": "A survey on Machine Learning-based Performance Improvement of Wireless\n  Networks: PHY, MAC and Network layer", "comments": "35 pages, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a systematic and comprehensive survey that reviews the\nlatest research efforts focused on machine learning (ML) based performance\nimprovement of wireless networks, while considering all layers of the protocol\nstack (PHY, MAC and network). First, the related work and paper contributions\nare discussed, followed by providing the necessary background on data-driven\napproaches and machine learning for non-machine learning experts to understand\nall discussed techniques. Then, a comprehensive review is presented on works\nemploying ML-based approaches to optimize the wireless communication parameters\nsettings to achieve improved network quality-of-service (QoS) and\nquality-of-experience (QoE). We first categorize these works into: radio\nanalysis, MAC analysis and network prediction approaches, followed by\nsubcategories within each. Finally, open challenges and broader perspectives\nare discussed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:33:29 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 14:44:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Kulin", "Merima", ""], ["Kazaz", "Tarik", ""], ["Moerman", "Ingrid", ""], ["de Poorter", "Eli", ""]]}, {"id": "2001.04567", "submitter": "Ali Siahkoohi", "authors": "Ali Siahkoohi, Gabrio Rizzuti, and Felix J. Herrmann", "title": "A deep-learning based Bayesian approach to seismic imaging and\n  uncertainty quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification is essential when dealing with ill-conditioned\ninverse problems due to the inherent nonuniqueness of the solution. Bayesian\napproaches allow us to determine how likely an estimation of the unknown\nparameters is via formulating the posterior distribution. Unfortunately, it is\noften not possible to formulate a prior distribution that precisely encodes our\nprior knowledge about the unknown. Furthermore, adherence to handcrafted priors\nmay greatly bias the outcome of the Bayesian analysis. To address this issue,\nwe propose to use the functional form of a randomly initialized convolutional\nneural network as an implicit structured prior, which is shown to promote\nnatural images and excludes images with unnatural noise. In order to\nincorporate the model uncertainty into the final estimate, we sample the\nposterior distribution using stochastic gradient Langevin dynamics and perform\nBayesian model averaging on the obtained samples. Our synthetic numerical\nexperiment verifies that deep priors combined with Bayesian model averaging are\nable to partially circumvent imaging artifacts and reduce the risk of\noverfitting in the presence of extreme noise. Finally, we present pointwise\nvariance of the estimates as a measure of uncertainty, which coincides with\nregions that are more difficult to image.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:46:18 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 04:10:53 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Siahkoohi", "Ali", ""], ["Rizzuti", "Gabrio", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2001.04571", "submitter": "David Zoltowski", "authors": "David M. Zoltowski, Jonathan W. Pillow, and Scott W. Linderman", "title": "Unifying and generalizing models of neural dynamics during\n  decision-making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open question in systems and computational neuroscience is how neural\ncircuits accumulate evidence towards a decision. Fitting models of\ndecision-making theory to neural activity helps answer this question, but\ncurrent approaches limit the number of these models that we can fit to neural\ndata. Here we propose a unifying framework for modeling neural activity during\ndecision-making tasks. The framework includes the canonical drift-diffusion\nmodel and enables extensions such as multi-dimensional accumulators, variable\nand collapsing boundaries, and discrete jumps. Our framework is based on\nconstraining the parameters of recurrent state-space models, for which we\nintroduce a scalable variational Laplace-EM inference algorithm. We applied the\nmodeling approach to spiking responses recorded from monkey parietal cortex\nduring two decision-making tasks. We found that a two-dimensional accumulator\nbetter captured the trial-averaged responses of a set of parietal neurons than\na single accumulator model. Next, we identified a variable lower boundary in\nthe responses of an LIP neuron during a random dot motion task.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:57:28 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zoltowski", "David M.", ""], ["Pillow", "Jonathan W.", ""], ["Linderman", "Scott W.", ""]]}, {"id": "2001.04589", "submitter": "Ciprian Chelba", "authors": "Ciprian Chelba, Mia Chen, Ankur Bapna, and Noam Shazeer", "title": "Faster Transformer Decoding: N-gram Masked Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fact that most of the information relevant to the prediction\nof target tokens is drawn from the source sentence $S=s_1, \\ldots, s_S$, we\npropose truncating the target-side window used for computing self-attention by\nmaking an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show\nthat the $N$-gram masked self-attention model loses very little in BLEU score\nfor $N$ values in the range $4, \\ldots, 8$, depending on the task.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 02:14:09 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chelba", "Ciprian", ""], ["Chen", "Mia", ""], ["Bapna", "Ankur", ""], ["Shazeer", "Noam", ""]]}, {"id": "2001.04601", "submitter": "Shi Zhao", "authors": "Shi Zhao, Ying Feng", "title": "For2For: Learning to forecast from forecasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a time series forecasting framework which combines\nstandard forecasting methods and a machine learning model. The inputs to the\nmachine learning model are not lagged values or regular time series features,\nbut instead forecasts produced by standard methods. The machine learning model\ncan be either a convolutional neural network model or a recurrent neural\nnetwork model. The intuition behind this approach is that forecasts of a time\nseries are themselves good features characterizing the series, especially when\nthe modelling purpose is forecasting. It can also be viewed as a weighted\nensemble method. Tested on the M4 competition dataset, this approach\noutperforms all submissions for quarterly series, and is more accurate than all\nbut the winning algorithm for monthly series.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 03:06:53 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhao", "Shi", ""], ["Feng", "Ying", ""]]}, {"id": "2001.04620", "submitter": "Chen Cheng", "authors": "Chen Cheng, Yuting Wei, Yuxin Chen", "title": "Tackling small eigen-gaps: Fine-grained eigenvector estimation and\n  inference under heteroscedastic noise", "comments": "69 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.NA eess.SP math.IT math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to address two fundamental challenges arising in eigenvector\nestimation and inference for a low-rank matrix from noisy observations: (1) how\nto estimate an unknown eigenvector when the eigen-gap (i.e. the spacing between\nthe associated eigenvalue and the rest of the spectrum) is particularly small;\n(2) how to perform estimation and inference on linear functionals of an\neigenvector -- a sort of \"fine-grained\" statistical reasoning that goes far\nbeyond the usual $\\ell_2$ analysis. We investigate how to address these\nchallenges in a setting where the unknown $n\\times n$ matrix is symmetric and\nthe additive noise matrix contains independent (and non-symmetric) entries.\nBased on eigen-decomposition of the asymmetric data matrix, we propose\nestimation and uncertainty quantification procedures for an unknown\neigenvector, which further allow us to reason about linear functionals of an\nunknown eigenvector. The proposed procedures and the accompanying theory enjoy\nseveral important features: (1) distribution-free (i.e. prior knowledge about\nthe noise distributions is not needed); (2) adaptive to heteroscedastic noise;\n(3) minimax optimal under Gaussian noise. Along the way, we establish optimal\nprocedures to construct confidence intervals for the unknown eigenvalues. All\nthis is guaranteed even in the presence of a small eigen-gap (up to\n$O(\\sqrt{n/\\mathrm{poly}\\log (n)})$ times smaller than the requirement in prior\ntheory), which goes significantly beyond what generic matrix perturbation\ntheory has to offer.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 04:26:10 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 08:55:58 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Cheng", "Chen", ""], ["Wei", "Yuting", ""], ["Chen", "Yuxin", ""]]}, {"id": "2001.04629", "submitter": "Fei Xue", "authors": "Fei Xue, Yanqing Zhang, Wenzhuo Zhou, Haoda Fu, Annie Qu", "title": "Multicategory Angle-based Learning for Estimating Optimal Dynamic\n  Treatment Regimes with Censored Data", "comments": "35 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal dynamic treatment regime (DTR) consists of a sequence of decision\nrules in maximizing long-term benefits, which is applicable for chronic\ndiseases such as HIV infection or cancer. In this paper, we develop a novel\nangle-based approach to search the optimal DTR under a multicategory treatment\nframework for survival data. The proposed method targets maximization the\nconditional survival function of patients following a DTR. In contrast to most\nexisting approaches which are designed to maximize the expected survival time\nunder a binary treatment framework, the proposed method solves the\nmulticategory treatment problem given multiple stages for censored data.\nSpecifically, the proposed method obtains the optimal DTR via integrating\nestimations of decision rules at multiple stages into a single multicategory\nclassification algorithm without imposing additional constraints, which is also\nmore computationally efficient and robust. In theory, we establish Fisher\nconsistency of the proposed method under regularity conditions. Our numerical\nstudies show that the proposed method outperforms competing methods in terms of\nmaximizing the conditional survival function. We apply the proposed method to\ntwo real datasets: Framingham heart study data and acquired immunodeficiency\nsyndrome (AIDS) clinical data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 05:19:15 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Xue", "Fei", ""], ["Zhang", "Yanqing", ""], ["Zhou", "Wenzhuo", ""], ["Fu", "Haoda", ""], ["Qu", "Annie", ""]]}, {"id": "2001.04639", "submitter": "Chiwoo Park", "authors": "Chiwoo Park, David J. Borth, Nicholas S. Wilson, Chad N. Hunter, and\n  Fritz J. Friedersdorf", "title": "Robust Gaussian Process Regression with a Bias Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to a robust Gaussian process (GP)\nregression. Most existing approaches replace an outlier-prone Gaussian\nlikelihood with a non-Gaussian likelihood induced from a heavy tail\ndistribution, such as the Laplace distribution and Student-t distribution.\nHowever, the use of a non-Gaussian likelihood would incur the need for a\ncomputationally expensive Bayesian approximate computation in the posterior\ninferences. The proposed approach models an outlier as a noisy and biased\nobservation of an unknown regression function, and accordingly, the likelihood\ncontains bias terms to explain the degree of deviations from the regression\nfunction. We entail how the biases can be estimated accurately with other\nhyperparameters by a regularized maximum likelihood estimation. Conditioned on\nthe bias estimates, the robust GP regression can be reduced to a standard GP\nregression problem with analytical forms of the predictive mean and variance\nestimates. Therefore, the proposed approach is simple and very computationally\nattractive. It also gives a very robust and accurate GP estimate for many\ntested scenarios. For the numerical evaluation, we perform a comprehensive\nsimulation study to evaluate the proposed approach with the comparison to the\nexisting robust GP approaches under various simulated scenarios of different\noutlier proportions and different noise levels. The approach is applied to data\nfrom two measurement systems, where the predictors are based on robust\nenvironmental parameter measurements and the response variables utilize more\ncomplex chemical sensing methods that contain a certain percentage of outliers.\nThe utility of the measurement systems and value of the environmental data are\nimproved through the computationally efficient GP regression and bias model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 06:21:51 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Park", "Chiwoo", ""], ["Borth", "David J.", ""], ["Wilson", "Nicholas S.", ""], ["Hunter", "Chad N.", ""], ["Friedersdorf", "Fritz J.", ""]]}, {"id": "2001.04643", "submitter": "Jesse Engel", "authors": "Jesse Engel, Lamtharn Hantrakul, Chenjie Gu, Adam Roberts", "title": "DDSP: Differentiable Digital Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most generative models of audio directly generate samples in one of two\ndomains: time or frequency. While sufficient to express any signal, these\nrepresentations are inefficient, as they do not utilize existing knowledge of\nhow sound is generated and perceived. A third approach (vocoders/synthesizers)\nsuccessfully incorporates strong domain knowledge of signal processing and\nperception, but has been less actively researched due to limited expressivity\nand difficulty integrating with modern auto-differentiation-based machine\nlearning methods. In this paper, we introduce the Differentiable Digital Signal\nProcessing (DDSP) library, which enables direct integration of classic signal\nprocessing elements with deep learning methods. Focusing on audio synthesis, we\nachieve high-fidelity generation without the need for large autoregressive\nmodels or adversarial losses, demonstrating that DDSP enables utilizing strong\ninductive biases without losing the expressive power of neural networks.\nFurther, we show that combining interpretable modules permits manipulation of\neach separate model component, with applications such as independent control of\npitch and loudness, realistic extrapolation to pitches not seen during\ntraining, blind dereverberation of room acoustics, transfer of extracted room\nacoustics to new environments, and transformation of timbre between disparate\nsources. In short, DDSP enables an interpretable and modular approach to\ngenerative modeling, without sacrificing the benefits of deep learning. The\nlibrary is publicly available at https://github.com/magenta/ddsp and we welcome\nfurther contributions from the community and domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 06:49:37 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Engel", "Jesse", ""], ["Hantrakul", "Lamtharn", ""], ["Gu", "Chenjie", ""], ["Roberts", "Adam", ""]]}, {"id": "2001.04676", "submitter": "Takashi Goda", "authors": "Kei Ishikawa, Takashi Goda", "title": "Efficient Debiased Evidence Estimation by Multilevel Monte Carlo\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new stochastic optimization algorithm for\nBayesian inference based on multilevel Monte Carlo (MLMC) methods. In Bayesian\nstatistics, biased estimators of the model evidence have been often used as\nstochastic objectives because the existing debiasing techniques are\ncomputationally costly to apply. To overcome this issue, we apply an MLMC\nsampling technique to construct low-variance unbiased estimators both for the\nmodel evidence and its gradient. In the theoretical analysis, we show that the\ncomputational cost required for our proposed MLMC estimator to estimate the\nmodel evidence or its gradient with a given accuracy is an order of magnitude\nsmaller than those of the previously known estimators. Our numerical\nexperiments confirm considerable computational savings compared to the\nconventional estimators. Combining our MLMC estimator with gradient-based\nstochastic optimization results in a new scalable, efficient, debiased\ninference algorithm for Bayesian statistical models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:14:24 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 23:48:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ishikawa", "Kei", ""], ["Goda", "Takashi", ""]]}, {"id": "2001.04678", "submitter": "David Balduzzi", "authors": "David Balduzzi, Wojciech M Czarnecki, Thomas W Anthony, Ian M Gemp,\n  Edward Hughes, Joel Z Leibo, Georgios Piliouras, Thore Graepel", "title": "Smooth markets: A basic mechanism for organizing gradient-based learners", "comments": "18 pages, 3 figures", "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of modern machine learning, it is becoming increasingly\nimportant to understand and control how learning algorithms interact.\nUnfortunately, negative results from game theory show there is little hope of\nunderstanding or controlling general n-player games. We therefore introduce\nsmooth markets (SM-games), a class of n-player games with pairwise zero sum\ninteractions. SM-games codify a common design pattern in machine learning that\nincludes (some) GANs, adversarial training, and other recent algorithms. We\nshow that SM-games are amenable to analysis and optimization using first-order\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:19:39 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 09:09:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Balduzzi", "David", ""], ["Czarnecki", "Wojciech M", ""], ["Anthony", "Thomas W", ""], ["Gemp", "Ian M", ""], ["Hughes", "Edward", ""], ["Leibo", "Joel Z", ""], ["Piliouras", "Georgios", ""], ["Graepel", "Thore", ""]]}, {"id": "2001.04686", "submitter": "Amir Hadifar", "authors": "Amir Hadifar, Johannes Deleu, Chris Develder, and Thomas Demeester", "title": "Block-wise Dynamic Sparseness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have achieved state of the art performance across a wide\nvariety of machine learning tasks, often with large and computation-heavy\nmodels. Inducing sparseness as a way to reduce the memory and computation\nfootprint of these models has seen significant research attention in recent\nyears. In this paper, we present a new method for \\emph{dynamic sparseness},\nwhereby part of the computations are omitted dynamically, based on the input.\nFor efficiency, we combined the idea of dynamic sparseness with block-wise\nmatrix-vector multiplications. In contrast to static sparseness, which\npermanently zeroes out selected positions in weight matrices, our method\npreserves the full network capabilities by potentially accessing any trained\nweights. Yet, matrix vector multiplications are accelerated by omitting a\npre-defined fraction of weight blocks from the matrix, based on the input.\nExperimental results on the task of language modeling, using recurrent and\nquasi-recurrent models, show that the proposed method can outperform a\nmagnitude-based static sparseness baseline. In addition, our method achieves\nsimilar language modeling perplexities as the dense baseline, at half the\ncomputational cost at inference time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:03:21 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hadifar", "Amir", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""], ["Demeester", "Thomas", ""]]}, {"id": "2001.04689", "submitter": "Nikolai Zolotykh", "authors": "Viktor Moskalenko, Nikolai Zolotykh, Grigory Osipov", "title": "Deep Learning for ECG Segmentation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-030-30425-6_29", "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for electrocardiogram (ECG) segmentation using a\nUNet-like full-convolutional neural network. The algorithm receives an\narbitrary sampling rate ECG signal as an input, and gives a list of onsets and\noffsets of P and T waves and QRS complexes as output. Our method of\nsegmentation differs from others in speed, a small number of parameters and a\ngood generalization: it is adaptive to different sampling rates and it is\ngeneralized to various types of ECG monitors. The proposed approach is superior\nto other state-of-the-art segmentation methods in terms of quality. In\nparticular, F1-measures for detection of onsets and offsets of P and T waves\nand for QRS-complexes are at least 97.8%, 99.5%, and 99.9%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:05:09 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Moskalenko", "Viktor", ""], ["Zolotykh", "Nikolai", ""], ["Osipov", "Grigory", ""]]}, {"id": "2001.04694", "submitter": "Linh Tran", "authors": "Linh Tran, Bastiaan S. Veeling, Kevin Roth, Jakub Swiatkowski, Joshua\n  V. Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Sebastian Nowozin,\n  Rodolphe Jenatton", "title": "Hydra: Preserving Ensemble Diversity for Model Distillation", "comments": "Accepted to ICML 2020 Workshop on Uncertainty and Robustness in Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of models have been empirically shown to improve predictive\nperformance and to yield robust measures of uncertainty. However, they are\nexpensive in computation and memory. Therefore, recent research has focused on\ndistilling ensembles into a single compact model, reducing the computational\nand memory burden of the ensemble while trying to preserve its predictive\nbehavior. Most existing distillation formulations summarize the ensemble by\ncapturing its average predictions. As a result, the diversity of the ensemble\npredictions, stemming from each member, is lost. Thus, the distilled model\ncannot provide a measure of uncertainty comparable to that of the original\nensemble. To retain more faithfully the diversity of the ensemble, we propose a\ndistillation method based on a single multi-headed neural network, which we\nrefer to as Hydra. The shared body network learns a joint feature\nrepresentation that enables each head to capture the predictive behavior of\neach ensemble member. We demonstrate that with a slight increase in parameter\ncount, Hydra improves distillation performance on classification and regression\nsettings while capturing the uncertainty behavior of the original ensemble over\nboth in-domain and out-of-distribution tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:13:52 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 11:25:46 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Tran", "Linh", ""], ["Veeling", "Bastiaan S.", ""], ["Roth", "Kevin", ""], ["Swiatkowski", "Jakub", ""], ["Dillon", "Joshua V.", ""], ["Snoek", "Jasper", ""], ["Mandt", "Stephan", ""], ["Salimans", "Tim", ""], ["Nowozin", "Sebastian", ""], ["Jenatton", "Rodolphe", ""]]}, {"id": "2001.04733", "submitter": "Ivan Kiskin", "authors": "Ivan Kiskin, Adam D. Cobb, Lawrence Wang, Stephen Roberts", "title": "HumBug Zooniverse: a crowd-sourced acoustic mosquito dataset", "comments": "Awarded Best Paper at the 2019 NeurIPS ML4D workshop. Accepted at\n  ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mosquitoes are the only known vector of malaria, which leads to hundreds of\nthousands of deaths each year. Understanding the number and location of\npotential mosquito vectors is of paramount importance to aid the reduction of\nmalaria transmission cases. In recent years, deep learning has become widely\nused for bioacoustic classification tasks. In order to enable further research\napplications in this field, we release a new dataset of mosquito audio\nrecordings. With over a thousand contributors, we obtained 195,434 labels of\ntwo second duration, of which approximately 10 percent signify mosquito events.\nWe present an example use of the dataset, in which we train a convolutional\nneural network on log-Mel features, showcasing the information content of the\nlabels. We hope this will become a vital resource for those researching all\naspects of malaria, and add to the existing audio datasets for bioacoustic\ndetection and signal processing.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 12:06:17 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:11:11 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kiskin", "Ivan", ""], ["Cobb", "Adam D.", ""], ["Wang", "Lawrence", ""], ["Roberts", "Stephen", ""]]}, {"id": "2001.04754", "submitter": "Yao Zhang", "authors": "Yao Zhang, Alexis Bellot, Mihaela van der Schaar", "title": "Learning Overlapping Representations for the Estimation of\n  Individualized Treatment Effects", "comments": null, "journal-ref": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of making an intervention depends on its potential benefit or harm\nin comparison to alternatives. Estimating the likely outcome of alternatives\nfrom observational data is a challenging problem as all outcomes are never\nobserved, and selection bias precludes the direct comparison of differently\nintervened groups. Despite their empirical success, we show that algorithms\nthat learn domain-invariant representations of inputs (on which to make\npredictions) are often inappropriate, and develop generalization bounds that\ndemonstrate the dependence on domain overlap and highlight the need for\ninvertible latent maps. Based on these results, we develop a deep kernel\nregression algorithm and posterior regularization framework that substantially\noutperforms the state-of-the-art on a variety of benchmarks data sets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 12:56:29 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:18:44 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 12:07:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Yao", ""], ["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.04756", "submitter": "Shiqiang Wang", "authors": "Pengchao Han, Shiqiang Wang, Kin K. Leung", "title": "Adaptive Gradient Sparsification for Efficient Federated Learning: An\n  Online Learning Approach", "comments": "Accepted at IEEE ICDCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging technique for training machine\nlearning models using geographically dispersed data collected by local\nentities. It includes local computation and synchronization steps. To reduce\nthe communication overhead and improve the overall efficiency of FL, gradient\nsparsification (GS) can be applied, where instead of the full gradient, only a\nsmall subset of important elements of the gradient is communicated. Existing\nwork on GS uses a fixed degree of gradient sparsity for i.i.d.-distributed data\nwithin a datacenter. In this paper, we consider adaptive degree of sparsity and\nnon-i.i.d. local datasets. We first present a fairness-aware GS method which\nensures that different clients provide a similar amount of updates. Then, with\nthe goal of minimizing the overall training time, we propose a novel online\nlearning formulation and algorithm for automatically determining the\nnear-optimal communication and computation trade-off that is controlled by the\ndegree of gradient sparsity. The online learning algorithm uses an estimated\nsign of the derivative of the objective function, which gives a regret bound\nthat is asymptotically equal to the case where exact derivative is available.\nExperiments with real datasets confirm the benefits of our proposed approaches,\nshowing up to $40\\%$ improvement in model accuracy for a finite training time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:09:23 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 17:56:09 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 16:34:48 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Han", "Pengchao", ""], ["Wang", "Shiqiang", ""], ["Leung", "Kin K.", ""]]}, {"id": "2001.04761", "submitter": "Jozsef Nemeth", "authors": "Jozsef Nemeth", "title": "Adversarial Disentanglement with Grouped Observations", "comments": "Accepted at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the disentanglement of the representations of the relevant\nattributes of the data (content) from all other factors of variations (style)\nusing Variational Autoencoders. Some recent works addressed this problem by\nutilizing grouped observations, where the content attributes are assumed to be\ncommon within each group, while there is no any supervised information on the\nstyle factors. In many cases, however, these methods fail to prevent the models\nfrom using the style variables to encode content related features as well. This\nwork supplements these algorithms with a method that eliminates the content\ninformation in the style representations. For that purpose the training\nobjective is augmented to minimize an appropriately defined mutual information\nterm in an adversarial way. Experimental results and comparisons on image\ndatasets show that the resulting method can efficiently separate the content\nand style related attributes and generalizes to unseen data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:21:25 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Nemeth", "Jozsef", ""]]}, {"id": "2001.04769", "submitter": "Kumar Vijay Mishra", "authors": "M. Ashok Kumar and Kumar Vijay Mishra", "title": "Cram\\'er-Rao Lower Bounds Arising from Generalized Csisz\\'ar Divergences", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the geometry of probability distributions with respect to a\ngeneralized family of Csisz\\'ar $f$-divergences. A member of this family is the\nrelative $\\alpha$-entropy which is also a R\\'enyi analog of relative entropy in\ninformation theory and known as logarithmic or projective power divergence in\nstatistics. We apply Eguchi's theory to derive the Fisher information metric\nand the dual affine connections arising from these generalized divergence\nfunctions. This enables us to arrive at a more widely applicable version of the\nCram\\'{e}r-Rao inequality, which provides a lower bound for the variance of an\nestimator for an escort of the underlying parametric probability distribution.\nWe then extend the Amari-Nagaoka's dually flat structure of the exponential and\nmixer models to other distributions with respect to the aforementioned\ngeneralized metric. We show that these formulations lead us to find unbiased\nand efficient estimators for the escort model. Finally, we compare our work\nwith prior results on generalized Cram\\'er-Rao inequalities that were derived\nfrom non-information-geometric frameworks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:41:13 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 05:24:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kumar", "M. Ashok", ""], ["Mishra", "Kumar Vijay", ""]]}, {"id": "2001.04782", "submitter": "Thomas Haugland Johansen", "authors": "Thomas Haugland Johansen and Steffen Aagaard S{\\o}rensen", "title": "Towards detection and classification of microscopic foraminifera using\n  transfer learning", "comments": "6 pages, 5 figures. To be published in proceedings of Northern Lights\n  Deep Learning Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Foraminifera are single-celled marine organisms, which may have a planktic or\nbenthic lifestyle. During their life cycle they construct shells consisting of\none or more chambers, and these shells remain as fossils in marine sediments.\nClassifying and counting these fossils have become an important tool in e.g.\noceanography and climatology. Currently the process of identifying and counting\nmicrofossils is performed manually using a microscope and is very time\nconsuming. Developing methods to automate this process is therefore considered\nimportant across a range of research fields. The first steps towards developing\na deep learning model that can detect and classify microscopic foraminifera are\nproposed. The proposed model is based on a VGG16 model that has been pretrained\non the ImageNet dataset, and adapted to the foraminifera task using transfer\nlearning. Additionally, a novel image dataset consisting of microscopic\nforaminifera and sediments from the Barents Sea region is introduced.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:57:08 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Johansen", "Thomas Haugland", ""], ["S\u00f8rensen", "Steffen Aagaard", ""]]}, {"id": "2001.04786", "submitter": "Mingyi Hong", "authors": "Tsung-Hui Chang, Mingyi Hong, Hoi-To Wai, Xinwei Zhang, and Songtao Lu", "title": "Distributed Learning in the Non-Convex World: From Batch to Streaming\n  Data, and Beyond", "comments": "Submitted to IEEE Signal Processing Magazine Special Issue on\n  Distributed, Streaming Machine Learning; THC, MH, HTW contributed equally", "journal-ref": null, "doi": "10.1109/MSP.2020.2970170", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning has become a critical enabler of the massively connected\nworld envisioned by many. This article discusses four key elements of scalable\ndistributed processing and real-time intelligence --- problems, data,\ncommunication and computation. Our aim is to provide a fresh and unique\nperspective about how these elements should work together in an effective and\ncoherent manner. In particular, we {provide a selective review} about the\nrecent techniques developed for optimizing non-convex models (i.e., problem\nclasses), processing batch and streaming data (i.e., data types), over the\nnetworks in a distributed manner (i.e., communication and computation\nparadigm). We describe the intuitions and connections behind a core set of\npopular distributed algorithms, emphasizing how to trade off between\ncomputation and communication costs. Practical issues and future research\ndirections will also be discussed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 14:11:32 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Chang", "Tsung-Hui", ""], ["Hong", "Mingyi", ""], ["Wai", "Hoi-To", ""], ["Zhang", "Xinwei", ""], ["Lu", "Songtao", ""]]}, {"id": "2001.04794", "submitter": "Francesco Bardozzo", "authors": "Francesco Bardozzo, Pietro Lio', Roberto Tagliaferri", "title": "A machine learning approach to investigate regulatory control circuits\n  in bacterial metabolic pathways", "comments": "5 pages, 3 figures", "journal-ref": "CIBB 2016 13th International Meeting, CIBB 2016, Stirling, UK,\n  September 1-3, 2016, Revised Selected Papers Springer, 2017, Vol. 10477 pp\n  22-26", "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a machine learning approach for identifying the multi-omics\nmetabolic regulatory control circuits inside the pathways is described.\nTherefore, the identification of bacterial metabolic pathways that are more\nregulated than others in term of their multi-omics follows from the analysis of\nthese circuits . This is a consequence of the alternation of the omic values of\ncodon usage and protein abundance along with the circuits. In this work, the\nE.Coli's Glycolysis and its multi-omic circuit features are shown as an\nexample.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:04:26 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Bardozzo", "Francesco", ""], ["Lio'", "Pietro", ""], ["Tagliaferri", "Roberto", ""]]}, {"id": "2001.04798", "submitter": "Adenilton Jos\\'e da Silva", "authors": "Rodrigo S. Sousa, Priscila G.M. dos Santos, Tiago M.L. Veras, Wilson\n  R. de Oliveira and Adenilton J. da Silva", "title": "Parametric Probabilistic Quantum Memory", "comments": null, "journal-ref": "Neurocomputing 416 (2020): 360-369", "doi": "10.1016/j.neucom.2020.01.116", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Quantum Memory (PQM) is a data structure that computes the\ndistance from a binary input to all binary patterns stored in superposition on\nthe memory. This data structure allows the development of heuristics to speed\nup artificial neural networks architecture selection. In this work, we propose\nan improved parametric version of the PQM to perform pattern classification,\nand we also present a PQM quantum circuit suitable for Noisy Intermediate Scale\nQuantum (NISQ) computers. We present a classical evaluation of a parametric PQM\nnetwork classifier on public benchmark datasets. We also perform experiments to\nverify the viability of PQM on a 5-qubit quantum computer.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 11:41:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sousa", "Rodrigo S.", ""], ["Santos", "Priscila G. M. dos", ""], ["Veras", "Tiago M. L.", ""], ["de Oliveira", "Wilson R.", ""], ["da Silva", "Adenilton J.", ""]]}, {"id": "2001.04802", "submitter": "Amir Mosavi Prof", "authors": "Amin Kazemian-Kale-Kale, Azadeh Gholami, Mohammad Rezaie-Balf, Amir\n  Mosavi, Ahmed A Sattar, Bahram Gharabaghi, Hossein Bonakdari", "title": "A Bayesian Monte-Carlo Uncertainty Model for Assessment of Shear Stress\n  Entropy", "comments": "48 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The entropy models have been recently adopted in many studies to evaluate the\ndistribution of the shear stress in circular channels. However, the uncertainty\nin their predictions and their reliability remains an open question. We present\na novel method to evaluate the uncertainty of four popular entropy models,\nincluding Shannon, Shannon-Power Low (PL), Tsallis, and Renyi, in shear stress\nestimation in circular channels. The Bayesian Monte-Carlo (BMC) uncertainty\nmethod is simplified considering a 95% Confidence Bound (CB). We developed a\nnew statistic index called as FREEopt-based OCB (FOCB) using the statistical\nindices Forecasting Range of Error Estimation (FREE) and the percentage of\nobserved data in the CB (Nin), which integrates their combined effect. The\nShannon and Shannon PL entropies had close values of the FOCB equal to 8.781\nand 9.808, respectively, had the highest certainty in the calculation of shear\nstress values in circular channels followed by traditional uniform flow shear\nstress and Tsallis models with close values of 14.491 and 14.895, respectively.\nHowever, Renyi entropy with much higher values of FOCB equal to 57.726 has less\ncertainty in the estimation of shear stress than other models. Using the\npresented results in this study, the amount of confidence in entropy methods in\nthe calculation of shear stress to design and implement different types of open\nchannels and their stability is determined.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 22:46:59 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Kazemian-Kale-Kale", "Amin", ""], ["Gholami", "Azadeh", ""], ["Rezaie-Balf", "Mohammad", ""], ["Mosavi", "Amir", ""], ["Sattar", "Ahmed A", ""], ["Gharabaghi", "Bahram", ""], ["Bonakdari", "Hossein", ""]]}, {"id": "2001.04825", "submitter": "Shahpar Yakhchi", "authors": "Shahpar Yakhchi (1), Amin Beheshti (1), Seyed Mohssen Ghafari (1),\n  Mehmet Orgun (1) ((1) Macquarie University- Sydney-Australia)", "title": "Enabling the Analysis of Personality Aspects in Recommender Systems", "comments": "This article contains 3 figures and 14 pages", "journal-ref": "Twenty-Third Pacific Asia Conference on Information Systems, China\n  2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Recommender Systems mainly focus on exploiting users' feedback,\ne.g., ratings, and reviews on common items to detect similar users. Thus, they\nmight fail when there are no common items of interest among users. We call this\nproblem the Data Sparsity With no Feedback on Common Items (DSW-n-FCI).\nPersonality-based recommender systems have shown a great success to identify\nsimilar users based on their personality types. However, there are only a few\npersonality-based recommender systems in the literature which either discover\npersonality explicitly through filling a questionnaire that is a tedious task,\nor neglect the impact of users' personal interests and level of knowledge, as a\nkey factor to increase recommendations' acceptance. Differently, we identifying\nusers' personality type implicitly with no burden on users and incorporate it\nalong with users' personal interests and their level of knowledge. Experimental\nresults on a real-world dataset demonstrate the effectiveness of our model,\nespecially in DSW-n-FCI situations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 23:02:07 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Yakhchi", "Shahpar", "", "Macquarie University- Sydney-Australia"], ["Beheshti", "Amin", "", "Macquarie University- Sydney-Australia"], ["Ghafari", "Seyed Mohssen", "", "Macquarie University- Sydney-Australia"], ["Orgun", "Mehmet", "", "Macquarie University- Sydney-Australia"]]}, {"id": "2001.04828", "submitter": "Kaushik Chakrabarti", "authors": "Kaushik Chakrabarti, Zhimin Chen, Siamak Shakeri, Guihong Cao, Surajit\n  Chaudhuri", "title": "TableQnA: Answering List Intent Queries With Web Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web contains a vast corpus of HTML tables. They can be used to provide\ndirect answers to many web queries. We focus on answering two classes of\nqueries with those tables: those seeking lists of entities (e.g., `cities in\ncalifornia') and those seeking superlative entities (e.g., `largest city in\ncalifornia'). The main challenge is to achieve high precision with significant\ncoverage. Existing approaches train machine learning models to select the\nanswer from the candidates; they rely on textual match features between the\nquery and the content of the table along with features capturing table\nquality/importance. These features alone are inadequate for achieving the above\ngoals. Our main insight is that we can improve precision by (i) first\nextracting intent (structured information) from the query for the above query\nclasses and (ii) then performing structure-aware matching (instead of just\ntextual matching) between the extracted intent and the candidates to select the\nanswer. We model (i) as a sequence tagging task. We leverage state-of-the-art\ndeep neural network models with word embeddings. The model requires large scale\ntraining data which is expensive to obtain via manual labeling; we therefore\ndevelop a novel method to automatically generate the training data. For (ii),\nwe develop novel features to compute structure-aware match and train a machine\nlearning model. Our experiments on real-life web search queries show that (i)\nour intent extractor for list and superlative intent queries has significantly\nhigher precision and coverage compared with baseline approaches and (ii) our\ntable answer selector significantly outperforms the state-of-the-art baseline\napproach. This technology has been used in production by Microsoft's Bing\nsearch engine since 2016.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 01:43:54 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chakrabarti", "Kaushik", ""], ["Chen", "Zhimin", ""], ["Shakeri", "Siamak", ""], ["Cao", "Guihong", ""], ["Chaudhuri", "Surajit", ""]]}, {"id": "2001.04829", "submitter": "Gavin Graham", "authors": "Gavin H. Graham and Yan Chen", "title": "Bayesian Inversion Of Generative Models For Geologic Storage Of Carbon\n  Dioxide", "comments": "Submitted to the Machine Learning and the Physical Sciences Workshop\n  (NeurIPS 2019), Vancouver, Canada. 5 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carbon capture and storage (CCS) can aid decarbonization of the atmosphere to\nlimit further global temperature increases. A framework utilizing unsupervised\nlearning is used to generate a range of subsurface geologic volumes to\ninvestigate potential sites for long-term storage of carbon dioxide. Generative\nadversarial networks are used to create geologic volumes, with a further neural\nnetwork used to sample the posterior distribution of a trained Generator\nconditional to sparsely sampled physical measurements. These generative models\nare further conditioned to historic dynamic fluid flow data through Bayesian\ninversion to improve the resolution of the forecast of the storage capacity of\ninjected carbon dioxide.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:09:27 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Graham", "Gavin H.", ""], ["Chen", "Yan", ""]]}, {"id": "2001.04831", "submitter": "Gabriel de Souza Pereira Moreira", "authors": "Gabriel de Souza Pereira Moreira", "title": "CHAMELEON: A Deep Learning Meta-Architecture for News Recommender\n  Systems [Phd. Thesis]", "comments": "Phd. Thesis presented on Dec. 09, 2019 to the Instituto Tecnol\\'ogico\n  de Aeron\\'autica (ITA), in partial fulfillment of the requirements for the\n  degree of Doctor of Science in the Graduate Program of Electronics and\n  Computing Engineering, Field of Informatics", "journal-ref": null, "doi": null, "report-no": "DCTA/ITA/TD-035/2019", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems (RS) have became a popular research topic and, since\n2016, Deep Learning methods and techniques have been increasingly explored in\nthis area. News RS are aimed to personalize users experiences and help them\ndiscover relevant articles from a large and dynamic search space. The main\ncontribution of this research was named CHAMELEON, a Deep Learning\nmeta-architecture designed to tackle the specific challenges of news\nrecommendation. It consists of a modular reference architecture which can be\ninstantiated using different neural building blocks. As information about\nusers' past interactions is scarce in the news domain, the user context can be\nleveraged to deal with the user cold-start problem. Articles' content is also\nimportant to tackle the item cold-start problem. Additionally, the temporal\ndecay of items (articles) relevance is very accelerated in the news domain.\nFurthermore, external breaking events may temporally attract global readership\nattention, a phenomenon generally known as concept drift in machine learning.\nAll those characteristics are explicitly modeled on this research by a\ncontextual hybrid session-based recommendation approach using Recurrent Neural\nNetworks. The task addressed by this research is session-based news\nrecommendation, i.e., next-click prediction using only information available in\nthe current user session. A method is proposed for a realistic temporal offline\nevaluation of such task, replaying the stream of user clicks and fresh articles\nbeing continuously published in a news portal. Experiments performed with two\nlarge datasets have shown the effectiveness of the CHAMELEON for news\nrecommendation on many quality factors such as accuracy, item coverage,\nnovelty, and reduced item cold-start problem, when compared to other\ntraditional and state-of-the-art session-based recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 13:40:56 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Moreira", "Gabriel de Souza Pereira", ""]]}, {"id": "2001.04832", "submitter": "Sami Khenissi", "authors": "Sami Khenissi and Olfa Nasraoui", "title": "Modeling and Counteracting Exposure Bias in Recommender Systems", "comments": "9 figures and one table. The paper has 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What we discover and see online, and consequently our opinions and decisions,\nare becoming increasingly affected by automated machine learned predictions.\nSimilarly, the predictive accuracy of learning machines heavily depends on the\nfeedback data that we provide them. This mutual influence can lead to\nclosed-loop interactions that may cause unknown biases which can be exacerbated\nafter several iterations of machine learning predictions and user feedback.\nMachine-caused biases risk leading to undesirable social effects ranging from\npolarization to unfairness and filter bubbles.\n  In this paper, we study the bias inherent in widely used recommendation\nstrategies such as matrix factorization. Then we model the exposure that is\nborne from the interaction between the user and the recommender system and\npropose new debiasing strategies for these systems.\n  Finally, we try to mitigate the recommendation system bias by engineering\nsolutions for several state of the art recommender system models.\n  Our results show that recommender systems are biased and depend on the prior\nexposure of the user. We also show that the studied bias iteratively decreases\ndiversity in the output recommendations. Our debiasing method demonstrates the\nneed for alternative recommendation strategies that take into account the\nexposure process in order to reduce bias.\n  Our research findings show the importance of understanding the nature of and\ndealing with bias in machine learning models such as recommender systems that\ninteract directly with humans, and are thus causing an increasing influence on\nhuman discovery and decision making\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 00:12:34 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Khenissi", "Sami", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2001.04833", "submitter": "L\\'eonard Torossian", "authors": "L\\'eonard Torossian, Victor Picheny, and Nicolas Durrande", "title": "Bayesian Quantile and Expectile Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is widely used to optimise stochastic black box\nfunctions. While most strategies are focused on optimising conditional\nexpectations, a large variety of applications require risk-averse decisions and\nalternative criteria accounting for the distribution tails need to be\nconsidered. In this paper, we propose new variational models for Bayesian\nquantile and expectile regression that are well-suited for heteroscedastic\nsettings. Our models consist of two latent Gaussian processes accounting\nrespectively for the conditional quantile (or expectile) and variance that are\nchained through asymmetric likelihood functions. Furthermore, we propose two\nBayesian optimisation strategies, either derived from a GP-UCB or Thompson\nsampling, that are tailored to such models and that can accommodate large\nbatches of points. As illustrated in the experimental section, the proposed\napproach clearly outperforms the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:51:21 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Torossian", "L\u00e9onard", ""], ["Picheny", "Victor", ""], ["Durrande", "Nicolas", ""]]}, {"id": "2001.04850", "submitter": "Kimessha Paupamah", "authors": "Kimessha Paupamah, Steven James, Richard Klein", "title": "Quantisation and Pruning for Neural Network Compression and\n  Regularisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically too computationally expensive to run in\nreal-time on consumer-grade hardware and low-powered devices. In this paper, we\ninvestigate reducing the computational and memory requirements of neural\nnetworks through network pruning and quantisation. We examine their efficacy on\nlarge networks like AlexNet compared to recent compact architectures:\nShuffleNet and MobileNet. Our results show that pruning and quantisation\ncompresses these networks to less than half their original size and improves\ntheir efficiency, particularly on MobileNet with a 7x speedup. We also\ndemonstrate that pruning, in addition to reducing the number of parameters in a\nnetwork, can aid in the correction of overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:22:34 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Paupamah", "Kimessha", ""], ["James", "Steven", ""], ["Klein", "Richard", ""]]}, {"id": "2001.04872", "submitter": "Peter Sorrenson", "authors": "Peter Sorrenson, Carsten Rother, Ullrich K\\\"othe", "title": "Disentanglement by Nonlinear ICA with General Incompressible-flow\n  Networks (GIN)", "comments": "23 pages, 15 figures, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question of representation learning asks under which conditions it\nis possible to reconstruct the true latent variables of an arbitrarily complex\ngenerative process. Recent breakthrough work by Khemakhem et al. (2019) on\nnonlinear ICA has answered this question for a broad class of conditional\ngenerative processes. We extend this important result in a direction relevant\nfor application to real-world data. First, we generalize the theory to the case\nof unknown intrinsic problem dimension and prove that in some special (but not\nvery restrictive) cases, informative latent variables will be automatically\nseparated from noise by an estimating model. Furthermore, the recovered\ninformative latent variables will be in one-to-one correspondence with the true\nlatent variables of the generating process, up to a trivial component-wise\ntransformation. Second, we introduce a modification of the RealNVP invertible\nneural network architecture (Dinh et al. (2016)) which is particularly suitable\nfor this type of problem: the General Incompressible-flow Network (GIN).\nExperiments on artificial data and EMNIST demonstrate that theoretical\npredictions are indeed verified in practice. In particular, we provide a\ndetailed set of exactly 22 informative latent variables extracted from EMNIST.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:25:08 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Sorrenson", "Peter", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2001.04878", "submitter": "Lior Wolf", "authors": "Etai Littwin, Lior Wolf", "title": "On the Convex Behavior of Deep Neural Networks in Relation to the\n  Layers' Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hessian of neural networks can be decomposed into a sum of two matrices:\n(i) the positive semidefinite generalized Gauss-Newton matrix G, and (ii) the\nmatrix H containing negative eigenvalues. We observe that for wider networks,\nminimizing the loss with the gradient descent optimization maneuvers through\nsurfaces of positive curvatures at the start and end of training, and close to\nzero curvatures in between. In other words, it seems that during crucial parts\nof the training process, the Hessian in wide networks is dominated by the\ncomponent G. To explain this phenomenon, we show that when initialized using\ncommon methodologies, the gradients of over-parameterized networks are\napproximately orthogonal to H, such that the curvature of the loss surface is\nstrictly positive in the direction of the gradient.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:30:01 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Littwin", "Etai", ""], ["Wolf", "Lior", ""]]}, {"id": "2001.04907", "submitter": "Dmitry Krotov", "authors": "Chaitanya K. Ryali, John J. Hopfield, Leopold Grinberg, Dmitry Krotov", "title": "Bio-Inspired Hashing for Unsupervised Similarity Search", "comments": "Accepted for publication in ICML 2020", "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2020, pp.8739-8750", "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fruit fly Drosophila's olfactory circuit has inspired a new locality\nsensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH\nalgorithms that produce low dimensional hash codes, FlyHash produces sparse\nhigh-dimensional hash codes and has also been shown to have superior empirical\nperformance compared to classical LSH algorithms in similarity search. However,\nFlyHash uses random projections and cannot learn from data. Building on\ninspiration from FlyHash and the ubiquity of sparse expansive representations\nin neurobiology, our work proposes a novel hashing algorithm BioHash that\nproduces sparse high dimensional hash codes in a data-driven manner. We show\nthat BioHash outperforms previously published benchmarks for various hashing\nmethods. Since our learning algorithm is based on a local and biologically\nplausible synaptic plasticity rule, our work provides evidence for the proposal\nthat LSH might be a computational reason for the abundance of sparse expansive\nmotifs in a variety of biological systems. We also propose a convolutional\nvariant BioConvHash that further improves performance. From the perspective of\ncomputer science, BioHash and BioConvHash are fast, scalable and yield\ncompressed binary representations that are useful for similarity search.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:04:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:29:56 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ryali", "Chaitanya K.", ""], ["Hopfield", "John J.", ""], ["Grinberg", "Leopold", ""], ["Krotov", "Dmitry", ""]]}, {"id": "2001.04918", "submitter": "Burak \\c{C}akmak", "authors": "Burak \\c{C}akmak and Manfred Opper", "title": "Analysis of Bayesian Inference Algorithms by the Dynamical Functional\n  Approach", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ab8ff4", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the dynamics of an algorithm for approximate inference with large\nGaussian latent variable models in a student-teacher scenario. To model\nnontrivial dependencies between the latent variables, we assume random\ncovariance matrices drawn from rotation invariant ensembles. For the case of\nperfect data-model matching, the knowledge of static order parameters derived\nfrom the replica method allows us to obtain efficient algorithmic updates in\nterms of matrix-vector multiplications with a fixed matrix. Using the dynamical\nfunctional approach, we obtain an exact effective stochastic process in the\nthermodynamic limit for a single node. From this, we obtain closed-form\nexpressions for the rate of the convergence. Analytical results are excellent\nagreement with simulations of single instances of large models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:22:02 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["\u00c7akmak", "Burak", ""], ["Opper", "Manfred", ""]]}, {"id": "2001.04935", "submitter": "Roei Schuster", "authors": "Roei Schuster, Tal Schuster, Yoav Meri, Vitaly Shmatikov", "title": "Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning", "comments": "Accepted at IEEE S&P 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings, i.e., low-dimensional vector representations such as GloVe\nand SGNS, encode word \"meaning\" in the sense that distances between words'\nvectors correspond to their semantic proximity. This enables transfer learning\nof semantics for a variety of natural language processing tasks.\n  Word embeddings are typically trained on large public corpora such as\nWikipedia or Twitter. We demonstrate that an attacker who can modify the corpus\non which the embedding is trained can control the \"meaning\" of new and existing\nwords by changing their locations in the embedding space. We develop an\nexplicit expression over corpus features that serves as a proxy for distance\nbetween words and establish a causative relationship between its values and\nembedding distances. We then show how to use this relationship for two\nadversarial objectives: (1) make a word a top-ranked neighbor of another word,\nand (2) move a word from one semantic cluster to another.\n  An attack on the embedding can affect diverse downstream tasks, demonstrating\nfor the first time the power of data poisoning in transfer learning scenarios.\nWe use this attack to manipulate query expansion in information retrieval\nsystems such as resume search, make certain names more or less visible to named\nentity recognition models, and cause new words to be translated to a particular\ntarget word regardless of the language. Finally, we show how the attacker can\ngenerate linguistically likely corpus modifications, thus fooling defenses that\nattempt to filter implausible sentences from the corpus using a language model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:48:52 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Schuster", "Roei", ""], ["Schuster", "Tal", ""], ["Meri", "Yoav", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2001.04942", "submitter": "David Barber", "authors": "David Barber", "title": "Private Machine Learning via Randomised Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general learning framework for private machine learning based\non randomised response. Our assumption is that all actors are potentially\nadversarial and as such we trust only to release a single noisy version of an\nindividual's datapoint. We discuss a general approach that forms a consistent\nway to estimate the true underlying machine learning model and demonstrate this\nin the case of logistic regression.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:56:16 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 19:13:28 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Barber", "David", ""]]}, {"id": "2001.04959", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Valery A. Makarov, Ivan Y. Tyukin", "title": "High--Dimensional Brain in a High-Dimensional World: Blessing of\n  Dimensionality", "comments": "18 pages, 5 figures", "journal-ref": "Entropy 2020, 22(1), 82", "doi": "10.3390/e22010082", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional data and high-dimensional representations of reality are\ninherent features of modern Artificial Intelligence systems and applications of\nmachine learning. The well-known phenomenon of the \"curse of dimensionality\"\nstates: many problems become exponentially difficult in high dimensions.\nRecently, the other side of the coin, the \"blessing of dimensionality\", has\nattracted much attention. It turns out that generic high-dimensional datasets\nexhibit fairly simple geometric properties. Thus, there is a fundamental\ntradeoff between complexity and simplicity in high dimensional spaces. Here we\npresent a brief explanatory review of recent ideas, results and hypotheses\nabout the blessing of dimensionality and related simplifying effects relevant\nto machine learning and neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:40:51 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Makarov", "Valery A.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2001.04974", "submitter": "Chuteng Zhou", "authors": "Chuteng Zhou, Prad Kadambi, Matthew Mattina, Paul N. Whatmough", "title": "Noisy Machines: Understanding Noisy Neural Networks and Enhancing\n  Robustness to Analog Hardware Errors Using Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning has brought forth a wave of interest in computer\nhardware design to better meet the high demands of neural network inference. In\nparticular, analog computing hardware has been heavily motivated specifically\nfor accelerating neural networks, based on either electronic, optical or\nphotonic devices, which may well achieve lower power consumption than\nconventional digital electronics. However, these proposed analog accelerators\nsuffer from the intrinsic noise generated by their physical components, which\nmakes it challenging to achieve high accuracy on deep neural networks. Hence,\nfor successful deployment on analog accelerators, it is essential to be able to\ntrain deep neural networks to be robust to random continuous noise in the\nnetwork weights, which is a somewhat new challenge in machine learning. In this\npaper, we advance the understanding of noisy neural networks. We outline how a\nnoisy neural network has reduced learning capacity as a result of loss of\nmutual information between its input and output. To combat this, we propose\nusing knowledge distillation combined with noise injection during training to\nachieve more noise robust networks, which is demonstrated experimentally across\ndifferent networks and datasets, including ImageNet. Our method achieves models\nwith as much as two times greater noise tolerance compared with the previous\nbest attempts, which is a significant step towards making analog hardware\npractical for deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:59:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhou", "Chuteng", ""], ["Kadambi", "Prad", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2001.04980", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Rohan Kohli, Shrimai Prabhumoye", "title": "Modeling Product Search Relevance in e-Commerce", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of e-Commerce, online product search has emerged as a\npopular and effective paradigm for customers to find desired products and\nengage in online shopping. However, there is still a big gap between the\nproducts that customers really desire to purchase and relevance of products\nthat are suggested in response to a query from the customer. In this paper, we\npropose a robust way of predicting relevance scores given a search query and a\nproduct, using techniques involving machine learning, natural language\nprocessing and information retrieval. We compare conventional information\nretrieval models such as BM25 and Indri with deep learning models such as\nword2vec, sentence2vec and paragraph2vec. We share some of our insights and\nfindings from our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:17:55 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Kohli", "Rohan", ""], ["Prabhumoye", "Shrimai", ""]]}, {"id": "2001.04990", "submitter": "Benjamin Nachman", "authors": "Benjamin Nachman and David Shih", "title": "Anomaly Detection with Density Estimation", "comments": "28 pages, 11 figures, v2: appendix on optimality, minor\n  modifications, journal version", "journal-ref": "Phys. Rev. D 101, 075042 (2020)", "doi": "10.1103/PhysRevD.101.075042", "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage recent breakthroughs in neural density estimation to propose a\nnew unsupervised anomaly detection technique (ANODE). By estimating the\nprobability density of the data in a signal region and in sidebands, and\ninterpolating the latter into the signal region, a likelihood ratio of data vs.\nbackground can be constructed. This likelihood ratio is broadly sensitive to\noverdensities in the data that could be due to localized anomalies. In\naddition, a unique potential benefit of the ANODE method is that the background\ncan be directly estimated using the learned densities. Finally, ANODE is robust\nagainst systematic differences between signal region and sidebands, giving it\nbroader applicability than other methods. We demonstrate the power of this new\napproach using the LHC Olympics 2020 R\\&D Dataset. We show how ANODE can\nenhance the significance of a dijet bump hunt by up to a factor of 7 with a\n10\\% accuracy on the background prediction. While the LHC is used as the\nrecurring example, the methods developed here have a much broader applicability\nto anomaly detection in physics and beyond.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:00:02 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 04:48:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Nachman", "Benjamin", ""], ["Shih", "David", ""]]}, {"id": "2001.05001", "submitter": "Benjamin Nachman", "authors": "Anders Andreassen, Benjamin Nachman, and David Shih", "title": "Simulation Assisted Likelihood-free Anomaly Detection", "comments": "19 pages, 9 figures", "journal-ref": "Phys. Rev. D 101, 095004 (2020)", "doi": "10.1103/PhysRevD.101.095004", "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the lack of evidence for new particle discoveries at the Large Hadron\nCollider (LHC), it is critical to broaden the search program. A variety of\nmodel-independent searches have been proposed, adding sensitivity to unexpected\nsignals. There are generally two types of such searches: those that rely\nheavily on simulations and those that are entirely based on (unlabeled) data.\nThis paper introduces a hybrid method that makes the best of both approaches.\nFor potential signals that are resonant in one known feature, this new method\nfirst learns a parameterized reweighting function to morph a given simulation\nto match the data in sidebands. This function is then interpolated into the\nsignal region and then the reweighted background-only simulation can be used\nfor supervised learning as well as for background estimation. The background\nestimation from the reweighted simulation allows for non-trivial correlations\nbetween features used for classification and the resonant feature. A dijet\nsearch with jet substructure is used to illustrate the new method. Future\napplications of Simulation Assisted Likelihood-free Anomaly Detection (SALAD)\ninclude a variety of final states and potential combinations with other\nmodel-independent approaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:00:09 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Andreassen", "Anders", ""], ["Nachman", "Benjamin", ""], ["Shih", "David", ""]]}, {"id": "2001.05014", "submitter": "Dimitrios Boursinos", "authors": "Dimitrios Boursinos, Xenofon Koutsoukos", "title": "Assurance Monitoring of Cyber-Physical Systems with Machine Learning\n  Components", "comments": "Accepted at TMCE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning components such as deep neural networks are used extensively\nin Cyber-Physical Systems (CPS). However, they may introduce new types of\nhazards that can have disastrous consequences and need to be addressed for\nengineering trustworthy systems. Although deep neural networks offer advanced\ncapabilities, they must be complemented by engineering methods and practices\nthat allow effective integration in CPS. In this paper, we investigate how to\nuse the conformal prediction framework for assurance monitoring of CPS with\nmachine learning components. In order to handle high-dimensional inputs in\nreal-time, we compute nonconformity scores using embedding representations of\nthe learned models. By leveraging conformal prediction, the approach provides\nwell-calibrated confidence and can allow monitoring that ensures a bounded\nsmall error rate while limiting the number of inputs for which an accurate\nprediction cannot be made. Empirical evaluation results using the German\nTraffic Sign Recognition Benchmark and a robot navigation dataset demonstrate\nthat the error rates are well-calibrated while the number of alarms is small.\nThe method is computationally efficient, and therefore, the approach is\npromising for assurance monitoring of CPS.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:34:51 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 22:59:01 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Boursinos", "Dimitrios", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2001.05026", "submitter": "Sagie Benaim", "authors": "Lior Wolf, Sagie Benaim, Tomer Galanti", "title": "Unsupervised Learning of the Set of Local Maxima", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new form of unsupervised learning, whose input is a\nset of unlabeled points that are assumed to be local maxima of an unknown value\nfunction v in an unknown subset of the vector space. Two functions are learned:\n(i) a set indicator c, which is a binary classifier, and (ii) a comparator\nfunction h that given two nearby samples, predicts which sample has the higher\nvalue of the unknown function v. Loss terms are used to ensure that all\ntraining samples x are a local maxima of v, according to h and satisfy c(x)=1.\nTherefore, c and h provide training signals to each other: a point x' in the\nvicinity of x satisfies c(x)=-1 or is deemed by h to be lower in value than x.\nWe present an algorithm, show an example where it is more efficient to use\nlocal maxima as an indicator function than to employ conventional\nclassification, and derive a suitable generalization bound. Our experiments\nshow that the method is able to outperform one-class classification algorithms\nin the task of anomaly detection and also provide an additional signal that is\nextracted in a completely unsupervised way.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:56:36 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wolf", "Lior", ""], ["Benaim", "Sagie", ""], ["Galanti", "Tomer", ""]]}, {"id": "2001.05028", "submitter": "Dongrui Wu", "authors": "Ziang Liu and Dongrui Wu", "title": "Unsupervised Pool-Based Active Learning for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world machine learning applications, unlabeled data can be\neasily obtained, but it is very time-consuming and/or expensive to label them.\nSo, it is desirable to be able to select the optimal samples to label, so that\na good machine learning model can be trained from a minimum amount of labeled\ndata. Active learning (AL) has been widely used for this purpose. However, most\nexisting AL approaches are supervised: they train an initial model from a small\namount of labeled samples, query new samples based on the model, and then\nupdate the model iteratively. Few of them have considered the completely\nunsupervised AL problem, i.e., starting from zero, how to optimally select the\nvery first few samples to label, without knowing any label information at all.\nThis problem is very challenging, as no label information can be utilized. This\npaper studies unsupervised pool-based AL for linear regression problems. We\npropose a novel AL approach that considers simultaneously the informativeness,\nrepresentativeness, and diversity, three essential criteria in AL. Extensive\nexperiments on 14 datasets from various application domains, using three\ndifferent linear regression models (ridge regression, LASSO, and linear support\nvector regression), demonstrated the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:00:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Liu", "Ziang", ""], ["Wu", "Dongrui", ""]]}, {"id": "2001.05034", "submitter": "Youssef Aboutaleb", "authors": "Youssef M Aboutaleb, Mazen Danaf, Yifei Xie, and Moshe Ben-Akiva", "title": "Sparse Covariance Estimation in Logit Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new data-driven methodology for estimating sparse\ncovariance matrices of the random coefficients in logit mixture models.\nResearchers typically specify covariance matrices in logit mixture models under\none of two extreme assumptions: either an unrestricted full covariance matrix\n(allowing correlations between all random coefficients), or a restricted\ndiagonal matrix (allowing no correlations at all). Our objective is to find\noptimal subsets of correlated coefficients for which we estimate covariances.\nWe propose a new estimator, called MISC, that uses a mixed-integer optimization\n(MIO) program to find an optimal block diagonal structure specification for the\ncovariance matrix, corresponding to subsets of correlated coefficients, for any\ndesired sparsity level using Markov Chain Monte Carlo (MCMC) posterior draws\nfrom the unrestricted full covariance matrix. The optimal sparsity level of the\ncovariance matrix is determined using out-of-sample validation. We demonstrate\nthe ability of MISC to correctly recover the true covariance structure from\nsynthetic data. In an empirical illustration using a stated preference survey\non modes of transportation, we use MISC to obtain a sparse covariance matrix\nindicating how preferences for attributes are related to one another.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:19:15 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Aboutaleb", "Youssef M", ""], ["Danaf", "Mazen", ""], ["Xie", "Yifei", ""], ["Ben-Akiva", "Moshe", ""]]}, {"id": "2001.05050", "submitter": "Michela Paganini", "authors": "Michela Paganini, Jessica Forde", "title": "On Iterative Neural Network Pruning, Reinitialization, and the\n  Similarity of Masks", "comments": "8 pages, 8 figures, plus 5 appendices with additional figures and\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine how recently documented, fundamental phenomena in deep learning\nmodels subject to pruning are affected by changes in the pruning procedure.\nSpecifically, we analyze differences in the connectivity structure and learning\ndynamics of pruned models found through a set of common iterative pruning\ntechniques, to address questions of uniqueness of trainable, high-sparsity\nsub-networks, and their dependence on the chosen pruning method. In\nconvolutional layers, we document the emergence of structure induced by\nmagnitude-based unstructured pruning in conjunction with weight rewinding that\nresembles the effects of structured pruning. We also show empirical evidence\nthat weight stability can be automatically achieved through apposite pruning\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:11:19 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Paganini", "Michela", ""], ["Forde", "Jessica", ""]]}, {"id": "2001.05070", "submitter": "Jingling Li", "authors": "Jingling Li, Yanchao Sun, Jiahao Su, Taiji Suzuki, Furong Huang", "title": "Understanding Generalization in Deep Learning via Tensor Methods", "comments": "9 pages (main paper), 42 pages (full version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks generalize well on unseen data though the number of\nparameters often far exceeds the number of training examples. Recently proposed\ncomplexity measures have provided insights to understanding the\ngeneralizability in neural networks from perspectives of PAC-Bayes, robustness,\noverparametrization, compression and so on. In this work, we advance the\nunderstanding of the relations between the network's architecture and its\ngeneralizability from the compression perspective. Using tensor analysis, we\npropose a series of intuitive, data-dependent and easily-measurable properties\nthat tightly characterize the compressibility and generalizability of neural\nnetworks; thus, in practice, our generalization bound outperforms the previous\ncompression-based ones, especially for neural networks using tensors as their\nweight kernels (e.g. CNNs). Moreover, these intuitive measurements provide\nfurther insights into designing neural network architectures with properties\nfavorable for better/guaranteed generalizability. Our experimental results\ndemonstrate that through the proposed measurable properties, our generalization\nerror bound matches the trend of the test error well. Our theoretical analysis\nfurther provides justifications for the empirical success and limitations of\nsome widely-used tensor-based compression approaches. We also discover the\nimprovements to the compressibility and robustness of current neural networks\nwhen incorporating tensor operations via our proposed layer-wise structure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:26:57 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 03:38:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Jingling", ""], ["Sun", "Yanchao", ""], ["Su", "Jiahao", ""], ["Suzuki", "Taiji", ""], ["Huang", "Furong", ""]]}, {"id": "2001.05113", "submitter": "Daniel Wilke", "authors": "Dominic Kafka and Daniel N. Wilke", "title": "Resolving learning rates adaptively by locating Stochastic Non-Negative\n  Associated Gradient Projection Points using line searches", "comments": "29 pages, 11 figures, 3 tables, submitted to journal for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rates in stochastic neural network training are currently determined\na priori to training, using expensive manual or automated iterative tuning.\nThis study proposes gradient-only line searches to resolve the learning rate\nfor neural network training algorithms. Stochastic sub-sampling during training\ndecreases computational cost and allows the optimization algorithms to progress\nover local minima. However, it also results in discontinuous cost functions.\nMinimization line searches are not effective in this context, as they use a\nvanishing derivative (first order optimality condition), which often do not\nexist in a discontinuous cost function and therefore converge to\ndiscontinuities as opposed to minima from the data trends. Instead, we base\ncandidate solutions along a search direction purely on gradient information, in\nparticular by a directional derivative sign change from negative to positive (a\nNon-negative Associative Gradient Projection Point (NN- GPP)). Only considering\na sign change from negative to positive always indicates a minimum, thus\nNN-GPPs contain second order information. Conversely, a vanishing gradient is\npurely a first order condition, which may indicate a minimum, maximum or saddle\npoint. This insight allows the learning rate of an algorithm to be reliably\nresolved as the step size along a search direction, increasing convergence\nperformance and eliminating an otherwise expensive hyperparameter.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:08:07 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Kafka", "Dominic", ""], ["Wilke", "Daniel N.", ""]]}, {"id": "2001.05140", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Haopeng Zhang, Congying Xia, Li Sun", "title": "Graph-Bert: Only Attention is Needed for Learning Graph Representations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant graph neural networks (GNNs) over-rely on the graph links,\nseveral serious performance problems with which have been witnessed already,\ne.g., suspended animation problem and over-smoothing problem. What's more, the\ninherently inter-connected nature precludes parallelization within the graph,\nwhich becomes critical for large-sized graph, as memory constraints limit\nbatching across the nodes. In this paper, we will introduce a new graph neural\nnetwork, namely GRAPH-BERT (Graph based BERT), solely based on the attention\nmechanism without any graph convolution or aggregation operators. Instead of\nfeeding GRAPH-BERT with the complete large input graph, we propose to train\nGRAPH-BERT with sampled linkless subgraphs within their local contexts.\nGRAPH-BERT can be learned effectively in a standalone mode. Meanwhile, a\npre-trained GRAPH-BERT can also be transferred to other application tasks\ndirectly or with necessary fine-tuning if any supervised label information or\ncertain application oriented objective is available. We have tested the\neffectiveness of GRAPH-BERT on several graph benchmark datasets. Based the\npre-trained GRAPH-BERT with the node attribute reconstruction and structure\nrecovery tasks, we further fine-tune GRAPH-BERT on node classification and\ngraph clustering tasks specifically. The experimental results have demonstrated\nthat GRAPH-BERT can out-perform the existing GNNs in both the learning\neffectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:56:59 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 15:16:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhang", "Jiawei", ""], ["Zhang", "Haopeng", ""], ["Xia", "Congying", ""], ["Sun", "Li", ""]]}, {"id": "2001.05142", "submitter": "Satoshi Takabe", "authors": "Satoshi Takabe, Tadashi Wadayama", "title": "Theoretical Interpretation of Learned Step Size in Deep-Unfolded\n  Gradient Descent", "comments": "12 pages, 12 figures, typos are fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding is a promising deep-learning technique in which an iterative\nalgorithm is unrolled to a deep network architecture with trainable parameters.\nIn the case of gradient descent algorithms, as a result of the training\nprocess, one often observes the acceleration of the convergence speed with\nlearned non-constant step size parameters whose behavior is not intuitive nor\ninterpretable from conventional theory. In this paper, we provide a theoretical\ninterpretation of the learned step size of deep-unfolded gradient descent\n(DUGD). We first prove that the training process of DUGD reduces not only the\nmean squared error loss but also the spectral radius related to the convergence\nrate. Next, we show that minimizing the upper bound of the spectral radius\nnaturally leads to the Chebyshev step which is a sequence of the step size\nbased on Chebyshev polynomials. The numerical experiments confirm that the\nChebyshev steps qualitatively reproduce the learned step size parameters in\nDUGD, which provides a plausible interpretation of the learned parameters.\nAdditionally, we show that the Chebyshev steps achieve the lower bound of the\nconvergence rate for the first-order method in a specific limit without\nlearning parameters or momentum terms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:58:07 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 11:27:52 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Takabe", "Satoshi", ""], ["Wadayama", "Tadashi", ""]]}, {"id": "2001.05166", "submitter": "Nupur Kumari", "authors": "Nupur Kumari, Siddarth R., Akash Rupela, Piyush Gupta, Balaji\n  Krishnamurthy", "title": "ShapeVis: High-dimensional Data Visualization at Scale", "comments": "Accepted at WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present ShapeVis, a scalable visualization technique for point cloud data\ninspired from topological data analysis. Our method captures the underlying\ngeometric and topological structure of the data in a compressed graphical\nrepresentation. Much success has been reported by the data visualization\ntechnique Mapper, that discreetly approximates the Reeb graph of a filter\nfunction on the data. However, when using standard dimensionality reduction\nalgorithms as the filter function, Mapper suffers from considerable\ncomputational cost. This makes it difficult to scale to high-dimensional data.\nOur proposed technique relies on finding a subset of points called landmarks\nalong the data manifold to construct a weighted witness-graph over it. This\ngraph captures the structural characteristics of the point cloud, and its\nweights are determined using a Finite Markov Chain. We further compress this\ngraph by applying induced maps from standard community detection algorithms.\nUsing techniques borrowed from manifold tearing, we prune and reinstate edges\nin the induced graph based on their modularity to summarize the shape of data.\nWe empirically demonstrate how our technique captures the structural\ncharacteristics of real and synthetic data sets. Further, we compare our\napproach with Mapper using various filter functions like t-SNE, UMAP, LargeVis\nand show that our algorithm scales to millions of data points while preserving\nthe quality of data visualization.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 07:59:13 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 16:12:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Kumari", "Nupur", ""], ["R.", "Siddarth", ""], ["Rupela", "Akash", ""], ["Gupta", "Piyush", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2001.05168", "submitter": "Hadi Mohaghegh Dolatabadi", "authors": "Hadi M. Dolatabadi and Sarah Erfani and Christopher Leckie", "title": "Invertible Generative Modeling using Linear Rational Splines", "comments": "Accepted to the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020, Palermo, Sicily, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows attempt to model an arbitrary probability distribution\nthrough a set of invertible mappings. These transformations are required to\nachieve a tractable Jacobian determinant that can be used in high-dimensional\nscenarios. The first normalizing flow designs used coupling layer mappings\nbuilt upon affine transformations. The significant advantage of such models is\ntheir easy-to-compute inverse. Nevertheless, making use of affine\ntransformations may limit the expressiveness of such models. Recently,\ninvertible piecewise polynomial functions as a replacement for affine\ntransformations have attracted attention. However, these methods require\nsolving a polynomial equation to calculate their inverse. In this paper, we\nexplore using linear rational splines as a replacement for affine\ntransformations used in coupling layers. Besides having a straightforward\ninverse, inference and generation have similar cost and architecture in this\nmethod. Moreover, simulation results demonstrate the competitiveness of this\napproach's performance compared to existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:05:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 00:49:42 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 05:22:02 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 00:01:14 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dolatabadi", "Hadi M.", ""], ["Erfani", "Sarah", ""], ["Leckie", "Christopher", ""]]}, {"id": "2001.05172", "submitter": "Cedric Fraces", "authors": "Cedric G. Fraces, Adrien Papaioannou, Hamdi Tchelepi", "title": "Physics Informed Deep Learning for Transport in Porous Media. Buckley\n  Leverett Problem", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new hybrid physics-based machine-learning approach to reservoir\nmodeling. The methodology relies on a series of deep adversarial neural network\narchitecture with physics-based regularization. The network is used to simulate\nthe dynamic behavior of physical quantities (i.e. saturation) subject to a set\nof governing laws (e.g. mass conservation) and corresponding boundary and\ninitial conditions. A residual equation is formed from the governing\npartial-differential equation and used as part of the training. Derivatives of\nthe estimated physical quantities are computed using automatic differentiation\nalgorithms. This allows the model to avoid overfitting, by reducing the\nvariance and permits extrapolation beyond the range of the training data\nincluding uncertainty implicitely derived from the distribution output of the\ngenerative adversarial networks. The approach is used to simulate a 2 phase\nimmiscible transport problem (Buckley Leverett). From a very limited dataset,\nthe model learns the parameters of the governing equation and is able to\nprovide an accurate physical solution, both in terms of shock and rarefaction.\nWe demonstrate how this method can be applied in the context of a forward\nsimulation for continuous problems. The use of these models for the inverse\nproblem is also presented, where the model simultaneously learns the physical\nlaws and determines key uncertainty subsurface parameters. The proposed\nmethodology is a simple and elegant way to instill physical knowledge to\nmachine-learning algorithms. This alleviates the two most significant\nshortcomings of machine-learning algorithms: the requirement for large datasets\nand the reliability of extrapolation. The principles presented in this paper\ncan be generalized in innumerable ways in the future and should lead to a new\nclass of algorithms to solve both forward and inverse physical problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:20:11 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Fraces", "Cedric G.", ""], ["Papaioannou", "Adrien", ""], ["Tchelepi", "Hamdi", ""]]}, {"id": "2001.05205", "submitter": "Gilad Yehudai", "authors": "Gilad Yehudai and Ohad Shamir", "title": "Learning a Single Neuron with Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of learning a single neuron $x\n\\mapsto\\sigma(w^\\top x)$ using standard gradient methods. As opposed to\nprevious works, which considered specific (and not always realistic) input\ndistributions and activation functions $\\sigma(\\cdot)$, we ask whether a more\ngeneral result is attainable, under milder assumptions. On the one hand, we\nshow that some assumptions on the distribution and the activation function are\nnecessary. On the other hand, we prove positive guarantees under mild\nassumptions, which go beyond those studied in the literature so far. We also\npoint out and study the challenges in further strengthening and generalizing\nour results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:02:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:46:34 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "2001.05207", "submitter": "Tomer Galanti", "authors": "Lior Wolf, Tomer Galanti, Tamir Hazan", "title": "A Formal Approach to Explainability", "comments": null, "journal-ref": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and\n  Society, January 2019, Pages 255-261", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We regard explanations as a blending of the input sample and the model's\noutput and offer a few definitions that capture various desired properties of\nthe function that generates these explanations. We study the links between\nthese properties and between explanation-generating functions and intermediate\nrepresentations of learned models and are able to show, for example, that if\nthe activations of a given layer are consistent with an explanation, then so do\nall other subsequent layers. In addition, we study the intersection and union\nof explanations as a way to construct new explanations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:06:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wolf", "Lior", ""], ["Galanti", "Tomer", ""], ["Hazan", "Tamir", ""]]}, {"id": "2001.05209", "submitter": "Rohan Saphal Mr", "authors": "Rohan Saphal, Balaraman Ravindran, Dheevatsa Mudigere, Sasikanth\n  Avancha, Bharat Kaul", "title": "SEERL: Sample Efficient Ensemble Reinforcement Learning", "comments": "Accepted at Proceedings of the 20th International Conference on\n  Autonomous Agents and MultiAgent Systems", "journal-ref": null, "doi": "10.5555/3463952.3464080", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a very prevalent method employed in machine learning.\nThe relative success of ensemble methods is attributed to their ability to\ntackle a wide range of instances and complex problems that require different\nlow-level approaches. However, ensemble methods are relatively less popular in\nreinforcement learning owing to the high sample complexity and computational\nexpense involved in obtaining a diverse ensemble. We present a novel training\nand model selection framework for model-free reinforcement algorithms that use\nensembles of policies obtained from a single training run. These policies are\ndiverse in nature and are learned through directed perturbation of the model\nparameters at regular intervals. We show that learning and selecting an\nadequately diverse set of policies is required for a good ensemble while\nextreme diversity can prove detrimental to overall performance. Selection of an\nadequately diverse set of policies is done through our novel policy selection\nframework. We evaluate our approach on challenging discrete and continuous\ncontrol tasks and also discuss various ensembling strategies. Our framework is\nsubstantially sample efficient, computationally inexpensive and is seen to\noutperform state-of-the-art (SOTA) scores in Atari 2600 and Mujoco.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:12:00 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 13:35:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Saphal", "Rohan", ""], ["Ravindran", "Balaraman", ""], ["Mudigere", "Dheevatsa", ""], ["Avancha", "Sasikanth", ""], ["Kaul", "Bharat", ""]]}, {"id": "2001.05228", "submitter": "Aditya Kusupati", "authors": "Yashoteja Prabhu, Aditya Kusupati, Nilesh Gupta and Manik Varma", "title": "Extreme Regression for Dynamic Search Advertising", "comments": "15 pages, 4 figures, published at WSDM 2020 as a Long Oral", "journal-ref": null, "doi": "10.1145/3336191.3371768", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new learning paradigm called eXtreme Regression (XR)\nwhose objective is to accurately predict the numerical degrees of relevance of\nan extremely large number of labels to a data point. XR can provide elegant\nsolutions to many large-scale ranking and recommendation applications including\nDynamic Search Advertising (DSA). XR can learn more accurate models than the\nrecently popular extreme classifiers which incorrectly assume strictly\nbinary-valued label relevances. Traditional regression metrics which sum the\nerrors over all the labels are unsuitable for XR problems since they could give\nextremely loose bounds for the label ranking quality. Also, the existing\nregression algorithms won't efficiently scale to millions of labels. This paper\naddresses these limitations through: (1) new evaluation metrics for XR which\nsum only the k largest regression errors; (2) a new algorithm called XReg which\ndecomposes XR task into a hierarchy of much smaller regression problems thus\nleading to highly efficient training and prediction. This paper also introduces\na (3) new labelwise prediction algorithm in XReg useful for DSA and other\nrecommendation tasks. Experiments on benchmark datasets demonstrated that XReg\ncan outperform the state-of-the-art extreme classifiers as well as large-scale\nregressors and rankers by up to 50% reduction in the new XR error metric, and\nup to 2% and 2.4% improvements in terms of the propensity-scored precision\nmetric used in extreme classification and the click-through rate metric used in\nDSA respectively. Deployment of XReg on DSA in Bing resulted in a relative gain\nof 27% in query coverage. XReg's source code can be downloaded from\nhttp://manikvarma.org/code/XReg/download.html.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:56:42 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 02:34:48 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 10:46:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Prabhu", "Yashoteja", ""], ["Kusupati", "Aditya", ""], ["Gupta", "Nilesh", ""], ["Varma", "Manik", ""]]}, {"id": "2001.05253", "submitter": "Mafalda Falc\\~ao Ferreira", "authors": "Mafalda Falcao Ferreira, Rui Camacho, Luis F. Teixeira", "title": "Autoencoders as Weight Initialization of Deep Classification Networks\n  for Cancer versus Cancer Studies", "comments": "5 pages, 2 figures (each one with 6 sub-figures), 2 tables. Special\n  Session of Machine Learning in Healthcare Informatics and Medical Biology of\n  the 16th International Conference on Computational Intelligence methods for\n  Bioinformatics and Biostatistics (CIBB2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is still one of the most devastating diseases of our time. One way of\nautomatically classifying tumor samples is by analyzing its derived molecular\ninformation (i.e., its genes expression signatures). In this work, we aim to\ndistinguish three different types of cancer: thyroid, skin, and stomach. For\nthat, we compare the performance of a Denoising Autoencoder (DAE) used as\nweight initialization of a deep neural network. Although we address a different\ndomain problem in this work, we have adopted the same methodology of Ferreira\net al.. In our experiments, we assess two different approaches when training\nthe classification model: (a) fixing the weights, after pre-training the DAE,\nand (b) allowing fine-tuning of the entire classification network.\nAdditionally, we apply two different strategies for embedding the DAE into the\nclassification network: (1) by only importing the encoding layers, and (2) by\ninserting the complete autoencoder. Our best result was the combination of\nunsupervised feature learning through a DAE, followed by its full import into\nthe classification network, and subsequent fine-tuning through supervised\ntraining, achieving an F1 score of 98.04% +/- 1.09 when identifying cancerous\nthyroid samples.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 11:49:41 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Ferreira", "Mafalda Falcao", ""], ["Camacho", "Rui", ""], ["Teixeira", "Luis F.", ""]]}, {"id": "2001.05270", "submitter": "Mario Holubar", "authors": "Mario S. Holubar, Marco A. Wiering", "title": "Continuous-action Reinforcement Learning for Playing Racing Games:\n  Comparing SPG to PPO", "comments": "12 pages, 9 figures. Code is available at\n  https://github.com/mario-holubar/RacingRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a novel racing environment for OpenAI Gym is introduced. This\nenvironment operates with continuous action- and state-spaces and requires\nagents to learn to control the acceleration and steering of a car while\nnavigating a randomly generated racetrack. Different versions of two\nactor-critic learning algorithms are tested on this environment: Sampled Policy\nGradient (SPG) and Proximal Policy Optimization (PPO). An extension of SPG is\nintroduced that aims to improve learning performance by weighting action\nsamples during the policy update step. The effect of using experience replay\n(ER) is also investigated. To this end, a modification to PPO is introduced\nthat allows for training using old action samples by optimizing the actor in\nlog space. Finally, a new technique for performing ER is tested that aims to\nimprove learning speed without sacrificing performance by splitting the\ntraining into two parts, whereby networks are first trained using state\ntransitions from the replay buffer, and then using only recent experiences. The\nresults indicate that experience replay is not beneficial to PPO in continuous\naction spaces. The training of SPG seems to be more stable when actions are\nweighted. All versions of SPG outperform PPO when ER is used. The ER trick is\neffective at improving training speed on a computationally less intensive\nversion of SPG.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:30:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Holubar", "Mario S.", ""], ["Wiering", "Marco A.", ""]]}, {"id": "2001.05272", "submitter": "Zhenyu Xuan", "authors": "Zhenyu Xuan, Rui Bao, Shengyi Jiang", "title": "FGN: Fusion Glyph Network for Chinese Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese NER is a challenging task. As pictographs, Chinese characters contain\nlatent glyph information, which is often overlooked. In this paper, we propose\nthe FGN, Fusion Glyph Network for Chinese NER. Except for adding glyph\ninformation, this method may also add extra interactive information with the\nfusion mechanism. The major innovations of FGN include: (1) a novel CNN\nstructure called CGS-CNN is proposed to capture both glyph information and\ninteractive information between glyphs from neighboring characters. (2) we\nprovide a method with sliding window and Slice-Attention to fuse the BERT\nrepresentation and glyph representation for a character, which may capture\npotential interactive knowledge between context and glyph. Experiments are\nconducted on four NER datasets, showing that FGN with LSTM-CRF as tagger\nachieves new state-of-the-arts performance for Chinese NER. Further, more\nexperiments are conducted to investigate the influences of various components\nand settings in FGN.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:39:20 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:58:51 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 05:05:45 GMT"}, {"version": "v4", "created": "Sat, 27 Jun 2020 13:28:21 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 07:54:43 GMT"}, {"version": "v6", "created": "Thu, 8 Oct 2020 11:46:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Xuan", "Zhenyu", ""], ["Bao", "Rui", ""], ["Jiang", "Shengyi", ""]]}, {"id": "2001.05295", "submitter": "Ethan Steinberg", "authors": "Ethan Steinberg, Ken Jung, Jason A. Fries, Conor K. Corbin, Stephen R.\n  Pfohl, Nigam H. Shah", "title": "Language Models Are An Effective Patient Representation Learning\n  Technique For Electronic Health Record Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread adoption of electronic health records (EHRs) has fueled the\ndevelopment of using machine learning to build prediction models for various\nclinical outcomes. This process is often constrained by having a relatively\nsmall number of patient records for training the model. We demonstrate that\nusing patient representation schemes inspired from techniques in natural\nlanguage processing can increase the accuracy of clinical prediction models by\ntransferring information learned from the entire patient population to the task\nof training a specific model, where only a subset of the population is\nrelevant. Such patient representation schemes enable a 3.5% mean improvement in\nAUROC on five prediction tasks compared to standard baselines, with the average\nimprovement rising to 19% when only a small number of patient records are\navailable for training the clinical prediction model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:24:59 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 20:58:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Steinberg", "Ethan", ""], ["Jung", "Ken", ""], ["Fries", "Jason A.", ""], ["Corbin", "Conor K.", ""], ["Pfohl", "Stephen R.", ""], ["Shah", "Nigam H.", ""]]}, {"id": "2001.05312", "submitter": "Bj{\\o}rn Magnus Mathisen", "authors": "Bj{\\o}rn Magnus Mathisen, Agnar Aamodt, Kerstin Bach, Helge Langseth", "title": "Learning similarity measures from data", "comments": "Prog Artif Intell (2019)", "journal-ref": null, "doi": "10.1007/s13748-019-00201-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Defining similarity measures is a requirement for some machine learning\nmethods. One such method is case-based reasoning (CBR) where the similarity\nmeasure is used to retrieve the stored case or set of cases most similar to the\nquery case. Describing a similarity measure analytically is challenging, even\nfor domain experts working with CBR experts. However, data sets are typically\ngathered as part of constructing a CBR or machine learning system. These\ndatasets are assumed to contain the features that correctly identify the\nsolution from the problem features, thus they may also contain the knowledge to\nconstruct or learn such a similarity measure. The main motivation for this work\nis to automate the construction of similarity measures using machine learning,\nwhile keeping training time as low as possible. Our objective is to investigate\nhow to apply machine learning to effectively learn a similarity measure. Such a\nlearned similarity measure could be used for CBR systems, but also for\nclustering data in semi-supervised learning, or one-shot learning tasks. Recent\nwork has advanced towards this goal, relies on either very long training times\nor manually modeling parts of the similarity measure. We created a framework to\nhelp us analyze current methods for learning similarity measures. This analysis\nresulted in two novel similarity measure designs. One design using a\npre-trained classifier as basis for a similarity measure. The second design\nuses as little modeling as possible while learning the similarity measure from\ndata and keeping training time low. Both similarity measures were evaluated on\n14 different datasets. The evaluation shows that using a classifier as basis\nfor a similarity measure gives state of the art performance. Finally the\nevaluation shows that our fully data-driven similarity measure design\noutperforms state of the art methods while keeping training time low.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:29:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Mathisen", "Bj\u00f8rn Magnus", ""], ["Aamodt", "Agnar", ""], ["Bach", "Kerstin", ""], ["Langseth", "Helge", ""]]}, {"id": "2001.05314", "submitter": "Siyu Liao", "authors": "Siyu Liao, Jie Chen, Yanzhi Wang, Qinru Qiu, Bo Yuan", "title": "Embedding Compression with Isotropic Iterative Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous representation of words is a standard component in deep\nlearning-based NLP models. However, representing a large vocabulary requires\nsignificant memory, which can cause problems, particularly on\nresource-constrained platforms. Therefore, in this paper we propose an\nisotropic iterative quantization (IIQ) approach for compressing embedding\nvectors into binary ones, leveraging the iterative quantization technique well\nestablished for image retrieval, while satisfying the desired isotropic\nproperty of PMI based models. Experiments with pre-trained embeddings (i.e.,\nGloVe and HDC) demonstrate a more than thirty-fold compression ratio with\ncomparable and sometimes even improved performance over the original\nreal-valued embedding vectors.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 20:53:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 01:01:56 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liao", "Siyu", ""], ["Chen", "Jie", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""], ["Yuan", "Bo", ""]]}, {"id": "2001.05317", "submitter": "Philip Sellars", "authors": "Philip Sellars, Angelica Aviles-Rivero, Carola Bibiane Sch\\\"onlieb", "title": "Two Cycle Learning: Clustering Based Regularisation for Deep\n  Semi-Supervised Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works addresses the challenge of classification with minimal\nannotations. Obtaining annotated data is time consuming, expensive and can\nrequire expert knowledge. As a result, there is an acceleration towards\nsemi-supervised learning (SSL) approaches which utilise large amounts of\nunlabelled data to improve classification performance. The vast majority of SSL\napproaches have focused on implementing the \\textit{low-density separation\nassumption}, in which the idea is that decision boundaries should lie in low\ndensity regions. However, they have implemented this assumption by treating the\ndataset as a set of individual attributes rather than as a global structure,\nwhich limits the overall performance of the classifier. Therefore, in this\nwork, we go beyond this implementation and propose a novel SSL framework called\ntwo-cycle learning. For the first cycle, we use clustering based regularisation\nthat allows for improved decision boundaries as well as features that\ngeneralises well. The second cycle is set as a graph based SSL that take\nadvantages of the richer discriminative features of the first cycle to\nsignificantly boost the accuracy of generated pseudo-labels. We evaluate our\ntwo-cycle learning method extensively across multiple datasets, outperforming\ncurrent approaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:34:02 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sellars", "Philip", ""], ["Aviles-Rivero", "Angelica", ""], ["Sch\u00f6nlieb", "Carola Bibiane", ""]]}, {"id": "2001.05343", "submitter": "Yuhao Wang", "authors": "Yuhao Wang, Vlado Menkovski, Hao Wang, Xin Du, Mykola Pechenizkiy", "title": "Causal Discovery from Incomplete Data: A Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As systems are getting more autonomous with the development of artificial\nintelligence, it is important to discover the causal knowledge from\nobservational sensory inputs. By encoding a series of cause-effect relations\nbetween events, causal networks can facilitate the prediction of effects from a\ngiven action and analyze their underlying data generation mechanism. However,\nmissing data are ubiquitous in practical scenarios. Directly performing\nexisting casual discovery algorithms on partially observed data may lead to the\nincorrect inference. To alleviate this issue, we proposed a deep learning\nframework, dubbed Imputated Causal Learning (ICL), to perform iterative missing\ndata imputation and causal structure discovery. Through extensive simulations\non both synthetic and real data, we show that ICL can outperform\nstate-of-the-art methods under different missing data mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:28:21 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wang", "Yuhao", ""], ["Menkovski", "Vlado", ""], ["Wang", "Hao", ""], ["Du", "Xin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2001.05348", "submitter": "Yusuke Sakemi Ph.D.", "authors": "Yusuke Sakemi, Kai Morino, Takashi Morie, Kazuyuki Aihara", "title": "A Supervised Learning Algorithm for Multilayer Spiking Neural Networks\n  Based on Temporal Coding Toward Energy-Efficient VLSI Processor Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are brain-inspired mathematical models with\nthe ability to process information in the form of spikes. SNNs are expected to\nprovide not only new machine-learning algorithms, but also energy-efficient\ncomputational models when implemented in VLSI circuits. In this paper, we\npropose a novel supervised learning algorithm for SNNs based on temporal\ncoding. A spiking neuron in this algorithm is designed to facilitate analog\nVLSI implementations with analog resistive memory, by which ultra-high energy\nefficiency can be achieved. We also propose several techniques to improve the\nperformance on a recognition task, and show that the classification accuracy of\nthe proposed algorithm is as high as that of the state-of-the-art temporal\ncoding SNN algorithms on the MNIST dataset. Finally, we discuss the robustness\nof the proposed SNNs against variations that arise from the device\nmanufacturing process and are unavoidable in analog VLSI implementation. We\nalso propose a technique to suppress the effects of variations in the\nmanufacturing process on the recognition performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:37:08 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sakemi", "Yusuke", ""], ["Morino", "Kai", ""], ["Morie", "Takashi", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "2001.05363", "submitter": "Vincent Adam", "authors": "Vincent Adam and Stefanos Eleftheriadis and Nicolas Durrande and Artem\n  Artemev and James Hensman", "title": "Doubly Sparse Variational Gaussian Processes", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Gaussian process models is typically limited to datasets with a\nfew tens of thousands of observations due to their complexity and memory\nfootprint. The two most commonly used methods to overcome this limitation are\n1) the variational sparse approximation which relies on inducing points and 2)\nthe state-space equivalent formulation of Gaussian processes which can be seen\nas exploiting some sparsity in the precision matrix. We propose to take the\nbest of both worlds: we show that the inducing point framework is still valid\nfor state space models and that it can bring further computational and memory\nsavings. Furthermore, we provide the natural gradient formulation for the\nproposed variational parameterisation. Finally, this work makes it possible to\nuse the state-space formulation inside deep Gaussian process models as\nillustrated in one of the experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:07:08 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Adam", "Vincent", ""], ["Eleftheriadis", "Stefanos", ""], ["Durrande", "Nicolas", ""], ["Artemev", "Artem", ""], ["Hensman", "James", ""]]}, {"id": "2001.05371", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger,\n  Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin Mahlein, Kristian Kersting", "title": "Making deep neural networks right for the right scientific reasons by\n  interacting with their explanations", "comments": "arXiv admin note: text overlap with arXiv:1805.08578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown excellent performances in many real-world\napplications. Unfortunately, they may show \"Clever Hans\"-like behavior---making\nuse of confounding factors within datasets---to achieve high performance. In\nthis work, we introduce the novel learning setting of \"explanatory interactive\nlearning\" (XIL) and illustrate its benefits on a plant phenotyping research\ntask. XIL adds the scientist into the training loop such that she interactively\nrevises the original model via providing feedback on its explanations. Our\nexperimental results demonstrate that XIL can help avoiding Clever Hans moments\nin machine learning and encourages (or discourages, if appropriate) trust into\nthe underlying model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:20:55 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:59:54 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 13:38:58 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Schramowski", "Patrick", ""], ["Stammer", "Wolfgang", ""], ["Teso", "Stefano", ""], ["Brugger", "Anna", ""], ["Shao", "Xiaoting", ""], ["Luigs", "Hans-Georg", ""], ["Mahlein", "Anne-Katrin", ""], ["Kersting", "Kristian", ""]]}, {"id": "2001.05400", "submitter": "James Meech", "authors": "James Timothy Meech and Phillip Stanley-Marbell", "title": "Efficient Programmable Random Variate Generation Accelerator from Sensor\n  Noise", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for non-uniform random number generation based on\nsampling a physical process in a controlled environment. We demonstrate one\nproof-of-concept implementation of the method that reduces the error of Monte\nCarlo integration of a univariate Gaussian by 1068 times while doubling the\nspeed of the Monte Carlo simulation. We show that the supply voltage and\ntemperature of the physical process must be controlled to prevent the mean and\nstandard deviation of the random number generator from drifting.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 13:43:29 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 11:31:20 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Meech", "James Timothy", ""], ["Stanley-Marbell", "Phillip", ""]]}, {"id": "2001.05401", "submitter": "Quentin Bertrand", "authors": "Mathurin Massias and Quentin Bertrand and Alexandre Gramfort and\n  Joseph Salmon", "title": "Support recovery and sup-norm convergence rates for sparse pivotal\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional sparse regression, pivotal estimators are estimators for\nwhich the optimal regularization parameter is independent of the noise level.\nThe canonical pivotal estimator is the square-root Lasso, formulated along with\nits derivatives as a \"non-smooth + non-smooth\" optimization problem. Modern\ntechniques to solve these include smoothing the datafitting term, to benefit\nfrom fast efficient proximal algorithms. In this work we show minimax sup-norm\nconvergence rates for non smoothed and smoothed, single task and multitask\nsquare-root Lasso-type estimators. Thanks to our theoretical analysis, we\nprovide some guidelines on how to set the smoothing hyperparameter, and\nillustrate on synthetic data the interest of such guidelines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:11:04 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 15:30:03 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:58:48 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Massias", "Mathurin", ""], ["Bertrand", "Quentin", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "2001.05407", "submitter": "Guillaume Marrelec", "authors": "Guillaume Marrelec and Alain Giron", "title": "Automated extraction of mutual independence patterns using Bayesian\n  comparison of partition models", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence (in\n  press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual independence is a key concept in statistics that characterizes the\nstructural relationships between variables. Existing methods to investigate\nmutual independence rely on the definition of two competing models, one being\nnested into the other and used to generate a null distribution for a statistic\nof interest, usually under the asymptotic assumption of large sample size. As\nsuch, these methods have a very restricted scope of application. In the present\nmanuscript, we propose to change the investigation of mutual independence from\na hypothesis-driven task that can only be applied in very specific cases to a\nblind and automated search within patterns of mutual independence. To this end,\nwe treat the issue as one of model comparison that we solve in a Bayesian\nframework. We show the relationship between such an approach and existing\nmethods in the case of multivariate normal distributions as well as\ncross-classified multinomial distributions. We propose a general Markov chain\nMonte Carlo (MCMC) algorithm to numerically approximate the posterior\ndistribution on the space of all patterns of mutual independence. The relevance\nof the method is demonstrated on synthetic data as well as two real datasets,\nshowing the unique insight provided by this approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:21:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Marrelec", "Guillaume", ""], ["Giron", "Alain", ""]]}, {"id": "2001.05411", "submitter": "Erwan Lecarpentier", "authors": "Erwan Lecarpentier, David Abel, Kavosh Asadi, Yuu Jinnai, Emmanuel\n  Rachelson, Michael L. Littman", "title": "Lipschitz Lifelong Reinforcement Learning", "comments": "In proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI 2021), 21 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of knowledge transfer when an agent is facing a\nseries of Reinforcement Learning (RL) tasks. We introduce a novel metric\nbetween Markov Decision Processes (MDPs) and establish that close MDPs have\nclose optimal value functions. Formally, the optimal value functions are\nLipschitz continuous with respect to the tasks space. These theoretical results\nlead us to a value-transfer method for Lifelong RL, which we use to build a\nPAC-MDP algorithm with improved convergence rate. Further, we show the method\nto experience no negative transfer with high probability. We illustrate the\nbenefits of the method in Lifelong RL experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:29:30 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 16:25:07 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 14:35:30 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Lecarpentier", "Erwan", ""], ["Abel", "David", ""], ["Asadi", "Kavosh", ""], ["Jinnai", "Yuu", ""], ["Rachelson", "Emmanuel", ""], ["Littman", "Michael L.", ""]]}, {"id": "2001.05419", "submitter": "Ev Zisselman", "authors": "Ev Zisselman and Aviv Tamar", "title": "Deep Residual Flow for Out of Distribution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effective application of neural networks in the real-world relies on\nproficiently detecting out-of-distribution examples. Contemporary methods seek\nto model the distribution of feature activations in the training data for\nadequately distinguishing abnormalities, and the state-of-the-art method uses\nGaussian distribution models. In this work, we present a novel approach that\nimproves upon the state-of-the-art by leveraging an expressive density model\nbased on normalizing flows. We introduce the residual flow, a novel flow\narchitecture that learns the residual distribution from a base Gaussian\ndistribution. Our model is general, and can be applied to any data that is\napproximately Gaussian. For out of distribution detection in image datasets,\nour approach provides a principled improvement over the state-of-the-art.\nSpecifically, we demonstrate the effectiveness of our method in ResNet and\nDenseNet architectures trained on various image datasets. For example, on a\nResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution\nsamples from the ImageNet dataset, holding the true positive rate (TPR) at\n$95\\%$, we improve the true negative rate (TNR) from $56.7\\%$ (current\nstate-of-the-art) to $77.5\\%$ (ours).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:38:47 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 16:20:47 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 17:44:12 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zisselman", "Ev", ""], ["Tamar", "Aviv", ""]]}, {"id": "2001.05437", "submitter": "Wayne Isaac Uy", "authors": "Wayne Isaac Tan Uy, Mircea Grigoriu", "title": "Neural network representation of the probability density function of\n  diffusion processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks are developed to characterize the state of\ndynamical systems in a random environment. The neural network approximates the\nprobability density function (pdf) or the characteristic function (chf) of the\nstate of these systems which satisfy the Fokker-Planck equation or an\nintegro-differential equation under Gaussian and/or Poisson white noises. We\nexamine analytically and numerically the advantages and disadvantages of\nsolving each type of differential equation to characterize the state. It is\nalso demonstrated how prior information of the dynamical system can be\nexploited to design and simplify the neural network architecture. Numerical\nexamples show that: 1) the neural network solution can approximate the target\nsolution even for partial integro-differential equations and system of PDEs\ndescribing the time evolution of the pdf/chf, 2) solving either the\nFokker-Planck equation or the chf differential equation using neural networks\nyields similar pdfs of the state, and 3) the solution to these differential\nequations can be used to study the behavior of the state for different types of\nrandom forcings.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:15:24 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 20:10:05 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Uy", "Wayne Isaac Tan", ""], ["Grigoriu", "Mircea", ""]]}, {"id": "2001.05443", "submitter": "G C Nandi", "authors": "Priya Shukla, Hitesh Kumar and G. C. Nandi", "title": "Robotic Grasp Manipulation Using Evolutionary Computing and Deep\n  Reinforcement Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Object manipulation for grasping is a challenging problem for\nrobots. Unlike robots, humans almost immediately know how to manipulate objects\nfor grasping due to learning over the years. A grown woman can grasp objects\nmore skilfully than a child because of learning skills developed over years,\nthe absence of which in the present day robotic grasping compels it to perform\nwell below the human object grasping benchmarks. In this paper we have taken up\nthe challenge of developing learning based pose estimation by decomposing the\nproblem into both position and orientation learning. More specifically, for\ngrasp position estimation, we explore three different methods - a Genetic\nAlgorithm (GA) based optimization method to minimize error between calculated\nimage points and predicted end-effector (EE) position, a regression based\nmethod (RM) where collected data points of robot EE and image points have been\nregressed with a linear model, a PseudoInverse (PI) model which has been\nformulated in the form of a mapping matrix with robot EE position and image\npoints for several observations. Further for grasp orientation learning, we\ndevelop a deep reinforcement learning (DRL) model which we name as Grasp Deep\nQ-Network (GDQN) and benchmarked our results with Modified VGG16 (MVGG16).\nRigorous experimentations show that due to inherent capability of producing\nvery high-quality solutions for optimization problems and search problems, GA\nbased predictor performs much better than the other two models for position\nestimation. For orientation learning results indicate that off policy learning\nthrough GDQN outperforms MVGG16, since GDQN architecture is specially made\nsuitable for the reinforcement learning. Based on our proposed architectures\nand algorithms, the robot is capable of grasping all rigid body objects having\nregular shapes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:23:55 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Shukla", "Priya", ""], ["Kumar", "Hitesh", ""], ["Nandi", "G. C.", ""]]}, {"id": "2001.05452", "submitter": "Abishek Sankararaman", "authors": "Ronshee Chawla, Abishek Sankararaman, Ayalvadi Ganesh, Sanjay\n  Shakkottai", "title": "The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits", "comments": "To Appear in AISTATS 2020. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup\nconsisting of $N$ agents, solving the same MAB instance to minimize individual\ncumulative regret. In our model, agents collaborate by exchanging messages\nthrough pairwise gossip style communications on an arbitrary connected graph.\nWe develop two novel algorithms, where each agent only plays from a subset of\nall the arms. Agents use the communication medium to recommend only arm-IDs\n(not samples), and thus update the set of arms from which they play. We\nestablish that, if agents communicate $\\Omega(\\log(T))$ times through any\nconnected pairwise gossip mechanism, then every agent's regret is a factor of\norder $N$ smaller compared to the case of no collaborations. Furthermore, we\nshow that the communication constraints only have a second order effect on the\nregret of our algorithm. We then analyze this second order term of the regret\nto derive bounds on the regret-communication tradeoffs. Finally, we empirically\nevaluate our algorithm and conclude that the insights are fundamental and not\nartifacts of our bounds. We also show a lower bound which gives that the regret\nscaling obtained by our algorithm cannot be improved even in the absence of any\ncommunication constraints. Our results thus demonstrate that even a minimal\nlevel of collaboration among agents greatly reduces regret for all agents.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:49:29 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:09:46 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 21:11:46 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chawla", "Ronshee", ""], ["Sankararaman", "Abishek", ""], ["Ganesh", "Ayalvadi", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2001.05472", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov and Leonid E. Fedichkin and Ray-Kuang Lee and\n  Alexander Alodjants", "title": "Machine learning transfer efficiencies for noisy quantum walks", "comments": "6 pages, 4 figures", "journal-ref": "Adv. Quantum Technol. 3, 1900115 (2020)", "doi": "10.1002/qute.201900115", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum effects are known to provide an advantage in particle transfer across\nnetworks. In order to achieve this advantage, requirements on both a graph type\nand a quantum system coherence must be found. Here we show that the process of\nfinding these requirements can be automated by learning from simulated\nexamples. The automation is done by using a convolutional neural network of a\nparticular type that learns to understand with which network and under which\ncoherence requirements quantum advantage is possible. Our machine learning\napproach is applied to study noisy quantum walks on cycle graphs of different\nsizes. We found that it is possible to predict the existence of quantum\nadvantage for the entire decoherence parameter range, even for graphs outside\nof the training set. Our results are of importance for demonstration of\nadvantage in quantum experiments and pave the way towards automating scientific\nresearch and discoveries.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:36:53 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:39:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Fedichkin", "Leonid E.", ""], ["Lee", "Ray-Kuang", ""], ["Alodjants", "Alexander", ""]]}, {"id": "2001.05484", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Jianqing Fan, Cong Ma, Yuling Yan", "title": "Bridging Convex and Nonconvex Optimization in Robust PCA: Noise,\n  Outliers, and Missing Data", "comments": "accepted to the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper delivers improved theoretical guarantees for the convex\nprogramming approach in low-rank matrix estimation, in the presence of (1)\nrandom noise, (2) gross sparse outliers, and (3) missing data. This problem,\noften dubbed as robust principal component analysis (robust PCA), finds\napplications in various domains. Despite the wide applicability of convex\nrelaxation, the available statistical support (particularly the stability\nanalysis vis-\\`a-vis random noise) remains highly suboptimal, which we\nstrengthen in this paper. When the unknown matrix is well-conditioned,\nincoherent, and of constant rank, we demonstrate that a principled convex\nprogram achieves near-optimal statistical accuracy, in terms of both the\nEuclidean loss and the $\\ell_{\\infty}$ loss. All of this happens even when\nnearly a constant fraction of observations are corrupted by outliers with\narbitrary magnitudes. The key analysis idea lies in bridging the convex program\nin use and an auxiliary nonconvex optimization algorithm, and hence the title\nof this paper.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:54:29 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 20:05:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""], ["Yan", "Yuling", ""]]}, {"id": "2001.05486", "submitter": "Claudius Krause", "authors": "Christina Gao, Joshua Isaacson, and Claudius Krause", "title": "i-flow: High-dimensional Integration and Sampling with Normalizing Flows", "comments": "21 pages, 5 figures, 4 tables; v2: improved presentation and\n  discussion, matches published version. Mach. Learn.: Sci. Technol (2020)", "journal-ref": null, "doi": "10.1088/2632-2153/abab62", "report-no": "FERMILAB-PUB-20-010-T", "categories": "physics.comp-ph cs.LG hep-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many fields of science, high-dimensional integration is required.\nNumerical methods have been developed to evaluate these complex integrals. We\nintroduce the code i-flow, a python package that performs high-dimensional\nnumerical integration utilizing normalizing flows. Normalizing flows are\nmachine-learned, bijective mappings between two distributions. i-flow can also\nbe used to sample random points according to complicated distributions in high\ndimensions. We compare i-flow to other algorithms for high-dimensional\nnumerical integration and show that i-flow outperforms them for high\ndimensional correlated integrals. The i-flow code is publicly available on\ngitlab at https://gitlab.com/i-flow/i-flow.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:56:57 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 18:16:12 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gao", "Christina", ""], ["Isaacson", "Joshua", ""], ["Krause", "Claudius", ""]]}, {"id": "2001.05492", "submitter": "Li Cheng", "authors": "Li Cheng, Yijie Wang, Xinwang Liu, Bin Li", "title": "Outlier Detection Ensemble with Embedded Feature Selection", "comments": "10pages, AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection places an important role in improving the performance of\noutlier detection, especially for noisy data. Existing methods usually perform\nfeature selection and outlier scoring separately, which would select feature\nsubsets that may not optimally serve for outlier detection, leading to\nunsatisfying performance. In this paper, we propose an outlier detection\nensemble framework with embedded feature selection (ODEFS), to address this\nissue. Specifically, for each random sub-sampling based learning component,\nODEFS unifies feature selection and outlier detection into a pairwise ranking\nformulation to learn feature subsets that are tailored for the outlier\ndetection method. Moreover, we adopt the thresholded self-paced learning to\nsimultaneously optimize feature selection and example selection, which is\nhelpful to improve the reliability of the training set. After that, we design\nan alternate algorithm with proved convergence to solve the resultant\noptimization problem. In addition, we analyze the generalization error bound of\nthe proposed framework, which provides theoretical guarantee on the method and\ninsightful practical guidance. Comprehensive experimental results on 12\nreal-world datasets from diverse domains validate the superiority of the\nproposed ODEFS.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:14:10 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Cheng", "Li", ""], ["Wang", "Yijie", ""], ["Liu", "Xinwang", ""], ["Li", "Bin", ""]]}, {"id": "2001.05494", "submitter": "Andrea Valenti", "authors": "Andrea Valenti, Antonio Carta, Davide Bacciu", "title": "Learning Style-Aware Symbolic Music Representations by Adversarial\n  Autoencoders", "comments": "Accepted for publication at the 24th European Conference on\n  Artificial Intelligence (ECAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenging open problem of learning an effective latent space\nfor symbolic music data in generative music modeling. We focus on leveraging\nadversarial regularization as a flexible and natural mean to imbue variational\nautoencoders with context information concerning music genre and style. Through\nthe paper, we show how Gaussian mixtures taking into account music metadata\ninformation can be used as an effective prior for the autoencoder latent space,\nintroducing the first Music Adversarial Autoencoder (MusAE). The empirical\nanalysis on a large scale benchmark shows that our model has a higher\nreconstruction accuracy than state-of-the-art models based on standard\nvariational autoencoders. It is also able to create realistic interpolations\nbetween two musical sequences, smoothly changing the dynamics of the different\ntracks. Experiments show that the model can organise its latent space\naccordingly to low-level properties of the musical pieces, as well as to embed\ninto the latent variables the high-level genre information injected from the\nprior distribution to increase its overall performance. This allows us to\nperform changes to the generated pieces in a principled way.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:07:20 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 14:44:50 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Valenti", "Andrea", ""], ["Carta", "Antonio", ""], ["Bacciu", "Davide", ""]]}, {"id": "2001.05497", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel Kane, Shachar Lovett, Gaurav Mahajan", "title": "Noise-tolerant, Reliable Active Classification with Comparison Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosion of massive, widely available unlabeled data in the past\nyears, finding label and time efficient, robust learning algorithms has become\never more important in theory and in practice. We study the paradigm of active\nlearning, in which algorithms with access to large pools of data may adaptively\nchoose what samples to label in the hope of exponentially increasing\nefficiency. By introducing comparisons, an additional type of query comparing\ntwo points, we provide the first time and query efficient algorithms for\nlearning non-homogeneous linear separators robust to bounded (Massart) noise.\nWe further provide algorithms for a generalization of the popular Tsybakov low\nnoise condition, and show how comparisons provide a strong reliability\nguarantee that is often impractical or impossible with only labels - returning\na classifier that makes no errors with high probability.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:00:00 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel", ""], ["Lovett", "Shachar", ""], ["Mahajan", "Gaurav", ""]]}, {"id": "2001.05513", "submitter": "Thomas Berrett", "authors": "Thomas B. Berrett, Ioannis Kontoyiannis, Richard J. Samworth", "title": "Optimal rates for independence testing via $U$-statistic permutation\n  tests", "comments": "58 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of independence testing given independent and\nidentically distributed pairs taking values in a $\\sigma$-finite, separable\nmeasure space. Defining a natural measure of dependence $D(f)$ as the squared\n$L^2$-distance between a joint density $f$ and the product of its marginals, we\nfirst show that there is no valid test of independence that is uniformly\nconsistent against alternatives of the form $\\{f: D(f) \\geq \\rho^2 \\}$. We\ntherefore restrict attention to alternatives that impose additional\nSobolev-type smoothness constraints, and define a permutation test based on a\nbasis expansion and a $U$-statistic estimator of $D(f)$ that we prove is\nminimax optimal in terms of its separation rates in many instances. Finally,\nfor the case of a Fourier basis on $[0,1]^2$, we provide an approximation to\nthe power function that offers several additional insights. Our methodology is\nimplemented in the R package USP.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:04:23 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 11:50:28 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Berrett", "Thomas B.", ""], ["Kontoyiannis", "Ioannis", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2001.05517", "submitter": "David Burns", "authors": "David M. Burns and Cari M. Whyne", "title": "Personalized Activity Recognition with Deep Triplet Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge for a supervised learning approach to inertial human\nactivity recognition is the heterogeneity of data between individual users,\nresulting in very poor performance of impersonal algorithms for some subjects.\nWe present an approach to personalized activity recognition based on deep\nembeddings derived from a fully convolutional neural network. We experiment\nwith both categorical cross entropy loss and triplet loss for training the\nembedding, and describe a novel triplet loss function based on subject\ntriplets. We evaluate these methods on three publicly available inertial human\nactivity recognition data sets (MHEALTH, WISDM, and SPAR) comparing\nclassification accuracy, out-of-distribution activity detection, and embedding\ngeneralization to new activities. The novel subject triplet loss provides the\nbest performance overall, and all personalized deep embeddings out-perform our\nbaseline personalized engineered feature embedding and an impersonal fully\nconvolutional neural network classifier.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:17:02 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Burns", "David M.", ""], ["Whyne", "Cari M.", ""]]}, {"id": "2001.05532", "submitter": "Huy Phan", "authors": "Huy Phan and Ian V. McLoughlin and Lam Pham and Oliver Y. Ch\\'en and\n  Philipp Koch and Maarten De Vos and Alfred Mertins", "title": "Improving GANs for Speech Enhancement", "comments": "This letter has been accepted for publication in IEEE Signal\n  Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2020.3025020", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have recently been shown to be\nefficient for speech enhancement. However, most, if not all, existing speech\nenhancement GANs (SEGAN) make use of a single generator to perform one-stage\nenhancement mapping. In this work, we propose to use multiple generators that\nare chained to perform multi-stage enhancement mapping, which gradually refines\nthe noisy input signals in a stage-wise fashion. Furthermore, we study two\nscenarios: (1) the generators share their parameters and (2) the generators'\nparameters are independent. The former constrains the generators to learn a\ncommon mapping that is iteratively applied at all enhancement stages and\nresults in a small model footprint. On the contrary, the latter allows the\ngenerators to flexibly learn different enhancement mappings at different stages\nof the network at the cost of an increased model size. We demonstrate that the\nproposed multi-stage enhancement approach outperforms the one-stage SEGAN\nbaseline, where the independent generators lead to more favorable results than\nthe tied generators. The source code is available at\nhttp://github.com/pquochuy/idsegan.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:57:03 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 11:39:00 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 23:48:06 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Phan", "Huy", ""], ["McLoughlin", "Ian V.", ""], ["Pham", "Lam", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["De Vos", "Maarten", ""], ["Mertins", "Alfred", ""]]}, {"id": "2001.05534", "submitter": "C\\'edric Beaulac", "authors": "C\\'edric Beaulac, Jeffrey S. Rosenthal, Qinglin Pei, Debra Friedman,\n  Suzanne Wolden and David Hodgson", "title": "An evaluation of machine learning techniques to predict the outcome of\n  children treated for Hodgkin-Lymphoma on the AHOD0031 trial: A report from\n  the Children's Oncology Group", "comments": null, "journal-ref": "Applied Artificial Intelligence 2020", "doi": "10.1080/08839514.2020.1815151", "report-no": null, "categories": "q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript we analyze a data set containing information on children\nwith Hodgkin Lymphoma (HL) enrolled on a clinical trial. Treatments received\nand survival status were collected together with other covariates such as\ndemographics and clinical measurements. Our main task is to explore the\npotential of machine learning (ML) algorithms in a survival analysis context in\norder to improve over the Cox Proportional Hazard (CoxPH) model. We discuss the\nweaknesses of the CoxPH model we would like to improve upon and then we\nintroduce multiple algorithms, from well-established ones to state-of-the-art\nmodels, that solve these issues. We then compare every model according to the\nconcordance index and the brier score. Finally, we produce a series of\nrecommendations, based on our experience, for practitioners that would like to\nbenefit from the recent advances in artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:03:26 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 17:43:56 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Beaulac", "C\u00e9dric", ""], ["Rosenthal", "Jeffrey S.", ""], ["Pei", "Qinglin", ""], ["Friedman", "Debra", ""], ["Wolden", "Suzanne", ""], ["Hodgson", "David", ""]]}, {"id": "2001.05537", "submitter": "Shiqian Ma", "authors": "Conghui Tan, Yuqiu Qian, Shiqian Ma, Tong Zhang", "title": "Accelerated Dual-Averaging Primal-Dual Method for Composite Convex\n  Minimization", "comments": null, "journal-ref": "Optimization Methods and Software 2020", "doi": "10.1080/10556788.2020.1713779", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual averaging-type methods are widely used in industrial machine learning\napplications due to their ability to promoting solution structure (e.g.,\nsparsity) efficiently. In this paper, we propose a novel accelerated\ndual-averaging primal-dual algorithm for minimizing a composite convex\nfunction. We also derive a stochastic version of the proposed method which\nsolves empirical risk minimization, and its advantages on handling sparse data\nare demonstrated both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:05:41 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Tan", "Conghui", ""], ["Qian", "Yuqiu", ""], ["Ma", "Shiqian", ""], ["Zhang", "Tong", ""]]}, {"id": "2001.05540", "submitter": "Laura Ruis", "authors": "Laura Ruis, Mitchell Stern, Julia Proskurnia, William Chan", "title": "Insertion-Deletion Transformer", "comments": "Accepted as an Extended Abstract at the Workshop of Neural Generation\n  and Translation (WNGT 2019) at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Insertion-Deletion Transformer, a novel transformer-based\nneural architecture and training method for sequence generation. The model\nconsists of two phases that are executed iteratively, 1) an insertion phase and\n2) a deletion phase. The insertion phase parameterizes a distribution of\ninsertions on the current output hypothesis, while the deletion phase\nparameterizes a distribution of deletions over the current output hypothesis.\nThe training method is a principled and simple algorithm, where the deletion\nmodel obtains its signal directly on-policy from the insertion model output. We\ndemonstrate the effectiveness of our Insertion-Deletion Transformer on\nsynthetic translation tasks, obtaining significant BLEU score improvement over\nan insertion-only model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:26:48 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ruis", "Laura", ""], ["Stern", "Mitchell", ""], ["Proskurnia", "Julia", ""], ["Chan", "William", ""]]}, {"id": "2001.05545", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Pravendra Singh, Vinay P. Namboodiri, Piyush Rai", "title": "A \"Network Pruning Network\" Approach to Deep Model Compression", "comments": "Accepted in WACV'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a filter pruning approach for deep model compression, using a\nmultitask network. Our approach is based on learning a a pruner network to\nprune a pre-trained target network. The pruner is essentially a multitask deep\nneural network with binary outputs that help identify the filters from each\nlayer of the original network that do not have any significant contribution to\nthe model and can therefore be pruned. The pruner network has the same\narchitecture as the original network except that it has a\nmultitask/multi-output last layer containing binary-valued outputs (one per\nfilter), which indicate which filters have to be pruned. The pruner's goal is\nto minimize the number of filters from the original network by assigning zero\nweights to the corresponding output feature-maps. In contrast to most of the\nexisting methods, instead of relying on iterative pruning, our approach can\nprune the network (original network) in one go and, moreover, does not require\nspecifying the degree of pruning for each layer (and can learn it instead). The\ncompressed model produced by our approach is generic and does not need any\nspecial hardware/software support. Moreover, augmenting with other methods such\nas knowledge distillation, quantization, and connection pruning can increase\nthe degree of compression for the proposed approach. We show the efficacy of\nour proposed approach for classification and object detection tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:38:23 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Singh", "Pravendra", ""], ["Namboodiri", "Vinay P.", ""], ["Rai", "Piyush", ""]]}, {"id": "2001.05559", "submitter": "Yan Ru Pei", "authors": "Haik Manukian, Yan Ru Pei, Sean R.B. Bearden, Massimiliano Di Ventra", "title": "Mode-Assisted Unsupervised Learning of Restricted Boltzmann Machines", "comments": "28 pages, 4 figures. Revision: Updated footnote format", "journal-ref": "Communications Physics volume 3, Article number:105 (2020)", "doi": "10.1038/s42005-020-0373-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines (RBMs) are a powerful class of generative\nmodels, but their training requires computing a gradient that, unlike\nsupervised backpropagation on typical loss functions, is notoriously difficult\neven to approximate. Here, we show that properly combining standard gradient\nupdates with an off-gradient direction, constructed from samples of the RBM\nground state (mode), improves their training dramatically over traditional\ngradient methods. This approach, which we call mode training, promotes faster\ntraining and stability, in addition to lower converged relative entropy (KL\ndivergence). Along with the proofs of stability and convergence of this method,\nwe also demonstrate its efficacy on synthetic datasets where we can compute KL\ndivergences exactly, as well as on a larger machine learning standard, MNIST.\nThe mode training we suggest is quite versatile, as it can be applied in\nconjunction with any given gradient method, and is easily extended to more\ngeneral energy-based neural network structures such as deep, convolutional and\nunrestricted Boltzmann machines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:12:44 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 21:50:27 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Manukian", "Haik", ""], ["Pei", "Yan Ru", ""], ["Bearden", "Sean R. B.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "2001.05567", "submitter": "Nimar Arora", "authors": "Nimar S. Arora, Nazanin Khosravani Tehrani, Kinjal Divesh Shah,\n  Michael Tingley, Yucen Lily Li, Narjes Torabi, David Noursi, Sepehr Akhavan\n  Masouleh, Eric Lippert, Erik Meijer", "title": "Newtonian Monte Carlo: single-site MCMC meets second-order gradient\n  methods", "comments": "StarAI has a 6 page limit excluding references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-site Markov Chain Monte Carlo (MCMC) is a variant of MCMC in which a\nsingle coordinate in the state space is modified in each step. Structured\nrelational models are a good candidate for this style of inference. In the\nsingle-site context, second order methods become feasible because the typical\ncubic costs associated with these methods is now restricted to the dimension of\neach coordinate. Our work, which we call Newtonian Monte Carlo (NMC), is a\nmethod to improve MCMC convergence by analyzing the first and second order\ngradients of the target density to determine a suitable proposal density at\neach point. Existing first order gradient-based methods suffer from the problem\nof determining an appropriate step size. Too small a step size and it will take\na large number of steps to converge, while a very large step size will cause it\nto overshoot the high density region. NMC is similar to the Newton-Raphson\nupdate in optimization where the second order gradient is used to automatically\nscale the step size in each dimension. However, our objective is to find a\nparameterized proposal density rather than the maxima.\n  As a further improvement on existing first and second order methods, we show\nthat random variables with constrained supports don't need to be transformed\nbefore taking a gradient step. We demonstrate the efficiency of NMC on a number\nof different domains. For statistical models where the prior is conjugate to\nthe likelihood, our method recovers the posterior quite trivially in one step.\nHowever, we also show results on fairly large non-conjugate models, where NMC\nperforms better than adaptive first order methods such as NUTS or other inexact\nscalable inference methods such as Stochastic Variational Inference or\nbootstrapping.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:40:50 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Arora", "Nimar S.", ""], ["Tehrani", "Nazanin Khosravani", ""], ["Shah", "Kinjal Divesh", ""], ["Tingley", "Michael", ""], ["Li", "Yucen Lily", ""], ["Torabi", "Narjes", ""], ["Noursi", "David", ""], ["Masouleh", "Sepehr Akhavan", ""], ["Lippert", "Eric", ""], ["Meijer", "Erik", ""]]}, {"id": "2001.05571", "submitter": "Jan Brabec", "authors": "Jan Brabec, Tom\\'a\\v{s} Kom\\'arek, Vojt\\v{e}ch Franc, Luk\\'a\\v{s}\n  Machlica", "title": "On Model Evaluation under Non-constant Class Imbalance", "comments": "Accepted for proceedings of ICCS 2020. Supplementary code at:\n  https://github.com/CiscoCTA/nci_eval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world classification problems are significantly class-imbalanced to\ndetriment of the class of interest. The standard set of proper evaluation\nmetrics is well-known but the usual assumption is that the test dataset\nimbalance equals the real-world imbalance. In practice, this assumption is\noften broken for various reasons. The reported results are then often too\noptimistic and may lead to wrong conclusions about industrial impact and\nsuitability of proposed techniques. We introduce methods focusing on evaluation\nunder non-constant class imbalance. We show that not only the absolute values\nof commonly used metrics, but even the order of classifiers in relation to the\nevaluation metric used is affected by the change of the imbalance rate.\nFinally, we demonstrate that using subsampling in order to get a test dataset\nwith class imbalance equal to the one observed in the wild is not necessary,\nand eventually can lead to significant errors in classifier's performance\nestimate.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:52:24 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 17:58:21 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Brabec", "Jan", ""], ["Kom\u00e1rek", "Tom\u00e1\u0161", ""], ["Franc", "Vojt\u011bch", ""], ["Machlica", "Luk\u00e1\u0161", ""]]}, {"id": "2001.05573", "submitter": "Michael Hind", "authors": "Michael Hind, Dennis Wei, Yunfeng Zhang", "title": "Consumer-Driven Explanations for Machine Learning Decisions: An\n  Empirical Study of Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many proposed methods for explaining machine learning predictions are in fact\nchallenging to understand for nontechnical consumers. This paper builds upon an\nalternative consumer-driven approach called TED that asks for explanations to\nbe provided in training data, along with target labels. Using semi-synthetic\ndata from credit approval and employee retention applications, experiments are\nconducted to investigate some practical considerations with TED, including its\nperformance with different classification algorithms, varying numbers of\nexplanations, and variability in explanations. A new algorithm is proposed to\nhandle the case where some training examples do not have explanations. Our\nresults show that TED is robust to increasing numbers of explanations, noisy\nexplanations, and large fractions of missing explanations, thus making advances\ntoward its practical deployment.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:45:48 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hind", "Michael", ""], ["Wei", "Dennis", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "2001.05574", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman, Hao Xin, Wang Yang, Wu Yuesheng, Xiong Junfeng, and Zhang\n  Huan", "title": "Advbox: a toolbox to generate adversarial examples that fool neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have been extensively deployed for computer\nvision tasks, particularly visual classification problems, where new algorithms\nreported to achieve or even surpass the human performance. Recent studies have\nshown that they are all vulnerable to the attack of adversarial examples. Small\nand often imperceptible perturbations to the input images are sufficient to\nfool the most powerful neural networks. \\emph{Advbox} is a toolbox to generate\nadversarial examples that fool neural networks in PaddlePaddle, PyTorch,\nCaffe2, MxNet, Keras, TensorFlow and it can benchmark the robustness of machine\nlearning models. Compared to previous work, our platform supports black box\nattacks on Machine-Learning-as-a-service, as well as more attack scenarios,\nsuch as Face Recognition Attack, Stealth T-shirt, and DeepFake Face Detect. The\ncode is licensed under the Apache 2.0 and is openly available at\nhttps://github.com/advboxes/AdvBox. Advbox now supports Python 3.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:11:27 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 01:43:39 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 13:35:30 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 14:57:04 GMT"}, {"version": "v5", "created": "Wed, 26 Aug 2020 23:19:21 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Goodman", "Dou", ""], ["Xin", "Hao", ""], ["Yang", "Wang", ""], ["Yuesheng", "Wu", ""], ["Junfeng", "Xiong", ""], ["Huan", "Zhang", ""]]}, {"id": "2001.05591", "submitter": "Michael Minyi Zhang", "authors": "Avinava Dubey, Michael Minyi Zhang, Eric P. Xing, Sinead A. Williamson", "title": "Distributed, partially collapsed MCMC for Bayesian Nonparametrics", "comments": "To appear in the 23rd International Conference on Artificial\n  Intelligence and Statistics", "journal-ref": "Artificial Intelligence and Statistics, 108:3685-3695, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric (BNP) models provide elegant methods for discovering\nunderlying latent features within a data set, but inference in such models can\nbe slow. We exploit the fact that completely random measures, which commonly\nused models like the Dirichlet process and the beta-Bernoulli process can be\nexpressed as, are decomposable into independent sub-measures. We use this\ndecomposition to partition the latent measure into a finite measure containing\nonly instantiated components, and an infinite measure containing all other\ncomponents. We then select different inference algorithms for the two\ncomponents: uncollapsed samplers mix well on the finite measure, while\ncollapsed samplers mix well on the infinite, sparsely occupied tail. The\nresulting hybrid algorithm can be applied to a wide class of models, and can be\neasily distributed to allow scalable inference without sacrificing asymptotic\nconvergence guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 23:10:13 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 09:29:19 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:57:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Dubey", "Avinava", ""], ["Zhang", "Michael Minyi", ""], ["Xing", "Eric P.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "2001.05617", "submitter": "Varun Embar", "authors": "Varun Embar, Sriram Srinivasan, Lise Getoor", "title": "Estimating Aggregate Properties In Relational Networks With Unobserved\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregate network properties such as cluster cohesion and the number of\nbridge nodes can be used to glean insights about a network's community\nstructure, spread of influence and the resilience of the network to faults.\nEfficiently computing network properties when the network is fully observed has\nreceived significant attention (Wasserman and Faust 1994; Cook and Holder\n2006), however the problem of computing aggregate network properties when there\nis missing data attributes has received little attention. Computing these\nproperties for networks with missing attributes involves performing inference\nover the network. Statistical relational learning (SRL) and graph neural\nnetworks (GNNs) are two classes of machine learning approaches well suited for\ninferring missing attributes in a graph. In this paper, we study the\neffectiveness of these approaches in estimating aggregate properties on\nnetworks with missing attributes. We compare two SRL approaches and three GNNs.\nFor these approaches we estimate these properties using point estimates such as\nMAP and mean. For SRL-based approaches that can infer a joint distribution over\nthe missing attributes, we also estimate these properties as an expectation\nover the distribution. To compute the expectation tractably for probabilistic\nsoft logic, one of the SRL approaches that we study, we introduce a novel\nsampling framework. In the experimental evaluation, using three benchmark\ndatasets, we show that SRL-based approaches tend to outperform GNN-based\napproaches both in computing aggregate properties and predictive accuracy.\nSpecifically, we show that estimating the aggregate properties as an\nexpectation over the joint distribution outperforms point estimates.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 02:43:02 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 00:50:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Embar", "Varun", ""], ["Srinivasan", "Sriram", ""], ["Getoor", "Lise", ""]]}, {"id": "2001.05624", "submitter": "Toshitaka Hayashi", "authors": "Toshitaka Hayashi and Hamido Fujita", "title": "Cluster-based Zero-shot learning for multivariate data", "comments": "J Ambient Intell Human Comput (2020)", "journal-ref": null, "doi": "10.1007/s12652-020-02268-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning requires a sufficient training dataset which includes all\nlabel. However, there are cases that some class is not in the training data.\nZero-Shot Learning (ZSL) is the task of predicting class that is not in the\ntraining data(target class). The existing ZSL method is done for image data.\nHowever, the zero-shot problem should happen to every data type. Hence,\nconsidering ZSL for other data types is required. In this paper, we propose the\ncluster-based ZSL method, which is a baseline method for multivariate binary\nclassification problems. The proposed method is based on the assumption that if\ndata is far from training data, the data is considered as target class. In\ntraining, clustering is done for training data. In prediction, the data is\ndetermined belonging to a cluster or not. If data does not belong to a cluster,\nthe data is predicted as target class. The proposed method is evaluated and\ndemonstrated using the KEEL dataset. This paper has been published in the\nJournal of Ambient Intelligence and Humanized Computing. The final version is\navailable at the following URL:\nhttps://link.springer.com/article/10.1007/s12652-020-02268-5\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:01:00 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 02:16:46 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 06:23:44 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 02:41:39 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Hayashi", "Toshitaka", ""], ["Fujita", "Hamido", ""]]}, {"id": "2001.05636", "submitter": "Haitao Xu", "authors": "Haitao Xu and Brendan McCane and Lech Szymanski and Craig Atkinson", "title": "MIME: Mutual Information Minimisation Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that reinforcement learning agents that learn by surprise (surprisal)\nget stuck at abrupt environmental transition boundaries because these\ntransitions are difficult to learn. We propose a counter-intuitive solution\nthat we call Mutual Information Minimising Exploration (MIME) where an agent\nlearns a latent representation of the environment without trying to predict the\nfuture states. We show that our agent performs significantly better over sharp\ntransition boundaries while matching the performance of surprisal driven agents\nelsewhere. In particular, we show state-of-the-art performance on difficult\nlearning games such as Gravitar, Montezuma's Revenge and Doom.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 04:01:10 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Xu", "Haitao", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Atkinson", "Craig", ""]]}, {"id": "2001.05665", "submitter": "Pegah Jandaghi", "authors": "Pegah Jandaghi, Jay Pujara", "title": "Human-like Time Series Summaries via Trend Utility Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, humans prefer a text-based representation of quantitative\ndata over numerical, tabular, or graphical representations. The attractiveness\nof textual summaries for complex data has inspired research on data-to-text\nsystems. While there are several data-to-text tools for time series, few of\nthem try to mimic how humans summarize for time series. In this paper, we\npropose a model to create human-like text descriptions for time series. Our\nsystem finds patterns in time series data and ranks these patterns based on\nempirical observations of human behavior using utility estimation. Our proposed\nutility estimation model is a Bayesian network capturing interdependencies\nbetween different patterns. We describe the learning steps for this network and\nintroduce baselines along with their performance for each step. The output of\nour system is a natural language description of time series that attempts to\nmatch a human's summary of the same data.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:09:50 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:55:15 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Jandaghi", "Pegah", ""], ["Pujara", "Jay", ""]]}, {"id": "2001.05676", "submitter": "Ji Hyung Jung", "authors": "Ji Hyung Jung, Hye Won Chung, and Ji Oon Lee", "title": "Weak Detection in the Spiked Wigner Model with General Rank", "comments": "35 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical decision process of detecting the signal from a\n`signal+noise' type matrix model with an additive Wigner noise. We propose a\nhypothesis test based on the linear spectral statistics of the data matrix,\nwhich does not depend on the distribution of the signal or the noise. The test\nis optimal under the Gaussian noise if the signal-to-noise ratio is small, as\nit minimizes the sum of the Type-I and Type-II errors. Under the non-Gaussian\nnoise, the test can be improved with an entrywise transformation to the data\nmatrix. We also introduce an algorithm that estimates the rank of the signal\nwhen it is not known a priori.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:40:24 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 08:29:54 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 05:33:32 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Jung", "Ji Hyung", ""], ["Chung", "Hye Won", ""], ["Lee", "Ji Oon", ""]]}, {"id": "2001.05699", "submitter": "Li Ye", "authors": "Li Ye, Yishi Lin, Hong Xie, John C.S. Lui", "title": "Combining Offline Causal Inference and Online Bandit Learning for Data\n  Driven Decision", "comments": "27 pages, 35 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question for companies with large amount of logged data is: How\nto use such logged data together with incoming streaming data to make good\ndecisions? Many companies currently make decisions via online A/B tests, but\nwrong decisions during testing hurt users' experiences and cause irreversible\ndamage. A typical alternative is offline causal inference, which analyzes\nlogged data alone to make decisions. However, these decisions are not adaptive\nto the new incoming data, and so a wrong decision will continuously hurt users'\nexperiences. To overcome the aforementioned limitations, we propose a framework\nto unify offline causal inference algorithms (e.g., weighting, matching) and\nonline learning algorithms (e.g., UCB, LinUCB). We propose novel algorithms and\nderive bounds on the decision accuracy via the notion of \"regret\". We derive\nthe first upper regret bound for forest-based online bandit algorithms.\nExperiments on two real datasets show that our algorithms outperform other\nalgorithms that use only logged data or online feedbacks, or algorithms that do\nnot use the data properly.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:58:42 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 13:27:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ye", "Li", ""], ["Lin", "Yishi", ""], ["Xie", "Hong", ""], ["Lui", "John C. S.", ""]]}, {"id": "2001.05726", "submitter": "Raju Ram", "authors": "Raju Ram, Sabine M\\\"uller, Franz-Josef Pfreundt, Nicolas R. Gauger,\n  Janis Keuper", "title": "Scalable Hyperparameter Optimization with Lazy Gaussian Processes", "comments": "14 pages; 6 figures; 4 tables; Accepted in proceedings of MLHPC 2019:\n  Fifth International Workshop on Machine Learning in High Performance\n  Computing Environments, Super Computing Conference 2019, Denver, Colorado", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning methods require careful selection of hyper-parameters\nin order to train a high performing model with good generalization abilities.\nHence, several automatic selection algorithms have been introduced to overcome\ntedious manual (try and error) tuning of these parameters. Due to its very high\nsample efficiency, Bayesian Optimization over a Gaussian Processes modeling of\nthe parameter space has become the method of choice. Unfortunately, this\napproach suffers from a cubic compute complexity due to underlying Cholesky\nfactorization, which makes it very hard to be scaled beyond a small number of\nsampling steps. In this paper, we present a novel, highly accurate\napproximation of the underlying Gaussian Process. Reducing its computational\ncomplexity from cubic to quadratic allows an efficient strong scaling of\nBayesian Optimization while outperforming the previous approach regarding\noptimization accuracy. The first experiments show speedups of a factor of 162\nin single node and further speed up by a factor of 5 in a parallel environment.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:15:55 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ram", "Raju", ""], ["M\u00fcller", "Sabine", ""], ["Pfreundt", "Franz-Josef", ""], ["Gauger", "Nicolas R.", ""], ["Keuper", "Janis", ""]]}, {"id": "2001.05759", "submitter": "Diego Garc\\'ia-Gil", "authors": "Diego Garc\\'ia-Gil, Salvador Garc\\'ia, Ning Xiong, Francisco Herrera", "title": "A Methodology guided by Decision Trees Ensemble and Smart Data for\n  Imbalanced Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differences in data size per class, also known as imbalanced data\ndistribution, have become a common problem affecting data quality. Big Data\nscenarios pose a new challenge to traditional imbalanced classification\nalgorithms, since they are not prepared to work with such amount of data. Split\ndata strategies and lack of data in the minority class due to the use of\nMapReduce paradigm have posed new challenges for tackling the imbalance between\nclasses in Big Data scenarios. Ensembles have shown to be able to successfully\naddress imbalanced data problems. Smart Data refers to data of enough quality\nto achieve high performance models. The combination of ensembles and Smart\nData, achieved through Big Data preprocessing, should be a great synergy. In\nthis paper, we propose a novel methodology based on Decision Trees Ensemble\nwith Smart Data for addressing the imbalanced classification problem in Big\nData domains, namely DeTE_SD methodology. This methodology is based on the\nlearning of different decision trees using distributed quality data for the\nensemble process. This quality data is achieved by fusing Random\nDiscretization, Principal Components Analysis and clustering-based Random\nOversampling for obtaining different Smart Data versions of the original data.\nExperiments carried out in 21 binary adapted datasets have shown that our\nmethodology outperforms Random Forest.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:25:59 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 07:29:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Garc\u00eda-Gil", "Diego", ""], ["Garc\u00eda", "Salvador", ""], ["Xiong", "Ning", ""], ["Herrera", "Francisco", ""]]}, {"id": "2001.05768", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Some convergent results for Backtracking Gradient Descent method on\n  Banach spaces", "comments": "More details and improvements added, including: C^1 convex functions\n  satisfy Condition C, normalized duality mapping, prevalence and shyness of\n  sets in Banach spaces, hereditary Lindelof property of weak topology. Several\n  typos fixed. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.AP math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main result concerns the following condition:\n  {\\bf Condition C.} Let $X$ be a Banach space. A $C^1$ function\n$f:X\\rightarrow \\mathbb{R}$ satisfies Condition C if whenever $\\{x_n\\}$ weakly\nconverges to $x$ and $\\lim _{n\\rightarrow\\infty}||\\nabla f(x_n)||=0$, then\n$\\nabla f(x)=0$.\n  We assume that there is given a canonical isomorphism between $X$ and its\ndual $X^*$, for example when $X$ is a Hilbert space.\n  {\\bf Theorem.} Let $X$ be a reflexive, complete Banach space and\n$f:X\\rightarrow \\mathbb{R}$ be a $C^2$ function which satisfies Condition C.\nMoreover, we assume that for every bounded set $S\\subset X$, then $\\sup _{x\\in\nS}||\\nabla ^2f(x)||<\\infty$. We choose a random point $x_0\\in X$ and construct\nby the Local Backtracking GD procedure (which depends on $3$ hyper-parameters\n$\\alpha ,\\beta ,\\delta _0$, see later for details) the sequence\n$x_{n+1}=x_n-\\delta (x_n)\\nabla f(x_n)$. Then we have:\n  1) Every cluster point of $\\{x_n\\}$, in the {\\bf weak} topology, is a\ncritical point of $f$.\n  2) Either $\\lim _{n\\rightarrow\\infty}f(x_n)=-\\infty$ or $\\lim\n_{n\\rightarrow\\infty}||x_{n+1}-x_n||=0$.\n  3) Here we work with the weak topology. Let $\\mathcal{C}$ be the set of\ncritical points of $f$. Assume that $\\mathcal{C}$ has a bounded component $A$.\nLet $\\mathcal{B}$ be the set of cluster points of $\\{x_n\\}$. If\n$\\mathcal{B}\\cap A\\not= \\emptyset$, then $\\mathcal{B}\\subset A$ and\n$\\mathcal{B}$ is connected.\n  4) Assume that $X$ is separable. Then for generic choices of $\\alpha ,\\beta\n,\\delta _0$ and the initial point $x_0$, if the sequence $\\{x_n\\}$ converges -\nin the {\\bf weak} topology, then the limit point cannot be a saddle point.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:49:42 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 13:40:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2001.05819", "submitter": "Yuling Jiao", "authors": "Jian Huang, Yuling Jiao, Lican Kang, Jin Liu, Yanyan Liu, Xiliang Lu", "title": "A Support Detection and Root Finding Approach for Learning\n  High-dimensional Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is important for modeling high-dimensional data, where the\nnumber of variables can be much larger than the sample size. In this paper, we\ndevelop a support detection and root finding procedure to learn the high\ndimensional sparse generalized linear models and denote this method by GSDAR.\nBased on the KKT condition for $\\ell_0$-penalized maximum likelihood\nestimations, GSDAR generates a sequence of estimators iteratively.\n  Under some restricted invertibility conditions on the maximum likelihood\nfunction and sparsity assumption on the target coefficients, the errors of the\nproposed estimate decays exponentially to the optimal order. Moreover, the\noracle estimator can be recovered if the target signal is stronger than the\ndetectable level.\n  We conduct simulations and real data analysis to illustrate the advantages of\nour proposed method over several existing methods, including Lasso and MCP.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 14:35:17 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Kang", "Lican", ""], ["Liu", "Jin", ""], ["Liu", "Yanyan", ""], ["Lu", "Xiliang", ""]]}, {"id": "2001.05834", "submitter": "Georg Hille", "authors": "Georg Hille and Johannes Steffen and Max D\\\"unnwald and Mathias Becker\n  and Sylvia Saalfeld and Klaus T\\\"onnies", "title": "Spinal Metastases Segmentation in MR Imaging using Deep Convolutional\n  Neural Networks", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study's objective was to segment spinal metastases in diagnostic MR\nimages using a deep learning-based approach. Segmentation of such lesions can\npresent a pivotal step towards enhanced therapy planning and validation, as\nwell as intervention support during minimally invasive and image-guided\nsurgeries like radiofrequency ablations. For this purpose, we used a U-Net like\narchitecture trained with 40 clinical cases including both, lytic and sclerotic\nlesion types and various MR sequences. Our proposed method was evaluated with\nregards to various factors influencing the segmentation quality, e.g. the used\nMR sequences and the input dimension. We quantitatively assessed our\nexperiments using Dice coefficients, sensitivity and specificity rates.\nCompared to expertly annotated lesion segmentations, the experiments yielded\npromising results with average Dice scores up to 77.6% and mean sensitivity\nrates up to 78.9%. To our best knowledge, our proposed study is one of the\nfirst to tackle this particular issue, which limits direct comparability with\nrelated works. In respect to similar deep learning-based lesion segmentations,\ne.g. in liver MR images or spinal CT images, our experiments showed similar or\nin some respects superior segmentation quality. Overall, our automatic approach\ncan provide almost expert-like segmentation accuracy in this challenging and\nambitious task.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:59:31 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:21:08 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Hille", "Georg", ""], ["Steffen", "Johannes", ""], ["D\u00fcnnwald", "Max", ""], ["Becker", "Mathias", ""], ["Saalfeld", "Sylvia", ""], ["T\u00f6nnies", "Klaus", ""]]}, {"id": "2001.05839", "submitter": "David Noever", "authors": "David Noever, Wes Regian, Matt Ciolino, Josh Kalin, Dom Hambrick, Kaye\n  Blankenship", "title": "Discoverability in Satellite Imagery: A Good Sentence is Worth a\n  Thousand Pictures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small satellite constellations provide daily global coverage of the earth's\nlandmass, but image enrichment relies on automating key tasks like change\ndetection or feature searches. For example, to extract text annotations from\nraw pixels requires two dependent machine learning models, one to analyze the\noverhead image and the other to generate a descriptive caption. We evaluate\nseven models on the previously largest benchmark for satellite image captions.\nWe extend the labeled image samples five-fold, then augment, correct and prune\nthe vocabulary to approach a rough min-max (minimum word, maximum description).\nThis outcome compares favorably to previous work with large pre-trained image\nmodels but offers a hundred-fold reduction in model size without sacrificing\noverall accuracy (when measured with log entropy loss). These smaller models\nprovide new deployment opportunities, particularly when pushed to edge\nprocessors, on-board satellites, or distributed ground stations. To quantify a\ncaption's descriptiveness, we introduce a novel multi-class confusion or error\nmatrix to score both human-labeled test data and never-labeled images that\ninclude bounding box detection but lack full sentence captions. This work\nsuggests future captioning strategies, particularly ones that can enrich the\nclass coverage beyond land use applications and that lessen color-centered and\nadjacency adjectives (\"green\", \"near\", \"between\", etc.). Many modern language\ntransformers present novel and exploitable models with world knowledge gleaned\nfrom training from their vast online corpus. One interesting, but easy example\nmight learn the word association between wind and waves, thus enriching a beach\nscene with more than just color descriptions that otherwise might be accessed\nfrom raw pixels without text annotation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 20:41:18 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Noever", "David", ""], ["Regian", "Wes", ""], ["Ciolino", "Matt", ""], ["Kalin", "Josh", ""], ["Hambrick", "Dom", ""], ["Blankenship", "Kaye", ""]]}, {"id": "2001.05844", "submitter": "Satoshi Ono", "authors": "Takahiro Suzuki, Shingo Takeshita, Satoshi Ono", "title": "Adversarial Example Generation using Evolutionary Multi-objective\n  Optimization", "comments": null, "journal-ref": "2019 IEEE Congress on Evolutionary Computation (CEC), Wellington,\n  New Zealand, 2019, pp. 2136-2144", "doi": "10.1109/CEC.2019.8790123", "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Evolutionary Multi-objective Optimization (EMO)-based\nAdversarial Example (AE) design method that performs under black-box setting.\nPrevious gradient-based methods produce AEs by changing all pixels of a target\nimage, while previous EC-based method changes small number of pixels to produce\nAEs. Thanks to EMO's property of population based-search, the proposed method\nproduces various types of AEs involving ones locating between AEs generated by\nthe previous two approaches, which helps to know the characteristics of a\ntarget model or to know unknown attack patterns. Experimental results showed\nthe potential of the proposed method, e.g., it can generate robust AEs and,\nwith the aid of DCT-based perturbation pattern generation, AEs for high\nresolution images.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:34:09 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Suzuki", "Takahiro", ""], ["Takeshita", "Shingo", ""], ["Ono", "Satoshi", ""]]}, {"id": "2001.05848", "submitter": "Xiao Huang", "authors": "Xiao Huang, Dong Xu, Zhenlong Li, Cuizhen Wang", "title": "Translating multispectral imagery to nighttime imagery via conditional\n  generative adversarial networks", "comments": "4 pages, 3 figures, submitted to the 2020 IEEE International\n  Geoscience and Remote Sensing Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nighttime satellite imagery has been applied in a wide range of fields.\nHowever, our limited understanding of how observed light intensity is formed\nand whether it can be simulated greatly hinders its further application. This\nstudy explores the potential of conditional Generative Adversarial Networks\n(cGAN) in translating multispectral imagery to nighttime imagery. A popular\ncGAN framework, pix2pix, was adopted and modified to facilitate this\ntranslation using gridded training image pairs derived from Landsat 8 and\nVisible Infrared Imaging Radiometer Suite (VIIRS). The results of this study\nprove the possibility of multispectral-to-nighttime translation and further\nindicate that, with the additional social media data, the generated nighttime\nimagery can be very similar to the ground-truth imagery. This study fills the\ngap in understanding the composition of satellite observed nighttime light and\nprovides new paradigms to solve the emerging problems in nighttime remote\nsensing fields, including nighttime series construction, light desaturation,\nand multi-sensor calibration.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 03:20:29 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Huang", "Xiao", ""], ["Xu", "Dong", ""], ["Li", "Zhenlong", ""], ["Wang", "Cuizhen", ""]]}, {"id": "2001.05855", "submitter": "Jacob Decoto", "authors": "Jacob J Decoto, David RC Dayton", "title": "Deep Learning Enabled Uncorrelated Space Observation Association", "comments": "Approved for public release by Department of Defense Prepublication\n  Office, Ref: 20-S-0428", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncorrelated optical space observation association represents a classic\nneedle in a haystack problem. The objective being to find small groups of\nobservations that are likely of the same resident space objects (RSOs) from\namongst the much larger population of all uncorrelated observations. These\nobservations being potentially widely disparate both temporally and with\nrespect to the observing sensor position. By training on a large representative\ndata set this paper shows that a deep learning enabled learned model with no\nencoded knowledge of physics or orbital mechanics can learn a model for\nidentifying observations of common objects. When presented with balanced input\nsets of 50% matching observation pairs the learned model was able to correctly\nidentify if the observation pairs were of the same RSO 83.1% of the time. The\nresulting learned model is then used in conjunction with a search algorithm on\nan unbalanced demonstration set of 1,000 disparate simulated uncorrelated\nobservations and is shown to be able to successfully identify true three\nobservation sets representing 111 out of 142 objects in the population. With\nmost objects being identified in multiple three observation triplets. This is\naccomplished while only exploring 0.06% of the search space of 1.66e8 possible\nunique triplet combinations.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:33:11 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Decoto", "Jacob J", ""], ["Dayton", "David RC", ""]]}, {"id": "2001.05862", "submitter": "Siming Bayer", "authors": "Siming Bayer, Ute Spiske, Jie Luo, Tobias Geimer, William M. Wells\n  III, Martin Ostermeier, Rebecca Fahrig, Arya Nabavi, Christoph Bert, Ilker\n  Eyupoglo, and Andreas Maier", "title": "An Investigation of Feature-based Nonrigid Image Registration using\n  Gaussian Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a wide range of clinical applications, such as adaptive treatment\nplanning or intraoperative image update, feature-based deformable registration\n(FDR) approaches are widely employed because of their simplicity and low\ncomputational complexity. FDR algorithms estimate a dense displacement field by\ninterpolating a sparse field, which is given by the established correspondence\nbetween selected features. In this paper, we consider the deformation field as\na Gaussian Process (GP), whereas the selected features are regarded as prior\ninformation on the valid deformations. Using GP, we are able to estimate the\nboth dense displacement field and a corresponding uncertainty map at once.\nFurthermore, we evaluated the performance of different hyperparameter settings\nfor squared exponential kernels with synthetic, phantom and clinical data\nrespectively. The quantitative comparison shows, GP-based interpolation has\nperformance on par with state-of-the-art B-spline interpolation. The greatest\nclinical benefit of GP-based interpolation is that it gives a reliable estimate\nof the mathematical uncertainty of the calculated dense displacement map.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:51:41 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Bayer", "Siming", ""], ["Spiske", "Ute", ""], ["Luo", "Jie", ""], ["Geimer", "Tobias", ""], ["Wells", "William M.", "III"], ["Ostermeier", "Martin", ""], ["Fahrig", "Rebecca", ""], ["Nabavi", "Arya", ""], ["Bert", "Christoph", ""], ["Eyupoglo", "Ilker", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.05873", "submitter": "Harshitha Machiraju", "authors": "Harshitha Machiraju, Vineeth N Balasubramanian", "title": "A Little Fog for a Large Turn", "comments": "Accepted to WACV 2020", "journal-ref": null, "doi": "10.1109/WACV45572.2020.9093549", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small, carefully crafted perturbations called adversarial perturbations can\neasily fool neural networks. However, these perturbations are largely additive\nand not naturally found. We turn our attention to the field of Autonomous\nnavigation wherein adverse weather conditions such as fog have a drastic effect\non the predictions of these systems. These weather conditions are capable of\nacting like natural adversaries that can help in testing models. To this end,\nwe introduce a general notion of adversarial perturbations, which can be\ncreated using generative models and provide a methodology inspired by\nCycle-Consistent Generative Adversarial Networks to generate adversarial\nweather conditions for a given image. Our formulation and results show that\nthese images provide a suitable testbed for steering models used in Autonomous\nnavigation models. Our work also presents a more natural and general definition\nof Adversarial perturbations based on Perceptual Similarity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:09:48 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Machiraju", "Harshitha", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2001.05878", "submitter": "Sourav Mishra", "authors": "Sourav Mishra, Subhajit Chaudhury, Hideaki Imaizumi, Toshihiko\n  Yamasaki", "title": "Assessing Robustness of Deep learning Methods in Dermatological Workflow", "comments": "Accepted in ACM CHIL 2020 Workshop (Oral and poster, without\n  publication)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to evaluate the suitability of current deep learning methods\nfor clinical workflow especially by focusing on dermatology. Although deep\nlearning methods have been attempted to get dermatologist level accuracy in\nseveral individual conditions, it has not been rigorously tested for common\nclinical complaints. Most projects involve data acquired in well-controlled\nlaboratory conditions. This may not reflect regular clinical evaluation where\ncorresponding image quality is not always ideal. We test the robustness of deep\nlearning methods by simulating non-ideal characteristics on user submitted\nimages of ten classes of diseases. Assessing via imitated conditions, we have\nfound the overall accuracy to drop and individual predictions change\nsignificantly in many cases despite of robust training.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:15:38 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 13:51:35 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Mishra", "Sourav", ""], ["Chaudhury", "Subhajit", ""], ["Imaizumi", "Hideaki", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "2001.05887", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Xudong Li, Shun Lu, Bo Zhang, and Jixiang Li", "title": "MixPath: A Unified Approach for One-shot Neural Architecture Search", "comments": "Bridge the gap between one shot NAS and multi branch using shadow BN\n  with good ranking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blending multiple convolutional kernels is proved advantageous in neural\narchitectural design. However, current neural architecture search approaches\nare mainly limited to stacked single-path search space. How can the one-shot\ndoctrine search for multi-path models remains unresolved. Specifically, we are\nmotivated to train a multi-path supernet to accurately evaluate the candidate\narchitectures. In this paper, we discover that in the studied search space,\nfeature vectors summed from multiple paths are nearly multiples of those from a\nsingle path, which perturbs supernet training and its ranking ability. In this\nregard, we propose a novel mechanism called Shadow Batch Normalization(SBN) to\nregularize the disparate feature statistics. Extensive experiments prove that\nSBN is capable of stabilizing the training and improving the ranking\nperformance (e.g. Kendall Tau 0.597 tested on NAS-Bench-101). We call our\nunified multi-path one-shot approach as MixPath, which generates a series of\nmodels that achieve state-of-the-art results on ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:24:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 11:05:45 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 10:47:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Li", "Xudong", ""], ["Lu", "Shun", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""]]}, {"id": "2001.05895", "submitter": "Daniel H Thompson", "authors": "Divya Gautam, Maria Lomeli, Kostis Gourgoulias, Daniel H. Thompson,\n  Saurabh Johri", "title": "Masking schemes for universal marginalisers", "comments": "To be published in Proceedings of the 2nd Symposium on Advances in\n  Approximate Bayesian Inference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the effect of structure-agnostic and structure-dependent masking\nschemes when training a universal marginaliser (arXiv:1711.00695) in order to\nlearn conditional distributions of the form $P(x_i |\\mathbf x_{\\mathbf b})$,\nwhere $x_i$ is a given random variable and $\\mathbf x_{\\mathbf b}$ is some\narbitrary subset of all random variables of the generative model of interest.\nIn other words, we mimic the self-supervised training of a denoising\nautoencoder, where a dataset of unlabelled data is used as partially observed\ninput and the neural approximator is optimised to minimise reconstruction loss.\nWe focus on studying the underlying process of the partially observed\ndata---how good is the neural approximator at learning all conditional\ndistributions when the observation process at prediction time differs from the\nmasking process during training? We compare networks trained with different\nmasking schemes in terms of their predictive performance and generalisation\nproperties.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:35:06 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Gautam", "Divya", ""], ["Lomeli", "Maria", ""], ["Gourgoulias", "Kostis", ""], ["Thompson", "Daniel H.", ""], ["Johri", "Saurabh", ""]]}, {"id": "2001.05918", "submitter": "Giorgi Nadiradze", "authors": "Giorgi Nadiradze, Ilia Markov, Bapi Chatterjee, Vyacheslav Kungurtsev,\n  Dan Alistarh", "title": "Elastic Consistency: A General Consistency Model for Distributed\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has made tremendous progress in recent years, with models\nmatching or even surpassing humans on a series of specialized tasks. One key\nelement behind the progress of machine learning in recent years has been the\nability to train machine learning models in large-scale distributed\nshared-memory and message-passing environments. Many of these models are\ntrained employing variants of stochastic gradient descent (SGD) based\noptimization.\n  In this paper, we introduce a general consistency condition covering\ncommunication-reduced and asynchronous distributed SGD implementations. Our\nframework, called elastic consistency enables us to derive convergence bounds\nfor a variety of distributed SGD methods used in practice to train large-scale\nmachine learning models. The proposed framework de-clutters the\nimplementation-specific convergence analysis and provides an abstraction to\nderive convergence bounds. We utilize the framework to analyze a sparsification\nscheme for distributed SGD methods in an asynchronous setting for convex and\nnon-convex objectives. We implement the distributed SGD variant to train deep\nCNN models in an asynchronous shared-memory setting. Empirical results show\nthat error-feedback may not necessarily help in improving the convergence of\nsparsified asynchronous distributed SGD, which corroborates an insight\nsuggested by our convergence analysis.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:10:58 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 11:02:38 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Nadiradze", "Giorgi", ""], ["Markov", "Ilia", ""], ["Chatterjee", "Bapi", ""], ["Kungurtsev", "Vyacheslav", ""], ["Alistarh", "Dan", ""]]}, {"id": "2001.05924", "submitter": "L\\'eo Neufcourt", "authors": "L\\'eo Neufcourt, Yuchen Cao, Samuel A. Giuliani, Witold Nazarewicz,\n  Erik Olsen and Oleg B. Tarasov", "title": "Quantified limits of the nuclear landscape", "comments": null, "journal-ref": "Phys. Rev. C 101, 044307 (2020)", "doi": "10.1103/PhysRevC.101.044307", "report-no": null, "categories": "nucl-th nucl-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chart of the nuclides is limited by particle drip lines beyond which\nnuclear stability to proton or neutron emission is lost. Predicting the range\nof particle-bound isotopes poses an appreciable challenge for nuclear theory as\nit involves extreme extrapolations of nuclear masses beyond the regions where\nexperimental information is available. Still, quantified extrapolations are\ncrucial for a variety of applications, including the modeling of stellar\nnucleosynthesis. We use microscopic nuclear mass models and Bayesian\nmethodology to provide quantified predictions of proton and neutron separation\nenergies as well as Bayesian probabilities of existence throughout the nuclear\nlandscape all the way to the particle drip lines. We apply nuclear density\nfunctional theory with several energy density functionals. To account for\nuncertainties, Bayesian Gaussian processes are trained on the separation-energy\nresiduals for each individual model, and the resulting predictions are combined\nvia Bayesian model averaging. This framework allows to account for systematic\nand statistical uncertainties and propagate them to extrapolative predictions.\nWe characterize the drip-line regions where the probability that the nucleus is\nparticle-bound decreases from $1$ to $0$. In these regions, we provide\nquantified predictions for one- and two-nucleon separation energies. According\nto our Bayesian model averaging analysis, 7759 nuclei with $Z\\leq 119$ have a\nprobability of existence $\\geq 0.5$. The extrapolations obtained in this study\nwill be put through stringent tests when new experimental information on exotic\nnuclei becomes available. In this respect, the quantified landscape of nuclear\nexistence obtained in this study should be viewed as a dynamical prediction\nthat will be fine-tuned when new experimental information and improved global\nmass models become available.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:25:00 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:07:01 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Neufcourt", "L\u00e9o", ""], ["Cao", "Yuchen", ""], ["Giuliani", "Samuel A.", ""], ["Nazarewicz", "Witold", ""], ["Olsen", "Erik", ""], ["Tarasov", "Oleg B.", ""]]}, {"id": "2001.05936", "submitter": "Joseph Bethge", "authors": "Joseph Bethge, Christian Bartz, Haojin Yang, Ying Chen, and Christoph\n  Meinel", "title": "MeliusNet: Can Binary Neural Networks Achieve MobileNet-level Accuracy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) are neural networks which use binary weights\nand activations instead of the typical 32-bit floating point values. They have\nreduced model sizes and allow for efficient inference on mobile or embedded\ndevices with limited power and computational resources. However, the\nbinarization of weights and activations leads to feature maps of lower quality\nand lower capacity and thus a drop in accuracy compared to traditional\nnetworks. Previous work has increased the number of channels or used multiple\nbinary bases to alleviate these problems. In this paper, we instead present an\narchitectural approach: MeliusNet. It consists of alternating a DenseBlock,\nwhich increases the feature capacity, and our proposed ImprovementBlock, which\nincreases the feature quality. Experiments on the ImageNet dataset demonstrate\nthe superior performance of our MeliusNet over a variety of popular binary\narchitectures with regards to both computation savings and accuracy.\nFurthermore, with our method we trained BNN models, which for the first time\ncan match the accuracy of the popular compact network MobileNet-v1 in terms of\nmodel size, number of operations and accuracy. Our code is published online at\nhttps://github.com/hpi-xnor/BMXNet-v2\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:56:10 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 11:52:06 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Bethge", "Joseph", ""], ["Bartz", "Christian", ""], ["Yang", "Haojin", ""], ["Chen", "Ying", ""], ["Meinel", "Christoph", ""]]}, {"id": "2001.05948", "submitter": "S\\'andor Baran", "authors": "\\'Agnes Baran, Sebastian Lerch, Mehrez El Ayari and S\\'andor Baran", "title": "Machine learning for total cloud cover prediction", "comments": "24 pages, 7 figures", "journal-ref": "Neural Computing and Applications 33 (2021), 2605-2620", "doi": "10.1007/s00521-020-05139-4", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and reliable forecasting of total cloud cover (TCC) is vital for\nmany areas such as astronomy, energy demand and production, or agriculture.\nMost meteorological centres issue ensemble forecasts of TCC, however, these\nforecasts are often uncalibrated and exhibit worse forecast skill than ensemble\nforecasts of other weather variables. Hence, some form of post-processing is\nstrongly required to improve predictive performance. As TCC observations are\nusually reported on a discrete scale taking just nine different values called\noktas, statistical calibration of TCC ensemble forecasts can be considered a\nclassification problem with outputs given by the probabilities of the oktas.\nThis is a classical area where machine learning methods are applied. We\ninvestigate the performance of post-processing using multilayer perceptron\n(MLP) neural networks, gradient boosting machines (GBM) and random forest (RF)\nmethods. Based on the European Centre for Medium-Range Weather Forecasts global\nTCC ensemble forecasts for 2002-2014 we compare these approaches with the\nproportional odds logistic regression (POLR) and multiclass logistic regression\n(MLR) models, as well as the raw TCC ensemble forecasts. We further assess\nwhether improvements in forecast skill can be obtained by incorporating\nensemble forecasts of precipitation as additional predictor. Compared to the\nraw ensemble, all calibration methods result in a significant improvement in\nforecast skill. RF models provide the smallest increase in predictive\nperformance, while MLP, POLR and GBM approaches perform best. The use of\nprecipitation forecast data leads to further improvements in forecast skill and\nexcept for very short lead times the extended MLP model shows the best overall\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:13:37 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Baran", "\u00c1gnes", ""], ["Lerch", "Sebastian", ""], ["Ayari", "Mehrez El", ""], ["Baran", "S\u00e1ndor", ""]]}, {"id": "2001.05989", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Cross-conformal e-prediction", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": "26", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note discusses a simple modification of cross-conformal prediction\ninspired by recent work on e-values. The precursor of conformal prediction\ndeveloped in the 1990s by Gammerman, Vapnik, and Vovk was also based on\ne-values and is called conformal e-prediction in this note. Replacing e-values\nby p-values led to conformal prediction, which has important advantages over\nconformal e-prediction without obvious disadvantages. The situation with\ncross-conformal prediction is, however, different: whereas for cross-conformal\nprediction validity is only an empirical fact (and can be broken with excessive\nrandomization), this note draws the reader's attention to the obvious fact that\ncross-conformal e-prediction enjoys a guaranteed property of validity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:41:17 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "2001.05990", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Jiachun Liao, Flavio P. Calmon, Oliver Kosut, Lalitha\n  Sankar", "title": "A Better Bound Gives a Hundred Rounds: Enhanced Privacy Guarantees via\n  $f$-Divergences", "comments": "Submitted for Publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the optimal differential privacy (DP) parameters of a mechanism\nthat satisfies a given level of R\\'enyi differential privacy (RDP). Our result\nis based on the joint range of two $f$-divergences that underlie the\napproximate and the R\\'enyi variations of differential privacy. We apply our\nresult to the moments accountant framework for characterizing privacy\nguarantees of stochastic gradient descent. When compared to the\nstate-of-the-art, our bounds may lead to about 100 more stochastic gradient\ndescent iterations for training deep learning models for the same privacy\nbudget.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:45:05 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Liao", "Jiachun", ""], ["Calmon", "Flavio P.", ""], ["Kosut", "Oliver", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2001.05992", "submitter": "Wei Hu", "authors": "Wei Hu, Lechao Xiao, Jeffrey Pennington", "title": "Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear\n  Networks", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of initial parameter values for gradient-based optimization of\ndeep neural networks is one of the most impactful hyperparameter choices in\ndeep learning systems, affecting both convergence times and model performance.\nYet despite significant empirical and theoretical analysis, relatively little\nhas been proved about the concrete effects of different initialization schemes.\nIn this work, we analyze the effect of initialization in deep linear networks,\nand provide for the first time a rigorous proof that drawing the initial\nweights from the orthogonal group speeds up convergence relative to the\nstandard Gaussian initialization with iid weights. We show that for deep\nnetworks, the width needed for efficient convergence to a global minimum with\northogonal initializations is independent of the depth, whereas the width\nneeded for efficient convergence with Gaussian initializations scales linearly\nin the depth. Our results demonstrate how the benefits of a good initialization\ncan persist throughout learning, suggesting an explanation for the recent\nempirical successes found by initializing very deep non-linear networks\naccording to the principle of dynamical isometry.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:48:34 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hu", "Wei", ""], ["Xiao", "Lechao", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2001.05993", "submitter": "Ryan Rossi", "authors": "Ryan Rossi, Somdeb Sarkhel, Nesreen Ahmed", "title": "Inferring Individual Level Causal Models from Graph-based Relational\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formalize the problem of causal inference over graph-based\nrelational time-series data where each node in the graph has one or more\ntime-series associated to it. We propose causal inference models for this\nproblem that leverage both the graph topology and time-series to accurately\nestimate local causal effects of nodes. Furthermore, the relational time-series\ncausal inference models are able to estimate local effects for individual nodes\nby exploiting local node-centric temporal dependencies and\ntopological/structural dependencies. We show that simpler causal models that do\nnot consider the graph topology are recovered as special cases of the proposed\nrelational time-series causal inference model. We describe the conditions under\nwhich the resulting estimate can be used to estimate a causal effect, and\ndescribe how the Durbin-Wu-Hausman test of specification can be used to test\nfor the consistency of the proposed estimator from data. Empirically, we\ndemonstrate the effectiveness of the causal inference models on both synthetic\ndata with known ground-truth and a large-scale observational relational\ntime-series data set collected from Wikipedia.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:48:40 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 17:07:33 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 22:14:30 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Rossi", "Ryan", ""], ["Sarkhel", "Somdeb", ""], ["Ahmed", "Nesreen", ""]]}, {"id": "2001.06001", "submitter": "Paola Cascante-Bonilla", "authors": "Paola Cascante-Bonilla, Fuwen Tan, Yanjun Qi, Vicente Ordonez", "title": "Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised\n  Learning", "comments": "In the 35th AAAI Conference on Artificial Intelligence. AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we revisit the idea of pseudo-labeling in the context of\nsemi-supervised learning where a learning algorithm has access to a small set\nof labeled samples and a large set of unlabeled samples. Pseudo-labeling works\nby applying pseudo-labels to samples in the unlabeled set by using a model\ntrained on the combination of the labeled samples and any previously\npseudo-labeled samples, and iteratively repeating this process in a\nself-training cycle. Current methods seem to have abandoned this approach in\nfavor of consistency regularization methods that train models under a\ncombination of different styles of self-supervised losses on the unlabeled\nsamples and standard supervised losses on the labeled samples. We empirically\ndemonstrate that pseudo-labeling can in fact be competitive with the\nstate-of-the-art, while being more resilient to out-of-distribution samples in\nthe unlabeled set. We identify two key factors that allow pseudo-labeling to\nachieve such remarkable results (1) applying curriculum learning principles and\n(2) avoiding concept drift by restarting model parameters before each\nself-training cycle. We obtain 94.91% accuracy on CIFAR-10 using only 4,000\nlabeled samples, and 68.87% top-1 accuracy on Imagenet-ILSVRC using only 10% of\nthe labeled samples. The code is available at\nhttps://github.com/uvavision/Curriculum-Labeling\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:24:27 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 16:14:35 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cascante-Bonilla", "Paola", ""], ["Tan", "Fuwen", ""], ["Qi", "Yanjun", ""], ["Ordonez", "Vicente", ""]]}, {"id": "2001.06027", "submitter": "David Benkeser", "authors": "David Benkeser", "title": "Nonparametric inference for interventional effects with multiple\n  mediators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the pathways whereby an intervention has an effect on an\noutcome is a common scientific goal. A rich body of literature provides various\ndecompositions of the total intervention effect into pathway specific effects.\nInterventional direct and indirect effects provide one such decomposition.\nExisting estimators of these effects are based on parametric models with\nconfidence interval estimation facilitated via the nonparametric bootstrap. We\nprovide theory that allows for more flexible, possibly machine learning-based,\nestimation techniques to be considered. In particular, we establish weak\nconvergence results that facilitate the construction of closed-form confidence\nintervals and hypothesis tests. Finally, we demonstrate multiple robustness\nproperties of the proposed estimators. Simulations show that inference based on\nlarge-sample theory has adequate small-sample performance. Our work thus\nprovides a means of leveraging modern statistical learning techniques in\nestimation of interventional mediation effects.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 19:05:00 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Benkeser", "David", ""]]}, {"id": "2001.06033", "submitter": "Vidhi Lalchand Miss", "authors": "Vidhi Lalchand", "title": "Extracting more from boosted decision trees: A high energy physics case\n  study", "comments": "Second Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle identification is one of the core tasks in the data analysis\npipeline at the Large Hadron Collider (LHC). Statistically, this entails the\nidentification of rare signal events buried in immense backgrounds that mimic\nthe properties of the former. In machine learning parlance, particle\nidentification represents a classification problem characterized by overlapping\nand imbalanced classes. Boosted decision trees (BDTs) have had tremendous\nsuccess in the particle identification domain but more recently have been\novershadowed by deep learning (DNNs) approaches. This work proposes an\nalgorithm to extract more out of standard boosted decision trees by targeting\ntheir main weakness, susceptibility to overfitting. This novel construction\nharnesses the meta-learning techniques of boosting and bagging simultaneously\nand performs remarkably well on the ATLAS Higgs (H) to tau-tau data set (ATLAS\net al., 2014) which was the subject of the 2014 Higgs ML Challenge\n(Adam-Bourdarios et al., 2015). While the decay of Higgs to a pair of tau\nleptons was established in 2018 (CMS collaboration et al., 2017) at the\n4.9$\\sigma$ significance based on the 2016 data taking period, the 2014 public\ndata set continues to serve as a benchmark data set to test the performance of\nsupervised classification schemes. We show that the score achieved by the\nproposed algorithm is very close to the published winning score which leverages\nan ensemble of deep neural networks (DNNs). Although this paper focuses on a\nsingle application, it is expected that this simple and robust technique will\nfind wider applications in high energy physics.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 19:13:28 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Lalchand", "Vidhi", ""]]}, {"id": "2001.06057", "submitter": "Evgenia Rusak", "authors": "Evgenia Rusak, Lukas Schott, Roland S. Zimmermann, Julian Bitterwolf,\n  Oliver Bringmann, Matthias Bethge, Wieland Brendel", "title": "A simple way to make neural networks robust against diverse image\n  corruptions", "comments": "Oral presentation at the European Conference for Computer Vision\n  (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human visual system is remarkably robust against a wide range of\nnaturally occurring variations and corruptions like rain or snow. In contrast,\nthe performance of modern image recognition models strongly degrades when\nevaluated on previously unseen corruptions. Here, we demonstrate that a simple\nbut properly tuned training with additive Gaussian and Speckle noise\ngeneralizes surprisingly well to unseen corruptions, easily reaching the\nprevious state of the art on the corruption benchmark ImageNet-C (with\nResNet50) and on MNIST-C. We build on top of these strong baseline results and\nshow that an adversarial training of the recognition model against uncorrelated\nworst-case noise distributions leads to an additional increase in performance.\nThis regularization can be combined with previously proposed defense methods\nfor further improvement.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:10:25 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 16:19:26 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:33:23 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 15:41:26 GMT"}, {"version": "v5", "created": "Wed, 22 Jul 2020 12:25:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Rusak", "Evgenia", ""], ["Schott", "Lukas", ""], ["Zimmermann", "Roland S.", ""], ["Bitterwolf", "Julian", ""], ["Bringmann", "Oliver", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "2001.06058", "submitter": "Chen Cai", "authors": "Chen Cai, Yusu Wang", "title": "Understanding the Power of Persistence Pairing via Permutation Test", "comments": "20 pages, 6 graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently many efforts have been made to incorporate persistence diagrams, one\nof the major tools in topological data analysis (TDA), into machine learning\npipelines. To better understand the power and limitation of persistence\ndiagrams, we carry out a range of experiments on both graph data and shape\ndata, aiming to decouple and inspect the effects of different factors involved.\nTo this end, we also propose the so-called \\emph{permutation test} for\npersistence diagrams to delineate critical values and pairings of critical\nvalues. For graph classification tasks, we note that while persistence pairing\nyields consistent improvement over various benchmark datasets, it appears that\nfor various filtration functions tested, most discriminative power comes from\ncritical values. For shape segmentation and classification, however, we note\nthat persistence pairing shows significant power on most of the benchmark\ndatasets, and improves over both summaries based on merely critical values, and\nthose based on permutation tests. Our results help provide insights on when\npersistence diagram based summaries could be more suitable.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:13:20 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Cai", "Chen", ""], ["Wang", "Yusu", ""]]}, {"id": "2001.06081", "submitter": "Soheil Mehrabkhani", "authors": "Soheil Mehrabkhani", "title": "Fourier Transform Approach to Machine Learning III: Fourier\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Fourier-based learning algorithm for highly nonlinear multiclass\nclassification. The algorithm is based on a smoothing technique to calculate\nthe probability distribution of all classes. To obtain the probability\ndistribution, the density distribution of each class is smoothed by a low-pass\nfilter separately. The advantage of the Fourier representation is capturing the\nnonlinearities of the data distribution without defining any kernel function.\nFurthermore, contrary to the support vector machines, it makes a probabilistic\nexplanation for the classification possible. Moreover, it can treat overlapped\nclasses as well. Comparing to the logistic regression, it does not require\nfeature engineering. In general, its computational performance is also very\nwell for large data sets and in contrast to other algorithms, the typical\noverfitting problem does not happen at all. The capability of the algorithm is\ndemonstrated for multiclass classification with overlapped classes and very\nhigh nonlinearity of the class distributions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 10:29:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 14:52:34 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Mehrabkhani", "Soheil", ""]]}, {"id": "2001.06089", "submitter": "Daniel Steinberg", "authors": "Daniel Steinberg, Alistair Reid and Simon O'Callaghan", "title": "Fairness Measures for Regression via Probabilistic Classification", "comments": "Accepted to the 2nd Ethics of Data Science Conference 2020 (March,\n  Sydney, Australia)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness involves expressing notions such as equity, or\nreasonable treatment, as quantifiable measures that a machine learning\nalgorithm can optimise. Most work in the literature to date has focused on\nclassification problems where the prediction is categorical, such as accepting\nor rejecting a loan application. This is in part because classification\nfairness measures are easily computed by comparing the rates of outcomes,\nleading to behaviours such as ensuring that the same fraction of eligible men\nare selected as eligible women. But such measures are computationally difficult\nto generalise to the continuous regression setting for problems such as\npricing, or allocating payments. The difficulty arises from estimating\nconditional densities (such as the probability density that a system will\nover-charge by a certain amount). For the regression setting we introduce\ntractable approximations of the independence, separation and sufficiency\ncriteria by observing that they factorise as ratios of different conditional\nprobabilities of the protected attributes. We introduce and train machine\nlearning classifiers, distinct from the predictor, as a mechanism to estimate\nthese probabilities from the data. This naturally leads to model agnostic,\ntractable approximations of the criteria, which we explore experimentally.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:53:26 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 03:46:01 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Steinberg", "Daniel", ""], ["Reid", "Alistair", ""], ["O'Callaghan", "Simon", ""]]}, {"id": "2001.06099", "submitter": "Farnaz Behnia", "authors": "Farnaz Behnia, Ali Mirzaeian, Mohammad Sabokrou, Sai Manoj, Tinoosh\n  Mohsenin, Khaled N. Khasawneh, Liang Zhao, Houman Homayoun, Avesta Sasan", "title": "Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for\n  Making a CNN Classifier Robust Against Adversarial Attacks", "comments": "6 pages, Accepted and to appear in ISQED 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Code-Bridged Classifier (CBC), a framework for\nmaking a Convolutional Neural Network (CNNs) robust against adversarial attacks\nwithout increasing or even by decreasing the overall models' computational\ncomplexity. More specifically, we propose a stacked encoder-convolutional\nmodel, in which the input image is first encoded by the encoder module of a\ndenoising auto-encoder, and then the resulting latent representation (without\nbeing decoded) is fed to a reduced complexity CNN for image classification. We\nillustrate that this network not only is more robust to adversarial examples\nbut also has a significantly lower computational complexity when compared to\nthe prior art defenses.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 22:16:58 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Behnia", "Farnaz", ""], ["Mirzaeian", "Ali", ""], ["Sabokrou", "Mohammad", ""], ["Manoj", "Sai", ""], ["Mohsenin", "Tinoosh", ""], ["Khasawneh", "Khaled N.", ""], ["Zhao", "Liang", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "2001.06103", "submitter": "Vansh Narula", "authors": "Vansh Narula, Zhangyang (Atlas) Wang and Theodora Chaspari", "title": "An adversarial learning framework for preserving users' anonymity in\n  face-based emotion recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image and video-capturing technologies have permeated our every-day life.\nSuch technologies can continuously monitor individuals' expressions in\nreal-life settings, affording us new insights into their emotional states and\ntransitions, thus paving the way to novel well-being and healthcare\napplications. Yet, due to the strong privacy concerns, the use of such\ntechnologies is met with strong skepticism, since current face-based emotion\nrecognition systems relying on deep learning techniques tend to preserve\nsubstantial information related to the identity of the user, apart from the\nemotion-specific information. This paper proposes an adversarial learning\nframework which relies on a convolutional neural network (CNN) architecture\ntrained through an iterative procedure for minimizing identity-specific\ninformation and maximizing emotion-dependent information. The proposed approach\nis evaluated through emotion classification and face identification metrics,\nand is compared against two CNNs, one trained solely for emotion recognition\nand the other trained solely for face identification. Experiments are performed\nusing the Yale Face Dataset and Japanese Female Facial Expression Database.\nResults indicate that the proposed approach can learn a convolutional\ntransformation for preserving emotion recognition accuracy and degrading face\nidentity recognition, providing a foundation toward privacy-aware emotion\nrecognition technologies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 22:45:52 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Narula", "Vansh", "", "Atlas"], ["Zhangyang", "", "", "Atlas"], ["Wang", "", ""], ["Chaspari", "Theodora", ""]]}, {"id": "2001.06105", "submitter": "Nikolaos Nikolaou", "authors": "Nikolaos Nikolaou, Joseph Mellor, Nikunj C. Oza, Gavin Brown", "title": "Better Boosting with Bandits for Online Learning", "comments": "44 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probability estimates generated by boosting ensembles are poorly calibrated\nbecause of the margin maximization nature of the algorithm. The outputs of the\nensemble need to be properly calibrated before they can be used as probability\nestimates. In this work, we demonstrate that online boosting is also prone to\nproducing distorted probability estimates. In batch learning, calibration is\nachieved by reserving part of the training data for training the calibrator\nfunction. In the online setting, a decision needs to be made on each round:\nshall the new example(s) be used to update the parameters of the ensemble or\nthose of the calibrator. We proceed to resolve this decision with the aid of\nbandit optimization algorithms. We demonstrate superior performance to\nuncalibrated and naively-calibrated on-line boosting ensembles in terms of\nprobability estimation. Our proposed mechanism can be easily adapted to other\ntasks(e.g. cost-sensitive classification) and is robust to the choice of\nhyperparameters of both the calibrator and the ensemble.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 22:48:22 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Nikolaou", "Nikolaos", ""], ["Mellor", "Joseph", ""], ["Oza", "Nikunj C.", ""], ["Brown", "Gavin", ""]]}, {"id": "2001.06116", "submitter": "Gaurav Manek", "authors": "Gaurav Manek, J. Zico Kolter", "title": "Learning Stable Deep Dynamics Models", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are commonly used to model dynamical systems, predicting how\nthe state of a system will evolve over time (either autonomously or in response\nto control inputs). Despite the predictive power of these systems, it has been\ndifficult to make formal claims about the basic properties of the learned\nsystems. In this paper, we propose an approach for learning dynamical systems\nthat are guaranteed to be stable over the entire state space. The approach\nworks by jointly learning a dynamics model and Lyapunov function that\nguarantees non-expansiveness of the dynamics under the learned Lyapunov\nfunction. We show that such learning systems are able to model simple dynamical\nsystems and can be combined with additional deep generative models to learn\ncomplex dynamics, such as video textures, in a fully end-to-end fashion.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 00:04:45 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Manek", "Gaurav", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2001.06130", "submitter": "Xuebin Zheng", "authors": "Bingxin Zhou, Xuebin Zheng, Junbin Gao", "title": "On the Trend-corrected Variant of Adaptive Stochastic Optimization\n  Methods", "comments": "8 pages, 4 figures, 2 tables, IJCNN2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207166", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam-type optimizers, as a class of adaptive moment estimation methods with\nthe exponential moving average scheme, have been successfully used in many\napplications of deep learning. Such methods are appealing due to the capability\non large-scale sparse datasets with high computational efficiency. In this\npaper, we present a new framework for Adam-type methods with the trend\ninformation when updating the parameters with the adaptive step size and\ngradients. The additional terms in the algorithm promise an efficient movement\non the complex cost surface, and thus the loss would converge more rapidly. We\nshow empirically the importance of adding the trend component, where our\nframework outperforms the conventional Adam and AMSGrad methods constantly on\nthe classical models with several real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 01:23:23 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 01:39:55 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhou", "Bingxin", ""], ["Zheng", "Xuebin", ""], ["Gao", "Junbin", ""]]}, {"id": "2001.06137", "submitter": "Zhen Cui", "authors": "Chunyan Xu, Zhen Cui, Xiaobin Hong, Tong Zhang, Jian Yang, and Wei Liu", "title": "Graph Inference Learning for Semi-supervised Classification", "comments": "11 pages", "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address semi-supervised classification of graph data, where\nthe categories of those unlabeled nodes are inferred from labeled nodes as well\nas graph structures. Recent works often solve this problem via advanced graph\nconvolution in a conventionally supervised manner, but the performance could\ndegrade significantly when labeled data is scarce. To this end, we propose a\nGraph Inference Learning (GIL) framework to boost the performance of\nsemi-supervised node classification by learning the inference of node labels on\ngraph topology. To bridge the connection between two nodes, we formally define\na structure relation by encapsulating node attributes, between-node paths, and\nlocal topological structures together, which can make the inference\nconveniently deduced from one node to another node. For learning the inference\nprocess, we further introduce meta-optimization on structure relations from\ntraining nodes to validation nodes, such that the learnt graph inference\ncapability can be better self-adapted to testing nodes. Comprehensive\nevaluations on four benchmark datasets (including Cora, Citeseer, Pubmed, and\nNELL) demonstrate the superiority of our proposed GIL when compared against\nstate-of-the-art methods on the semi-supervised node classification task.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 02:52:30 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Xu", "Chunyan", ""], ["Cui", "Zhen", ""], ["Hong", "Xiaobin", ""], ["Zhang", "Tong", ""], ["Yang", "Jian", ""], ["Liu", "Wei", ""]]}, {"id": "2001.06145", "submitter": "Adam Stinchcombe", "authors": "Jihun Han, Mihai Nica, Adam R Stinchcombe", "title": "A Derivative-Free Method for Solving Elliptic Partial Differential\n  Equations with Deep Neural Networks", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109672", "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep neural network based method for solving a class of\nelliptic partial differential equations. We approximate the solution of the PDE\nwith a deep neural network which is trained under the guidance of a\nprobabilistic representation of the PDE in the spirit of the Feynman-Kac\nformula. The solution is given by an expectation of a martingale process driven\nby a Brownian motion. As Brownian walkers explore the domain, the deep neural\nnetwork is iteratively trained using a form of reinforcement learning. Our\nmethod is a 'Derivative-Free Loss Method' since it does not require the\nexplicit calculation of the derivatives of the neural network with respect to\nthe input neurons in order to compute the training loss. The advantages of our\nmethod are showcased in a series of test problems: a corner singularity\nproblem, an interface problem, and an application to a chemotaxis population\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 03:29:24 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Han", "Jihun", ""], ["Nica", "Mihai", ""], ["Stinchcombe", "Adam R", ""]]}, {"id": "2001.06178", "submitter": "Marelie Davel", "authors": "Marelie H. Davel, Marthinus W. Theunissen, Arnold M. Pretorius,\n  Etienne Barnard", "title": "DNNs as Layers of Cooperating Classifiers", "comments": "Accepted at AAAI-2020. The preprint contains additional figures and\n  an appendix not included in the conference version. Main text remains\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust theoretical framework that can describe and predict the\ngeneralization ability of deep neural networks (DNNs) in general circumstances\nremains elusive. Classical attempts have produced complexity metrics that rely\nheavily on global measures of compactness and capacity with little\ninvestigation into the effects of sub-component collaboration. We demonstrate\nintriguing regularities in the activation patterns of the hidden nodes within\nfully-connected feedforward networks. By tracing the origin of these patterns,\nwe show how such networks can be viewed as the combination of two information\nprocessing systems: one continuous and one discrete. We describe how these two\nsystems arise naturally from the gradient-based optimization process, and\ndemonstrate the classification ability of the two systems, individually and in\ncollaboration. This perspective on DNN classification offers a novel way to\nthink about generalization, in which different subsets of the training data are\nused to train distinct classifiers; those classifiers are then combined to\nperform the classification task, and their consistency is crucial for accurate\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 07:45:26 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Davel", "Marelie H.", ""], ["Theunissen", "Marthinus W.", ""], ["Pretorius", "Arnold M.", ""], ["Barnard", "Etienne", ""]]}, {"id": "2001.06188", "submitter": "Leonid Pastur", "authors": "Leonid Pastur", "title": "On Random Matrices Arising in Deep Neural Networks. Gaussian Case", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with distribution of singular values of product of random\nmatrices arising in the analysis of deep neural networks. The matrices resemble\nthe product analogs of the sample covariance matrices, however, an important\ndifference is that the population covariance matrices, which are assumed to be\nnon-random in the standard setting of statistics and random matrix theory, are\nnow random, moreover, are certain functions of random data matrices. The\nproblem has been considered in recent work [21] by using the techniques of free\nprobability theory. Since, however, free probability theory deals with\npopulation matrices which are independent of the data matrices, its\napplicability in this case requires an additional justification. We present\nthis justification by using a version of the standard techniques of random\nmatrix theory under the assumption that the entries of data matrices are\nindependent Gaussian random variables. In the subsequent paper [18] we extend\nour results to the case where the entries of data matrices are just independent\nidentically distributed random variables with several finite moments. This, in\nparticular, extends the property of the so-called macroscopic universality on\nthe considered random matrices.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 08:30:57 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 15:11:44 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Pastur", "Leonid", ""]]}, {"id": "2001.06194", "submitter": "Zhen Yu", "authors": "Ping Zhou, Zhen Yu, Jingyi Ma, Maozai Tian, and Ye Fan", "title": "Communication-Efficient Distributed Estimator for Generalized Linear\n  Models with a Diverging Number of Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed statistical inference has recently attracted immense attention.\nThe asymptotic efficiency of the maximum likelihood estimator (MLE), the\none-step MLE, and the aggregated estimating equation estimator are established\nfor generalized linear models under the \"large $n$, diverging $p_n$\" framework,\nwhere the dimension of the covariates $p_n$ grows to infinity at a polynomial\nrate $o(n^\\alpha)$ for some $0<\\alpha<1$. Then a novel method is proposed to\nobtain an asymptotically efficient estimator for large-scale distributed data\nby two rounds of communication. In this novel method, the assumption on the\nnumber of servers is more relaxed and thus practical for real-world\napplications. Simulations and a case study demonstrate the satisfactory\nfinite-sample performance of the proposed estimators.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 08:51:11 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 17:25:05 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zhou", "Ping", ""], ["Yu", "Zhen", ""], ["Ma", "Jingyi", ""], ["Tian", "Maozai", ""], ["Fan", "Ye", ""]]}, {"id": "2001.06202", "submitter": "Anbu Huang", "authors": "Yang Liu, Anbu Huang, Yun Luo, He Huang, Youzhi Liu, Yuanyuan Chen,\n  Lican Feng, Tianjian Chen, Han Yu, Qiang Yang", "title": "FedVision: An Online Visual Object Detection Platform Powered by\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual object detection is a computer vision-based artificial intelligence\n(AI) technique which has many practical applications (e.g., fire hazard\nmonitoring). However, due to privacy concerns and the high cost of transmitting\nvideo data, it is highly challenging to build object detection models on\ncentrally stored large training datasets following the current approach.\nFederated learning (FL) is a promising approach to resolve this challenge.\nNevertheless, there currently lacks an easy to use tool to enable computer\nvision application developers who are not experts in federated learning to\nconveniently leverage this technology and apply it in their systems. In this\npaper, we report FedVision - a machine learning engineering platform to support\nthe development of federated learning powered computer vision applications. The\nplatform has been deployed through a collaboration between WeBank and Extreme\nVision to help customers develop computer vision-based safety monitoring\nsolutions in smart city applications. Over four months of usage, it has\nachieved significant efficiency improvement and cost reduction while removing\nthe need to transmit sensitive data for three major corporate customers. To the\nbest of our knowledge, this is the first real application of FL in computer\nvision-based tasks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 09:02:36 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Liu", "Yang", ""], ["Huang", "Anbu", ""], ["Luo", "Yun", ""], ["Huang", "He", ""], ["Liu", "Youzhi", ""], ["Chen", "Yuanyuan", ""], ["Feng", "Lican", ""], ["Chen", "Tianjian", ""], ["Yu", "Han", ""], ["Yang", "Qiang", ""]]}, {"id": "2001.06216", "submitter": "Qiang Huang", "authors": "Qiang Huang, Makoto Yamada, Yuan Tian, Dinesh Singh, Dawei Yin, Yi\n  Chang", "title": "GraphLIME: Local Interpretable Model Explanations for Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph structured data has wide applicability in various domains such as\nphysics, chemistry, biology, computer vision, and social networks, to name a\nfew. Recently, graph neural networks (GNN) were shown to be successful in\neffectively representing graph structured data because of their good\nperformance and generalization ability. GNN is a deep learning based method\nthat learns a node representation by combining specific nodes and the\nstructural/topological information of a graph. However, like other deep models,\nexplaining the effectiveness of GNN models is a challenging task because of the\ncomplex nonlinear transformations made over the iterations. In this paper, we\npropose GraphLIME, a local interpretable model explanation for graphs using the\nHilbert-Schmidt Independence Criterion (HSIC) Lasso, which is a nonlinear\nfeature selection method. GraphLIME is a generic GNN-model explanation\nframework that learns a nonlinear interpretable model locally in the subgraph\nof the node being explained. More specifically, to explain a node, we generate\na nonlinear interpretable model from its $N$-hop neighborhood and then compute\nthe K most representative features as the explanations of its prediction using\nHSIC Lasso. Through experiments on two real-world datasets, the explanations of\nGraphLIME are found to be of extraordinary degree and more descriptive in\ncomparison to the existing explanation methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 09:50:28 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 04:29:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Huang", "Qiang", ""], ["Yamada", "Makoto", ""], ["Tian", "Yuan", ""], ["Singh", "Dinesh", ""], ["Yin", "Dawei", ""], ["Chang", "Yi", ""]]}, {"id": "2001.06232", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Grzegorz Swirszcz and Joao Carreira and Viorica\n  Patraucean", "title": "Sideways: Depth-Parallel Training of Video Models", "comments": "Accepted at CVPR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Sideways, an approximate backpropagation scheme for training video\nmodels. In standard backpropagation, the gradients and activations at every\ncomputation step through the model are temporally synchronized. The forward\nactivations need to be stored until the backward pass is executed, preventing\ninter-layer (depth) parallelization. However, can we leverage smooth, redundant\ninput streams such as videos to develop a more efficient training scheme? Here,\nwe explore an alternative to backpropagation; we overwrite network activations\nwhenever new ones, i.e., from new frames, become available. Such a more gradual\naccumulation of information from both passes breaks the precise correspondence\nbetween gradients and activations, leading to theoretically more noisy weight\nupdates. Counter-intuitively, we show that Sideways training of deep\nconvolutional video networks not only still converges, but can also potentially\nexhibit better generalization compared to standard synchronized\nbackpropagation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:49:55 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 18:16:44 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 22:48:10 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Swirszcz", "Grzegorz", ""], ["Carreira", "Joao", ""], ["Patraucean", "Viorica", ""]]}, {"id": "2001.06246", "submitter": "Wilhelm Kirchg\\\"assner", "authors": "Wilhelm Kirchg\\\"assner, Oliver Wallscheid, Joachim B\\\"ocker", "title": "Data-Driven Permanent Magnet Temperature Estimation in Synchronous\n  Motors with Supervised Machine Learning", "comments": "preprint for TII: SS on Applications of Artificial Intelligence in\n  Industrial Power Electronics and Systems", "journal-ref": null, "doi": "10.1109/TEC.2021.3052546", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the magnet temperature in permanent magnet synchronous motors\n(PMSMs) for automotive applications is a challenging task for several decades\nnow, as signal injection or sensor-based methods still prove unfeasible in a\ncommercial context. Overheating results in severe motor deterioration and is\nthus of high concern for the machine's control strategy and its design. Lack of\nprecise temperature estimations leads to lesser device utilization and higher\nmaterial cost. In this work, several machine learning (ML) models are\nempirically evaluated on their estimation accuracy for the task of predicting\nlatent high-dynamic magnet temperature profiles. The range of selected\nalgorithms covers as diverse approaches as possible with ordinary and weighted\nleast squares, support vector regression, $k$-nearest neighbors, randomized\ntrees and neural networks. Having test bench data available, it is shown that\nML approaches relying merely on collected data meet the estimation performance\nof classical thermal models built on thermodynamic theory, yet not all kinds of\nmodels render efficient use of large datasets or sufficient modeling\ncapacities. Especially linear regression and simple feed-forward neural\nnetworks with optimized hyperparameters mark strong predictive quality at low\nto moderate model sizes.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 11:41:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Kirchg\u00e4ssner", "Wilhelm", ""], ["Wallscheid", "Oliver", ""], ["B\u00f6cker", "Joachim", ""]]}, {"id": "2001.06263", "submitter": "Shayan Aziznejad", "authors": "Shayan Aziznejad, Harshit Gupta, Joaquim Campos, Michael Unser", "title": "Deep Neural Networks with Trainable Activations and Controlled Lipschitz\n  Constant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variational framework to learn the activation functions of\ndeep neural networks. Our aim is to increase the capacity of the network while\ncontrolling an upper-bound of the actual Lipschitz constant of the input-output\nrelation. To that end, we first establish a global bound for the Lipschitz\nconstant of neural networks. Based on the obtained bound, we then formulate a\nvariational problem for learning activation functions. Our variational problem\nis infinite-dimensional and is not computationally tractable. However, we prove\nthat there always exists a solution that has continuous and piecewise-linear\n(linear-spline) activations. This reduces the original problem to a\nfinite-dimensional minimization where an l1 penalty on the parameters of the\nactivations favors the learning of sparse nonlinearities. We numerically\ncompare our scheme with standard ReLU network and its variations, PReLU and\nLeakyReLU and we empirically demonstrate the practical aspects of our\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 12:32:55 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:27:44 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Aziznejad", "Shayan", ""], ["Gupta", "Harshit", ""], ["Campos", "Joaquim", ""], ["Unser", "Michael", ""]]}, {"id": "2001.06270", "submitter": "Marc Bocquet", "authors": "Marc Bocquet, Julien Brajard, Alberto Carrassi, Laurent Bertino", "title": "Bayesian inference of chaotic dynamics by merging data assimilation,\n  machine learning and expectation-maximization", "comments": null, "journal-ref": "Foundations of Data Science, 2, 55-80, 2020", "doi": "10.3934/fods.2020004", "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction from observations of high-dimensional chaotic dynamics\nsuch as geophysical flows is hampered by (i) the partial and noisy observations\nthat can realistically be obtained, (ii) the need to learn from long time\nseries of data, and (iii) the unstable nature of the dynamics. To achieve such\ninference from the observations over long time series, it has been suggested to\ncombine data assimilation and machine learning in several ways. We show how to\nunify these approaches from a Bayesian perspective using\nexpectation-maximization and coordinate descents. In doing so, the model, the\nstate trajectory and model error statistics are estimated all together.\nImplementations and approximations of these methods are discussed. Finally, we\nnumerically and successfully test the approach on two relevant low-order\nchaotic models with distinct identifiability.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 12:46:26 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 19:52:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bocquet", "Marc", ""], ["Brajard", "Julien", ""], ["Carrassi", "Alberto", ""], ["Bertino", "Laurent", ""]]}, {"id": "2001.06282", "submitter": "Omid Kavehei", "authors": "Tennison Liu, Nhan Duy Truong, Armin Nikpour, Luping Zhou, Omid\n  Kavehei", "title": "Epileptic Seizure Classification with Symmetric and Hybrid Bilinear\n  Models", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy affects nearly 1% of the global population, of which two thirds can\nbe treated by anti-epileptic drugs and a much lower percentage by surgery.\nDiagnostic procedures for epilepsy and monitoring are highly specialized and\nlabour-intensive. The accuracy of the diagnosis is also complicated by\noverlapping medical symptoms, varying levels of experience and inter-observer\nvariability among clinical professions. This paper proposes a novel hybrid\nbilinear deep learning network with an application in the clinical procedures\nof epilepsy classification diagnosis, where the use of surface\nelectroencephalogram (sEEG) and audiovisual monitoring is standard practice.\nHybrid bilinear models based on two types of feature extractors, namely\nConvolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), are\ntrained using Short-Time Fourier Transform (STFT) of one-second sEEG. In the\nproposed hybrid models, CNNs extract spatio-temporal patterns, while RNNs focus\non the characteristics of temporal dynamics in relatively longer intervals\ngiven the same input data. Second-order features, based on interactions between\nthese spatio-temporal features are further explored by bilinear pooling and\nused for epilepsy classification. Our proposed methods obtain an F1-score of\n97.4% on the Temple University Hospital Seizure Corpus and 97.2% on the\nEPILEPSIAE dataset, comparing favourably to existing benchmarks for sEEG-based\nseizure type classification. The open-source implementation of this study is\navailable at https://github.com/NeuroSyd/Epileptic-Seizure-Classification\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:22:10 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Liu", "Tennison", ""], ["Truong", "Nhan Duy", ""], ["Nikpour", "Armin", ""], ["Zhou", "Luping", ""], ["Kavehei", "Omid", ""]]}, {"id": "2001.06296", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele, Isabelle Dehaene, Gy\\\"orgy Kov\\'acs, Lucas Sterckx,\n  Olivier Janssens, Femke Ongenae, Femke De Backere, Filip De Turck, Kristien\n  Roelens, Johan Decruyenaere, Sofie Van Hoecke, Thomas Demeester", "title": "Overly Optimistic Prediction Results on Imbalanced Data: a Case Study of\n  Flaws and Benefits when Applying Over-sampling", "comments": null, "journal-ref": "Artificial Intelligence in Medicine. 111 (2021). 101987", "doi": "10.1016/j.artmed.2020.101987", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information extracted from electrohysterography recordings could potentially\nprove to be an interesting additional source of information to estimate the\nrisk on preterm birth. Recently, a large number of studies have reported\nnear-perfect results to distinguish between recordings of patients that will\ndeliver term or preterm using a public resource, called the Term/Preterm\nElectrohysterogram database. However, we argue that these results are overly\noptimistic due to a methodological flaw being made. In this work, we focus on\none specific type of methodological flaw: applying over-sampling before\npartitioning the data into mutually exclusive training and testing sets. We\nshow how this causes the results to be biased using two artificial datasets and\nreproduce results of studies in which this flaw was identified. Moreover, we\nevaluate the actual impact of over-sampling on predictive performance, when\napplied prior to data partitioning, using the same methodologies of related\nstudies, to provide a realistic view of these methodologies' generalization\ncapabilities. We make our research reproducible by providing all the code under\nan open license.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:53:23 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 16:41:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Dehaene", "Isabelle", ""], ["Kov\u00e1cs", "Gy\u00f6rgy", ""], ["Sterckx", "Lucas", ""], ["Janssens", "Olivier", ""], ["Ongenae", "Femke", ""], ["De Backere", "Femke", ""], ["De Turck", "Filip", ""], ["Roelens", "Kristien", ""], ["Decruyenaere", "Johan", ""], ["Van Hoecke", "Sofie", ""], ["Demeester", "Thomas", ""]]}, {"id": "2001.06309", "submitter": "Antoine Delplace", "authors": "Antoine Delplace, Sheryl Hermoso and Kristofer Anandita", "title": "Cyber Attack Detection thanks to Machine Learning Algorithms", "comments": "46 pages, 38 figures, project report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity attacks are growing both in frequency and sophistication over\nthe years. This increasing sophistication and complexity call for more\nadvancement and continuous innovation in defensive strategies. Traditional\nmethods of intrusion detection and deep packet inspection, while still largely\nused and recommended, are no longer sufficient to meet the demands of growing\nsecurity threats. As computing power increases and cost drops, Machine Learning\nis seen as an alternative method or an additional mechanism to defend against\nmalwares, botnets, and other attacks. This paper explores Machine Learning as a\nviable solution by examining its capabilities to classify malicious traffic in\na network.\n  First, a strong data analysis is performed resulting in 22 extracted features\nfrom the initial Netflow datasets. All these features are then compared with\none another through a feature selection process. Then, our approach analyzes\nfive different machine learning algorithms against NetFlow dataset containing\ncommon botnets. The Random Forest Classifier succeeds in detecting more than\n95% of the botnets in 8 out of 13 scenarios and more than 55% in the most\ndifficult datasets. Finally, insight is given to improve and generalize the\nresults, especially through a bootstrapping technique.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 13:52:12 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Delplace", "Antoine", ""], ["Hermoso", "Sheryl", ""], ["Anandita", "Kristofer", ""]]}, {"id": "2001.06323", "submitter": "Adenilton Jos\\'e da Silva", "authors": "Juan C. Rodriguez Gamboa, Eva Susana Albarracin E., Adenilton J. da\n  Silva, Luciana Leite, Tiago A. E. Ferreira", "title": "Wine quality rapid detection using a compact electronic nose system:\n  application focused on spoilage thresholds by acetic acid", "comments": null, "journal-ref": "LWT, Volume 108, 2019, Pages 377-384", "doi": "10.1016/j.lwt.2019.03.074", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial for the wine industry to have methods like electronic nose\nsystems (E-Noses) for real-time monitoring thresholds of acetic acid in wines,\npreventing its spoilage or determining its quality. In this paper, we prove\nthat the portable and compact self-developed E-Nose, based on thin film\nsemiconductor (SnO2) sensors and trained with an approach that uses deep\nMultilayer Perceptron (MLP) neural network, can perform early detection of wine\nspoilage thresholds in routine tasks of wine quality control. To obtain rapid\nand online detection, we propose a method of rising-window focused on raw data\nprocessing to find an early portion of the sensor signals with the best\nrecognition performance. Our approach was compared with the conventional\napproach employed in E-Noses for gas recognition that involves feature\nextraction and selection techniques for preprocessing data, succeeded by a\nSupport Vector Machine (SVM) classifier. The results evidence that is possible\nto classify three wine spoilage levels in 2.7 seconds after the gas injection\npoint, implying in a methodology 63 times faster than the results obtained with\nthe conventional approach in our experimental setup.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:49:06 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Gamboa", "Juan C. Rodriguez", ""], ["E.", "Eva Susana Albarracin", ""], ["da Silva", "Adenilton J.", ""], ["Leite", "Luciana", ""], ["Ferreira", "Tiago A. E.", ""]]}, {"id": "2001.06325", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Zhengbao He, Chengjin Sun, Jie Yang, Xiaolin Huang", "title": "Universal Adversarial Attack on Attention and the Resulting Dataset\n  DAmageNet", "comments": "accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks on deep neural networks (DNNs) have been found for\nseveral years. However, the existing adversarial attacks have high success\nrates only when the information of the victim DNN is well-known or could be\nestimated by the structure similarity or massive queries. In this paper, we\npropose to Attack on Attention (AoA), a semantic property commonly shared by\nDNNs. AoA enjoys a significant increase in transferability when the traditional\ncross entropy loss is replaced with the attention loss. Since AoA alters the\nloss function only, it could be easily combined with other\ntransferability-enhancement techniques and then achieve SOTA performance. We\napply AoA to generate 50000 adversarial samples from ImageNet validation set to\ndefeat many neural networks, and thus name the dataset as DAmageNet. 13\nwell-trained DNNs are tested on DAmageNet, and all of them have an error rate\nover 85%. Even with defenses or adversarial training, most models still\nmaintain an error rate over 70% on DAmageNet. DAmageNet is the first universal\nadversarial dataset. It could be downloaded freely and serve as a benchmark for\nrobustness testing and adversarial training.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 07:58:21 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 04:45:15 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 09:10:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Chen", "Sizhe", ""], ["He", "Zhengbao", ""], ["Sun", "Chengjin", ""], ["Yang", "Jie", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2001.06338", "submitter": "Henrique Da Costa Siqueira", "authors": "Henrique Siqueira, Sven Magg and Stefan Wermter", "title": "Efficient Facial Feature Learning with Wide Ensemble-based Convolutional\n  Neural Networks", "comments": "Accepted at the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20), 1-1, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods, traditionally built with independently trained\nde-correlated models, have proven to be efficient methods for reducing the\nremaining residual generalization error, which results in robust and accurate\nmethods for real-world applications. In the context of deep learning, however,\ntraining an ensemble of deep networks is costly and generates high redundancy\nwhich is inefficient. In this paper, we present experiments on Ensembles with\nShared Representations (ESRs) based on convolutional networks to demonstrate,\nquantitatively and qualitatively, their data processing efficiency and\nscalability to large-scale datasets of facial expressions. We show that\nredundancy and computational load can be dramatically reduced by varying the\nbranching level of the ESR without loss of diversity and generalization power,\nwhich are both important for ensemble performance. Experiments on large-scale\ndatasets suggest that ESRs reduce the remaining residual generalization error\non the AffectNet and FER+ datasets, reach human-level performance, and\noutperform state-of-the-art methods on facial expression recognition in the\nwild using emotion and affect concepts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 14:32:27 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Siqueira", "Henrique", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "2001.06370", "submitter": "Nicholas Gerard Timmons", "authors": "Nicholas Gerard Timmons, Andrew Rice", "title": "Approximating Activation Functions", "comments": "10 Pages, 5 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ReLU is widely seen as the default choice for activation functions in neural\nnetworks. However, there are cases where more complicated functions are\nrequired. In particular, recurrent neural networks (such as LSTMs) make\nextensive use of both hyperbolic tangent and sigmoid functions. These functions\nare expensive to compute. We used function approximation techniques to develop\nreplacements for these functions and evaluated them empirically on three\npopular network configurations. We find safe approximations that yield a 10% to\n37% improvement in training times on the CPU. These approximations were\nsuitable for all cases we considered and we believe are appropriate\nreplacements for all networks using these activation functions. We also develop\nranged approximations which only apply in some cases due to restrictions on\ntheir input domain. Our ranged approximations yield a performance improvement\nof 20% to 53% in network training time. Our functions also match or\nconsiderably out perform the ad-hoc approximations used in Theano and the\nimplementation of Word2Vec.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:25:44 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Timmons", "Nicholas Gerard", ""], ["Rice", "Andrew", ""]]}, {"id": "2001.06386", "submitter": "Mikhail Hushchyn", "authors": "Mikhail Hushchyn and Andrey Ustyuzhanin", "title": "Generalization of Change-Point Detection in Time Series Data Based on\n  Direct Density Ratio Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of the change-point detection is to discover changes of time series\ndistribution. One of the state of the art approaches of the change-point\ndetection are based on direct density ratio estimation. In this work we show\nhow existing algorithms can be generalized using various binary classification\nand regression models. In particular, we show that the Gradient Boosting over\nDecision Trees and Neural Networks can be used for this purpose. The algorithms\nare tested on several synthetic and real-world datasets. The results show that\nthe proposed methods outperform classical RuLSIF algorithm. Discussion of cases\nwhere the proposed algorithms have advantages over existing methods are also\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:45:38 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Hushchyn", "Mikhail", ""], ["Ustyuzhanin", "Andrey", ""]]}, {"id": "2001.06448", "submitter": "Lynton Ardizzone", "authors": "Lynton Ardizzone, Radek Mackowiak, Carsten Rother, Ullrich K\\\"othe", "title": "Training Normalizing Flows with the Information Bottleneck for\n  Competitive Generative Classification", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 Proceedings\n  (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck (IB) objective uses information theory to\nformulate a task-performance versus robustness trade-off. It has been\nsuccessfully applied in the standard discriminative classification setting. We\npose the question whether the IB can also be used to train generative\nlikelihood models such as normalizing flows. Since normalizing flows use\ninvertible network architectures (INNs), they are information-preserving by\nconstruction. This seems contradictory to the idea of a bottleneck. In this\nwork, firstly, we develop the theory and methodology of IB-INNs, a class of\nconditional normalizing flows where INNs are trained using the IB objective:\nIntroducing a small amount of {\\em controlled} information loss allows for an\nasymptotically exact formulation of the IB, while keeping the INN's generative\ncapabilities intact. Secondly, we investigate the properties of these models\nexperimentally, specifically used as generative classifiers. This model class\noffers advantages such as improved uncertainty quantification and\nout-of-distribution detection, but traditional generative classifier solutions\nsuffer considerably in classification accuracy. We find the trade-off parameter\nin the IB controls a mix of generative capabilities and accuracy close to\nstandard classifiers. Empirically, our uncertainty estimates in this mixed\nregime compare favourably to conventional generative and discriminative\nclassifiers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 17:48:40 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 12:41:05 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 15:24:12 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 14:37:54 GMT"}, {"version": "v5", "created": "Tue, 12 Jan 2021 15:01:24 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Ardizzone", "Lynton", ""], ["Mackowiak", "Radek", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2001.06471", "submitter": "Hussein Hazimeh", "authors": "Antoine Dedieu, Hussein Hazimeh, Rahul Mazumder", "title": "Learning Sparse Classifiers: Continuous and Mixed Integer Optimization\n  Perspectives", "comments": "To appear in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a discrete optimization formulation for learning sparse\nclassifiers, where the outcome depends upon a linear combination of a small\nsubset of features. Recent work has shown that mixed integer programming (MIP)\ncan be used to solve (to optimality) $\\ell_0$-regularized regression problems\nat scales much larger than what was conventionally considered possible. Despite\ntheir usefulness, MIP-based global optimization approaches are significantly\nslower compared to the relatively mature algorithms for $\\ell_1$-regularization\nand heuristics for nonconvex regularized problems. We aim to bridge this gap in\ncomputation times by developing new MIP-based algorithms for\n$\\ell_0$-regularized classification. We propose two classes of scalable\nalgorithms: an exact algorithm that can handle $p\\approx 50,000$ features in a\nfew minutes, and approximate algorithms that can address instances with\n$p\\approx 10^6$ in times comparable to the fast $\\ell_1$-based algorithms. Our\nexact algorithm is based on the novel idea of \\textsl{integrality generation},\nwhich solves the original problem (with $p$ binary variables) via a sequence of\nmixed integer programs that involve a small number of binary variables. Our\napproximate algorithms are based on coordinate descent and local combinatorial\nsearch. In addition, we present new estimation error bounds for a class of\n$\\ell_0$-regularized estimators. Experiments on real and synthetic data\ndemonstrate that our approach leads to models with considerably improved\nstatistical performance (especially, variable selection) when compared to\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 18:47:02 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 17:38:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dedieu", "Antoine", ""], ["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""]]}, {"id": "2001.06472", "submitter": "Masudul Haque", "authors": "Goran Nakerst, John Brennan, Masudul Haque", "title": "Gradient descent with momentum --- to accelerate or to super-accelerate?", "comments": "19 pages + references, 8 figures. A variant of Nesterov acceleration\n  is proposed and studied", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider gradient descent with `momentum', a widely used method for loss\nfunction minimization in machine learning. This method is often used with\n`Nesterov acceleration', meaning that the gradient is evaluated not at the\ncurrent position in parameter space, but at the estimated position after one\nstep. In this work, we show that the algorithm can be improved by extending\nthis `acceleration' --- by using the gradient at an estimated position several\nsteps ahead rather than just one step ahead. How far one looks ahead in this\n`super-acceleration' algorithm is determined by a new hyperparameter.\nConsidering a one-parameter quadratic loss function, the optimal value of the\nsuper-acceleration can be exactly calculated and analytically estimated. We\nshow explicitly that super-accelerating the momentum algorithm is beneficial,\nnot only for this idealized problem, but also for several synthetic loss\nlandscapes and for the MNIST classification task with neural networks.\nSuper-acceleration is also easy to incorporate into adaptive algorithms like\nRMSProp or Adam, and is shown to improve these algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 18:50:07 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Nakerst", "Goran", ""], ["Brennan", "John", ""], ["Haque", "Masudul", ""]]}, {"id": "2001.06485", "submitter": "Boris Ndjia Njike", "authors": "Boris Ndjia Njike, Xavier Siebert", "title": "K-NN active learning under local smoothness assumption", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.03055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large body of work on convergence rates either in passive or\nactive learning. Here we first outline some of the main results that have been\nobtained, more specifically in a nonparametric setting under assumptions about\nthe smoothness of the regression function (or the boundary between classes) and\nthe margin noise. We discuss the relative merits of these underlying\nassumptions by putting active learning in perspective with recent work on\npassive learning. We design an active learning algorithm with a rate of\nconvergence better than in passive learning, using a particular smoothness\nassumption customized for k-nearest neighbors. Unlike previous active learning\nalgorithms, we use a smoothness assumption that provides a dependence on the\nmarginal distribution of the instance space. Additionally, our algorithm avoids\nthe strong density assumption that supposes the existence of the density\nfunction of the marginal distribution of the instance space and is therefore\nmore generally applicable.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:44:36 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 08:05:48 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Njike", "Boris Ndjia", ""], ["Siebert", "Xavier", ""]]}, {"id": "2001.06509", "submitter": "Dakuo Wang", "authors": "Jaimie Drozdal, Justin Weisz, Dakuo Wang, Gaurav Dass, Bingsheng Yao,\n  Changruo Zhao, Michael Muller, Lin Ju, Hui Su", "title": "Trust in AutoML: Exploring Information Needs for Establishing Trust in\n  Automated Machine Learning Systems", "comments": "IUI 2020", "journal-ref": null, "doi": "10.1145/3377325.3377501", "report-no": null, "categories": "cs.LG cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore trust in a relatively new area of data science: Automated Machine\nLearning (AutoML). In AutoML, AI methods are used to generate and optimize\nmachine learning models by automatically engineering features, selecting\nmodels, and optimizing hyperparameters. In this paper, we seek to understand\nwhat kinds of information influence data scientists' trust in the models\nproduced by AutoML? We operationalize trust as a willingness to deploy a model\nproduced using automated methods. We report results from three studies --\nqualitative interviews, a controlled experiment, and a card-sorting task -- to\nunderstand the information needs of data scientists for establishing trust in\nAutoML systems. We find that including transparency features in an AutoML tool\nincreased user trust and understandability in the tool; and out of all proposed\nfeatures, model performance metrics and visualizations are the most important\ninformation to data scientists when establishing their trust with an AutoML\ntool.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 19:50:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Drozdal", "Jaimie", ""], ["Weisz", "Justin", ""], ["Wang", "Dakuo", ""], ["Dass", "Gaurav", ""], ["Yao", "Bingsheng", ""], ["Zhao", "Changruo", ""], ["Muller", "Michael", ""], ["Ju", "Lin", ""], ["Su", "Hui", ""]]}, {"id": "2001.06541", "submitter": "Imtiaz Ahmed", "authors": "Imtiaz Ahmed, Xia Ben Hu, Mithun P. Acharya and Yu Ding", "title": "Neighborhood Structure Assisted Non-negative Matrix Factorization and\n  its Application in Unsupervised Point-wise Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is considered as an important step for ensuring\ncompetitive performance in unsupervised learning such as anomaly detection.\nNon-negative matrix factorization (NMF) is a popular and widely used method to\naccomplish this goal. But NMF do not have the provision to include the\nneighborhood structure information and, as a result, may fail to provide\nsatisfactory performance in presence of nonlinear manifold structure. To\naddress that shortcoming, we propose to consider and incorporate the\nneighborhood structural similarity information within the NMF framework by\nmodeling the data through a minimum spanning tree. We label the resulting\nmethod as the neighborhood structure assisted NMF. We further devise both\noffline and online algorithmic versions of the proposed method. Empirical\ncomparisons using twenty benchmark datasets as well as an industrial dataset\nextracted from a hydropower plant demonstrate the superiority of the\nneighborhood structure assisted NMF and support our claim of merit. Looking\ncloser into the formulation and properties of the neighborhood structure\nassisted NMF with other recent, enhanced versions of NMF reveals that inclusion\nof the neighborhood structure information using MST plays a key role in\nattaining the enhanced performance in anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 21:43:20 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 20:40:48 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 03:04:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Ahmed", "Imtiaz", ""], ["Hu", "Xia Ben", ""], ["Acharya", "Mithun P.", ""], ["Ding", "Yu", ""]]}, {"id": "2001.06546", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Mario Diaz, and Flavio P. Calmon", "title": "Privacy Amplification of Iterative Algorithms via Contraction\n  Coefficients", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the framework of privacy amplification by iteration, recently\nproposed by Feldman et al., from an information-theoretic lens. We demonstrate\nthat differential privacy guarantees of iterative mappings can be determined by\na direct application of contraction coefficients derived from strong data\nprocessing inequalities for $f$-divergences. In particular, by generalizing the\nDobrushin's contraction coefficient for total variation distance to an\n$f$-divergence known as $E_{\\gamma}$-divergence, we derive tighter bounds on\nthe differential privacy parameters of the projected noisy stochastic gradient\ndescent algorithm with hidden intermediate updates.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:06:48 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Diaz", "Mario", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2001.06555", "submitter": "Elizabeth Ogburn", "authors": "Elizabeth L. Ogburn, Ilya Shpitser, Eric J. Tchetgen Tchetgen", "title": "Counterexamples to \"The Blessings of Multiple Causes\" by Wang and Blei", "comments": "This note has been updated (April, 2020) to respond to \"Towards\n  Clarifying the Theory of the Deconfounder\" by Yixin Wang, David M. Blei\n  (arXiv:2003.04948)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note has been updated (April, 2020) to respond to \"Towards Clarifying\nthe Theory of the Deconfounder\" by Yixin Wang, David M. Blei\n(arXiv:2003.04948). This original note, posted in January, 2020, is meant to\ncomplement our previous comment on \"The Blessings of Multiple Causes\" by Wang\nand Blei (2019). We provide a more succinct and transparent explanation of the\nfact that the deconfounder does not control for multi-cause confounding. The\nargument given in Wang and Blei (2019) makes two mistakes: (1) attempting to\ninfer independence conditional on one variable from independence conditional on\na different, unrelated variable, and (2) attempting to infer joint independence\nfrom pairwise independence. We give two simple counterexamples to the\ndeconfounder claim.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 23:33:32 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:24:45 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 15:30:13 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ogburn", "Elizabeth L.", ""], ["Shpitser", "Ilya", ""], ["Tchetgen", "Eric J. Tchetgen", ""]]}, {"id": "2001.06576", "submitter": "Mengyuan Chen", "authors": "Mengyuan Chen, Jiang Zhang, Zhang Zhang, Lun Du, Qiao Hu, Shuo Wang,\n  Jiaqi Zhu", "title": "Inference for Network Structure and Dynamics from Time Series Data via\n  Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network structures in various backgrounds play important roles in social,\ntechnological, and biological systems. However, the observable network\nstructures in real cases are often incomplete or unavailable due to measurement\nerrors or private protection issues. Therefore, inferring the complete network\nstructure is useful for understanding complex systems. The existing studies\nhave not fully solved the problem of inferring network structure with partial\nor no information about connections or nodes. In this paper, we tackle the\nproblem by utilizing time series data generated by network dynamics. We regard\nthe network inference problem based on dynamical time series data as a problem\nof minimizing errors for predicting future states and proposed a novel\ndata-driven deep learning model called Gumbel Graph Network (GGN) to solve the\ntwo kinds of network inference problems: Network Reconstruction and Network\nCompletion. For the network reconstruction problem, the GGN framework includes\ntwo modules: the dynamics learner and the network generator. For the network\ncompletion problem, GGN adds a new module called the States Learner to infer\nmissing parts of the network. We carried out experiments on discrete and\ncontinuous time series data. The experiments show that our method can\nreconstruct up to 100% network structure on the network reconstruction task.\nWhile the model can also infer the unknown parts of the structure with up to\n90% accuracy when some nodes are missing. And the accuracy decays with the\nincrease of the fractions of missing nodes. Our framework may have wide\napplication areas where the network structure is hard to obtained and the time\nseries data is rich.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 02:05:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chen", "Mengyuan", ""], ["Zhang", "Jiang", ""], ["Zhang", "Zhang", ""], ["Du", "Lun", ""], ["Hu", "Qiao", ""], ["Wang", "Shuo", ""], ["Zhu", "Jiaqi", ""]]}, {"id": "2001.06587", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Saayan Mitra, Somdeb Sarkhel, Jason Xie, Gang Wu,\n  Viswanathan Swaminathan", "title": "Scalable Bid Landscape Forecasting in Real-time Bidding", "comments": "Appeared in ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In programmatic advertising, ad slots are usually sold using second-price\n(SP) auctions in real-time. The highest bidding advertiser wins but pays only\nthe second-highest bid (known as the winning price). In SP, for a single item,\nthe dominant strategy of each bidder is to bid the true value from the bidder's\nperspective. However, in a practical setting, with budget constraints, bidding\nthe true value is a sub-optimal strategy. Hence, to devise an optimal bidding\nstrategy, it is of utmost importance to learn the winning price distribution\naccurately. Moreover, a demand-side platform (DSP), which bids on behalf of\nadvertisers, observes the winning price if it wins the auction. For losing\nauctions, DSPs can only treat its bidding price as the lower bound for the\nunknown winning price. In literature, typically censored regression is used to\nmodel such partially observed data. A common assumption in censored regression\nis that the winning price is drawn from a fixed variance (homoscedastic)\nuni-modal distribution (most often Gaussian). However, in reality, these\nassumptions are often violated. We relax these assumptions and propose a\nheteroscedastic fully parametric censored regression approach, as well as a\nmixture density censored network. Our approach not only generalizes censored\nregression but also provides flexibility to model arbitrarily distributed\nreal-world data. Experimental evaluation on the publicly available dataset for\nwinning price estimation demonstrates the effectiveness of our method.\nFurthermore, we evaluate our algorithm on one of the largest demand-side\nplatforms and significant improvement has been achieved in comparison with the\nbaseline solutions.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:20:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ghosh", "Aritra", ""], ["Mitra", "Saayan", ""], ["Sarkhel", "Somdeb", ""], ["Xie", "Jason", ""], ["Wu", "Gang", ""], ["Swaminathan", "Viswanathan", ""]]}, {"id": "2001.06588", "submitter": "Pooyan Jamshidi", "authors": "Md Shahriar Iqbal, Jianhai Su, Lars Kotthoff, Pooyan Jamshidi", "title": "FlexiBO: Cost-Aware Multi-Objective Optimization of Deep Neural Networks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in designing machine learning systems is to\ndetermine the right balance amongst several objectives, which also oftentimes\nare incommensurable and conflicting. For example, when designing deep neural\nnetworks (DNNs), one often has to trade-off between multiple objectives, such\nas accuracy, energy consumption, and inference time. Typically, there is no\nsingle configuration that performs equally well for all objectives.\nConsequently, one is interested in identifying Pareto-optimal designs. Although\ndifferent multi-objective optimization algorithms have been developed to\nidentify Pareto-optimal configurations, state-of-the-art multi-objective\noptimization methods do not consider the different evaluation costs attending\nthe objectives under consideration. This is particularly important for\noptimizing DNNs: the cost arising on account of assessing the accuracy of DNNs\nis orders of magnitude higher than that of measuring the energy consumption of\npre-trained DNNs. We propose FlexiBO, a flexible Bayesian optimization method,\nto address this issue. We formulate a new acquisition function based on the\nimprovement of the Pareto hyper-volume weighted by the measurement cost of each\nobjective. Our acquisition function selects the next sample and objective that\nprovides maximum information gain per unit of cost. We evaluated FlexiBO on 7\nstate-of-the-art DNNs for object detection, natural language processing, and\nspeech recognition. Our results indicate that, when compared to other\nstate-of-the-art methods across the 7 architectures we tested, the Pareto front\nobtained using FlexiBO has, on average, a 28.44% higher contribution to the\ntrue Pareto front and achieves 25.64% better diversity.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:26:03 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Iqbal", "Md Shahriar", ""], ["Su", "Jianhai", ""], ["Kotthoff", "Lars", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2001.06591", "submitter": "Ziyi Yang", "authors": "Ziyi Yang, Iman Soltani Bozchalooi and Eric Darve", "title": "Regularized Cycle Consistent Generative Adversarial Network for Anomaly\n  Detection", "comments": "the 24th European Conference on Artificial Intelligence (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate algorithms for anomaly detection. Previous\nanomaly detection methods focus on modeling the distribution of non-anomalous\ndata provided during training. However, this does not necessarily ensure the\ncorrect detection of anomalous data. We propose a new Regularized Cycle\nConsistent Generative Adversarial Network (RCGAN) in which deep neural networks\nare adversarially trained to better recognize anomalous samples. This approach\nis based on leveraging a penalty distribution with a new definition of the loss\nfunction and novel use of discriminator networks. It is based on a solid\nmathematical foundation, and proofs show that our approach has stronger\nguarantees for detecting anomalous examples compared to the current\nstate-of-the-art. Experimental results on both real-world and synthetic data\nshow that our model leads to significant and consistent improvements on\nprevious anomaly detection benchmarks. Notably, RCGAN improves on the\nstate-of-the-art on the KDDCUP, Arrhythmia, Thyroid, Musk and CIFAR10 datasets.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:35:05 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 20:35:24 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Yang", "Ziyi", ""], ["Bozchalooi", "Iman Soltani", ""], ["Darve", "Eric", ""]]}, {"id": "2001.06597", "submitter": "Xiaofeng Yang", "authors": "Tonghe Wang, Yang Lei, Yabo Fu, Walter J. Curran, Tian Liu, Xiaofeng\n  Yang", "title": "Machine Learning in Quantitative PET Imaging", "comments": "25 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviewed the machine learning-based studies for quantitative\npositron emission tomography (PET). Specifically, we summarized the recent\ndevelopments of machine learning-based methods in PET attenuation correction\nand low-count PET reconstruction by listing and comparing the proposed methods,\nstudy designs and reported performances of the current published studies with\nbrief discussion on representative studies. The contributions and challenges\namong the reviewed studies were summarized and highlighted in the discussion\npart followed by.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 04:35:59 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Tonghe", ""], ["Lei", "Yang", ""], ["Fu", "Yabo", ""], ["Curran", "Walter J.", ""], ["Liu", "Tian", ""], ["Yang", "Xiaofeng", ""]]}, {"id": "2001.06640", "submitter": "Shuo Wang", "authors": "Shuo Wang, Tianle Chen, Shangyu Chen, Carsten Rudolph, Surya Nepal,\n  Marthie Grobler", "title": "OIAD: One-for-all Image Anomaly Detection with Disentanglement Learning", "comments": "arXiv admin note: text overlap with arXiv:1802.05983,\n  arXiv:1909.02755, arXiv:1804.03599 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to recognize samples with anomalous and unusual\npatterns with respect to a set of normal data. This is significant for numerous\ndomain applications, such as industrial inspection, medical imaging, and\nsecurity enforcement. There are two key research challenges associated with\nexisting anomaly detection approaches: (1) many approaches perform well on\nlow-dimensional problems however the performance on high-dimensional instances,\nsuch as images, is limited; (2) many approaches often rely on traditional\nsupervised approaches and manual engineering of features, while the topic has\nnot been fully explored yet using modern deep learning approaches, even when\nthe well-label samples are limited. In this paper, we propose a One-for-all\nImage Anomaly Detection system (OIAD) based on disentangled learning using only\nclean samples. Our key insight is that the impact of small perturbation on the\nlatent representation can be bounded for normal samples while anomaly images\nare usually outside such bounded intervals, referred to as structure\nconsistency. We implement this idea and evaluate its performance for anomaly\ndetection. Our experiments with three datasets show that OIAD can detect over\n$90\\%$ of anomalies while maintaining a low false alarm rate. It can also\ndetect suspicious samples from samples labeled as clean, coincided with what\nhumans would deem unusual.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 09:57:37 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 09:00:14 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Tianle", ""], ["Chen", "Shangyu", ""], ["Rudolph", "Carsten", ""], ["Nepal", "Surya", ""], ["Grobler", "Marthie", ""]]}, {"id": "2001.06657", "submitter": "Vinay Verma Kumar", "authors": "Anubha Pandey, Ashish Mishra, Vinay Kumar Verma, Anurag Mittal and\n  Hema A. Murthy", "title": "Stacked Adversarial Network for Zero-Shot Sketch based Image Retrieval", "comments": "Accepted in WACV'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional approaches to Sketch-Based Image Retrieval (SBIR) assume that\nthe data of all the classes are available during training. The assumption may\nnot always be practical since the data of a few classes may be unavailable, or\nthe classes may not appear at the time of training. Zero-Shot Sketch-Based\nImage Retrieval (ZS-SBIR) relaxes this constraint and allows the algorithm to\nhandle previously unseen classes during the test. This paper proposes a\ngenerative approach based on the Stacked Adversarial Network (SAN) and the\nadvantage of Siamese Network (SN) for ZS-SBIR. While SAN generates a\nhigh-quality sample, SN learns a better distance metric compared to that of the\nnearest neighbor search. The capability of the generative model to synthesize\nimage features based on the sketch reduces the SBIR problem to that of an\nimage-to-image retrieval problem. We evaluate the efficacy of our proposed\napproach on TU-Berlin, and Sketchy database in both standard ZSL and\ngeneralized ZSL setting. The proposed method yields a significant improvement\nin standard ZSL as well as in a more challenging generalized ZSL setting (GZSL)\nfor SBIR.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 12:18:28 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Pandey", "Anubha", ""], ["Mishra", "Ashish", ""], ["Verma", "Vinay Kumar", ""], ["Mittal", "Anurag", ""], ["Murthy", "Hema A.", ""]]}, {"id": "2001.06668", "submitter": "Douglas Blank", "authors": "Douglas S. Blank", "title": "Learning to See Analogies: A Connectionist Exploration", "comments": "191 pages, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation explores the integration of learning and analogy-making\nthrough the development of a computer program, called Analogator, that learns\nto make analogies by example. By \"seeing\" many different analogy problems,\nalong with possible solutions, Analogator gradually develops an ability to make\nnew analogies. That is, it learns to make analogies by analogy. This approach\nstands in contrast to most existing research on analogy-making, in which\ntypically the a priori existence of analogical mechanisms within a model is\nassumed. The present research extends standard connectionist methodologies by\ndeveloping a specialized associative training procedure for a recurrent network\narchitecture. The network is trained to divide input scenes (or situations)\ninto appropriate figure and ground components. Seeing one scene in terms of a\nparticular figure and ground provides the context for seeing another in an\nanalogous fashion. After training, the model is able to make new analogies\nbetween novel situations. Analogator has much in common with lower-level\nperceptual models of categorization and recognition; it thus serves as a\nunifying framework encompassing both high-level analogical learning and\nlow-level perception. This approach is compared and contrasted with other\ncomputational models of analogy-making. The model's training and generalization\nperformance is examined, and limitations are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 14:06:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Blank", "Douglas S.", ""]]}, {"id": "2001.06679", "submitter": "Zixiang Ding", "authors": "Zixiang Ding, Yaran Chen, Nannan Li, Dongbin Zhao, Zhiquan Sun and\n  C.L. Philip Chen", "title": "BNAS:An Efficient Neural Architecture Search Approach Using Broad\n  Scalable Architecture", "comments": "15 pages, 12 figures, 5 tables", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3067028", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Broad Neural Architecture Search (BNAS) where we\nelaborately design broad scalable architecture dubbed Broad Convolutional\nNeural Network (BCNN) to solve the above issue. On one hand, the proposed broad\nscalable architecture has fast training speed due to its shallow topology.\nMoreover, we also adopt reinforcement learning and parameter sharing used in\nENAS as the optimization strategy of BNAS. Hence, the proposed approach can\nachieve higher search efficiency. On the other hand, the broad scalable\narchitecture extracts multi-scale features and enhancement representations, and\nfeeds them into global average pooling layer to yield more reasonable and\ncomprehensive representations. Therefore, the performance of broad scalable\narchitecture can be promised. In particular, we also develop two variants for\nBNAS who modify the topology of BCNN. In order to verify the effectiveness of\nBNAS, several experiments are performed and experimental results show that 1)\nBNAS delivers 0.19 days which is 2.37x less expensive than ENAS who ranks the\nbest in reinforcement learning-based NAS approaches, 2) compared with\nsmall-size (0.5 millions parameters) and medium-size (1.1 millions parameters)\nmodels, the architecture learned by BNAS obtains state-of-the-art performance\n(3.58% and 3.24% test error) on CIFAR-10, 3) the learned architecture achieves\n25.3% top-1 error on ImageNet just using 3.9 millions parameters.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:07:55 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 11:04:01 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 15:06:12 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 07:09:50 GMT"}, {"version": "v5", "created": "Wed, 20 Jan 2021 07:09:11 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ding", "Zixiang", ""], ["Chen", "Yaran", ""], ["Li", "Nannan", ""], ["Zhao", "Dongbin", ""], ["Sun", "Zhiquan", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "2001.06684", "submitter": "Dakuo Wang", "authors": "Amy X. Zhang, Michael Muller, Dakuo Wang", "title": "How do Data Science Workers Collaborate? Roles, Workflows, and Tools", "comments": "CSCW'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the prominence of data science within organizations has given rise to\nteams of data science workers collaborating on extracting insights from data,\nas opposed to individual data scientists working alone. However, we still lack\na deep understanding of how data science workers collaborate in practice. In\nthis work, we conducted an online survey with 183 participants who work in\nvarious aspects of data science. We focused on their reported interactions with\neach other (e.g., managers with engineers) and with different tools (e.g.,\nJupyter Notebook). We found that data science teams are extremely collaborative\nand work with a variety of stakeholders and tools during the six common steps\nof a data science workflow (e.g., clean data and train model). We also found\nthat the collaborative practices workers employ, such as documentation, vary\naccording to the kinds of tools they use. Based on these findings, we discuss\ndesign implications for supporting data science team collaborations and future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:11:56 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 08:38:00 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 16:38:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Zhang", "Amy X.", ""], ["Muller", "Michael", ""], ["Wang", "Dakuo", ""]]}, {"id": "2001.06699", "submitter": "Frank E. Curtis", "authors": "Frank E. Curtis and Katya Scheinberg", "title": "Adaptive Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization lies at the heart of machine learning and signal processing.\nContemporary approaches based on the stochastic gradient method are\nnon-adaptive in the sense that their implementation employs prescribed\nparameter values that need to be tuned for each application. This article\nsummarizes recent research and motivates future work on adaptive stochastic\noptimization methods, which have the potential to offer significant\ncomputational savings when training large-scale systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 16:30:19 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Curtis", "Frank E.", ""], ["Scheinberg", "Katya", ""]]}, {"id": "2001.06720", "submitter": "Marek Smieja", "authors": "Marek \\'Smieja, {\\L}ukasz Struski, M\\'ario A. T. Figueiredo", "title": "A Classification-Based Approach to Semi-Supervised Clustering with\n  Pairwise Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a neural network framework for semi-supervised\nclustering (SSC) with pairwise (must-link or cannot-link) constraints. In\ncontrast to existing approaches, we decompose SSC into two simpler\nclassification tasks/stages: the first stage uses a pair of Siamese neural\nnetworks to label the unlabeled pairs of points as must-link or cannot-link;\nthe second stage uses the fully pairwise-labeled dataset produced by the first\nstage in a supervised neural-network-based clustering method. The proposed\napproach, S3C2 (Semi-Supervised Siamese Classifiers for Clustering), is\nmotivated by the observation that binary classification (such as assigning\npairwise relations) is usually easier than multi-class clustering with partial\nsupervision. On the other hand, being classification-based, our method solves\nonly well-defined classification problems, rather than less well specified\nclustering tasks. Extensive experiments on various datasets demonstrate the\nhigh performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 20:13:07 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["\u015amieja", "Marek", ""], ["Struski", "\u0141ukasz", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "2001.06725", "submitter": "Juan Vargas", "authors": "Juan Vargas, Lazar Andjelic, Amir Barati Farimani", "title": "Effects of sparse rewards of different magnitudes in the speed of\n  learning of model-based actor critic methods", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor critic methods with sparse rewards in model-based deep reinforcement\nlearning typically require a deterministic binary reward function that reflects\nonly two possible outcomes: if, for each step, the goal has been achieved or\nnot. Our hypothesis is that we can influence an agent to learn faster by\napplying an external environmental pressure during training, which adversely\nimpacts its ability to get higher rewards. As such, we deviate from the\nclassical paradigm of sparse rewards and add a uniformly sampled reward value\nto the baseline reward to show that (1) sample efficiency of the training\nprocess can be correlated to the adversity experienced during training, (2) it\nis possible to achieve higher performance in less time and with less resources,\n(3) we can reduce the performance variability experienced seed over seed, (4)\nthere is a maximum point after which more pressure will not generate better\nresults, and (5) that random positive incentives have an adverse effect when\nusing a negative reward strategy, making an agent under those conditions learn\npoorly and more slowly. These results have been shown to be valid for Deep\nDeterministic Policy Gradients using Hindsight Experience Replay in a well\nknown Mujoco environment, but we argue that they could be generalized to other\nmethods and environments as well.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 20:52:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Vargas", "Juan", ""], ["Andjelic", "Lazar", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "2001.06744", "submitter": "Borja S\\'anchez-L\\'opez", "authors": "Borja S\\'anchez-L\\'opez and Jesus Cerquides", "title": "Dual Stochastic Natural Gradient Descent and convergence of interior\n  half-space gradient approximations", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multinomial logistic regression (MLR) model is widely used in statistics\nand machine learning. Stochastic gradient descent (SGD) is the most common\napproach for determining the parameters of a MLR model in big data scenarios.\nHowever, SGD has slow sub-linear rates of convergence. A way to improve these\nrates of convergence is to use manifold optimization. Along this line,\nstochastic natural gradient descent (SNGD), proposed by Amari, was proven to be\nFisher efficient when it converged. However, SNGD is not guaranteed to converge\nand it is computationally too expensive for MLR models with a large number of\nparameters.\n  Here, we propose a stochastic optimization method for MLR based on manifold\noptimization concepts which (i) has per-iteration computational complexity is\nlinear in the number of parameters and (ii) can be proven to converge.\n  To achieve (i) we establish that the family of joint distributions for MLR is\na dually flat manifold and we use that to speed up calculations.\nS\\'anchez-L\\'opez and Cerquides have recently introduced convergent stochastic\nnatural gradient descent (CSNGD), a variant of SNGD whose convergence is\nguaranteed. To obtain (ii) our algorithm uses the fundamental idea from CSNGD,\nthus relying on an independent sequence to build a bounded approximation of the\nnatural gradient. We call the resulting algorithm dual stochastic natural\ngradient descent (DNSGD). By generalizing a result from Sunehag et al., we\nprove that DSNGD converges. Furthermore, we prove that the computational\ncomplexity of DSNGD iterations are linear on the number of variables of the\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 00:53:49 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 16:45:51 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["S\u00e1nchez-L\u00f3pez", "Borja", ""], ["Cerquides", "Jesus", ""]]}, {"id": "2001.06776", "submitter": "Soumyabrata Pal", "authors": "Akshay Krishnamurthy, Arya Mazumdar, Andrew McGregor, Soumyabrata Pal", "title": "Algebraic and Analytic Approaches for Parameter Learning in Mixture\n  Models", "comments": "22 pages, Accepted at Algorithmic Learning Theory (ALT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two different approaches for parameter learning in several mixture\nmodels in one dimension. Our first approach uses complex-analytic methods and\napplies to Gaussian mixtures with shared variance, binomial mixtures with\nshared success probability, and Poisson mixtures, among others. An example\nresult is that $\\exp(O(N^{1/3}))$ samples suffice to exactly learn a mixture of\n$k<N$ Poisson distributions, each with integral rate parameters bounded by $N$.\nOur second approach uses algebraic and combinatorial tools and applies to\nbinomial mixtures with shared trial parameter $N$ and differing success\nparameters, as well as to mixtures of geometric distributions. Again, as an\nexample, for binomial mixtures with $k$ components and success parameters\ndiscretized to resolution $\\epsilon$, $O(k^2(N/\\epsilon)^{8/\\sqrt{\\epsilon}})$\nsamples suffice to exactly recover the parameters. For some of these\ndistributions, our results represent the first guarantees for parameter\nestimation.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 05:10:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Mazumdar", "Arya", ""], ["McGregor", "Andrew", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2001.06780", "submitter": "Canhong Wen", "authors": "Quan Xiao, Canhong Wen, Zirui Yan", "title": "Image denoising via K-SVD with primal-dual active set algorithm", "comments": "9 pages, 6 figures. The paper was accepted by IEEE. WACV 2020 and\n  will placed in the IEEE Xplore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-SVD algorithm has been successfully applied to image denoising tasks dozens\nof years but the big bottleneck in speed and accuracy still needs attention to\nbreak. For the sparse coding stage in K-SVD, which involves $\\ell_{0}$\nconstraint, prevailing methods usually seek approximate solutions greedily but\nare less effective once the noise level is high. The alternative $\\ell_{1}$\noptimization is proved to be powerful than $\\ell_{0}$, however, the time\nconsumption prevents it from the implementation. In this paper, we propose a\nnew K-SVD framework called K-SVD$_P$ by applying the Primal-dual active set\n(PDAS) algorithm to it. Different from the greedy algorithms based K-SVD, the\nK-SVD$_P$ algorithm develops a selection strategy motivated by KKT\n(Karush-Kuhn-Tucker) condition and yields to an efficient update in the sparse\ncoding stage. Since the K-SVD$_P$ algorithm seeks for an equivalent solution to\nthe dual problem iteratively with simple explicit expression in this denoising\nproblem, speed and quality of denoising can be reached simultaneously.\nExperiments are carried out and demonstrate the comparable denoising\nperformance of our K-SVD$_P$ with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 06:03:39 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xiao", "Quan", ""], ["Wen", "Canhong", ""], ["Yan", "Zirui", ""]]}, {"id": "2001.06782", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol\n  Hausman, Chelsea Finn", "title": "Gradient Surgery for Multi-Task Learning", "comments": "NeurIPS 2020. Code is available at\n  https://github.com/tianheyu927/PCGrad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning and deep reinforcement learning (RL) systems have\ndemonstrated impressive results in domains such as image classification, game\nplaying, and robotic control, data efficiency remains a major challenge.\nMulti-task learning has emerged as a promising approach for sharing structure\nacross multiple tasks to enable more efficient learning. However, the\nmulti-task setting presents a number of optimization challenges, making it\ndifficult to realize large efficiency gains compared to learning tasks\nindependently. The reasons why multi-task learning is so challenging compared\nto single-task learning are not fully understood. In this work, we identify a\nset of three conditions of the multi-task optimization landscape that cause\ndetrimental gradient interference, and develop a simple yet general approach\nfor avoiding such interference between task gradients. We propose a form of\ngradient surgery that projects a task's gradient onto the normal plane of the\ngradient of any other task that has a conflicting gradient. On a series of\nchallenging multi-task supervised and multi-task RL problems, this approach\nleads to substantial gains in efficiency and performance. Further, it is\nmodel-agnostic and can be combined with previously-proposed multi-task\narchitectures for enhanced performance.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 06:33:47 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 23:41:08 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 06:07:19 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 00:35:46 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Yu", "Tianhe", ""], ["Kumar", "Saurabh", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Hausman", "Karol", ""], ["Finn", "Chelsea", ""]]}, {"id": "2001.06793", "submitter": "Matthew Cockcroft", "authors": "Matthew Cockcroft, Shahil Mawjee, Steven James, Pravesh Ranchod", "title": "Learning Options from Demonstration using Skill Segmentation", "comments": "To be published in SAUPEC/RobMech/PRASA 2020. Consists of 6 pages, 5\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning options from segmented demonstration\ntrajectories. The trajectories are first segmented into skills using\nnonparametric Bayesian clustering and a reward function for each segment is\nthen learned using inverse reinforcement learning. From this, a set of inferred\ntrajectories for the demonstration are generated. Option initiation sets and\ntermination conditions are learned from these trajectories using the one-class\nsupport vector machine clustering algorithm. We demonstrate our method in the\nfour rooms domain, where an agent is able to autonomously discover usable\noptions from human demonstration. Our results show that these inferred options\ncan then be used to improve learning and planning.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 09:29:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Cockcroft", "Matthew", ""], ["Mawjee", "Shahil", ""], ["James", "Steven", ""], ["Ranchod", "Pravesh", ""]]}, {"id": "2001.06808", "submitter": "Daichi Nishio", "authors": "Daichi Nishio, Daiki Kuyoshi, Toi Tsuneda and Satoshi Yamane", "title": "Discriminator Soft Actor Critic without Extrinsic Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to be able to imitate well in unknown states from a small\namount of expert data and sampling data. Supervised learning methods such as\nBehavioral Cloning do not require sampling data, but usually suffer from\ndistribution shift. The methods based on reinforcement learning, such as\ninverse reinforcement learning and generative adversarial imitation learning\n(GAIL), can learn from only a few expert data. However, they often need to\ninteract with the environment. Soft Q imitation learning addressed the\nproblems, and it was shown that it could learn efficiently by combining\nBehavioral Cloning and soft Q-learning with constant rewards. In order to make\nthis algorithm more robust to distribution shift, we propose Discriminator Soft\nActor Critic (DSAC). It uses a reward function based on adversarial inverse\nreinforcement learning instead of constant rewards. We evaluated it on PyBullet\nenvironments with only four expert trajectories.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 10:45:35 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 15:39:22 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 12:39:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Nishio", "Daichi", ""], ["Kuyoshi", "Daiki", ""], ["Tsuneda", "Toi", ""], ["Yamane", "Satoshi", ""]]}, {"id": "2001.06814", "submitter": "Thanh Nguyen Tang", "authors": "Thanh Tang Nguyen, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh", "title": "Distributionally Robust Bayesian Quadrature Optimization", "comments": "AISTATS2020", "journal-ref": "AISTATS2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian quadrature optimization (BQO) maximizes the expectation of an\nexpensive black-box integrand taken over a known probability distribution. In\nthis work, we study BQO under distributional uncertainty in which the\nunderlying probability distribution is unknown except for a limited set of its\ni.i.d. samples. A standard BQO approach maximizes the Monte Carlo estimate of\nthe true expected objective given the fixed sample set. Though Monte Carlo\nestimate is unbiased, it has high variance given a small set of samples; thus\ncan result in a spurious objective function. We adopt the distributionally\nrobust optimization perspective to this problem by maximizing the expected\nobjective under the most adversarial distribution. In particular, we propose a\nnovel posterior sampling based algorithm, namely distributionally robust BQO\n(DRBQO) for this purpose. We demonstrate the empirical effectiveness of our\nproposed framework in synthetic and real-world problems, and characterize its\ntheoretical convergence via Bayesian regret.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 12:00:33 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Nguyen", "Thanh Tang", ""], ["Gupta", "Sunil", ""], ["Ha", "Huong", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2001.06838", "submitter": "Ruosi Wan", "authors": "Junjie Yan, Ruosi Wan, Xiangyu Zhang, Wei Zhang, Yichen Wei, Jian Sun", "title": "Towards Stabilizing Batch Statistics in Backward Propagation of Batch\n  Normalization", "comments": "ICLR2020; https://github.com/megvii-model/MABN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) is one of the most widely used techniques in Deep\nLearning field. But its performance can awfully degrade with insufficient batch\nsize. This weakness limits the usage of BN on many computer vision tasks like\ndetection or segmentation, where batch size is usually small due to the\nconstraint of memory consumption. Therefore many modified normalization\ntechniques have been proposed, which either fail to restore the performance of\nBN completely, or have to introduce additional nonlinear operations in\ninference procedure and increase huge consumption. In this paper, we reveal\nthat there are two extra batch statistics involved in backward propagation of\nBN, on which has never been well discussed before. The extra batch statistics\nassociated with gradients also can severely affect the training of deep neural\nnetwork. Based on our analysis, we propose a novel normalization method, named\nMoving Average Batch Normalization (MABN). MABN can completely restore the\nperformance of vanilla BN in small batch cases, without introducing any\nadditional nonlinear operations in inference procedure. We prove the benefits\nof MABN by both theoretical analysis and experiments. Our experiments\ndemonstrate the effectiveness of MABN in multiple computer vision tasks\nincluding ImageNet and COCO. The code has been released in\nhttps://github.com/megvii-model/MABN.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 14:41:22 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 10:06:09 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yan", "Junjie", ""], ["Wan", "Ruosi", ""], ["Zhang", "Xiangyu", ""], ["Zhang", "Wei", ""], ["Wei", "Yichen", ""], ["Sun", "Jian", ""]]}, {"id": "2001.06858", "submitter": "Yuan Wang", "authors": "Ray-Bing Chen, Yuan Wang, C. F. Jeff Wu", "title": "Finding Optimal Points for Expensive Functions Using Adaptive RBF-Based\n  Surrogate Model Via Uncertainty Quantification", "comments": "35 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global optimization of expensive functions has important applications in\nphysical and computer experiments. It is a challenging problem to develop\nefficient optimization scheme, because each function evaluation can be costly\nand the derivative information of the function is often not available. We\npropose a novel global optimization framework using adaptive Radial Basis\nFunctions (RBF) based surrogate model via uncertainty quantification. The\nframework consists of two iteration steps. It first employs an RBF-based\nBayesian surrogate model to approximate the true function, where the parameters\nof the RBFs can be adaptively estimated and updated each time a new point is\nexplored. Then it utilizes a model-guided selection criterion to identify a new\npoint from a candidate set for function evaluation. The selection criterion\nadopted here is a sample version of the expected improvement (EI) criterion. We\nconduct simulation studies with standard test functions, which show that the\nproposed method has some advantages, especially when the true surface is not\nvery smooth. In addition, we also propose modified approaches to improve the\nsearch performance for identifying global optimal points and to deal with the\nhigher dimension scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 16:15:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chen", "Ray-Bing", ""], ["Wang", "Yuan", ""], ["Wu", "C. F. Jeff", ""]]}, {"id": "2001.06880", "submitter": "Vidhi Lalchand Miss", "authors": "Vidhi Lalchand", "title": "A meta-algorithm for classification using random recursive tree\n  ensembles: A high energy physics application", "comments": "MPhil Thesis (Scientific Computing, Physics, Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to propose a meta-algorithm for automatic\nclassification in the presence of discrete binary classes. Classifier learning\nin the presence of overlapping class distributions is a challenging problem in\nmachine learning. Overlapping classes are described by the presence of\nambiguous areas in the feature space with a high density of points belonging to\nboth classes. This often occurs in real-world datasets, one such example is\nnumeric data denoting properties of particle decays derived from high-energy\naccelerators like the Large Hadron Collider (LHC). A significant body of\nresearch targeting the class overlap problem use ensemble classifiers to boost\nthe performance of algorithms by using them iteratively in multiple stages or\nusing multiple copies of the same model on different subsets of the input\ntraining data. The former is called boosting and the latter is called bagging.\nThe algorithm proposed in this thesis targets a challenging classification\nproblem in high energy physics - that of improving the statistical significance\nof the Higgs discovery. The underlying dataset used to train the algorithm is\nexperimental data built from the official ATLAS full-detector simulation with\nHiggs events (signal) mixed with different background events (background) that\nclosely mimic the statistical properties of the signal generating class\noverlap. The algorithm proposed is a variant of the classical boosted decision\ntree which is known to be one of the most successful analysis techniques in\nexperimental physics. The algorithm utilizes a unified framework that combines\ntwo meta-learning techniques - bagging and boosting. The results show that this\ncombination only works in the presence of a randomization trick in the base\nlearners.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 18:22:18 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lalchand", "Vidhi", ""]]}, {"id": "2001.06892", "submitter": "Guang Cheng", "authors": "Tianyang Hu, Zuofeng Shang, Guang Cheng", "title": "Sharp Rate of Convergence for Deep Neural Network Classifiers under the\n  Teacher-Student Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers built with neural networks handle large-scale high dimensional\ndata, such as facial images from computer vision, extremely well while\ntraditional statistical methods often fail miserably. In this paper, we attempt\nto understand this empirical success in high dimensional classification by\nderiving the convergence rates of excess risk. In particular, a teacher-student\nframework is proposed that assumes the Bayes classifier to be expressed as ReLU\nneural networks. In this setup, we obtain a sharp rate of convergence, i.e.,\n$\\tilde{O}_d(n^{-2/3})$, for classifiers trained using either 0-1 loss or hinge\nloss. This rate can be further improved to $\\tilde{O}_d(n^{-1})$ when the data\ndistribution is separable. Here, $n$ denotes the sample size. An interesting\nobservation is that the data dimension only contributes to the $\\log(n)$ term\nin the above rates. This may provide one theoretical explanation for the\nempirical successes of deep neural networks in high dimensional classification,\nparticularly for structured data.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 19:58:43 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 04:58:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hu", "Tianyang", ""], ["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "2001.06931", "submitter": "Shunichi Amari", "authors": "Shun-ichi Amari", "title": "Any Target Function Exists in a Neighborhood of Any Sufficiently Wide\n  Random Network: A Geometrical Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that any target function is realized in a sufficiently small\nneighborhood of any randomly connected deep network, provided the width (the\nnumber of neurons in a layer) is sufficiently large. There are sophisticated\ntheories and discussions concerning this striking fact, but rigorous theories\nare very complicated. We give an elementary geometrical proof by using a simple\nmodel for the purpose of elucidating its structure. We show that\nhigh-dimensional geometry plays a magical role: When we project a\nhigh-dimensional sphere of radius 1 to a low-dimensional subspace, the uniform\ndistribution over the sphere reduces to a Gaussian distribution of negligibly\nsmall covariances.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:09:53 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 01:00:37 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Amari", "Shun-ichi", ""]]}, {"id": "2001.06937", "submitter": "Jie Gui", "authors": "Jie Gui, Zhenan Sun, Yonggang Wen, Dacheng Tao, Jieping Ye", "title": "A Review on Generative Adversarial Networks: Algorithms, Theory, and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a hot research topic recently.\nGANs have been widely studied since 2014, and a large number of algorithms have\nbeen proposed. However, there is few comprehensive study explaining the\nconnections among different GANs variants, and how they have evolved. In this\npaper, we attempt to provide a review on various GANs methods from the\nperspectives of algorithms, theory, and applications. Firstly, the motivations,\nmathematical representations, and structure of most GANs algorithms are\nintroduced in details. Furthermore, GANs have been combined with other machine\nlearning algorithms for specific applications, such as semi-supervised\nlearning, transfer learning, and reinforcement learning. This paper compares\nthe commonalities and differences of these GANs methods. Secondly, theoretical\nissues related to GANs are investigated. Thirdly, typical applications of GANs\nin image processing and computer vision, natural language processing, music,\nspeech and audio, medical field, and data science are illustrated. Finally, the\nfuture open research problems for GANs are pointed out.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:52:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gui", "Jie", ""], ["Sun", "Zhenan", ""], ["Wen", "Yonggang", ""], ["Tao", "Dacheng", ""], ["Ye", "Jieping", ""]]}, {"id": "2001.06938", "submitter": "Roman Vershynin", "authors": "Roman Vershynin", "title": "Memory capacity of neural networks with threshold and ReLU activations", "comments": "26 pages. Minor inaccuracies corrected, discussion of prior work\n  expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overwhelming theoretical and empirical evidence shows that mildly\noverparametrized neural networks -- those with more connections than the size\nof the training data -- are often able to memorize the training data with\n$100\\%$ accuracy. This was rigorously proved for networks with sigmoid\nactivation functions and, very recently, for ReLU activations. Addressing a\n1988 open question of Baum, we prove that this phenomenon holds for general\nmultilayered perceptrons, i.e. neural networks with threshold activation\nfunctions, or with any mix of threshold and ReLU activations. Our construction\nis probabilistic and exploits sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:54:21 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 18:38:18 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Vershynin", "Roman", ""]]}, {"id": "2001.06940", "submitter": "Tom Blau", "authors": "Philippe Morere, Gilad Francis, Tom Blau, Fabio Ramos", "title": "Reinforcement Learning with Probabilistically Complete Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing exploration and exploitation remains a key challenge in\nreinforcement learning (RL). State-of-the-art RL algorithms suffer from high\nsample complexity, particularly in the sparse reward case, where they can do no\nbetter than to explore in all directions until the first positive rewards are\nfound. To mitigate this, we propose Rapidly Randomly-exploring Reinforcement\nLearning (R3L). We formulate exploration as a search problem and leverage\nwidely-used planning algorithms such as Rapidly-exploring Random Tree (RRT) to\nfind initial solutions. These solutions are used as demonstrations to\ninitialize a policy, then refined by a generic RL algorithm, leading to faster\nand more stable convergence. We provide theoretical guarantees of R3L\nexploration finding successful solutions, as well as bounds for its sampling\ncomplexity. We experimentally demonstrate the method outperforms classic and\nintrinsic exploration techniques, requiring only a fraction of exploration\nsamples and achieving better asymptotic performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 02:11:24 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Morere", "Philippe", ""], ["Francis", "Gilad", ""], ["Blau", "Tom", ""], ["Ramos", "Fabio", ""]]}, {"id": "2001.06954", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Aaron Zimmer, Navaneeth Kamballur Kottayil, Xinyao\n  Sun, Parwant Ghuman, Irene Cheng", "title": "CNN-based InSAR Denoising and Coherence Metric", "comments": "2018 IEEE SENSORS", "journal-ref": null, "doi": "10.1109/ICSENS.2018.8589920", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interferometric Synthetic Aperture Radar (InSAR) imagery for estimating\nground movement, based on microwaves reflected off ground targets is gaining\nincreasing importance in remote sensing. However, noise corrupts microwave\nreflections received at satellite and contaminates the signal's wrapped phase.\nWe introduce Convolutional Neural Networks (CNNs) to this problem domain and\nshow the effectiveness of autoencoder CNN architectures to learn InSAR image\ndenoising filters in the absence of clean ground truth images, and for artefact\nreduction in estimated coherence through intelligent preprocessing of training\ndata. We compare our results with four established methods to illustrate\nsuperiority of proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 03:20:29 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Zimmer", "Aaron", ""], ["Kottayil", "Navaneeth Kamballur", ""], ["Sun", "Xinyao", ""], ["Ghuman", "Parwant", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.06956", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Aaron Zimmer, Xinyao Sun, Parwant Ghuman, and\n  Irene Cheng", "title": "CNN-based InSAR Coherence Classification", "comments": "2018 IEEE SENSORS", "journal-ref": null, "doi": "10.1109/ICSENS.2018.8589742", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interferometric Synthetic Aperture Radar (InSAR) imagery based on microwaves\nreflected off ground targets is becoming increasingly important in remote\nsensing for ground movement estimation. However, the reflections are\ncontaminated by noise, which distorts the signal's wrapped phase. Demarcation\nof image regions based on degree of contamination (\"coherence\") is an important\ncomponent of the InSAR processing pipeline. We introduce Convolutional Neural\nNetworks (CNNs) to this problem domain and show their effectiveness in\nimproving coherence-based demarcation and reducing misclassifications in\ncompletely incoherent regions through intelligent preprocessing of training\ndata. Quantitative and qualitative comparisons prove superiority of proposed\nmethod over three established methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 03:25:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Zimmer", "Aaron", ""], ["Sun", "Xinyao", ""], ["Ghuman", "Parwant", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.06961", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Navaneeth Kamballur Kottayil, Xinyao Sun, and\n  Irene Cheng", "title": "CNN-Based Real-Time Parameter Tuning for Optimizing Denoising Filter\n  Performance", "comments": "2019 International Conference on Image Analysis and Recognition", "journal-ref": null, "doi": "10.1007/978-3-030-27202-9_10", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel direction to improve the denoising quality of\nfiltering-based denoising algorithms in real time by predicting the best filter\nparameter value using a Convolutional Neural Network (CNN). We take the use\ncase of BM3D, the state-of-the-art filtering-based denoising algorithm, to\ndemonstrate and validate our approach. We propose and train a simple, shallow\nCNN to predict in real time, the optimum filter parameter value, given the\ninput noisy image. Each training example consists of a noisy input image\n(training data) and the filter parameter value that produces the best output\n(training label). Both qualitative and quantitative results using the widely\nused PSNR and SSIM metrics on the popular BSD68 dataset show that the\nCNN-guided BM3D outperforms the original, unguided BM3D across different noise\nlevels. Thus, our proposed method is a CNN-based improvement on the original\nBM3D which uses a fixed, default parameter value for all images.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 03:46:06 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Kottayil", "Navaneeth Kamballur", ""], ["Sun", "Xinyao", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.06970", "submitter": "Qing Qu", "authors": "Qing Qu, Zhihui Zhu, Xiao Li, Manolis C. Tsakiris, John Wright, and\n  Ren\\'e Vidal", "title": "Finding the Sparsest Vectors in a Subspace: Theory, Algorithms, and\n  Applications", "comments": "QQ and ZZ contributed equally to the work. Invited review paper for\n  IEEE Signal Processing Magazine Special Issue on non-convex optimization for\n  signal processing and machine learning. This article contains 26 pages with\n  11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.IV math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding the sparsest vector (direction) in a low dimensional\nsubspace can be considered as a homogeneous variant of the sparse recovery\nproblem, which finds applications in robust subspace recovery, dictionary\nlearning, sparse blind deconvolution, and many other problems in signal\nprocessing and machine learning. However, in contrast to the classical sparse\nrecovery problem, the most natural formulation for finding the sparsest vector\nin a subspace is usually nonconvex. In this paper, we overview recent advances\non global nonconvex optimization theory for solving this problem, ranging from\ngeometric analysis of its optimization landscapes, to efficient optimization\nalgorithms for solving the associated nonconvex optimization problem, to\napplications in machine intelligence, representation learning, and imaging\nsciences. Finally, we conclude this review by pointing out several interesting\nopen problems for future research.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:48:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Qu", "Qing", ""], ["Zhu", "Zhihui", ""], ["Li", "Xiao", ""], ["Tsakiris", "Manolis C.", ""], ["Wright", "John", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "2001.06988", "submitter": "Yasuho Yamashita", "authors": "Yasuho Yamashita, Takuma Shibahara and Junichi Kuwata", "title": "A point-wise linear model reveals reasons for 30-day readmission of\n  heart failure patients", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart failures in the United States cost an estimated 30.7 billion dollars\nannually and predictive analysis can decrease costs due to readmission of heart\nfailure patients. Deep learning can predict readmissions but does not give\nreasons for its predictions. Ours is the first study on a deep-learning\napproach to explaining decisions behind readmission predictions. Additionally,\nit provides an automatic patient stratification to explain cohorts of\nreadmitted patients. The new deep-learning model called a point-wise linear\nmodel is a meta-learning machine of linear models. It generates a logistic\nregression model to predict early readmission for each patient. The custom-made\nprediction models allow us to analyze feature importance. We evaluated the\napproach using a dataset that had 30-days readmission patients with heart\nfailures. This study has been submitted in PLOS ONE. In advance, we would like\nto share the theoretical aspect of the point-wise linear model as a part of our\nstudy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:56:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yamashita", "Yasuho", ""], ["Shibahara", "Takuma", ""], ["Kuwata", "Junichi", ""]]}, {"id": "2001.07026", "submitter": "Daniel J. Trosten", "authors": "Daniel J. Trosten, Michael C. Kampffmeyer, Robert Jenssen", "title": "Deep Image Clustering with Tensor Kernels and Unsupervised Companion\n  Objectives", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a new model for deep image clustering, using\nconvolutional neural networks and tensor kernels. The proposed Deep Tensor\nKernel Clustering (DTKC) consists of a convolutional neural network (CNN),\nwhich is trained to reflect a common cluster structure at the output of its\nintermediate layers. Encouraging a consistent cluster structure throughout the\nnetwork has the potential to guide it towards meaningful clusters, even though\nthese clusters might appear to be nonlinear in the input space. The cluster\nstructure is enforced through the idea of unsupervised companion objectives,\nwhere separate loss functions are attached to layers in the network. These\nunsupervised companion objectives are constructed based on a proposed\ngeneralization of the Cauchy-Schwarz (CS) divergence, from vectors to tensors\nof arbitrary rank. Generalizing the CS divergence to tensor-valued data is a\ncrucial step, due to the tensorial nature of the intermediate representations\nin the CNN. Several experiments are conducted to thoroughly assess the\nperformance of the proposed DTKC model. The results indicate that the model\noutperforms, or performs comparable to, a wide range of baseline algorithms. We\nalso empirically demonstrate that our model does not suffer from objective\nfunction mismatch, which can be a problematic artifact in autoencoder-based\nclustering models.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 09:07:59 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 15:12:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Trosten", "Daniel J.", ""], ["Kampffmeyer", "Michael C.", ""], ["Jenssen", "Robert", ""]]}, {"id": "2001.07042", "submitter": "Arjun Seshadri", "authors": "Arjun Seshadri, Johan Ugander", "title": "Fundamental Limits of Testing the Independence of Irrelevant\n  Alternatives in Discrete Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multinomial Logit (MNL) model and the axiom it satisfies, the\nIndependence of Irrelevant Alternatives (IIA), are together the most widely\nused tools of discrete choice. The MNL model serves as the workhorse model for\na variety of fields, but is also widely criticized, with a large body of\nexperimental literature claiming to document real-world settings where IIA\nfails to hold. Statistical tests of IIA as a modelling assumption have been the\nsubject of many practical tests focusing on specific deviations from IIA over\nthe past several decades, but the formal size properties of hypothesis testing\nIIA are still not well understood. In this work we replace some of the\nambiguity in this literature with rigorous pessimism, demonstrating that any\ngeneral test for IIA with low worst-case error would require a number of\nsamples exponential in the number of alternatives of the choice problem. A\nmajor benefit of our analysis over previous work is that it lies entirely in\nthe finite-sample domain, a feature crucial to understanding the behavior of\ntests in the common data-poor settings of discrete choice. Our lower bounds are\nstructure-dependent, and as a potential cause for optimism, we find that if one\nrestricts the test of IIA to violations that can occur in a specific collection\nof choice sets (e.g., pairs), one obtains structure-dependent lower bounds that\nare much less pessimistic. Our analysis of this testing problem is unorthodox\nin being highly combinatorial, counting Eulerian orientations of cycle\ndecompositions of a particular bipartite graph constructed from a data set of\nchoices. By identifying fundamental relationships between the comparison\nstructure of a given testing problem and its sample efficiency, we hope these\nrelationships will help lay the groundwork for a rigorous rethinking of the IIA\ntesting problem as well as other testing problems in discrete choice.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 10:15:28 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Seshadri", "Arjun", ""], ["Ugander", "Johan", ""]]}, {"id": "2001.07072", "submitter": "Zhengqi Gao", "authors": "Zhengqi Gao, Jun Tao, Yangfeng Su, Dian Zhou, and Xuan Zeng", "title": "Projection based Active Gaussian Process Regression for Pareto Front\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pareto Front (PF) modeling is essential in decision making problems across\nall domains such as economics, medicine or engineering. In Operation Research\nliterature, this task has been addressed based on multi-objective optimization\nalgorithms. However, without learning models for PF, these methods cannot\nexamine whether a new provided point locates on PF or not. In this paper, we\nreconsider the task from Data Mining perspective. A novel projection based\nactive Gaussian process regression (P- aGPR) method is proposed for efficient\nPF modeling. First, P- aGPR chooses a series of projection spaces with\ndimensionalities ranking from low to high. Next, in each projection space, a\nGaussian process regression (GPR) model is trained to represent the constraint\nthat PF should satisfy in that space. Moreover, in order to improve modeling\nefficacy and stability, an active learning framework has been developed by\nexploiting the uncertainty information obtained in the GPR models. Different\nfrom all existing methods, our proposed P-aGPR method can not only provide a\ngenerative PF model, but also fast examine whether a provided point locates on\nPF or not. The numerical results demonstrate that compared to state-of-the-art\npassive learning methods the proposed P-aGPR method can achieve higher modeling\naccuracy and stability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 11:52:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gao", "Zhengqi", ""], ["Tao", "Jun", ""], ["Su", "Yangfeng", ""], ["Zhou", "Dian", ""], ["Zeng", "Xuan", ""]]}, {"id": "2001.07119", "submitter": "Mengzhuo Guo", "authors": "Mengzhuo Guo, Qingpeng Zhang, Xiuwu Liao, Daniel Dajun Zeng", "title": "An interpretable neural network model through piecewise linear\n  approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing interpretable methods explain a black-box model in a post-hoc\nmanner, which uses simpler models or data analysis techniques to interpret the\npredictions after the model is learned. However, they (a) may derive\ncontradictory explanations on the same predictions given different methods and\ndata samples, and (b) focus on using simpler models to provide higher\ndescriptive accuracy at the sacrifice of prediction accuracy. To address these\nissues, we propose a hybrid interpretable model that combines a piecewise\nlinear component and a nonlinear component. The first component describes the\nexplicit feature contributions by piecewise linear approximation to increase\nthe expressiveness of the model. The other component uses a multi-layer\nperceptron to capture feature interactions and implicit nonlinearity, and\nincrease the prediction performance. Different from the post-hoc approaches,\nthe interpretability is obtained once the model is learned in the form of\nfeature shapes. We also provide a variant to explore higher-order interactions\namong features to demonstrate that the proposed model is flexible for\nadaptation. Experiments demonstrate that the proposed model can achieve good\ninterpretability by describing feature shapes while maintaining\nstate-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 14:32:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Guo", "Mengzhuo", ""], ["Zhang", "Qingpeng", ""], ["Liao", "Xiuwu", ""], ["Zeng", "Daniel Dajun", ""]]}, {"id": "2001.07135", "submitter": "Zhi-Hua Zhou", "authors": "Xi-Zhu Wu, Wenkai Xu, Song Liu, and Zhi-Hua Zhou", "title": "Model Reuse with Reduced Kernel Mean Embedding Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a publicly available pool of machine learning models constructed for\nvarious tasks, when a user plans to build a model for her own machine learning\napplication, is it possible to build upon models in the pool such that the\nprevious efforts on these existing models can be reused rather than starting\nfrom scratch? Here, a grand challenge is how to find models that are helpful\nfor the current application, without accessing the raw training data for the\nmodels in the pool. In this paper, we present a two-phase framework. In the\nupload phase, when a model is uploading into the pool, we construct a reduced\nkernel mean embedding (RKME) as a specification for the model. Then in the\ndeployment phase, the relatedness of the current task and pre-trained models\nwill be measured based on the value of the RKME specification. Theoretical\nresults and extensive experiments validate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:15:07 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Xi-Zhu", ""], ["Xu", "Wenkai", ""], ["Liu", "Song", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2001.07155", "submitter": "Vladimir Berikov", "authors": "Vladimir Berikov", "title": "Heterogeneous Transfer Learning in Ensemble Clustering", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an ensemble clustering method using transfer learning\napproach. We consider a clustering problem, in which in addition to data under\nconsideration, \"similar\" labeled data are available. The datasets can be\ndescribed with different features. The method is based on constructing\nmeta-features which describe structural characteristics of data, and their\ntransfer from source to target domain. An experimental study of the method\nusing Monte Carlo modeling has confirmed its efficiency. In comparison with\nother similar methods, the proposed one is able to work under arbitrary feature\ndescriptions of source and target domains; it has smaller complexity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 16:03:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Berikov", "Vladimir", ""]]}, {"id": "2001.07248", "submitter": "Liudmila Ostroumova Prokhorenkova", "authors": "Aleksei Ustimenko and Liudmila Prokhorenkova", "title": "SGLB: Stochastic Gradient Langevin Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Stochastic Gradient Langevin Boosting (SGLB) - a\npowerful and efficient machine learning framework that may deal with a wide\nrange of loss functions and has provable generalization guarantees. The method\nis based on a special form of the Langevin diffusion equation specifically\ndesigned for gradient boosting. This allows us to theoretically guarantee the\nglobal convergence even for multimodal loss functions, while standard gradient\nboosting algorithms can guarantee only local optimum. We also empirically show\nthat SGLB outperforms classic gradient boosting when applied to classification\ntasks with 0-1 loss function, which is known to be multimodal.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 20:44:52 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 14:45:51 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 15:56:26 GMT"}, {"version": "v4", "created": "Sun, 4 Jul 2021 19:03:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ustimenko", "Aleksei", ""], ["Prokhorenkova", "Liudmila", ""]]}, {"id": "2001.07278", "submitter": "Arturo Berrones", "authors": "Arturo Berrones-Santos", "title": "Mixed integer programming formulation of unsupervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel formulation and training procedure for full Boltzmann machines in\nterms of a mixed binary quadratic feasibility problem is given. As a proof of\nconcept, the theory is analytically and numerically tested on XOR patterns.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 23:09:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Berrones-Santos", "Arturo", ""]]}, {"id": "2001.07301", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein, Roman Novak, Samuel S. Schoenholz, Jaehoon Lee", "title": "On the infinite width limit of neural networks with a standard\n  parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are currently two parameterizations used to derive fixed kernels\ncorresponding to infinite width neural networks, the NTK (Neural Tangent\nKernel) parameterization and the naive standard parameterization. However, the\nextrapolation of both of these parameterizations to infinite width is\nproblematic. The standard parameterization leads to a divergent neural tangent\nkernel while the NTK parameterization fails to capture crucial aspects of\nfinite width networks such as: the dependence of training dynamics on relative\nlayer widths, the relative training dynamics of weights and biases, and overall\nlearning rate scale. Here we propose an improved extrapolation of the standard\nparameterization that preserves all of these properties as width is taken to\ninfinity and yields a well-defined neural tangent kernel. We show\nexperimentally that the resulting kernels typically achieve similar accuracy to\nthose resulting from an NTK parameterization, but with better correspondence to\nthe parameterization of typical finite width networks. Additionally, with\ncareful tuning of width parameters, the improved standard parameterization\nkernels can outperform those stemming from an NTK parameterization. We release\ncode implementing this improved standard parameterization as part of the Neural\nTangents library at https://github.com/google/neural-tangents.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 01:02:21 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 00:53:47 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 21:06:06 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""], ["Novak", "Roman", ""], ["Schoenholz", "Samuel S.", ""], ["Lee", "Jaehoon", ""]]}, {"id": "2001.07322", "submitter": "Bahareh Behboodi", "authors": "Bahareh Behboodi, Mina Amiri, Rupert Brooks, Hassan Rivaz", "title": "Breast lesion segmentation in ultrasound images with limited annotated\n  data", "comments": "Accepted to ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is one of the most commonly used imaging modalities in both\ndiagnosis and surgical interventions due to its low-cost, safety, and\nnon-invasive characteristic. US image segmentation is currently a unique\nchallenge because of the presence of speckle noise. As manual segmentation\nrequires considerable efforts and time, the development of automatic\nsegmentation algorithms has attracted researchers attention. Although recent\nmethodologies based on convolutional neural networks have shown promising\nperformances, their success relies on the availability of a large number of\ntraining data, which is prohibitively difficult for many applications.\nTherefore, in this study we propose the use of simulated US images and natural\nimages as auxiliary datasets in order to pre-train our segmentation network,\nand then to fine-tune with limited in vivo data. We show that with as little as\n19 in vivo images, fine-tuning the pre-trained network improves the dice score\nby 21% compared to training from scratch. We also demonstrate that if the same\nnumber of natural and simulation US images is available, pre-training on\nsimulation data is preferable.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:34:42 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Behboodi", "Bahareh", ""], ["Amiri", "Mina", ""], ["Brooks", "Rupert", ""], ["Rivaz", "Hassan", ""]]}, {"id": "2001.07384", "submitter": "Jinlong Liu", "authors": "Jinlong Liu, Guoqing Jiang, Yunzhi Bai, Ting Chen, Huayan Wang", "title": "Understanding Why Neural Networks Generalize Well Through GSNR of\n  Parameters", "comments": "14 pages, 8 figures, ICLR2020 accepted as spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As deep neural networks (DNNs) achieve tremendous success across many\napplication domains, researchers tried to explore in many aspects on why they\ngeneralize well. In this paper, we provide a novel perspective on these issues\nusing the gradient signal to noise ratio (GSNR) of parameters during training\nprocess of DNNs. The GSNR of a parameter is defined as the ratio between its\ngradient's squared mean and variance, over the data distribution. Based on\nseveral approximations, we establish a quantitative relationship between model\nparameters' GSNR and the generalization gap. This relationship indicates that\nlarger GSNR during training process leads to better generalization performance.\nMoreover, we show that, different from that of shallow models (e.g. logistic\nregression, support vector machines), the gradient descent optimization\ndynamics of DNNs naturally produces large GSNR during training, which is\nprobably the key to DNNs' remarkable generalization ability.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 08:33:29 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 10:47:39 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Liu", "Jinlong", ""], ["Jiang", "Guoqing", ""], ["Bai", "Yunzhi", ""], ["Chen", "Ting", ""], ["Wang", "Huayan", ""]]}, {"id": "2001.07402", "submitter": "Daniele Gammelli", "authors": "Daniele Gammelli, Inon Peled, Filipe Rodrigues, Dario Pacino, Haci A.\n  Kurtaran, Francisco C. Pereira", "title": "Estimating Latent Demand of Shared Mobility through Censored Gaussian\n  Processes", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transport demand is highly dependent on supply, especially for shared\ntransport services where availability is often limited. As observed demand\ncannot be higher than available supply, historical transport data typically\nrepresents a biased, or censored, version of the true underlying demand\npattern. Without explicitly accounting for this inherent distinction,\npredictive models of demand would necessarily represent a biased version of\ntrue demand, thus less effectively predicting the needs of service users. To\ncounter this problem, we propose a general method for censorship-aware demand\nmodeling, for which we devise a censored likelihood function. We apply this\nmethod to the task of shared mobility demand prediction by incorporating the\ncensored likelihood within a Gaussian Process model, which can flexibly\napproximate arbitrary functional forms. Experiments on artificial and\nreal-world datasets show how taking into account the limiting effect of supply\non demand is essential in the process of obtaining an unbiased predictive model\nof user demand behavior.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:26:16 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 12:09:18 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gammelli", "Daniele", ""], ["Peled", "Inon", ""], ["Rodrigues", "Filipe", ""], ["Pacino", "Dario", ""], ["Kurtaran", "Haci A.", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2001.07415", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on", "title": "Explicit agreement extremes for a $2\\times2$ table with given marginals", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of maximizing (or minimizing) the agreement between clusterings,\nsubject to given marginals, can be formally posed under a common framework for\nseveral agreement measures. Until now, it was possible to find its solution\nonly through numerical algorithms. Here, an explicit solution is shown for the\ncase where the two clusterings have two clusters each.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:47:57 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""]]}, {"id": "2001.07417", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia, Foster Provost, Xintian Han", "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine counterfactual explanations for explaining the decisions made by\nmodel-based AI systems. The counterfactual approach we consider defines an\nexplanation as a set of the system's data inputs that causally drives the\ndecision (i.e., changing the inputs in the set changes the decision) and is\nirreducible (i.e., changing any subset of the inputs does not change the\ndecision). We (1) demonstrate how this framework may be used to provide\nexplanations for decisions made by general, data-driven AI systems that may\nincorporate features with arbitrary data types and multiple predictive models,\nand (2) propose a heuristic procedure to find the most useful explanations\ndepending on the context. We then contrast counterfactual explanations with\nmethods that explain model predictions by weighting features according to their\nimportance (e.g., SHAP, LIME) and present two fundamental reasons why we should\ncarefully consider whether importance-weight explanations are well-suited to\nexplain system decisions. Specifically, we show that (i) features that have a\nlarge importance weight for a model prediction may not affect the corresponding\ndecision, and (ii) importance weights are insufficient to communicate whether\nand how features influence decisions. We demonstrate this with several concise\nexamples and three detailed case studies that compare the counterfactual\napproach with SHAP to illustrate various conditions under which counterfactual\nexplanations explain data-driven decisions better than importance weights.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:58:58 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:28:14 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 03:30:11 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 21:52:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Provost", "Foster", ""], ["Han", "Xintian", ""]]}, {"id": "2001.07426", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson, Uri Shalit, Nathan Kallus, David Sontag", "title": "Generalization Bounds and Representation Learning for Estimation of\n  Potential Outcomes and Causal Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners in diverse fields such as healthcare, economics and education\nare eager to apply machine learning to improve decision making. The cost and\nimpracticality of performing experiments and a recent monumental increase in\nelectronic record keeping has brought attention to the problem of evaluating\ndecisions based on non-experimental observational data. This is the setting of\nthis work. In particular, we study estimation of individual-level causal\neffects, such as a single patient's response to alternative medication, from\nrecorded contexts, decisions and outcomes. We give generalization bounds on the\nerror in estimated effects based on distance measures between groups receiving\ndifferent treatments, allowing for sample re-weighting. We provide conditions\nunder which our bound is tight and show how it relates to results for\nunsupervised domain adaptation. Led by our theoretical results, we devise\nrepresentation learning algorithms that minimize our bound, by regularizing the\nrepresentation's induced treatment group distance, and encourage sharing of\ninformation between treatment groups. We extend these algorithms to\nsimultaneously learn a weighted representation to further reduce treatment\ngroup distances. Finally, an experimental evaluation on real and synthetic data\nshows the value of our proposed representation architecture and regularization\nscheme.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 10:16:33 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 09:21:02 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Johansson", "Fredrik D.", ""], ["Shalit", "Uri", ""], ["Kallus", "Nathan", ""], ["Sontag", "David", ""]]}, {"id": "2001.07457", "submitter": "Philipp Holl", "authors": "Philipp Holl, Vladlen Koltun, Nils Thuerey", "title": "Learning to Control PDEs with Differentiable Physics", "comments": "Published as a conference paper at ICLR 2020. Main text: 10 pages, 6\n  figures, 3 tables. Total: 28 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting outcomes and planning interactions with the physical world are\nlong-standing goals for machine learning. A variety of such tasks involves\ncontinuous physical systems, which can be described by partial differential\nequations (PDEs) with many degrees of freedom. Existing methods that aim to\ncontrol the dynamics of such systems are typically limited to relatively short\ntime frames or a small number of interaction parameters. We present a novel\nhierarchical predictor-corrector scheme which enables neural networks to learn\nto understand and control complex nonlinear physical systems over long time\nframes. We propose to split the problem into two distinct tasks: planning and\ncontrol. To this end, we introduce a predictor network that plans optimal\ntrajectories and a control network that infers the corresponding control\nparameters. Both stages are trained end-to-end using a differentiable PDE\nsolver. We demonstrate that our method successfully develops an understanding\nof complex physical systems and learns to control them for tasks involving PDEs\nsuch as the incompressible Navier-Stokes equations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:58:41 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Holl", "Philipp", ""], ["Koltun", "Vladlen", ""], ["Thuerey", "Nils", ""]]}, {"id": "2001.07463", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Rik Sarkar", "title": "Fast Sequence-Based Embedding with Diffusion Graphs", "comments": "Source code available at:\n  https://github.com/benedekrozemberczki/diff2vec", "journal-ref": "CompleNet 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A graph embedding is a representation of graph vertices in a low-dimensional\nspace, which approximately preserves properties such as distances between\nnodes. Vertex sequence-based embedding procedures use features extracted from\nlinear sequences of nodes to create embeddings using a neural network. In this\npaper, we propose diffusion graphs as a method to rapidly generate vertex\nsequences for network embedding. Its computational efficiency is superior to\nprevious methods due to simpler sequence generation, and it produces more\naccurate results. In experiments, we found that the performance relative to\nother methods improves with increasing edge density in the graph. In a\ncommunity detection task, clustering nodes in the embedding space produces\nbetter results compared to other sequence-based embedding methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 12:04:21 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2001.07523", "submitter": "Nick Dexter", "authors": "Ben Adcock and Nick Dexter", "title": "The gap between theory and practice in function approximation with deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is transforming industry as decision-making processes are\nbeing automated by deep neural networks (DNNs) trained on real-world data.\nDriven partly by rapidly-expanding literature on DNN approximation theory\nshowing they can approximate a rich variety of functions, such tools are\nincreasingly being considered for problems in scientific computing. Yet, unlike\ntraditional algorithms in this field, little is known about DNNs from the\nprinciples of numerical analysis, e.g., stability, accuracy, computational\nefficiency and sample complexity. In this paper we introduce a computational\nframework for examining DNNs in practice, and use it to study empirical\nperformance with regard to these issues. We study performance of DNNs of\ndifferent widths & depths on test functions in various dimensions, including\nsmooth and piecewise smooth functions. We also compare DL against best-in-class\nmethods for smooth function approx. based on compressed sensing (CS). Our main\nconclusion from these experiments is that there is a crucial gap between the\napproximation theory of DNNs and their practical performance, with trained DNNs\nperforming relatively poorly on functions for which there are strong\napproximation results (e.g. smooth functions), yet performing well in\ncomparison to best-in-class methods for other functions. To analyze this gap\nfurther, we provide some theoretical insights. We establish a practical\nexistence theorem, asserting existence of a DNN architecture and training\nprocedure that offers the same performance as CS. This establishes a key\ntheoretical benchmark, showing the gap can be closed, albeit via a strategy\nguaranteed to perform as well as, but no better than, current best-in-class\nschemes. Nevertheless, it demonstrates the promise of practical DNN approx., by\nhighlighting potential for better schemes through careful design of DNN\narchitectures and training strategies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:08:56 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 00:23:46 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 23:42:03 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Adcock", "Ben", ""], ["Dexter", "Nick", ""]]}, {"id": "2001.07524", "submitter": "Pushkar Mishra", "authors": "Pushkar Mishra, Aleksandra Piktus, Gerard Goossen, Fabrizio Silvestri", "title": "Node Masking: Making Graph Neural Networks Generalize and Scale Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have received a lot of interest in the recent\ntimes. From the early spectral architectures that could only operate on\nundirected graphs per a transductive learning paradigm to the current state of\nthe art spatial ones that can apply inductively to arbitrary graphs, GNNs have\nseen significant contributions from the research community. In this paper, we\nutilize some theoretical tools to better visualize the operations performed by\nstate of the art spatial GNNs. We analyze the inner workings of these\narchitectures and introduce a simple concept, Node Masking, that allows them to\ngeneralize and scale better. To empirically validate the concept, we perform\nseveral experiments on some widely-used datasets for node classification in\nboth the transductive and inductive settings, hence laying down strong\nbenchmarks for future research.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 06:26:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 10:14:08 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 12:40:50 GMT"}, {"version": "v4", "created": "Sun, 16 May 2021 19:40:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mishra", "Pushkar", ""], ["Piktus", "Aleksandra", ""], ["Goossen", "Gerard", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "2001.07527", "submitter": "Eugenio Bargiacchi", "authors": "Eugenio Bargiacchi, Timothy Verstraeten, Diederik M. Roijers, Ann\n  Now\\'e", "title": "Model-based Multi-Agent Reinforcement Learning with Cooperative\n  Prioritized Sweeping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based reinforcement learning algorithm, Cooperative\nPrioritized Sweeping, for efficient learning in multi-agent Markov decision\nprocesses. The algorithm allows for sample-efficient learning on large problems\nby exploiting a factorization to approximate the value function. Our approach\nonly requires knowledge about the structure of the problem in the form of a\ndynamic decision network. Using this information, our method learns a model of\nthe environment and performs temporal difference updates which affect multiple\njoint states and actions at once. Batch updates are additionally performed\nwhich efficiently back-propagate knowledge throughout the factored Q-function.\nOur method outperforms the state-of-the-art algorithm sparse cooperative\nQ-learning algorithm, both on the well-known SysAdmin benchmark and randomized\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:13:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bargiacchi", "Eugenio", ""], ["Verstraeten", "Timothy", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.07553", "submitter": "Nuno M. Rodrigues", "authors": "Nuno M. Rodrigues, Jo\\~ao E. Batista, Sara Silva", "title": "Ensemble Genetic Programming", "comments": "eurogp 2020 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a powerful paradigm that has been usedin the top\nstate-of-the-art machine learning methods like Random Forestsand XGBoost.\nInspired by the success of such methods, we have devel-oped a new Genetic\nProgramming method called Ensemble GP. The evo-lutionary cycle of Ensemble GP\nfollows the same steps as other GeneticProgramming systems, but with\ndifferences in the population structure,fitness evaluation and genetic\noperators. We have tested this method oneight binary classification problems,\nachieving results significantly betterthan standard GP, with much smaller\nmodels. Although other methodslike M3GP and XGBoost were the best overall,\nEnsemble GP was able toachieve exceptionally good generalization results on a\nparticularly hardproblem where none of the other methods was able to succeed.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:10:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rodrigues", "Nuno M.", ""], ["Batista", "Jo\u00e3o E.", ""], ["Silva", "Sara", ""]]}, {"id": "2001.07558", "submitter": "Tiphaine Viard", "authors": "Tiphaine Viard, Thomas McLachlan, Hamidreza Ghader, Satoshi Sekine", "title": "Classifying Wikipedia in a fine-grained hierarchy: what graphs can\n  contribute", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia is a huge opportunity for machine learning, being the largest\nsemi-structured base of knowledge available. Because of this, many works\nexamine its contents, and focus on structuring it in order to make it usable in\nlearning tasks, for example by classifying it into an ontology. Beyond its\ntextual contents, Wikipedia also displays a typical graph structure, where\npages are linked together through citations. In this paper, we address the task\nof integrating graph (i.e. structure) information to classify Wikipedia into a\nfine-grained named entity ontology (NE), the Extended Named Entity hierarchy.\nTo address this task, we first start by assessing the relevance of the graph\nstructure for NE classification. We then explore two directions, one related to\nfeature vectors using graph descriptors commonly used in large-scale network\nanalysis, and one extending flat classification to a weighted model taking into\naccount semantic similarity. We conduct at-scale practical experiments, on a\nmanually labeled subset of 22,000 pages extracted from the Japanese Wikipedia.\nOur results show that integrating graph information succeeds at reducing\nsparsity of the input feature space, and yields classification results that are\ncomparable or better than previous works.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:19:49 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 08:24:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Viard", "Tiphaine", ""], ["McLachlan", "Thomas", ""], ["Ghader", "Hamidreza", ""], ["Sekine", "Satoshi", ""]]}, {"id": "2001.07569", "submitter": "Luca Benedetto", "authors": "Luca Benedetto, Andrea Cappelli, Roberto Turrin, Paolo Cremonesi", "title": "R2DE: a NLP approach to estimating IRT parameters of newly generated\n  questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of exams consists in performing an assessment of students'\nexpertise on a specific subject. Such expertise, also referred to as skill or\nknowledge level, can then be leveraged in different ways (e.g., to assign a\ngrade to the students, to understand whether a student might need some support,\netc.). Similarly, the questions appearing in the exams have to be assessed in\nsome way before being used to evaluate students. Standard approaches to\nquestions' assessment are either subjective (e.g., assessment by human experts)\nor introduce a long delay in the process of question generation (e.g.,\npretesting with real students). In this work we introduce R2DE (which is a\nRegressor for Difficulty and Discrimination Estimation), a model capable of\nassessing newly generated multiple-choice questions by looking at the text of\nthe question and the text of the possible choices. In particular, it can\nestimate the difficulty and the discrimination of each question, as they are\ndefined in Item Response Theory. We also present the results of extensive\nexperiments we carried out on a real world large scale dataset coming from an\ne-learning platform, showing that our model can be used to perform an initial\nassessment of newly created questions and ease some of the problems that arise\nin question generation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:31:01 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Benedetto", "Luca", ""], ["Cappelli", "Andrea", ""], ["Turrin", "Roberto", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2001.07582", "submitter": "Yadong Zhang", "authors": "Yadong Zhang and Xin Chen", "title": "Motif Difference Field: A Simple and Effective Image Representation of\n  Time Series for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series motifs play an important role in the time series analysis. The\nmotif-based time series clustering is used for the discovery of higher-order\npatterns or structures in time series data. Inspired by the convolutional\nneural network (CNN) classifier based on the image representations of time\nseries, motif difference field (MDF) is proposed. Compared to other image\nrepresentations of time series, MDF is simple and easy to construct. With the\nFully Convolution Network (FCN) as the classifier, MDF demonstrates the\nsuperior performance on the UCR time series dataset in benchmark with other\ntime series classification methods. It is interesting to find that the triadic\ntime series motifs give the best result in the test. Due to the motif\nclustering reflected in MDF, the significant motifs are detected with the help\nof the Gradient-weighted Class Activation Mapping (Grad-CAM). The areas in MDF\nwith high weight in Grad-CAM have a high contribution from the significant\nmotifs with the desired ordinal patterns associated with the signature patterns\nin time series. However, the signature patterns cannot be identified with the\nneural network classifiers directly based on the time series.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:48:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhang", "Yadong", ""], ["Chen", "Xin", ""]]}, {"id": "2001.07607", "submitter": "Timothy LaRock", "authors": "Timothy LaRock, Timothy Sakharov, Sahely Bhadra, Tina Eliassi-Rad", "title": "Understanding the Limitations of Network Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies of networked phenomena, such as interactions in online social media,\noften rely on incomplete data, either because these phenomena are partially\nobserved, or because the data is too large or expensive to acquire all at once.\nAnalysis of incomplete data leads to skewed or misleading results. In this\npaper, we investigate limitations of learning to complete partially observed\nnetworks via node querying. Concretely, we study the following problem: given\n(i) a partially observed network, (ii) the ability to query nodes for their\nconnections (e.g., by accessing an API), and (iii) a budget on the number of\nsuch queries, sequentially learn which nodes to query in order to maximally\nincrease observability. We call this querying process Network Online Learning\nand present a family of algorithms called NOL*. These algorithms learn to\nchoose which partially observed node to query next based on a parameterized\nmodel that is trained online through a process of exploration and exploitation.\nExtensive experiments on both synthetic and real world networks show that (i)\nit is possible to sequentially learn to choose which nodes are best to query in\na network and (ii) some macroscopic properties of networks, such as the degree\ndistribution and modular structure, impact the potential for learning and the\noptimal amount of random exploration.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:59:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["LaRock", "Timothy", ""], ["Sakharov", "Timothy", ""], ["Bhadra", "Sahely", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "2001.07608", "submitter": "Mark Chilenski", "authors": "Mark Chilenski, George Cybenko, Isaac Dekine, Piyush Kumar, Gil Raz", "title": "Analytic Properties of Trackable Weak Models", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several new results on the feasibility of inferring the hidden\nstates in strongly-connected trackable weak models. Here, a weak model is a\ndirected graph in which each node is assigned a set of colors which may be\nemitted when that node is visited. A hypothesis is a node sequence which is\nconsistent with a given color sequence. A weak model is said to be trackable if\nthe worst case number of such hypotheses grows as a polynomial in the sequence\nlength. We show that the number of hypotheses in strongly-connected trackable\nmodels is bounded by a constant and give an expression for this constant. We\nalso consider the problem of reconstructing which branch was taken at a node\nwith same-colored out-neighbors, and show that it is always eventually possible\nto identify which branch was taken if the model is strongly connected and\ntrackable. We illustrate these properties by assigning transition probabilities\nand employing standard tools for analyzing Markov chains. In addition, we\npresent new results for the entropy rates of weak models according to whether\nthey are trackable or not. These theorems indicate that the combination of\ntrackability and strong connectivity dramatically simplifies the task of\nreconstructing which nodes were visited. This work has implications for any\nproblem which can be described in terms of an agent traversing a colored graph,\nsuch as the reconstruction of hidden states in a hidden Markov model (HMM).\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:54:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chilenski", "Mark", ""], ["Cybenko", "George", ""], ["Dekine", "Isaac", ""], ["Kumar", "Piyush", ""], ["Raz", "Gil", ""]]}, {"id": "2001.07613", "submitter": "Kyoung-Woon On", "authors": "Kyoung-Woon On, Eun-Sol Kim, Yu-Jung Heo and Byoung-Tak Zhang", "title": "Cut-Based Graph Learning Networks to Discover Compositional Structure of\n  Sequential Video Data", "comments": "8 pages, 3 figures, Association for the Advancement of Artificial\n  Intelligence (AAAI2020). arXiv admin note: substantial text overlap with\n  arXiv:1907.01709", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional sequential learning methods such as Recurrent Neural Networks\n(RNNs) focus on interactions between consecutive inputs, i.e. first-order\nMarkovian dependency. However, most of sequential data, as seen with videos,\nhave complex dependency structures that imply variable-length semantic flows\nand their compositions, and those are hard to be captured by conventional\nmethods. Here, we propose Cut-Based Graph Learning Networks (CB-GLNs) for\nlearning video data by discovering these complex structures of the video. The\nCB-GLNs represent video data as a graph, with nodes and edges corresponding to\nframes of the video and their dependencies respectively. The CB-GLNs find\ncompositional dependencies of the data in multilevel graph forms via a\nparameterized kernel with graph-cut and a message passing framework. We\nevaluate the proposed method on the two different tasks for video\nunderstanding: Video theme classification (Youtube-8M dataset) and Video\nQuestion and Answering (TVQA dataset). The experimental results show that our\nmodel efficiently learns the semantic compositional structure of video data.\nFurthermore, our model achieves the highest performance in comparison to other\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:09:24 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["On", "Kyoung-Woon", ""], ["Kim", "Eun-Sol", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2001.07614", "submitter": "Guillaume Salha", "authors": "Guillaume Salha, Romain Hennequin, Michalis Vazirgiannis", "title": "Simple and Effective Graph Autoencoders with One-Hop Linear Models", "comments": "Accepted at ECML-PKDD 2020. A preliminary version of this work has\n  previously been presented at the NeurIPS 2019 workshop on Graph\n  Representation Learning: arXiv:1910.00942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, graph autoencoders (AE) and variational autoencoders\n(VAE) emerged as powerful node embedding methods, with promising performances\non challenging tasks such as link prediction and node clustering. Graph AE, VAE\nand most of their extensions rely on multi-layer graph convolutional networks\n(GCN) encoders to learn vector space representations of nodes. In this paper,\nwe show that GCN encoders are actually unnecessarily complex for many\napplications. We propose to replace them by significantly simpler and more\ninterpretable linear models w.r.t. the direct neighborhood (one-hop) adjacency\nmatrix of the graph, involving fewer operations, fewer parameters and no\nactivation function. For the two aforementioned tasks, we show that this\nsimpler approach consistently reaches competitive performances w.r.t. GCN-based\ngraph AE and VAE for numerous real-world graphs, including all benchmark\ndatasets commonly used to evaluate graph AE and VAE. Based on these results, we\nalso question the relevance of repeatedly using these datasets to compare\ncomplex graph AE and VAE.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:33:12 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 15:09:36 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 09:54:33 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2001.07615", "submitter": "Stefan Ultes", "authors": "Stefan Ultes", "title": "Improving Interaction Quality Estimation with BiLSTMs and the Impact on\n  Dialogue Policy Learning", "comments": "Published at SIGDIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning suitable and well-performing dialogue behaviour in statistical\nspoken dialogue systems has been in the focus of research for many years. While\nmost work which is based on reinforcement learning employs an objective measure\nlike task success for modelling the reward signal, we use a reward based on\nuser satisfaction estimation. We propose a novel estimator and show that it\noutperforms all previous estimators while learning temporal dependencies\nimplicitly. Furthermore, we apply this novel user satisfaction estimation model\nlive in simulated experiments where the satisfaction estimation model is\ntrained on one domain and applied in many other domains which cover a similar\ntask. We show that applying this model results in higher estimated\nsatisfaction, similar task success rates and a higher robustness to noise.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:39:12 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ultes", "Stefan", ""]]}, {"id": "2001.07617", "submitter": "Haolin Zou", "authors": "Victor de la Pena, Haolin Zou", "title": "TopRank+: A Refinement of TopRank Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning to rank is a core problem in machine learning. In Lattimore\net al. (2018), a novel online learning algorithm was proposed based on\ntopological sorting. In the paper they provided a set of self-normalized\ninequalities (a) in the algorithm as a criterion in iterations and (b) to\nprovide an upper bound for cumulative regret, which is a measure of algorithm\nperformance. In this work, we utilized method of mixtures and asymptotic\nexpansions of certain implicit function to provide a tighter, iterated-log-like\nboundary for the inequalities, and as a consequence improve both the algorithm\nitself as well as its performance estimation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:44:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["de la Pena", "Victor", ""], ["Zou", "Haolin", ""]]}, {"id": "2001.07620", "submitter": "Fernando Gama", "authors": "Elvin Isufi, Fernando Gama, Alejandro Ribeiro", "title": "EdgeNets:Edge Varying Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the outstanding performance of neural networks in the structured\nEuclidean domain, recent years have seen a surge of interest in developing\nneural networks for graphs and data supported on graphs. The graph is leveraged\nat each layer of the neural network as a parameterization to capture detail at\nthe node level with a reduced number of parameters and computational\ncomplexity. Following this rationale, this paper puts forth a general framework\nthat unifies state-of-the-art graph neural networks (GNNs) through the concept\nof EdgeNet. An EdgeNet is a GNN architecture that allows different nodes to use\ndifferent parameters to weigh the information of different neighbors. By\nextrapolating this strategy to more iterations between neighboring nodes, the\nEdgeNet learns edge- and neighbor-dependent weights to capture local detail.\nThis is a general linear and local operation that a node can perform and\nencompasses under one formulation all existing graph convolutional neural\nnetworks (GCNNs) as well as graph attention networks (GATs). In writing\ndifferent GNN architectures with a common language, EdgeNets highlight specific\narchitecture advantages and limitations, while providing guidelines to improve\ntheir capacity without compromising their local implementation. An interesting\nconclusion is the unification of GCNNs and GATs -- approaches that have been so\nfar perceived as separate. In particular, we show that GATs are GCNNs on a\ngraph that is learned from the features. This particularization opens the doors\nto develop alternative attention mechanisms for improving discriminatory power.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:51:17 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 13:28:10 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 14:02:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Isufi", "Elvin", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2001.07627", "submitter": "Maciej A. Czyzewski", "authors": "Maciej A. Czyzewski", "title": "batchboost: regularization for stabilizing training with resistance to\n  underfitting & overfitting", "comments": "6 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting & underfitting and stable training are an important challenges in\nmachine learning. Current approaches for these issues are mixup, SamplePairing\nand BC learning. In our work, we state the hypothesis that mixing many images\ntogether can be more effective than just two. Batchboost pipeline has three\nstages: (a) pairing: method of selecting two samples. (b) mixing: how to create\na new one from two samples. (c) feeding: combining mixed samples with new ones\nfrom dataset into batch (with ratio $\\gamma$). Note that sample that appears in\nour batch propagates with subsequent iterations with less and less importance\nuntil the end of training. Pairing stage calculates the error per sample, sorts\nthe samples and pairs with strategy: hardest with easiest one, than mixing\nstage merges two samples using mixup, $x_1 + (1-\\lambda)x_2$. Finally, feeding\nstage combines new samples with mixed by ratio 1:1. Batchboost has 0.5-3%\nbetter accuracy than the current state-of-the-art mixup regularization on\nCIFAR-10 & Fashion-MNIST. Our method is slightly better than SamplePairing\ntechnique on small datasets (up to 5%). Batchboost provides stable training on\nnot tuned parameters (like weight decay), thus its a good method to test\nperformance of different architectures. Source code is at:\nhttps://github.com/maciejczyzewski/batchboost\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:07:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Czyzewski", "Maciej A.", ""]]}, {"id": "2001.07631", "submitter": "Sizhe Chen", "authors": "Zhixing Ye, Sizhe Chen, Peidong Zhang, Chengjin Sun, Xiaolin Huang", "title": "HRFA: High-Resolution Feature-based Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have long been developed for revealing the vulnerability\nof Deep Neural Networks (DNNs) by adding imperceptible perturbations to the\ninput. Most methods generate perturbations like normal noise, which is not\ninterpretable and without semantic meaning. In this paper, we propose\nHigh-Resolution Feature-based Attack (HRFA), yielding authentic adversarial\nexamples with up to $1024 \\times 1024$ resolution. HRFA exerts attack by\nmodifying the latent feature representation of the image, i.e., the gradients\nback propagate not only through the victim DNN, but also through the generative\nmodel that maps the feature space to the image space. In this way, HRFA\ngenerates adversarial examples that are in high-resolution, realistic,\nnoise-free, and hence is able to evade several denoising-based defenses. In the\nexperiment, the effectiveness of HRFA is validated by attacking the object\nclassification and face verification tasks with BigGAN and StyleGAN,\nrespectively. The advantages of HRFA are verified from the high quality, high\nauthenticity, and high attack success rate faced with defenses.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:21:20 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:08:04 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ye", "Zhixing", ""], ["Chen", "Sizhe", ""], ["Zhang", "Peidong", ""], ["Sun", "Chengjin", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2001.07636", "submitter": "Lei Shi", "authors": "Lei Shi", "title": "Mobility Inference on Long-Tailed Sparse Trajectory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the urban trajectory in cities has become an important topic in\ndata mining. How can we model the human mobility consisting of stay and travel\nfrom the raw trajectory data? How can we infer such a mobility model from the\nsingle trajectory information? How can we further generalize the mobility\ninference to accommodate the real-world trajectory data that is sparsely\nsampled over time?\n  In this paper, based on formal and rigid definitions of the stay/travel\nmobility, we propose a single trajectory inference algorithm that utilizes a\ngeneric long-tailed sparsity pattern in the large-scale trajectory data. The\nalgorithm guarantees a 100\\% precision in the stay/travel inference with a\nprovable lower-bound in the recall. Furthermore, we introduce an\nencoder-decoder learning architecture that admits multiple trajectories as\ninputs. The architecture is optimized for the mobility inference problem\nthrough customized embedding and learning mechanism. Evaluations with three\ntrajectory data sets of 40 million urban users validate the performance\nguarantees of the proposed inference algorithm and demonstrate the superiority\nof our deep learning model, in comparison to well-known sequence learning\nmethods. On extremely sparse trajectories, the deep learning model achieves a\n2$\\times$ overall accuracy improvement from the single trajectory inference\nalgorithm, through proven scalability and generalizability to large-scale\nversatile training data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:32:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Shi", "Lei", ""]]}, {"id": "2001.07641", "submitter": "Johannes Schneider", "authors": "Johannes Schneider, Joshua Handali, Michalis Vlachos and Christian\n  Meske", "title": "Deceptive AI Explanations: Creation and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) comes with great opportunities but also great\nrisks. Automatically generated explanations for decisions are deemed helpful to\nbetter understand AI, increasing transparency and fostering trust. However,\ngiven e.g. economic incentives to create dishonest AI, can we trust its\nexplanations? To address this issue, our paper investigates to what extent\nmodels of AI, i.e. deep learning, and existing instruments to increase\ntransparency regarding AI decisions can be used to create and detect deceptive\nexplanations. For empirical evaluation, we focus on text classification and\nalter explanations originating from GradCAM, a well-established technique for\ncreating explanations in neural networks. We then evaluate the effect of\ndeceptive explanations on users in an experiment with 200 participants. Our\nfindings confirm that deceptive explanations can indeed fool humans while\nmachine learning methods can detect seemingly minor attempts of deception with\naccuracy that exceeds 80\\% given sufficient domain knowledge in the form of\ntraining data. Without domain knowledge, one can still infer inconsistencies in\nthe explanations in an unsupervised manner given basic knowledge on the\nallegedly deceptive model.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:41:22 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 21:02:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schneider", "Johannes", ""], ["Handali", "Joshua", ""], ["Vlachos", "Michalis", ""], ["Meske", "Christian", ""]]}, {"id": "2001.07685", "submitter": "Kihyuk Sohn", "authors": "Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas\n  Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel", "title": "FixMatch: Simplifying Semi-Supervised Learning with Consistency and\n  Confidence", "comments": "Published at NeurIPS 2020 as a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) provides an effective means of leveraging\nunlabeled data to improve a model's performance. In this paper, we demonstrate\nthe power of a simple combination of two common SSL methods: consistency\nregularization and pseudo-labeling. Our algorithm, FixMatch, first generates\npseudo-labels using the model's predictions on weakly-augmented unlabeled\nimages. For a given image, the pseudo-label is only retained if the model\nproduces a high-confidence prediction. The model is then trained to predict the\npseudo-label when fed a strongly-augmented version of the same image. Despite\nits simplicity, we show that FixMatch achieves state-of-the-art performance\nacross a variety of standard semi-supervised learning benchmarks, including\n94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just\n4 labels per class. Since FixMatch bears many similarities to existing SSL\nmethods that achieve worse performance, we carry out an extensive ablation\nstudy to tease apart the experimental factors that are most important to\nFixMatch's success. We make our code available at\nhttps://github.com/google-research/fixmatch.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:32:27 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 17:22:06 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Sohn", "Kihyuk", ""], ["Berthelot", "David", ""], ["Li", "Chun-Liang", ""], ["Zhang", "Zizhao", ""], ["Carlini", "Nicholas", ""], ["Cubuk", "Ekin D.", ""], ["Kurakin", "Alex", ""], ["Zhang", "Han", ""], ["Raffel", "Colin", ""]]}, {"id": "2001.07697", "submitter": "Darina Dvinskikh", "authors": "Darina Dvinskikh", "title": "Stochastic Approximation versus Sample Average Approximation for\n  population Wasserstein barycenters", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning and optimization community there are two main approaches\nfor convex risk minimization problem, namely, the Stochastic Approximation (SA)\nand the Sample Average Approximation (SAA). In terms of oracle complexity\n(required number of stochastic gradient evaluations), both approaches are\nconsidered equivalent on average (up to a logarithmic factor). The total\ncomplexity depends on the specific problem, however, starting from work\n\\cite{nemirovski2009robust} it was generally accepted that the SA is better\nthan the SAA. Nevertheless, in case of large-scale problems SA may run out of\nmemory as storing all data on one machine and organizing online access to it\ncan be impossible without communications with other machines. SAA in\ncontradistinction to SA allows parallel/distributed calculations. In this\npaper, we shed new light on the comparison of SA and SAA for particular problem\nof calculating the population (regularized) Wasserstein barycenter of discrete\nmeasures. The conclusion is valid even for non-parallel (non-decentralized)\nsetup.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:54:39 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 14:56:01 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 21:29:32 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 10:02:53 GMT"}, {"version": "v5", "created": "Wed, 16 Sep 2020 13:33:01 GMT"}, {"version": "v6", "created": "Wed, 21 Oct 2020 13:02:59 GMT"}, {"version": "v7", "created": "Thu, 26 Nov 2020 16:09:07 GMT"}, {"version": "v8", "created": "Tue, 1 Dec 2020 14:34:25 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dvinskikh", "Darina", ""]]}, {"id": "2001.07712", "submitter": "Tian Xu", "authors": "X. Chen (1), S. Chen (1), T. Xu (1), B. Yin (1), X. Mei (2), J. Peng\n  (2), H. Li (2) ((1) School of Computer Science, Wuhan University, Wuhan,\n  China, (2) School of Geosciences and Info-Physics, Central South University,\n  Changsha, China)", "title": "SMAPGAN: Generative Adversarial Network Based Semi-Supervised Styled Map\n  Tiles Generating Method", "comments": "in IEEE Transactions on Geoscience and Remote Sensing", "journal-ref": null, "doi": "10.1109/TGRS.2020.3021819", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional online map tiles, widely used on the Internet such as Google Map\nand Baidu Map, are rendered from vector data. Timely updating online map tiles\nfrom vector data, of which the generating is time-consuming, is a difficult\nmission. It is a shortcut to generate map tiles in time from remote sensing\nimages, which can be acquired timely without vector data. However, this mission\nused to be challenging or even impossible. Inspired by image-to-image\ntranslation (img2img) techniques based on generative adversarial networks\n(GAN), we proposed a semi-supervised Generation of styled map Tiles based on\nGenerative Adversarial Network (SMAPGAN) model to generate styled map tiles\ndirectly from remote sensing images. In this model, we designed a\nsemi-supervised learning strategy to pre-train SMAPGAN on rich unpaired samples\nand fine-tune it on limited paired samples in reality. We also designed image\ngradient L1 loss and image gradient structure loss to generate a styled map\ntile with global topological relationships and detailed edge curves of objects,\nwhich are important in cartography. Moreover, we proposed edge structural\nsimilarity index (ESSI) as a metric to evaluate the quality of topological\nconsistency between generated map tiles and ground truths. Experimental results\npresent that SMAPGAN outperforms state-of-the-art (SOTA) works according to\nmean squared error, structural similarity index, and ESSI. Also, SMAPGAN won\nmore approval than SOTA in the human perceptual test on the visual realism of\ncartography. Our work shows that SMAPGAN is potentially a new paradigm to\nproduce styled map tiles. Our implementation of the SMAPGAN is available at\nhttps://github.com/imcsq/SMAPGAN.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 04:13:21 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 11:47:26 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Chen", "X.", ""], ["Chen", "S.", ""], ["Xu", "T.", ""], ["Yin", "B.", ""], ["Mei", "X.", ""], ["Peng", "J.", ""], ["Li", "H.", ""]]}, {"id": "2001.07744", "submitter": "Lihi Dery", "authors": "Lihi Dery and Erez Shmueli", "title": "Improving Label Ranking Ensembles using Boosting Techniques", "comments": null, "journal-ref": "IEEE Access 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label ranking is a prediction task which deals with learning a mapping\nbetween an instance and a ranking (i.e., order) of labels from a finite set,\nrepresenting their relevance to the instance. Boosting is a well-known and\nreliable ensemble technique that was shown to often outperform other learning\nalgorithms. While boosting algorithms were developed for a multitude of machine\nlearning tasks, label ranking tasks were overlooked. In this paper, we propose\na boosting algorithm which was specifically designed for label ranking tasks.\nExtensive evaluation of the proposed algorithm on 24 semi-synthetic and\nreal-world label ranking datasets shows that it significantly outperforms\nexisting state-of-the-art label ranking algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:16:11 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dery", "Lihi", ""], ["Shmueli", "Erez", ""]]}, {"id": "2001.07769", "submitter": "Haekyu Park", "authors": "Nilaksh Das, Haekyu Park, Zijie J. Wang, Fred Hohman, Robert Firstman,\n  Emily Rogers, Duen Horng Chau", "title": "Massif: Interactive Interpretation of Adversarial Attacks on Deep\n  Learning", "comments": "Appear in ACM Conference on Human Factors in Computing Systems (CHI)\n  Late-Breaking Works 2020, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are increasingly powering high-stakes\napplications such as autonomous cars and healthcare; however, DNNs are often\ntreated as \"black boxes\" in such applications. Recent research has also\nrevealed that DNNs are highly vulnerable to adversarial attacks, raising\nserious concerns over deploying DNNs in the real world. To overcome these\ndeficiencies, we are developing Massif, an interactive tool for deciphering\nadversarial attacks. Massif identifies and interactively visualizes neurons and\ntheir connections inside a DNN that are strongly activated or suppressed by an\nadversarial attack. Massif provides both a high-level, interpretable overview\nof the effect of an attack on a DNN, and a low-level, detailed description of\nthe affected neurons. These tightly coupled views in Massif help people better\nunderstand which input features are most vulnerable or important for correct\npredictions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 20:41:27 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 17:26:08 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 22:19:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Das", "Nilaksh", ""], ["Park", "Haekyu", ""], ["Wang", "Zijie J.", ""], ["Hohman", "Fred", ""], ["Firstman", "Robert", ""], ["Rogers", "Emily", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.07778", "submitter": "Hugo Maruri-Aguilar", "authors": "Hugo Maruri-Aguilar and Simon Lunagomez", "title": "Lasso for hierarchical polynomial models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a polynomial regression model, the divisibility conditions implicit in\npolynomial hierarchy give way to a natural construction of constraints for the\nmodel parameters. We use this principle to derive versions of strong and weak\nhierarchy and to extend existing work in the literature, which at the moment is\nonly concerned with models of degree two. We discuss how to estimate parameters\nin lasso using standard quadratic programming techniques and apply our proposal\nto both simulated data and examples from the literature. The proposed\nmethodology compares favorably with existing techniques in terms of low\nvalidation error and model size.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 21:26:24 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Maruri-Aguilar", "Hugo", ""], ["Lunagomez", "Simon", ""]]}, {"id": "2001.07787", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias, Manar Jammal, Hassan Hawilo, Abdallah Shami,\n  Parisa Heidari, Adel Larabi, Richard Brunner", "title": "Machine Learning for Performance-Aware Virtual Network Function\n  Placement", "comments": "6 pages, 6 figures, 1 table, 9 equations, 18 references, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing demand for data connectivity, network service providers are\nfaced with the task of reducing their capital and operational expenses while\nsimultaneously improving network performance and addressing the increased\nconnectivity demand. Although Network Function Virtualization (NFV) has been\nidentified as a solution, several challenges must be addressed to ensure its\nfeasibility. In this paper, we address the Virtual Network Function (VNF)\nplacement problem by developing a machine learning decision tree model that\nlearns from the effective placement of the various VNF instances forming a\nService Function Chain (SFC). The model takes several performance-related\nfeatures from the network as an input and selects the placement of the various\nVNF instances on network servers with the objective of minimizing the delay\nbetween dependent VNF instances. The benefits of using machine learning are\nrealized by moving away from a complex mathematical modelling of the system and\ntowards a data-based understanding of the system. Using the Evolved Packet Core\n(EPC) as a use case, we evaluate our model on different data center networks\nand compare it to the BACON algorithm in terms of the delay between\ninterconnected components and the total delay across the SFC. Furthermore, a\ntime complexity analysis is performed to show the effectiveness of the model in\nNFV applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:08:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Jammal", "Manar", ""], ["Hawilo", "Hassan", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""]]}, {"id": "2001.07798", "submitter": "Rohit Jena", "authors": "Rohit Jena, Changliu Liu, Katia Sycara", "title": "Augmenting GAIL with BC for sample efficient imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is the problem of recovering an expert policy without\naccess to a reward signal. Behavior cloning and GAIL are two widely used\nmethods for performing imitation learning. Behavior cloning converges in a few\niterations but doesn't achieve peak performance due to its inherent iid\nassumption about the state-action distribution. GAIL addresses the issue by\naccounting for the temporal dependencies when performing a state distribution\nmatching between the agent and the expert. Although GAIL is sample efficient in\nthe number of expert trajectories required, it is still not very sample\nefficient in terms of the environment interactions needed for convergence of\nthe policy. Given the complementary benefits of both methods, we present a\nsimple and elegant method to combine both methods to enable stable and sample\nefficient learning. Our algorithm is very simple to implement and integrates\nwith different policy gradient algorithms. We demonstrate the effectiveness of\nthe algorithm in low dimensional control tasks, gridworlds and in high\ndimensional image-based tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 22:28:50 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 19:45:53 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 02:18:24 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 20:04:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Jena", "Rohit", ""], ["Liu", "Changliu", ""], ["Sycara", "Katia", ""]]}, {"id": "2001.07805", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao, Jacob Steinhardt", "title": "When does the Tukey median work?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of the Tukey median estimator under total\nvariation (TV) distance corruptions. Previous results show that under Huber's\nadditive corruption model, the breakdown point is 1/3 for high-dimensional\nhalfspace-symmetric distributions. We show that under TV corruptions, the\nbreakdown point reduces to 1/4 for the same set of distributions. We also show\nthat a certain projection algorithm can attain the optimal breakdown point of\n1/2. Both the Tukey median estimator and the projection algorithm achieve\nsample complexity linear in dimension.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:04:39 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 19:46:43 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2001.07819", "submitter": "Krishnakumar Balasubramanian", "authors": "Zhongruo Wang, Krishnakumar Balasubramanian, Shiqian Ma, Meisam\n  Razaviyayn", "title": "Zeroth-Order Algorithms for Nonconvex Minimax Problems with Improved\n  Complexities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study zeroth-order algorithms for minimax optimization\nproblems that are nonconvex in one variable and strongly-concave in the other\nvariable. Such minimax optimization problems have attracted significant\nattention lately due to their applications in modern machine learning tasks. We\nfirst design and analyze the Zeroth-Order Gradient Descent Ascent\n(\\texttt{ZO-GDA}) algorithm, and provide improved results compared to existing\nworks, in terms of oracle complexity. Next, we propose the Zeroth-Order\nGradient Descent Multi-Step Ascent (\\texttt{ZO-GDMSA}) algorithm that\nsignificantly improves the oracle complexity of \\texttt{ZO-GDA}. We also\nprovide stochastic version of \\texttt{ZO-GDA} and \\texttt{ZO-GDMSA} to handle\nstochastic nonconvex minimax problems, and provide oracle complexity results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:05:14 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Wang", "Zhongruo", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ma", "Shiqian", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2001.07827", "submitter": "Derek DeSantis", "authors": "Derek DeSantis, Phillip J. Wolfram, Katrina Bennett, Boian Alexandrov", "title": "Coarse-Grain Cluster Analysis of Tensors with Application to Climate\n  Biome Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-20-20548", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tensor provides a concise way to codify the interdependence of complex\ndata. Treating a tensor as a d-way array, each entry records the interaction\nbetween the different indices. Clustering provides a way to parse the\ncomplexity of the data into more readily understandable information. Clustering\nmethods are heavily dependent on the algorithm of choice, as well as the chosen\nhyperparameters of the algorithm. However, their sensitivity to data scales is\nlargely unknown.\n  In this work, we apply the discrete wavelet transform to analyze the effects\nof coarse-graining on clustering tensor data. We are particularly interested in\nunderstanding how scale effects clustering of the Earth's climate system. The\ndiscrete wavelet transform allows classification of the Earth's climate across\na multitude of spatial-temporal scales. The discrete wavelet transform is used\nto produce an ensemble of classification estimates, as opposed to a single\nclassification. Information theoretic approaches are used to identify important\nscale lenghts in clustering The L15 Climate Datset. We also discover a\nsub-collection of the ensemble that spans the majority of the variance\nobserved, allowing for efficient consensus clustering techniques that can be\nused to identify climate biomes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:28:58 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:49:14 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["DeSantis", "Derek", ""], ["Wolfram", "Phillip J.", ""], ["Bennett", "Katrina", ""], ["Alexandrov", "Boian", ""]]}, {"id": "2001.07845", "submitter": "Mingzhe Chen", "authors": "Mingzhe Chen, H. Vincent Poor, Walid Saad, and Shuguang Cui", "title": "Convergence Time Optimization for Federated Learning over Wireless\n  Networks", "comments": "This paper has been accepted in the IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the convergence time of federated learning (FL), when deployed\nover a realistic wireless network, is studied. In particular, a wireless\nnetwork is considered in which wireless users transmit their local FL models\n(trained using their locally collected data) to a base station (BS). The BS,\nacting as a central controller, generates a global FL model using the received\nlocal FL models and broadcasts it back to all users. Due to the limited number\nof resource blocks (RBs) in a wireless network, only a subset of users can be\nselected to transmit their local FL model parameters to the BS at each learning\nstep. Moreover, since each user has unique training data samples, the BS\nprefers to include all local user FL models to generate a converged global FL\nmodel. Hence, the FL performance and convergence time will be significantly\naffected by the user selection scheme. Therefore, it is necessary to design an\nappropriate user selection scheme that enables users of higher importance to be\nselected more frequently. This joint learning, wireless resource allocation,\nand user selection problem is formulated as an optimization problem whose goal\nis to minimize the FL convergence time while optimizing the FL performance. To\nsolve this problem, a probabilistic user selection scheme is proposed such that\nthe BS is connected to the users whose local FL models have significant effects\non its global FL model with high probabilities. Given the user selection\npolicy, the uplink RB allocation can be determined. To further reduce the FL\nconvergence time, artificial neural networks (ANNs) are used to estimate the\nlocal FL models of the users that are not allocated any RBs for local FL model\ntransmission at each given learning step, which enables the BS to enhance its\nglobal FL model and improve the FL convergence speed and performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 01:55:12 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 13:28:33 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Chen", "Mingzhe", ""], ["Poor", "H. Vincent", ""], ["Saad", "Walid", ""], ["Cui", "Shuguang", ""]]}, {"id": "2001.07853", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal and Theja Tulabandhula", "title": "Incentivising Exploration and Recommendations for Contextual Bandits\n  with Payments", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a contextual bandit based model to capture the learning and social\nwelfare goals of a web platform in the presence of myopic users. By using\npayments to incentivize these agents to explore different\nitems/recommendations, we show how the platform can learn the inherent\nattributes of items and achieve a sublinear regret while maximizing cumulative\nsocial welfare. We also calculate theoretical bounds on the cumulative costs of\nincentivization to the platform. Unlike previous works in this domain, we\nconsider contexts to be completely adversarial, and the behavior of the\nadversary is unknown to the platform. Our approach can improve various\nengagement metrics of users on e-commerce stores, recommendation engines and\nmatching platforms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:26:22 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Agrawal", "Priyank", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2001.07859", "submitter": "Christopher Urban", "authors": "Christopher J. Urban and Daniel J. Bauer", "title": "A Deep Learning Algorithm for High-Dimensional Exploratory Item Factor\n  Analysis", "comments": "30 pages; 12 figures; accepted for publication in Psychometrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal maximum likelihood (MML) estimation is the preferred approach to\nfitting item response theory models in psychometrics due to the MML estimator's\nconsistency, normality, and efficiency as the sample size tends to infinity.\nHowever, state-of-the-art MML estimation procedures such as the\nMetropolis-Hastings Robbins-Monro (MH-RM) algorithm as well as approximate MML\nestimation procedures such as variational inference (VI) are computationally\ntime-consuming when the sample size and the number of latent factors are very\nlarge. In this work, we investigate a deep learning-based VI algorithm for\nexploratory item factor analysis (IFA) that is computationally fast even in\nlarge data sets with many latent factors. The proposed approach applies a deep\nartificial neural network model called an importance-weighted autoencoder\n(IWAE) for exploratory IFA. The IWAE approximates the MML estimator using an\nimportance sampling technique wherein increasing the number of\nimportance-weighted (IW) samples drawn during fitting improves the\napproximation, typically at the cost of decreased computational efficiency. We\nprovide a real data application that recovers results aligning with\npsychological theory across random starts. Via simulation studies, we show that\nthe IWAE yields more accurate estimates as either the sample size or the number\nof IW samples increases (although factor correlation and intercepts estimates\nexhibit some bias) and obtains similar results to MH-RM in less time. Our\nsimulations also suggest that the proposed approach performs similarly to and\nis potentially faster than constrained joint maximum likelihood estimation, a\nfast procedure that is consistent when the sample size and the number of items\nsimultaneously tend to infinity.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:02:34 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 00:21:19 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 18:24:46 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 17:29:22 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Urban", "Christopher J.", ""], ["Bauer", "Daniel J.", ""]]}, {"id": "2001.07861", "submitter": "Xin Bing", "authors": "Xin Bing and Florentina Bunea and Marten Wegkamp", "title": "Optimal estimation of sparse topic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have become popular tools for dimension reduction and\nexploratory analysis of text data which consists in observed frequencies of a\nvocabulary of $p$ words in $n$ documents, stored in a $p\\times n$ matrix. The\nmain premise is that the mean of this data matrix can be factorized into a\nproduct of two non-negative matrices: a $p\\times K$ word-topic matrix $A$ and a\n$K\\times n$ topic-document matrix $W$. This paper studies the estimation of $A$\nthat is possibly element-wise sparse, and the number of topics $K$ is unknown.\nIn this under-explored context, we derive a new minimax lower bound for the\nestimation of such $A$ and propose a new computationally efficient algorithm\nfor its recovery. We derive a finite sample upper bound for our estimator, and\nshow that it matches the minimax lower bound in many scenarios. Our estimate\nadapts to the unknown sparsity of $A$ and our analysis is valid for any finite\n$n$, $p$, $K$ and document lengths. Empirical results on both synthetic data\nand semi-synthetic data show that our proposed estimator is a strong competitor\nof the existing state-of-the-art algorithms for both non-sparse $A$ and sparse\n$A$, and has superior performance is many scenarios of interest.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:19:50 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Bing", "Xin", ""], ["Bunea", "Florentina", ""], ["Wegkamp", "Marten", ""]]}, {"id": "2001.07866", "submitter": "Xingyu Wang", "authors": "Xingyu Wang, Lida Zhang, Diego Klabjan", "title": "Keyword-based Topic Modeling and Keyword Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain type of documents such as tweets are collected by specifying a set of\nkeywords. As topics of interest change with time it is beneficial to adjust\nkeywords dynamically. The challenge is that these need to be specified ahead of\nknowing the forthcoming documents and the underlying topics. The future topics\nshould mimic past topics of interest yet there should be some novelty in them.\nWe develop a keyword-based topic model that dynamically selects a subset of\nkeywords to be used to collect future documents. The generative process first\nselects keywords and then the underlying documents based on the specified\nkeywords. The model is trained by using a variational lower bound and\nstochastic gradient optimization. The inference consists of finding a subset of\nkeywords where given a subset the model predicts the underlying topic-word\nmatrix for the unknown forthcoming documents. We compare the keyword topic\nmodel against a benchmark model using viral predictions of tweets combined with\na topic model. The keyword-based topic model outperforms this sophisticated\nbaseline model by 67%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:41:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Wang", "Xingyu", ""], ["Zhang", "Lida", ""], ["Klabjan", "Diego", ""]]}, {"id": "2001.07883", "submitter": "Hao Liu", "authors": "Hao Liu, Wenjing Liao", "title": "Learning functions varying along an active subspace", "comments": "39 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many functions of interest are in a high-dimensional space but exhibit\nlow-dimensional structures. This paper studies regression of a $s$-H\\\"{o}lder\nfunction $f$ in $\\mathbb{R}^D$ which varies along an active subspace of\ndimension $d$ while $d\\ll D$. A direct approximation of $f$ in $\\mathbb{R}^D$\nwith an $\\varepsilon$ accuracy requires the number of samples $n$ in the order\nof $\\varepsilon^{-(2s+D)/s}$. In this paper, we modify the Generalized Contour\nRegression (GCR) algorithm to estimate the active subspace and use piecewise\npolynomials for function approximation. GCR is among the best estimators for\nthe active subspace, but its sample complexity is an open question. Our\nmodified GCR improves the efficiency over the original GCR and leads to an mean\nsquared estimation error of $O(n^{-1})$ for the active subspace, when $n$ is\nsufficiently large. The mean squared regression error of $f$ is proved to be in\nthe order of $\\left(n/\\log n\\right)^{-\\frac{2s}{2s+d}}$ where the exponent\ndepends on the dimension of the active subspace $d$ instead of the ambient\nspace $D$. This result demonstrates that GCR is effective in learning\nlow-dimensional active subspaces. The convergence rate is validated through\nseveral numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 05:28:45 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 14:51:47 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Liu", "Hao", ""], ["Liao", "Wenjing", ""]]}, {"id": "2001.07910", "submitter": "Victor Berger", "authors": "Victor Berger (TAU), Mich\\`ele Sebag (LRI)", "title": "From abstract items to latent spaces to observed data and back:\n  Compositional Variational Auto-Encoder", "comments": null, "journal-ref": "ECMLPKDD 2019 : European Conference on Machine learning and\n  knowledge discovery in databases, Sep 2019, W{\\\"u}rzburg, Germany", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Generative Models are now acknowledged an essential tool in\nMachine Learning. This paper focuses on their control. While many approaches\naim at disentangling the data through the coordinate-wise control of their\nlatent representations, another direction is explored in this paper. The\nproposed CompVAE handles data with a natural multi-ensemblist structure (i.e.\nthat can naturally be decomposed into elements). Derived from Bayesian\nvariational principles, CompVAE learns a latent representation leveraging both\nobservational and symbolic information. A first contribution of the approach is\nthat this latent representation supports a compositional generative model,\namenable to multi-ensemblist operations (addition or subtraction of elements in\nthe composition). This compositional ability is enabled by the invariance and\ngenerality of the whole framework w.r.t. respectively, the order and number of\nthe elements. The second contribution of the paper is a proof of concept on\nsynthetic 1D and 2D problems, demonstrating the efficiency of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 08:30:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Berger", "Victor", "", "TAU"], ["Sebag", "Mich\u00e8le", "", "LRI"]]}, {"id": "2001.07922", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Get Rid of Suspended Animation Problem: Deep Diffusive Neural Network on\n  Graph Semi-Supervised Classification", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph neural networks may suffer from the \"suspended animation\nproblem\" when the model architecture goes deep. Meanwhile, for some graph\nlearning scenarios, e.g., nodes with text/image attributes or graphs with\nlong-distance node correlations, deep graph neural networks will be necessary\nfor effective graph representation learning. In this paper, we propose a new\ngraph neural network, namely DIFNET (Graph Diffusive Neural Network), for graph\nrepresentation learning and node classification. DIFNET utilizes both neural\ngates and graph residual learning for node hidden state modeling, and includes\nan attention mechanism for node neighborhood information diffusion. Extensive\nexperiments will be done in this paper to compare DIFNET against several\nstate-of-the-art graph neural network models. The experimental results can\nillustrate both the learning performance advantages and effectiveness of\nDIFNET, especially in addressing the \"suspended animation problem\".\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:19:12 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2001.07933", "submitter": "Han Zhichao", "authors": "Jia Li, Honglei Zhang, Zhichao Han, Yu Rong, Hong Cheng, Junzhou Huang", "title": "Adversarial Attack on Community Detection by Hiding Individuals", "comments": "In Proceedings of The Web Conference 2020, April 20-24, 2020, Taipei,\n  Taiwan. 11 pages", "journal-ref": null, "doi": "10.1145/3366423.3380171", "report-no": null, "categories": "cs.SI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated that adversarial graphs, i.e., graphs with\nimperceptible perturbations added, can cause deep graph models to fail on\nnode/graph classification tasks. In this paper, we extend adversarial graphs to\nthe problem of community detection which is much more difficult. We focus on\nblack-box attack and aim to hide targeted individuals from the detection of\ndeep graph community detection models, which has many applications in\nreal-world scenarios, for example, protecting personal privacy in social\nnetworks and understanding camouflage patterns in transaction networks. We\npropose an iterative learning framework that takes turns to update two modules:\none working as the constrained graph generator and the other as the surrogate\ncommunity detection model. We also find that the adversarial graphs generated\nby our method can be transferred to other learning based community detection\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:50:04 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Li", "Jia", ""], ["Zhang", "Honglei", ""], ["Han", "Zhichao", ""], ["Rong", "Yu", ""], ["Cheng", "Hong", ""], ["Huang", "Junzhou", ""]]}, {"id": "2001.07935", "submitter": "Grigori Fursin", "authors": "Grigori Fursin, Herve Guillou and Nicolas Essayan", "title": "CodeReef: an open platform for portable MLOps, reusable automation\n  actions and reproducible benchmarking", "comments": "Presented at the 1st Workshop on MLOps Systems co-located with the\n  3rd Conference on Machine Learning and Systems (MLSys'20) in Austin, TX, USA:\n  https://mlops-systems.github.io . A live interactive demo:\n  https://CodeReef.ai/demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present CodeReef - an open platform to share all the components necessary\nto enable cross-platform MLOps (MLSysOps), i.e. automating the deployment of ML\nmodels across diverse systems in the most efficient way. We also introduce the\nCodeReef solution - a way to package and share models as non-virtualized,\nportable, customizable and reproducible archive files. Such ML packages include\nJSON meta description of models with all dependencies, Python APIs, CLI actions\nand portable workflows necessary to automatically build, benchmark, test and\ncustomize models across diverse platforms, AI frameworks, libraries, compilers\nand datasets. We demonstrate several CodeReef solutions to automatically build,\nrun and measure object detection based on SSD-Mobilenets, TensorFlow and COCO\ndataset from the latest MLPerf inference benchmark across a wide range of\nplatforms from Raspberry Pi, Android phones and IoT devices to data centers.\nOur long-term goal is to help researchers share their new techniques as\nproduction-ready packages along with research papers to participate in\ncollaborative and reproducible benchmarking, compare the different\nML/software/hardware stacks and select the most efficient ones on a Pareto\nfrontier using online CodeReef dashboards.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:52:51 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 11:09:34 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fursin", "Grigori", ""], ["Guillou", "Herve", ""], ["Essayan", "Nicolas", ""]]}, {"id": "2001.07937", "submitter": "Mustafa Ozger", "authors": "Amin Azari, Fayezeh Ghavimi, Mustafa Ozger, Riku Jantti, and Cicek\n  Cavdar", "title": "Machine Learning assisted Handover and Resource Management for Cellular\n  Connected Drones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling cellular connectivity for drones introduces a wide set of challenges\nand opportunities. Communication of cellular-connected drones is influenced by\n3-dimensional mobility and line-of-sight channel characteristics which results\nin higher number of handovers with increasing altitude. Our cell planning\nsimulations in coexistence of aerial and terrestrial users indicate that the\nsevere interference from drones to base stations is a major challenge for\nuplink communications of terrestrial users. Here, we first present the major\nchallenges in co-existence of terrestrial and drone communications by\nconsidering real geographical network data for Stockholm. Then, we derive\nanalytical models for the key performance indicators (KPIs), including\ncommunications delay and interference over cellular networks, and formulate the\nhandover and radio resource management (H-RRM) optimization problem.\nAfterwards, we transform this problem into a machine learning problem, and\npropose a deep reinforcement learning solution to solve H-RRM problem. Finally,\nusing simulation results, we present how the speed and altitude of drones, and\nthe tolerable level of interference, shape the optimal H-RRM policy in the\nnetwork. Especially, the heat-maps of handover decisions in different drone's\naltitudes/speeds have been presented, which promote a revision of the legacy\nhandover schemes and redefining the boundaries of cells in the sky.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 10:04:26 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Azari", "Amin", ""], ["Ghavimi", "Fayezeh", ""], ["Ozger", "Mustafa", ""], ["Jantti", "Riku", ""], ["Cavdar", "Cicek", ""]]}, {"id": "2001.07949", "submitter": "Karsten Schweikert", "authors": "Karsten Schweikert", "title": "Oracle Efficient Estimation of Structural Breaks in Cointegrating\n  Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an adaptive group lasso procedure to efficiently\nestimate structural breaks in cointegrating regressions. It is well-known that\nthe group lasso estimator is not simultaneously estimation consistent and model\nselection consistent in structural break settings. Hence, we use a first step\ngroup lasso estimation of a diverging number of breakpoint candidates to\nproduce weights for a second adaptive group lasso estimation. We prove that\nparameter changes are estimated consistently by group lasso and show that the\nnumber of estimated breaks is greater than the true number but still\nsufficiently close to it. Then, we use these results and prove that the\nadaptive group lasso has oracle properties if weights are obtained from our\nfirst step estimation. Simulation results show that the proposed estimator\ndelivers the expected results. An economic application to the long-run US money\ndemand function demonstrates the practical importance of this methodology.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 10:32:01 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 08:39:43 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 12:26:04 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 09:38:52 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Schweikert", "Karsten", ""]]}, {"id": "2001.08001", "submitter": "Oliver Willers", "authors": "Oliver Willers, Sebastian Sudholt, Shervin Raafatnia, Stephanie\n  Abrecht", "title": "Safety Concerns and Mitigation Approaches Regarding the Use of Deep\n  Learning in Safety-Critical Perception Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are widely regarded as indispensable when it comes to\ndesigning perception pipelines for autonomous agents such as robots, drones or\nautomated vehicles. The main reasons, however, for deep learning not being used\nfor autonomous agents at large scale already are safety concerns. Deep learning\napproaches typically exhibit a black-box behavior which makes it hard for them\nto be evaluated with respect to safety-critical aspects. While there have been\nsome work on safety in deep learning, most papers typically focus on high-level\nsafety concerns. In this work, we seek to dive into the safety concerns of deep\nlearning methods and present a concise enumeration on a deeply technical level.\nAdditionally, we present extensive discussions on possible mitigation methods\nand give an outlook regarding what mitigation methods are still missing in\norder to facilitate an argumentation for the safety of a deep learning method.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:22:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Willers", "Oliver", ""], ["Sudholt", "Sebastian", ""], ["Raafatnia", "Shervin", ""], ["Abrecht", "Stephanie", ""]]}, {"id": "2001.08025", "submitter": "Guillermo Navas Palencia", "authors": "Guillermo Navas-Palencia", "title": "Optimal binning: mathematical programming formulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal binning is the optimal discretization of a variable into bins\ngiven a discrete or continuous numeric target. We present a rigorous and\nextensible mathematical programming formulation to solving the optimal binning\nproblem for a binary, continuous and multi-class target type, incorporating\nconstraints not previously addressed. For all three target types, we introduce\na convex mixed-integer programming formulation. Several algorithmic\nenhancements such as automatic determination of the most suitable monotonic\ntrend via a Machine-Learning-based classifier and implementation aspects are\nthoughtfully discussed. The new mathematical programming formulations are\ncarefully implemented in the open-source python library OptBinning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:11:13 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Navas-Palencia", "Guillermo", ""]]}, {"id": "2001.08049", "submitter": "Nicolas Brosse", "authors": "Nicolas Brosse, Carlos Riquelme, Alice Martin, Sylvain Gelly, \\'Eric\n  Moulines", "title": "On Last-Layer Algorithms for Classification: Decoupling Representation\n  from Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification for deep learning is a challenging open problem.\nBayesian statistics offer a mathematically grounded framework to reason about\nuncertainties; however, approximate posteriors for modern neural networks still\nrequire prohibitive computational costs. We propose a family of algorithms\nwhich split the classification task into two stages: representation learning\nand uncertainty estimation. We compare four specific instances, where\nuncertainty estimation is performed via either an ensemble of Stochastic\nGradient Descent or Stochastic Gradient Langevin Dynamics snapshots, an\nensemble of bootstrapped logistic regressions, or via a number of Monte Carlo\nDropout passes. We evaluate their performance in terms of \\emph{selective}\nclassification (risk-coverage), and their ability to detect out-of-distribution\nsamples. Our experiments suggest there is limited value in adding multiple\nuncertainty layers to deep classifiers, and we observe that these simple\nmethods strongly outperform a vanilla point-estimate SGD in some complex\nbenchmarks like ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:08:30 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Brosse", "Nicolas", ""], ["Riquelme", "Carlos", ""], ["Martin", "Alice", ""], ["Gelly", "Sylvain", ""], ["Moulines", "\u00c9ric", ""]]}, {"id": "2001.08055", "submitter": "Muhammad Firmansyah Kasim", "authors": "M. F. Kasim, D. Watson-Parris, L. Deaconu, S. Oliver, P. Hatfield, D.\n  H. Froula, G. Gregori, M. Jarvis, S. Khatiwala, J. Korenaga, J.\n  Topp-Mugglestone, E. Viezzer, S. M. Vinko", "title": "Building high accuracy emulators for scientific simulations with deep\n  neural architecture search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph physics.comp-ph physics.plasm-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer simulations are invaluable tools for scientific discovery. However,\naccurate simulations are often slow to execute, which limits their\napplicability to extensive parameter exploration, large-scale data analysis,\nand uncertainty quantification. A promising route to accelerate simulations by\nbuilding fast emulators with machine learning requires large training datasets,\nwhich can be prohibitively expensive to obtain with slow simulations. Here we\npresent a method based on neural architecture search to build accurate\nemulators even with a limited number of training data. The method successfully\naccelerates simulations by up to 2 billion times in 10 scientific cases\nincluding astrophysics, climate science, biogeochemistry, high energy density\nphysics, fusion energy, and seismology, using the same super-architecture,\nalgorithm, and hyperparameters. Our approach also inherently provides emulator\nuncertainty estimation, adding further confidence in their use. We anticipate\nthis work will accelerate research involving expensive simulations, allow more\nextensive parameters exploration, and enable new, previously unfeasible\ncomputational discovery.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:14:12 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 14:42:35 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Kasim", "M. F.", ""], ["Watson-Parris", "D.", ""], ["Deaconu", "L.", ""], ["Oliver", "S.", ""], ["Hatfield", "P.", ""], ["Froula", "D. H.", ""], ["Gregori", "G.", ""], ["Jarvis", "M.", ""], ["Khatiwala", "S.", ""], ["Korenaga", "J.", ""], ["Topp-Mugglestone", "J.", ""], ["Viezzer", "E.", ""], ["Vinko", "S. M.", ""]]}, {"id": "2001.08075", "submitter": "Yang Chen", "authors": "Yang Chen", "title": "Active Learning over DNN: Automated Engineering Design Optimization for\n  Fluid Dynamics Based on Self-Simulated Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing fluid-dynamic performance is an important engineering task.\nTraditionally, experts design shapes based on empirical estimations and verify\nthem through expensive experiments. This costly process, both in terms of time\nand space, may only explore a limited number of shapes and lead to sub-optimal\ndesigns. In this research, a test-proven deep learning architecture is applied\nto predict the performance under various restrictions and search for better\nshapes by optimizing the learned prediction function. The major challenge is\nthe vast amount of data points Deep Neural Network (DNN) demands, which is\nimprovident to simulate. To remedy this drawback, a Frequentist active learning\nis used to explore regions of the output space that DNN predicts promising.\nThis operation reduces the number of data samples demanded from ~8000 to 625.\nThe final stage, a user interface, made the model capable of optimizing with\ngiven user input of minimum area and viscosity. Flood fill is used to define a\nboundary area function so that the optimal shape does not bypass the minimum\narea. Stochastic Gradient Langevin Dynamics (SGLD) is employed to make sure the\nultimate shape is optimized while circumventing the required area. Jointly,\nshapes with extremely low drags are found explored by a practical user\ninterface with no human domain knowledge and modest computation overhead.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 07:35:00 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 03:16:45 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Chen", "Yang", ""]]}, {"id": "2001.08088", "submitter": "Shakiba Yaghoubi", "authors": "Shakiba Yaghoubi, Georgios Fainekos, Sriram Sankaranarayanan", "title": "Training Neural Network Controllers Using Control Barrier Functions in\n  the Presence of Disturbances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control Barrier Functions (CBF) have been recently utilized in the design of\nprovably safe feedback control laws for nonlinear systems. These feedback\ncontrol methods typically compute the next control input by solving an online\nQuadratic Program (QP). Solving QP in real-time can be a computationally\nexpensive process for resource constraint systems. In this work, we propose to\nuse imitation learning to learn Neural Network-based feedback controllers which\nwill satisfy the CBF constraints. In the process, we also develop a new class\nof High Order CBF for systems under external disturbances. We demonstrate the\nframework on a unicycle model subject to external disturbances, e.g., wind or\ncurrents.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 18:43:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Yaghoubi", "Shakiba", ""], ["Fainekos", "Georgios", ""], ["Sankaranarayanan", "Sriram", ""]]}, {"id": "2001.08090", "submitter": "Romain Bey", "authors": "R. Bey, R. Goussault, M. Benchoufi, R. Porcher", "title": "Stratified cross-validation for unbiased and privacy-preserving\n  federated learning", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": "10.1093/jamia/ocaa096", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale collections of electronic records constitute both an opportunity\nfor the development of more accurate prediction models and a threat for\nprivacy. To limit privacy exposure new privacy-enhancing techniques are\nemerging such as federated learning which enables large-scale data analysis\nwhile avoiding the centralization of records in a unique database that would\nrepresent a critical point of failure. Although promising regarding privacy\nprotection, federated learning prevents using some data-cleaning algorithms\nthus inducing new biases. In this work we focus on the recurrent problem of\nduplicated records that, if not handled properly, may cause over-optimistic\nestimations of a model's performances. We introduce and discuss stratified\ncross-validation, a validation methodology that leverages stratification\ntechniques to prevent data leakage in federated learning settings without\nrelying on demanding deduplication algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:49:34 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 08:43:26 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bey", "R.", ""], ["Goussault", "R.", ""], ["Benchoufi", "M.", ""], ["Porcher", "R.", ""]]}, {"id": "2001.08092", "submitter": "Devesh Jha", "authors": "Patrik Kolaric, Devesh K. Jha, Arvind U. Raghunathan, Frank L. Lewis,\n  Mouhacine Benosman, Diego Romeres and Daniel Nikovski", "title": "Local Policy Optimization for Trajectory-Centric Reinforcement Learning", "comments": null, "journal-ref": "ICRA 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to present a method for simultaneous trajectory and\nlocal stabilizing policy optimization to generate local policies for\ntrajectory-centric model-based reinforcement learning (MBRL). This is motivated\nby the fact that global policy optimization for non-linear systems could be a\nvery challenging problem both algorithmically and numerically. However, a lot\nof robotic manipulation tasks are trajectory-centric, and thus do not require a\nglobal model or policy. Due to inaccuracies in the learned model estimates, an\nopen-loop trajectory optimization process mostly results in very poor\nperformance when used on the real system. Motivated by these problems, we try\nto formulate the problem of trajectory optimization and local policy synthesis\nas a single optimization problem. It is then solved simultaneously as an\ninstance of nonlinear programming. We provide some results for analysis as well\nas achieved performance of the proposed technique under some simplifying\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:56:00 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kolaric", "Patrik", ""], ["Jha", "Devesh K.", ""], ["Raghunathan", "Arvind U.", ""], ["Lewis", "Frank L.", ""], ["Benosman", "Mouhacine", ""], ["Romeres", "Diego", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2001.08103", "submitter": "Adnan Qayyum", "authors": "Adnan Qayyum, Junaid Qadir, Muhammad Bilal, and Ala Al-Fuqaha", "title": "Secure and Robust Machine Learning for Healthcare: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed widespread adoption of machine learning (ML)/deep\nlearning (DL) techniques due to their superior performance for a variety of\nhealthcare applications ranging from the prediction of cardiac arrest from\none-dimensional heart signals to computer-aided diagnosis (CADx) using\nmulti-dimensional medical images. Notwithstanding the impressive performance of\nML/DL, there are still lingering doubts regarding the robustness of ML/DL in\nhealthcare settings (which is traditionally considered quite challenging due to\nthe myriad security and privacy issues involved), especially in light of recent\nresults that have shown that ML/DL are vulnerable to adversarial attacks. In\nthis paper, we present an overview of various application areas in healthcare\nthat leverage such techniques from security and privacy point of view and\npresent associated challenges. In addition, we present potential methods to\nensure secure and privacy-preserving ML for healthcare applications. Finally,\nwe provide insight into the current research challenges and promising\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 08:12:36 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Qayyum", "Adnan", ""], ["Qadir", "Junaid", ""], ["Bilal", "Muhammad", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2001.08116", "submitter": "David Warde-Farley", "authors": "Tom Van de Wiele, David Warde-Farley, Andriy Mnih and Volodymyr Mnih", "title": "Q-Learning in enormous action spaces via amortized approximate\n  maximization", "comments": "A previous version of this work appeared at the Deep Reinforcement\n  Learning Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Q-learning to high-dimensional or continuous action spaces can be\ndifficult due to the required maximization over the set of possible actions.\nMotivated by techniques from amortized inference, we replace the expensive\nmaximization over all actions with a maximization over a small subset of\npossible actions sampled from a learned proposal distribution. The resulting\napproach, which we dub Amortized Q-learning (AQL), is able to handle discrete,\ncontinuous, or hybrid action spaces while maintaining the benefits of\nQ-learning. Our experiments on continuous control tasks with up to 21\ndimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018)\nand QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action\nspaces demonstrate that AQL can efficiently learn good policies in spaces with\nthousands of discrete actions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:14:38 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Van de Wiele", "Tom", ""], ["Warde-Farley", "David", ""], ["Mnih", "Andriy", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "2001.08142", "submitter": "Csan\\'ad S\\'andor", "authors": "Csan\\'ad S\\'andor, Szabolcs P\\'avel, Lehel Csat\\'o", "title": "Pruning CNN's with linear filter ensembles", "comments": "accepted to ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the promising results of convolutional neural networks (CNNs), their\napplication on devices with limited resources is still a big challenge; this is\nmainly due to the huge memory and computation requirements of the CNN. To\ncounter the limitation imposed by the network size, we use pruning to reduce\nthe network size and -- implicitly -- the number of floating point operations\n(FLOPs). Contrary to the filter norm method -- used in ``conventional`` network\npruning -- based on the assumption that a smaller norm implies ``less\nimportance'' to its associated component, we develop a novel filter importance\nnorm that is based on the change in the empirical loss caused by the presence\nor removal of a component from the network architecture.\n  Since there are too many individual possibilities for filter configuration,\nwe repeatedly sample from these architectural components and measure the system\nperformance in the respective state of components being active or disabled. The\nresult is a collection of filter ensembles -- filter masks -- and associated\nperformance values. We rank the filters based on a linear and additive model\nand remove the least important ones such that the drop in network accuracy is\nminimal. We evaluate our method on a fully connected network, as well as on the\nResNet architecture trained on the CIFAR-10 dataset. Using our pruning method,\nwe managed to remove $60\\%$ of the parameters and $64\\%$ of the FLOPs from the\nResNet with an accuracy drop of less than $0.6\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:52:06 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 09:25:32 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["S\u00e1ndor", "Csan\u00e1d", ""], ["P\u00e1vel", "Szabolcs", ""], ["Csat\u00f3", "Lehel", ""]]}, {"id": "2001.08155", "submitter": "Awais Ahmed Mr", "authors": "Awais Ahmed, Sufian Hameed, Muhammad Rafi, Qublai Khan Ali Mirza", "title": "An Intelligent and Time-Efficient DDoS Identification Framework for\n  Real-Time Enterprise Networks SAD-F: Spark Based Anomaly Detection Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a crucial step for preventing malicious activities in\nthe network and keeping resources available all the time for legitimate users.\nIt is noticed from various studies that classical anomaly detectors work well\nwith small and sampled data, but the chances of failures increase with\nreal-time (non-sampled data) traffic data. In this paper, we will be exploring\nsecurity analytic techniques for DDoS anomaly detection using different machine\nlearning techniques. In this paper, we are proposing a novel approach which\ndeals with real traffic as input to the system. Further, we study and compare\nthe performance factor of our proposed framework on three different testbeds\nincluding normal commodity hardware, low-end system, and high-end system.\nHardware details of testbeds are discussed in the respective section. Further\nin this paper, we investigate the performance of the classifiers in (near)\nreal-time detection of anomalies attacks. This study also focused on the\nfeature selection process that is as important for the anomaly detection\nprocess as it is for general modeling problems. Several techniques have been\nstudied for feature selection and it is observed that proper feature selection\ncan increase performance in terms of model's execution time - which totally\ndepends upon the traffic file or traffic capturing process.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:05:48 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:19:56 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ahmed", "Awais", ""], ["Hameed", "Sufian", ""], ["Rafi", "Muhammad", ""], ["Mirza", "Qublai Khan Ali", ""]]}, {"id": "2001.08169", "submitter": "Nawanol Theera-Ampornpunt", "authors": "Nawanol Theera-Ampornpunt, Shikhar Suryavansh, Sameer Manchanda,\n  Rajesh Panta, Kaustubh Joshi, Mostafa Ammar, Mung Chiang, Saurabh Bagchi", "title": "AppStreamer: Reducing Storage Requirements of Mobile Games through\n  Predictive Streaming", "comments": "12 pages; EWSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storage has become a constrained resource on smartphones. Gaming is a popular\nactivity on mobile devices and the explosive growth in the number of games\ncoupled with their growing size contributes to the storage crunch. Even where\nstorage is plentiful, it takes a long time to download and install a heavy app\nbefore it can be launched. This paper presents AppStreamer, a novel technique\nfor reducing the storage requirements or startup delay of mobile games, and\nheavy mobile apps in general. AppStreamer is based on the intuition that most\napps do not need the entirety of its files (images, audio and video clips,\netc.) at any one time. AppStreamer can, therefore, keep only a small part of\nthe files on the device, akin to a \"cache\", and download the remainder from a\ncloud storage server or a nearby edge server when it predicts that the app will\nneed them in the near future. AppStreamer continuously predicts file blocks for\nthe near future as the user uses the app, and fetches them from the storage\nserver before the user sees a stall due to missing resources. We implement\nAppStreamer at the Android file system layer. This ensures that the apps\nrequire no source code or modification, and the approach generalizes across\napps. We evaluate AppStreamer using two popular games: Dead Effect 2, a 3D\nfirst-person shooter, and Fire Emblem Heroes, a 2D turn-based strategy\nrole-playing game. Through a user study, 75% and 87% of the users respectively\nfind that AppStreamer provides the same quality of user experience as the\nbaseline where all files are stored on the device. AppStreamer cuts down the\nstorage requirement by 87% for Dead Effect 2 and 86% for Fire Emblem Heroes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:42:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Theera-Ampornpunt", "Nawanol", ""], ["Suryavansh", "Shikhar", ""], ["Manchanda", "Sameer", ""], ["Panta", "Rajesh", ""], ["Joshi", "Kaustubh", ""], ["Ammar", "Mostafa", ""], ["Chiang", "Mung", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2001.08184", "submitter": "Harsh Vardhan Jain", "authors": "Nikhil Goyal, Harsh Vardhan Jain, Sayan Ranu", "title": "GraphGen: A Scalable Approach to Domain-agnostic Labeled Graph\n  Generation", "comments": "Fixed typo in Table 1; The Web Conference (WWW) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph generative models have been extensively studied in the data mining\nliterature. While traditional techniques are based on generating structures\nthat adhere to a pre-decided distribution, recent techniques have shifted\ntowards learning this distribution directly from the data. While learning-based\napproaches have imparted significant improvement in quality, some limitations\nremain to be addressed. First, learning graph distributions introduces\nadditional computational overhead, which limits their scalability to large\ngraph databases. Second, many techniques only learn the structure and do not\naddress the need to also learn node and edge labels, which encode important\nsemantic information and influence the structure itself. Third, existing\ntechniques often incorporate domain-specific rules and lack generalizability.\nFourth, the experimentation of existing techniques is not comprehensive enough\ndue to either using weak evaluation metrics or focusing primarily on synthetic\nor small datasets. In this work, we develop a domain-agnostic technique called\nGraphGen to overcome all of these limitations. GraphGen converts graphs to\nsequences using minimum DFS codes. Minimum DFS codes are canonical labels and\ncapture the graph structure precisely along with the label information. The\ncomplex joint distributions between structure and semantic labels are learned\nthrough a novel LSTM architecture. Extensive experiments on million-sized, real\ngraph datasets show GraphGen to be 4 times faster on average than\nstate-of-the-art techniques while being significantly better in quality across\na comprehensive set of 11 different metrics. Our code is released at\nhttps://github.com/idea-iitd/graphgen.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:07:43 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 13:18:05 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Goyal", "Nikhil", ""], ["Jain", "Harsh Vardhan", ""], ["Ranu", "Sayan", ""]]}, {"id": "2001.08255", "submitter": "Stefan L\\\"ockel", "authors": "Stefan L\\\"ockel, Jan Peters, Peter van Vliet", "title": "A Probabilistic Framework for Imitating Human Race Driver Behavior", "comments": "updated references [17] and [33]; added journal info", "journal-ref": "IEEE Robotics and Automation Letters, vol. 5, no. 2, pp.\n  2086-2093, April 2020", "doi": "10.1109/LRA.2020.2970620", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and modeling human driver behavior is crucial for advanced\nvehicle development. However, unique driving styles, inconsistent behavior, and\ncomplex decision processes render it a challenging task, and existing\napproaches often lack variability or robustness. To approach this problem, we\npropose Probabilistic Modeling of Driver behavior (ProMoD), a modular framework\nwhich splits the task of driver behavior modeling into multiple modules. A\nglobal target trajectory distribution is learned with Probabilistic Movement\nPrimitives, clothoids are utilized for local path generation, and the\ncorresponding choice of actions is performed by a neural network. Experiments\nin a simulated car racing setting show considerable advantages in imitation\naccuracy and robustness compared to other imitation learning algorithms. The\nmodular architecture of the proposed framework facilitates straightforward\nextensibility in driving line adaptation and sequencing of multiple movement\nprimitives for future research.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:06:38 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 09:43:38 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["L\u00f6ckel", "Stefan", ""], ["Peters", "Jan", ""], ["van Vliet", "Peter", ""]]}, {"id": "2001.08269", "submitter": "Karol Antczak", "authors": "Karol Antczak", "title": "Representation Learning for Medical Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a representation learning framework for medical diagnosis domain.\nIt is based on heterogeneous network-based model of diagnostic data as well as\nmodified metapath2vec algorithm for learning latent node representation. We\ncompare the proposed algorithm with other representation learning methods in\ntwo practical case studies: symptom/disease classification and disease\nprediction. We observe a significant performance boost in these task resulting\nfrom learning representations of domain data in a form of heterogeneous\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:34:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Antczak", "Karol", ""]]}, {"id": "2001.08277", "submitter": "Haozhao Wang", "authors": "Haozhao Wang, Zhihao Qu, Song Guo, Xin Gao, Ruixuan Li, and Baoliu Ye", "title": "Intermittent Pulling with Local Compensation for Communication-Efficient\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a powerful machine learning paradigm to cooperatively\ntrain a global model with highly distributed data. A major bottleneck on the\nperformance of distributed Stochastic Gradient Descent (SGD) algorithm for\nlarge-scale Federated Learning is the communication overhead on pushing local\ngradients and pulling global model. In this paper, to reduce the communication\ncomplexity of Federated Learning, a novel approach named Pulling Reduction with\nLocal Compensation (PRLC) is proposed. Specifically, each training node\nintermittently pulls the global model from the server in SGD iterations,\nresulting in that it is sometimes unsynchronized with the server. In such a\ncase, it will use its local update to compensate the gap between the local\nmodel and the global model. Our rigorous theoretical analysis of PRLC achieves\ntwo important findings. First, we prove that the convergence rate of PRLC\npreserves the same order as the classical synchronous SGD for both\nstrongly-convex and non-convex cases with good scalability due to the linear\nspeedup with respect to the number of training nodes. Second, we show that PRLC\nadmits lower pulling frequency than the existing pulling reduction method\nwithout local compensation. We also conduct extensive experiments on various\nmachine learning models to validate our theoretical results. Experimental\nresults show that our approach achieves a significant pulling reduction over\nthe state-of-the-art methods, e.g., PRLC requiring only half of the pulling\noperations of LAG.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:53:14 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wang", "Haozhao", ""], ["Qu", "Zhihao", ""], ["Guo", "Song", ""], ["Gao", "Xin", ""], ["Li", "Ruixuan", ""], ["Ye", "Baoliu", ""]]}, {"id": "2001.08286", "submitter": "Justin  Reyes", "authors": "Justin Reyes, Miles Stoudenmire", "title": "A Multi-Scale Tensor Network Architecture for Classification and\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for supervised learning using tensor networks,\nemploying a step of preprocessing the data by coarse-graining through a\nsequence of wavelet transformations. We represent these transformations as a\nset of tensor network layers identical to those in a multi-scale entanglement\nrenormalization ansatz (MERA) tensor network, and perform supervised learning\nand regression tasks through a model based on a matrix product state (MPS)\ntensor network acting on the coarse-grained data. Because the entire model\nconsists of tensor contractions (apart from the initial non-linear feature\nmap), we can adaptively fine-grain the optimized MPS model backwards through\nthe layers with essentially no loss in performance. The MPS itself is trained\nusing an adaptive algorithm based on the density matrix renormalization group\n(DMRG) algorithm. We test our methods by performing a classification task on\naudio data and a regression task on temperature time-series data, studying the\ndependence of training accuracy on the number of coarse-graining layers and\nshowing how fine-graining through the network may be used to initialize models\nwith access to finer-scale features.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 21:26:28 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Reyes", "Justin", ""], ["Stoudenmire", "Miles", ""]]}, {"id": "2001.08290", "submitter": "Haoran Miao", "authors": "Haoran Miao, Gaofeng Cheng, Changfeng Gao, Pengyuan Zhang and Yonghong\n  Yan", "title": "Transformer-based Online CTC/attention End-to-End Speech Recognition\n  Architecture", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Transformer has gained success in automatic speech recognition\n(ASR) field. However, it is challenging to deploy a Transformer-based\nend-to-end (E2E) model for online speech recognition. In this paper, we propose\nthe Transformer-based online CTC/attention E2E ASR architecture, which contains\nthe chunk self-attention encoder (chunk-SAE) and the monotonic truncated\nattention (MTA) based self-attention decoder (SAD). Firstly, the chunk-SAE\nsplits the speech into isolated chunks. To reduce the computational cost and\nimprove the performance, we propose the state reuse chunk-SAE. Sencondly, the\nMTA based SAD truncates the speech features monotonically and performs\nattention on the truncated features. To support the online recognition, we\nintegrate the state reuse chunk-SAE and the MTA based SAD into online\nCTC/attention architecture. We evaluate the proposed online models on the HKUST\nMandarin ASR benchmark and achieve a 23.66% character error rate (CER) with a\n320 ms latency. Our online model yields as little as 0.19% absolute CER\ndegradation compared with the offline baseline, and achieves significant\nimprovement over our prior work on Long Short-Term Memory (LSTM) based online\nE2E models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:36:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 08:05:47 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Miao", "Haoran", ""], ["Cheng", "Gaofeng", ""], ["Gao", "Changfeng", ""], ["Zhang", "Pengyuan", ""], ["Yan", "Yonghong", ""]]}, {"id": "2001.08300", "submitter": "Shiqiang Wang", "authors": "Tiffany Tuor, Shiqiang Wang, Bong Jun Ko, Changchang Liu, Kin K. Leung", "title": "Overcoming Noisy and Irrelevant Data in Federated Learning", "comments": "Accepted version in the 25th International Conference on Pattern\n  Recognition (ICPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many image and vision applications require a large amount of data for model\ntraining. Collecting all such data at a central location can be challenging due\nto data privacy and communication bandwidth restrictions. Federated learning is\nan effective way of training a machine learning model in a distributed manner\nfrom local data collected by client devices, which does not require exchanging\nthe raw data among clients. A challenge is that among the large variety of data\ncollected at each client, it is likely that only a subset is relevant for a\nlearning task while the rest of data has a negative impact on model training.\nTherefore, before starting the learning process, it is important to select the\nsubset of data that is relevant to the given federated learning task. In this\npaper, we propose a method for distributedly selecting relevant data, where we\nuse a benchmark model trained on a small benchmark dataset that is\ntask-specific, to evaluate the relevance of individual data samples at each\nclient and select the data with sufficiently high relevance. Then, each client\nonly uses the selected subset of its data in the federated learning process.\nThe effectiveness of our proposed approach is evaluated on multiple real-world\nimage datasets in a simulated system with a large number of clients, showing up\nto $25\\%$ improvement in model accuracy compared to training with all data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 22:28:47 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:12:29 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tuor", "Tiffany", ""], ["Wang", "Shiqiang", ""], ["Ko", "Bong Jun", ""], ["Liu", "Changchang", ""], ["Leung", "Kin K.", ""]]}, {"id": "2001.08317", "submitter": "Neo Wu", "authors": "Neo Wu, Bradley Green, Xue Ben, Shawn O'Banion", "title": "Deep Transformer Models for Time Series Forecasting: The Influenza\n  Prevalence Case", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new approach to time series forecasting. Time\nseries data are prevalent in many scientific and engineering disciplines. Time\nseries forecasting is a crucial task in modeling time series data, and is an\nimportant area of machine learning. In this work we developed a novel method\nthat employs Transformer-based machine learning models to forecast time series\ndata. This approach works by leveraging self-attention mechanisms to learn\ncomplex patterns and dynamics from time series data. Moreover, it is a generic\nframework and can be applied to univariate and multivariate time series data,\nas well as time series embeddings. Using influenza-like illness (ILI)\nforecasting as a case study, we show that the forecasting results produced by\nour approach are favorably comparable to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 00:22:22 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wu", "Neo", ""], ["Green", "Bradley", ""], ["Ben", "Xue", ""], ["O'Banion", "Shawn", ""]]}, {"id": "2001.08322", "submitter": "Makoto Yamada", "authors": "Dinesh Singh and H\\'ector Climente-Gonz\\'alez and Mathis Petrovich and\n  Eiryo Kawakami and Makoto Yamada", "title": "FsNet: Feature Selection Network on High-dimensional Biological Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological data including gene expression data are generally high-dimensional\nand require efficient, generalizable, and scalable machine-learning methods to\ndiscover their complex nonlinear patterns. The recent advances in machine\nlearning can be attributed to deep neural networks (DNNs), which excel in\nvarious tasks in terms of computer vision and natural language processing.\nHowever, standard DNNs are not appropriate for high-dimensional datasets\ngenerated in biology because they have many parameters, which in turn require\nmany samples. In this paper, we propose a DNN-based, nonlinear feature\nselection method, called the feature selection network (FsNet), for\nhigh-dimensional and small number of sample data. Specifically, FsNet comprises\na selection layer that selects features and a reconstruction layer that\nstabilizes the training. Because a large number of parameters in the selection\nand reconstruction layers can easily result in overfitting under a limited\nnumber of samples, we use two tiny networks to predict the large, virtual\nweight matrices of the selection and reconstruction layers. Experimental\nresults on several real-world, high-dimensional biological datasets demonstrate\nthe efficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 00:49:57 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 06:46:11 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 00:48:37 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Singh", "Dinesh", ""], ["Climente-Gonz\u00e1lez", "H\u00e9ctor", ""], ["Petrovich", "Mathis", ""], ["Kawakami", "Eiryo", ""], ["Yamada", "Makoto", ""]]}, {"id": "2001.08327", "submitter": "Himel Mallick", "authors": "Himel Mallick, Rahim Alhamzawi, Erina Paul, Vladimir Svetnik", "title": "The Reciprocal Bayesian LASSO", "comments": "35 pages, 2 figures, 4 tables; includes revised simulation and real\n  data analysis results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reciprocal LASSO (rLASSO) regularization employs a decreasing penalty\nfunction as opposed to conventional penalization approaches that use increasing\npenalties on the coefficients, leading to stronger parsimony and superior model\nselection relative to traditional shrinkage methods. Here we consider a fully\nBayesian formulation of the rLASSO problem, which is based on the observation\nthat the rLASSO estimate for linear regression parameters can be interpreted as\na Bayesian posterior mode estimate when the regression parameters are assigned\nindependent inverse Laplace priors. Bayesian inference from this posterior is\npossible using an expanded hierarchy motivated by a scale mixture of double\nPareto or truncated normal distributions. On simulated and real datasets, we\nshow that the Bayesian formulation outperforms its classical cousin in\nestimation, prediction, and variable selection across a wide range of scenarios\nwhile offering the advantage of posterior inference. Finally, we discuss other\nvariants of this new approach and provide a unified framework for variable\nselection using flexible reciprocal penalties. All methods described in this\npaper are publicly available as an R package at:\nhttps://github.com/himelmallick/BayesRecipe.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:21:59 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 18:33:20 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 11:06:34 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mallick", "Himel", ""], ["Alhamzawi", "Rahim", ""], ["Paul", "Erina", ""], ["Svetnik", "Vladimir", ""]]}, {"id": "2001.08333", "submitter": "Clarence Chen", "authors": "Clarence Chen, Zachary Pardos", "title": "Applying Recent Innovations from NLP to MOOC Student Course Trajectory\n  Modeling", "comments": "4 pages, 0 figures, accepted to EDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents several strategies that can improve neural network-based\npredictive methods for MOOC student course trajectory modeling, applying\nmultiple ideas previously applied to tackle NLP (Natural Language Processing)\ntasks. In particular, this paper investigates LSTM networks enhanced with two\nforms of regularization, along with the more recently introduced Transformer\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:36:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 19:11:26 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chen", "Clarence", ""], ["Pardos", "Zachary", ""]]}, {"id": "2001.08345", "submitter": "Daniel Jarrett", "authors": "Daniel Jarrett, Mihaela van der Schaar", "title": "Target-Embedding Autoencoders for Supervised Representation Learning", "comments": null, "journal-ref": "In Proc. 8th International Conference on Learning Representations\n  (ICLR 2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder-based learning has emerged as a staple for disciplining\nrepresentations in unsupervised and semi-supervised settings. This paper\nanalyzes a framework for improving generalization in a purely supervised\nsetting, where the target space is high-dimensional. We motivate and formalize\nthe general framework of target-embedding autoencoders (TEA) for supervised\nprediction, learning intermediate latent representations jointly optimized to\nbe both predictable from features as well as predictive of targets---encoding\nthe prior that variations in targets are driven by a compact set of underlying\nfactors. As our theoretical contribution, we provide a guarantee of\ngeneralization for linear TEAs by demonstrating uniform stability, interpreting\nthe benefit of the auxiliary reconstruction task as a form of regularization.\nAs our empirical contribution, we extend validation of this approach beyond\nexisting static classification applications to multivariate sequence\nforecasting, verifying their advantage on both linear and nonlinear recurrent\narchitectures---thereby underscoring the further generality of this framework\nbeyond feedforward instantiations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 02:37:10 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Jarrett", "Daniel", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.08356", "submitter": "Xin Tong Thomson", "authors": "Jing Dong and Xin T. Tong", "title": "Replica Exchange for Non-Convex Optimization", "comments": "70 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent (GD) is known to converge quickly for convex objective\nfunctions, but it can be trapped at local minima. On the other hand, Langevin\ndynamics (LD) can explore the state space and find global minima, but in order\nto give accurate estimates, LD needs to run with a small discretization step\nsize and weak stochastic force, which in general slow down its convergence.\nThis paper shows that these two algorithms and their non-swapping variants. can\n``collaborate\" through a simple exchange mechanism, in which they swap their\ncurrent positions if LD yields a lower objective function. This idea can be\nseen as the singular limit of the replica-exchange technique from the sampling\nliterature. We show that this new algorithm converges to the global minimum\nlinearly with high probability, assuming the objective function is strongly\nconvex in a neighborhood of the unique global minimum. By replacing gradients\nwith stochastic gradients, and adding a proper threshold to the exchange\nmechanism, our algorithm can also be used in online settings. We also study\nnon-swapping variants of the algorithm, which achieve similar performance. We\nfurther verify our theoretical results through some numerical experiments and\nobserve superior performance of the proposed algorithm over running GD or LD\nalone.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:13:19 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 07:25:21 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 22:38:03 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 06:23:31 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Dong", "Jing", ""], ["Tong", "Xin T.", ""]]}, {"id": "2001.08357", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Zhengang Li, Yifan Gong, Tianyun Zhang, Wei Niu, Zheng\n  Zhan, Pu Zhao, Jian Tang, Xue Lin, Bin Ren, Yanzhi Wang", "title": "BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted\n  Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating DNN execution on various resource-limited computing platforms\nhas been a long-standing problem. Prior works utilize l1-based group lasso or\ndynamic regularization such as ADMM to perform structured pruning on DNN models\nto leverage the parallel computing architectures. However, both of the pruning\ndimensions and pruning methods lack universality, which leads to degraded\nperformance and limited applicability. To solve the problem, we propose a new\nblock-based pruning framework that comprises a general and flexible structured\npruning dimension as well as a powerful and efficient reweighted regularization\nmethod. Our framework is universal, which can be applied to both CNNs and RNNs,\nimplying complete support for the two major kinds of computation-intensive\nlayers (i.e., CONV and FC layers). To complete all aspects of the\npruning-for-acceleration task, we also integrate compiler-based code\noptimization into our framework that can perform DNN inference in a real-time\nmanner. To the best of our knowledge, it is the first time that the weight\npruning framework achieves universal coverage for both CNNs and RNNs with\nreal-time mobile acceleration and no accuracy compromise.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:30:56 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:00:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiaolong", ""], ["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Zhang", "Tianyun", ""], ["Niu", "Wei", ""], ["Zhan", "Zheng", ""], ["Zhao", "Pu", ""], ["Tang", "Jian", ""], ["Lin", "Xue", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.08361", "submitter": "Samuel McCandlish", "authors": "Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin\n  Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei", "title": "Scaling Laws for Neural Language Models", "comments": "19 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study empirical scaling laws for language model performance on the\ncross-entropy loss. The loss scales as a power-law with model size, dataset\nsize, and the amount of compute used for training, with some trends spanning\nmore than seven orders of magnitude. Other architectural details such as\nnetwork width or depth have minimal effects within a wide range. Simple\nequations govern the dependence of overfitting on model/dataset size and the\ndependence of training speed on model size. These relationships allow us to\ndetermine the optimal allocation of a fixed compute budget. Larger models are\nsignificantly more sample-efficient, such that optimally compute-efficient\ntraining involves training very large models on a relatively modest amount of\ndata and stopping significantly before convergence.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:59:20 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kaplan", "Jared", ""], ["McCandlish", "Sam", ""], ["Henighan", "Tom", ""], ["Brown", "Tom B.", ""], ["Chess", "Benjamin", ""], ["Child", "Rewon", ""], ["Gray", "Scott", ""], ["Radford", "Alec", ""], ["Wu", "Jeffrey", ""], ["Amodei", "Dario", ""]]}, {"id": "2001.08366", "submitter": "Canyu Le", "authors": "Canyu Le, Zhonggui Chen, Xihan Wei, Biao Wang, Lei Zhang", "title": "Continual Local Replacement for Few-shot Learning", "comments": "Update experiment results and reorganize paper writting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot learning is to learn a model that can recognize novel\nclasses based on one or few training data. It is challenging mainly due to two\naspects: (1) it lacks good feature representation of novel classes; (2) a few\nof labeled data could not accurately represent the true data distribution and\nthus it's hard to learn a good decision function for classification. In this\nwork, we use a sophisticated network architecture to learn better feature\nrepresentation and focus on the second issue. A novel continual local\nreplacement strategy is proposed to address the data deficiency problem. It\ntakes advantage of the content in unlabeled images to continually enhance\nlabeled ones. Specifically, a pseudo labeling method is adopted to constantly\nselect semantically similar images on the fly. Original labeled images will be\nlocally replaced by the selected images for the next epoch training. In this\nway, the model can directly learn new semantic information from unlabeled\nimages and the capacity of supervised signals in the embedding space can be\nsignificantly enlarged. This allows the model to improve generalization and\nlearn a better decision boundary for classification. Our method is conceptually\nsimple and easy to implement. Extensive experiments demonstrate that it can\nachieve state-of-the-art results on various few-shot image recognition\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 04:26:21 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:21:57 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Le", "Canyu", ""], ["Chen", "Zhonggui", ""], ["Wei", "Xihan", ""], ["Wang", "Biao", ""], ["Zhang", "Lei", ""]]}, {"id": "2001.08370", "submitter": "Mohamed El Amine Seddik", "authors": "Mohamed El Amine Seddik, Cosme Louart, Mohamed Tamaazousti, Romain\n  Couillet", "title": "Random Matrix Theory Proves that Deep Learning Representations of\n  GAN-data Behave as Gaussian Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that deep learning (DL) representations of data produced by\ngenerative adversarial nets (GANs) are random vectors which fall within the\nclass of so-called \\textit{concentrated} random vectors. Further exploiting the\nfact that Gram matrices, of the type $G = X^T X$ with $X=[x_1,\\ldots,x_n]\\in\n\\mathbb{R}^{p\\times n}$ and $x_i$ independent concentrated random vectors from\na mixture model, behave asymptotically (as $n,p\\to \\infty$) as if the $x_i$\nwere drawn from a Gaussian mixture, suggests that DL representations of\nGAN-data can be fully described by their first two statistical moments for a\nwide range of standard classifiers. Our theoretical findings are validated by\ngenerating images with the BigGAN model and across different popular deep\nrepresentation networks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 22:17:09 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Seddik", "Mohamed El Amine", ""], ["Louart", "Cosme", ""], ["Tamaazousti", "Mohamed", ""], ["Couillet", "Romain", ""]]}, {"id": "2001.08374", "submitter": "Zhengkun Li", "authors": "Zhengkun Li, Minh-Ngoc Tran, Chao Wang, Richard Gerlach and Junbin Gao", "title": "A Bayesian Long Short-Term Memory Model for Value at Risk and Expected\n  Shortfall Joint Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-at-Risk (VaR) and Expected Shortfall (ES) are widely used in the\nfinancial sector to measure the market risk and manage the extreme market\nmovement. The recent link between the quantile score function and the\nAsymmetric Laplace density has led to a flexible likelihood-based framework for\njoint modelling of VaR and ES. It is of high interest in financial applications\nto be able to capture the underlying joint dynamics of these two quantities. We\naddress this problem by developing a hybrid model that is based on the\nAsymmetric Laplace quasi-likelihood and employs the Long Short-Term Memory\n(LSTM) time series modelling technique from Machine Learning to capture\nefficiently the underlying dynamics of VaR and ES. We refer to this model as\nLSTM-AL. We adopt the adaptive Markov chain Monte Carlo (MCMC) algorithm for\nBayesian inference in the LSTM-AL model. Empirical results show that the\nproposed LSTM-AL model can improve the VaR and ES forecasting accuracy over a\nrange of well-established competing models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:13:36 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 01:19:08 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Li", "Zhengkun", ""], ["Tran", "Minh-Ngoc", ""], ["Wang", "Chao", ""], ["Gerlach", "Richard", ""], ["Gao", "Junbin", ""]]}, {"id": "2001.08389", "submitter": "Yaguan Qian", "authors": "Ya-guan Qian, Xi-Ming Zhang, Wassim Swaileh, Li Wei, Bin Wang,\n  Jian-Hai Chen, Wu-Jie Zhou, and Jing-Sheng Lei", "title": "TEAM: An Taylor Expansion-Based Method for Generating Adversarial\n  Examples", "comments": "25 pages,5 figures,3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Deep Neural Networks(DNNs) have achieved successful applications in\nmany fields, they are vulnerable to adversarial examples.Adversarial training\nis one of the most effective methods to improve the robustness of DNNs, and it\nis generally considered as solving a saddle point problem that minimizes risk\nand maximizes perturbation.Therefore, powerful adversarial examples can\neffectively replicate the situation of perturbation maximization to solve the\nsaddle point problem.The method proposed in this paper approximates the output\nof DNNs in the input neighborhood by using the Taylor expansion, and then\noptimizes it by using the Lagrange multiplier method to generate adversarial\nexamples. If it is used for adversarial training, the DNNs can be effectively\nregularized and the defects of the model can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 07:03:32 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 15:08:20 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Qian", "Ya-guan", ""], ["Zhang", "Xi-Ming", ""], ["Swaileh", "Wassim", ""], ["Wei", "Li", ""], ["Wang", "Bin", ""], ["Chen", "Jian-Hai", ""], ["Zhou", "Wu-Jie", ""], ["Lei", "Jing-Sheng", ""]]}, {"id": "2001.08406", "submitter": "Tuukka Salmi", "authors": "Tuukka Salmi, Jussi Kiljander and Daniel Pakkala", "title": "Stacked Boosters Network Architecture for Short Term Load Forecasting in\n  Buildings", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning architecture for short term load\nforecasting of building energy loads. The architecture is based on a simple\nbase learner and multiple boosting systems that are modelled as a single deep\nneural network. The architecture transforms the original multivariate time\nseries into multiple cascading univariate time series. Together with sparse\ninteractions, parameter sharing and equivariant representations, this approach\nmakes it possible to combat against overfitting while still achieving good\npresentation power with a deep network architecture. The architecture is\nevaluated in several short-term load forecasting tasks with energy data from an\noffice building in Finland. The proposed architecture outperforms\nstate-of-the-art load forecasting model in all the tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 08:35:36 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 05:20:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Salmi", "Tuukka", ""], ["Kiljander", "Jussi", ""], ["Pakkala", "Daniel", ""]]}, {"id": "2001.08427", "submitter": "Maxim Panov", "authors": "Valentina Shumovskaia, Kirill Fedyanin, Ivan Sukharev, Dmitry\n  Berestnev and Maxim Panov", "title": "Linking Bank Clients using Graph Neural Networks Powered by Rich\n  Transactional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial institutions obtain enormous amounts of data about user\ntransactions and money transfers, which can be considered as a large graph\ndynamically changing in time. In this work, we focus on the task of predicting\nnew interactions in the network of bank clients and treat it as a link\nprediction problem. We propose a new graph neural network model, which uses not\nonly the topological structure of the network but rich time-series data\navailable for the graph nodes and edges. We evaluate the developed method using\nthe data provided by a large European bank for several years. The proposed\nmodel outperforms the existing approaches, including other neural network\nmodels, with a significant gap in ROC AUC score on link prediction problem and\nalso allows to improve the quality of credit scoring.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:02:02 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Shumovskaia", "Valentina", ""], ["Fedyanin", "Kirill", ""], ["Sukharev", "Ivan", ""], ["Berestnev", "Dmitry", ""], ["Panov", "Maxim", ""]]}, {"id": "2001.08437", "submitter": "Fengwei Zhou", "authors": "Zewei Chen, Fengwei Zhou, George Trimponias, Zhenguo Li", "title": "Multi-objective Neural Architecture Search via Non-stationary Policy\n  Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective Neural Architecture Search (NAS) aims to discover novel\narchitectures in the presence of multiple conflicting objectives. Despite\nrecent progress, the problem of approximating the full Pareto front accurately\nand efficiently remains challenging. In this work, we explore the novel\nreinforcement learning (RL) based paradigm of non-stationary policy gradient\n(NPG). NPG utilizes a non-stationary reward function, and encourages a\ncontinuous adaptation of the policy to capture the entire Pareto front\nefficiently. We introduce two novel reward functions with elements from the\ndominant paradigms of scalarization and evolution. To handle non-stationarity,\nwe propose a new exploration scheme using cosine temperature decay with warm\nrestarts. For fast and accurate architecture evaluation, we introduce a novel\npre-trained shared model that we continuously fine-tune throughout training.\nOur extensive experimental study with various datasets shows that our framework\ncan approximate the full Pareto front well at fast speeds. Moreover, our\ndiscovered cells can achieve supreme predictive performance compared to other\nmulti-objective NAS methods, and other single-objective NAS methods at similar\nnetwork sizes. Our work demonstrates the potential of NPG as a simple,\nefficient, and effective paradigm for multi-objective NAS.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:37:11 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 03:42:43 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chen", "Zewei", ""], ["Zhou", "Fengwei", ""], ["Trimponias", "George", ""], ["Li", "Zhenguo", ""]]}, {"id": "2001.08444", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo and Roberto Santana", "title": "On the human evaluation of audio adversarial examples", "comments": "Preprint. 17 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human-machine interaction is increasingly dependent on speech communication.\nMachine Learning models are usually applied to interpret human speech commands.\nHowever, these models can be fooled by adversarial examples, which are inputs\nintentionally perturbed to produce a wrong prediction without being noticed.\nWhile much research has been focused on developing new techniques to generate\nadversarial perturbations, less attention has been given to aspects that\ndetermine whether and how the perturbations are noticed by humans. This\nquestion is relevant since high fooling rates of proposed adversarial\nperturbation strategies are only valuable if the perturbations are not\ndetectable. In this paper we investigate to which extent the distortion metrics\nproposed in the literature for audio adversarial examples, and which are\ncommonly applied to evaluate the effectiveness of methods for generating these\nattacks, are a reliable measure of the human perception of the perturbations.\nUsing an analytical framework, and an experiment in which 18 subjects evaluate\naudio adversarial examples, we demonstrate that the metrics employed by\nconvention are not a reliable measure of the perceptual similarity of\nadversarial examples in the audio domain.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:56:50 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 14:27:20 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""]]}, {"id": "2001.08450", "submitter": "Yu-Tung Liu", "authors": "Yu-Tung Liu, Tzi-Dar Chiueh", "title": "Low-Complexity LSTM Training and Inference with FloatSD8 Weight\n  Representation", "comments": "Submitted to International Joint Conference on Neural Networks\n  (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FloatSD technology has been shown to have excellent performance on\nlow-complexity convolutional neural networks (CNNs) training and inference. In\nthis paper, we applied FloatSD to recurrent neural networks (RNNs),\nspecifically long short-term memory (LSTM). In addition to FloatSD weight\nrepresentation, we quantized the gradients and activations in model training to\n8 bits. Moreover, the arithmetic precision for accumulations and the master\ncopy of weights were reduced from 32 bits to 16 bits. We demonstrated that the\nproposed training scheme can successfully train several LSTM models from\nscratch, while fully preserving model accuracy. Finally, to verify the proposed\nmethod's advantage in implementation, we designed an LSTM neuron circuit and\nshowed that it achieved significantly reduced die area and power consumption.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 11:17:48 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liu", "Yu-Tung", ""], ["Chiueh", "Tzi-Dar", ""]]}, {"id": "2001.08456", "submitter": "Aviad Aberdam", "authors": "Aviad Aberdam, Alona Golts, Michael Elad", "title": "Ada-LISTA: Learned Solvers Adaptive to Varying Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks that are based on unfolding of an iterative solver, such as\nLISTA (learned iterative soft threshold algorithm), are widely used due to\ntheir accelerated performance. Nevertheless, as opposed to non-learned solvers,\nthese networks are trained on a certain dictionary, and therefore they are\ninapplicable for varying model scenarios. This work introduces an adaptive\nlearned solver, termed Ada-LISTA, which receives pairs of signals and their\ncorresponding dictionaries as inputs, and learns a universal architecture to\nserve them all. We prove that this scheme is guaranteed to solve sparse coding\nin linear rate for varying models, including dictionary perturbations and\npermutations. We also provide an extensive numerical study demonstrating its\npractical adaptation capabilities. Finally, we deploy Ada-LISTA to natural\nimage inpainting, where the patch-masks vary spatially, thus requiring such an\nadaptation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 11:34:03 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:28:35 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Aberdam", "Aviad", ""], ["Golts", "Alona", ""], ["Elad", "Michael", ""]]}, {"id": "2001.08477", "submitter": "G C Nandi", "authors": "Mridul Mahajan, Tryambak Bhattacharjee, Arya Krishnan, Priya Shukla\n  and G C Nandi", "title": "Semi-supervised Grasp Detection by Representation Learning in a Vector\n  Quantized Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a robot to perform complex manipulation tasks, it is necessary for it to\nhave a good grasping ability. However, vision based robotic grasp detection is\nhindered by the unavailability of sufficient labelled data. Furthermore, the\napplication of semi-supervised learning techniques to grasp detection is\nunder-explored. In this paper, a semi-supervised learning based grasp detection\napproach has been presented, which models a discrete latent space using a\nVector Quantized Variational AutoEncoder (VQ-VAE). To the best of our\nknowledge, this is the first time a Variational AutoEncoder (VAE) has been\napplied in the domain of robotic grasp detection. The VAE helps the model in\ngeneralizing beyond the Cornell Grasping Dataset (CGD) despite having a limited\namount of labelled data by also utilizing the unlabelled data. This claim has\nbeen validated by testing the model on images, which are not available in the\nCGD. Along with this, we augment the Generative Grasping Convolutional Neural\nNetwork (GGCNN) architecture with the decoder structure used in the VQ-VAE\nmodel with the intuition that it should help to regress in the vector-quantized\nlatent space. Subsequently, the model performs significantly better than the\nexisting approaches which do not make use of unlabelled images to improve the\ngrasp.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 12:47:13 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 06:41:33 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 05:50:35 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mahajan", "Mridul", ""], ["Bhattacharjee", "Tryambak", ""], ["Krishnan", "Arya", ""], ["Shukla", "Priya", ""], ["Nandi", "G C", ""]]}, {"id": "2001.08533", "submitter": "Fariba Zohrizadeh", "authors": "Mohsen Kheirandishfard, Fariba Zohrizadeh, Farhad Kamangar", "title": "Multi-Level Representation Learning for Deep Subspace Clustering", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep subspace clustering approach which uses\nconvolutional autoencoders to transform input images into new representations\nlying on a union of linear subspaces. The first contribution of our work is to\ninsert multiple fully-connected linear layers between the encoder layers and\ntheir corresponding decoder layers to promote learning more favorable\nrepresentations for subspace clustering. These connection layers facilitate the\nfeature learning procedure by combining low-level and high-level information\nfor generating multiple sets of self-expressive and informative representations\nat different levels of the encoder. Moreover, we introduce a novel loss\nminimization problem which leverages an initial clustering of the samples to\neffectively fuse the multi-level representations and recover the underlying\nsubspaces more accurately. The loss function is then minimized through an\niterative scheme which alternatively updates the network parameters and\nproduces new clusterings of the samples. Experiments on four real-world\ndatasets demonstrate that our approach exhibits superior performance compared\nto the state-of-the-art methods on most of the subspace clustering problems.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 23:29:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kheirandishfard", "Mohsen", ""], ["Zohrizadeh", "Fariba", ""], ["Kamangar", "Farhad", ""]]}, {"id": "2001.08537", "submitter": "Weijun Xie", "authors": "Yongchun Li, Weijun Xie", "title": "Best Principal Submatrix Selection for the Maximum Entropy Sampling\n  Problem: Scalable Algorithms and Performance Guarantees", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a classic maximum entropy sampling problem (MESP), which\naims to select the most informative principal submatrix of a prespecified size\nfrom a covariance matrix. MESP has been widely applied to many areas, including\nhealthcare, power system, manufacturing and data science. By investigating its\nLagrangian dual and primal characterization, we derive a novel convex integer\nprogram for MESP and show that its continuous relaxation yields a near-optimal\nsolution. The results motivate us to study an efficient sampling algorithm and\ndevelop its approximation bound for MESP, which improves the best-known bound\nin literature. We then provide an efficient deterministic implementation of the\nsampling algorithm with the same approximation bound. By developing new\nmathematical tools for the singular matrices and analyzing the Lagrangian dual\nof the proposed convex integer program, we investigate the widely-used local\nsearch algorithm and prove its first-known approximation bound for MESP. The\nproof techniques further inspire us with an efficient implementation of the\nlocal search algorithm. Our numerical experiments demonstrate that these\napproximation algorithms can efficiently solve medium-sized and large-scale\ninstances to near-optimality. Our proposed algorithms are coded and released as\nopen-source software. Finally, we extend the analyses to the A-Optimal MESP\n(A-MESP), where the objective is to minimize the trace of the inverse of the\nselected principal submatrix.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:14:18 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Li", "Yongchun", ""], ["Xie", "Weijun", ""]]}, {"id": "2001.08559", "submitter": "Zehao Wang", "authors": "Zehao Wang, Kaili Wang, Tinne Tuytelaars, Jose Oramas", "title": "Information Compensation for Deep Conditional Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, unsupervised/weakly-supervised conditional generative\nadversarial networks (GANs) have achieved many successes on the task of\nmodeling and generating data. However, one of their weaknesses lies in their\npoor ability to separate, or disentangle, the different factors that\ncharacterize the representation encoded in their latent space. To address this\nissue, we propose a novel structure for unsupervised conditional GANs powered\nby a novel Information Compensation Connection (IC-Connection). The proposed\nIC-Connection enables GANs to compensate for information loss incurred during\ndeconvolution operations. In addition, to quantify the degree of\ndisentanglement on both discrete and continuous latent variables, we design a\nnovel evaluation procedure. Our empirical results suggest that our method\nachieves better disentanglement compared to the state-of-the-art GANs in a\nconditional generation setting.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:39:53 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 12:00:10 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Wang", "Zehao", ""], ["Wang", "Kaili", ""], ["Tuytelaars", "Tinne", ""], ["Oramas", "Jose", ""]]}, {"id": "2001.08570", "submitter": "Nathaniel Braman", "authors": "Nathaniel Braman, Mohammed El Adoui, Manasa Vulchi, Paulette Turk,\n  Maryam Etesami, Pingfu Fu, Kaustav Bera, Stylianos Drisis, Vinay Varadan,\n  Donna Plecha, Mohammed Benjelloun, Jame Abraham, Anant Madabhushi", "title": "Deep learning-based prediction of response to HER2-targeted neoadjuvant\n  chemotherapy from pre-treatment dynamic breast MRI: A multi-institutional\n  validation study", "comments": "Braman and El Adoui contributed equally to this work. 33 pages, 3\n  figures in main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting response to neoadjuvant therapy is a vexing challenge in breast\ncancer. In this study, we evaluate the ability of deep learning to predict\nresponse to HER2-targeted neo-adjuvant chemotherapy (NAC) from pre-treatment\ndynamic contrast-enhanced (DCE) MRI acquired prior to treatment. In a\nretrospective study encompassing DCE-MRI data from a total of 157 HER2+ breast\ncancer patients from 5 institutions, we developed and validated a deep learning\napproach for predicting pathological complete response (pCR) to HER2-targeted\nNAC prior to treatment. 100 patients who received HER2-targeted neoadjuvant\nchemotherapy at a single institution were used to train (n=85) and tune (n=15)\na convolutional neural network (CNN) to predict pCR. A multi-input CNN\nleveraging both pre-contrast and late post-contrast DCE-MRI acquisitions was\nidentified to achieve optimal response prediction within the validation set\n(AUC=0.93). This model was then tested on two independent testing cohorts with\npre-treatment DCE-MRI data. It achieved strong performance in a 28 patient\ntesting set from a second institution (AUC=0.85, 95% CI 0.67-1.0, p=.0008) and\na 29 patient multicenter trial including data from 3 additional institutions\n(AUC=0.77, 95% CI 0.58-0.97, p=0.006). Deep learning-based response prediction\nmodel was found to exceed a multivariable model incorporating predictive\nclinical variables (AUC < .65 in testing cohorts) and a model of\nsemi-quantitative DCE-MRI pharmacokinetic measurements (AUC < .60 in testing\ncohorts). The results presented in this work across multiple sites suggest that\nwith further validation deep learning could provide an effective and reliable\ntool to guide targeted therapy in breast cancer, thus reducing overtreatment\namong HER2+ patients.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 17:54:24 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Braman", "Nathaniel", ""], ["Adoui", "Mohammed El", ""], ["Vulchi", "Manasa", ""], ["Turk", "Paulette", ""], ["Etesami", "Maryam", ""], ["Fu", "Pingfu", ""], ["Bera", "Kaustav", ""], ["Drisis", "Stylianos", ""], ["Varadan", "Vinay", ""], ["Plecha", "Donna", ""], ["Benjelloun", "Mohammed", ""], ["Abraham", "Jame", ""], ["Madabhushi", "Anant", ""]]}, {"id": "2001.08572", "submitter": "Zengjie Song", "authors": "Zengjie Song, Oluwasanmi Koyejo, Jiangshe Zhang", "title": "Toward a Controllable Disentanglement Network", "comments": "Improved version of arXiv:1912.11675", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses two crucial problems of learning disentangled image\nrepresentations, namely controlling the degree of disentanglement during image\nediting, and balancing the disentanglement strength and the reconstruction\nquality. To encourage disentanglement, we devise a distance covariance based\ndecorrelation regularization. Further, for the reconstruction step, our model\nleverages a soft target representation combined with the latent image code. By\nexploring the real-valued space of the soft target representation, we are able\nto synthesize novel images with the designated properties. To improve the\nperceptual quality of images generated by autoencoder (AE)-based models, we\nextend the encoder-decoder architecture with the generative adversarial network\n(GAN) by collapsing the AE decoder and the GAN generator into one. We also\ndesign a classification based protocol to quantitatively evaluate the\ndisentanglement strength of our model. Experimental results showcase the\nbenefits of the proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:54:07 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 06:13:18 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 04:02:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Song", "Zengjie", ""], ["Koyejo", "Oluwasanmi", ""], ["Zhang", "Jiangshe", ""]]}, {"id": "2001.08582", "submitter": "Sevgi Zubeyde Gurbuz", "authors": "Baris Erol, Sevgi Zubeyde Gurbuz, Moeness G. Amin", "title": "Motion Classification using Kinematically Sifted ACGAN-Synthesized Radar\n  Micro-Doppler Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have recently received vast attention in\napplications requiring classification of radar returns, including radar-based\nhuman activity recognition for security, smart homes, assisted living, and\nbiomedicine. However,acquiring a sufficiently large training dataset remains a\ndaunting task due to the high human costs and resources required for radar data\ncollection. In this paper, an extended approach to adversarial learning is\nproposed for generation of synthetic radar micro-Doppler signatures that are\nwell-adapted to different environments. The synthetic data is evaluated using\nvisual interpretation, analysis of kinematic consistency, data diversity,\ndimensions of the latent space, and saliency maps. A principle-component\nanalysis (PCA) based kinematic-sifting algorithm is introduced to ensure that\nsynthetic signatures are consistent with physically possible human motions. The\nsynthetic dataset is used to train a 19-layer deep convolutional neural network\n(DCNN) to classify micro-Doppler signatures acquired from an environment\ndifferent from that of the dataset supplied to the adversarial network. An\noverall accuracy 93% is achieved on a dataset that contains multiple aspect\nangles (0 deg., 30 deg., and 45 deg. as well as 60 deg.), with 9% improvement\nas a result of kinematic sifting.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 16:50:10 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Erol", "Baris", ""], ["Gurbuz", "Sevgi Zubeyde", ""], ["Amin", "Moeness G.", ""]]}, {"id": "2001.08583", "submitter": "Amir Mosavi Prof", "authors": "Nader Karballaeezadeh, Farah Zaremotekhases, Shahaboddin Shamshirband,\n  Amir Mosavi, Narjes Nabipour, Peter Csiba, Annamaria R. Varkonyi-Koczy", "title": "Intelligent Road Inspection with Advanced Machine Learning; Hybrid\n  Prediction Models for Smart Mobility and Transportation Maintenance Systems", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction models in mobility and transportation maintenance systems have\nbeen dramatically improved through using machine learning methods. This paper\nproposes novel machine learning models for intelligent road inspection. The\ntraditional road inspection systems based on the pavement condition index (PCI)\nare often associated with the critical safety, energy and cost issues.\nAlternatively, the proposed models utilize surface deflection data from falling\nweight deflectometer (FWD) tests to predict the PCI. Machine learning methods\nare the single multi-layer perceptron (MLP) and radial basis function (RBF)\nneural networks as well as their hybrids, i.e., Levenberg-Marquardt (MLP-LM),\nscaled conjugate gradient (MLP-SCG), imperialist competitive (RBF-ICA), and\ngenetic algorithms (RBF-GA). Furthermore, the committee machine intelligent\nsystems (CMIS) method was adopted to combine the results and improve the\naccuracy of the modeling. The results of the analysis have been verified\nthrough using four criteria of average percent relative error (APRE), average\nabsolute percent relative error (AAPRE), root mean square error (RMSE), and\nstandard error (SD). The CMIS model outperforms other models with the promising\nresults of APRE=2.3303, AAPRE=11.6768, RMSE=12.0056, and SD=0.0210.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 19:12:51 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Karballaeezadeh", "Nader", ""], ["Zaremotekhases", "Farah", ""], ["Shamshirband", "Shahaboddin", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Csiba", "Peter", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "2001.08600", "submitter": "Anbu Huang", "authors": "Anbu Huang, Yuanyuan Chen, Yang Liu, Tianjian Chen, and Qiang Yang", "title": "RPN: A Residual Pooling Network for Efficient Federated Learning", "comments": "Accepted by the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed machine learning framework which enables\ndifferent parties to collaboratively train a model while protecting data\nprivacy and security. Due to model complexity, network unreliability and\nconnection in-stability, communication cost has became a major bottleneck for\napplying federated learning to real-world applications. Current existing\nstrategies are either need to manual setting for hyperparameters, or break up\nthe original process into multiple steps, which make it hard to realize\nend-to-end implementation. In this paper, we propose a novel compression\nstrategy called Residual Pooling Network (RPN). Our experiments show that RPN\nnot only reduce data transmission effectively, but also achieve almost the same\nperformance as compared to standard federated learning. Our new approach\nperforms as an end-to-end procedure, which should be readily applied to all\nCNN-based model training scenarios for improvement of communication efficiency,\nand hence make it easy to deploy in real-world application without much human\nintervention.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:30:56 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 00:15:52 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Huang", "Anbu", ""], ["Chen", "Yuanyuan", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Yang", "Qiang", ""]]}, {"id": "2001.08606", "submitter": "Han Wu", "authors": "Han Wu, Kun Zhang, Guangyi Lv, Qi Liu, Runlong Yu, Weihao Zhao, Enhong\n  Chen and Jianhui Ma", "title": "Deep Technology Tracing for High-tech Companies", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": "10.1109/ICDM.2019.00180", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological change and innovation are vitally important, especially for\nhigh-tech companies. However, factors influencing their future research and\ndevelopment (R&D) trends are both complicated and various, leading it a quite\ndifficult task to make technology tracing for high-tech companies. To this end,\nin this paper, we develop a novel data-driven solution, i.e., Deep Technology\nForecasting (DTF) framework, to automatically find the most possible technology\ndirections customized to each high-tech company. Specially, DTF consists of\nthree components: Potential Competitor Recognition (PCR), Collaborative\nTechnology Recognition (CTR), and Deep Technology Tracing (DTT) neural network.\nFor one thing, PCR and CTR aim to capture competitive relations among\nenterprises and collaborative relations among technologies, respectively. For\nanother, DTT is designed for modeling dynamic interactions between companies\nand technologies with the above relations involved. Finally, we evaluate our\nDTF framework on real-world patent data, and the experimental results clearly\nprove that DTF can precisely help to prospect future technology emphasis of\ncompanies by exploiting hybrid factors.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 07:44:12 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wu", "Han", ""], ["Zhang", "Kun", ""], ["Lv", "Guangyi", ""], ["Liu", "Qi", ""], ["Yu", "Runlong", ""], ["Zhao", "Weihao", ""], ["Chen", "Enhong", ""], ["Ma", "Jianhui", ""]]}, {"id": "2001.08618", "submitter": "Bence Keresztury", "authors": "Bence Keresztury and Elia Bruni", "title": "Compositional properties of emergent languages in deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in multi-agent deep learning systems point towards the\nemergence of compositional languages. These claims are often made without exact\nanalysis or testing of the language. In this work, we analyze the emergent\nlanguage resulting from two different cooperative multi-agent game with more\nexact measures for compositionality. Our findings suggest that solutions found\nby deep learning models are often lacking the ability to reason on an abstract\nlevel therefore failing to generalize the learned knowledge to out of the\ntraining distribution examples. Strategies for testing compositional capacities\nand emergence of human-level concepts are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:55:36 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Keresztury", "Bence", ""], ["Bruni", "Elia", ""]]}, {"id": "2001.08650", "submitter": "Gobinda Saha", "authors": "Gobinda Saha, Isha Garg, Aayush Ankit and Kaushik Roy", "title": "SPACE: Structured Compression and Sharing of Representational Space for\n  Continual Learning", "comments": "The first two authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans learn adaptively and efficiently throughout their lives. However,\nincrementally learning tasks causes artificial neural networks to overwrite\nrelevant information learned about older tasks, resulting in 'Catastrophic\nForgetting'. Efforts to overcome this phenomenon often utilize resources\npoorly, for instance, by growing the network architecture or needing to save\nparametric importance scores, or violate data privacy between tasks. To tackle\nthis, we propose SPACE, an algorithm that enables a network to learn\ncontinually and efficiently by partitioning the learnt space into a Core space,\nthat serves as the condensed knowledge base over previously learned tasks, and\na Residual space, which is akin to a scratch space for learning the current\ntask. After learning each task, the Residual is analyzed for redundancy, both\nwithin itself and with the learnt Core space. A minimal number of extra\ndimensions required to explain the current task are added to the Core space and\nthe remaining Residual is freed up for learning the next task. We evaluate our\nalgorithm on P-MNIST, CIFAR and a sequence of 8 different datasets, and achieve\ncomparable accuracy to the state-of-the-art methods while overcoming\ncatastrophic forgetting. Additionally, our algorithm is well suited for\npractical use. The partitioning algorithm analyzes all layers in one shot,\nensuring scalability to deeper networks. Moreover, the analysis of dimensions\ntranslates to filter-level sparsity, and the structured nature of the resulting\narchitecture gives us up to 5x improvement in energy efficiency during task\ninference over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:40:56 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:02:50 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 15:22:00 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 06:23:33 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Saha", "Gobinda", ""], ["Garg", "Isha", ""], ["Ankit", "Aayush", ""], ["Roy", "Kaushik", ""]]}, {"id": "2001.08655", "submitter": "Zixin Zhong", "authors": "Zixin Zhong, Wang Chi Cheung, and Vincent Y. F. Tan", "title": "Best Arm Identification for Cascading Bandits in the Fixed Confidence\n  Setting", "comments": "39 pages, 25 figures. Proceedings of the 37th International\n  Conference on Machine Learning (ICML), Vienna, Austria, PMLR 108, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and analyze CascadeBAI, an algorithm for finding the best set of\n$K$ items, also called an arm, within the framework of cascading bandits. An\nupper bound on the time complexity of CascadeBAI is derived by overcoming a\ncrucial analytical challenge, namely, that of probabilistically estimating the\namount of available feedback at each step. To do so, we define a new class of\nrandom variables (r.v.'s) which we term as left-sided sub-Gaussian r.v.'s;\nthese are r.v.'s whose cumulant generating functions (CGFs) can be bounded by a\nquadratic only for non-positive arguments of the CGFs. This enables the\napplication of a sufficiently tight Bernstein-type concentration inequality. We\nshow, through the derivation of a lower bound on the time complexity, that the\nperformance of CascadeBAI is optimal in some practical regimes. Finally,\nextensive numerical simulations corroborate the efficacy of CascadeBAI as well\nas the tightness of our upper bound on its time complexity.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:47:52 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 04:03:09 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 16:26:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhong", "Zixin", ""], ["Cheung", "Wang Chi", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2001.08677", "submitter": "Diego Pinheiro", "authors": "Paulo Rocha, Diego Pinheiro, Martin Cadeiras, Carmelo Bastos-Filho", "title": "Towards Automatic Clustering Analysis using Traces of Information Gain:\n  The InfoGuide Method", "comments": "The 33rd International FLAIRS Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering analysis has become a ubiquitous information retrieval tool in a\nwide range of domains, but a more automatic framework is still lacking. Though\ninternal metrics are the key players towards a successful retrieval of\nclusters, their effectiveness on real-world datasets remains not fully\nunderstood, mainly because of their unrealistic assumptions underlying\ndatasets. We hypothesized that capturing {\\it traces of information gain}\nbetween increasingly complex clustering retrievals---{\\it InfoGuide}---enables\nan automatic clustering analysis with improved clustering retrievals. We\nvalidated the {\\it InfoGuide} hypothesis by capturing the traces of information\ngain using the Kolmogorov-Smirnov statistic and comparing the clusters\nretrieved by {\\it InfoGuide} against those retrieved by other commonly used\ninternal metrics in artificially-generated, benchmarks, and real-world\ndatasets. Our results suggested that {\\it InfoGuide} can enable a more\nautomatic clustering analysis and may be more suitable for retrieving clusters\nin real-world datasets displaying nontrivial statistical properties.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:19:29 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Rocha", "Paulo", ""], ["Pinheiro", "Diego", ""], ["Cadeiras", "Martin", ""], ["Bastos-Filho", "Carmelo", ""]]}, {"id": "2001.08682", "submitter": "Philipp Becker", "authors": "Philipp Becker, Oleg Arenz, Gerhard Neumann", "title": "Expected Information Maximization: Using the I-Projection for Mixture\n  Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling highly multi-modal data is a challenging problem in machine\nlearning. Most algorithms are based on maximizing the likelihood, which\ncorresponds to the M(oment)-projection of the data distribution to the model\ndistribution. The M-projection forces the model to average over modes it cannot\nrepresent. In contrast, the I(information)-projection ignores such modes in the\ndata and concentrates on the modes the model can represent. Such behavior is\nappealing whenever we deal with highly multi-modal data where modelling single\nmodes correctly is more important than covering all the modes. Despite this\nadvantage, the I-projection is rarely used in practice due to the lack of\nalgorithms that can efficiently optimize it based on data. In this work, we\npresent a new algorithm called Expected Information Maximization (EIM) for\ncomputing the I-projection solely based on samples for general latent variable\nmodels, where we focus on Gaussian mixtures models and Gaussian mixtures of\nexperts. Our approach applies a variational upper bound to the I-projection\nobjective which decomposes the original objective into single objectives for\neach mixture component as well as for the coefficients, allowing an efficient\noptimization. Similar to GANs, our approach employs discriminators but uses a\nmore stable optimization procedure, using a tight upper bound. We show that our\nalgorithm is much more effective in computing the I-projection than recent GAN\napproaches and we illustrate the effectiveness of our approach for modelling\nmulti-modal behavior on two pedestrian and traffic prediction datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:24:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Becker", "Philipp", ""], ["Arenz", "Oleg", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2001.08699", "submitter": "Aaron Defazio", "authors": "Aaron Defazio and Tullie Murrell and Michael P. Recht", "title": "MRI Banding Removal via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  MRI images reconstructed from sub-sampled Cartesian data using deep learning\ntechniques often show a characteristic banding (sometimes described as\nstreaking), which is particularly strong in low signal-to-noise regions of the\nreconstructed image. In this work, we propose the use of an adversarial loss\nthat penalizes banding structures without requiring any human annotation. Our\ntechnique greatly reduces the appearance of banding, without requiring any\nadditional computation or post-processing at reconstruction time. We report the\nresults of a blind comparison against a strong baseline by a group of expert\nevaluators (board-certified radiologists), where our approach is ranked\nsuperior at banding removal with no statistically significant loss of detail.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:46:14 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:15:01 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 15:54:45 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Defazio", "Aaron", ""], ["Murrell", "Tullie", ""], ["Recht", "Michael P.", ""]]}, {"id": "2001.08741", "submitter": "Leihao Wei", "authors": "Leihao Wei and Yannan Lin and William Hsu", "title": "Using a Generative Adversarial Network for CT Normalization and its\n  Impact on Radiomic Features", "comments": "ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-Aided-Diagnosis (CADx) systems assist radiologists with identifying\nand classifying potentially malignant pulmonary nodules on chest CT scans using\nmorphology and texture-based (radiomic) features. However, radiomic features\nare sensitive to differences in acquisitions due to variations in dose levels\nand slice thickness. This study investigates the feasibility of generating a\nnormalized scan from heterogeneous CT scans as input. We obtained projection\ndata from 40 low-dose chest CT scans, simulating acquisitions at 10%, 25% and\n50% dose and reconstructing the scans at 1.0mm and 2.0mm slice thickness. A 3D\ngenerative adversarial network (GAN) was used to simultaneously normalize\nreduced dose, thick slice (2.0mm) images to normal dose (100%), thinner slice\n(1.0mm) images. We evaluated the normalized image quality using peak\nsignal-to-noise ratio (PSNR), structural similarity index (SSIM) and Learned\nPerceptual Image Patch Similarity (LPIPS). Our GAN improved perceptual\nsimilarity by 35%, compared to a baseline CNN method. Our analysis also shows\nthat the GAN-based approach led to a significantly smaller error (p-value <\n0.05) in nine studied radiomic features. These results indicated that GANs\ncould be used to normalize heterogeneous CT images and reduce the variability\nin radiomic feature values.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 23:41:29 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Wei", "Leihao", ""], ["Lin", "Yannan", ""], ["Hsu", "William", ""]]}, {"id": "2001.08743", "submitter": "Byung Hoon Ahn", "authors": "Byung Hoon Ahn, Prannoy Pilligundla, Amir Yazdanbakhsh, Hadi\n  Esmaeilzadeh", "title": "Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network\n  Compilation", "comments": "Published as a conference paper at ICLR 2020. arXiv admin note: text\n  overlap with arXiv:1905.12799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving faster execution with shorter compilation time can foster further\ndiversity and innovation in neural networks. However, the current paradigm of\nexecuting neural networks either relies on hand-optimized libraries,\ntraditional compilation heuristics, or very recently genetic algorithms and\nother stochastic methods. These methods suffer from frequent costly hardware\nmeasurements rendering them not only too time consuming but also suboptimal. As\nsuch, we devise a solution that can learn to quickly adapt to a previously\nunseen design space for code optimization, both accelerating the search and\nimproving the output performance. This solution dubbed Chameleon leverages\nreinforcement learning whose solution takes fewer steps to converge, and\ndevelops an adaptive sampling algorithm that not only focuses on the costly\nsamples (real hardware measurements) on representative points but also uses a\ndomain-knowledge inspired logic to improve the samples itself. Experimentation\nwith real hardware shows that Chameleon provides 4.45x speed up in optimization\ntime over AutoTVM, while also improving inference time of the modern deep\nnetworks by 5.6%.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 20:42:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ahn", "Byung Hoon", ""], ["Pilligundla", "Prannoy", ""], ["Yazdanbakhsh", "Amir", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2001.08747", "submitter": "Max Daniels", "authors": "Max Daniels, Paul Hand, Reinhard Heckel", "title": "Reducing the Representation Error of GAN Image Priors Using the Deep\n  Decoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models, such as GANs, learn an explicit low-dimensional\nrepresentation of a particular class of images, and so they may be used as\nnatural image priors for solving inverse problems such as image restoration and\ncompressive sensing. GAN priors have demonstrated impressive performance on\nthese tasks, but they can exhibit substantial representation error for both\nin-distribution and out-of-distribution images, because of the mismatch between\nthe learned, approximate image distribution and the data generating\ndistribution. In this paper, we demonstrate a method for reducing the\nrepresentation error of GAN priors by modeling images as the linear combination\nof a GAN prior with a Deep Decoder. The deep decoder is an underparameterized\nand most importantly unlearned natural signal model similar to the Deep Image\nPrior. No knowledge of the specific inverse problem is needed in the training\nof the GAN underlying our method. For compressive sensing and image\nsuperresolution, our hybrid model exhibits consistently higher PSNRs than both\nthe GAN priors and Deep Decoder separately, both on in-distribution and\nout-of-distribution images. This model provides a method for extensibly and\ncheaply leveraging both the benefits of learned and unlearned image recovery\npriors in inverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:37:24 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Daniels", "Max", ""], ["Hand", "Paul", ""], ["Heckel", "Reinhard", ""]]}, {"id": "2001.08785", "submitter": "Marjan Ghazvininejad", "authors": "Marjan Ghazvininejad, Omer Levy, Luke Zettlemoyer", "title": "Semi-Autoregressive Training Improves Mask-Predict Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed mask-predict decoding algorithm has narrowed the\nperformance gap between semi-autoregressive machine translation models and the\ntraditional left-to-right approach. We introduce a new training method for\nconditional masked language models, SMART, which mimics the semi-autoregressive\nbehavior of mask-predict, producing training examples that contain model\npredictions as part of their inputs. Models trained with SMART produce\nhigher-quality translations when using mask-predict decoding, effectively\nclosing the remaining performance gap with fully autoregressive models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:56:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ghazvininejad", "Marjan", ""], ["Levy", "Omer", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2001.08809", "submitter": "Kursat Rasim Mestav", "authors": "Kursat Rasim Mestav, Lang Tong", "title": "Universal Data Anomaly Detection via Inverse Generative Adversary\n  Network", "comments": "5 pages, letter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting data anomaly is considered. Under the null\nhypothesis that models anomaly-free data, measurements are assumed to be from\nan unknown distribution with some authenticated historical samples. Under the\ncomposite alternative hypothesis, measurements are from an unknown distribution\npositive distance away from the distribution under the null hypothesis. No\ntraining data are available for the distribution of anomaly data. A\nsemi-supervised deep learning technique based on an inverse generative\nadversary network is proposed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:11:36 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Mestav", "Kursat Rasim", ""], ["Tong", "Lang", ""]]}, {"id": "2001.08817", "submitter": "Evan Schwab", "authors": "Evan Schwab, Andr\\'e Goo{\\ss}en, Hrishikesh Deshpande, Axel Saalbach", "title": "Localization of Critical Findings in Chest X-Ray without Local\n  Annotations Using Multi-Instance Learning", "comments": "Accepted to International Symposium of Biomedical Imaging (ISBI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of critical findings in chest X-rays (CXR), such as\npneumothorax, is important for assisting radiologists in their clinical\nworkflow like triaging time-sensitive cases and screening for incidental\nfindings. While deep learning (DL) models has become a promising predictive\ntechnology with near-human accuracy, they commonly suffer from a lack of\nexplainability, which is an important aspect for clinical deployment of DL\nmodels in the highly regulated healthcare industry. For example, localizing\ncritical findings in an image is useful for explaining the predictions of DL\nclassification algorithms. While there have been a host of joint classification\nand localization methods for computer vision, the state-of-the-art DL models\nrequire locally annotated training data in the form of pixel level labels or\nbounding box coordinates. In the medical domain, this requires an expensive\namount of manual annotation by medical experts for each critical finding. This\nrequirement becomes a major barrier for training models that can rapidly scale\nto various findings. In this work, we address these shortcomings with an\ninterpretable DL algorithm based on multi-instance learning that jointly\nclassifies and localizes critical findings in CXR without the need for local\nannotations. We show competitive classification results on three different\ncritical findings (pneumothorax, pneumonia, and pulmonary edema) from three\ndifferent CXR datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:29:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Schwab", "Evan", ""], ["Goo\u00dfen", "Andr\u00e9", ""], ["Deshpande", "Hrishikesh", ""], ["Saalbach", "Axel", ""]]}, {"id": "2001.08837", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Matthew Hausknecht", "title": "Graph Constrained Reinforcement Learning for Natural Language Action\n  Spaces", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Fiction games are text-based simulations in which an agent\ninteracts with the world purely through natural language. They are ideal\nenvironments for studying how to extend reinforcement learning agents to meet\nthe challenges of natural language understanding, partial observability, and\naction generation in combinatorially-large text-based action spaces. We present\nKG-A2C, an agent that builds a dynamic knowledge graph while exploring and\ngenerates actions using a template-based action space. We contend that the dual\nuses of the knowledge graph to reason about game state and to constrain natural\nlanguage generation are the keys to scalable exploration of combinatorially\nlarge natural language actions. Results across a wide variety of IF games show\nthat KG-A2C outperforms current IF agents despite the exponential increase in\naction space size.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:33:18 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "2001.08841", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Sima Azizi, Mohammadamir Kavousi, and Donald Wunsch", "title": "Autonomous Control of a Line Follower Robot Using a Q-Learning\n  Controller", "comments": "Accepted paper in IEEE CCWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a MIMO simulated annealing SA based Q learning method is\nproposed to control a line follower robot. The conventional controller for\nthese types of robots is the proportional P controller. Considering the unknown\nmechanical characteristics of the robot and uncertainties such as friction and\nslippery surfaces, system modeling and controller designing can be extremely\nchallenging. The mathematical modeling for the robot is presented in this\npaper, and a simulator is designed based on this model. The basic Q learning\nmethods are based pure exploitation and the epsilon-greedy methods, which help\nexploration, can harm the controller performance after learning completion by\nexploring nonoptimal actions. The simulated annealing based Q learning method\ntackles this drawback by decreasing the exploration rate when the learning\nincreases. The simulation and experimental results are provided to evaluate the\neffectiveness of the proposed controller.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:50:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Azizi", "Sima", ""], ["Kavousi", "Mohammadamir", ""], ["Wunsch", "Donald", ""]]}, {"id": "2001.08842", "submitter": "Benjamin Evans", "authors": "Benjamin Patrick Evans, Bing Xue, Mengjie Zhang", "title": "Improving generalisation of AutoML systems with dynamic fitness\n  evaluations", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": "10.1145/3377930.3389805", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem machine learning developers are faced with is overfitting,\nthat is, fitting a pipeline too closely to the training data that the\nperformance degrades for unseen data. Automated machine learning aims to free\n(or at least ease) the developer from the burden of pipeline creation, but this\noverfitting problem can persist. In fact, this can become more of a problem as\nwe look to iteratively optimise the performance of an internal cross-validation\n(most often \\textit{k}-fold). While this internal cross-validation hopes to\nreduce this overfitting, we show we can still risk overfitting to the\nparticular folds used. In this work, we aim to remedy this problem by\nintroducing dynamic fitness evaluations which approximate repeated\n\\textit{k}-fold cross-validation, at little extra cost over single\n\\textit{k}-fold, and far lower cost than typical repeated \\textit{k}-fold. The\nresults show that when time equated, the proposed fitness function results in\nsignificant improvement over the current state-of-the-art baseline method which\nuses an internal single \\textit{k}-fold. Furthermore, the proposed extension is\nvery simple to implement on top of existing evolutionary computation methods,\nand can provide essentially a free boost in generalisation/testing performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:54:54 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.08853", "submitter": "Kijung Shin", "authors": "Jihoon Ko, Kyuhan Lee, Kijung Shin, Noseong Park", "title": "MONSTOR: An Inductive Approach for Estimating and Maximizing Influence\n  over Unseen Networks", "comments": "To appear at the 2020 IEEE/ACM International Conference on Advances\n  in Social Networks Analysis and Mining (ASONAM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization (IM) is one of the most important problems in social\nnetwork analysis. Its objective is to find a given number of seed nodes that\nmaximize the spread of information through a social network. Since it is an\nNP-hard problem, many approximate/heuristic methods have been developed, and a\nnumber of them repeat Monte Carlo (MC) simulations over and over to reliably\nestimate the influence (i.e., the number of infected nodes) of a seed set. In\nthis work, we present an inductive machine learning method, called Monte Carlo\nSimulator (MONSTOR), for estimating the influence of given seed nodes in social\nnetworks unseen during training. To the best of our knowledge, MONSTOR is the\nfirst inductive method for this purpose. MONSTOR can greatly accelerate\nexisting IM algorithms by replacing repeated MC simulations. In our\nexperiments, MONSTOR provided highly accurate estimates, achieving 0.998 or\nhigher Pearson and Spearman correlation coefficients in unseen real-world\nsocial networks. Moreover, IM algorithms equipped with MONSTOR are more\naccurate than state-of-the-art competitors in 63% of IM use cases.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 00:20:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 00:56:42 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 05:38:55 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 17:12:03 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 10:18:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ko", "Jihoon", ""], ["Lee", "Kyuhan", ""], ["Shin", "Kijung", ""], ["Park", "Noseong", ""]]}, {"id": "2001.08873", "submitter": "Penny Chong", "authors": "Penny Chong, Lukas Ruff, Marius Kloft, Alexander Binder", "title": "Simple and Effective Prevention of Mode Collapse in Deep One-Class\n  Classification", "comments": "Accepted in 2020 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207209", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection algorithms find extensive use in various fields. This area\nof research has recently made great advances thanks to deep learning. A recent\nmethod, the deep Support Vector Data Description (deep SVDD), which is inspired\nby the classic kernel-based Support Vector Data Description (SVDD), is capable\nof simultaneously learning a feature representation of the data and a\ndata-enclosing hypersphere. The method has shown promising results in both\nunsupervised and semi-supervised settings. However, deep SVDD suffers from\nhypersphere collapse -- also known as mode collapse, if the architecture of the\nmodel does not comply with certain architectural constraints, e.g. the removal\nof bias terms. These constraints limit the adaptability of the model and in\nsome cases, may affect the model performance due to learning sub-optimal\nfeatures. In this work, we consider two regularizers to prevent hypersphere\ncollapse in deep SVDD. The first regularizer is based on injecting random noise\nvia the standard cross-entropy loss. The second regularizer penalizes the\nminibatch variance when it becomes too small. Moreover, we introduce an\nadaptive weighting scheme to control the amount of penalization between the\nSVDD loss and the respective regularizer. Our proposed regularized variants of\ndeep SVDD show encouraging results and outperform a prominent state-of-the-art\nmethod on a setup where the anomalies have no apparent geometrical structure.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 03:44:47 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 01:51:12 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 09:25:17 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 06:45:48 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chong", "Penny", ""], ["Ruff", "Lukas", ""], ["Kloft", "Marius", ""], ["Binder", "Alexander", ""]]}, {"id": "2001.08876", "submitter": "Suvrit Sra", "authors": "Kwangjun Ahn and Suvrit Sra", "title": "From Nesterov's Estimate Sequence to Riemannian Acceleration", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first global accelerated gradient method for Riemannian\nmanifolds. Toward establishing our result we revisit Nesterov's estimate\nsequence technique and develop an alternative analysis for it that may also be\nof independent interest. Then, we extend this analysis to the Riemannian\nsetting, localizing the key difficulty due to non-Euclidean structure into a\ncertain ``metric distortion.'' We control this distortion by developing a novel\ngeometric inequality, which permits us to propose and analyze a Riemannian\ncounterpart to Nesterov's accelerated gradient method.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:17:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ahn", "Kwangjun", ""], ["Sra", "Suvrit", ""]]}, {"id": "2001.08877", "submitter": "Hongji Wei", "authors": "T. Tony Cai, Hongji Wei", "title": "Distributed Gaussian Mean Estimation under Communication Constraints:\n  Optimal Rates and Communication-Efficient Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed estimation of a Gaussian mean under communication\nconstraints in a decision theoretical framework. Minimax rates of convergence,\nwhich characterize the tradeoff between the communication costs and statistical\naccuracy, are established in both the univariate and multivariate settings.\nCommunication-efficient and statistically optimal procedures are developed. In\nthe univariate case, the optimal rate depends only on the total communication\nbudget, so long as each local machine has at least one bit. However, in the\nmultivariate case, the minimax rate depends on the specific allocations of the\ncommunication budgets among the local machines.\n  Although optimal estimation of a Gaussian mean is relatively simple in the\nconventional setting, it is quite involved under the communication constraints,\nboth in terms of the optimal procedure design and lower bound argument. The\ntechniques developed in this paper can be of independent interest. An essential\nstep is the decomposition of the minimax estimation problem into two stages,\nlocalization and refinement. This critical decomposition provides a framework\nfor both the lower bound analysis and optimal procedure design.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:19:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Cai", "T. Tony", ""], ["Wei", "Hongji", ""]]}, {"id": "2001.08885", "submitter": "Khe Chai Sim", "authors": "Mary Gooneratne, Khe Chai Sim, Petr Zadrazil, Andreas Kabel,\n  Fran\\c{c}oise Beaufays, Giovanni Motta", "title": "Low-rank Gradient Approximation For Memory-Efficient On-device Training\n  of Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models on mobile devices has the potential of\nimproving both privacy and accuracy of the models. However, one of the major\nobstacles to achieving this goal is the memory limitation of mobile devices.\nReducing training memory enables models with high-dimensional weight matrices,\nlike automatic speech recognition (ASR) models, to be trained on-device. In\nthis paper, we propose approximating the gradient matrices of deep neural\nnetworks using a low-rank parameterization as an avenue to save training\nmemory. The low-rank gradient approximation enables more advanced,\nmemory-intensive optimization techniques to be run on device. Our experimental\nresults show that we can reduce the training memory by about 33.0% for Adam\noptimization. It uses comparable memory to momentum optimization and achieves a\n4.5% relative lower word error rate on an ASR personalization task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 05:12:18 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Gooneratne", "Mary", ""], ["Sim", "Khe Chai", ""], ["Zadrazil", "Petr", ""], ["Kabel", "Andreas", ""], ["Beaufays", "Fran\u00e7oise", ""], ["Motta", "Giovanni", ""]]}, {"id": "2001.08886", "submitter": "Luna Zhang", "authors": "Luna M. Zhang", "title": "PairNets: Novel Fast Shallow Artificial Neural Networks on Partitioned\n  Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, an artificial neural network (ANN) is trained slowly by a\ngradient descent algorithm such as the backpropagation algorithm since a large\nnumber of hyperparameters of the ANN need to be fine-tuned with many training\nepochs. To highly speed up training, we created a novel shallow 4-layer ANN\ncalled \"Pairwise Neural Network\" (\"PairNet\") with high-speed hyperparameter\noptimization. In addition, a value of each input is partitioned into multiple\nintervals, and then an n-dimensional space is partitioned into M n-dimensional\nsubspaces. M local PairNets are built in M partitioned local n-dimensional\nsubspaces. A local PairNet is trained very quickly with only one epoch since\nits hyperparameters are directly optimized one-time via simply solving a system\nof linear equations by using the multivariate least squares fitting method.\nSimulation results for three regression problems indicated that the PairNet\nachieved much higher speeds and lower average testing mean squared errors\n(MSEs) for the three cases, and lower average training MSEs for two cases than\nthe traditional ANNs. A significant future work is to develop better and faster\noptimization algorithms based on intelligent methods and parallel computing\nmethods to optimize both partitioned subspaces and hyperparameters to build the\nfast and effective PairNets for applications in big data mining and real-time\nmachine learning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 05:23:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhang", "Luna M.", ""]]}, {"id": "2001.08896", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Paul N. Whatmough, Zhi-Gang Liu, Matthew Mattina,\n  Jesse Beu", "title": "Compressing Language Models using Doped Kronecker Products", "comments": "Link to Workshop\n  (https://research.fb.com/programs/on-device-intelligence-workshop/)", "journal-ref": "Presented at On-device Intelligence Workshop at Third Conference\n  on Machine Learning and Systems (MLSys) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Kronecker Products (KP) have been used to compress IoT RNN Applications by\n15-38x compression factors, achieving better results than traditional\ncompression methods. However when KP is applied to large Natural Language\nProcessing tasks, it leads to significant accuracy loss (approx 26%). This\npaper proposes a way to recover accuracy otherwise lost when applying KP to\nlarge NLP tasks, by allowing additional degrees of freedom in the KP matrix.\nMore formally, we propose doping, a process of adding an extremely sparse\noverlay matrix on top of the pre-defined KP structure. We call this compression\nmethod doped kronecker product compression. To train these models, we present a\nnew solution to the phenomenon of co-matrix adaption (CMA), which uses a new\nregularization scheme called co matrix dropout regularization (CMR). We present\nexperimental results that demonstrate compression of a large language model\nwith LSTM layers of size 25 MB by 25x with 1.4% loss in perplexity score. At\n25x compression, an equivalent pruned network leads to 7.9% loss in perplexity\nscore, while HMD and LMF lead to 15% and 27% loss in perplexity score\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 06:07:21 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 05:36:36 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:58:58 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 07:07:22 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 05:27:00 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Thakker", "Urmish", ""], ["Whatmough", "Paul N.", ""], ["Liu", "Zhi-Gang", ""], ["Mattina", "Matthew", ""], ["Beu", "Jesse", ""]]}, {"id": "2001.08904", "submitter": "Muhammad Khan", "authors": "Muhammad Raza Khan, Morteza Ziyadi and Mohamed AbdelHady", "title": "MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition\n  using Deep Bidirectional Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents such as Cortana, Alexa and Siri are continuously\nworking on increasing their capabilities by adding new domains. The support of\na new domain includes the design and development of a number of NLU components\nfor domain classification, intents classification and slots tagging (including\nnamed entity recognition). Each component only performs well when trained on a\nlarge amount of labeled data. Second, these components are deployed on\nlimited-memory devices which requires some model compression. Third, for some\ndomains such as the health domain, it is hard to find a single training data\nset that covers all the required slot types. To overcome these mentioned\nproblems, we present a multi-task transformer-based neural architecture for\nslot tagging. We consider the training of a slot tagger using multiple data\nsets covering different slot types as a multi-task learning problem. The\nexperimental results on the biomedical domain have shown that the proposed\napproach outperforms the previous state-of-the-art systems for slot tagging on\nthe different benchmark biomedical datasets in terms of (time and memory)\nefficiency and effectiveness. The output slot tagger can be used by the\nconversational agent to better identify entities in the input utterances.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 07:16:32 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Khan", "Muhammad Raza", ""], ["Ziyadi", "Morteza", ""], ["AbdelHady", "Mohamed", ""]]}, {"id": "2001.08922", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "RePAD: Real-time Proactive Anomaly Detection for Time Series", "comments": "12 pages, 8 figures, the 34th International Conference on Advanced\n  Information Networking and Applications (AINA 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-44041-1_110", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decade, many anomaly detection approaches have been\nintroduced in different fields such as network monitoring, fraud detection, and\nintrusion detection. However, they require understanding of data pattern and\noften need a long off-line period to build a model or network for the target\ndata. Providing real-time and proactive anomaly detection for streaming time\nseries without human intervention and domain knowledge is highly valuable since\nit greatly reduces human effort and enables appropriate countermeasures to be\nundertaken before a disastrous damage, failure, or other harmful event occurs.\nHowever, this issue has not been well studied yet. To address it, this paper\nproposes RePAD, which is a Real-time Proactive Anomaly Detection algorithm for\nstreaming time series based on Long Short-Term Memory (LSTM). RePAD utilizes\nshort-term historic data points to predict and determine whether or not the\nupcoming data point is a sign that an anomaly is likely to happen in the near\nfuture. By dynamically adjusting the detection threshold over time, RePAD is\nable to tolerate minor pattern change in time series and detect anomalies\neither proactively or on time. Experiments based on two time series datasets\ncollected from the Numenta Anomaly Benchmark demonstrate that RePAD is able to\nproactively detect anomalies and provide early warnings in real time without\nhuman intervention and domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:13:33 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 10:05:32 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 13:48:49 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2001.08943", "submitter": "Max Berrendorf", "authors": "Max Berrendorf and Evgeniy Faerman and Volker Tresp", "title": "Active Learning for Entity Alignment", "comments": "to be published in ECIR'21; fix typo and add acknowledgement", "journal-ref": null, "doi": "10.1007/978-3-030-72113-8_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel framework for the labeling of entity\nalignments in knowledge graph datasets. Different strategies to select\ninformative instances for the human labeler build the core of our framework. We\nillustrate how the labeling of entity alignments is different from assigning\nclass labels to single instances and how these differences affect the labeling\nefficiency. Based on these considerations we propose and evaluate different\nactive and passive learning strategies. One of our main findings is that\npassive learning approaches, which can be efficiently precomputed and deployed\nmore easily, achieve performance comparable to the active learning strategies.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 10:33:08 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:16:03 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 15:10:00 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.08950", "submitter": "Saurabh Goyal", "authors": "Saurabh Goyal, Anamitra R. Choudhury, Saurabh M. Raje, Venkatesan T.\n  Chakaravarthy, Yogish Sabharwal, Ashish Verma", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector\n  Elimination", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel method, called PoWER-BERT, for improving the inference\ntime of the popular BERT model, while maintaining the accuracy. It works by: a)\nexploiting redundancy pertaining to word-vectors (intermediate encoder outputs)\nand eliminating the redundant vectors. b) determining which word-vectors to\neliminate by developing a strategy for measuring their significance, based on\nthe self-attention mechanism. c) learning how many word-vectors to eliminate by\naugmenting the BERT model and the loss function. Experiments on the standard\nGLUE benchmark shows that PoWER-BERT achieves up to 4.5x reduction in inference\ntime over BERT with <1% loss in accuracy. We show that PoWER-BERT offers\nsignificantly better trade-off between accuracy and inference time compared to\nprior methods. We demonstrate that our method attains up to 6.8x reduction in\ninference time with <1% loss in accuracy when applied over ALBERT, a highly\ncompressed version of BERT. The code for PoWER-BERT is publicly available at\nhttps://github.com/IBM/PoWER-BERT.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 11:36:12 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:53:56 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 12:22:08 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 18:35:54 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 14:11:33 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Goyal", "Saurabh", ""], ["Choudhury", "Anamitra R.", ""], ["Raje", "Saurabh M.", ""], ["Chakaravarthy", "Venkatesan T.", ""], ["Sabharwal", "Yogish", ""], ["Verma", "Ashish", ""]]}, {"id": "2001.08975", "submitter": "Carlos Sevilla Salcedo", "authors": "Carlos Sevilla-Salcedo, Vanessa G\\'omez-Verdejo and Pablo M. Olmos", "title": "Sparse Semi-supervised Heterogeneous Interbattery Bayesian Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian approach to feature extraction, known as factor analysis (FA),\nhas been widely studied in machine learning to obtain a latent representation\nof the data. An adequate selection of the probabilities and priors of these\nbayesian models allows the model to better adapt to the data nature (i.e.\nheterogeneity, sparsity), obtaining a more representative latent space.\n  The objective of this article is to propose a general FA framework capable of\nmodelling any problem. To do so, we start from the Bayesian Inter-Battery\nFactor Analysis (BIBFA) model, enhancing it with new functionalities to be able\nto work with heterogeneous data, include feature selection, and handle missing\nvalues as well as semi-supervised problems.\n  The performance of the proposed model, Sparse Semi-supervised Heterogeneous\nInterbattery Bayesian Analysis (SSHIBA) has been tested on 4 different\nscenarios to evaluate each one of its novelties, showing not only a great\nversatility and an interpretability gain, but also outperforming most of the\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:00:56 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Sevilla-Salcedo", "Carlos", ""], ["G\u00f3mez-Verdejo", "Vanessa", ""], ["Olmos", "Pablo M.", ""]]}, {"id": "2001.08976", "submitter": "J{\\o}rgen Agersborg", "authors": "J{\\o}rgen A. Agersborg, Stian Normann Anfinsen and Jane Uhd Jepsen", "title": "Polarimetric Guided Nonlocal Means Covariance Matrix Estimation for\n  Defoliation Mapping", "comments": "Update to match final submitted version accepted to IGARSS 2020. 4\n  pages, 2 columns, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we investigate the potential for using synthetic aperture radar\n(SAR) data to provide high resolution defoliation and regrowth mapping of trees\nin the tundra-forest ecotone. Using aerial photographs, four areas with live\nforest and four areas with dead trees were identified. Quad-polarimetric SAR\ndata from RADARSAT-2 was collected from the same area, and the complex\nmultilook polarimetric covariance matrix was calculated using a novel extension\nof guided nonlocal means speckle filtering. The nonlocal approach allows us to\npreserve the high spatial resolution of single-look complex data, which is\nessential for accurate mapping of the sparsely scattered trees in the study\narea. Using a standard random forest classification algorithm, our filtering\nresults in over $99.7 \\%$ classification accuracy, higher than traditional\nspeckle filtering methods, and on par with the classification accuracy based on\noptical data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:06:12 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 09:12:32 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Agersborg", "J\u00f8rgen A.", ""], ["Anfinsen", "Stian Normann", ""], ["Jepsen", "Jane Uhd", ""]]}, {"id": "2001.08979", "submitter": "Amit Tewari", "authors": "Amit Tewari", "title": "Forecasting NIFTY 50 benchmark Index using Seasonal ARIMA time series\n  models", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10332.95364", "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyses how Time Series Analysis techniques can be applied to\ncapture movement of an exchange traded index in a stock market. Specifically,\nSeasonal Auto Regressive Integrated Moving Average (SARIMA) class of models is\napplied to capture the movement of Nifty 50 index which is one of the most\nactively exchange traded contracts globally [1]. A total of 729 model parameter\ncombinations were evaluated and the most appropriate selected for making the\nfinal forecast based on AIC criteria [8]. NIFTY 50 can be used for a variety of\npurposes such as benchmarking fund portfolios, launching of index funds,\nexchange traded funds (ETFs) and structured products. The index tracks the\nbehaviour of a portfolio of blue chip companies, the largest and most liquid\nIndian securities and can be regarded as a true reflection of the Indian stock\nmarket [2].\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 12:58:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Tewari", "Amit", ""]]}, {"id": "2001.08985", "submitter": "Saptarshi Ghosh", "authors": "M.A. Ganaie, Saptarshi Ghosh, Naveen Mendola, M Tanveer and Sarika\n  Jalan", "title": "Identification of Chimera using Machine Learning", "comments": "20 Pages, 4 Figures; Comments welcome", "journal-ref": "Chaos 30, 063128 (2020)", "doi": "10.1063/1.5143285", "report-no": null, "categories": "nlin.AO cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chimera state refers to coexistence of coherent and non-coherent phases in\nidentically coupled dynamical units found in various complex dynamical systems.\nIdentification of Chimera, on one hand is essential due to its applicability in\nvarious areas including neuroscience, and on other hand is challenging due to\nits widely varied appearance in different systems and the peculiar nature of\nits profile. Therefore, a simple yet universal method for its identification\nremains an open problem. Here, we present a very distinctive approach using\nmachine learning techniques to characterize different dynamical phases and\nidentify the chimera state from given spatial profiles generated using various\ndifferent models. The experimental results show that the performance of the\nclassification algorithms varies for different dynamical models. The machine\nlearning algorithms, namely random forest, oblique random forest based on\ntikhonov, parallel-axis split and null space regularization achieved more than\n$96\\% $ accuracy for the Kuramoto model. For the logistic-maps, random forest\nand tikhonov regularization based oblique random forest showed more than $90\\%$\naccuracy, and for the H\\'enon-Map model, random forest, null-space and\naxis-parallel split regularization based oblique random forest achieved more\nthan $80\\%$ accuracy. The oblique random forest with null space regularization\nachieved consistent performance (more than $83\\%$ accuracy) across different\ndynamical models while the auto-encoder based random vector functional link\nneural network showed relatively lower performance. This work provides a\ndirection for employing machine learning techniques to identify dynamical\npatterns arising in coupled non-linear units on large-scale, and for\ncharacterizing complex spatio-temporal patterns in real-world systems for\nvarious applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:59:27 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 14:16:51 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ganaie", "M. A.", ""], ["Ghosh", "Saptarshi", ""], ["Mendola", "Naveen", ""], ["Tanveer", "M", ""], ["Jalan", "Sarika", ""]]}, {"id": "2001.08997", "submitter": "Yana Lyakhova", "authors": "Ya. S. Lyakhova, E. A. Polyakov, A. N. Rubtsov", "title": "Effectively Trainable Semi-Quantum Restricted Boltzmann Machine", "comments": "8 pages, 6 figures; misprints have been corrected; numerical\n  experiments have been extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel quantum model for the restricted Boltzmann machine (RBM),\nin which the visible units remain classical whereas the hidden units are\nquantized as noninteracting fermions. The free motion of the fermions is\nparametrically coupled to the classical signal of the visible units. This model\npossesses a quantum behaviour such as coherences between the hidden units.\nNumerical experiments show that this fact makes it more powerful than the\nclassical RBM with the same number of hidden units. At the same time, a\nsignificant advantage of the proposed model over the other approaches to the\nQuantum Boltzmann Machine (QBM) is that it is exactly solvable and efficiently\ntrainable on a classical computer: there is a closed expression for the\nlog-likelihood gradient with respect to its parameters. This fact makes it\ninteresting not only as a model of a hypothetical quantum simulator, but also\nas a quantum-inspired classical machine-learning algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:38:48 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 08:48:37 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 17:02:33 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 21:05:44 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Lyakhova", "Ya. S.", ""], ["Polyakov", "E. A.", ""], ["Rubtsov", "A. N.", ""]]}, {"id": "2001.09001", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha, Arslan Ali, Burhan A. Mudassar, Yun Long, and Saibal\n  Mukhopadhyay", "title": "MagNet: Discovering Multi-agent Interaction Dynamics using Neural\n  Network", "comments": "Accepted manuscript by ICRA 2020", "journal-ref": "ICRA 2020, pp. 8158-8164", "doi": "10.1109/ICRA40945.2020.9196846", "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the MagNet, a neural network-based multi-agent interaction model\nto discover the governing dynamics and predict evolution of a complex\nmulti-agent system from observations. We formulate a multi-agent system as a\ncoupled non-linear network with a generic ordinary differential equation (ODE)\nbased state evolution, and develop a neural network-based realization of its\ntime-discretized model. MagNet is trained to discover the core dynamics of a\nmulti-agent system from observations, and tuned on-line to learn agent-specific\nparameters of the dynamics to ensure accurate prediction even when physical or\nrelational attributes of agents, or number of agents change. We evaluate MagNet\non a point-mass system in two-dimensional space, Kuramoto phase synchronization\ndynamics and predator-swarm interaction dynamics demonstrating orders of\nmagnitude improvement in prediction accuracy over traditional deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:41:01 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:17:45 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Saha", "Priyabrata", ""], ["Ali", "Arslan", ""], ["Mudassar", "Burhan A.", ""], ["Long", "Yun", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2001.09005", "submitter": "Federico Errica", "authors": "Federico Errica, Davide Bacciu, Alessio Micheli", "title": "Theoretically Expressive and Edge-aware Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Graph Neural Network that combines recent advancements in\nthe field. We give theoretical contributions by proving that the model is\nstrictly more general than the Graph Isomorphism Network and the Gated Graph\nNeural Network, as it can approximate the same functions and deal with\narbitrary edge values. Then, we show how a single node information can flow\nthrough the graph unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:43:39 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Errica", "Federico", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "2001.09027", "submitter": "Yu-Feng Li", "authors": "Lan-Zhe Guo, Feng Kuang, Zhang-Xun Liu, Yu-Feng Li, Nan Ma, Xiao-Hu\n  Qie", "title": "Weakly Supervised Learning Meets Ride-Sharing User Experience\n  Enhancement", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning aims at coping with scarce labeled data. Previous\nweakly supervised studies typically assume that there is only one kind of weak\nsupervision in data. In many applications, however, raw data usually contains\nmore than one kind of weak supervision at the same time. For example, in user\nexperience enhancement from Didi, one of the largest online ride-sharing\nplatforms, the ride comment data contains severe label noise (due to the\nsubjective factors of passengers) and severe label distribution bias (due to\nthe sampling bias). We call such a problem as \"compound weakly supervised\nlearning\". In this paper, we propose the CWSL method to address this problem\nbased on Didi ride-sharing comment data. Specifically, an instance reweighting\nstrategy is employed to cope with severe label noise in comment data, where the\nweights for harmful noisy instances are small. Robust criteria like AUC rather\nthan accuracy and the validation performance are optimized for the correction\nof biased data label. Alternating optimization and stochastic gradient methods\naccelerate the optimization on large-scale data. Experiments on Didi\nride-sharing comment data clearly validate the effectiveness. We hope this work\nmay shed some light on applying weakly supervised learning to complex real\nsituations.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 05:36:27 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Guo", "Lan-Zhe", ""], ["Kuang", "Feng", ""], ["Liu", "Zhang-Xun", ""], ["Li", "Yu-Feng", ""], ["Ma", "Nan", ""], ["Qie", "Xiao-Hu", ""]]}, {"id": "2001.09040", "submitter": "Se Un Park", "authors": "Se Un Park", "title": "Estimation for Compositional Data using Measurements from Nonlinear\n  Systems using Artificial Neural Networks", "comments": "43 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our objective is to estimate the unknown compositional input from its output\nresponse through an unknown system after estimating the inverse of the original\nsystem with a training set. The proposed methods using artificial neural\nnetworks (ANNs) can compete with the optimal bounds for linear systems, where\nconvex optimization theory applies, and demonstrate promising results for\nnonlinear system inversions. We performed extensive experiments by designing\nnumerous different types of nonlinear systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 14:50:13 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Park", "Se Un", ""]]}, {"id": "2001.09046", "submitter": "Bart Smets", "authors": "Bart Smets, Jim Portegies, Erik Bekkers, Remco Duits", "title": "PDE-based Group Equivariant Convolutional Neural Networks", "comments": "27 pages, 18 figures. v2 changes: - mentioned KerCNNs - added section\n  Generalization of G-CNNs - clarification that the experiments utilized\n  automatic differentiation and SGD. v3 changes: - streamlined theoretical\n  framework - formulation and proof Thm.1 & 2 - expanded experiments. v4\n  changes: typos in Prop.5 and (20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a PDE-based framework that generalizes Group equivariant\nConvolutional Neural Networks (G-CNNs). In this framework, a network layer is\nseen as a set of PDE-solvers where geometrically meaningful PDE-coefficients\nbecome the layer's trainable weights. Formulating our PDEs on homogeneous\nspaces allows these networks to be designed with built-in symmetries such as\nrotation in addition to the standard translation equivariance of CNNs.\n  Having all the desired symmetries included in the design obviates the need to\ninclude them by means of costly techniques such as data augmentation. We will\ndiscuss our PDE-based G-CNNs (PDE-G-CNNs) in a general homogeneous space\nsetting while also going into the specifics of our primary case of interest:\nroto-translation equivariance.\n  We solve the PDE of interest by a combination of linear group convolutions\nand non-linear morphological group convolutions with analytic kernel\napproximations that we underpin with formal theorems. Our kernel approximations\nallow for fast GPU-implementation of the PDE-solvers, we release our\nimplementation with this article. Just like for linear convolution a\nmorphological convolution is specified by a kernel that we train in our\nPDE-G-CNNs. In PDE-G-CNNs we do not use non-linearities such as max/min-pooling\nand ReLUs as they are already subsumed by morphological convolutions.\n  We present a set of experiments to demonstrate the strength of the proposed\nPDE-G-CNNs in increasing the performance of deep learning based imaging\napplications with far fewer parameters than traditional CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:00:46 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 14:16:16 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 07:56:22 GMT"}, {"version": "v4", "created": "Sat, 24 Jul 2021 11:14:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Smets", "Bart", ""], ["Portegies", "Jim", ""], ["Bekkers", "Erik", ""], ["Duits", "Remco", ""]]}, {"id": "2001.09055", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu, Sotirios V. Archontoulis", "title": "Forecasting Corn Yield with Machine Learning Ensembles", "comments": null, "journal-ref": "Frontiers in Plant Science 11 (2020) 1120", "doi": "10.3389/fpls.2020.01120", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerge of new technologies to synthesize and analyze big data with\nhigh-performance computing, has increased our capacity to more accurately\npredict crop yields. Recent research has shown that Machine learning (ML) can\nprovide reasonable predictions, faster, and with higher flexibility compared to\nsimulation crop modeling. The earlier the prediction during the growing season\nthe better, but this has not been thoroughly investigated as previous studies\nconsidered all data available to predict yields. This paper provides a machine\nlearning based framework to forecast corn yields in three US Corn Belt states\n(Illinois, Indiana, and Iowa) considering complete and partial in-season\nweather knowledge. Several ensemble models are designed using blocked\nsequential procedure to generate out-of-bag predictions. The forecasts are made\nin county-level scale and aggregated for agricultural district, and state level\nscales. Results show that ensemble models based on weighted average of the base\nlearners outperform individual models. Specifically, the proposed ensemble\nmodel could achieve best prediction accuracy (RRMSE of 7.8%) and least mean\nbias error (-6.06 bu/acre) compared to other developed models. Comparing our\nproposed model forecasts with the literature demonstrates the superiority of\nforecasts made by our proposed ensemble model. Results from the scenario of\nhaving partial in-season weather knowledge reveal that decent yield forecasts\ncan be made as early as June 1st. To find the marginal effect of each input\nfeature on the forecasts made by the proposed ensemble model, a methodology is\nsuggested that is the basis for finding feature importance for the ensemble\nmodel. The findings suggest that weather features corresponding to weather in\nweeks 18-24 (May 1st to June 1st) are the most important input features.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:55:20 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 18:20:59 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""], ["Archontoulis", "Sotirios V.", ""]]}, {"id": "2001.09061", "submitter": "Jonas Teuwen", "authors": "Nikita Moriakov, Jonas Adler, Jonas Teuwen", "title": "Kernel of CycleGAN as a Principle homogeneous space", "comments": "Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unpaired image-to-image translation has attracted significant interest due to\nthe invention of CycleGAN, a method which utilizes a combination of adversarial\nand cycle consistency losses to avoid the need for paired data. It is known\nthat the CycleGAN problem might admit multiple solutions, and our goal in this\npaper is to analyze the space of exact solutions and to give perturbation\nbounds for approximate solutions. We show theoretically that the exact solution\nspace is invariant with respect to automorphisms of the underlying probability\nspaces, and, furthermore, that the group of automorphisms acts freely and\ntransitively on the space of exact solutions. We examine the case of zero\n`pure' CycleGAN loss first in its generality, and, subsequently, expand our\nanalysis to approximate solutions for `extended' CycleGAN loss where identity\nloss term is included. In order to demonstrate that these results are\napplicable, we show that under mild conditions nontrivial smooth automorphisms\nexist. Furthermore, we provide empirical evidence that neural networks can\nlearn these automorphisms with unexpected and unwanted results. We conclude\nthat finding optimal solutions to the CycleGAN loss does not necessarily lead\nto the envisioned result in image-to-image translation tasks and that\nunderlying hidden symmetries can render the result utterly useless.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:47:12 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Moriakov", "Nikita", ""], ["Adler", "Jonas", ""], ["Teuwen", "Jonas", ""]]}, {"id": "2001.09063", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden", "title": "Towards Graph Representation Learning in Emergent Communication", "comments": "The first two authors contributed equally. Accepted at the\n  Reinforcement Learning in Games workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in neuroscience suggest that the human brain represents\ninformation in a geometric structure (for instance, through conceptual spaces).\nIn order to communicate, we flatten the complex representation of entities and\ntheir attributes into a single word or a sentence. In this paper we use graph\nconvolutional networks to support the evolution of language and cooperation in\nmulti-agent systems. Motivated by an image-based referential game, we propose a\ngraph referential game with varying degrees of complexity, and we provide\nstrong baseline models that exhibit desirable properties in terms of language\nemergence and cooperation. We show that the emerged communication protocol is\nrobust, that the agents uncover the true factors of variation in the game, and\nthat they learn to generalize beyond the samples encountered during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:55:59 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 14:18:31 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""]]}, {"id": "2001.09122", "submitter": "Lydia Zakynthinou", "authors": "Thomas Steinke and Lydia Zakynthinou", "title": "Reasoning About Generalization via Conditional Mutual Information", "comments": "58 pages. Changes from previous version: Added discussion on related\n  work and updated references. Simplified part of the proof of Theorem 4.10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an information-theoretic framework for studying the generalization\nproperties of machine learning algorithms. Our framework ties together existing\napproaches, including uniform convergence bounds and recent methods for\nadaptive data analysis. Specifically, we use Conditional Mutual Information\n(CMI) to quantify how well the input (i.e., the training data) can be\nrecognized given the output (i.e., the trained model) of the learning\nalgorithm. We show that bounds on CMI can be obtained from VC dimension,\ncompression schemes, differential privacy, and other methods. We then show that\nbounded CMI implies various forms of generalization.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:13:04 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 05:48:00 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 00:42:03 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Steinke", "Thomas", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "2001.09180", "submitter": "Kabir Chandrasekher", "authors": "Kabir Aladin Chandrasekher, Ahmed El Alaoui, Andrea Montanari", "title": "Imputation for High-Dimensional Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study high-dimensional regression with missing entries in the covariates.\nA common strategy in practice is to \\emph{impute} the missing entries with an\nappropriate substitute and then implement a standard statistical procedure\nacting as if the covariates were fully observed. Recent literature on this\nsubject proposes instead to design a specific, often complicated or non-convex,\nalgorithm tailored to the case of missing covariates. We investigate a simpler\napproach where we fill-in the missing entries with their conditional mean given\nthe observed covariates. We show that this imputation scheme coupled with\nstandard off-the-shelf procedures such as the LASSO and square-root LASSO\nretains the minimax estimation rate in the random-design setting where the\ncovariates are i.i.d.\\ sub-Gaussian. We further show that the square-root LASSO\nremains \\emph{pivotal} in this setting.\n  It is often the case that the conditional expectation cannot be computed\nexactly and must be approximated from data. We study two cases where the\ncovariates either follow an autoregressive (AR) process, or are jointly\nGaussian with sparse precision matrix. We propose tractable estimators for the\nconditional expectation and then perform linear regression via LASSO, and show\nsimilar estimation rates in both cases. We complement our theoretical results\nwith simulations on synthetic and semi-synthetic examples, illustrating not\nonly the sharpness of our bounds, but also the broader utility of this strategy\nbeyond our theoretical assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 19:54:09 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chandrasekher", "Kabir Aladin", ""], ["Alaoui", "Ahmed El", ""], ["Montanari", "Andrea", ""]]}, {"id": "2001.09209", "submitter": "Mahdi Bohlouli", "authors": "Rasoul Kiani, Amin Keshavarzi, and Mahdi Bohlouli", "title": "Detection of Thin Boundaries between Different Types of Anomalies in\n  Outlier Detection using Enhanced Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection has received special attention in various fields, mainly\nfor those dealing with machine learning and artificial intelligence. As strong\noutliers, anomalies are divided into the point, contextual and collective\noutliers. The most important challenges in outlier detection include the thin\nboundary between the remote points and natural area, the tendency of new data\nand noise to mimic the real data, unlabelled datasets and different definitions\nfor outliers in different applications. Considering the stated challenges, we\ndefined new types of anomalies called Collective Normal Anomaly and Collective\nPoint Anomaly in order to improve a much better detection of the thin boundary\nbetween different types of anomalies. Basic domain-independent methods are\nintroduced to detect these defined anomalies in both unsupervised and\nsupervised datasets. The Multi-Layer Perceptron Neural Network is enhanced\nusing the Genetic Algorithm to detect newly defined anomalies with higher\nprecision so as to ensure a test error less than that calculated for the\nconventional Multi-Layer Perceptron Neural Network. Experimental results on\nbenchmark datasets indicated reduced error of anomaly detection process in\ncomparison to baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 21:52:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kiani", "Rasoul", ""], ["Keshavarzi", "Amin", ""], ["Bohlouli", "Mahdi", ""]]}, {"id": "2001.09212", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa, Philip Bontrager, Sam Earle and Julian Togelius", "title": "PCGRL: Procedural Content Generation via Reinforcement Learning", "comments": "7 pages, 7 figures, 1 table, published at AIIDE2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how reinforcement learning can be used to train\nlevel-designing agents. This represents a new approach to procedural content\ngeneration in games, where level design is framed as a game, and the content\ngenerator itself is learned. By seeing the design problem as a sequential task,\nwe can use reinforcement learning to learn how to take the next action so that\nthe expected final level quality is maximized. This approach can be used when\nfew or no examples exist to train from, and the trained generator is very fast.\nWe investigate three different ways of transforming two-dimensional level\ndesign problems into Markov decision processes and apply these to three game\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:09:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 06:33:01 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 02:31:50 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Earle", "Sam", ""], ["Togelius", "Julian", ""]]}, {"id": "2001.09223", "submitter": "Kezhi Wang", "authors": "Feibo Jiang, Kezhi Wang, Li Dong, Cunhua Pan, Kun Yang", "title": "Stacked Auto Encoder Based Deep Reinforcement Learning for Online\n  Resource Scheduling in Large-Scale MEC Networks", "comments": "Accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online resource scheduling framework is proposed for minimizing the sum of\nweighted task latency for all the Internet of things (IoT) users, by optimizing\noffloading decision, transmission power and resource allocation in the\nlarge-scale mobile edge computing (MEC) system. Towards this end, a deep\nreinforcement learning (DRL) based solution is proposed, which includes the\nfollowing components. Firstly, a related and regularized stacked auto encoder\n(2r-SAE) with unsupervised learning is applied to perform data compression and\nrepresentation for high dimensional channel quality information (CQI) data,\nwhich can reduce the state space for DRL. Secondly, we present an adaptive\nsimulated annealing based approach (ASA) as the action search method of DRL, in\nwhich an adaptive h-mutation is used to guide the search direction and an\nadaptive iteration is proposed to enhance the search efficiency during the DRL\nprocess. Thirdly, a preserved and prioritized experience replay (2p-ER) is\nintroduced to assist the DRL to train the policy network and find the optimal\noffloading policy. Numerical results are provided to demonstrate that the\nproposed algorithm can achieve near-optimal performance while significantly\ndecreasing the computational time compared with existing benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 23:01:15 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 21:47:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Jiang", "Feibo", ""], ["Wang", "Kezhi", ""], ["Dong", "Li", ""], ["Pan", "Cunhua", ""], ["Yang", "Kun", ""]]}, {"id": "2001.09225", "submitter": "Ryan Martin", "authors": "Leonardo Cella and Ryan Martin", "title": "Strong validity, consonance, and conformal prediction", "comments": "34 pages, 3 figures, 2 tables. Comments welcome at\n  https://www.researchers.one/article/2020-01-12", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valid prediction of future observations is an important and challenging\nproblem. The two general approaches for quantifying uncertainty about the\nfuture value employ prediction regions and predictive distribution,\nrespectively, with the latter usually considered to be more informative because\nit performs other prediction-related tasks. Standard notions of validity focus\non the former, i.e., coverage probability bounds for prediction regions, but a\nnotion of validity relevant to the other prediction-related tasks performed by\nthe latter is lacking. In this paper, we present a new notion---strong\nprediction validity---relevant to these more general prediction tasks. We show\nthat strong validity is connected to more familiar notions of coherence, and\nargue that imprecise probability considerations are required in order to\nachieve it. We go on to show that strong prediction validity can be achieved by\ninterpreting the conformal prediction output as the contour function of a\nconsonant plausibility function. We also offer an alternative characterization,\nbased on a new nonparametric inferential model construction, wherein the\nappearance of consonance is more natural, and prove strong prediction validity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 23:24:15 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 22:10:12 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Cella", "Leonardo", ""], ["Martin", "Ryan", ""]]}, {"id": "2001.09249", "submitter": "Ahsan Ali Mr", "authors": "Zheng Chai, Ahsan Ali, Syed Zawad, Stacey Truex, Ali Anwar, Nathalie\n  Baracaldo, Yi Zhou, Heiko Ludwig, Feng Yan, Yue Cheng", "title": "TiFL: A Tier-based Federated Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) enables learning a shared model across many clients\nwithout violating the privacy requirements. One of the key attributes in FL is\nthe heterogeneity that exists in both resource and data due to the differences\nin computation and communication capacity, as well as the quantity and content\nof data among different clients. We conduct a case study to show that\nheterogeneity in resource and data has a significant impact on training time\nand model accuracy in conventional FL systems. To this end, we propose TiFL, a\nTier-based Federated Learning System, which divides clients into tiers based on\ntheir training performance and selects clients from the same tier in each\ntraining round to mitigate the straggler problem caused by heterogeneity in\nresource and data quantity. To further tame the heterogeneity caused by non-IID\n(Independent and Identical Distribution) data and resources, TiFL employs an\nadaptive tier selection approach to update the tiering on-the-fly based on the\nobserved training performance and accuracy overtime. We prototype TiFL in a FL\ntestbed following Google's FL architecture and evaluate it using popular\nbenchmarks and the state-of-the-art FL benchmark LEAF. Experimental evaluation\nshows that TiFL outperforms the conventional FL in various heterogeneous\nconditions. With the proposed adaptive tier selection policy, we demonstrate\nthat TiFL achieves much faster training performance while keeping the same (and\nin some cases - better) test accuracy across the board.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:40:42 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chai", "Zheng", ""], ["Ali", "Ahsan", ""], ["Zawad", "Syed", ""], ["Truex", "Stacey", ""], ["Anwar", "Ali", ""], ["Baracaldo", "Nathalie", ""], ["Zhou", "Yi", ""], ["Ludwig", "Heiko", ""], ["Yan", "Feng", ""], ["Cheng", "Yue", ""]]}, {"id": "2001.09254", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Karan Singh, Elad Hazan", "title": "Improper Learning for Non-Stochastic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling a possibly unknown linear dynamical\nsystem with adversarial perturbations, adversarially chosen convex loss\nfunctions, and partially observed states, known as non-stochastic control. We\nintroduce a controller parametrization based on the denoised observations, and\nprove that applying online gradient descent to this parametrization yields a\nnew controller which attains sublinear regret vs. a large class of closed-loop\npolicies. In the fully-adversarial setting, our controller attains an optimal\nregret bound of $\\sqrt{T}$-when the system is known, and, when combined with an\ninitial stage of least-squares estimation, $T^{2/3}$ when the system is\nunknown; both yield the first sublinear regret for the partially observed\nsetting.\n  Our bounds are the first in the non-stochastic control setting that compete\nwith \\emph{all} stabilizing linear dynamical controllers, not just state\nfeedback. Moreover, in the presence of semi-adversarial noise containing both\nstochastic and adversarial components, our controller attains the optimal\nregret bounds of $\\mathrm{poly}(\\log T)$ when the system is known, and\n$\\sqrt{T}$ when unknown. To our knowledge, this gives the first end-to-end\n$\\sqrt{T}$ regret for online Linear Quadratic Gaussian controller, and applies\nin a more general setting with adversarial losses and semi-adversarial noise.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 02:12:48 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 03:03:45 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 23:48:03 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Simchowitz", "Max", ""], ["Singh", "Karan", ""], ["Hazan", "Elad", ""]]}, {"id": "2001.09266", "submitter": "Liam Hodgkinson", "authors": "Liam Hodgkinson, Robert Salomone, Fred Roosta", "title": "The reproducing Stein kernel approach for post-hoc corrected sampling", "comments": "29 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein importance sampling is a widely applicable technique based on\nkernelized Stein discrepancy, which corrects the output of approximate sampling\nalgorithms by reweighting the empirical distribution of the samples. A general\nanalysis of this technique is conducted for the previously unconsidered setting\nwhere samples are obtained via the simulation of a Markov chain, and applies to\nan arbitrary underlying Polish space. We prove that Stein importance sampling\nyields consistent estimators for quantities related to a target distribution of\ninterest by using samples obtained from a geometrically ergodic Markov chain\nwith a possibly unknown invariant measure that differs from the desired target.\nThe approach is shown to be valid under conditions that are satisfied for a\nlarge number of unadjusted samplers, and is capable of retaining consistency\nwhen data subsampling is used. Along the way, a universal theory of reproducing\nStein kernels is established, which enables the construction of kernelized\nStein discrepancy on general Polish spaces, and provides sufficient conditions\nfor kernels to be convergence-determining on such spaces. These results are of\nindependent interest for the development of future methodology based on\nkernelized Stein discrepancies.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 05:33:05 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hodgkinson", "Liam", ""], ["Salomone", "Robert", ""], ["Roosta", "Fred", ""]]}, {"id": "2001.09277", "submitter": "Christian H\\\"ager", "authors": "Christian H\\\"ager, Henry D. Pfister, Rick M. B\\\"utler, Gabriele Liga,\n  Alex Alvarado", "title": "Model-Based Machine Learning for Joint Digital Backpropagation and PMD\n  Compensation", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-based machine-learning approach for\npolarization-multiplexed systems by parameterizing the split-step method for\nthe Manakov-PMD equation. This approach performs hardware-friendly DBP and\ndistributed PMD compensation with performance close to the PMD-free case.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:33:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""], ["B\u00fctler", "Rick M.", ""], ["Liga", "Gabriele", ""], ["Alvarado", "Alex", ""]]}, {"id": "2001.09292", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty and Sondipon Adhikari and Ranjan Ganguli", "title": "The role of surrogate models in the development of digital twins of\n  dynamic systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital twin technology has significant promise, relevance and potential of\nwidespread applicability in various industrial sectors such as aerospace,\ninfrastructure and automotive. However, the adoption of this technology has\nbeen slower due to the lack of clarity for specific applications. A discrete\ndamped dynamic system is used in this paper to explore the concept of a digital\ntwin. As digital twins are also expected to exploit data and computational\nmethods, there is a compelling case for the use of surrogate models in this\ncontext. Motivated by this synergy, we have explored the possibility of using\nsurrogate models within the digital twin technology. In particular, the use of\nGaussian process (GP) emulator within the digital twin technology is explored.\nGP has the inherent capability of addressing noise and sparse data and hence,\nmakes a compelling case to be used within the digital twin framework. Cases\ninvolving stiffness variation and mass variation are considered, individually\nand jointly along with different levels of noise and sparsity in data. Our\nnumerical simulation results clearly demonstrate that surrogate models such as\nGP emulators have the potential to be an effective tool for the development of\ndigital twins. Aspects related to data quality and sampling rate are analysed.\nKey concepts introduced in this paper are summarised and ideas for urgent\nfuture research needs are proposed.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 10:48:35 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:44:50 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chakraborty", "Souvik", ""], ["Adhikari", "Sondipon", ""], ["Ganguli", "Ranjan", ""]]}, {"id": "2001.09325", "submitter": "Nengli Lim", "authors": "Yueqin Li and Nengli Lim", "title": "Bayesian optimization for backpropagation in Monte-Carlo tree search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large domains, Monte-Carlo tree search (MCTS) is required to estimate the\nvalues of the states as efficiently and accurately as possible. However, the\nstandard update rule in backpropagation assumes a stationary distribution for\nthe returns, and particularly in min-max trees, convergence to the true value\ncan be slow because of averaging. We present two methods, Softmax MCTS and\nMonotone MCTS, which generalize previous attempts to improve upon the\nbackpropagation strategy. We demonstrate that both methods reduce to finding\noptimal monotone functions, which we do so by performing Bayesian optimization\nwith a Gaussian process (GP) prior. We conduct experiments on computer Go,\nwhere the returns are given by a deep value neural network, and show that our\nproposed framework outperforms previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:33:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Yueqin", ""], ["Lim", "Nengli", ""]]}, {"id": "2001.09327", "submitter": "Zexin Wang", "authors": "Zexin Wang, Vincent Y. F. Tan, Jonathan Scarlett", "title": "Tight Regret Bounds for Noisy Optimization of a Brownian Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Bayesian optimization of a one-dimensional\nBrownian motion in which the $T$ adaptively chosen observations are corrupted\nby Gaussian noise. We show that as the smallest possible expected simple regret\nand the smallest possible expected cumulative regret scale as $\\Omega(1 /\n\\sqrt{T \\log (T)}) \\cap \\mathcal{O}(\\log T / \\sqrt{T})$ and $\\Omega(\\sqrt{T /\n\\log (T)}) \\cap \\mathcal{O}(\\sqrt{T} \\cdot \\log T)$ respectively. Thus, our\nupper and lower bounds are tight up to a factor of $\\mathcal{O}( (\\log T)^{1.5}\n)$. The upper bound uses an algorithm based on confidence bounds and the Markov\nproperty of Brownian motion, and the lower bound is based on a reduction to\nbinary hypothesis testing.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:44:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Wang", "Zexin", ""], ["Tan", "Vincent Y. F.", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2001.09328", "submitter": "Zifeng Wang", "authors": "Zifeng Wang, Xi Chen, Rui Wen, Shao-Lun Huang", "title": "On the Fairness of Randomized Trials for Recommendation with\n  Heterogeneous Demographics and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observed events in recommendation are consequence of the decisions made by a\npolicy, thus they are usually selectively labeled, namely the data are Missing\nNot At Random (MNAR), which often causes large bias to the estimate of true\noutcomes risk. A general approach to correct MNAR bias is performing small\nRandomized Controlled Trials (RCTs), where an additional uniform policy is\nemployed to randomly assign items to each user. In this work, we concentrate on\nthe fairness of RCTs under both homogeneous and heterogeneous demographics,\nespecially analyzing the bias for the least favorable group on the latter\nsetting. Considering RCTs' limitations, we propose a novel Counterfactual\nRobust Risk Minimization (CRRM) framework, which is totally free of expensive\nRCTs, and derive its theoretical generalization error bound. At last, empirical\nexperiments are performed on synthetic tasks and real-world data sets,\nsubstantiating our method's superiority both in fairness and generalization.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:59:46 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 11:09:18 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wang", "Zifeng", ""], ["Chen", "Xi", ""], ["Wen", "Rui", ""], ["Huang", "Shao-Lun", ""]]}, {"id": "2001.09330", "submitter": "Amedeo Buonanno", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Antonio Di Girolamo, Armando\n  Ospedale, Francesco A.N. Palmieri", "title": "Intent Classification in Question-Answering Using LSTM Architectures", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -\n  June 2019", "journal-ref": "Progresses in Artificial Intelligence and Neural Systems. Smart\n  Innovation, Systems and Technologies, vol 184. Springer, Singapore - First\n  Online: July 2020", "doi": "10.1007/978-981-15-5093-5_11", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) is certainly the best known and probably also one of\nthe most complex problem within Natural Language Processing (NLP) and\nartificial intelligence (AI). Since the complete solution to the problem of\nfinding a generic answer still seems far away, the wisest thing to do is to\nbreak down the problem by solving single simpler parts. Assuming a modular\napproach to the problem, we confine our research to intent classification for\nan answer, given a question. Through the use of an LSTM network, we show how\nthis type of classification can be approached effectively and efficiently, and\nhow it can be properly used within a basic prototype responder.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:07:07 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Di Girolamo", "Antonio", ""], ["Ospedale", "Armando", ""], ["Palmieri", "Francesco A. N.", ""]]}, {"id": "2001.09332", "submitter": "Amedeo Buonanno", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Antonio Di Girolamo, Armando\n  Ospedale, Francesco A.N. Palmieri, Gianfranco Fedele", "title": "An Analysis of Word2Vec for the Italian Language", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -\n  June 2019", "journal-ref": "Progresses in Artificial Intelligence and Neural Systems. Smart\n  Innovation, Systems and Technologies, vol 184. Springer, Singapore - First\n  Online: July 2020", "doi": "10.1007/978-981-15-5093-5_13", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representation is fundamental in NLP tasks, because it is precisely from\nthe coding of semantic closeness between words that it is possible to think of\nteaching a machine to understand text. Despite the spread of word embedding\nconcepts, still few are the achievements in linguistic contexts other than\nEnglish. In this work, analysing the semantic capacity of the Word2Vec\nalgorithm, an embedding for the Italian language is produced. Parameter setting\nsuch as the number of epochs, the size of the context window and the number of\nnegatively backpropagated samples is explored.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:12:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Di Girolamo", "Antonio", ""], ["Ospedale", "Armando", ""], ["Palmieri", "Francesco A. N.", ""], ["Fedele", "Gianfranco", ""]]}, {"id": "2001.09346", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi, Edward A. Fox", "title": "CorGAN: Correlation-Capturing Convolutional Generative Adversarial\n  Networks for Generating Synthetic Healthcare Records", "comments": "Accepted to be published in the 33rd International FLAIRS Conference,\n  AI in Healthcare Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have demonstrated high-quality performance in areas such\nas image classification and speech processing. However, creating a deep\nlearning model using electronic health record (EHR) data, requires addressing\nparticular privacy challenges that are unique to researchers in this domain.\nThis matter focuses attention on generating realistic synthetic data while\nensuring privacy. In this paper, we propose a novel framework called\ncorrelation-capturing Generative Adversarial Network (CorGAN), to generate\nsynthetic healthcare records. In CorGAN we utilize Convolutional Neural\nNetworks to capture the correlations between adjacent medical features in the\ndata representation space by combining Convolutional Generative Adversarial\nNetworks and Convolutional Autoencoders. To demonstrate the model fidelity, we\nshow that CorGAN generates synthetic data with performance similar to that of\nreal data in various Machine Learning settings such as classification and\nprediction. We also give a privacy assessment and report on statistical\nanalysis regarding realistic characteristics of the synthetic data. The\nsoftware of this work is open-source and is available at:\nhttps://github.com/astorfi/cor-gan.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 18:43:47 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:22:37 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Torfi", "Amirsina", ""], ["Fox", "Edward A.", ""]]}, {"id": "2001.09360", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer", "title": "Robust Submodular Minimization with Applications to Cooperative Modeling", "comments": "To Appear in ECAI 2020. arXiv admin note: substantial text overlap\n  with arXiv:1906.06393", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Optimization is becoming increasingly important in machine learning\napplications. This paper studies the problem of robust submodular minimization\nsubject to combinatorial constraints. Constrained Submodular Minimization\narises in several applications such as co-operative cuts in image segmentation,\nco-operative matchings in image correspondence, etc. Many of these models are\ndefined over clusterings of data points (for example pixels in images), and it\nis important for these models to be robust to perturbations and uncertainty in\nthe data. While several existing papers have studied robust submodular\nmaximization, ours is the first work to study the minimization version under a\nbroad range of combinatorial constraints including cardinality, knapsack,\nmatroid as well as graph-based constraints such as cuts, paths, matchings, and\ntrees. In each case, we provide scalable approximation algorithms and also\nstudy hardness bounds. Finally, we empirically demonstrate the utility of our\nalgorithms on synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 20:40:37 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Iyer", "Rishabh", ""]]}, {"id": "2001.09367", "submitter": "Andrew Roth", "authors": "Alexandre Bouchard-C\\^ot\\'e and Andrew Roth", "title": "Particle-Gibbs Sampling For Bayesian Feature Allocation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian feature allocation models are a popular tool for modelling data with\na combinatorial latent structure. Exact inference in these models is generally\nintractable and so practitioners typically apply Markov Chain Monte Carlo\n(MCMC) methods for posterior inference. The most widely used MCMC strategies\nrely on an element wise Gibbs update of the feature allocation matrix. These\nelement wise updates can be inefficient as features are typically strongly\ncorrelated. To overcome this problem we have developed a Gibbs sampler that can\nupdate an entire row of the feature allocation matrix in a single move.\nHowever, this sampler is impractical for models with a large number of features\nas the computational complexity scales exponentially in the number of features.\nWe develop a Particle Gibbs sampler that targets the same distribution as the\nrow wise Gibbs updates, but has computational complexity that only grows\nlinearly in the number of features. We compare the performance of our proposed\nmethods to the standard Gibbs sampler using synthetic data from a range of\nfeature allocation models. Our results suggest that row wise updates using the\nPG methodology can significantly improve the performance of samplers for\nfeature allocation models.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 22:11:51 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bouchard-C\u00f4t\u00e9", "Alexandre", ""], ["Roth", "Andrew", ""]]}, {"id": "2001.09373", "submitter": "John Kanu", "authors": "John Kanu, Eadom Dessalene, Xiaomin Lin, Cornelia Fermuller, Yiannis\n  Aloimonos", "title": "Following Instructions by Imagining and Reaching Visual Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditional methods for instruction-following typically assume prior\nlinguistic and perceptual knowledge, many recent works in reinforcement\nlearning (RL) have proposed learning policies end-to-end, typically by training\nneural networks to map joint representations of observations and instructions\ndirectly to actions. In this work, we present a novel framework for learning to\nperform temporally extended tasks using spatial reasoning in the RL framework,\nby sequentially imagining visual goals and choosing appropriate actions to\nfulfill imagined goals. Our framework operates on raw pixel images, assumes no\nprior linguistic or perceptual knowledge, and learns via intrinsic motivation\nand a single extrinsic reward signal measuring task completion. We validate our\nmethod in two environments with a robot arm in a simulated interactive 3D\nenvironment. Our method outperforms two flat architectures with raw-pixel and\nground-truth states, and a hierarchical architecture with ground-truth states\non object arrangement tasks.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 23:26:56 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Kanu", "John", ""], ["Dessalene", "Eadom", ""], ["Lin", "Xiaomin", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2001.09377", "submitter": "Liyuan Zheng", "authors": "Liyuan Zheng, Lillian J. Ratliff", "title": "Constrained Upper Confidence Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Processes are a class of stochastic decision\nproblems in which the decision maker must select a policy that satisfies\nauxiliary cost constraints. This paper extends upper confidence reinforcement\nlearning for settings in which the reward function and the constraints,\ndescribed by cost functions, are unknown a priori but the transition kernel is\nknown. Such a setting is well-motivated by a number of applications including\nexploration of unknown, potentially unsafe, environments. We present an\nalgorithm C-UCRL and show that it achieves sub-linear regret ($\nO(T^{\\frac{3}{4}}\\sqrt{\\log(T/\\delta)})$) with respect to the reward while\nsatisfying the constraints even while learning with probability $1-\\delta$.\nIllustrative examples are provided.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 00:23:02 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zheng", "Liyuan", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "2001.09382", "submitter": "Zhaocheng Zhu", "authors": "Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, Jian\n  Tang", "title": "GraphAF: a Flow-based Autoregressive Model for Molecular Graph\n  Generation", "comments": null, "journal-ref": "Published at ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular graph generation is a fundamental problem for drug discovery and\nhas been attracting growing attention. The problem is challenging since it\nrequires not only generating chemically valid molecular structures but also\noptimizing their chemical properties in the meantime. Inspired by the recent\nprogress in deep generative models, in this paper we propose a flow-based\nautoregressive model for graph generation called GraphAF. GraphAF combines the\nadvantages of both autoregressive and flow-based approaches and enjoys: (1)\nhigh model flexibility for data density estimation; (2) efficient parallel\ncomputation for training; (3) an iterative sampling process, which allows\nleveraging chemical domain knowledge for valency checking. Experimental results\nshow that GraphAF is able to generate 68% chemically valid molecules even\nwithout chemical knowledge rules and 100% valid molecules with chemical rules.\nThe training process of GraphAF is two times faster than the existing\nstate-of-the-art approach GCPN. After fine-tuning the model for goal-directed\nproperty optimization with reinforcement learning, GraphAF achieves\nstate-of-the-art performance on both chemical property optimization and\nconstrained property optimization.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 01:12:40 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 05:34:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shi", "Chence", ""], ["Xu", "Minkai", ""], ["Zhu", "Zhaocheng", ""], ["Zhang", "Weinan", ""], ["Zhang", "Ming", ""], ["Tang", "Jian", ""]]}, {"id": "2001.09384", "submitter": "Richard Nock", "authors": "Richard Nock and Wilko Henecka", "title": "Boosted and Differentially Private Ensembles of Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosted ensemble of decision tree (DT) classifiers are extremely popular in\ninternational competitions, yet to our knowledge nothing is formally known on\nhow to make them \\textit{also} differential private (DP), up to the point that\nrandom forests currently reign supreme in the DP stage. Our paper starts with\nthe proof that the privacy vs boosting picture for DT involves a notable and\ngeneral technical tradeoff: the sensitivity tends to increase with the boosting\nrate of the loss, for any proper loss. DT induction algorithms being\nfundamentally iterative, our finding implies non-trivial choices to select or\ntune the loss to balance noise against utility to split nodes. To address this,\nwe craft a new parametererized proper loss, called the M$\\alpha$-loss, which,\nas we show, allows to finely tune the tradeoff in the complete spectrum of\nsensitivity vs boosting guarantees. We then introduce \\textit{objective\ncalibration} as a method to adaptively tune the tradeoff during DT induction to\nlimit the privacy budget spent while formally being able to keep\nboosting-compliant convergence on limited-depth nodes with high probability.\nExtensive experiments on 19 UCI domains reveal that objective calibration is\nhighly competitive, even in the DP-free setting. Our approach tends to very\nsignificantly beat random forests, in particular on high DP regimes\n($\\varepsilon \\leq 0.1$) and even with boosted ensembles containing ten times\nless trees, which could be crucial to keep a key feature of DT models under\ndifferential privacy: interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 01:28:03 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 22:34:23 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Nock", "Richard", ""], ["Henecka", "Wilko", ""]]}, {"id": "2001.09390", "submitter": "Ningyuan Chen", "authors": "Xiang Zhou, Yi Xiong, Ningyuan Chen, Xuefeng Gao", "title": "Regime Switching Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-armed bandit problem where the rewards exhibit regime\nswitching. Specifically, the distributions of the random rewards generated from\nall arms are modulated by a common underlying state modeled as a finite-state\nMarkov chain. The agent does not observe the underlying state and has to learn\nthe transition matrix and the reward distributions. We propose a learning\nalgorithm for this problem, building on spectral method-of-moments estimations\nfor hidden Markov models, belief error control in partially observable Markov\ndecision processes and upper-confidence-bound methods for online learning. We\nalso establish an upper bound $O(T^{2/3}\\sqrt{\\log T})$ for the proposed\nlearning algorithm where $T$ is the learning horizon. Finally, we conduct\nproof-of-concept experiments to illustrate the performance of the learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:50:56 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 15:13:46 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 16:35:36 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhou", "Xiang", ""], ["Xiong", "Yi", ""], ["Chen", "Ningyuan", ""], ["Gao", "Xuefeng", ""]]}, {"id": "2001.09394", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Pascal Van Hentenryck, Terrence WK Mak, Cuong\n  Tran, Federico Baldo, Michele Lombardi", "title": "Lagrangian Duality for Constrained Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the potential of Lagrangian duality for learning\napplications that feature complex constraints. Such constraints arise in many\nscience and engineering domains, where the task amounts to learning\noptimization problems which must be solved repeatedly and include hard physical\nand operational constraints. The paper also considers applications where the\nlearning task must enforce constraints on the predictor itself, either because\nthey are natural properties of the function to learn or because it is desirable\nfrom a societal standpoint to impose them. This paper demonstrates\nexperimentally that Lagrangian duality brings significant benefits for these\napplications. In energy domains, the combination of Lagrangian duality and deep\nlearning can be used to obtain state-of-the-art results to predict optimal\npower flows, in energy systems, and optimal compressor settings, in gas\nnetworks. In transprecision computing, Lagrangian duality can complement deep\nlearning to impose monotonicity constraints on the predictor without\nsacrificing accuracy. Finally, Lagrangian duality can be used to enforce\nfairness constraints on a predictor and obtain state-of-the-art results when\nminimizing disparate treatments.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 03:38:43 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:41:19 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""], ["Mak", "Terrence WK", ""], ["Tran", "Cuong", ""], ["Baldo", "Federico", ""], ["Lombardi", "Michele", ""]]}, {"id": "2001.09396", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Sundeep Rangan, Philip\n  Schniter, Alyson K. Fletcher", "title": "Inference in Multi-Layer Networks with Matrix-Valued Unknowns", "comments": "3 figures, 6 pages (two-column) + Appendix. arXiv admin note: text\n  overlap with arXiv:1911.03409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the input and hidden variables of a\nstochastic multi-layer neural network from an observation of the output. The\nhidden variables in each layer are represented as matrices. This problem\napplies to signal recovery via deep generative prior models, multi-task and\nmixed regression and learning certain classes of two-layer neural networks. A\nunified approximation algorithm for both MAP and MMSE inference is proposed by\nextending a recently-developed Multi-Layer Vector Approximate Message Passing\n(ML-VAMP) algorithm to handle matrix-valued unknowns. It is shown that the\nperformance of the proposed Multi-Layer Matrix VAMP (ML-Mat-VAMP) algorithm can\nbe exactly predicted in a certain random large-system limit, where the\ndimensions $N\\times d$ of the unknown quantities grow as $N\\rightarrow\\infty$\nwith $d$ fixed. In the two-layer neural-network learning problem, this scaling\ncorresponds to the case where the number of input features and training samples\ngrow to infinity but the number of hidden nodes stays fixed. The analysis\nenables a precise prediction of the parameter and test error of the learning.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 04:00:24 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Rangan", "Sundeep", ""], ["Schniter", "Philip", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "2001.09419", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "LiteMORT: A memory efficient gradient boosting tree system on adaptive\n  compact distributions", "comments": "6 Pages,1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted decision trees (GBDT) is the leading algorithm for many\ncommercial and academic data applications. We give a deep analysis of this\nalgorithm, especially the histogram technique, which is a basis for the\nregulized distribution with compact support. We present three new\nmodifications. 1) Share memory technique to reduce memory usage. In many cases,\nit only need the data source itself and no extra memory. 2) Implicit merging\nfor \"merge overflow problem\".\"merge overflow\" means that merge some small\ndatasets to huge datasets, which are too huge to be solved. By implicit\nmerging, we just need the original small datasets to train the GBDT model. 3)\nAdaptive resize algorithm of histogram bins to improve accuracy. Experiments on\ntwo large Kaggle competitions verified our methods. They use much less memory\nthan LightGBM and have higher accuracy. We have implemented these algorithms in\nan open-source package LiteMORT. The source codes are available at\nhttps://github.com/closest-git/LiteMORT\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 08:21:14 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2001.09464", "submitter": "Frank Emmert-Streib", "authors": "Frank Emmert-Streib, Olli Yli-Harja, and Matthias Dehmer", "title": "Explainable Artificial Intelligence and Machine Learning: A reality\n  rooted perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are used to the availability of big data generated in nearly all fields of\nscience as a consequence of technological progress. However, the analysis of\nsuch data possess vast challenges. One of these relates to the explainability\nof artificial intelligence (AI) or machine learning methods. Currently, many of\nsuch methods are non-transparent with respect to their working mechanism and\nfor this reason are called black box models, most notably deep learning\nmethods. However, it has been realized that this constitutes severe problems\nfor a number of fields including the health sciences and criminal justice and\narguments have been brought forward in favor of an explainable AI. In this\npaper, we do not assume the usual perspective presenting explainable AI as it\nshould be, but rather we provide a discussion what explainable AI can be. The\ndifference is that we do not present wishful thinking but reality grounded\nproperties in relation to a scientific theory beyond physics.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:09:45 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Emmert-Streib", "Frank", ""], ["Yli-Harja", "Olli", ""], ["Dehmer", "Matthias", ""]]}, {"id": "2001.09467", "submitter": "Harish Kumaar Venkataraman", "authors": "Harish Venkataraman, Derya Aksaray, Peter Seiler", "title": "Tractable Reinforcement Learning of Signal Temporal Logic Objectives", "comments": "Github code repository:\n  https://github.com/kumaa001/Tractable_RL_for_STL_Objectives. arXiv admin\n  note: text overlap with arXiv:1609.07409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal temporal logic (STL) is an expressive language to specify time-bound\nreal-world robotic tasks and safety specifications. Recently, there has been an\ninterest in learning optimal policies to satisfy STL specifications via\nreinforcement learning (RL). Learning to satisfy STL specifications often needs\na sufficient length of state history to compute reward and the next action. The\nneed for history results in exponential state-space growth for the learning\nproblem. Thus the learning problem becomes computationally intractable for most\nreal-world applications. In this paper, we propose a compact means to capture\nstate history in a new augmented state-space representation. An approximation\nto the objective (maximizing probability of satisfaction) is proposed and\nsolved for in the new augmented state-space. We show the performance bound of\nthe approximate solution and compare it with the solution of an existing\ntechnique via simulations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:23:54 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:17:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Venkataraman", "Harish", ""], ["Aksaray", "Derya", ""], ["Seiler", "Peter", ""]]}, {"id": "2001.09485", "submitter": "Zafeirios Fountas PhD", "authors": "Cong Bao, Zafeirios Fountas, Temitayo Olugbade, Nadia\n  Bianchi-Berthouze", "title": "Multimodal Data Fusion based on the Global Workspace Theory", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network architecture, named the Global Workspace\nNetwork (GWN), which addresses the challenge of dynamic and unspecified\nuncertainties in multimodal data fusion. Our GWN is a model of attention across\nmodalities and evolving through time, and is inspired by the well-established\nGlobal Workspace Theory from the field of cognitive science. The GWN achieved\naverage F1 score of 0.92 for discrimination between pain patients and healthy\nparticipants and average F1 score = 0.75 for further classification of three\npain levels for a patient, both based on the multimodal EmoPain dataset\ncaptured from people with chronic pain and healthy people performing different\ntypes of exercise movements in unconstrained settings. In these tasks, the GWN\nsignificantly outperforms the typical fusion approach of merging by\nconcatenation. We further provide extensive analysis of the behaviour of the\nGWN and its ability to address uncertainties (hidden noise) in multimodal data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 16:52:43 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 15:00:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bao", "Cong", ""], ["Fountas", "Zafeirios", ""], ["Olugbade", "Temitayo", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "2001.09486", "submitter": "Aly El Gamal", "authors": "Rehana Mahfuz, Rajeev Sahay, Aly El Gamal", "title": "Ensemble Noise Simulation to Handle Uncertainty about Gradient-based\n  Adversarial Attacks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based adversarial attacks on neural networks can be crafted in a\nvariety of ways by varying either how the attack algorithm relies on the\ngradient, the network architecture used for crafting the attack, or both. Most\nrecent work has focused on defending classifiers in a case where there is no\nuncertainty about the attacker's behavior (i.e., the attacker is expected to\ngenerate a specific attack using a specific network architecture). However, if\nthe attacker is not guaranteed to behave in a certain way, the literature lacks\nmethods in devising a strategic defense. We fill this gap by simulating the\nattacker's noisy perturbation using a variety of attack algorithms based on\ngradients of various classifiers. We perform our analysis using a\npre-processing Denoising Autoencoder (DAE) defense that is trained with the\nsimulated noise. We demonstrate significant improvements in post-attack\naccuracy, using our proposed ensemble-trained defense, compared to a situation\nwhere no effort is made to handle uncertainty.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 17:12:47 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Mahfuz", "Rehana", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2001.09498", "submitter": "Hendra Nurdin", "authors": "Jiayin Chen and Hendra I. Nurdin and Naoki Yamamoto", "title": "Temporal Information Processing on Noisy Quantum Computers", "comments": "9 pages main text, 14 pages appendices, 13 figures. Added\n  implementation scheme using QND measurements and proposal of more efficient\n  implementation schemes without and with QND measurements. To appear in\n  Physical Review Applied", "journal-ref": "Phys. Rev. Applied 14, 024065 (2020)", "doi": "10.1103/PhysRevApplied.14.024065", "report-no": null, "categories": "quant-ph cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of machine learning and quantum computing has emerged as a\npromising approach for addressing previously untenable problems. Reservoir\ncomputing is an efficient learning paradigm that utilizes nonlinear dynamical\nsystems for temporal information processing, i.e., processing of input\nsequences to produce output sequences. Here we propose quantum reservoir\ncomputing that harnesses complex dissipative quantum dynamics. Our class of\nquantum reservoirs is universal, in that any nonlinear fading memory map can be\napproximated arbitrarily closely and uniformly over all inputs by a quantum\nreservoir from this class. We describe a subclass of the universal class that\nis readily implementable using quantum gates native to current noisy gate-model\nquantum computers. Proof-of-principle experiments on remotely accessed\ncloud-based superconducting quantum computers demonstrate that small and noisy\nquantum reservoirs can tackle high-order nonlinear temporal tasks. Our\ntheoretical and experimental results pave the path for attractive temporal\nprocessing applications of near-term gate-model quantum computers of increasing\nfidelity but without quantum error correction, signifying the potential of\nthese devices for wider applications including neural modeling, speech\nrecognition and natural language processing, going beyond static classification\nand regression tasks.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 19:00:03 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 04:04:39 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Chen", "Jiayin", ""], ["Nurdin", "Hendra I.", ""], ["Yamamoto", "Naoki", ""]]}, {"id": "2001.09502", "submitter": "Isel Grau", "authors": "Isel Grau, Dipankar Sengupta, Maria M. Garcia Lorenzo, Ann Nowe", "title": "An interpretable semi-supervised classifier using two different\n  strategies for amended self-labeling", "comments": "Accepted at Special Session on Advances on Explainable Artificial\n  Intelligence, IEEE International Conference on Fuzzy Systems (FUZZ-IEEE\n  2020), IEEE World Congress on Computational Intelligence (WCCI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of some machine learning applications, obtaining data\ninstances is a relatively easy process but labeling them could become quite\nexpensive or tedious. Such scenarios lead to datasets with few labeled\ninstances and a larger number of unlabeled ones. Semi-supervised classification\ntechniques combine labeled and unlabeled data during the learning phase in\norder to increase the classifier's generalization capability. Regrettably, most\nsuccessful semi-supervised classifiers do not allow explaining their outcome,\nthus behaving like black boxes. However, there is an increasing number of\nproblem domains in which experts demand a clear understanding of the decision\nprocess. In this paper, we report on an extended experimental study presenting\nan interpretable self-labeling grey-box classifier that uses a black box to\nestimate the missing class labels and a white box to explain the final\npredictions. Two different approaches for amending the self-labeling process\nare explored: a first one based on the confidence of the black box and the\nlatter one based on measures from Rough Set Theory. The results of the extended\nexperimental study support the interpretability by means of transparency and\nsimplicity of our classifier, while attaining superior prediction rates when\ncompared with state-of-the-art self-labeling classifiers reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 19:37:41 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 12:00:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Grau", "Isel", ""], ["Sengupta", "Dipankar", ""], ["Lorenzo", "Maria M. Garcia", ""], ["Nowe", "Ann", ""]]}, {"id": "2001.09519", "submitter": "Siddharth Sigtia", "authors": "Siddharth Sigtia, Pascal Clark, Rob Haynes, Hywel Richards, John\n  Bridle", "title": "Multi-task Learning for Voice Trigger Detection", "comments": null, "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7449-7453", "doi": "10.1109/ICASSP40776.2020.9053577", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design of a voice trigger detection system for smart\nspeakers. In this study, we address two major challenges. The first is that the\ndetectors are deployed in complex acoustic environments with external noise and\nloud playback by the device itself. Secondly, collecting training examples for\na specific keyword or trigger phrase is challenging resulting in a scarcity of\ntrigger phrase specific training data. We describe a two-stage cascaded\narchitecture where a low-power detector is always running and listening for the\ntrigger phrase. If a detection is made at this stage, the candidate audio\nsegment is re-scored by larger, more complex models to verify that the segment\ncontains the trigger phrase. In this study, we focus our attention on the\narchitecture and design of these second-pass detectors. We start by training a\ngeneral acoustic model that produces phonetic transcriptions given a large\nlabelled training dataset. Next, we collect a much smaller dataset of examples\nthat are challenging for the baseline system. We then use multi-task learning\nto train a model to simultaneously produce accurate phonetic transcriptions on\nthe larger dataset \\emph{and} discriminate between true and easily confusable\nexamples using the smaller dataset. Our results demonstrate that the proposed\nmodel reduces errors by half compared to the baseline in a range of challenging\ntest conditions \\emph{without} requiring extra parameters.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:13:07 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 09:05:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sigtia", "Siddharth", ""], ["Clark", "Pascal", ""], ["Haynes", "Rob", ""], ["Richards", "Hywel", ""], ["Bridle", "John", ""]]}, {"id": "2001.09523", "submitter": "Weimin Zhou", "authors": "Weimin Zhou, Sayantan Bhadra, Frank J. Brooks, Hua Li, Mark A.\n  Anastasio", "title": "Progressively-Growing AmbientGANs For Learning Stochastic Object Models\n  From Imaging Measurements", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective optimization of medical imaging systems requires full\ncharacterization of all sources of randomness in the measured data, which\nincludes the variability within the ensemble of objects to-be-imaged. This can\nbe accomplished by establishing a stochastic object model (SOM) that describes\nthe variability in the class of objects to-be-imaged. Generative adversarial\nnetworks (GANs) can be potentially useful to establish SOMs because they hold\ngreat promise to learn generative models that describe the variability within\nan ensemble of training data. However, because medical imaging systems record\nimaging measurements that are noisy and indirect representations of object\nproperties, GANs cannot be directly applied to establish stochastic models of\nobjects to-be-imaged. To address this issue, an augmented GAN architecture\nnamed AmbientGAN was developed to establish SOMs from noisy and indirect\nmeasurement data. However, because the adversarial training can be unstable,\nthe applicability of the AmbientGAN can be potentially limited. In this work,\nwe propose a novel training strategy---Progressive Growing of AmbientGANs\n(ProAGAN)---to stabilize the training of AmbientGANs for establishing SOMs from\nnoisy and indirect imaging measurements. An idealized magnetic resonance (MR)\nimaging system and clinical MR brain images are considered. The proposed\nmethodology is evaluated by comparing signal detection performance computed by\nuse of ProAGAN-generated synthetic images and images that depict the true\nobject properties.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:33:14 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhou", "Weimin", ""], ["Bhadra", "Sayantan", ""], ["Brooks", "Frank J.", ""], ["Li", "Hua", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2001.09526", "submitter": "Weimin Zhou", "authors": "Weimin Zhou, Mark A. Anastasio", "title": "Markov-Chain Monte Carlo Approximation of the Ideal Observer using\n  Generative Adversarial Networks", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ideal Observer (IO) performance has been advocated when optimizing\nmedical imaging systems for signal detection tasks. However, analytical\ncomputation of the IO test statistic is generally intractable. To approximate\nthe IO test statistic, sampling-based methods that employ Markov-Chain Monte\nCarlo (MCMC) techniques have been developed. However, current applications of\nMCMC techniques have been limited to several object models such as a lumpy\nobject model and a binary texture model, and it remains unclear how MCMC\nmethods can be implemented with other more sophisticated object models. Deep\nlearning methods that employ generative adversarial networks (GANs) hold great\npromise to learn stochastic object models (SOMs) from image data. In this\nstudy, we described a method to approximate the IO by applying MCMC techniques\nto SOMs learned by use of GANs. The proposed method can be employed with\narbitrary object models that can be learned by use of GANs, thereby the domain\nof applicability of MCMC techniques for approximating the IO performance is\nextended. In this study, both signal-known-exactly (SKE) and\nsignal-known-statistically (SKS) binary signal detection tasks are considered.\nThe IO performance computed by the proposed method is compared to that computed\nby the conventional MCMC method. The advantages of the proposed method are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:51:08 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhou", "Weimin", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2001.09528", "submitter": "Alberto Olmo", "authors": "Niharika Jain, Alberto Olmo, Sailik Sengupta, Lydia Manikonda,\n  Subbarao Kambhampati", "title": "Imperfect ImaGANation: Implications of GANs Exacerbating Biases on\n  Facial Data Augmentation and Snapchat Selfie Lenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that popular Generative Adversarial Networks (GANs)\nexacerbate biases along the axes of gender and skin tone when given a skewed\ndistribution of face-shots. While practitioners celebrate synthetic data\ngeneration using GANs as an economical way to augment data for training\ndata-hungry machine learning models, it is unclear whether they recognize the\nperils of such techniques when applied to real world datasets biased along\nlatent dimensions. Specifically, we show that (1) traditional GANs further skew\nthe distribution of a dataset consisting of engineering faculty headshots,\ngenerating minority modes less often and of worse quality and (2)\nimage-to-image translation (conditional) GANs also exacerbate biases by\nlightening skin color of non-white faces and transforming female facial\nfeatures to be masculine when generating faces of engineering professors. Thus,\nour study is meant to serve as a cautionary tale.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:57:26 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 23:13:23 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 02:13:46 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jain", "Niharika", ""], ["Olmo", "Alberto", ""], ["Sengupta", "Sailik", ""], ["Manikonda", "Lydia", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2001.09532", "submitter": "Diego Marcondes", "authors": "Diego Marcondes, Adilson Simonis and Junior Barrera", "title": "Learning the Hypotheses Space from data: Learning Space and U-curve\n  Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension of the classical agnostic PAC learning model\nin which learning problems are modelled not only by a Hypothesis Space\n$\\mathcal{H}$, but also by a Learning Space $\\mathbb{L}(\\mathcal{H})$, which is\na cover of $\\mathcal{H}$, constrained by a VC-dimension property, that is a\nsuitable domain for Model Selection algorithms. Our main contribution is a data\ndriven general learning algorithm to perform regularized Model Selection on\n$\\mathbb{L}(\\mathcal{H})$. A remarkable, formally proved, consequence of this\napproach are conditions on $\\mathbb{L}(\\mathcal{H})$ and on the loss function\nthat lead to estimated out-of-sample error surfaces which are true U-curves on\n$\\mathbb{L}(\\mathcal{H})$ chains, enabling a more efficient search on\n$\\mathbb{L}(\\mathcal{H})$. To our knowledge, this is the first rigorous result\nasserting that a non exhaustive search of a family of candidate models can\nreturn an optimal solution. In this new framework, an U-curve optimization\nalgorithm becomes a natural component of Model Selection, hence of learning\nalgorithms. The abstract general framework proposed here may have important\nimplications on modern learning models and on areas such as Neural Architecture\nSearch.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 22:29:33 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 13:55:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Marcondes", "Diego", ""], ["Simonis", "Adilson", ""], ["Barrera", "Junior", ""]]}, {"id": "2001.09547", "submitter": "Manie Tadayon", "authors": "Manie Tadayon, Yumi Iwashita", "title": "A clustering approach to time series forecasting using neural networks:\n  A comparative study on distance-based vs. feature-based clustering methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting has gained lots of attention recently; this is\nbecause many real-world phenomena can be modeled as time series. The massive\nvolume of data and recent advancements in the processing power of the computers\nenable researchers to develop more sophisticated machine learning algorithms\nsuch as neural networks to forecast the time series data. In this paper, we\npropose various neural network architectures to forecast the time series data\nusing the dynamic measurements; moreover, we introduce various architectures on\nhow to combine static and dynamic measurements for forecasting. We also\ninvestigate the importance of performing techniques such as anomaly detection\nand clustering on forecasting accuracy. Our results indicate that clustering\ncan improve the overall prediction time as well as improve the forecasting\nperformance of the neural network. Furthermore, we show that feature-based\nclustering can outperform the distance-based clustering in terms of speed and\nefficiency. Finally, our results indicate that adding more predictors to\nforecast the target variable will not necessarily improve the forecasting\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 00:31:37 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 09:44:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Tadayon", "Manie", ""], ["Iwashita", "Yumi", ""]]}, {"id": "2001.09569", "submitter": "Rohan Paleja", "authors": "Rohan Paleja, Matthew Gombolay", "title": "Heterogeneous Learning from Demonstration", "comments": null, "journal-ref": "2019 14th Human-Robot Interaction (HRI) Pioneers Workshop", "doi": "10.1109/HRI.2019.8673267", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of human-robot systems able to leverage the strengths of both\nhumans and their robotic counterparts has been greatly sought after because of\nthe foreseen, broad-ranging impact across industry and research. We believe the\ntrue potential of these systems cannot be reached unless the robot is able to\nact with a high level of autonomy, reducing the burden of manual tasking or\nteleoperation. To achieve this level of autonomy, robots must be able to work\nfluidly with its human partners, inferring their needs without explicit\ncommands. This inference requires the robot to be able to detect and classify\nthe heterogeneity of its partners. We propose a framework for learning from\nheterogeneous demonstration based upon Bayesian inference and evaluate a suite\nof approaches on a real-world dataset of gameplay from StarCraft II. This\nevaluation provides evidence that our Bayesian approach can outperform\nconventional methods by up to 12.8$%$.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 03:08:57 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 19:29:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Paleja", "Rohan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2001.09576", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Dylan J. Foster", "title": "Naive Exploration is Optimal for Online LQR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online adaptive control of the linear quadratic\nregulator, where the true system parameters are unknown. We prove new upper and\nlower bounds demonstrating that the optimal regret scales as\n$\\widetilde{\\Theta}({\\sqrt{d_{\\mathbf{u}}^2 d_{\\mathbf{x}} T}})$, where $T$ is\nthe number of time steps, $d_{\\mathbf{u}}$ is the dimension of the input space,\nand $d_{\\mathbf{x}}$ is the dimension of the system state. Notably, our lower\nbounds rule out the possibility of a $\\mathrm{poly}(\\log{}T)$-regret algorithm,\nwhich had been conjectured due to the apparent strong convexity of the problem.\nOur upper bound is attained by a simple variant of $\\textit{{certainty\nequivalent control}}$, where the learner selects control inputs according to\nthe optimal controller for their estimate of the system while injecting\nexploratory random noise. While this approach was shown to achieve\n$\\sqrt{T}$-regret by (Mania et al. 2019), we show that if the learner\ncontinually refines their estimates of the system matrices, the method attains\noptimal dimension dependence as well.\n  Central to our upper and lower bounds is a new approach for controlling\nperturbations of Riccati equations called the $\\textit{self-bounding ODE\nmethod}$, which we use to derive suboptimality bounds for the certainty\nequivalent controller synthesized from estimated system dynamics. This in turn\nenables regret upper bounds which hold for $\\textit{any stabilizable instance}$\nand scale with natural control-theoretic quantities.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 03:44:54 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:37:04 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 01:13:25 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Simchowitz", "Max", ""], ["Foster", "Dylan J.", ""]]}, {"id": "2001.09595", "submitter": "Xi Liu", "authors": "Xi Liu, Li Li, Ping-Chun Hsieh, Muhe Xie, Yong Ge, Rui Chen", "title": "Developing Multi-Task Recommendations with Long-Term Rewards via Policy\n  Distilled Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of online products and content, recommendation\ntechniques have been considered as an effective tool to overcome information\noverload, improve user experience, and boost business revenue. In recent years,\nwe have observed a new desideratum of considering long-term rewards of multiple\nrelated recommendation tasks simultaneously. The consideration of long-term\nrewards is strongly tied to business revenue and growth. Learning multiple\ntasks simultaneously could generally improve the performance of individual task\ndue to knowledge sharing in multi-task learning. While a few existing works\nhave studied long-term rewards in recommendations, they mainly focus on a\nsingle recommendation task. In this paper, we propose {\\it PoDiRe}: a\n\\underline{po}licy \\underline{di}stilled \\underline{re}commender that can\naddress long-term rewards of recommendations and simultaneously handle multiple\nrecommendation tasks. This novel recommendation solution is based on a marriage\nof deep reinforcement learning and knowledge distillation techniques, which is\nable to establish knowledge sharing among different tasks and reduce the size\nof a learning model. The resulting model is expected to attain better\nperformance and lower response latency for real-time recommendation services.\nIn collaboration with Samsung Game Launcher, one of the world's largest\ncommercial mobile game platforms, we conduct a comprehensive experimental study\non large-scale real data with hundreds of millions of events and show that our\nsolution outperforms many state-of-the-art methods in terms of several standard\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 06:05:42 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Liu", "Xi", ""], ["Li", "Li", ""], ["Hsieh", "Ping-Chun", ""], ["Xie", "Muhe", ""], ["Ge", "Yong", ""], ["Chen", "Rui", ""]]}, {"id": "2001.09608", "submitter": "Changjian Li", "authors": "Changjian Li", "title": "Some Insights into Lifelong Reinforcement Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A lifelong reinforcement learning system is a learning system that has the\nability to learn through trail-and-error interaction with the environment over\nits lifetime. In this paper, I give some arguments to show that the traditional\nreinforcement learning paradigm fails to model this type of learning system.\nSome insights into lifelong reinforcement learning are provided, along with a\nsimplistic prototype lifelong reinforcement learning system.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:26:12 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Changjian", ""]]}, {"id": "2001.09610", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz", "title": "Practical Fast Gradient Sign Attack against Mammographic Image\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has been a topic of major research for many\nyears. Especially, with the emergence of deep neural network (DNN), these\nstudies have been tremendously successful. Today machines are capable of making\nfaster, more accurate decision than human. Thanks to the great development of\nmachine learning (ML) techniques, ML have been used many different fields such\nas education, medicine, malware detection, autonomous car etc. In spite of\nhaving this degree of interest and much successful research, ML models are\nstill vulnerable to adversarial attacks. Attackers can manipulate clean data in\norder to fool the ML classifiers to achieve their desire target. For instance;\na benign sample can be modified as a malicious sample or a malicious one can be\naltered as benign while this modification can not be recognized by human\nobserver. This can lead to many financial losses, or serious injuries, even\ndeaths. The motivation behind this paper is that we emphasize this issue and\nwant to raise awareness. Therefore, the security gap of mammographic image\nclassifier against adversarial attack is demonstrated. We use mamographic\nimages to train our model then evaluate our model performance in terms of\naccuracy. Later on, we poison original dataset and generate adversarial samples\nthat missclassified by the model. We then using structural similarity index\n(SSIM) analyze similarity between clean images and adversarial images. Finally,\nwe show how successful we are to misuse by using different poisoning factors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:37:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Yilmaz", "Ibrahim", ""]]}, {"id": "2001.09612", "submitter": "Irandokht Parviziomran", "authors": "Irandokht Parviziomran, Shun Cao, Haeyong Yang, Seungbae Park, and\n  Daehan Won", "title": "Optimization of Passive Chip Components Placement with Self-Alignment\n  Effect for Advanced Surface Mounting Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface mount technology (SMT) is an enhanced method in electronic packaging\nin which electronic components are placed directly on soldered printing circuit\nboard (PCB) and are permanently attached on PCB with the aim of reflow\nsoldering process. During reflow process, once deposited solder pastes start\nmelting, electronic components move in a direction that achieve their highest\nsymmetry. This motion is known as self-alignment since can correct potential\nmounting misalignment. In this study, two noticeable machine learning\nalgorithms, including support vector regression (SVR) and random forest\nregression (RFR) are proposed as a prediction technique to (1) diagnose the\nrelation among component self-alignment, deposited solder paste status and\nplacement machining parameters, (2) predict the final component position on PCB\nin x, y, and rotational directions before entering in the reflow process. Based\non the prediction result, a non-linear optimization model (NLP) is developed to\noptimize placement parameters at initial stage. Resultantly, RFR outperforms in\nterms of prediction model fitness and error. The optimization model is run for\n6 samples in which the minimum Euclidean distance from component position after\nreflow process from ideal position (i.e., the center of pads) is outlined as\n25.57 ({\\mu}m) regarding defined boundaries in model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:37:47 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Parviziomran", "Irandokht", ""], ["Cao", "Shun", ""], ["Yang", "Haeyong", ""], ["Park", "Seungbae", ""], ["Won", "Daehan", ""]]}, {"id": "2001.09619", "submitter": "Irandokht Parviziomran", "authors": "Irandokht Parviziomran, Shun Cao, Krishnaswami Srihari, and Daehan Won", "title": "Data-Driven Prediction Model of Components Shift during Reflow Process\n  in Surface Mount Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In surface mount technology (SMT), mounted components on soldered pads are\nsubject to move during reflow process. This capability is known as\nself-alignment and is the result of fluid dynamic behaviour of molten solder\npaste. This capability is critical in SMT because inaccurate self-alignment\ncauses defects such as overhanging, tombstoning, etc. while on the other side,\nit can enable components to be perfectly self-assembled on or near the desire\nposition. The aim of this study is to develop a machine learning model that\npredicts the components movement during reflow in x and y-directions as well as\nrotation. Our study is composed of two steps: (1) experimental data are studied\nto reveal the relationships between self-alignment and various factors\nincluding component geometry, pad geometry, etc. (2) advanced machine learning\nprediction models are applied to predict the distance and the direction of\ncomponents shift using support vector regression (SVR), neural network (NN),\nand random forest regression (RFR). As a result, RFR can predict components\nshift with the average fitness of 99%, 99%, and 96% and with average prediction\nerror of 13.47 (um), 12.02 (um), and 1.52 (deg.) for component shift in x, y,\nand rotational directions, respectively. This enhancement provides the future\ncapability of the parameters' optimization in the pick and placement machine to\ncontrol the best placement location and minimize the intrinsic defects caused\nby the self-alignment.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:00:23 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Parviziomran", "Irandokht", ""], ["Cao", "Shun", ""], ["Srihari", "Krishnaswami", ""], ["Won", "Daehan", ""]]}, {"id": "2001.09621", "submitter": "Matthias Fey", "authors": "Matthias Fey, Jan E. Lenssen, Christopher Morris, Jonathan Masci, Nils\n  M. Kriege", "title": "Deep Graph Matching Consensus", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a two-stage neural architecture for learning and refining\nstructural correspondences between graphs. First, we use localized node\nembeddings computed by a graph neural network to obtain an initial ranking of\nsoft correspondences between nodes. Secondly, we employ synchronous message\npassing networks to iteratively re-rank the soft correspondences to reach a\nmatching consensus in local neighborhoods between graphs. We show,\ntheoretically and empirically, that our message passing scheme computes a\nwell-founded measure of consensus for corresponding neighborhoods, which is\nthen used to guide the iterative re-ranking process. Our purely local and\nsparsity-aware architecture scales well to large, real-world inputs while still\nbeing able to recover global correspondences consistently. We demonstrate the\npractical effectiveness of our method on real-world tasks from the fields of\ncomputer vision and entity alignment between knowledge graphs, on which we\nimprove upon the current state-of-the-art. Our source code is available under\nhttps://github.com/rusty1s/ deep-graph-matching-consensus.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:05:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fey", "Matthias", ""], ["Lenssen", "Jan E.", ""], ["Morris", "Christopher", ""], ["Masci", "Jonathan", ""], ["Kriege", "Nils M.", ""]]}, {"id": "2001.09623", "submitter": "Melih Elibol", "authors": "Melih Elibol, Lihua Lei, Michael I. Jordan", "title": "Variance Reduction with Sparse Gradients", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduction methods such as SVRG and SpiderBoost use a mixture of\nlarge and small batch gradients to reduce the variance of stochastic gradients.\nCompared to SGD, these methods require at least double the number of operations\nper update to model parameters. To reduce the computational cost of these\nmethods, we introduce a new sparsity operator: The random-top-k operator. Our\noperator reduces computational complexity by estimating gradient sparsity\nexhibited in a variety of applications by combining the top-k operator and the\nrandomized coordinate descent operator. With this operator, large batch\ngradients offer an extra benefit beyond variance reduction: A reliable estimate\nof gradient sparsity. Theoretically, our algorithm is at least as good as the\nbest algorithm (SpiderBoost), and further excels in performance whenever the\nrandom-top-k operator captures gradient sparsity. Empirically, our algorithm\nconsistently outperforms SpiderBoost using various models on various tasks\nincluding image classification, natural language processing, and sparse matrix\nfactorization. We also provide empirical evidence to support the intuition\nbehind our algorithm via a simple gradient entropy computation, which serves to\nquantify gradient sparsity at every iteration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:23:58 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Elibol", "Melih", ""], ["Lei", "Lihua", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2001.09631", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Aaron Zimmer, Xinyao Sun, Parwant Ghuman, Irene\n  Cheng", "title": "An Unsupervised Generative Neural Approach for InSAR Phase Filtering and\n  Coherence Estimation", "comments": "to be published in a future issue of IEEE Geoscience and Remote\n  Sensing Letters", "journal-ref": null, "doi": "10.1109/LGRS.2020.3010504", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase filtering and pixel quality (coherence) estimation is critical in\nproducing Digital Elevation Models (DEMs) from Interferometric Synthetic\nAperture Radar (InSAR) images, as it removes spatial inconsistencies (residues)\nand immensely improves the subsequent unwrapping. Large amount of InSAR data\nfacilitates Wide Area Monitoring (WAM) over geographical regions. Advances in\nparallel computing have accelerated Convolutional Neural Networks (CNNs),\ngiving them advantages over human performance on visual pattern recognition,\nwhich makes CNNs a good choice for WAM. Nevertheless, this research is largely\nunexplored. We thus propose \"GenInSAR\", a CNN-based generative model for joint\nphase filtering and coherence estimation, that directly learns the InSAR data\ndistribution. GenInSAR's unsupervised training on satellite and simulated noisy\nInSAR images outperforms other five related methods in total residue reduction\n(over 16.5% better on average) with less over-smoothing/artefacts around branch\ncuts. GenInSAR's Phase, and Coherence Root-Mean-Squared-Error and Phase Cosine\nError have average improvements of 0.54, 0.07, and 0.05 respectively compared\nto the related methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:50:39 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 03:29:41 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 22:33:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Zimmer", "Aaron", ""], ["Sun", "Xinyao", ""], ["Ghuman", "Parwant", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.09636", "submitter": "Meysam Vakili", "authors": "Meysam Vakili, Mohammad Ghamsari and Masoumeh Rezaei", "title": "Performance Analysis and Comparison of Machine and Deep Learning\n  Algorithms for IoT Data Classification", "comments": "13 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the growth of Internet of Things (IoT) as an emerging\ntechnology has been unbelievable. The number of networkenabled devices in IoT\ndomains is increasing dramatically, leading to the massive production of\nelectronic data. These data contain valuable information which can be used in\nvarious areas, such as science, industry, business and even social life. To\nextract and analyze this information and make IoT systems smart, the only\nchoice is entering artificial intelligence (AI) world and leveraging the power\nof machine learning and deep learning techniques. This paper evaluates the\nperformance of 11 popular machine and deep learning algorithms for\nclassification task using six IoT-related datasets. These algorithms are\ncompared according to several performance evaluation metrics including\nprecision, recall, f1-score, accuracy, execution time, ROC-AUC score and\nconfusion matrix. A specific experiment is also conducted to assess the\nconvergence speed of developed models. The comprehensive experiments indicated\nthat, considering all performance metrics, Random Forests performed better than\nother machine learning models, while among deep learning models, ANN and CNN\nachieved more interesting results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:14:11 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Vakili", "Meysam", ""], ["Ghamsari", "Mohammad", ""], ["Rezaei", "Masoumeh", ""]]}, {"id": "2001.09654", "submitter": "Catuscia Palamidessi", "authors": "Catuscia Palamidessi and Marco Romanelli", "title": "Feature selection in machine learning: R\\'enyi min-entropy vs Shannon\n  entropy", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection, in the context of machine learning, is the process of\nseparating the highly predictive feature from those that might be irrelevant or\nredundant. Information theory has been recognized as a useful concept for this\ntask, as the prediction power stems from the correlation, i.e., the mutual\ninformation, between features and labels. Many algorithms for feature selection\nin the literature have adopted the Shannon-entropy-based mutual information. In\nthis paper, we explore the possibility of using R\\'enyi min-entropy instead. In\nparticular, we propose an algorithm based on a notion of conditional R\\'enyi\nmin-entropy that has been recently adopted in the field of security and\nprivacy, and which is strictly related to the Bayes error. We prove that in\ngeneral the two approaches are incomparable, in the sense that we show that we\ncan construct datasets on which the R\\'enyi-based algorithm performs better\nthan the corresponding Shannon-based one, and datasets on which the situation\nis reversed. In practice, however, when considering datasets of real data, it\nseems that the R\\'enyi-based algorithm tends to outperform the other one. We\nhave effectuate several experiments on the BASEHOCK, SEMEION, and GISETTE\ndatasets, and in all of them we have indeed observed that the R\\'enyi-based\nalgorithm gives better results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:50:54 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Palamidessi", "Catuscia", ""], ["Romanelli", "Marco", ""]]}, {"id": "2001.09695", "submitter": "\\'Alvaro L\\'opez Garc\\'ia", "authors": "Mar\\'ia Castrillo and \\'Alvaro L\\'opez Garc\\'ia", "title": "Estimation of high frequency nutrient concentrations from water quality\n  surrogates using machine learning methods", "comments": null, "journal-ref": "Water Research. Volume 172, 1 April 2020, 115490", "doi": "10.1016/j.watres.2020.115490", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous high frequency water quality monitoring is becoming a critical\ntask to support water management. Despite the advancements in sensor\ntechnologies, certain variables cannot be easily and/or economically monitored\nin-situ and in real time. In these cases, surrogate measures can be used to\nmake estimations by means of data-driven models. In this work, variables that\nare commonly measured in-situ are used as surrogates to estimate the\nconcentrations of nutrients in a rural catchment and in an urban one, making\nuse of machine learning models, specifically Random Forests. The results are\ncompared with those of linear modelling using the same number of surrogates,\nobtaining a reduction in the Root Mean Squared Error (RMSE) of up to 60.1%. The\nprofit from including up to seven surrogate sensors was computed, concluding\nthat adding more than 4 and 5 sensors in each of the catchments respectively\nwas not worthy in terms of error improvement.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:18:22 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Castrillo", "Mar\u00eda", ""], ["Garc\u00eda", "\u00c1lvaro L\u00f3pez", ""]]}, {"id": "2001.09696", "submitter": "Vincent Moens", "authors": "Vincent Moens, Simiao Yu, Gholamreza Salimi-Khorshidi", "title": "$\\P$ILCRO: Making Importance Landscapes Flat Again", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have had a great success in numerous tasks,\nincluding image classification, object detection, sequence modelling, and many\nmore. It is generally assumed that such neural networks are translation\ninvariant, meaning that they can detect a given feature independent of its\nlocation in the input image. While this is true for simple cases, where\nnetworks are composed of a restricted number of layer classes and where images\nare fairly simple, complex images with common state-of-the-art networks do not\nusually enjoy this property as one might hope. This paper shows that most of\nthe existing convolutional architectures define, at initialisation, a specific\nfeature importance landscape that conditions their capacity to attend to\ndifferent locations of the images later during training or even at test time.\nWe demonstrate how this phenomenon occurs under specific conditions and how it\ncan be adjusted under some assumptions. We derive the P-objective, or PILCRO\nfor Pixel-wise Importance Landscape Curvature Regularised Objective, a simple\nregularisation technique that favours weight configurations that produce\nsmooth, low-curvature importance landscapes that are conditioned on the data\nand not on the chosen architecture. Through extensive experiments, we further\nshow that P-regularised versions of popular computer vision networks have a\nflat importance landscape, train faster, result in a better accuracy and are\nmore robust to noise at test time, when compared to their original counterparts\nin common computer-vision classification settings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:20:56 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 11:41:02 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Moens", "Vincent", ""], ["Yu", "Simiao", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "2001.09700", "submitter": "Reihaneh Torkzadehmahani", "authors": "Reihaneh Torkzadehmahani, Peter Kairouz, Benedict Paten", "title": "DP-CGAN: Differentially Private Synthetic Data and Label Generation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) are one of the well-known models to\ngenerate synthetic data including images, especially for research communities\nthat cannot use original sensitive datasets because they are not publicly\naccessible. One of the main challenges in this area is to preserve the privacy\nof individuals who participate in the training of the GAN models. To address\nthis challenge, we introduce a Differentially Private Conditional GAN (DP-CGAN)\ntraining framework based on a new clipping and perturbation strategy, which\nimproves the performance of the model while preserving privacy of the training\ndataset. DP-CGAN generates both synthetic data and corresponding labels and\nleverages the recently introduced Renyi differential privacy accountant to\ntrack the spent privacy budget. The experimental results show that DP-CGAN can\ngenerate visually and empirically promising results on the MNIST dataset with a\nsingle-digit epsilon parameter in differential privacy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:26:58 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Torkzadehmahani", "Reihaneh", ""], ["Kairouz", "Peter", ""], ["Paten", "Benedict", ""]]}, {"id": "2001.09734", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "One Explanation Does Not Fit All: The Promise of Interactive\n  Explanations for Machine Learning Transparency", "comments": "Published in the Kunstliche Intelligenz journal, special issue on\n  Challenges in Interactive Machine Learning", "journal-ref": null, "doi": "10.1007/s13218-020-00637-y", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for transparency of predictive systems based on Machine Learning\nalgorithms arises as a consequence of their ever-increasing proliferation in\nthe industry. Whenever black-box algorithmic predictions influence human\naffairs, the inner workings of these algorithms should be scrutinised and their\ndecisions explained to the relevant stakeholders, including the system\nengineers, the system's operators and the individuals whose case is being\ndecided. While a variety of interpretability and explainability methods is\navailable, none of them is a panacea that can satisfy all diverse expectations\nand competing objectives that might be required by the parties involved. We\naddress this challenge in this paper by discussing the promises of Interactive\nMachine Learning for improved transparency of black-box systems using the\nexample of contrastive explanations -- a state-of-the-art approach to\nInterpretable Machine Learning.\n  Specifically, we show how to personalise counterfactual explanations by\ninteractively adjusting their conditional statements and extract additional\nexplanations by asking follow-up \"What if?\" questions. Our experience in\nbuilding, deploying and presenting this type of system allowed us to list\ndesired properties as well as potential limitations, which can be used to guide\nthe development of interactive explainers. While customising the medium of\ninteraction, i.e., the user interface comprising of various communication\nchannels, may give an impression of personalisation, we argue that adjusting\nthe explanation itself and its content is more important. To this end,\nproperties such as breadth, scope, context, purpose and target of the\nexplanation have to be considered, in addition to explicitly informing the\nexplainee about its limitations and caveats...\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 13:10:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2001.09735", "submitter": "Homayoun Valafar", "authors": "Nicholas Boltin, Daniel Vu, Bethany Janos, Alyssa Shofner, Joan\n  Culley, Homayoun Valafar", "title": "An AI model for Rapid and Accurate Identification of Chemical Agents in\n  Mass Casualty Incidents", "comments": "7 pages, published in HIMS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we examine the effectiveness of WISER in identification of a\nchemical culprit during a chemical based Mass Casualty Incident (MCI). We also\nevaluate and compare Binary Decision Tree (BDT) and Artificial Neural Networks\n(ANN) using the same experimental conditions as WISER. The reverse engineered\nset of Signs/Symptoms from the WISER application was used as the training set\nand 31,100 simulated patient records were used as the testing set. Three sets\nof simulated patient records were generated by 5%, 10% and 15% perturbation of\nthe Signs/Symptoms of each chemical record. While all three methods achieved a\n100% training accuracy, WISER, BDT and ANN produced performances in the range\nof: 1.8%-0%, 65%-26%, 67%-21% respectively. A preliminary investigation of\ndimensional reduction using ANN illustrated a dimensional collapse from 79\nvariables to 40 with little loss of classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:08:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Boltin", "Nicholas", ""], ["Vu", "Daniel", ""], ["Janos", "Bethany", ""], ["Shofner", "Alyssa", ""], ["Culley", "Joan", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2001.09740", "submitter": "Hoda Sedighi", "authors": "Hoda Sedighi", "title": "Classification of human activity recognition using smartphones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have been the most popular and widely used devices among means of\ncommunication. Nowadays, human activity recognition is possible on mobile\ndevices by embedded sensors, which can be exploited to manage user behavior on\nmobile devices by predicting user activity. To reach this aim, storing activity\ncharacteristics, Classification, and mapping them to a learning algorithm was\nstudied in this research. In this study, we applied categorization through deep\nbelief network to test and training data, which resulted in 98.25% correct\ndiagnosis in training data and 93.01% in test data. Therefore, in this study,\nwe prove that the deep belief network is a suitable method for this particular\npurpose.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 16:08:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sedighi", "Hoda", ""]]}, {"id": "2001.09748", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Walter Karlen", "title": "A Deep Learning Approach to Diagnosing Multiple Sclerosis from\n  Smartphone Data", "comments": null, "journal-ref": null, "doi": "10.1109/JBHI.2020.3021143", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis (MS) affects the central nervous system with a wide range\nof symptoms. MS can, for example, cause pain, changes in mood and fatigue, and\nmay impair a person's movement, speech and visual functions. Diagnosis of MS\ntypically involves a combination of complex clinical assessments and tests to\nrule out other diseases with similar symptoms. New technologies, such as\nsmartphone monitoring in free-living conditions, could potentially aid in\nobjectively assessing the symptoms of MS by quantifying symptom presence and\nintensity over long periods of time. Here, we present a deep-learning approach\nto diagnosing MS from smartphone-derived digital biomarkers that uses a novel\ncombination of a multilayer perceptron with neural soft attention to improve\nlearning of patterns in long-term smartphone monitoring data. Using data from a\ncohort of 774 participants, we demonstrate that our deep-learning models are\nable to distinguish between people with and without MS with an area under the\nreceiver operating characteristic curve of 0.88 (95% CI: 0.70, 0.88). Our\nexperimental results indicate that digital biomarkers derived from smartphone\ndata could in the future be used as additional diagnostic criteria for MS.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:29:16 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 12:12:43 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 07:32:28 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Schwab", "Patrick", ""], ["Karlen", "Walter", ""]]}, {"id": "2001.09771", "submitter": "Justin Domke", "authors": "Justin Domke", "title": "Moment-Matching Conditions for Exponential Families with Conditioning or\n  Hidden Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood learning with exponential families leads to\nmoment-matching of the sufficient statistics, a classic result. This can be\ngeneralized to conditional exponential families and/or when there are hidden\ndata. This document gives a first-principles explanation of these generalized\nmoment-matching conditions, along with a self-contained derivation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:31:16 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Domke", "Justin", ""]]}, {"id": "2001.09773", "submitter": "Zachary Lipton", "authors": "Sina Fazelpour, Zachary C. Lipton", "title": "Algorithmic Fairness from a Non-ideal Perspective", "comments": "Accepted for publication at the AAAI/ACM Conference on Artificial\n  Intelligence, Ethics, and Society (AIES) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent breakthroughs in predictive modeling, practitioners in\nboth industry and government have turned to machine learning with hopes of\noperationalizing predictions to drive automated decisions. Unfortunately, many\nsocial desiderata concerning consequential decisions, such as justice or\nfairness, have no natural formulation within a purely predictive framework. In\nefforts to mitigate these problems, researchers have proposed a variety of\nmetrics for quantifying deviations from various statistical parities that we\nmight expect to observe in a fair world and offered a variety of algorithms in\nattempts to satisfy subsets of these parities or to trade off the degree to\nwhich they are satisfied against utility. In this paper, we connect this\napproach to \\emph{fair machine learning} to the literature on ideal and\nnon-ideal methodological approaches in political philosophy. The ideal approach\nrequires positing the principles according to which a just world would operate.\nIn the most straightforward application of ideal theory, one supports a\nproposed policy by arguing that it closes a discrepancy between the real and\nthe perfectly just world. However, by failing to account for the mechanisms by\nwhich our non-ideal world arose, the responsibilities of various\ndecision-makers, and the impacts of proposed policies, naive applications of\nideal thinking can lead to misguided interventions. In this paper, we\ndemonstrate a connection between the fair machine learning literature and the\nideal approach in political philosophy, and argue that the increasingly\napparent shortcomings of proposed fair machine learning algorithms reflect\nbroader troubles faced by the ideal approach. We conclude with a critical\ndiscussion of the harms of misguided solutions, a reinterpretation of\nimpossibility results, and directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:44:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2001.09784", "submitter": "Dana Pessach", "authors": "Dana Pessach and Erez Shmueli", "title": "Algorithmic Fairness", "comments": "31 pages, 1 figure, This is a survey article that reviews the field\n  of algorithmic fairness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of decisions regarding the daily lives of human beings\nare being controlled by artificial intelligence (AI) algorithms in spheres\nranging from healthcare, transportation, and education to college admissions,\nrecruitment, provision of loans and many more realms. Since they now touch on\nmany aspects of our lives, it is crucial to develop AI algorithms that are not\nonly accurate but also objective and fair. Recent studies have shown that\nalgorithmic decision-making may be inherently prone to unfairness, even when\nthere is no intention for it. This paper presents an overview of the main\nconcepts of identifying, measuring and improving algorithmic fairness when\nusing AI algorithms. The paper begins by discussing the causes of algorithmic\nbias and unfairness and the common definitions and measures for fairness.\nFairness-enhancing mechanisms are then reviewed and divided into pre-process,\nin-process and post-process mechanisms. A comprehensive comparison of the\nmechanisms is then conducted, towards a better understanding of which\nmechanisms should be used in different scenarios. The paper then describes the\nmost commonly used fairness-related datasets in this field. Finally, the paper\nends by reviewing several emerging research sub-fields of algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:01:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pessach", "Dana", ""], ["Shmueli", "Erez", ""]]}, {"id": "2001.09797", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Nikolaos Mittas, George Kakarontzas, Theodosios\n  Theodosiou, Lefteris Angelis, Madjid Fathi", "title": "Competence Assessment as an Expert System for Human Resource Management:\n  A Mathematical Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient human resource management needs accurate assessment and\nrepresentation of available competences as well as effective mapping of\nrequired competences for specific jobs and positions. In this regard,\nappropriate definition and identification of competence gaps express\ndifferences between acquired and required competences. Using a detailed\nquantification scheme together with a mathematical approach is a way to support\naccurate competence analytics, which can be applied in a wide variety of\nsectors and fields. This article describes the combined use of software\ntechnologies and mathematical and statistical methods for assessing and\nanalyzing competences in human resource information systems. Based on a\nstandard competence model, which is called a Professional, Innovative and\nSocial competence tree, the proposed framework offers flexible tools to experts\nin real enterprise environments, either for evaluation of employees towards an\noptimal job assignment and vocational training or for recruitment processes.\nThe system has been tested with real human resource data sets in the frame of\nthe European project called ComProFITS.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:37:15 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Mittas", "Nikolaos", ""], ["Kakarontzas", "George", ""], ["Theodosiou", "Theodosios", ""], ["Angelis", "Lefteris", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09821", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee and Jia-Chun Lin", "title": "DALC: Distributed Automatic LSTM Customization for Fine-Grained Traffic\n  Speed Prediction", "comments": "12 pages, 5 figures, the 34th International Conference on Advanced\n  Information Networking and Applications (AINA 2020), Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, several approaches have been introduced for short-term\ntraffic prediction. However, providing fine-grained traffic prediction for\nlarge-scale transportation networks where numerous detectors are geographically\ndeployed to collect traffic data is still an open issue. To address this issue,\nin this paper, we formulate the problem of customizing an LSTM model for a\nsingle detector into a finite Markov decision process and then introduce an\nAutomatic LSTM Customization (ALC) algorithm to automatically customize an LSTM\nmodel for a single detector such that the corresponding prediction accuracy can\nbe as satisfactory as possible and the time consumption can be as low as\npossible. Based on the ALC algorithm, we introduce a distributed approach\ncalled Distributed Automatic LSTM Customization (DALC) to customize an LSTM\nmodel for every detector in large-scale transportation networks. Our experiment\ndemonstrates that the DALC provides higher prediction accuracy than several\napproaches provided by Apache Spark MLlib.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:25:36 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 12:44:23 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""]]}, {"id": "2001.09822", "submitter": "Mario Aguilar-Simon", "authors": "Andrew Brna, Ryan Brown, Patrick Connolly, Stephen Simons, Renee\n  Shimizu, Mario Aguilar-Simon", "title": "Uncertainty-based Modulation for Lifelong Learning", "comments": null, "journal-ref": "Neural Networks, Vol. 120, pp 129-142, 2019", "doi": "10.1016/j.neunet.2019.09.011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of machine learning algorithms for intelligent agents capable of\ncontinuous, lifelong learning is a critical objective for algorithms being\ndeployed on real-life systems in dynamic environments. Here we present an\nalgorithm inspired by neuromodulatory mechanisms in the human brain that\nintegrates and expands upon Stephen Grossberg\\'s ground-breaking Adaptive\nResonance Theory proposals. Specifically, it builds on the concept of\nuncertainty, and employs a series of neuromodulatory mechanisms to enable\ncontinuous learning, including self-supervised and one-shot learning. Algorithm\ncomponents were evaluated in a series of benchmark experiments that demonstrate\nstable learning without catastrophic forgetting. We also demonstrate the\ncritical role of developing these systems in a closed-loop manner where the\nenvironment and the agent\\'s behaviors constrain and guide the learning\nprocess. To this end, we integrated the algorithm into an embodied simulated\ndrone agent. The experiments show that the algorithm is capable of continuous\nlearning of new tasks and under changed conditions with high classification\naccuracy (greater than 94 percent) in a virtual environment, without\ncatastrophic forgetting. The algorithm accepts high dimensional inputs from any\nstate-of-the-art detection and feature extraction algorithms, making it a\nflexible addition to existing systems. We also describe future development\nefforts focused on imbuing the algorithm with mechanisms to seek out new\nknowledge as well as employ a broader range of neuromodulatory processes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:34:37 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Brna", "Andrew", ""], ["Brown", "Ryan", ""], ["Connolly", "Patrick", ""], ["Simons", "Stephen", ""], ["Shimizu", "Renee", ""], ["Aguilar-Simon", "Mario", ""]]}, {"id": "2001.09832", "submitter": "Olivier Teytaud", "authors": "Tristan Cazenave, Yen-Chi Chen, Guan-Wei Chen, Shi-Yu Chen, Xian-Dong\n  Chiu, Julien Dehos, Maria Elsa, Qucheng Gong, Hengyuan Hu, Vasil Khalidov,\n  Cheng-Ling Li, Hsin-I Lin, Yu-Jin Lin, Xavier Martinet, Vegard Mella, Jeremy\n  Rapin, Baptiste Roziere, Gabriel Synnaeve, Fabien Teytaud, Olivier Teytaud,\n  Shi-Cheng Ye, Yi-Jun Ye, Shi-Jim Yen, Sergey Zagoruyko", "title": "Polygames: Improved Zero Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since DeepMind's AlphaZero, Zero learning quickly became the state-of-the-art\nmethod for many board games. It can be improved using a fully convolutional\nstructure (no fully connected layer). Using such an architecture plus global\npooling, we can create bots independent of the board size. The training can be\nmade more robust by keeping track of the best checkpoints during the training\nand by training against them. Using these features, we release Polygames, our\nframework for Zero learning, with its library of games and its checkpoints. We\nwon against strong humans at the game of Hex in 19x19, which was often said to\nbe untractable for zero learning; and in Havannah. We also won several first\nplaces at the TAAI competitions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:49:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Cazenave", "Tristan", ""], ["Chen", "Yen-Chi", ""], ["Chen", "Guan-Wei", ""], ["Chen", "Shi-Yu", ""], ["Chiu", "Xian-Dong", ""], ["Dehos", "Julien", ""], ["Elsa", "Maria", ""], ["Gong", "Qucheng", ""], ["Hu", "Hengyuan", ""], ["Khalidov", "Vasil", ""], ["Li", "Cheng-Ling", ""], ["Lin", "Hsin-I", ""], ["Lin", "Yu-Jin", ""], ["Martinet", "Xavier", ""], ["Mella", "Vegard", ""], ["Rapin", "Jeremy", ""], ["Roziere", "Baptiste", ""], ["Synnaeve", "Gabriel", ""], ["Teytaud", "Fabien", ""], ["Teytaud", "Olivier", ""], ["Ye", "Shi-Cheng", ""], ["Ye", "Yi-Jun", ""], ["Yen", "Shi-Jim", ""], ["Zagoruyko", "Sergey", ""]]}, {"id": "2001.09841", "submitter": "Amir Mosavi Prof", "authors": "Javad Hassannataj Joloudari, Edris Hassannataj Joloudari, Hamid\n  Saadatfar, Mohammad GhasemiGol, Seyyed Mohammad Razavi, Amir Mosavi, Narjes\n  Nabipour, Shahaboddin Shamshirband, and Laszlo Nadai", "title": "Coronary Artery Disease Diagnosis; Ranking the Significant Features\n  Using Random Trees Model", "comments": "25 pages, 9 figures", "journal-ref": "International Journal of Environmental Research and Public Health,\n  2020", "doi": "10.3390/ijerph17030731", "report-no": null, "categories": "physics.med-ph cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heart disease is one of the most common diseases in middle-aged citizens.\nAmong the vast number of heart diseases, the coronary artery disease (CAD) is\nconsidered as a common cardiovascular disease with a high death rate. The most\npopular tool for diagnosing CAD is the use of medical imaging, e.g.,\nangiography. However, angiography is known for being costly and also associated\nwith a number of side effects. Hence, the purpose of this study is to increase\nthe accuracy of coronary heart disease diagnosis through selecting significant\npredictive features in order of their ranking. In this study, we propose an\nintegrated method using machine learning. The machine learning methods of\nrandom trees (RTs), decision tree of C5.0, support vector machine (SVM),\ndecision tree of Chi-squared automatic interaction detection (CHAID) are used\nin this study. The proposed method shows promising results and the study\nconfirms that RTs model outperforms other models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:01:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Joloudari", "Javad Hassannataj", ""], ["Joloudari", "Edris Hassannataj", ""], ["Saadatfar", "Hamid", ""], ["GhasemiGol", "Mohammad", ""], ["Razavi", "Seyyed Mohammad", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Shamshirband", "Shahaboddin", ""], ["Nadai", "Laszlo", ""]]}, {"id": "2001.09849", "submitter": "Yuqing Hu", "authors": "Yuqing Hu, Vincent Gripon, St\\'ephane Pateux", "title": "Graph-based Interpolation of Feature Vectors for Accurate Few-Shot\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot classification, the aim is to learn models able to discriminate\nclasses using only a small number of labeled examples. In this context, works\nhave proposed to introduce Graph Neural Networks (GNNs) aiming at exploiting\nthe information contained in other samples treated concurrently, what is\ncommonly referred to as the transductive setting in the literature. These GNNs\nare trained all together with a backbone feature extractor. In this paper, we\npropose a new method that relies on graphs only to interpolate feature vectors\ninstead, resulting in a transductive learning setting with no additional\nparameters to train. Our proposed method thus exploits two levels of\ninformation: a) transfer features obtained on generic datasets, b) transductive\ninformation obtained from other samples to be classified. Using standard\nfew-shot vision classification datasets, we demonstrate its ability to bring\nsignificant gains compared to other works.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:12:43 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 10:05:59 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 13:17:55 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 07:56:12 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Hu", "Yuqing", ""], ["Gripon", "Vincent", ""], ["Pateux", "St\u00e9phane", ""]]}, {"id": "2001.09876", "submitter": "Sandipan Sikdar", "authors": "Binny Mathew, Sandipan Sikdar, Florian Lemmerich and Markus Strohmaier", "title": "The POLAR Framework: Polar Opposites Enable Interpretability of\n  Pre-Trained Word Embeddings", "comments": "Accepted at Web Conference (WWW) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce POLAR - a framework that adds interpretability to pre-trained\nword embeddings via the adoption of semantic differentials. Semantic\ndifferentials are a psychometric construct for measuring the semantics of a\nword by analysing its position on a scale between two polar opposites (e.g.,\ncold -- hot, soft -- hard). The core idea of our approach is to transform\nexisting, pre-trained word embeddings via semantic differentials to a new\n\"polar\" space with interpretable dimensions defined by such polar opposites.\nOur framework also allows for selecting the most discriminative dimensions from\na set of polar dimensions provided by an oracle, i.e., an external source. We\ndemonstrate the effectiveness of our framework by deploying it to various\ndownstream tasks, in which our interpretable word embeddings achieve a\nperformance that is comparable to the original word embeddings. We also show\nthat the interpretable dimensions selected by our framework align with human\njudgement. Together, these results demonstrate that interpretability can be\nadded to word embeddings without compromising performance. Our work is relevant\nfor researchers and engineers interested in interpreting pre-trained word\nembeddings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:58:57 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:40:53 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mathew", "Binny", ""], ["Sikdar", "Sandipan", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2001.09886", "submitter": "Olga Mikheeva", "authors": "Olga Mikheeva, Ieva Kazlauskaite, Hedvig Kjellstr\\\"om, Carl Henrik Ek", "title": "Bayesian nonparametric shared multi-sequence time series segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a method for segmenting time series data using\ntools from Bayesian nonparametrics. We consider the task of temporal\nsegmentation of a set of time series data into representative stationary\nsegments. We use Gaussian process (GP) priors to impose our knowledge about the\ncharacteristics of the underlying stationary segments, and use a nonparametric\ndistribution to partition the sequences into such segments, formulated in terms\nof a prior distribution on segment length. Given the segmentation, the model\ncan be viewed as a variant of a Gaussian mixture model where the mixture\ncomponents are described using the covariance function of a GP. We demonstrate\nthe effectiveness of our model on synthetic data as well as on real time-series\ndata of heartbeats where the task is to segment the indicative types of beats\nand to classify the heartbeat recordings into classes that correspond to\nhealthy and abnormal heart sounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:19:20 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Mikheeva", "Olga", ""], ["Kazlauskaite", "Ieva", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "2001.09887", "submitter": "Yifan Cui", "authors": "Yifan Cui, Michael R. Kosorok, Erik Sverdrup, Stefan Wager, Ruoqing\n  Zhu", "title": "Estimating heterogeneous treatment effects with right-censored data via\n  causal survival forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forest-based methods have recently gained in popularity for non-parametric\ntreatment effect estimation. Building on this line of work, we introduce causal\nsurvival forests, which can be used to estimate heterogeneous treatment effects\nin a survival and observational setting where outcomes may be right-censored.\nOur approach relies on orthogonal estimating equations to robustly adjust for\nboth censoring and selection effects. In our experiments, we find our approach\nto perform well relative to a number of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:22:05 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 16:35:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cui", "Yifan", ""], ["Kosorok", "Michael R.", ""], ["Sverdrup", "Erik", ""], ["Wager", "Stefan", ""], ["Zhu", "Ruoqing", ""]]}, {"id": "2001.09896", "submitter": "Vinicius Carid\\'a", "authors": "Amir Jalilifard, Vinicius F. Carid\\'a, Alex F. Mansano, Rogers S.\n  Cristo, Felipe Penhorate C. da Fonseca", "title": "Semantic Sensitive TF-IDF to Determine Word Relevance in Documents", "comments": "11 pages, 2 figures, 22 references", "journal-ref": null, "doi": "10.1007/978-981-33-6977-1", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword extraction has received an increasing attention as an important\nresearch topic which can lead to have advancements in diverse applications such\nas document context categorization, text indexing and document classification.\nIn this paper we propose STF-IDF, a novel semantic method based on TF-IDF, for\nscoring word importance of informal documents in a corpus. A set of nearly four\nmillion documents from health-care social media was collected and was trained\nin order to draw semantic model and to find the word embeddings. Then, the\nfeatures of semantic space were utilized to rearrange the original TF-IDF\nscores through an iterative solution so as to improve the moderate performance\nof this algorithm on informal texts. After testing the proposed method with 200\nrandomly chosen documents, our method managed to decrease the TF-IDF mean error\nrate by a factor of 50% and reaching the mean error of 13.7%, as opposed to\n27.2% of the original TF-IDF.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 00:23:11 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 23:52:07 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Jalilifard", "Amir", ""], ["Carid\u00e1", "Vinicius F.", ""], ["Mansano", "Alex F.", ""], ["Cristo", "Rogers S.", ""], ["da Fonseca", "Felipe Penhorate C.", ""]]}, {"id": "2001.09902", "submitter": "Saeed Khaki", "authors": "Saeed Khaki, Zahra Khalilzadeh and Lizhi Wang", "title": "Predicting Yield Performance of Parents in Plant Breeding: A Neural\n  Collaborative Filtering Approach", "comments": "13 pages, 4 figures", "journal-ref": "PLoS ONE 15(5): e0233382 (2020)", "doi": "10.1371/journal.pone.0233382", "report-no": null, "categories": "cs.LG q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental corn hybrids are created in plant breeding programs by crossing\ntwo parents, so-called inbred and tester, together. Identification of best\nparent combinations for crossing is challenging since the total number of\npossible cross combinations of parents is large and it is impractical to test\nall possible cross combinations due to limited resources of time and budget. In\nthe 2020 Syngenta Crop Challenge, Syngenta released several large datasets that\nrecorded the historical yield performances of around 4% of total cross\ncombinations of 593 inbreds with 496 testers which were planted in 280\nlocations between 2016 and 2018 and asked participants to predict the yield\nperformance of cross combinations of inbreds and testers that have not been\nplanted based on the historical yield data collected from crossing other\ninbreds and testers. In this paper, we present a collaborative filtering method\nwhich is an ensemble of matrix factorization method and neural networks to\nsolve this problem. Our computational results suggested that the proposed model\nsignificantly outperformed other models such as LASSO, random forest (RF), and\nneural networks. Presented method and results were produced within the 2020\nSyngenta Crop Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:39:45 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 00:10:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Khaki", "Saeed", ""], ["Khalilzadeh", "Zahra", ""], ["Wang", "Lizhi", ""]]}, {"id": "2001.09908", "submitter": "Chang Ye", "authors": "Chang Ye, Ahmed Khalifa, Philip Bontrager, Julian Togelius", "title": "Rotation, Translation, and Cropping for Zero-Shot Generalization", "comments": "IEEE Conference on Games 2020 Full Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has shown impressive performance on domains\nwith visual inputs, in particular various games. However, the agent is usually\ntrained on a fixed environment, e.g. a fixed number of levels. A growing mass\nof evidence suggests that these trained models fail to generalize to even\nslight variations of the environments they were trained on. This paper advances\nthe hypothesis that the lack of generalization is partly due to the input\nrepresentation, and explores how rotation, cropping and translation could\nincrease generality. We show that a cropped, translated and rotated observation\ncan get better generalization on unseen levels of two-dimensional arcade games\nfrom the GVGAI framework. The generality of the agents is evaluated on both\nhuman-designed and procedurally generated levels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:56:05 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 18:42:57 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 03:18:52 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ye", "Chang", ""], ["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Togelius", "Julian", ""]]}, {"id": "2001.09930", "submitter": "Xiaotong Jiang", "authors": "Xiaotong Jiang, Amanda E. Nelson, Rebecca J. Cleveland, Daniel P.\n  Beavers, Todd A. Schwartz, Liubov Arbeeva, Carolina Alvarez, Leigh F.\n  Callahan, Stephen Messier, Richard Loeser, Michael R. Kosorok", "title": "Technical Background for \"A Precision Medicine Approach to Develop and\n  Internally Validate Optimal Exercise and Weight Loss Treatments for\n  Overweight and Obese Adults with Knee Osteoarthritis\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide additional statistical background for the methodology developed in\nthe clinical analysis of knee osteoarthritis in \"A Precision Medicine Approach\nto Develop and Internally Validate Optimal Exercise and Weight Loss Treatments\nfor Overweight and Obese Adults with Knee Osteoarthritis\" (Jiang et al. 2020).\nJiang et al. 2020 proposed a pipeline to learn optimal treatment rules with\nprecision medicine models and compared them with zero-order models with a\nZ-test. The model performance was based on value functions, a scalar that\npredicts the future reward of each decision rule. The jackknife (i.e.,\nleave-one-out cross validation) method was applied to estimate the value\nfunction and its variance of several outcomes in IDEA. IDEA is a randomized\nclinical trial studying three interventions (exercise (E), dietary weight loss\n(D), and D+E) on overweight and obese participants with knee osteoarthritis. In\nthis report, we expand the discussion and justification with additional\nstatistical background. We elaborate more on the background of precision\nmedicine, the derivation of the jackknife estimator of value function and its\nestimated variance, the consistency property of jackknife estimator, as well as\nadditional simulation results that reflect more of the performance of jackknife\nestimators. We recommend reading Jiang et al. 2020 for clinical application and\ninterpretation of the optimal ITR of knee osteoarthritis as well as the overall\nunderstanding of the pipeline and recommend using this article to understand\nthe underlying statistical derivation and methodology.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:50:20 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 21:48:55 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 20:20:44 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jiang", "Xiaotong", ""], ["Nelson", "Amanda E.", ""], ["Cleveland", "Rebecca J.", ""], ["Beavers", "Daniel P.", ""], ["Schwartz", "Todd A.", ""], ["Arbeeva", "Liubov", ""], ["Alvarez", "Carolina", ""], ["Callahan", "Leigh F.", ""], ["Messier", "Stephen", ""], ["Loeser", "Richard", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "2001.09947", "submitter": "Sheela Ramanna", "authors": "Sheela Ramanna and Cenker Sengoz and Scott Kehler and Dat Pham", "title": "Near real-time map building with multi-class image set labelling and\n  classification of road conditions using convolutional neural networks", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather is an important factor affecting transportation and road safety. In\nthis paper, we leverage state-of-the-art convolutional neural networks in\nlabelling images taken by street and highway cameras located across across\nNorth America. Road camera snapshots were used in experiments with multiple\ndeep learning frameworks to classify images by road condition. The training\ndata for these experiments used images labelled as dry, wet, snow/ice, poor,\nand offline. The experiments tested different configurations of six\nconvolutional neural networks (VGG-16, ResNet50, Xception, InceptionResNetV2,\nEfficientNet-B0 and EfficientNet-B4) to assess their suitability to this\nproblem. The precision, accuracy, and recall were measured for each framework\nconfiguration. In addition, the training sets were varied both in overall size\nand by size of individual classes. The final training set included 47,000\nimages labelled using the five aforementioned classes. The EfficientNet-B4\nframework was found to be most suitable to this problem, achieving validation\naccuracy of 90.6%, although EfficientNet-B0 achieved an accuracy of 90.3% with\nhalf the execution time. It was observed that VGG-16 with transfer learning\nproved to be very useful for data acquisition and pseudo-labelling with limited\nhardware resources, throughout this project. The EfficientNet-B4 framework was\nthen placed into a real-time production environment, where images could be\nclassified in real-time on an ongoing basis. The classified images were then\nused to construct a map showing real-time road conditions at various camera\nlocations across North America. The choice of these frameworks and our analysis\ntake into account unique requirements of real-time map building functions. A\ndetailed analysis of the process of semi-automated dataset labelling using\nthese frameworks is also presented in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:07:40 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ramanna", "Sheela", ""], ["Sengoz", "Cenker", ""], ["Kehler", "Scott", ""], ["Pham", "Dat", ""]]}, {"id": "2001.09957", "submitter": "David A. Monge Ph.D.", "authors": "Yisel Gar\\'i, David A. Monge, Elina Pacini, Cristian Mateos, and\n  Carlos Garc\\'ia Garino", "title": "Reinforcement Learning-based Application Autoscaling in the Cloud: A\n  Survey", "comments": "40 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has demonstrated a great potential for\nautomatically solving decision-making problems in complex uncertain\nenvironments. RL proposes a computational approach that allows learning through\ninteraction in an environment with stochastic behavior, where agents take\nactions to maximize some cumulative short-term and long-term rewards. Some of\nthe most impressive results have been shown in Game Theory where agents\nexhibited superhuman performance in games like Go or Starcraft 2, which led to\nits gradual adoption in many other domains, including Cloud Computing.\nTherefore, RL appears as a promising approach for Autoscaling in Cloud since it\nis possible to learn transparent (with no human intervention), dynamic (no\nstatic plans), and adaptable (constantly updated) resource management policies\nto execute applications. These are three important distinctive aspects to\nconsider in comparison with other widely used autoscaling policies that are\ndefined in an ad-hoc way or statically computed as in solutions based on\nmeta-heuristics. Autoscaling exploits the Cloud elasticity to optimize the\nexecution of applications according to given optimization criteria, which\ndemands to decide when and how to scale-up/down computational resources, and\nhow to assign them to the upcoming processing workload. Such actions have to be\ntaken considering that the Cloud is a dynamic and uncertain environment.\nMotivated by this, many works apply RL to the autoscaling problem in the Cloud.\nIn this work, we survey exhaustively those proposals from major venues, and\nuniformly compare them based on a set of proposed taxonomies. We also discuss\nopen problems and prospective research in the area.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:23:43 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 14:10:54 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 14:14:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Gar\u00ed", "Yisel", ""], ["Monge", "David A.", ""], ["Pacini", "Elina", ""], ["Mateos", "Cristian", ""], ["Garino", "Carlos Garc\u00eda", ""]]}, {"id": "2001.09977", "submitter": "Daniel de Freitas Adiwardana", "authors": "Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah\n  Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng\n  Lu, Quoc V. Le", "title": "Towards a Human-like Open-Domain Chatbot", "comments": "38 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Meena, a multi-turn open-domain chatbot trained end-to-end on data\nmined and filtered from public domain social media conversations. This 2.6B\nparameter neural network is simply trained to minimize perplexity of the next\ntoken. We also propose a human evaluation metric called Sensibleness and\nSpecificity Average (SSA), which captures key elements of a human-like\nmulti-turn conversation. Our experiments show strong correlation between\nperplexity and SSA. The fact that the best perplexity end-to-end trained Meena\nscores high on SSA (72% on multi-turn evaluation) suggests that a human-level\nSSA of 86% is potentially within reach if we can better optimize perplexity.\nAdditionally, the full version of Meena (with a filtering mechanism and tuned\ndecoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots\nwe evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:53:15 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:58:14 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 07:36:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Adiwardana", "Daniel", ""], ["Luong", "Minh-Thang", ""], ["So", "David R.", ""], ["Hall", "Jamie", ""], ["Fiedel", "Noah", ""], ["Thoppilan", "Romal", ""], ["Yang", "Zi", ""], ["Kulshreshtha", "Apoorv", ""], ["Nemade", "Gaurav", ""], ["Lu", "Yifeng", ""], ["Le", "Quoc V.", ""]]}, {"id": "2001.09993", "submitter": "Jean-Christophe Burnel", "authors": "Jean-Christophe Burnel (OBELIX), Kilian Fatras (OBELIX), Nicolas\n  Courty (OBELIX)", "title": "Generating Natural Adversarial Hyperspectral examples with a modified\n  Wasserstein GAN", "comments": "C&ESAR, Nov 2019, Rennes, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a hot topic due to their abilities to fool a\nclassifier's prediction. There are two strategies to create such examples, one\nuses the attacked classifier's gradients, while the other only requires access\nto the clas-sifier's prediction. This is particularly appealing when the\nclassifier is not full known (black box model). In this paper, we present a new\nmethod which is able to generate natural adversarial examples from the true\ndata following the second paradigm. Based on Generative Adversarial Networks\n(GANs) [5], it reweights the true data empirical distribution to encourage the\nclassifier to generate ad-versarial examples. We provide a proof of concept of\nour method by generating adversarial hyperspectral signatures on a remote\nsensing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:32:46 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Burnel", "Jean-Christophe", "", "OBELIX"], ["Fatras", "Kilian", "", "OBELIX"], ["Courty", "Nicolas", "", "OBELIX"]]}, {"id": "2001.09994", "submitter": "Pirmin Lemberger", "authors": "Pirmin Lemberger and Ivan Panico", "title": "A Primer on Domain Adaptation", "comments": "31 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard supervised machine learning assumes that the distribution of the\nsource samples used to train an algorithm is the same as the one of the target\nsamples on which it is supposed to make predictions. However, as any data\nscientist will confirm, this is hardly ever the case in practice. The set of\nstatistical and numerical methods that deal with such situations is known as\ndomain adaptation, a field with a long and rich history. The myriad of methods\navailable and the unfortunate lack of a clear and universally accepted\nterminology can however make the topic rather daunting for the newcomer.\nTherefore, rather than aiming at completeness, which leads to exhibiting a\ntedious catalog of methods, this pedagogical review aims at a coherent\npresentation of four important special cases: (1) prior shift, a situation in\nwhich training samples were selected according to their labels without any\nknowledge of their actual distribution in the target, (2) covariate shift which\ndeals with a situation where training examples were picked according to their\nfeatures but with some selection bias, (3) concept shift where the dependence\nof the labels on the features defers between the source and the target, and\nlast but not least (4) subspace mapping which deals with a situation where\nfeatures in the target have been subjected to an unknown distortion with\nrespect to the source features. In each case we first build an intuition, next\nwe provide the appropriate mathematical framework and eventually we describe a\npractical application.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:10:18 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 17:47:48 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Lemberger", "Pirmin", ""], ["Panico", "Ivan", ""]]}, {"id": "2001.10006", "submitter": "Molei Tao", "authors": "Molei Tao, Tomoki Ohsawa", "title": "Variational Optimization on Lie Groups, with Examples of Leading\n  (Generalized) Eigenvalue Problems", "comments": "Accepted by AISTATS 2020; never submitted elsewhere", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers smooth optimization of functions on Lie groups. By\ngeneralizing NAG variational principle in vector space (Wibisono et al., 2016)\nto Lie groups, continuous Lie-NAG dynamics which are guaranteed to converge to\nlocal optimum are obtained. They correspond to momentum versions of gradient\nflow on Lie groups. A particular case of $\\mathsf{SO}(n)$ is then studied in\ndetails, with objective functions corresponding to leading Generalized\nEigenValue problems: the Lie-NAG dynamics are first made explicit in\ncoordinates, and then discretized in structure preserving fashions, resulting\nin optimization algorithms with faithful energy behavior (due to conformal\nsymplecticity) and exactly remaining on the Lie group. Stochastic gradient\nversions are also investigated. Numerical experiments on both synthetic data\nand practical problem (LDA for MNIST) demonstrate the effectiveness of the\nproposed methods as optimization algorithms ($not$ as a classification method).\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:00:03 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tao", "Molei", ""], ["Ohsawa", "Tomoki", ""]]}, {"id": "2001.10025", "submitter": "Tim Barfoot", "authors": "Timothy D. Barfoot", "title": "Multivariate Gaussian Variational Inference by Natural Gradient Descent", "comments": "11 pages, 0 figures; second version fixed a single typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note reviews so-called Natural Gradient Descent (NGD) for\nmultivariate Gaussians. The Fisher Information Matrix (FIM) is derived for\nseveral different parameterizations of Gaussians. Careful attention is paid to\nthe symmetric nature of the covariance matrix when calculating derivatives. We\nshow that there are some advantages to choosing a parameterization comprising\nthe mean and inverse covariance matrix and provide a simple NGD update that\naccounts for the symmetric (and sparse) nature of the inverse covariance\nmatrix.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:20:03 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:54:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Barfoot", "Timothy D.", ""]]}, {"id": "2001.10054", "submitter": "Junyi Gao", "authors": "Junyi Gao, Cao Xiao, Yasha Wang, Wen Tang, Lucas M. Glass, Jimeng Sun", "title": "StageNet: Stage-Aware Neural Networks for Health Risk Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3366423.3380136", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has demonstrated success in health risk prediction especially\nfor patients with chronic and progressing conditions. Most existing works focus\non learning disease Network (StageNet) model to extract disease stage\ninformation from patient data and integrate it into risk prediction. StageNet\nis enabled by (1) a stage-aware long short-term memory (LSTM) module that\nextracts health stage variations unsupervisedly; (2) a stage-adaptive\nconvolutional module that incorporates stage-related progression patterns into\nrisk prediction. We evaluate StageNet on two real-world datasets and show that\nStageNet outperforms state-of-the-art models in risk prediction task and\npatient subtyping task. Compared to the best baseline model, StageNet achieves\nup to 12% higher AUPRC for risk prediction task on two real-world patient\ndatasets. StageNet also achieves over 58% higher Calinski-Harabasz score (a\ncluster quality metric) for a patient subtyping task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 17:50:36 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Gao", "Junyi", ""], ["Xiao", "Cao", ""], ["Wang", "Yasha", ""], ["Tang", "Wen", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.10055", "submitter": "Ganesh Ghalme", "authors": "Ganesh Ghalme, Swapnil Dhamal, Shweta Jain, Sujit Gujar, Y. Narahari", "title": "Ballooning Multi-Armed Bandits", "comments": "A full version of this paper is accepted in the Journal of Artificial\n  Intelligence (AIJ) of Elsevier. A preliminary version is published as an\n  extended abstract in AAMAS 2020. Proceedings of the 19th International\n  Conference on Autonomous Agents and MultiAgent Systems. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Ballooning Multi-Armed Bandits (BL-MAB), a novel\nextension of the classical stochastic MAB model. In the BL-MAB model, the set\nof available arms grows (or balloons) over time. In contrast to the classical\nMAB setting where the regret is computed with respect to the best arm overall,\nthe regret in a BL-MAB setting is computed with respect to the best available\narm at each time. We first observe that the existing stochastic MAB algorithms\nresult in linear regret for the BL-MAB model. We prove that, if the best arm is\nequally likely to arrive at any time instant, a sub-linear regret cannot be\nachieved. Next, we show that if the best arm is more likely to arrive in the\nearly rounds, one can achieve sub-linear regret. Our proposed algorithm\ndetermines (1) the fraction of the time horizon for which the newly arriving\narms should be explored and (2) the sequence of arm pulls in the exploitation\nphase from among the explored arms. Making reasonable assumptions on the\narrival distribution of the best arm in terms of the thinness of the\ndistribution's tail, we prove that the proposed algorithm achieves sub-linear\ninstance-independent regret. We further quantify explicit dependence of regret\non the arrival distribution parameters. We reinforce our theoretical findings\nwith extensive simulation results. We conclude by showing that our algorithm\nwould achieve sub-linear regret even if (a) the distributional parameters are\nnot exactly known, but are obtained using a reasonable learning mechanism or\n(b) the best arm is not more likely to arrive early, but a large fraction of\narms is likely to arrive relatively early.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:35:05 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 10:41:13 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 12:33:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ghalme", "Ganesh", ""], ["Dhamal", "Swapnil", ""], ["Jain", "Shweta", ""], ["Gujar", "Sujit", ""], ["Narahari", "Y.", ""]]}, {"id": "2001.10065", "submitter": "Lin Wu", "authors": "Deyin Liu, Lin Wu, Xue Li", "title": "Medi-Care AI: Predicting Medications From Billing Codes via Robust\n  Recurrent Neural Networks", "comments": "Under Review for Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an effective deep prediction framework based on\nrobust recurrent neural networks (RNNs) to predict the likely therapeutic\nclasses of medications a patient is taking, given a sequence of diagnostic\nbilling codes in their record. Accurately capturing the list of medications\ncurrently taken by a given patient is extremely challenging due to undefined\nerrors and omissions. We present a general robust framework that explicitly\nmodels the possible contamination through overtime decay mechanism on the input\nbilling codes and noise injection into the recurrent hidden states,\nrespectively. By doing this, billing codes are reformulated into its temporal\npatterns with decay rates on each medical variable, and the hidden states of\nRNNs are regularised by random noises which serve as dropout to improved RNNs\nrobustness towards data variability in terms of missing values and multiple\nerrors. The proposed method is extensively evaluated on real health care data\nto demonstrate its effectiveness in suggesting medication orders from\ncontaminated values.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:49:46 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Liu", "Deyin", ""], ["Wu", "Lin", ""], ["Li", "Xue", ""]]}, {"id": "2001.10073", "submitter": "Amir M. Mir", "authors": "Amir M. Mir, Mahdi Rahbar, Jalal A. Nasiri", "title": "LIBTwinSVM: A Library for Twin Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents LIBTwinSVM, a free, efficient, and open source library\nfor Twin Support Vector Machines (TSVMs). Our library provides a set of useful\nfunctionalities such as fast TSVMs estimators, model selection, visualization,\na graphical user interface (GUI) application, and a Python application\nprogramming interface (API). The benchmarks results indicate the effectiveness\nof the LIBTwinSVM library for large-scale classification problems. The source\ncode of LIBTwinSVM library, installation guide, documentation, and usage\nexamples are available at https://github.com/mir-am/LIBTwinSVM.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 20:40:37 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mir", "Amir M.", ""], ["Rahbar", "Mahdi", ""], ["Nasiri", "Jalal A.", ""]]}, {"id": "2001.10098", "submitter": "Wenyu Zhang", "authors": "Wenyu Zhang, Devesh K. Jha, Emil Laftchiev, Daniel Nikovski", "title": "Multi-label Prediction in Time Series Data using Deep Neural Networks", "comments": "Accepted by IJPHM. Presented at PHM19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses a multi-label predictive fault classification problem\nfor multidimensional time-series data. While fault (event) detection problems\nhave been thoroughly studied in literature, most of the state-of-the-art\ntechniques can't reliably predict faults (events) over a desired future\nhorizon. In the most general setting of these types of problems, one or more\nsamples of data across multiple time series can be assigned several concurrent\nfault labels from a finite, known set and the task is to predict the\npossibility of fault occurrence over a desired time horizon. This type of\nproblem is usually accompanied by strong class imbalances where some classes\nare represented by only a few samples. Importantly, in many applications of the\nproblem such as fault prediction and predictive maintenance, it is exactly\nthese rare classes that are of most interest. To address the problem, this\npaper proposes a general approach that utilizes a multi-label recurrent neural\nnetwork with a new cost function that accentuates learning in the imbalanced\nclasses. The proposed algorithm is tested on two public benchmark datasets: an\nindustrial plant dataset from the PHM Society Data Challenge, and a human\nactivity recognition dataset. The results are compared with state-of-the-art\ntechniques for time-series classification and evaluation is performed using the\nF1-score, precision and recall.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 21:35:15 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zhang", "Wenyu", ""], ["Jha", "Devesh K.", ""], ["Laftchiev", "Emil", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2001.10102", "submitter": "Jerome Friedman", "authors": "Jerome H. Friedman", "title": "Predicting Regression Probability Distributions with Imperfect Data\n  Through Optimal Transformations", "comments": "33 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of regression analysis is to predict the value of a numeric outcome\nvariable y given a vector of joint values of other (predictor) variables x.\nUsually a particular x-vector does not specify a repeatable value for y, but\nrather a probability distribution of possible y--values, p(y|x). This\ndistribution has a location, scale and shape, all of which can depend on x, and\nare needed to infer likely values for y given x. Regression methods usually\nassume that training data y-values are perfect numeric realizations from some\nwell behaived p(y|x). Often actual training data y-values are discrete,\ntruncated and/or arbitrary censored. Regression procedures based on an optimal\ntransformation strategy are presented for estimating location, scale and shape\nof p(y|x) as general functions of x, in the possible presence of such imperfect\ntraining data. In addition, validation diagnostics are presented to ascertain\nthe quality of the solutions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:13:29 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Friedman", "Jerome H.", ""]]}, {"id": "2001.10109", "submitter": "Kriton Konstantinidis", "authors": "Alexandros Haliassos, Kriton Konstantinidis, Danilo P. Mandic", "title": "Supervised Learning for Non-Sequential Data: A Canonical Polyadic\n  Decomposition Approach", "comments": "Accepted at IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient modelling of feature interactions underpins supervised learning for\nnon-sequential tasks, characterized by a lack of inherent ordering of features\n(variables). The brute force approach of learning a parameter for each\ninteraction of every order comes at an exponential computational and memory\ncost (Curse of Dimensionality). To alleviate this issue, it has been proposed\nto implicitly represent the model parameters as a tensor, the order of which is\nequal to the number of features; for efficiency, it can be further factorized\ninto a compact Tensor Train (TT) format. However, both TT and other Tensor\nNetworks (TNs), such as Tensor Ring and Hierarchical Tucker, are sensitive to\nthe ordering of their indices (and hence to the features). To establish the\ndesired invariance to feature ordering, we propose to represent the weight\ntensor through the Canonical Polyadic (CP) Decomposition (CPD), and introduce\nthe associated inference and learning algorithms, including suitable\nregularization and initialization schemes. It is demonstrated that the proposed\nCP-based predictor significantly outperforms other TN-based predictors on\nsparse data while exhibiting comparable performance on dense non-sequential\ntasks. Furthermore, for enhanced expressiveness, we generalize the framework to\nallow feature mapping to arbitrarily high-dimensional feature vectors. In\nconjunction with feature vector normalization, this is shown to yield dramatic\nimprovements in performance for dense non-sequential tasks, matching models\nsuch as fully-connected neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:38:40 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 09:10:27 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 09:29:17 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Haliassos", "Alexandros", ""], ["Konstantinidis", "Kriton", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2001.10119", "submitter": "Chenghui Zhou", "authors": "Chenghui Zhou, Chun-Liang Li, Barnabas Poczos", "title": "Unsupervised Program Synthesis for Images By Sampling Without\n  Replacement", "comments": "Accepted to UAI 2021", "journal-ref": "UAI 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis has emerged as a successful approach to the image parsing\ntask. Most prior works rely on a two-step scheme involving supervised\npretraining of a Seq2Seq model with synthetic programs followed by\nreinforcement learning (RL) for fine-tuning with real reference images. Fully\nunsupervised approaches promise to train the model directly on the target\nimages without requiring curated pretraining datasets. However, they struggle\nwith the inherent sparsity of meaningful programs in the search space. In this\npaper, we present the first unsupervised algorithm capable of parsing\nconstructive solid geometry (CSG) images into context-free grammar (CFG)\nwithout pretraining via non-differentiable renderer. To tackle the\n\\emph{non-Markovian} sparse reward problem, we combine three key ingredients --\n(i) a grammar-encoded tree LSTM ensuring program validity (ii) entropy\nregularization and (iii) sampling without replacement from the CFG syntax tree.\nEmpirically, our algorithm recovers meaningful programs in large search spaces\n(up to $3.8 \\times 10^{28}$). Further, even though our approach is fully\nunsupervised, it generalizes better than supervised methods on the synthetic 2D\nCSG dataset. On the 2D computer aided design (CAD) dataset, our approach\nsignificantly outperforms the supervised pretrained model and is competitive to\nthe refined model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:30:33 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 21:11:14 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhou", "Chenghui", ""], ["Li", "Chun-Liang", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2001.10122", "submitter": "Seyed Mohammad Asghari", "authors": "Seyed Mohammad Asghari, Yi Ouyang, and Ashutosh Nayyar", "title": "Regret Bounds for Decentralized Learning in Cooperative Multi-Agent\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret analysis is challenging in Multi-Agent Reinforcement Learning (MARL)\nprimarily due to the dynamical environments and the decentralized information\namong agents. We attempt to solve this challenge in the context of\ndecentralized learning in multi-agent linear-quadratic (LQ) dynamical systems.\nWe begin with a simple setup consisting of two agents and two dynamically\ndecoupled stochastic linear systems, each system controlled by an agent. The\nsystems are coupled through a quadratic cost function. When both systems'\ndynamics are unknown and there is no communication among the agents, we show\nthat no learning policy can generate sub-linear in $T$ regret, where $T$ is the\ntime horizon. When only one system's dynamics are unknown and there is\none-directional communication from the agent controlling the unknown system to\nthe other agent, we propose a MARL algorithm based on the construction of an\nauxiliary single-agent LQ problem. The auxiliary single-agent problem in the\nproposed MARL algorithm serves as an implicit coordination mechanism among the\ntwo learning agents. This allows the agents to achieve a regret within\n$O(\\sqrt{T})$ of the regret of the auxiliary single-agent problem.\nConsequently, using existing results for single-agent LQ regret, our algorithm\nprovides a $\\tilde{O}(\\sqrt{T})$ regret bound. (Here $\\tilde{O}(\\cdot)$ hides\nconstants and logarithmic factors). Our numerical experiments indicate that\nthis bound is matched in practice. From the two-agent problem, we extend our\nresults to multi-agent LQ systems with certain communication patterns.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:37:41 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Asghari", "Seyed Mohammad", ""], ["Ouyang", "Yi", ""], ["Nayyar", "Ashutosh", ""]]}, {"id": "2001.10133", "submitter": "Ping Xu", "authors": "Ping Xu, Yue Wang, Xiang Chen, Zhi Tian", "title": "COKE: Communication-Censored Decentralized Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the decentralized optimization and learning problem where\nmultiple interconnected agents aim to learn an optimal decision function\ndefined over a reproducing kernel Hilbert space by jointly minimizing a global\nobjective function, with access to their own locally observed dataset. As a\nnon-parametric approach, kernel learning faces a major challenge in distributed\nimplementation: the decision variables of local objective functions are\ndata-dependent and thus cannot be optimized under the decentralized consensus\nframework without any raw data exchange among agents. To circumvent this major\nchallenge, we leverage the random feature (RF) approximation approach to enable\nconsensus on the function modeled in the RF space by data-independent\nparameters across different agents. We then design an iterative algorithm,\ntermed DKLA, for fast-convergent implementation via ADMM. Based on DKLA, we\nfurther develop a communication-censored kernel learning (COKE) algorithm that\nreduces the communication load of DKLA by preventing an agent from transmitting\nat every iteration unless its local updates are deemed informative. Theoretical\nresults in terms of linear convergence guarantee and generalization performance\nanalysis of DKLA and COKE are provided. Comprehensive tests on both synthetic\nand real datasets are conducted to verify the communication efficiency and\nlearning effectiveness of COKE.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 01:05:57 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 00:52:48 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Xu", "Ping", ""], ["Wang", "Yue", ""], ["Chen", "Xiang", ""], ["Tian", "Zhi", ""]]}, {"id": "2001.10167", "submitter": "Lei Chen", "authors": "Lei Chen, Le Wu, Richang Hong, Kun Zhang, Meng Wang", "title": "Revisiting Graph based Collaborative Filtering: A Linear Residual Graph\n  Convolutional Network Approach", "comments": "The updated version is publised in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) are state-of-the-art graph based\nrepresentation learning models by iteratively stacking multiple layers of\nconvolution aggregation operations and non-linear activation operations.\nRecently, in Collaborative Filtering (CF) based Recommender Systems (RS), by\ntreating the user-item interaction behavior as a bipartite graph, some\nresearchers model higher-layer collaborative signals with GCNs. These GCN based\nrecommender models show superior performance compared to traditional works.\nHowever, these models suffer from training difficulty with non-linear\nactivations for large user-item graphs. Besides, most GCN based models could\nnot model deeper layers due to the over smoothing effect with the graph\nconvolution operation. In this paper, we revisit GCN based CF models from two\naspects. First, we empirically show that removing non-linearities would enhance\nrecommendation performance, which is consistent with the theories in simple\ngraph convolutional networks. Second, we propose a residual network structure\nthat is specifically designed for CF with user-item interaction modeling, which\nalleviates the over smoothing problem in graph convolution aggregation\noperation with sparse user-item interaction data. The proposed model is a\nlinear model and it is easy to train, scale to large datasets, and yield better\nefficiency and effectiveness on two real datasets. We publish the source code\nat https://github.com/newlei/LRGCCF.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:41:25 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Chen", "Lei", ""], ["Wu", "Le", ""], ["Hong", "Richang", ""], ["Zhang", "Kun", ""], ["Wang", "Meng", ""]]}, {"id": "2001.10188", "submitter": "Muhammad Shahzad", "authors": "Muhammad Shahzad, Arif Iqbal Umar, Muazzam A. Khan, Syed Hamad\n  Shirazi, Zakir Khan, and Waqas Yousaf", "title": "Robust Method for Semantic Segmentation of Whole-Slide Blood Cell\n  Microscopic Image", "comments": "13 pages, 13 figures", "journal-ref": "Volume 2020, Article ID 4015323, 13 pages", "doi": "10.1155/2020/4015323", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous works on segmentation of SEM (scanning electron microscope) blood\ncell image ignore the semantic segmentation approach of whole-slide blood cell\nsegmentation. In the proposed work, we address the problem of whole-slide blood\ncell segmentation using the semantic segmentation approach. We design a novel\nconvolutional encoder-decoder framework along with VGG-16 as the pixel-level\nfeature extraction model. -e proposed framework comprises 3 main steps: First,\nall the original images along with manually generated ground truth masks of\neach blood cell type are passed through the preprocessing stage. In the\npreprocessing stage, pixel-level labeling, RGB to grayscale conversion of\nmasked image and pixel fusing, and unity mask generation are performed. After\nthat, VGG16 is loaded into the system, which acts as a pretrained pixel-level\nfeature extraction model. In the third step, the training process is initiated\non the proposed model. We have evaluated our network performance on three\nevaluation metrics. We obtained outstanding results with respect to classwise,\nas well as global and mean accuracies. Our system achieved classwise accuracies\nof 97.45%, 93.34%, and 85.11% for RBCs, WBCs, and platelets, respectively,\nwhile global and mean accuracies remain 97.18% and 91.96%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 06:32:21 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Shahzad", "Muhammad", ""], ["Umar", "Arif Iqbal", ""], ["Khan", "Muazzam A.", ""], ["Shirazi", "Syed Hamad", ""], ["Khan", "Zakir", ""], ["Yousaf", "Waqas", ""]]}, {"id": "2001.10218", "submitter": "Hendrik Schr\\\"oter", "authors": "Hendrik Schr\\\"oter, Tobias Rosenkranz, Alberto N. Escalante B., Marc\n  Aubreville, Andreas Maier", "title": "CLCNet: Deep learning-based Noise Reduction for Hearing Aids using\n  Complex Linear Coding", "comments": "5 Pages, ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise reduction is an important part of modern hearing aids and is included\nin most commercially available devices. Deep learning-based state-of-the-art\nalgorithms, however, either do not consider real-time and frequency resolution\nconstrains or result in poor quality under very noisy conditions. To improve\nmonaural speech enhancement in noisy environments, we propose CLCNet, a\nframework based on complex valued linear coding. First, we define complex\nlinear coding (CLC) motivated by linear predictive coding (LPC) that is applied\nin the complex frequency domain. Second, we propose a framework that\nincorporates complex spectrogram input and coefficient output. Third, we define\na parametric normalization for complex valued spectrograms that complies with\nlow-latency and on-line processing. Our CLCNet was evaluated on a mixture of\nthe EUROM database and a real-world noise dataset recorded with hearing aids\nand compared to traditional real-valued Wiener-Filter gains.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 09:08:35 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Schr\u00f6ter", "Hendrik", ""], ["Rosenkranz", "Tobias", ""], ["B.", "Alberto N. Escalante", ""], ["Aubreville", "Marc", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.10237", "submitter": "Jialin Dong", "authors": "Jialin Dong, Jun Zhang, Yuanming Shi, Jessie Hui Wang", "title": "Faster Activity and Data Detection in Massive Random Access: A\n  Multi-armed Bandit Approach", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the grant-free random access with massive IoT\ndevices. By embedding the data symbols in the signature sequences, joint device\nactivity detection and data decoding can be achieved, which, however,\nsignificantly increases the computational complexity. Coordinate descent\nalgorithms that enjoy a low per-iteration complexity have been employed to\nsolve the detection problem, but previous works typically employ a random\ncoordinate selection policy which leads to slow convergence. In this paper, we\ndevelop multi-armed bandit approaches for more efficient detection via\ncoordinate descent, which make a delicate trade-off between exploration and\nexploitation in coordinate selection. Specifically, we first propose a bandit\nbased strategy, i.e., Bernoulli sampling, to speed up the convergence rate of\ncoordinate descent, by learning which coordinates will result in more\naggressive descent of the objective function. To further improve the\nconvergence rate, an inner multi-armed bandit problem is established to learn\nthe exploration policy of Bernoulli sampling. Both convergence rate analysis\nand simulation results are provided to show that the proposed bandit based\nalgorithms enjoy faster convergence rates with a lower time complexity compared\nwith the state-of-the-art algorithm. Furthermore, our proposed algorithms are\napplicable to different scenarios, e.g., massive random access with\nlow-precision analog-to-digital converters (ADCs).\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:00:25 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Dong", "Jialin", ""], ["Zhang", "Jun", ""], ["Shi", "Yuanming", ""], ["Wang", "Jessie Hui", ""]]}, {"id": "2001.10238", "submitter": "Antoine Plumerault", "authors": "Antoine Plumerault, Herv\\'e Le Borgne, C\\'eline Hudelot", "title": "Controlling generative models with continuous factors of variations", "comments": "Accepted as a poster presentation at the International Conference for\n  Learning Representations (ICLR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep generative models are able to provide photo-realistic images as\nwell as visual or textual content embeddings useful to address various tasks of\ncomputer vision and natural language processing. Their usefulness is\nnevertheless often limited by the lack of control over the generative process\nor the poor understanding of the learned representation. To overcome these\nmajor issues, very recent work has shown the interest of studying the semantics\nof the latent space of generative models. In this paper, we propose to advance\non the interpretability of the latent space of generative models by introducing\na new method to find meaningful directions in the latent space of any\ngenerative model along which we can move to control precisely specific\nproperties of the generated image like the position or scale of the object in\nthe image. Our method does not require human annotations and is particularly\nwell suited for the search of directions encoding simple transformations of the\ngenerated image, such as translation, zoom or color variations. We demonstrate\nthe effectiveness of our method qualitatively and quantitatively, both for GANs\nand variational auto-encoders.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:04:04 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Plumerault", "Antoine", ""], ["Borgne", "Herv\u00e9 Le", ""], ["Hudelot", "C\u00e9line", ""]]}, {"id": "2001.10269", "submitter": "Debo Cheng", "authors": "Debo Cheng (1), Jiuyong Li (1), Lin Liu (1), Jixue Liu (1), Kui Yu\n  (2), and Thuc Duy Le (1) ((1) School of Information Technology and\n  Mathematical Sciences, University of South Australia (2) School of Computer\n  Science and Information Engineering, Hefei University of Technology)", "title": "Causal query in observational data with hidden variables", "comments": "8 pages and 7 figures. The paper has been accepted by ECAI2020. We\n  have updated the proof of the Theorem 1 and removed Theorem 2 from the\n  conference version", "journal-ref": null, "doi": "10.3233/FAIA200390", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the problem of causal query in observational data with\nhidden variables, with the aim of seeking the change of an outcome when\n\"manipulating\" a variable while given a set of plausible confounding variables\nwhich affect the manipulated variable and the outcome. Such an \"experiment on\ndata\" to estimate the causal effect of the manipulated variable is useful for\nvalidating an experiment design using historical data or for exploring\nconfounders when studying a new relationship. However, existing data-driven\nmethods for causal effect estimation face some major challenges, including poor\nscalability with high dimensional data, low estimation accuracy due to\nheuristics used by the global causal structure learning algorithms, and the\nassumption of causal sufficiency when hidden variables are inevitable in data.\nIn this paper, we develop a theorem for using local search to find a superset\nof the adjustment (or confounding) variables for causal effect estimation from\nobservational data under a realistic pretreatment assumption. The theorem\nensures that the unbiased estimate of causal effect is included in the set of\ncausal effects estimated by the superset of adjustment variables. Based on the\ndeveloped theorem, we propose a data-driven algorithm for causal query.\nExperiments show that the proposed algorithm is faster and produces better\ncausal effect estimation than an existing data-driven causal effect estimation\nmethod with hidden variables. The causal effects estimated by the proposed\nalgorithm are as accurate as those by the state-of-the-art methods using domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:23:26 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 05:14:20 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 06:52:09 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 05:11:56 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Cheng", "Debo", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Liu", "Jixue", ""], ["Yu", "Kui", ""], ["Le", "Thuc Duy", ""]]}, {"id": "2001.10318", "submitter": "Nikolaos Nikolaou", "authors": "Nikolaos Nikolaou, Henry Reeve, Gavin Brown", "title": "Margin Maximization as Lossless Maximal Compression", "comments": "19 pages Main Paper + 7 pages Supplementary Material, 7 Figures,\n  Submitted to the Machine Learning journal (11/11/19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ultimate goal of a supervised learning algorithm is to produce models\nconstructed on the training data that can generalize well to new examples. In\nclassification, functional margin maximization -- correctly classifying as many\ntraining examples as possible with maximal confidence --has been known to\nconstruct models with good generalization guarantees. This work gives an\ninformation-theoretic interpretation of a margin maximizing model on a\nnoiseless training dataset as one that achieves lossless maximal compression of\nsaid dataset -- i.e. extracts from the features all the useful information for\npredicting the label and no more. The connection offers new insights on\ngeneralization in supervised machine learning, showing margin maximization as a\nspecial case (that of classification) of a more general principle and explains\nthe success and potential limitations of popular learning algorithms like\ngradient boosting. We support our observations with theoretical arguments and\nempirical evidence and identify interesting directions for future work.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 13:40:22 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Nikolaou", "Nikolaos", ""], ["Reeve", "Henry", ""], ["Brown", "Gavin", ""]]}, {"id": "2001.10335", "submitter": "Georgios Leontidis", "authors": "Mamatha Thota, Stefanos Kollias, Mark Swainson, Georgios Leontidis", "title": "Multi-Source Deep Domain Adaptation for Quality Control in Retail Food\n  Packaging", "comments": "8 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retail food packaging contains information which informs choice and can be\nvital to consumer health, including product name, ingredients list, nutritional\ninformation, allergens, preparation guidelines, pack weight, storage and shelf\nlife information (use-by / best before dates). The presence and accuracy of\nsuch information is critical to ensure a detailed understanding of the product\nand to reduce the potential for health risks. Consequently, erroneous or\nillegible labeling has the potential to be highly detrimental to consumers and\nmany other stakeholders in the supply chain. In this paper, a multi-source deep\nlearning-based domain adaptation system is proposed and tested to identify and\nverify the presence and legibility of use-by date information from food\npackaging photos taken as part of the validation process as the products pass\nalong the food production line. This was achieved by improving the\ngeneralization of the techniques via making use of multi-source datasets in\norder to extract domain-invariant representations for all domains and aligning\ndistribution of all pairs of source and target domains in a common feature\nspace, along with the class boundaries. The proposed system performed very well\nin the conducted experiments, for automating the verification process and\nreducing labeling errors that could otherwise threaten public health and\ncontravene legal requirements for food packaging information and accuracy.\nComprehensive experiments on our food packaging datasets demonstrate that the\nproposed multi-source deep domain adaptation method significantly improves the\nclassification accuracy and therefore has great potential for application and\nbeneficial impact in food manufacturing control systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:16:58 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Thota", "Mamatha", ""], ["Kollias", "Stefanos", ""], ["Swainson", "Mark", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2001.10337", "submitter": "Michael Bloodgood", "authors": "Thomas Orth and Michael Bloodgood", "title": "Early Forecasting of Text Classification Accuracy and F-Measure with\n  Active Learning", "comments": "8 pages, 9 figures, 2 tables; published in Proceedings of the IEEE\n  14th International Conference on Semantic Computing (ICSC), San Diego, CA,\n  USA, pages 77-84, February 2020", "journal-ref": "In Proceedings of the 2020 IEEE 14th International Conference on\n  Semantic Computing (ICSC), pages 77-84, San Diego, CA, USA, February 2020.\n  IEEE", "doi": "10.1109/ICSC.2020.00018", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating text classification systems, one of the major bottlenecks is\nthe annotation of training data. Active learning has been proposed to address\nthis bottleneck using stopping methods to minimize the cost of data annotation.\nAn important capability for improving the utility of stopping methods is to\neffectively forecast the performance of the text classification models.\nForecasting can be done through the use of logarithmic models regressed on some\nportion of the data as learning is progressing. A critical unexplored question\nis what portion of the data is needed for accurate forecasting. There is a\ntension, where it is desirable to use less data so that the forecast can be\nmade earlier, which is more useful, versus it being desirable to use more data,\nso that the forecast can be more accurate. We find that when using active\nlearning it is even more important to generate forecasts earlier so as to make\nthem more useful and not waste annotation effort. We investigate the difference\nin forecasting difficulty when using accuracy and F-measure as the text\nclassification system performance metrics and we find that F-measure is more\ndifficult to forecast. We conduct experiments on seven text classification\ndatasets in different semantic domains with different characteristics and with\nthree different base machine learning algorithms. We find that forecasting is\neasiest for decision tree learning, moderate for Support Vector Machines, and\nmost difficult for neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 06:27:33 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 08:59:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Orth", "Thomas", ""], ["Bloodgood", "Michael", ""]]}, {"id": "2001.10338", "submitter": "Wei Pang Xubu", "authors": "Wei Pang", "title": "Short Text Classification via Term Graph", "comments": "9 pages, 15 figures, Short Text Classification, Term Graph", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text classi cation is a method for classifying short sentence with\nprede ned labels. However, short text is limited in shortness in text length\nthat leads to a challenging problem of sparse features. Most of existing\nmethods treat each short sentences as independently and identically distributed\n(IID), local context only in the sentence itself is focused and the relational\ninformation between sentences are lost. To overcome these limitations, we\npropose a PathWalk model that combine the strength of graph networks and short\nsentences to solve the sparseness of short text. Experimental results on four\ndifferent available datasets show that our PathWalk method achieves the\nstate-of-the-art results, demonstrating the efficiency and robustness of graph\nnetworks for short text classification.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:32:13 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pang", "Wei", ""]]}, {"id": "2001.10340", "submitter": "Raviraj Joshi", "authors": "Ramchandra Joshi, Purvi Goel, Raviraj Joshi", "title": "Deep Learning for Hindi Text Classification: A Comparison", "comments": "Accepted at International Conference on Intelligent Human Computer\n  Interaction(IHCI) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-44689-5_9", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) and especially natural language text\nanalysis have seen great advances in recent times. Usage of deep learning in\ntext processing has revolutionized the techniques for text processing and\nachieved remarkable results. Different deep learning architectures like CNN,\nLSTM, and very recent Transformer have been used to achieve state of the art\nresults variety on NLP tasks. In this work, we survey a host of deep learning\narchitectures for text classification tasks. The work is specifically concerned\nwith the classification of Hindi text. The research in the classification of\nmorphologically rich and low resource Hindi language written in Devanagari\nscript has been limited due to the absence of large labeled corpus. In this\nwork, we used translated versions of English data-sets to evaluate models based\non CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based\non BERT and LASER are also compared to evaluate their effectiveness for the\nHindi language. The paper also serves as a tutorial for popular text\nclassification techniques.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 09:29:12 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Joshi", "Ramchandra", ""], ["Goel", "Purvi", ""], ["Joshi", "Raviraj", ""]]}, {"id": "2001.10341", "submitter": "Ning Yang", "authors": "Huanrui Luo, Ning Yang, Philip S. Yu", "title": "Hybrid Deep Embedding for Recommendations with Dynamic Aspect-Level\n  Explanations", "comments": "2019 IEEE International Conference on Big Data (Big Data) Best Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable recommendation is far from being well solved partly due to three\nchallenges. The first is the personalization of preference learning, which\nrequires that different items/users have different contributions to the\nlearning of user preference or item quality. The second one is dynamic\nexplanation, which is crucial for the timeliness of recommendation\nexplanations. The last one is the granularity of explanations. In practice,\naspect-level explanations are more persuasive than item-level or user-level\nones. In this paper, to address these challenges simultaneously, we propose a\nnovel model called Hybrid Deep Embedding (HDE) for aspect-based explainable\nrecommendations, which can make recommendations with dynamic aspect-level\nexplanations. The main idea of HDE is to learn the dynamic embeddings of users\nand items for rating prediction and the dynamic latent aspect\npreference/quality vectors for the generation of aspect-level explanations,\nthrough fusion of the dynamic implicit feedbacks extracted from reviews and the\nattentive user-item interactions. Particularly, as the aspect\npreference/quality of users/items is learned automatically, HDE is able to\ncapture the impact of aspects that are not mentioned in reviews of a user or an\nitem. The extensive experiments conducted on real datasets verify the\nrecommending performance and explainability of HDE. The source code of our work\nis available at \\url{https://github.com/lola63/HDE-Python}\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:16:32 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Luo", "Huanrui", ""], ["Yang", "Ning", ""], ["Yu", "Philip S.", ""]]}, {"id": "2001.10342", "submitter": "Enrico Giampieri PhD", "authors": "Carlo Mengucci, Daniel Remondini, Gastone Castellani, Enrico Giampieri", "title": "WISDoM: characterizing neurological timeseries with the Wishart\n  distribution", "comments": "17 pages, 6 figures, submitted to Frontiers in Neuroinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WISDoM (Wishart Distributed Matrices) is a new framework for the\nquantification of deviation of symmetric positive-definite matrices associated\nto experimental samples, like covariance or correlation matrices, from expected\nones governed by the Wishart distribution WISDoM can be applied to tasks of\nsupervised learning, like classification, in particular when such matrices are\ngenerated by data of different dimensionality (e.g. time series with same\nnumber of variables but different time sampling). We show the application of\nthe method in two different scenarios. The first is the ranking of features\nassociated to electro encephalogram (EEG) data with a time series design,\nproviding a theoretically sound approach for this type of studies. The second\nis the classification of autistic subjects of the ABIDE study, using brain\nconnectivity measurements.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:20:17 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 14:33:15 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Mengucci", "Carlo", ""], ["Remondini", "Daniel", ""], ["Castellani", "Gastone", ""], ["Giampieri", "Enrico", ""]]}, {"id": "2001.10353", "submitter": "Eric Wolsztynski", "authors": "Eric Wolsztynski", "title": "Statistical Exploration of Relationships Between Routine and Agnostic\n  Features Towards Interpretable Risk Characterization", "comments": "This work was presented at the 2019 IEEE Medical Imaging Conference,\n  2 November, Manchester, UK. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As is typical in other fields of application of high throughput systems,\nradiology is faced with the challenge of interpreting increasingly\nsophisticated predictive models such as those derived from radiomics analyses.\nInterpretation may be guided by the learning output from machine learning\nmodels, which may however vary greatly with each technique. Whatever this\noutput model, it will raise some essential questions. How do we interpret the\nprognostic model for clinical implementation? How can we identify potential\ninformation structures within sets of radiomic features, in order to create\nclinically interpretable models? And how can we recombine or exploit potential\nrelationships between features towards improved interpretability? A number of\nstatistical techniques are explored to assess (possibly nonlinear)\nrelationships between radiological features from different angles.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:27:09 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Wolsztynski", "Eric", ""]]}, {"id": "2001.10378", "submitter": "Fei Chen", "authors": "Mi Luo, Fei Chen, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Jiashi\n  Feng, Zhenguo Li", "title": "MetaSelector: Meta-Learning for Recommendation with User-Level Adaptive\n  Model Selection", "comments": "Accepted by WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems often face heterogeneous datasets containing highly\npersonalized historical data of users, where no single model could give the\nbest recommendation for every user. We observe this ubiquitous phenomenon on\nboth public and private datasets and address the model selection problem in\npursuit of optimizing the quality of recommendation for each user. We propose a\nmeta-learning framework to facilitate user-level adaptive model selection in\nrecommender systems. In this framework, a collection of recommenders is trained\nwith data from all users, on top of which a model selector is trained via\nmeta-learning to select the best single model for each user with the\nuser-specific historical data. We conduct extensive experiments on two public\ndatasets and a real-world production dataset, demonstrating that our proposed\nframework achieves improvements over single model baselines and sample-level\nmodel selector in terms of AUC and LogLoss. In particular, the improvements may\nlead to huge profit gain when deployed in online recommender systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:05:01 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 08:03:25 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 03:18:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Luo", "Mi", ""], ["Chen", "Fei", ""], ["Cheng", "Pengxiang", ""], ["Dong", "Zhenhua", ""], ["He", "Xiuqiang", ""], ["Feng", "Jiashi", ""], ["Li", "Zhenguo", ""]]}, {"id": "2001.10379", "submitter": "Qianyu Guo", "authors": "Qianyu Guo, Jianzhong Qi", "title": "SANST: A Self-Attentive Network for Next Point-of-Interest\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next point-of-interest (POI) recommendation aims to offer suggestions on\nwhich POI to visit next, given a user's POI visit history. This problem has a\nwide application in the tourism industry, and it is gaining an increasing\ninterest as more POI check-in data become available. The problem is often\nmodeled as a sequential recommendation problem to take advantage of the\nsequential patterns of user check-ins, e.g., people tend to visit Central Park\nafter The Metropolitan Museum of Art in New York City. Recently, self-attentive\nnetworks have been shown to be both effective and efficient in general\nsequential recommendation problems, e.g., to recommend products, video games,\nor movies. Directly adopting self-attentive networks for next POI\nrecommendation, however, may produce sub-optimal recommendations. This is\nbecause vanilla self-attentive networks do not consider the spatial and\ntemporal patterns of user check-ins, which are two critical features in next\nPOI recommendation. To address this limitation, in this paper, we propose a\nmodel named SANST that incorporates spatio-temporal patterns of user check-ins\ninto self-attentive networks. To incorporate the spatial patterns, we encode\nthe relative positions of POIs into their embeddings before feeding the\nembeddings into the self-attentive network. To incorporate the temporal\npatterns, we discretize the time of POI check-ins and model the temporal\nrelationship between POI check-ins by a relation-aware self-attention module.\nWe evaluate the performance of our SANST model with three real-world datasets.\nThe results show that SANST consistently outperforms the state-of-theart\nmodels, and the advantage in nDCG@10 is up to 13.65%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:21:09 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Guo", "Qianyu", ""], ["Qi", "Jianzhong", ""]]}, {"id": "2001.10380", "submitter": "Aladdin Ayesh", "authors": "Qadri Mishael and Aladdin Ayesh", "title": "Investigating Classification Techniques with Feature Selection For\n  Intention Mining From Twitter Feed", "comments": "24 pages, 7 figures, 6 tables, DRAFT journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the last decade, social networks became most popular medium for\ncommunication and interaction. As an example, micro-blogging service Twitter\nhas more than 200 million registered users who exchange more than 65 million\nposts per day. Users express their thoughts, ideas, and even their intentions\nthrough these tweets. Most of the tweets are written informally and often in\nslang language, that contains misspelt and abbreviated words. This paper\ninvestigates the problem of selecting features that affect extracting user's\nintention from Twitter feeds based on text mining techniques. It starts by\npresenting the method we used to construct our own dataset from extracted\nTwitter feeds. Following that, we present two techniques of feature selection\nfollowed by classification. In the first technique, we use Information Gain as\na one-phase feature selection, followed by supervised classification\nalgorithms. In the second technique, we use a hybrid approach based on forward\nfeature selection algorithm in which two feature selection techniques employed\nfollowed by classification algorithms. We examine these two techniques with\nfour classification algorithms. We evaluate them using our own dataset, and we\ncritically review the results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:55:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mishael", "Qadri", ""], ["Ayesh", "Aladdin", ""]]}, {"id": "2001.10389", "submitter": "Jonathan Tuck", "authors": "Jonathan Tuck, Stephen Boyd", "title": "Eigen-Stratified Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stratified models depend in an arbitrary way on a selected categorical\nfeature that takes $K$ values, and depend linearly on the other $n$ features.\nLaplacian regularization with respect to a graph on the feature values can\ngreatly improve the performance of a stratified model, especially in the\nlow-data regime. A significant issue with Laplacian-regularized stratified\nmodels is that the model is $K$ times the size of the base model, which can be\nquite large.\n  We address this issue by formulating eigen-stratifed models, which are\nstratified models with an additional constraint that the model parameters are\nlinear combinations of some modest number $m$ of bottom eigenvectors of the\ngraph Laplacian, i.e., those associated with the $m$ smallest eigenvalues. With\neigen-stratified models, we only need to store the $m$ bottom eigenvectors and\nthe corresponding coefficients as the stratified model parameters. This leads\nto a reduction, sometimes large, of model size when $m \\leq n$ and $m \\ll K$.\nIn some cases, the additional regularization implicit in eigen-stratified\nmodels can improve out-of-sample performance over standard Laplacian\nregularized stratified models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:26:08 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tuck", "Jonathan", ""], ["Boyd", "Stephen", ""]]}, {"id": "2001.10393", "submitter": "Despoina Makariou", "authors": "Despoina Makariou, Pauline Barrieu, Yining Chen", "title": "A random forest based approach for predicting spreads in the primary\n  catastrophe bond market", "comments": "34 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a random forest approach to enable spreads' prediction in the\nprimary catastrophe bond market. We investigate whether all information\nprovided to investors in the offering circular prior to a new issuance is\nequally important in predicting its spread. The whole population of non-life\ncatastrophe bonds issued from December 2009 to May 2018 is used. The random\nforest shows an impressive predictive power on unseen primary catastrophe bond\ndata explaining 93% of the total variability. For comparison, linear\nregression, our benchmark model, has inferior predictive performance explaining\nonly 47% of the total variability. All details provided in the offering\ncircular are predictive of spread but in a varying degree. The stability of the\nresults is studied. The usage of random forest can speed up investment\ndecisions in the catastrophe bond industry.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:04:57 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Makariou", "Despoina", ""], ["Barrieu", "Pauline", ""], ["Chen", "Yining", ""]]}, {"id": "2001.10394", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato, Sarunas Girdzijauskas", "title": "Graph Neighborhood Attentive Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) is a powerful technique for learning\nlow-dimensional vector representation of high-dimensional and sparse graphs.\nMost studies explore the structure and metadata associated with the graph using\nrandom walks and employ an unsupervised or semi-supervised learning schemes.\nLearning in these methods is context-free, because only a single representation\nper node is learned. Recently studies have argued on the sufficiency of a\nsingle representation and proposed a context-sensitive approach that proved to\nbe highly effective in applications such as link prediction and ranking.\n  However, most of these methods rely on additional textual features that\nrequire RNNs or CNNs to capture high-level features or rely on a community\ndetection algorithm to identify multiple contexts of a node.\n  In this study, without requiring additional features nor a community\ndetection algorithm, we propose a novel context-sensitive algorithm called GAP\nthat learns to attend on different parts of a node's neighborhood using\nattentive pooling networks. We show the efficacy of GAP using three real-world\ndatasets on link prediction and node clustering tasks and compare it against 10\npopular and state-of-the-art (SOTA) baselines. GAP consistently outperforms\nthem and achieves up to ~9% and ~20% gain over the best performing methods on\nlink prediction and clustering tasks, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:05:48 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 09:20:57 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2001.10396", "submitter": "David Janz", "authors": "David Janz, David R. Burt, Javier Gonz\\'alez", "title": "Bandit optimisation of functions in the Mat\\'ern kernel RKHS", "comments": "AISTATS 2020, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimising functions in the reproducing kernel\nHilbert space (RKHS) of a Mat\\'ern kernel with smoothness parameter $\\nu$ over\nthe domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the\n$\\pi$-GP-UCB algorithm, is the first practical approach with guaranteed\nsublinear regret for all $\\nu>1$ and $d \\geq 1$. Empirical validation suggests\nbetter performance and drastically improved computational scalablity compared\nwith its predecessor, Improved GP-UCB.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:09:21 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 14:50:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Janz", "David", ""], ["Burt", "David R.", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "2001.10399", "submitter": "Taraneh Younesian", "authors": "Taraneh Younesian, Zilong Zhao, Amirmasoud Ghiassi, Robert Birke,\n  Lydia Y. Chen", "title": "QActor: On-line Active Learning for Noisy Labeled Stream Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labeled data is more a norm than a rarity for self-generated content\nthat is continuously published on the web and social media. Due to privacy\nconcerns and governmental regulations, such a data stream can only be stored\nand used for learning purposes in a limited duration. To overcome the noise in\nthis on-line scenario we propose QActor which novel combines: the selection of\nsupposedly clean samples via quality models and actively querying an oracle for\nthe most informative true labels. While the former can suffer from low data\nvolumes of on-line scenarios, the latter is constrained by the availability and\ncosts of human experts. QActor swiftly combines the merits of quality models\nfor data filtering and oracle queries for cleaning the most informative data.\nThe objective of QActor is to leverage the stringent oracle budget to robustly\nmaximize the learning accuracy. QActor explores various strategies combining\ndifferent query allocations and uncertainty measures. A central feature of\nQActor is to dynamically adjust the query limit according to the learning loss\nfor each data batch. We extensively evaluate different image datasets fed into\nthe classifier that can be standard machine learning (ML) models or deep neural\nnetworks (DNN) with noise label ratios ranging between 30% and 80%. Our results\nshow that QActor can nearly match the optimal accuracy achieved using only\nclean data at the cost of at most an additional 6% of ground truth data from\nthe oracle.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:13:21 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Younesian", "Taraneh", ""], ["Zhao", "Zilong", ""], ["Ghiassi", "Amirmasoud", ""], ["Birke", "Robert", ""], ["Chen", "Lydia Y.", ""]]}, {"id": "2001.10420", "submitter": "Gustavo De Rosa", "authors": "Gustavo Henrique de Rosa, Jo\\~ao Paulo Papa, Alexandre Xavier Falc\\~ao", "title": "OPFython: A Python-Inspired Optimum-Path Forest Classifier", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning techniques have been paramount throughout the last years,\nbeing applied in a wide range of tasks, such as classification, object\nrecognition, person identification, and image segmentation. Nevertheless,\nconventional classification algorithms, e.g., Logistic Regression, Decision\nTrees, and Bayesian classifiers, might lack complexity and diversity, not\nsuitable when dealing with real-world data. A recent graph-inspired classifier,\nknown as the Optimum-Path Forest, has proven to be a state-of-the-art\ntechnique, comparable to Support Vector Machines and even surpassing it in some\ntasks. This paper proposes a Python-based Optimum-Path Forest framework,\ndenoted as OPFython, where all of its functions and classes are based upon the\noriginal C language implementation. Additionally, as OPFython is a Python-based\nlibrary, it provides a more friendly environment and a faster prototyping\nworkspace than the C language.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:46:19 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 14:06:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["de Rosa", "Gustavo Henrique", ""], ["Papa", "Jo\u00e3o Paulo", ""], ["Falc\u00e3o", "Alexandre Xavier", ""]]}, {"id": "2001.10422", "submitter": "Arber Zela", "authors": "Arber Zela, Julien Siems, Frank Hutter", "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural\n  Architecture Search", "comments": "In: International Conference on Learning Representations (ICLR 2020);\n  19 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still\na lack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS\nmethods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:50:22 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 22:48:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zela", "Arber", ""], ["Siems", "Julien", ""], ["Hutter", "Frank", ""]]}, {"id": "2001.10460", "submitter": "Etai Littwin", "authors": "Etai Littwin, Tomer Galanti, Lior Wolf", "title": "On Random Kernels of Residual Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive finite width and depth corrections for the Neural Tangent Kernel\n(NTK) of ResNets and DenseNets. Our analysis reveals that finite size residual\narchitectures are initialized much closer to the \"kernel regime\" than their\nvanilla counterparts: while in networks that do not use skip connections,\nconvergence to the NTK requires one to fix the depth, while increasing the\nlayers' width. Our findings show that in ResNets, convergence to the NTK may\noccur when depth and width simultaneously tend to infinity, provided with a\nproper initialization. In DenseNets, however, convergence of the NTK to its\nlimit as the width tends to infinity is guaranteed, at a rate that is\nindependent of both the depth and scale of the weights. Our experiments\nvalidate the theoretical results and demonstrate the advantage of deep ResNets\nand DenseNets for kernel regression with random gradient features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 16:47:53 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 01:33:58 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:43:28 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 14:12:19 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Littwin", "Etai", ""], ["Galanti", "Tomer", ""], ["Wolf", "Lior", ""]]}, {"id": "2001.10468", "submitter": "Firas Kassawat", "authors": "Firas Kassawat, Debanjan Chaudhuri, Jens Lehmann", "title": "Incorporating Joint Embeddings into Goal-Oriented Dialogues with\n  Multi-Task Learning", "comments": "The Semantic Web - 16th International Conference, ESWC 2019,\n  Portoro\\v{z}, Slovenia, June 2-6, 2019, Proceedings, page 225-239", "journal-ref": null, "doi": "10.1007/978-3-030-21348-0_15", "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder neural network models have recently shown\npromising results in goal-oriented dialogue systems. However, these models\nstruggle to reason over and incorporate state-full knowledge while preserving\ntheir end-to-end text generation functionality. Since such models can greatly\nbenefit from user intent and knowledge graph integration, in this paper we\npropose an RNN-based end-to-end encoder-decoder architecture which is trained\nwith joint embeddings of the knowledge graph and the corpus as input. The model\nprovides an additional integration of user intent along with text generation,\ntrained with a multi-task learning paradigm along with an additional\nregularization technique to penalize generating the wrong entity as output. The\nmodel further incorporates a Knowledge Graph entity lookup during inference to\nguarantee the generated output is state-full based on the local knowledge graph\nprovided. We finally evaluated the model using the BLEU score, empirical\nevaluation depicts that our proposed architecture can aid in the betterment of\ntask-oriented dialogue system`s performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:15:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kassawat", "Firas", ""], ["Chaudhuri", "Debanjan", ""], ["Lehmann", "Jens", ""]]}, {"id": "2001.10474", "submitter": "Modjtaba Shokrian Zini", "authors": "Modjtaba Shokrian Zini, Mohammad Pedramfar, Matthew Riemer, Miao Liu", "title": "Coagent Networks Revisited", "comments": "Added multiple experiments and new results to the previous version\n  \"Parameter Sharing in Coagent Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is aiming to discuss and close some of the gaps in the literature\non models using options (and more generally coagents). Briefly surveying the\ntheory behind these models, it also aims to provide a unifying point of view on\nthe many diverse examples that fall under a same category called coagent\nnetwork. Motivated by the result of [10] on parameter sharing of options, we\nrevisit the theory of (a)synchronous Coagent Network [8] by generalizing the\nresult to the context where parameters are shared among the function\napproximators of coagents. The proof is more intuitive and uses the concept of\nexecution paths in a coagent network. Theoretically, this informs us of some\nnecessary modifications to the algorithms found in the literature which make\nthem more mathematically accurate. It also allows us to introduce a new simple\noption framework, Feedforward Option Network, which outperforms the previous\noption models in time to convergence and stability in the famous nonstationary\nFour Rooms task. In addition, a stabilization effect is observed in\nhierarchical models which justify the unnecessity of the target network in\ntraining such models. Finally, we publish our code which allows us to be\nflexible in our experiments settings.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:31:23 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 11:09:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zini", "Modjtaba Shokrian", ""], ["Pedramfar", "Mohammad", ""], ["Riemer", "Matthew", ""], ["Liu", "Miao", ""]]}, {"id": "2001.10477", "submitter": "Andrea Rocchetto", "authors": "Carlo Ciliberto, Andrea Rocchetto, Alessandro Rudi, Leonard Wossnig", "title": "Statistical Limits of Supervised Quantum Learning", "comments": "v3: 6 pages, journal version, title changed (previous title \"The\n  Statistical Limits of Supervised Quantum Learning\"), other minor\n  improvements; v2: 6 pages, title changed (previous title \"Fast quantum\n  learning with statistical guarantees\"), format changed to two-columns, typos\n  corrected, remarks that better clarify the limitations of our analysis added", "journal-ref": "Phys. Rev. A 102, 042414 (2020)", "doi": "10.1103/PhysRevA.102.042414", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the framework of statistical learning theory it is possible to bound\nthe minimum number of samples required by a learner to reach a target accuracy.\nWe show that if the bound on the accuracy is taken into account, quantum\nmachine learning algorithms for supervised learning---for which statistical\nguarantees are available---cannot achieve polylogarithmic runtimes in the input\ndimension. We conclude that, when no further assumptions on the problem are\nmade, quantum machine learning algorithms for supervised learning can have at\nmost polynomial speedups over efficient classical algorithms, even in cases\nwhere quantum access to the data is naturally available.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:35:32 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:10:57 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 09:36:24 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ciliberto", "Carlo", ""], ["Rocchetto", "Andrea", ""], ["Rudi", "Alessandro", ""], ["Wossnig", "Leonard", ""]]}, {"id": "2001.10485", "submitter": "Cheng Yang", "authors": "Cheng Yang, Gene Cheung, Wei Hu", "title": "Graph Metric Learning via Gershgorin Disc Alignment", "comments": "accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast general projection-free metric learning framework, where\nthe minimization objective $\\min_{\\textbf{M} \\in \\mathcal{S}} Q(\\textbf{M})$ is\na convex differentiable function of the metric matrix $\\textbf{M}$, and\n$\\textbf{M}$ resides in the set $\\mathcal{S}$ of generalized graph Laplacian\nmatrices for connected graphs with positive edge weights and node degrees.\nUnlike low-rank metric matrices common in the literature, $\\mathcal{S}$\nincludes the important positive-diagonal-only matrices as a special case in the\nlimit. The key idea for fast optimization is to rewrite the positive definite\ncone constraint in $\\mathcal{S}$ as signal-adaptive linear constraints via\nGershgorin disc alignment, so that the alternating optimization of the diagonal\nand off-diagonal terms in $\\textbf{M}$ can be solved efficiently as linear\nprograms via Frank-Wolfe iterations. We prove that the Gershgorin discs can be\naligned perfectly using the first eigenvector $\\textbf{v}$ of $\\textbf{M}$,\nwhich we update iteratively using Locally Optimal Block Preconditioned\nConjugate Gradient (LOBPCG) with warm start as diagonal / off-diagonal terms\nare optimized. Experiments show that our efficiently computed graph metric\nmatrices outperform metrics learned using competing methods in terms of\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:44:01 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:09:24 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 14:02:27 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 22:42:43 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Yang", "Cheng", ""], ["Cheung", "Gene", ""], ["Hu", "Wei", ""]]}, {"id": "2001.10494", "submitter": "Feiyang Cai", "authors": "Feiyang Cai and Xenofon Koutsoukos", "title": "Real-time Out-of-distribution Detection in Learning-Enabled\n  Cyber-Physical Systems", "comments": "Accepted by 11th International Conference on Cyber-Physical Systems\n  (ICCPS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) greatly benefit by using machine learning\ncomponents that can handle the uncertainty and variability of the real-world.\nTypical components such as deep neural networks, however, introduce new types\nof hazards that may impact system safety. The system behavior depends on data\nthat are available only during runtime and may be different than the data used\nfor training. Out-of-distribution data may lead to a large error and compromise\nsafety. The paper considers the problem of efficiently detecting\nout-of-distribution data in CPS control systems. Detection must be robust and\nlimit the number of false alarms while being computational efficient for\nreal-time monitoring. The proposed approach leverages inductive conformal\nprediction and anomaly detection for developing a method that has a\nwell-calibrated false alarm rate. We use variational autoencoders and deep\nsupport vector data description to learn models that can be used efficiently\ncompute the nonconformity of new inputs relative to the training set and enable\nreal-time detection of out-of-distribution high-dimensional inputs. We\ndemonstrate the method using an advanced emergency braking system and a\nself-driving end-to-end controller implemented in an open source simulator for\nself-driving cars. The simulation results show very small number of false\npositives and detection delay while the execution time is comparable to the\nexecution time of the original machine learning components.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:51:07 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Cai", "Feiyang", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2001.10495", "submitter": "Amar Budhiraja", "authors": "Amar Budhiraja, Gaurush Hiranandani, Darshak Chhatbar, Aditya Sinha,\n  Navya Yarrabelly, Ayush Choure, Oluwasanmi Koyejo, Prateek Jain", "title": "Rich-Item Recommendations for Rich-Users: Exploiting Dynamic and Static\n  Side Information", "comments": "The first two authors contributed equally. 21 pages, 8 figures and 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of recommendation system where the users\nand items to be recommended are rich data structures with multiple entity types\nand with multiple sources of side-information in the form of graphs. We provide\na general formulation for the problem that captures the complexities of modern\nreal-world recommendations and generalizes many existing formulations. In our\nformulation, each user/document that requires a recommendation and each item or\ntag that is to be recommended, both are modeled by a set of static entities and\na dynamic component. The relationships between entities are captured by several\nweighted bipartite graphs. To effectively exploit these complex interactions\nand learn the recommendation model, we propose MEDRES- a multiple graph-CNN\nbased novel deep-learning architecture. MEDRES uses AL-GCN, a novel graph\nconvolution network block, that harnesses strong representative features from\nthe underlying graphs. Moreover, in order to capture highly heterogeneous\nengagement of different users with the system and constraints on the number of\nitems to be recommended, we propose a novel ranking metric pAp@k along with a\nmethod to optimize the metric directly. We demonstrate effectiveness of our\nmethod on two benchmarks: a) citation data, b) Flickr data. In addition, we\npresent two real-world case studies of our formulation and the MEDRES\narchitecture. We show how our technique can be used to naturally model the\nmessage recommendation problem and the teams recommendation problem in the\nMicrosoft Teams (MSTeams) product and demonstrate that it is 5-6% points more\naccurate than the production-grade models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:53:38 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 12:34:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Budhiraja", "Amar", ""], ["Hiranandani", "Gaurush", ""], ["Chhatbar", "Darshak", ""], ["Sinha", "Aditya", ""], ["Yarrabelly", "Navya", ""], ["Choure", "Ayush", ""], ["Koyejo", "Oluwasanmi", ""], ["Jain", "Prateek", ""]]}, {"id": "2001.10509", "submitter": "Christoph Studer", "authors": "Ramina Ghods, Andrew S. Lan, Tom Goldstein, Christoph Studer", "title": "MSE-Optimal Neural Network Initialization via Layer Fusion", "comments": "Extended version of the CISS 2020 paper containing the proof for\n  convolutional layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve state-of-the-art performance for a range of\nclassification and inference tasks. However, the use of stochastic gradient\ndescent combined with the nonconvexity of the underlying optimization problems\nrenders parameter learning susceptible to initialization. To address this\nissue, a variety of methods that rely on random parameter initialization or\nknowledge distillation have been proposed in the past. In this paper, we\npropose FuseInit, a novel method to initialize shallower networks by fusing\nneighboring layers of deeper networks that are trained with random\ninitialization. We develop theoretical results and efficient algorithms for\nmean-square error (MSE)-optimal fusion of neighboring dense-dense,\nconvolutional-dense, and convolutional-convolutional layers. We show\nexperiments for a range of classification and regression datasets, which\nsuggest that deeper neural networks are less sensitive to initialization and\nshallower networks can perform better (sometimes as well as their deeper\ncounterparts) if initialized with FuseInit.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:25:15 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ghods", "Ramina", ""], ["Lan", "Andrew S.", ""], ["Goldstein", "Tom", ""], ["Studer", "Christoph", ""]]}, {"id": "2001.10516", "submitter": "Hao Xu", "authors": "Hao Xu, Shengqi Sang and Haiping Lu", "title": "Tri-graph Information Propagation for Polypharmacy Side Effect\n  Prediction", "comments": "Presented at NeruIPS 2019 Graph Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of drug combinations often leads to polypharmacy side effects (POSE).\nA recent method formulates POSE prediction as a link prediction problem on a\ngraph of drugs and proteins, and solves it with Graph Convolutional Networks\n(GCNs). However, due to the complex relationships in POSE, this method has high\ncomputational cost and memory demand. This paper proposes a flexible Tri-graph\nInformation Propagation (TIP) model that operates on three subgraphs to learn\nrepresentations progressively by propagation from protein-protein graph to\ndrug-drug graph via protein-drug graph. Experiments show that TIP improves\naccuracy by 7%+, time efficiency by 83$\\times$, and space efficiency by\n3$\\times$.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:39:11 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Xu", "Hao", ""], ["Sang", "Shengqi", ""], ["Lu", "Haiping", ""]]}, {"id": "2001.10523", "submitter": "Carlos Villacampa-Calvo", "authors": "Carlos Villacampa-Calvo, Bryan Zaldivar, Eduardo C. Garrido-Merch\\'an,\n  Daniel Hern\\'andez-Lobato", "title": "Multi-class Gaussian Process Classification with Noisy Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a common practice in the machine learning community to assume that the\nobserved data are noise-free in the input attributes. Nevertheless, scenarios\nwith input noise are common in real problems, as measurements are never\nperfectly accurate. If this input noise is not taken into account, a supervised\nmachine learning method is expected to perform sub-optimally. In this paper, we\nfocus on multi-class classification problems and use Gaussian processes (GPs)\nas the underlying classifier. Motivated by a data set coming from the\nastrophysics domain, we hypothesize that the observed data may contain noise in\nthe inputs. Therefore, we devise several multi-class GP classifiers that can\naccount for input noise. Such classifiers can be efficiently trained using\nvariational inference to approximate the posterior distribution of the latent\nvariables of the model. Moreover, in some situations, the amount of noise can\nbe known before-hand. If this is the case, it can be readily introduced in the\nproposed methods. This prior information is expected to lead to better\nperformance results. We have evaluated the proposed methods by carrying out\nseveral experiments, involving synthetic and real data. These include several\ndata sets from the UCI repository, the MNIST data set and a data set coming\nfrom astrophysics. The results obtained show that, although the classification\nerror is similar across methods, the predictive distribution of the proposed\nmethods is better, in terms of the test log-likelihood, than the predictive\ndistribution of a classifier based on GPs that ignores input noise.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:55:13 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 11:16:24 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 13:41:55 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Villacampa-Calvo", "Carlos", ""], ["Zaldivar", "Bryan", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2001.10528", "submitter": "Geoff Pleiss", "authors": "Geoff Pleiss, Tianyi Zhang, Ethan R. Elenberg, Kilian Q. Weinberger", "title": "Identifying Mislabeled Data using the Area Under the Margin Ranking", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all data in a typical training set help with generalization; some samples\ncan be overly ambiguous or outrightly mislabeled. This paper introduces a new\nmethod to identify such samples and mitigate their impact when training neural\nnetworks. At the heart of our algorithm is the Area Under the Margin (AUM)\nstatistic, which exploits differences in the training dynamics of clean and\nmislabeled samples. A simple procedure - adding an extra class populated with\npurposefully mislabeled threshold samples - learns a AUM upper bound that\nisolates mislabeled data. This approach consistently improves upon prior work\non synthetic and real-world datasets. On the WebVision50 classification task\nour method removes 17% of training data, yielding a 1.6% (absolute) improvement\nin test error. On CIFAR100 removing 13% of the data leads to a 1.2% drop in\nerror.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:59:03 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:41:30 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 18:55:17 GMT"}, {"version": "v4", "created": "Wed, 23 Dec 2020 14:01:54 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Pleiss", "Geoff", ""], ["Zhang", "Tianyi", ""], ["Elenberg", "Ethan R.", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2001.10560", "submitter": "Mehdi Ali", "authors": "Mehdi Ali, Hajira Jabeen, Charles Tapley Hoyt, and Jens Lehman", "title": "The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a\n  Focus on Reproducibility and Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an emerging trend of embedding knowledge graphs (KGs) in continuous\nvector spaces in order to use those for machine learning tasks. Recently, many\nknowledge graph embedding (KGE) models have been proposed that learn low\ndimensional representations while trying to maintain the structural properties\nof the KGs such as the similarity of nodes depending on their edges to other\nnodes. KGEs can be used to address tasks within KGs such as the prediction of\nnovel links and the disambiguation of entities. They can also be used for\ndownstream tasks like question answering and fact-checking. Overall, these\ntasks are relevant for the semantic web community. Despite their popularity,\nthe reproducibility of KGE experiments and the transferability of proposed KGE\nmodels to research fields outside the machine learning community can be a major\nchallenge. Therefore, we present the KEEN Universe, an ecosystem for knowledge\ngraph embeddings that we have developed with a strong focus on reproducibility\nand transferability. The KEEN Universe currently consists of the Python\npackages PyKEEN (Python KnowlEdge EmbeddiNgs), BioKEEN (Biological KnowlEdge\nEmbeddiNgs), and the KEEN Model Zoo for sharing trained KGE models with the\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:12:37 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ali", "Mehdi", ""], ["Jabeen", "Hajira", ""], ["Hoyt", "Charles Tapley", ""], ["Lehman", "Jens", ""]]}, {"id": "2001.10568", "submitter": "Seyed Alireza Razavi", "authors": "Alireza Razavi", "title": "Landmark2Vec: An Unsupervised Neural Network-Based Landmark Positioning\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Neural Network-based method for unsupervised landmarks map estimation from\nmeasurements taken from landmarks is introduced. The measurements needed for\ntraining the network are the signals observed/received from landmarks by an\nagent. The definition of landmarks, agent, and the measurements taken by agent\nfrom landmarks is rather broad here: landmarks can be visual objects, e.g.,\npoles along a road, with measurements being the size of landmark in a visual\nsensor mounted on a vehicle (agent), or they can be radio transmitters, e.g.,\nWiFi access points inside a building, with measurements being the Received\nSignal Strength (RSS) heard from them by a mobile device carried by a person\n(agent). The goal of the map estimation is then to find the positions of\nlandmarks up to a scale, rotation, and shift (i.e., the topological map of the\nlandmarks). Assuming that there are $L$ landmarks, the measurements will be $L\n\\times 1$ vectors collected over the area. A shallow network then will be\ntrained to learn the map without any ground truth information.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:39:55 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Razavi", "Alireza", ""]]}, {"id": "2001.10616", "submitter": "Yuling Jiao", "authors": "Jian Huang, Yuling Jiao, Lican Kang, Jin Liu, Yanyan Liu, Xiliang Lu,\n  and Yuanyuan Yang", "title": "On Newton Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening and working set techniques are important approaches to reducing the\nsize of an optimization problem. They have been widely used in accelerating\nfirst-order methods for solving large-scale sparse learning problems. In this\npaper, we develop a new screening method called Newton screening (NS) which is\na generalized Newton method with a built-in screening mechanism. We derive an\nequivalent KKT system for the Lasso and utilize a generalized Newton method to\nsolve the KKT equations. Based on this KKT system, a built-in working set with\na relatively small size is first determined using the sum of primal and dual\nvariables generated from the previous iteration, then the primal variable is\nupdated by solving a least-squares problem on the working set and the dual\nvariable updated based on a closed-form expression. Moreover, we consider a\nsequential version of Newton screening (SNS) with a warm-start strategy. We\nshow that NS possesses an optimal convergence property in the sense that it\nachieves one-step local convergence. Under certain regularity conditions on the\nfeature matrix, we show that SNS hits a solution with the same signs as the\nunderlying true target and achieves a sharp estimation error bound with high\nprobability. Simulation studies and real data analysis support our theoretical\nresults and demonstrate that SNS is faster and more accurate than several\nstate-of-the-art methods in our comparative studies.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:25:33 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 16:09:52 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Kang", "Lican", ""], ["Liu", "Jin", ""], ["Liu", "Yanyan", ""], ["Lu", "Xiliang", ""], ["Yang", "Yuanyuan", ""]]}, {"id": "2001.10623", "submitter": "Nikita Zhivotovskiy", "authors": "Gergely Neu and Nikita Zhivotovskiy", "title": "Fast Rates for Online Prediction with Abstention", "comments": "19 pages, minor corrections, to appear in COLT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of sequential prediction of individual $\\{0, 1\\}$-sequences\nwith expert advice, we show that by allowing the learner to abstain from the\nprediction by paying a cost marginally smaller than $\\frac 12$ (say, $0.49$),\nit is possible to achieve expected regret bounds that are independent of the\ntime horizon $T$. We exactly characterize the dependence on the abstention cost\n$c$ and the number of experts $N$ by providing matching upper and lower bounds\nof order $\\frac{\\log N}{1-2c}$, which is to be contrasted with the best\npossible rate of $\\sqrt{T\\log N}$ that is available without the option to\nabstain. We also discuss various extensions of our model, including a setting\nwhere the sequence of abstention costs can change arbitrarily over time, where\nwe show regret bounds interpolating between the slow and the fast rates\nmentioned above, under some natural assumptions on the sequence of abstention\ncosts.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 22:34:55 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 19:07:38 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Neu", "Gergely", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2001.10631", "submitter": "Xiaowei Li", "authors": "Halyun Jeong, Xiaowei Li, Yaniv Plan, \\\"Ozg\\\"ur Y{\\i}lmaz", "title": "Sub-Gaussian Matrices on Sets: Optimal Tail Dependence and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random linear mappings are widely used in modern signal processing,\ncompressed sensing and machine learning. These mappings may be used to embed\nthe data into a significantly lower dimension while at the same time preserving\nuseful information. This is done by approximately preserving the distances\nbetween data points, which are assumed to belong to $\\mathbb{R}^n$. Thus, the\nperformance of these mappings is usually captured by how close they are to an\nisometry on the data. Gaussian linear mappings have been the object of much\nstudy, while the sub-Gaussian settings is not yet fully understood. In the\nlatter case, the performance depends on the sub-Gaussian norm of the rows. In\nmany applications, e.g., compressed sensing, this norm may be large, or even\ngrowing with dimension, and thus it is important to characterize this\ndependence.\n  We study when a sub-Gaussian matrix can become a near isometry on a set, show\nthat previous best known dependence on the sub-Gaussian norm was sub-optimal,\nand present the optimal dependence. Our result not only answers a remaining\nquestion posed by Liaw, Mehrabian, Plan and Vershynin in 2017, but also\ngeneralizes their work. We also develop a new Bernstein type inequality for\nsub-exponential random variables, and a new Hanson-Wright inequality for\nquadratic forms of sub-Gaussian random variables, in both cases improving the\nbounds in the sub-Gaussian regime under moment constraints. Finally, we\nillustrate popular applications such as Johnson-Lindenstrauss embeddings, null\nspace property for 0-1 matrices, randomized sketches and blind demodulation,\nwhose theoretical guarantees can be improved by our results (in the\nsub-Gaussian case).\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 23:06:20 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 21:30:18 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Jeong", "Halyun", ""], ["Li", "Xiaowei", ""], ["Plan", "Yaniv", ""], ["Y\u0131lmaz", "\u00d6zg\u00fcr", ""]]}, {"id": "2001.10642", "submitter": "Kazuhiko Shinoda", "authors": "Kazuhiko Shinoda, Hirotaka Kaji, Masashi Sugiyama", "title": "Binary Classification from Positive Data with Skewed Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive-confidence (Pconf) classification [Ishida et al., 2018] is a\npromising weakly-supervised learning method which trains a binary classifier\nonly from positive data equipped with confidence. However, in practice, the\nconfidence may be skewed by bias arising in an annotation process. The Pconf\nclassifier cannot be properly learned with skewed confidence, and consequently,\nthe classification performance might be deteriorated. In this paper, we\nintroduce the parameterized model of the skewed confidence, and propose the\nmethod for selecting the hyperparameter which cancels out the negative impact\nof skewed confidence under the assumption that we have the misclassification\nrate of positive samples as a prior knowledge. We demonstrate the effectiveness\nof the proposed method through a synthetic experiment with simple linear models\nand benchmark problems with neural network models. We also apply our method to\ndrivers' drowsiness prediction to show that it works well with a real-world\nproblem where confidence is obtained based on manual annotation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 00:04:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Shinoda", "Kazuhiko", ""], ["Kaji", "Hirotaka", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2001.10648", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi and Mohamed Ali Kaafar", "title": "Modelling and Quantifying Membership Information Leakage in Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been shown to be vulnerable to membership\ninference attacks, i.e., inferring whether individuals' data have been used for\ntraining models. The lack of understanding about factors contributing success\nof these attacks motivates the need for modelling membership information\nleakage using information theory and for investigating properties of machine\nlearning models and training algorithms that can reduce membership information\nleakage. We use conditional mutual information leakage to measure the amount of\ninformation leakage from the trained machine learning model about the presence\nof an individual in the training dataset. We devise an upper bound for this\nmeasure of information leakage using Kullback--Leibler divergence that is more\namenable to numerical computation. We prove a direct relationship between the\nKullback--Leibler membership information leakage and the probability of success\nfor a hypothesis-testing adversary examining whether a particular data record\nbelongs to the training dataset of a machine learning model. We show that the\nmutual information leakage is a decreasing function of the training dataset\nsize and the regularization weight. We also prove that, if the sensitivity of\nthe machine learning model (defined in terms of the derivatives of the fitness\nwith respect to model parameters) is high, more membership information is\npotentially leaked. This illustrates that complex models, such as deep neural\nnetworks, are more susceptible to membership inference attacks in comparison to\nsimpler models with fewer degrees of freedom. We show that the amount of the\nmembership information leakage is reduced by\n$\\mathcal{O}(\\log^{1/2}(\\delta^{-1})\\epsilon^{-1})$ when using Gaussian\n$(\\epsilon,\\delta)$-differentially-private additive noises.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 00:42:08 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 00:43:42 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Farokhi", "Farhad", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "2001.10652", "submitter": "Weijia Zhang", "authors": "Weijia Zhang, Lin Liu, Jiuyong Li", "title": "Treatment effect estimation with disentangled latent factors", "comments": "Published in the Proceedings of the 35th AAAI Conference on\n  Artificial Intelligence (AAAI'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research has been devoted to the problem of estimating treatment effects\nfrom observational data; however, most methods assume that the observed\nvariables only contain confounders, i.e., variables that affect both the\ntreatment and the outcome. Unfortunately, this assumption is frequently\nviolated in real-world applications, since some variables only affect the\ntreatment but not the outcome, and vice versa. Moreover, in many cases only the\nproxy variables of the underlying confounding factors can be observed. In this\nwork, we first show the importance of differentiating confounding factors from\ninstrumental and risk factors for both average and conditional average\ntreatment effect estimation, and then we propose a variational inference\napproach to simultaneously infer latent factors from the observed variables,\ndisentangle the factors into three disjoint sets corresponding to the\ninstrumental, confounding, and risk factors, and use the disentangled factors\nfor treatment effect estimation. Experimental results demonstrate the\neffectiveness of the proposed method on a wide range of synthetic, benchmark,\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 01:00:36 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 02:28:34 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 13:42:03 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Weijia", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""]]}, {"id": "2001.10655", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Regularization Helps with Mitigating Poisoning Attacks:\n  Distributionally-Robust Machine Learning Using the Wasserstein Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use distributionally-robust optimization for machine learning to mitigate\nthe effect of data poisoning attacks. We provide performance guarantees for the\ntrained model on the original data (not including the poison records) by\ntraining the model for the worst-case distribution on a neighbourhood around\nthe empirical distribution (extracted from the training dataset corrupted by a\npoisoning attack) defined using the Wasserstein distance. We relax the\ndistributionally-robust machine learning problem by finding an upper bound for\nthe worst-case fitness based on the empirical sampled-averaged fitness and the\nLipschitz-constant of the fitness function (on the data for given model\nparameters) as regularizer. For regression models, we prove that this\nregularizer is equal to the dual norm of the model parameters. We use the Wine\nQuality dataset, the Boston Housing Market dataset, and the Adult dataset for\ndemonstrating the results of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 01:16:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2001.10657", "submitter": "Patrick Dallaire", "authors": "Patrick Dallaire, Luca Ambrogioni, Ludovic Trottier, Umut\n  G\\\"u\\c{c}l\\\"u, Max Hinne, Philippe Gigu\\`ere, Brahim Chaib-Draa, Marcel van\n  Gerven, and Francois Laviolette", "title": "The Indian Chefs Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Indian Chefs Process (ICP), a Bayesian\nnonparametric prior on the joint space of infinite directed acyclic graphs\n(DAGs) and orders that generalizes Indian Buffet Processes. As our construction\nshows, the proposed distribution relies on a latent Beta Process controlling\nboth the orders and outgoing connection probabilities of the nodes, and yields\na probability distribution on sparse infinite graphs. The main advantage of the\nICP over previously proposed Bayesian nonparametric priors for DAG structures\nis its greater flexibility. To the best of our knowledge, the ICP is the first\nBayesian nonparametric model supporting every possible DAG. We demonstrate the\nusefulness of the ICP on learning the structure of deep generative sigmoid\nnetworks as well as convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 01:28:15 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Dallaire", "Patrick", ""], ["Ambrogioni", "Luca", ""], ["Trottier", "Ludovic", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["Hinne", "Max", ""], ["Gigu\u00e8re", "Philippe", ""], ["Chaib-Draa", "Brahim", ""], ["van Gerven", "Marcel", ""], ["Laviolette", "Francois", ""]]}, {"id": "2001.10675", "submitter": "Robert Bamler", "authors": "Fabian Jirasek, Rodrigo A. S. Alves, Julie Damay, Robert A.\n  Vandermeulen, Robert Bamler, Michael Bortz, Stephan Mandt, Marius Kloft, Hans\n  Hasse", "title": "Machine Learning in Thermodynamics: Prediction of Activity Coefficients\n  by Matrix Completion", "comments": "Published version: J. Phys. Chem. Lett. 11 (2020) 981-985;\n  https://pubs.acs.org/doi/full/10.1021/acs.jpclett.9b03657", "journal-ref": "J. Phys. Chem. Lett. 11 (2020) 981-985", "doi": "10.1021/acs.jpclett.9b03657", "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity coefficients, which are a measure of the non-ideality of liquid\nmixtures, are a key property in chemical engineering with relevance to modeling\nchemical and phase equilibria as well as transport processes. Although\nexperimental data on thousands of binary mixtures are available, prediction\nmethods are needed to calculate the activity coefficients in many relevant\nmixtures that have not been explored to-date. In this report, we propose a\nprobabilistic matrix factorization model for predicting the activity\ncoefficients in arbitrary binary mixtures. Although no physical descriptors for\nthe considered components were used, our method outperforms the\nstate-of-the-art method that has been refined over three decades while\nrequiring much less training effort. This opens perspectives to novel methods\nfor predicting physico-chemical properties of binary mixtures with the\npotential to revolutionize modeling and simulation in chemical engineering.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 03:16:23 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Jirasek", "Fabian", ""], ["Alves", "Rodrigo A. S.", ""], ["Damay", "Julie", ""], ["Vandermeulen", "Robert A.", ""], ["Bamler", "Robert", ""], ["Bortz", "Michael", ""], ["Mandt", "Stephan", ""], ["Kloft", "Marius", ""], ["Hasse", "Hans", ""]]}, {"id": "2001.10726", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Hao Wang, Enrique Alba, Thomas B\\\"ack", "title": "Bayesian Neural Architecture Search using A Training-Free Performance\n  Metric", "comments": null, "journal-ref": "Applied Soft Computing, p.107356 (2021)", "doi": "10.1016/j.asoc.2021.107356", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a powerful approach for time series\nprediction. However, their performance is strongly affected by their\narchitecture and hyperparameter settings. The architecture optimization of RNNs\nis a time-consuming task, where the search space is typically a mixture of\nreal, integer and categorical values. To allow for shrinking and expanding the\nsize of the network, the representation of architectures often has a variable\nlength. In this paper, we propose to tackle the architecture optimization\nproblem with a variant of the Bayesian Optimization (BO) algorithm. To reduce\nthe evaluation time of candidate architectures the Mean Absolute Error Random\nSampling (MRS), a training-free method to estimate the network performance, is\nadopted as the objective function for BO. Also, we propose three fixed-length\nencoding schemes to cope with the variable-length architecture representation.\nThe result is a new perspective on accurate and efficient design of RNNs, that\nwe validate on three problems. Our findings show that 1) the BO algorithm can\nexplore different network architectures using the proposed encoding schemes and\nsuccessfully designs well-performing architectures, and 2) the optimization\ntime is significantly reduced by using MRS, without compromising the\nperformance as compared to the architectures obtained from the actual training\nprocedure.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:42:58 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 07:48:42 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Wang", "Hao", ""], ["Alba", "Enrique", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2001.10741", "submitter": "Alexander Tornede", "authors": "Alexander Tornede, Marcel Wever, Eyke H\\\"ullermeier", "title": "Extreme Algorithm Selection With Dyadic Feature Representation", "comments": "Published at Discovery Science 2020", "journal-ref": null, "doi": "10.1007/978-3-030-61527-7_21", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithm selection (AS) deals with selecting an algorithm from a fixed set\nof candidate algorithms most suitable for a specific instance of an algorithmic\nproblem, e.g., choosing solvers for SAT problems. Benchmark suites for AS\nusually comprise candidate sets consisting of at most tens of algorithms,\nwhereas in combined algorithm selection and hyperparameter optimization\nproblems the number of candidates becomes intractable, impeding to learn\neffective meta-models and thus requiring costly online performance evaluations.\nTherefore, here we propose the setting of extreme algorithm selection (XAS)\nwhere we consider fixed sets of thousands of candidate algorithms, facilitating\nmeta learning. We assess the applicability of state-of-the-art AS techniques to\nthe XAS setting and propose approaches leveraging a dyadic feature\nrepresentation in which both problem instances and algorithms are described. We\nfind the latter to improve significantly over the current state of the art in\nvarious metrics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:40:58 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:56:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tornede", "Alexander", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2001.10742", "submitter": "Ming Yin", "authors": "Ming Yin and Yu-Xiang Wang (University of California Santa Barbara)", "title": "Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement\n  Learning", "comments": "Includes appendix. Accepted for AISTATS 2020", "journal-ref": "International Conference on Artificial Intelligence and\n  Statistics, 108 (2020) 3948-3958", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of off-policy evaluation for reinforcement learning,\nwhere the goal is to estimate the expected reward of a target policy $\\pi$\nusing offline data collected by running a logging policy $\\mu$. Standard\nimportance-sampling based approaches for this problem suffer from a variance\nthat scales exponentially with time horizon $H$, which motivates a splurge of\nrecent interest in alternatives that break the \"Curse of Horizon\" (Liu et al.\n2018, Xie et al. 2019). In particular, it was shown that a marginalized\nimportance sampling (MIS) approach can be used to achieve an estimation error\nof order $O(H^3/ n)$ in mean square error (MSE) under an episodic Markov\nDecision Process model with finite states and potentially infinite actions. The\nMSE bound however is still a factor of $H$ away from a Cramer-Rao lower bound\nof order $\\Omega(H^2/n)$. In this paper, we prove that with a simple\nmodification to the MIS estimator, we can asymptotically attain the Cramer-Rao\nlower bound, provided that the action space is finite. We also provide a\ngeneral method for constructing MIS estimators with high-probability error\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:56:26 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yin", "Ming", "", "University of California Santa Barbara"], ["Wang", "Yu-Xiang", "", "University of California Santa Barbara"]]}, {"id": "2001.10816", "submitter": "Siddharth Sigtia", "authors": "Siddharth Sigtia, Erik Marchi, Sachin Kajarekar, Devang Naik, John\n  Bridle", "title": "Multi-task Learning for Speaker Verification and Voice Trigger Detection", "comments": null, "journal-ref": "International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Spain, 2020, pp. 6844-6848", "doi": "10.1109/ICASSP40776.2020.9054760", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech transcription and speaker recognition are usually treated as\nseparate tasks even though they are interdependent. In this study, we\ninvestigate training a single network to perform both tasks jointly. We train\nthe network in a supervised multi-task learning setup, where the speech\ntranscription branch of the network is trained to minimise a phonetic\nconnectionist temporal classification (CTC) loss while the speaker recognition\nbranch of the network is trained to label the input sequence with the correct\nlabel for the speaker. We present a large-scale empirical study where the model\nis trained using several thousand hours of labelled training data for each\ntask. We evaluate the speech transcription branch of the network on a voice\ntrigger detection task while the speaker recognition branch is evaluated on a\nspeaker verification task. Results demonstrate that the network is able to\nencode both phonetic \\emph{and} speaker information in its learnt\nrepresentations while yielding accuracies at least as good as the baseline\nmodels for each task, with the same number of parameters as the independent\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:19:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sigtia", "Siddharth", ""], ["Marchi", "Erik", ""], ["Kajarekar", "Sachin", ""], ["Naik", "Devang", ""], ["Bridle", "John", ""]]}, {"id": "2001.10817", "submitter": "Soonshin Seo", "authors": "Soonshin Seo, Ji-Hwan Kim", "title": "MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding", "comments": "5 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, a self-attention mechanism has been applied for speaker embedding\nencoding. Previous studies focused on training the self-attention in a\nhigh-level layer, such as the last pooling layer. However, the effect of\nlow-level features was reduced in the speaker embedding encoding. Therefore, we\npropose masked cross self-attentive encoding (MCSAE) using ResNet. It focuses\non the features of both high-level and lowlevel layers. Based on multi-layer\naggregation, the output features of each residual layer are used for the MCSAE.\nIn the MCSAE, cross self-attention module is trained the interdependence of\neach input features. A random masking regularization module also applied to\npreventing overfitting problem. As such, the MCSAE enhances the weight of\nframes representing the speaker information. Then, the output features are\nconcatenated and encoded to the speaker embedding. Therefore, a more\ninformative speaker embedding is encoded by using the MCSAE. The experimental\nresults showed an equal error rate of 2.63% and a minimum detection cost\nfunction of 0.1453 using the VoxCeleb1 evaluation dataset. These were improved\nperformances compared with the previous self-attentive encoding and\nstate-of-the-art encoding methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:09:11 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 18:47:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 08:05:36 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 07:19:37 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Seo", "Soonshin", ""], ["Kim", "Ji-Hwan", ""]]}, {"id": "2001.10818", "submitter": "George Wynne", "authors": "George Wynne, Fran\\c{c}ois-Xavier Briol and Mark Girolami", "title": "Convergence Guarantees for Gaussian Process Means With Misspecified\n  Likelihoods and Smoothness", "comments": "Accepted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are ubiquitous in machine learning, statistics, and\napplied mathematics. They provide a flexible modelling framework for\napproximating functions, whilst simultaneously quantifying uncertainty.\nHowever, this is only true when the model is well-specified, which is often not\nthe case in practice. In this paper, we study the properties of Gaussian\nprocess means when the smoothness of the model and the likelihood function are\nmisspecified. In this setting, an important theoretical question of practial\nrelevance is how accurate the Gaussian process approximations will be given the\ndifficulty of the problem, our model and the extent of the misspecification.\nThe answer to this problem is particularly useful since it can inform our\nchoice of model and experimental design. In particular, we describe how the\nexperimental design and choice of kernel and kernel hyperparameters can be\nadapted to alleviate model misspecification.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 13:28:27 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:52:29 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 12:33:03 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Wynne", "George", ""], ["Briol", "Fran\u00e7ois-Xavier", ""], ["Girolami", "Mark", ""]]}, {"id": "2001.10820", "submitter": "Gopi Kishan", "authors": "Gopi Kishan", "title": "Reproducibility Challenge NeurIPS 2019 Report on \"Competitive Gradient\n  Descent\"", "comments": "9 Pages. arXiv admin note: substantial text overlap with 1905.12103;\n  substantial text overlap with arXiv:1905.12103 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a report for reproducibility challenge of NeurlIPS 2019 on the paper\nCompetitive Gradient Descent (Schafer et al., 2019). The paper introduces a\nnovel algorithm for the numerical computation of Nash equilibria of competitive\ntwo-player games. It avoids oscillatory and divergent behaviours seen in\nalternating gradient descent. The purpose of this report is to critically\nexamine the reproducibility of the work by (Schafer et al., 2019), within the\nframework of the NeurIPS 2019 Reproducibility Challenge. The experiments\nreplicated in this report confirms the results of the original study. Moreover,\nthis project offers a Python (Pytorch based) implementation of the proposed CGD\nalgorithm which can be found at the following public git repository:\n(https://github.com/GopiKishan14/Reproducibility_Challenge_NeurIPS_2019)\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 11:51:38 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kishan", "Gopi", ""]]}, {"id": "2001.10822", "submitter": "Pranay Dighe", "authors": "Pranay Dighe, Saurabh Adya, Nuoyu Li, Srikanth Vishnubhotla, Devang\n  Naik, Adithya Sagar, Ying Ma, Stephen Pulman, Jason Williams", "title": "Lattice-based Improvements for Voice Triggering Using Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-triggered smart assistants often rely on detection of a trigger-phrase\nbefore they start listening for the user request. Mitigation of false triggers\nis an important aspect of building a privacy-centric non-intrusive smart\nassistant. In this paper, we address the task of false trigger mitigation (FTM)\nusing a novel approach based on analyzing automatic speech recognition (ASR)\nlattices using graph neural networks (GNN). The proposed approach uses the fact\nthat decoding lattice of a falsely triggered audio exhibits uncertainties in\nterms of many alternative paths and unexpected words on the lattice arcs as\ncompared to the lattice of a correctly triggered audio. A pure trigger-phrase\ndetector model doesn't fully utilize the intent of the user speech whereas by\nusing the complete decoding lattice of user audio, we can effectively mitigate\nspeech not intended for the smart assistant. We deploy two variants of GNNs in\nthis paper based on 1) graph convolution layers and 2) self-attention mechanism\nrespectively. Our experiments demonstrate that GNNs are highly accurate in FTM\ntask by mitigating ~87% of false triggers at 99% true positive rate (TPR).\nFurthermore, the proposed models are fast to train and efficient in parameter\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:34:15 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Dighe", "Pranay", ""], ["Adya", "Saurabh", ""], ["Li", "Nuoyu", ""], ["Vishnubhotla", "Srikanth", ""], ["Naik", "Devang", ""], ["Sagar", "Adithya", ""], ["Ma", "Ying", ""], ["Pulman", "Stephen", ""], ["Williams", "Jason", ""]]}, {"id": "2001.10829", "submitter": "Georgios Papoudakis", "authors": "Georgios Papoudakis, Stefano V. Albrecht", "title": "Variational Autoencoders for Opponent Modeling in Multi-Agent Systems", "comments": "AAAI-20 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent systems exhibit complex behaviors that emanate from the\ninteractions of multiple agents in a shared environment. In this work, we are\ninterested in controlling one agent in a multi-agent system and successfully\nlearn to interact with the other agents that have fixed policies. Modeling the\nbehavior of other agents (opponents) is essential in understanding the\ninteractions of the agents in the system. By taking advantage of recent\nadvances in unsupervised learning, we propose modeling opponents using\nvariational autoencoders. Additionally, many existing methods in the literature\nassume that the opponent models have access to opponent's observations and\nactions during both training and execution. To eliminate this assumption, we\npropose a modification that attempts to identify the underlying opponent model\nusing only local information of our agent, such as its observations, actions,\nand rewards. The experiments indicate that our opponent modeling methods\nachieve equal or greater episodic returns in reinforcement learning tasks\nagainst another modeling method.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 13:38:59 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2001.10830", "submitter": "Sayantan Bhadra Mr.", "authors": "Sayantan Bhadra, Weimin Zhou, and Mark A. Anastasio", "title": "Medical image reconstruction with image-adaptive priors learned by use\n  of generative adversarial networks", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image reconstruction is typically an ill-posed inverse problem. In\norder to address such ill-posed problems, the prior distribution of the sought\nafter object property is usually incorporated by means of some\nsparsity-promoting regularization. Recently, prior distributions for images\nestimated using generative adversarial networks (GANs) have shown great promise\nin regularizing some of these image reconstruction problems. In this work, we\napply an image-adaptive GAN-based reconstruction method (IAGAN) to reconstruct\nhigh fidelity images from incomplete medical imaging data. It is observed that\nthe IAGAN method can potentially recover fine structures in the object that are\nrelevant for medical diagnosis but may be oversmoothed in reconstructions with\ntraditional sparsity-promoting regularization.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:39:47 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Bhadra", "Sayantan", ""], ["Zhou", "Weimin", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2001.10872", "submitter": "Alessio Figalli", "authors": "Oksana Berezniuk, Alessio Figalli, Raffaele Ghigliazza, Kharen\n  Musaelian", "title": "A scale-dependent notion of effective dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of \"effective dimension\" of a statistical model based\non the number of cubes of size $1/\\sqrt{n}$ needed to cover the model space\nwhen endowed with the Fisher Information Matrix as metric, $n$ being the number\nof observations. The number of observations fixes a natural scale or\nresolution. The effective dimension is then measured via the spectrum of the\nFisher Information Matrix regularized using this natural scale.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 14:48:51 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Berezniuk", "Oksana", ""], ["Figalli", "Alessio", ""], ["Ghigliazza", "Raffaele", ""], ["Musaelian", "Kharen", ""]]}, {"id": "2001.10883", "submitter": "Max Berrendorf", "authors": "Diana Davletshina, Valentyn Melnychuk, Viet Tran, Hitansh Singla, Max\n  Berrendorf, Evgeniy Faerman, Michael Fromm, and Matthias Schubert", "title": "Unsupervised Anomaly Detection for X-Ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining labels for medical (image) data requires scarce and expensive\nexperts. Moreover, due to ambiguous symptoms, single images rarely suffice to\ncorrectly diagnose a medical condition. Instead, it often requires to take\nadditional background information such as the patient's medical history or test\nresults into account. Hence, instead of focusing on uninterpretable black-box\nsystems delivering an uncertain final diagnosis in an end-to-end-fashion, we\ninvestigate how unsupervised methods trained on images without anomalies can be\nused to assist doctors in evaluating X-ray images of hands. Our method\nincreases the efficiency of making a diagnosis and reduces the risk of missing\nimportant regions. Therefore, we adopt state-of-the-art approaches for\nunsupervised learning to detect anomalies and show how the outputs of these\nmethods can be explained. To reduce the effect of noise, which often can be\nmistaken for an anomaly, we introduce a powerful preprocessing pipeline. We\nprovide an extensive evaluation of different approaches and demonstrate\nempirically that even without labels it is possible to achieve satisfying\nresults on a real-world dataset of X-ray images of hands. We also evaluate the\nimportance of preprocessing and one of our main findings is that without it,\nmost of our approaches perform not better than random. To foster\nreproducibility and accelerate research we make our code publicly available at\nhttps://github.com/Valentyn1997/xray\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 15:14:56 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 12:26:37 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Davletshina", "Diana", ""], ["Melnychuk", "Valentyn", ""], ["Tran", "Viet", ""], ["Singla", "Hitansh", ""], ["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Fromm", "Michael", ""], ["Schubert", "Matthias", ""]]}, {"id": "2001.10893", "submitter": "Peter Fenner", "authors": "Peter Fenner, Edward O. Pyzer-Knapp", "title": "Privacy-Preserving Gaussian Process Regression -- A Modular Approach to\n  the Application of Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of machine learning relies on the use of large amounts of data to train\nmodels to make predictions. When this data comes from multiple sources, for\nexample when evaluation of data against a machine learning model is offered as\na service, there can be privacy issues and legal concerns over the sharing of\ndata. Fully homomorphic encryption (FHE) allows data to be computed on whilst\nencrypted, which can provide a solution to the problem of data privacy.\nHowever, FHE is both slow and restrictive, so existing algorithms must be\nmanipulated to make them work efficiently under the FHE paradigm. Some commonly\nused machine learning algorithms, such as Gaussian process regression, are\npoorly suited to FHE and cannot be manipulated to work both efficiently and\naccurately. In this paper, we show that a modular approach, which applies FHE\nto only the sensitive steps of a workflow that need protection, allows one\nparty to make predictions on their data using a Gaussian process regression\nmodel built from another party's data, without either party gaining access to\nthe other's data, in a way which is both accurate and efficient. This\nconstruction is, to our knowledge, the first example of an effectively\nencrypted Gaussian process.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:50:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Fenner", "Peter", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "2001.10954", "submitter": "Charles Houston", "authors": "C. Houston, B. Marchand, L. Engelbert, C. D. Cantwell", "title": "Reducing complexity and unidentifiability when modelling human atrial\n  cells", "comments": "15 pages, 6 figures, submitted to Philosophical Transactions A", "journal-ref": null, "doi": "10.1098/rsta.2019.0339", "report-no": null, "categories": "q-bio.QM stat.AP stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mathematical models of a cellular action potential in cardiac modelling have\nbecome increasingly complex, particularly in gating kinetics which control the\nopening and closing of individual ion channel currents. As cardiac models\nadvance towards use in personalised medicine to inform clinical\ndecision-making, it is critical to understand the uncertainty hidden in\nparameter estimates from their calibration to experimental data. This study\napplies approximate Bayesian computation to re-calibrate the gating kinetics of\nfour ion channels in two existing human atrial cell models to their original\ndatasets, providing a measure of uncertainty and indication of potential issues\nwith selecting a single unique value given the available experimental data. Two\napproaches are investigated to reduce the uncertainty present: re-calibrating\nthe models to a more complete dataset and using a less complex formulation with\nfewer parameters to constrain. The re-calibrated models are inserted back into\nthe full cell model to study the overall effect on the action potential. The\nuse of more complete datasets does not eliminate uncertainty present in\nparameter estimates. The less complex model, particularly for the fast sodium\ncurrent, gave a better fit to experimental data alongside lower parameter\nuncertainty and improved computational speed.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:57:07 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Houston", "C.", ""], ["Marchand", "B.", ""], ["Engelbert", "L.", ""], ["Cantwell", "C. D.", ""]]}, {"id": "2001.10964", "submitter": "Arjun Punjabi", "authors": "Arjun Punjabi, Jonas Schmid, Aggelos K. Katsaggelos", "title": "Examining the Benefits of Capsule Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks are a recently developed class of neural networks that\npotentially address some of the deficiencies with traditional convolutional\nneural networks. By replacing the standard scalar activations with vectors, and\nby connecting the artificial neurons in a new way, capsule networks aim to be\nthe next great development for computer vision applications. However, in order\nto determine whether these networks truly operate differently than traditional\nnetworks, one must look at the differences in the capsule features. To this\nend, we perform several analyses with the purpose of elucidating capsule\nfeatures and determining whether they perform as described in the initial\npublication. First, we perform a deep visualization analysis to visually\ncompare capsule features and convolutional neural network features. Then, we\nlook at the ability for capsule features to encode information across the\nvector components and address what changes in the capsule architecture provides\nthe most benefit. Finally, we look at how well the capsule features are able to\nencode instantiation parameters of class objects via visual transformations.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:18:43 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Punjabi", "Arjun", ""], ["Schmid", "Jonas", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "2001.10965", "submitter": "Toni Karvonen", "authors": "Toni Karvonen, George Wynne, Filip Tronarp, Chris J. Oates, Simo\n  S\\\"arkk\\\"a", "title": "Maximum likelihood estimation and uncertainty quantification for\n  Gaussian process approximation of deterministic functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ubiquity of the Gaussian process regression model, few\ntheoretical results are available that account for the fact that parameters of\nthe covariance kernel typically need to be estimated from the dataset. This\narticle provides one of the first theoretical analyses in the context of\nGaussian process regression with a noiseless dataset. Specifically, we consider\nthe scenario where the scale parameter of a Sobolev kernel (such as a\nMat\\'{e}rn kernel) is estimated by maximum likelihood. We show that the maximum\nlikelihood estimation of the scale parameter alone provides significant\nadaptation against misspecification of the Gaussian process model in the sense\nthat the model can become \"slowly\" overconfident at worst, regardless of the\ndifference between the smoothness of the data-generating function and that\nexpected by the model. The analysis is based on a combination of techniques\nfrom nonparametric regression and scattered data interpolation. Empirical\nresults are provided in support of the theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:20:21 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 11:09:48 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 15:39:18 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Karvonen", "Toni", ""], ["Wynne", "George", ""], ["Tronarp", "Filip", ""], ["Oates", "Chris J.", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2001.10972", "submitter": "Samuele Tosatto", "authors": "Samuele Tosatto, Riad Akrour, Jan Peters", "title": "An Upper Bound of the Bias of Nadaraya-Watson Kernel Regression under\n  Lipschitz Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nadaraya-Watson kernel estimator is among the most popular nonparameteric\nregression technique thanks to its simplicity. Its asymptotic bias has been\nstudied by Rosenblatt in 1969 and has been reported in a number of related\nliterature. However, Rosenblatt's analysis is only valid for infinitesimal\nbandwidth. In contrast, we propose in this paper an upper bound of the bias\nwhich holds for finite bandwidths. Moreover, contrarily to the classic analysis\nwe allow for discontinuous first order derivative of the regression function,\nwe extend our bounds for multidimensional domains and we include the knowledge\nof the bound of the regression function when it exists and if it is known, to\nobtain a tighter bound. We believe that this work has potential applications in\nthose fields where some hard guarantees on the error are needed\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:33:58 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 09:01:12 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Tosatto", "Samuele", ""], ["Akrour", "Riad", ""], ["Peters", "Jan", ""]]}, {"id": "2001.10977", "submitter": "Xiaoli Liu", "authors": "Xiaoli Liu, Pan Hu, Zhi Mao, Po-Chih Kuo, Peiyao Li, Chao Liu, Jie Hu,\n  Deyu Li, Desen Cao, Roger G. Mark, Leo Anthony Celi, Zhengbo Zhang, Feihu\n  Zhou", "title": "Interpretable Machine Learning Model for Early Prediction of Mortality\n  in Elderly Patients with Multiple Organ Dysfunction Syndrome (MODS): a\n  Multicenter Retrospective Study and Cross Validation", "comments": "33 pages, 14 figures, 14 tables, article, Co-author: Xiaoli Liu and\n  Pan Hu, Co-correspondence: Feihu Zhou and Zhengbo Zhang", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Elderly patients with MODS have high risk of death and poor\nprognosis. The performance of current scoring systems assessing the severity of\nMODS and its mortality remains unsatisfactory. This study aims to develop an\ninterpretable and generalizable model for early mortality prediction in elderly\npatients with MODS. Methods: The MIMIC-III, eICU-CRD and PLAGH-S databases were\nemployed for model generation and evaluation. We used the eXtreme Gradient\nBoosting model with the SHapley Additive exPlanations method to conduct early\nand interpretable predictions of patients' hospital outcome. Three types of\ndata source combinations and five typical evaluation indexes were adopted to\ndevelop a generalizable model. Findings: The interpretable model, with optimal\nperformance developed by using MIMIC-III and eICU-CRD datasets, was separately\nvalidated in MIMIC-III, eICU-CRD and PLAGH-S datasets (no overlapping with\ntraining set). The performances of the model in predicting hospital mortality\nas validated by the three datasets were: AUC of 0.858, sensitivity of 0.834 and\nspecificity of 0.705; AUC of 0.849, sensitivity of 0.763 and specificity of\n0.784; and AUC of 0.838, sensitivity of 0.882 and specificity of 0.691,\nrespectively. Comparisons of AUC between this model and baseline models with\nMIMIC-III dataset validation showed superior performances of this model; In\naddition, comparisons in AUC between this model and commonly used clinical\nscores showed significantly better performance of this model. Interpretation:\nThe interpretable machine learning model developed in this study using fused\ndatasets with large sample sizes was robust and generalizable. This model\noutperformed the baseline models and several clinical scores for early\nprediction of mortality in elderly ICU patients. The interpretative nature of\nthis model provided clinicians with the ranking of mortality risk features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:15:34 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Liu", "Xiaoli", ""], ["Hu", "Pan", ""], ["Mao", "Zhi", ""], ["Kuo", "Po-Chih", ""], ["Li", "Peiyao", ""], ["Liu", "Chao", ""], ["Hu", "Jie", ""], ["Li", "Deyu", ""], ["Cao", "Desen", ""], ["Mark", "Roger G.", ""], ["Celi", "Leo Anthony", ""], ["Zhang", "Zhengbo", ""], ["Zhou", "Feihu", ""]]}, {"id": "2001.10980", "submitter": "Jing Jiang", "authors": "Jing Jiang", "title": "Multimodal Story Generation on Plural Images", "comments": "This is an undergraduate project report. Completed Dec. 2019 at the\n  Cooper Union", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:39:00 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 10:44:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jiang", "Jing", ""]]}, {"id": "2001.10995", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson", "title": "The Case for Bayesian Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key distinguishing property of a Bayesian approach is marginalization\ninstead of optimization, not the prior, or Bayes rule. Bayesian inference is\nespecially compelling for deep neural networks. (1) Neural networks are\ntypically underspecified by the data, and can represent many different but high\nperforming models corresponding to different settings of parameters, which is\nexactly when marginalization will make the biggest difference for both\ncalibration and accuracy. (2) Deep ensembles have been mistaken as competing\napproaches to Bayesian methods, but can be seen as approximate Bayesian\nmarginalization. (3) The structure of neural networks gives rise to a\nstructured prior in function space, which reflects the inductive biases of\nneural networks that help them generalize. (4) The observed correlation between\nparameters in flat regions of the loss and a diversity of solutions that\nprovide good generalization is further conducive to Bayesian marginalization,\nas flat regions occupy a large volume in a high dimensional space, and each\ndifferent solution will make a good contribution to a Bayesian model average.\n(5) Recent practical advances for Bayesian deep learning provide improvements\nin accuracy and calibration compared to standard training, while retaining\nscalability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:08:52 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Wilson", "Andrew Gordon", ""]]}, {"id": "2001.10996", "submitter": "Anders Bredahl Kock", "authors": "Anders Bredahl Kock, David Preinerstorfer, Bezirgen Veliyev", "title": "Functional Sequential Treatment Allocation with Covariates", "comments": "The material in this paper replaces the material on covariates in\n  [v5] of \"Functional Sequential Treatment Allocation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-armed bandit problem with covariates. Given a realization\nof the covariate vector, instead of targeting the treatment with highest\nconditional expectation, the decision maker targets the treatment which\nmaximizes a general functional of the conditional potential outcome\ndistribution, e.g., a conditional quantile, trimmed mean, or a socio-economic\nfunctional such as an inequality, welfare or poverty measure. We develop\nexpected regret lower bounds for this problem, and construct a near minimax\noptimal assignment policy.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:08:53 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Kock", "Anders Bredahl", ""], ["Preinerstorfer", "David", ""], ["Veliyev", "Bezirgen", ""]]}, {"id": "2001.11019", "submitter": "Andrew Titus", "authors": "Andrew Titus, Jan Silovsky, Nanxin Chen, Roger Hsiao, Mary Young and\n  Arnab Ghoshal", "title": "Improving Language Identification for Multilingual Speakers", "comments": "5 pages, 2 figures. Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language identification (LID) technologies have improved in recent\nyears from discriminating largely distinct languages to discriminating highly\nsimilar languages or even dialects of the same language. One aspect that has\nbeen mostly neglected, however, is discrimination of languages for multilingual\nspeakers, despite being a primary target audience of many systems that utilize\nLID technologies. As we show in this work, LID systems can have a high average\naccuracy for most combinations of languages while greatly underperforming for\nothers when accented speech is present. We address this by using\ncoarser-grained targets for the acoustic LID model and integrating its outputs\nwith interaction context signals in a context-aware model to tailor the system\nto each user. This combined system achieves an average 97% accuracy across all\nlanguage combinations while improving worst-case accuracy by over 60% relative\nto our baseline.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:58:11 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Titus", "Andrew", ""], ["Silovsky", "Jan", ""], ["Chen", "Nanxin", ""], ["Hsiao", "Roger", ""], ["Young", "Mary", ""], ["Ghoshal", "Arnab", ""]]}, {"id": "2001.11027", "submitter": "Volker Tresp", "authors": "Volker Tresp and Sahand Sharifzadeh and Dario Konopatzki and Yunpu Ma", "title": "The Tensor Brain: Semantic Decoding for Perception and Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse perception and memory, using mathematical models for knowledge\ngraphs and tensors, to gain insights into the corresponding functionalities of\nthe human mind. Our discussion is based on the concept of propositional\nsentences consisting of \\textit{subject-predicate-object} (SPO) triples for\nexpressing elementary facts. SPO sentences are the basis for most natural\nlanguages but might also be important for explicit perception and declarative\nmemories, as well as intra-brain communication and the ability to argue and\nreason. A set of SPO sentences can be described as a knowledge graph, which can\nbe transformed into an adjacency tensor. We introduce tensor models, where\nconcepts have dual representations as indices and associated embeddings, two\nconstructs we believe are essential for the understanding of implicit and\nexplicit perception and memory in the brain. We argue that a biological\nrealization of perception and memory imposes constraints on information\nprocessing. In particular, we propose that explicit perception and declarative\nmemories require a semantic decoder, which, in a simple realization, is based\non four layers: First, a sensory memory layer, as a buffer for sensory input,\nsecond, an index layer representing concepts, third, a memoryless\nrepresentation layer for the broadcasting of information ---the \"blackboard\",\nor the \"canvas\" of the brain--- and fourth, a working memory layer as a\nprocessing center and data buffer. We discuss the operations of the four layers\nand relate them to the global workspace theory. In a Bayesian brain\ninterpretation, semantic memory defines the prior for observable triple\nstatements. We propose that ---in evolution and during development--- semantic\nmemory, episodic memory, and natural language evolved as emergent properties in\nagents' process to gain a deeper understanding of sensory information.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 07:48:01 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:21:01 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 08:41:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tresp", "Volker", ""], ["Sharifzadeh", "Sahand", ""], ["Konopatzki", "Dario", ""], ["Ma", "Yunpu", ""]]}, {"id": "2001.11031", "submitter": "Jakob Knollm\\\"uller", "authors": "Jakob Knollm\\\"uller and Torsten En{\\ss}lin", "title": "Bayesian Reasoning with Trained Neural Networks", "comments": null, "journal-ref": "Entropy 2021, 23(6), 693", "doi": "10.3390/e23060693", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We showed how to use trained neural networks to perform Bayesian reasoning in\norder to solve tasks outside their initial scope. Deep generative models\nprovide prior knowledge, and classification/regression networks impose\nconstraints. The tasks at hand were formulated as Bayesian inference problems,\nwhich we approximately solved through variational or sampling techniques. The\napproach built on top of already trained networks, and the addressable\nquestions grew super-exponentially with the number of available networks. In\nits simplest form, the approach yielded conditional generative models. However,\nmultiple simultaneous constraints constitute elaborate questions. We compared\nthe approach to specifically trained generators, showed how to solve riddles,\nand demonstrated its compatibility with state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:00:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 18:00:05 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 09:55:29 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Knollm\u00fcller", "Jakob", ""], ["En\u00dflin", "Torsten", ""]]}, {"id": "2001.11062", "submitter": "Olivia Brown", "authors": "Stephen Mell, Olivia Brown, Justin Goodwin, Sung-Hyun Son", "title": "Safe Predictors for Enforcing Input-Output Specifications", "comments": "10 pages, 5 figures, paper accepted to the NeurIPS 2019 Workshop on\n  Machine Learning with Guarantees and the NeurIPS 2019 Workshop on Safety and\n  Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for designing correct-by-construction neural networks\n(and other machine learning models) that are guaranteed to be consistent with a\ncollection of input-output specifications before, during, and after algorithm\ntraining. Our method involves designing a constrained predictor for each set of\ncompatible constraints, and combining them safely via a convex combination of\ntheir predictions. We demonstrate our approach on synthetic datasets and an\naircraft collision avoidance problem.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:39:22 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mell", "Stephen", ""], ["Brown", "Olivia", ""], ["Goodwin", "Justin", ""], ["Son", "Sung-Hyun", ""]]}, {"id": "2001.11077", "submitter": "Pawe{\\l} Ksieniewicz", "authors": "Pawe{\\l} Ksieniewicz, Pawe{\\l} Zyblewski", "title": "stream-learn -- open-source Python library for difficult data stream\n  batch analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  stream-learn is a Python package compatible with scikit-learn and developed\nfor the drifting and imbalanced data stream analysis. Its main component is a\nstream generator, which allows to produce a synthetic data stream that may\nincorporate each of the three main concept drift types (i.e. sudden, gradual\nand incremental drift) in their recurring or non-recurring versions. The\npackage allows conducting experiments following established evaluation\nmethodologies (i.e. Test-Then-Train and Prequential). In addition, estimators\nadapted for data stream classification have been implemented, including both\nsimple classifiers and state-of-art chunk-based and online classifier\nensembles. To improve computational efficiency, package utilises its own\nimplementations of prediction metrics for imbalanced binary classification\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 20:15:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ksieniewicz", "Pawe\u0142", ""], ["Zyblewski", "Pawe\u0142", ""]]}, {"id": "2001.11101", "submitter": "Zhecheng Wang", "authors": "Zhecheng Wang, Haoyuan Li, Ram Rajagopal", "title": "Urban2Vec: Incorporating Street View Imagery and POIs for Multi-Modal\n  Urban Neighborhood Embedding", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding intrinsic patterns and predicting spatiotemporal\ncharacteristics of cities require a comprehensive representation of urban\nneighborhoods. Existing works relied on either inter- or intra-region\nconnectivities to generate neighborhood representations but failed to fully\nutilize the informative yet heterogeneous data within neighborhoods. In this\nwork, we propose Urban2Vec, an unsupervised multi-modal framework which\nincorporates both street view imagery and point-of-interest (POI) data to learn\nneighborhood embeddings. Specifically, we use a convolutional neural network to\nextract visual features from street view images while preserving geospatial\nsimilarity. Furthermore, we model each POI as a bag-of-words containing its\ncategory, rating, and review information. Analog to document embedding in\nnatural language processing, we establish the semantic similarity between\nneighborhood (\"document\") and the words from its surrounding POIs in the vector\nspace. By jointly encoding visual, textual, and geospatial information into the\nneighborhood representation, Urban2Vec can achieve performances better than\nbaseline models and comparable to fully-supervised methods in downstream\nprediction tasks. Extensive experiments on three U.S. metropolitan areas also\ndemonstrate the model interpretability, generalization capability, and its\nvalue in neighborhood similarity analysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:30:53 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Zhecheng", ""], ["Li", "Haoyuan", ""], ["Rajagopal", "Ram", ""]]}, {"id": "2001.11102", "submitter": "Yifeng Gao", "authors": "Yifeng Gao, Jessica Lin, Constantin Brif", "title": "Ensemble Grammar Induction For Detecting Anomalies in Time Series", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Time series anomaly detection is an important task, with applications in a\nbroad variety of domains. Many approaches have been proposed in recent years,\nbut often they require that the length of the anomalies be known in advance and\nprovided as an input parameter. This limits the practicality of the algorithms,\nas such information is often unknown in advance, or anomalies with different\nlengths might co-exist in the data. To address this limitation, previously, a\nlinear time anomaly detection algorithm based on grammar induction has been\nproposed. While the algorithm can find variable-length patterns, it still\nrequires preselecting values for at least two parameters at the discretization\nstep. How to choose these parameter values properly is still an open problem.\nIn this paper, we introduce a grammar-induction-based anomaly detection method\nutilizing ensemble learning. Instead of using a particular choice of parameter\nvalues for anomaly detection, the method generates the final result based on a\nset of results obtained using different parameter values. We demonstrate that\nthe proposed ensemble approach can outperform existing grammar-induction-based\napproaches with different criteria for selection of parameter values. We also\nshow that the proposed approach can achieve performance similar to that of the\nstate-of-the-art distance-based anomaly detection algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:33:03 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Gao", "Yifeng", ""], ["Lin", "Jessica", ""], ["Brif", "Constantin", ""]]}, {"id": "2001.11103", "submitter": "Wally Melnitchouk", "authors": "Yasir Alanazi, N. Sato, Tianbo Liu, W. Melnitchouk, Pawel Ambrozewicz,\n  Florian Hauenstein, Michelle P. Kuchera, Evan Pritchard, Michael Robertson,\n  Ryan Strauss, Luisa Velasco, Yaohang Li", "title": "Simulation of electron-proton scattering events by a Feature-Augmented\n  and Transformed Generative Adversarial Network (FAT-GAN)", "comments": "7 pages, 5 figures, expanded author list, paper accepted in IJCAI21", "journal-ref": null, "doi": null, "report-no": "JLAB-THY-20-3136", "categories": "hep-ph cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply generative adversarial network (GAN) technology to build an event\ngenerator that simulates particle production in electron-proton scattering that\nis free of theoretical assumptions about underlying particle dynamics. The\ndifficulty of efficiently training a GAN event simulator lies in learning the\ncomplicated patterns of the distributions of the particles physical properties.\nWe develop a GAN that selects a set of transformed features from particle\nmomenta that can be generated easily by the generator, and uses these to\nproduce a set of augmented features that improve the sensitivity of the\ndiscriminator. The new Feature-Augmented and Transformed GAN (FAT-GAN) is able\nto faithfully reproduce the distribution of final state electron momenta in\ninclusive electron scattering, without the need for input derived from\ndomain-based theoretical assumptions. The developed technology can play a\nsignificant role in boosting the science of existing and future accelerator\nfacilities, such as the Electron-Ion Collider.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:35:33 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 19:10:19 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Alanazi", "Yasir", ""], ["Sato", "N.", ""], ["Liu", "Tianbo", ""], ["Melnitchouk", "W.", ""], ["Ambrozewicz", "Pawel", ""], ["Hauenstein", "Florian", ""], ["Kuchera", "Michelle P.", ""], ["Pritchard", "Evan", ""], ["Robertson", "Michael", ""], ["Strauss", "Ryan", ""], ["Velasco", "Luisa", ""], ["Li", "Yaohang", ""]]}, {"id": "2001.11113", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Shimon Whiteson", "title": "GradientDICE: Rethinking Generalized Offline Estimation of Stationary\n  Values", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GradientDICE for estimating the density ratio between the state\ndistribution of the target policy and the sampling distribution in off-policy\nreinforcement learning. GradientDICE fixes several problems of GenDICE (Zhang\net al., 2020), the state-of-the-art for estimating such density ratios. Namely,\nthe optimization problem in GenDICE is not a convex-concave saddle-point\nproblem once nonlinearity in optimization variable parameterization is\nintroduced to ensure positivity, so any primal-dual algorithm is not guaranteed\nto converge or find the desired solution. However, such nonlinearity is\nessential to ensure the consistency of GenDICE even with a tabular\nrepresentation. This is a fundamental contradiction, resulting from GenDICE's\noriginal formulation of the optimization problem. In GradientDICE, we optimize\na different objective from GenDICE by using the Perron-Frobenius theorem and\neliminating GenDICE's use of divergence. Consequently, nonlinearity in\nparameterization is not necessary for GradientDICE, which is provably\nconvergent under linear function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 22:10:11 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 15:25:06 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 17:12:32 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 00:17:19 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2020 23:58:06 GMT"}, {"version": "v6", "created": "Fri, 31 Jul 2020 18:17:50 GMT"}, {"version": "v7", "created": "Thu, 26 Nov 2020 17:49:45 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2001.11114", "submitter": "Liang Mi", "authors": "Jos\\'e Bento and Liang Mi", "title": "Multi-Marginal Optimal Transport Defines a Generalized Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Optimal transport (OT) problem is rapidly finding its way into machine\nlearning. Favoring its use are its metric properties. Many problems admit\nsolutions that guarantee only for objects embedded in metric spaces, and the\nuse of non-metrics can complicate them. Multi-marginal OT (MMOT) generalizes OT\nto simultaneously transporting multiple distributions. It captures important\nrelations that are missed if the transport is pairwise. Research on MMOT,\nhowever, has been focused on its existence, uniqueness, practical algorithms,\nand the choice of cost functions. There is a lack of discussion on the metric\nproperties of MMOT, which limits its theoretical and practical use. Here, we\nprove that (pairwise) MMOT defines a generalized metric. We first explain the\ndifficulty of proving this via two negative results. Afterwards, we prove key\nintermediate steps and then MMOT's metric properties. Finally, we show that the\ngeneralized triangle inequality of MMOT cannot be improved.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 22:10:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:03:28 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 08:27:56 GMT"}, {"version": "v4", "created": "Mon, 29 Mar 2021 10:17:44 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Bento", "Jos\u00e9", ""], ["Mi", "Liang", ""]]}, {"id": "2001.11130", "submitter": "Max Cytrynbaum", "authors": "Max Cytrynbaum", "title": "Blocked Clusterwise Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent literature in econometrics models unobserved cross-sectional\nheterogeneity in panel data by assigning each cross-sectional unit a\none-dimensional, discrete latent type. Such models have been shown to allow\nestimation and inference by regression clustering methods. This paper is\nmotivated by the finding that the clustered heterogeneity models studied in\nthis literature can be badly misspecified, even when the panel has significant\ndiscrete cross-sectional structure. To address this issue, we generalize\nprevious approaches to discrete unobserved heterogeneity by allowing each unit\nto have multiple, imperfectly-correlated latent variables that describe its\nresponse-type to different covariates. We give inference results for a k-means\nstyle estimator of our model and develop information criteria to jointly select\nthe number clusters for each latent variable. Monte Carlo simulations confirm\nour theoretical results and give intuition about the finite-sample performance\nof estimation and model selection. We also contribute to the theory of\nclustering with an over-specified number of clusters and derive new convergence\nrates for this setting. Our results suggest that over-fitting can be severe in\nk-means style estimators when the number of clusters is over-specified.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 23:29:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Cytrynbaum", "Max", ""]]}, {"id": "2001.11137", "submitter": "Yigit Alparslan", "authors": "Yigit Alparslan, Ken Alparslan, Jeremy Keim-Shenk, Shweta Khade,\n  Rachel Greenstadt", "title": "Adversarial Attacks on Convolutional Neural Networks in Facial\n  Recognition Domain", "comments": "18 pages, 8 figures, fixed typos, replotted figures, restyled the\n  plots and tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Numerous recent studies have demonstrated how Deep Neural Network (DNN)\nclassifiers can be fooled by adversarial examples, in which an attacker adds\nperturbations to an original sample, causing the classifier to misclassify the\nsample. Adversarial attacks that render DNNs vulnerable in real life represent\na serious threat in autonomous vehicles, malware filters, or biometric\nauthentication systems. In this paper, we apply Fast Gradient Sign Method to\nintroduce perturbations to a facial image dataset and then test the output on a\ndifferent classifier that we trained ourselves, to analyze transferability of\nthis method. Next, we craft a variety of different black-box attack algorithms\non a facial image dataset assuming minimal adversarial knowledge, to further\nassess the robustness of DNNs in facial recognition. While experimenting with\ndifferent image distortion techniques, we focus on modifying single optimal\npixels by a large amount, or modifying all pixels by a smaller amount, or\ncombining these two attack approaches. While our single-pixel attacks achieved\nabout a 15% average decrease in classifier confidence level for the actual\nclass, the all-pixel attacks were more successful and achieved up to an 84%\naverage decrease in confidence, along with an 81.6% misclassification rate, in\nthe case of the attack that we tested with the highest levels of perturbation.\nEven with these high levels of perturbation, the face images remained\nidentifiable to a human. Understanding how these noised and perturbed images\nbaffle the classification algorithms can yield valuable advances in the\ntraining of DNNs against defense-aware adversarial attacks, as well as adaptive\nnoise reduction techniques. We hope our research may help to advance the study\nof adversarial attacks on DNNs and defensive mechanisms to counteract them,\nparticularly in the facial recognition domain.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:25:05 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:19:12 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 07:43:45 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Alparslan", "Yigit", ""], ["Alparslan", "Ken", ""], ["Keim-Shenk", "Jeremy", ""], ["Khade", "Shweta", ""], ["Greenstadt", "Rachel", ""]]}, {"id": "2001.11143", "submitter": "Hongjing Zhang", "authors": "Hongjing Zhang, S. S. Ravi, Ian Davidson", "title": "A Graph-Based Approach for Active Learning in Regression", "comments": "SDM 2020 camera-ready. 9 pages, 4 figures, links to supplementary\n  material available at\n  https://sdm2020.s3-us-west-1.amazonaws.com/supplementary.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to reduce labeling efforts by selectively asking humans\nto annotate the most important data points from an unlabeled pool and is an\nexample of human-machine interaction. Though active learning has been\nextensively researched for classification and ranking problems, it is\nrelatively understudied for regression problems. Most existing active learning\nfor regression methods use the regression function learned at each active\nlearning iteration to select the next informative point to query. This\nintroduces several challenges such as handling noisy labels, parameter\nuncertainty and overcoming initially biased training data. Instead, we propose\na feature-focused approach that formulates both sequential and batch-mode\nactive regression as a novel bipartite graph optimization problem. We conduct\nexperiments on both noise-free and noisy settings. Our experimental results on\nbenchmark data sets demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:59:43 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Zhang", "Hongjing", ""], ["Ravi", "S. S.", ""], ["Davidson", "Ian", ""]]}, {"id": "2001.11154", "submitter": "Siwei Feng", "authors": "Siwei Feng and Han Yu", "title": "Multi-Participant Multi-Class Vertical Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a privacy-preserving paradigm for training\ncollective machine learning models with locally stored data from multiple\nparticipants. Vertical federated learning (VFL) deals with the case where\nparticipants sharing the same sample ID space but having different feature\nspaces, while label information is owned by one participant. Current studies of\nVFL only support two participants, and mostly focus on binaryclass logistic\nregression problems. In this paper, we propose the Multi-participant\nMulti-class Vertical Federated Learning (MMVFL) framework for multi-class VFL\nproblems involving multiple parties. Extending the idea of multi-view learning\n(MVL), MMVFL enables label sharing from its owner to other VFL participants in\na privacypreserving manner. To demonstrate the effectiveness of MMVFL, a\nfeature selection scheme is incorporated into MMVFL to compare its performance\nagainst supervised feature selection and MVL-based approaches. Experiment\nresults on real-world datasets show that MMVFL can effectively share label\ninformation among multiple VFL participants and match multi-class\nclassification performance of existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 02:39:50 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Feng", "Siwei", ""], ["Yu", "Han", ""]]}, {"id": "2001.11158", "submitter": "Tien Dung Nguyen", "authors": "Tien-Dung Nguyen, Tomasz Maszczyk, Katarzyna Musial, Marc-Andre\n  Z\\\"oller, Bogdan Gabrys", "title": "AVATAR -- Machine Learning Pipeline Evaluation Using Surrogate Model", "comments": "The Eighteenth International Symposium on Intelligent Data Analysis,\n  IDA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of machine learning (ML) pipelines is essential during\nautomatic ML pipeline composition and optimisation. The previous methods such\nas Bayesian-based and genetic-based optimisation, which are implemented in\nAuto-Weka, Auto-sklearn and TPOT, evaluate pipelines by executing them.\nTherefore, the pipeline composition and optimisation of these methods requires\na tremendous amount of time that prevents them from exploring complex pipelines\nto find better predictive models. To further explore this research challenge,\nwe have conducted experiments showing that many of the generated pipelines are\ninvalid, and it is unnecessary to execute them to find out whether they are\ngood pipelines. To address this issue, we propose a novel method to evaluate\nthe validity of ML pipelines using a surrogate model (AVATAR). The AVATAR\nenables to accelerate automatic ML pipeline composition and optimisation by\nquickly ignoring invalid pipelines. Our experiments show that the AVATAR is\nmore efficient in evaluating complex pipelines in comparison with the\ntraditional evaluation approaches requiring their execution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 02:53:29 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 01:00:59 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Nguyen", "Tien-Dung", ""], ["Maszczyk", "Tomasz", ""], ["Musial", "Katarzyna", ""], ["Z\u00f6ller", "Marc-Andre", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2001.11168", "submitter": "Ryoya Yamasaki", "authors": "Ryoya Yamasaki, Toshiyuki Tanaka", "title": "Kernel Selection for Modal Linear Regression: Optimal Kernel and IRLS\n  Algorithm", "comments": "7 pages, 4 figures, published in the proceedings of the 18th IEEE\n  International Conference on Machine Learning and Applications - ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modal linear regression (MLR) is a method for obtaining a conditional mode\npredictor as a linear model. We study kernel selection for MLR from two\nperspectives: \"which kernel achieves smaller error?\" and \"which kernel is\ncomputationally efficient?\". First, we show that a Biweight kernel is optimal\nin the sense of minimizing an asymptotic mean squared error of a resulting MLR\nparameter. This result is derived from our refined analysis of an asymptotic\nstatistical behavior of MLR. Secondly, we provide a kernel class for which\niteratively reweighted least-squares algorithm (IRLS) is guaranteed to\nconverge, and especially prove that IRLS with an Epanechnikov kernel terminates\nin a finite number of iterations. Simulation studies empirically verified that\nusing a Biweight kernel provides good estimation accuracy and that using an\nEpanechnikov kernel is computationally efficient. Our results improve MLR of\nwhich existing studies often stick to a Gaussian kernel and modal EM algorithm\nspecialized for it, by providing guidelines of kernel selection.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:57:07 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Yamasaki", "Ryoya", ""], ["Tanaka", "Toshiyuki", ""]]}, {"id": "2001.11177", "submitter": "Fatemeh Amini", "authors": "Fatemeh Amini and Guiping Hu", "title": "A Hybrid Two-layer Feature Selection Method Using GeneticAlgorithm and\n  Elastic Net", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2020.114072", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection, as a critical pre-processing step for machine learning,\naims at determining representative predictors from a high-dimensional feature\nspace dataset to improve the prediction accuracy. However, the increase in\nfeature space dimensionality, comparing to the number of observations, poses a\nsevere challenge to many existing feature selection methods with respect to\ncomputational efficiency and prediction performance. This paper presents a new\nhybrid two-layer feature selection approach that combines a wrapper and an\nembedded method in constructing an appropriate subset of predictors. In the\nfirst layer of the proposed method, the Genetic Algorithm(GA) has been adopted\nas a wrapper to search for the optimal subset of predictors, which aims to\nreduce the number of predictors and the prediction error. As one of the\nmeta-heuristic approaches, GA is selected due to its computational efficiency;\nhowever, GAs do not guarantee the optimality. To address this issue, a second\nlayer is added to the proposed method to eliminate any remaining\nredundant/irrelevant predictors to improve the prediction accuracy. Elastic\nNet(EN) has been selected as the embedded method in the second layer because of\nits flexibility in adjusting the penalty terms in regularization process and\ntime efficiency. This hybrid two-layer approach has been applied on a Maize\ngenetic dataset from NAM population, which consists of multiple subsets of\ndatasets with different ratio of the number of predictors to the number of\nobservations. The numerical results confirm the superiority of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 05:01:30 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Amini", "Fatemeh", ""], ["Hu", "Guiping", ""]]}, {"id": "2001.11201", "submitter": "Vrettos Moulos", "authors": "Vrettos Moulos", "title": "Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence\n  Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian\n  Rewards", "comments": "31 pages, simulation results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of the classic stochastic multi-armed bandit problem\nwhich involves multiple plays and Markovian rewards in the rested bandits\nsetting. In order to tackle this problem we consider an adaptive allocation\nrule which at each stage combines the information from the sample means of all\nthe arms, with the Kullback-Leibler upper confidence bound of a single arm\nwhich is selected in round-robin way. For rewards generated from a\none-parameter exponential family of Markov chains, we provide a finite-time\nupper bound for the regret incurred from this adaptive allocation rule, which\nreveals the logarithmic dependence of the regret on the time horizon, and which\nis asymptotically optimal. For our analysis we devise several concentration\nresults for Markov chains, including a maximal inequality for Markov chains,\nthat may be of interest in their own right. As a byproduct of our analysis we\nalso establish asymptotically optimal, finite-time guarantees for the case of\nmultiple plays, and i.i.d. rewards drawn from a one-parameter exponential\nfamily of probability densities. Additionally, we provide simulation results\nthat illustrate that calculating Kullback-Leibler upper confidence bounds in a\nround-robin way, is significantly more efficient than calculating them for\nevery arm at each round, and that the expected regrets of those two approaches\nbehave similarly.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:09:01 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:28:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Moulos", "Vrettos", ""]]}, {"id": "2001.11212", "submitter": "Benjamin Regler", "authors": "Benjamin Regler, Matthias Scheffler, Luca M. Ghiringhelli", "title": "TCMI: a non-parametric mutual-dependence estimator for multivariate\n  continuous distributions", "comments": "36 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of relevant features, i.e., the driving variables that\ndetermine a process or the property of a system, is an essential part of the\nanalysis of data sets whose entries are described by a large number of\nvariables. The preferred measure for quantifying the relevance of nonlinear\nstatistical dependencies is mutual information, which requires as input\nprobability distributions. Probability distributions cannot be reliably sampled\nand estimated from limited data, especially for real-valued data samples such\nas lengths or energies. Here, we introduce total cumulative mutual information\n(TCMI), a measure of the relevance of mutual dependencies based on cumulative\nprobability distributions. TCMI can be estimated directly from sample data and\nis a non-parametric, robust and deterministic measure that facilitates\ncomparisons and rankings between feature sets with different cardinality. The\nranking induced by TCMI allows for feature selection, i.e., the identification\nof the set of relevant features that are statistical related to the process or\nthe property of a system, while taking into account the number of data samples\nas well as the cardinality of the feature subsets. We evaluate the performance\nof our measure with simulated data, compare its performance with similar\nmultivariate dependence measures, and demonstrate the effectiveness of our\nfeature selection method on a set of standard data sets and a typical scenario\nin materials science.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:42:25 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Regler", "Benjamin", ""], ["Scheffler", "Matthias", ""], ["Ghiringhelli", "Luca M.", ""]]}, {"id": "2001.11216", "submitter": "Xinjiang Wang", "authors": "Sheng Zhou, Xinjiang Wang, Ping Luo, Litong Feng, Wenjie Li, Wei Zhang", "title": "How Does BN Increase Collapsed Neural Network Filters?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving sparsity of deep neural networks (DNNs) is essential for network\ncompression and has drawn much attention. In this work, we disclose a harmful\nsparsifying process called filter collapse, which is common in DNNs with batch\nnormalization (BN) and rectified linear activation functions (e.g. ReLU, Leaky\nReLU). It occurs even without explicit sparsity-inducing regularizations such\nas $L_1$. This phenomenon is caused by the normalization effect of BN, which\ninduces a non-trainable region in the parameter space and reduces the network\ncapacity as a result. This phenomenon becomes more prominent when the network\nis trained with large learning rates (LR) or adaptive LR schedulers, and when\nthe network is finetuned. We analytically prove that the parameters of BN tend\nto become sparser during SGD updates with high gradient noise and that the\nsparsifying probability is proportional to the square of learning rate and\ninversely proportional to the square of the scale parameter of BN. To prevent\nthe undesirable collapsed filters, we propose a simple yet effective approach\nnamed post-shifted BN (psBN), which has the same representation ability as BN\nwhile being able to automatically make BN parameters trainable again as they\nsaturate during training. With psBN, we can recover collapsed filters and\nincrease the model performance in various tasks such as classification on\nCIFAR-10 and object detection on MS-COCO2017.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 09:00:08 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 01:31:33 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhou", "Sheng", ""], ["Wang", "Xinjiang", ""], ["Luo", "Ping", ""], ["Feng", "Litong", ""], ["Li", "Wenjie", ""], ["Zhang", "Wei", ""]]}, {"id": "2001.11231", "submitter": "Szilard Aradi", "authors": "Szil\\'ard Aradi", "title": "Survey of Deep Reinforcement Learning for Motion Planning of Autonomous\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic research in the field of autonomous vehicles has reached high\npopularity in recent years related to several topics as sensor technologies,\nV2X communications, safety, security, decision making, control, and even legal\nand standardization rules. Besides classic control design approaches,\nArtificial Intelligence and Machine Learning methods are present in almost all\nof these fields. Another part of research focuses on different layers of Motion\nPlanning, such as strategic decisions, trajectory planning, and control. A wide\nrange of techniques in Machine Learning itself have been developed, and this\narticle describes one of these fields, Deep Reinforcement Learning (DRL). The\npaper provides insight into the hierarchical motion planning problem and\ndescribes the basics of DRL. The main elements of designing such a system are\nthe modeling of the environment, the modeling abstractions, the description of\nthe state and the perception models, the appropriate rewarding, and the\nrealization of the underlying neural network. The paper describes vehicle\nmodels, simulation possibilities and computational requirements. Strategic\ndecisions on different layers and the observation models, e.g., continuous and\ndiscrete state representations, grid-based, and camera-based solutions are\npresented. The paper surveys the state-of-art solutions systematized by the\ndifferent tasks and levels of autonomous driving, such as car-following,\nlane-keeping, trajectory following, merging, or driving in dense traffic.\nFinally, open questions and future challenges are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 09:47:22 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Aradi", "Szil\u00e1rd", ""]]}, {"id": "2001.11235", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Taco S. Cohen, Jakub M. Tomczak", "title": "Learning Discrete Distributions by Dequantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Media is generally stored digitally and is therefore discrete. Many\nsuccessful deep distribution models in deep learning learn a density, i.e., the\ndistribution of a continuous random variable. Na\\\"ive optimization on discrete\ndata leads to arbitrarily high likelihoods, and instead, it has become standard\npractice to add noise to datapoints. In this paper, we present a general\nframework for dequantization that captures existing methods as a special case.\nWe derive two new dequantization objectives: importance-weighted (iw)\ndequantization and R\\'enyi dequantization. In addition, we introduce\nautoregressive dequantization (ARD) for more flexible dequantization\ndistributions. Empirically we find that iw and R\\'enyi dequantization\nconsiderably improve performance for uniform dequantization distributions. ARD\nachieves a negative log-likelihood of 3.06 bits per dimension on CIFAR10, which\nto the best of our knowledge is state-of-the-art among distribution models that\ndo not require autoregressive inverses for sampling.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 10:00:08 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Cohen", "Taco S.", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "2001.11242", "submitter": "Tuomo Alasalmi", "authors": "Tuomo Alasalmi, Jaakko Suutala, Heli Koskim\\\"aki and Juha R\\\"oning", "title": "Better Multi-class Probability Estimates for Small Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classification applications require accurate probability estimates in\naddition to good class separation but often classifiers are designed focusing\nonly on the latter. Calibration is the process of improving probability\nestimates by post-processing but commonly used calibration algorithms work\npoorly on small data sets and assume the classification task to be binary. Both\nof these restrictions limit their real-world applicability. Previously\nintroduced Data Generation and Grouping algorithm alleviates the problem posed\nby small data sets and in this article, we will demonstrate that its\napplication to multi-class problems is also possible which solves the other\nlimitation. Our experiments show that calibration error can be decreased using\nthe proposed approach and the additional computational cost is acceptable.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 10:21:26 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Alasalmi", "Tuomo", ""], ["Suutala", "Jaakko", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "2001.11247", "submitter": "Thomas Deschatre", "authors": "Thomas Deschatre and Joseph Mikael", "title": "Deep combinatorial optimisation for optimal stopping time problems :\n  application to swing options pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for stochastic control based on neural networks and using\nrandomisation of discrete random variables is proposed and applied to optimal\nstopping time problems. The method models directly the policy and does not need\nthe derivation of a dynamic programming principle nor a backward stochastic\ndifferential equation. Unlike continuous optimization where automatic\ndifferentiation is used directly, we propose a likelihood ratio method for\ngradient computation. Numerical tests are done on the pricing of American and\nswing options. The proposed algorithm succeeds in pricing high dimensional\nAmerican and swing options in a reasonable computation time, which is not\npossible with classical algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 10:39:20 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 14:55:16 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Deschatre", "Thomas", ""], ["Mikael", "Joseph", ""]]}, {"id": "2001.11256", "submitter": "Tsuyoshi Ishizone", "authors": "Tsuyoshi Ishizone and Kazuyuki Nakamura", "title": "Real-time Linear Operator Construction and State Estimation with the\n  Kalman Filter", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kalman filter is the most powerful tool for estimation of the states of a\nlinear Gaussian system. In addition, using this method, an expectation\nmaximization algorithm can be used to estimate the parameters of the model.\nHowever, this algorithm cannot function in real time. Thus, we propose a new\nmethod that can be used to estimate the transition matrices and the states of\nthe system in real time. The proposed method uses three ideas: estimation in an\nobservation space, a time-invariant interval, and an online learning framework.\nApplied to damped oscillation model, we have obtained extraordinary performance\nto estimate the matrices. In addition, by introducing localization and spatial\nuniformity to the proposed method, we have demonstrated that noise can be\nreduced in high-dimensional spatio-temporal data. Moreover, the proposed method\nhas potential for use in areas such as weather forecasting and vector field\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:16:16 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 06:44:45 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 03:04:27 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ishizone", "Tsuyoshi", ""], ["Nakamura", "Kazuyuki", ""]]}, {"id": "2001.11261", "submitter": "Mischa Schmidt", "authors": "Mischa Schmidt, Julia Gastinger, S\\'ebastien Nicolas, Anett Sch\\\"ulke\n  (NEC Laboratories Europe GmbH)", "title": "HAMLET -- A Learning Curve-Enabled Multi-Armed Bandit for Algorithm\n  Selection", "comments": "8 pages, 8 figures; IJCNN 2020: International Joint Conference on\n  Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated algorithm selection and hyperparameter tuning facilitates the\napplication of machine learning. Traditional multi-armed bandit strategies look\nto the history of observed rewards to identify the most promising arms for\noptimizing expected total reward in the long run. When considering limited time\nbudgets and computational resources, this backward view of rewards is\ninappropriate as the bandit should look into the future for anticipating the\nhighest final reward at the end of a specified time budget. This work addresses\nthat insight by introducing HAMLET, which extends the bandit approach with\nlearning curve extrapolation and computation time-awareness for selecting among\na set of machine learning algorithms. Results show that the HAMLET Variants 1-3\nexhibit equal or better performance than other bandit-based algorithm selection\nstrategies in experiments with recorded hyperparameter tuning traces for the\nmajority of considered time budgets. The best performing HAMLET Variant 3\ncombines learning curve extrapolation with the well-known upper confidence\nbound exploration bonus. That variant performs better than all non-HAMLET\npolicies with statistical significance at the 95% level for 1,485 runs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:28:39 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 08:37:16 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 06:56:35 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Schmidt", "Mischa", "", "NEC Laboratories Europe GmbH"], ["Gastinger", "Julia", "", "NEC Laboratories Europe GmbH"], ["Nicolas", "S\u00e9bastien", "", "NEC Laboratories Europe GmbH"], ["Sch\u00fclke", "Anett", "", "NEC Laboratories Europe GmbH"]]}, {"id": "2001.11267", "submitter": "Ehsan Yaghoubi", "authors": "Ehsan Yaghoubi, Diana Borza, Aruna Kumar, Hugo Proen\\c{c}a", "title": "Person Re-identification: Implicitly Defining the Receptive Fields of\n  Deep Learning Classification Frameworks", "comments": "Submitted to PRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{receptive fields} of deep learning classification models determine\nthe regions of the input data that have the most significance for providing\ncorrect decisions. The primary way to learn such receptive fields is to train\nthe models upon masked data, which helps the networks to ignore any unwanted\nregions, but has two major drawbacks: 1) it often yields edge-sensitive\ndecision processes; and 2) augments the computational cost of the inference\nphase considerably. This paper describes a solution for implicitly driving the\ninference of the networks' receptive fields, by creating synthetic learning\ndata composed of interchanged segments that should be \\emph{apriori}\nimportant/irrelevant for the network decision. In practice, we use a\nsegmentation module to distinguish between the foreground\n(important)/background (irrelevant) parts of each learning instance, and\nrandomly swap segments between image pairs, while keeping the class label\nexclusively consistent with the label of the deemed important segments. This\nstrategy typically drives the networks to early convergence and appropriate\nsolutions, where the identity and clutter descriptions are not correlated.\nMoreover, this data augmentation solution has various interesting properties:\n1) it is parameter-free; 2) it fully preserves the label information; and, 3)\nit is compatible with the typical data augmentation techniques. In the\nempirical validation, we considered the person re-identification problem and\nevaluated the effectiveness of the proposed solution in the well-known\n\\emph{Richly Annotated Pedestrian} (RAP) dataset for two different settings\n(\\emph{upper-body} and \\emph{full-body}), observing highly competitive results\nover the state-of-the-art. Under a reproducible research paradigm, both the\ncode and the empirical evaluation protocol are available at\n\\url{https://github.com/Ehsan-Yaghoubi/reid-strong-baseline}.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:45:44 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 12:38:49 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 18:38:32 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 19:59:52 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Yaghoubi", "Ehsan", ""], ["Borza", "Diana", ""], ["Kumar", "Aruna", ""], ["Proen\u00e7a", "Hugo", ""]]}, {"id": "2001.11279", "submitter": "Victor-Alexandru Darvariu", "authors": "Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi", "title": "Improving the Robustness of Graphs through Reinforcement Learning and\n  Graph Neural Networks", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs can be used to represent and reason about real world systems and a\nvariety of metrics have been devised to quantify their global characteristics.\nAn important property is robustness to failures and attacks, which is relevant\nfor the infrastructure and communication networks that power modern society.\nPrior work on making topological modifications to a graph, e.g., adding edges,\nin order to increase robustness is typically based on local and spectral\nproperties or a shallow search since robustness is expensive to compute\ndirectly. However, such strategies are necessarily suboptimal.\n  In this work, we present RNet-DQN, an approach for constructing networks that\nuses Reinforcement Learning to address improving the robustness of graphs to\nrandom and targeted removals of nodes. In particular, the approach relies on\nchanges in the estimated robustness as a reward signal and Graph Neural\nNetworks for representing states. Experiments on synthetic and real-world\ngraphs show that this approach can deliver performance superior to existing\nmethods while being much cheaper to evaluate and generalizing to out-of-sample\ngraphs, as well as to larger out-of-distribution graphs in some cases. The\napproach is readily applicable to optimizing other global structural properties\nof graphs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:11:45 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 20:38:53 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 10:24:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Darvariu", "Victor-Alexandru", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2001.11297", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato, Nasrullah Sheikh, Alberto Montresor", "title": "Which way? Direction-Aware Attributed Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding algorithms are used to efficiently represent (encode) a graph\nin a low-dimensional continuous vector space that preserves the most important\nproperties of the graph. One aspect that is often overlooked is whether the\ngraph is directed or not. Most studies ignore the directionality, so as to\nlearn high-quality representations optimized for node classification. On the\nother hand, studies that capture directionality are usually effective on link\nprediction but do not perform well on other tasks. This preliminary study\npresents a novel text-enriched, direction-aware algorithm called DIAGRAM ,\nbased on a carefully designed multi-objective model to learn embeddings that\npreserve the direction of edges, textual features and graph context of nodes.\nAs a result, our algorithm does not have to trade one property for another and\njointly learns high-quality representations for multiple network analysis\ntasks. We empirically show that DIAGRAM significantly outperforms six\nstate-of-the-art baselines, both direction-aware and oblivious ones,on link\nprediction and network reconstruction experiments using two popular datasets.\nIt also achieves a comparable performance on node classification experiments\nagainst these baselines using the same datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:08:19 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Sheikh", "Nasrullah", ""], ["Montresor", "Alberto", ""]]}, {"id": "2001.11316", "submitter": "Akbar Karimi", "authors": "Akbar Karimi, Leonardo Rossi, Andrea Prati", "title": "Adversarial Training for Aspect-Based Sentiment Analysis with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of\nsentiments and their targets. Collecting labeled data for this task in order to\nhelp neural networks generalize better can be laborious and time-consuming. As\nan alternative, similar data to the real-world examples can be produced\nartificially through an adversarial process which is carried out in the\nembedding space. Although these examples are not real sentences, they have been\nshown to act as a regularization method which can make neural networks more\nrobust. In this work, we apply adversarial training, which was put forward by\nGoodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model\nproposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and\nAspect Sentiment Classification in sentiment analysis. After improving the\nresults of post-trained BERT by an ablation study, we propose a novel\narchitecture called BERT Adversarial Training (BAT) to utilize adversarial\ntraining in ABSA. The proposed model outperforms post-trained BERT in both\ntasks. To the best of our knowledge, this is the first study on the application\nof adversarial training in ABSA.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:53:58 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 12:33:57 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:39:32 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 07:39:17 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Karimi", "Akbar", ""], ["Rossi", "Leonardo", ""], ["Prati", "Andrea", ""]]}, {"id": "2001.11342", "submitter": "Xiaoran Cai", "authors": "Xiaoran Cai, Xiaopeng Mo, Junyang Chen, and Jie Xu", "title": "D2D-Enabled Data Sharing for Distributed Machine Learning at Wireless\n  Network Edge", "comments": "Submit to IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge learning is an emerging technique that enables distributed edge\ndevices to collaborate in training shared machine learning models by exploiting\ntheir local data samples and communication and computation resources. To deal\nwith the straggler dilemma issue faced in this technique, this paper proposes a\nnew device to device enabled data sharing approach, in which different edge\ndevices share their data samples among each other over communication links, in\norder to properly adjust their computation loads for increasing the training\nspeed. Under this setup, we optimize the radio resource allocation for both\ndata sharing and distributed training, with the objective of minimizing the\ntotal training delay under fixed numbers of local and global iterations.\nNumerical results show that the proposed data sharing design significantly\nreduces the training delay, and also enhances the training accuracy when the\ndata samples are non independent and identically distributed among edge\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 01:49:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Cai", "Xiaoran", ""], ["Mo", "Xiaopeng", ""], ["Chen", "Junyang", ""], ["Xu", "Jie", ""]]}, {"id": "2001.11349", "submitter": "Ioannis Papantonis", "authors": "Ioannis Papantonis, Vaishak Belle", "title": "On Constraint Definability in Tractable Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating constraints is a major concern in probabilistic machine\nlearning. A wide variety of problems require predictions to be integrated with\nreasoning about constraints, from modelling routes on maps to approving loan\npredictions. In the former, we may require the prediction model to respect the\npresence of physical paths between the nodes on the map, and in the latter, we\nmay require that the prediction model respect fairness constraints that ensure\nthat outcomes are not subject to bias. Broadly speaking, constraints may be\nprobabilistic, logical or causal, but the overarching challenge is to determine\nif and how a model can be learnt that handles all the declared constraints. To\nthe best of our knowledge, this is largely an open problem. In this paper, we\nconsider a mathematical inquiry on how the learning of tractable probabilistic\nmodels, such as sum-product networks, is possible while incorporating\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:05:56 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Papantonis", "Ioannis", ""], ["Belle", "Vaishak", ""]]}, {"id": "2001.11355", "submitter": "Jia Guo", "authors": "Jia Guo and Chenyang Yang", "title": "Constructing Deep Neural Networks with a Priori Knowledge of Wireless\n  Tasks", "comments": "30 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1910.13728", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been employed for designing wireless systems\nin many aspects, say transceiver design, resource optimization, and information\nprediction. Existing works either use the fully-connected DNN or the DNNs with\nparticular architectures developed in other domains. While generating labels\nfor supervised learning and gathering training samples are time-consuming or\ncost-prohibitive, how to develop DNNs with wireless priors for reducing\ntraining complexity remains open. In this paper, we show that two kinds of\npermutation invariant properties widely existed in wireless tasks can be\nharnessed to reduce the number of model parameters and hence the sample and\ncomputational complexity for training. We find special architecture of DNNs\nwhose input-output relationships satisfy the properties, called permutation\ninvariant DNN (PINN), and augment the data with the properties. By learning the\nimpact of the scale of a wireless system, the size of the constructed PINNs can\nflexibly adapt to the input data dimension. We take predictive resource\nallocation and interference coordination as examples to show how the PINNs can\nbe employed for learning the optimal policy with unsupervised and supervised\nlearning. Simulations results demonstrate a dramatic gain of the proposed PINNs\nin terms of reducing training complexity.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:54:42 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Guo", "Jia", ""], ["Yang", "Chenyang", ""]]}, {"id": "2001.11359", "submitter": "Xiaodong Yang", "authors": "Yiqiang Chen, Xiaodong Yang, Xin Qin, Han Yu, Biao Chen, Zhiqi Shen", "title": "FOCUS: Dealing with Label Quality Disparity in Federated Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous systems with End-Edge-Cloud architecture are increasingly being\nused in healthcare applications. Federated Learning (FL) is highly useful for\nsuch applications, due to silo effect and privacy preserving. Existing FL\napproaches generally do not account for disparities in the quality of local\ndata labels. However, the clients in ubiquitous systems tend to suffer from\nlabel noise due to varying skill-levels, biases or malicious tampering of the\nannotators. In this paper, we propose Federated Opportunistic Computing for\nUbiquitous Systems (FOCUS) to address this challenge. It maintains a small set\nof benchmark samples on the FL server and quantifies the credibility of the\nclient local data without directly observing them by computing the mutual\ncross-entropy between performance of the FL model on the local datasets and\nthat of the client local FL model on the benchmark dataset. Then, a credit\nweighted orchestration is performed to adjust the weight assigned to clients in\nthe FL model based on their credibility values. FOCUS has been experimentally\nevaluated on both synthetic data and real-world data. The results show that it\neffectively identifies clients with noisy labels and reduces their impact on\nthe model performance, thereby significantly outperforming existing FL\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:31:01 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Chen", "Yiqiang", ""], ["Yang", "Xiaodong", ""], ["Qin", "Xin", ""], ["Yu", "Han", ""], ["Chen", "Biao", ""], ["Shen", "Zhiqi", ""]]}, {"id": "2001.11363", "submitter": "Rahul Duggal", "authors": "Rahul Duggal, Scott Freitas, Cao Xiao, Duen Horng Chau, Jimeng Sun", "title": "REST: Robust and Efficient Neural Networks for Sleep Monitoring in the\n  Wild", "comments": "Accepted to WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380241", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant attention has been devoted towards integrating\ndeep learning technologies in the healthcare domain. However, to safely and\npractically deploy deep learning models for home health monitoring, two\nsignificant challenges must be addressed: the models should be (1) robust\nagainst noise; and (2) compact and energy-efficient. We propose REST, a new\nmethod that simultaneously tackles both issues via 1) adversarial training and\ncontrolling the Lipschitz constant of the neural network through spectral\nregularization while 2) enabling neural network compression through sparsity\nregularization. We demonstrate that REST produces highly-robust and efficient\nmodels that substantially outperform the original full-sized models in the\npresence of noise. For the sleep staging task over single-channel\nelectroencephalogram (EEG), the REST model achieves a macro-F1 score of 0.67\nvs. 0.39 achieved by a state-of-the-art model in the presence of Gaussian noise\nwhile obtaining 19x parameter reduction and 15x MFLOPS reduction on two large,\nreal-world EEG datasets. By deploying these models to an Android application on\na smartphone, we quantitatively observe that REST allows models to achieve up\nto 17x energy reduction and 9x faster inference. We open-source the code\nrepository with this paper: https://github.com/duggalrahul/REST.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:23:16 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Duggal", "Rahul", ""], ["Freitas", "Scott", ""], ["Xiao", "Cao", ""], ["Chau", "Duen Horng", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.11366", "submitter": "Anna Bosman", "authors": "Mamuku Mokuwe, Michael Burke, Anna Sergeevna Bosman", "title": "Black-Box Saliency Map Generation Using Bayesian Optimisation", "comments": "Submitted to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency maps are often used in computer vision to provide intuitive\ninterpretations of what input regions a model has used to produce a specific\nprediction. A number of approaches to saliency map generation are available,\nbut most require access to model parameters. This work proposes an approach for\nsaliency map generation for black-box models, where no access to model\nparameters is available, using a Bayesian optimisation sampling method. The\napproach aims to find the global salient image region responsible for a\nparticular (black-box) model's prediction. This is achieved by a sampling-based\napproach to model perturbations that seeks to localise salient regions of an\nimage to the black-box model. Results show that the proposed approach to\nsaliency map generation outperforms grid-based perturbation approaches, and\nperforms similarly to gradient-based approaches which require access to model\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 14:39:12 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mokuwe", "Mamuku", ""], ["Burke", "Michael", ""], ["Bosman", "Anna Sergeevna", ""]]}, {"id": "2001.11396", "submitter": "Matthew Willetts", "authors": "Miguel Morin, Matthew Willetts", "title": "Non-Determinism in TensorFlow ResNets", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the stochasticity in training ResNets for image classification\non GPUs in TensorFlow is dominated by the non-determinism from GPUs, rather\nthan by the initialisation of the weights and biases of the network or by the\nsequence of minibatches given. The standard deviation of test set accuracy is\n0.02 with fixed seeds, compared to 0.027 with different seeds---nearly 74\\% of\nthe standard deviation of a ResNet model is non-deterministic. For test set\nloss the ratio of standard deviations is more than 80\\%. These results call for\nmore robust evaluation strategies of deep learning models, as a significant\namount of the variation in results across runs can arise simply from GPU\nrandomness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:29:13 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Morin", "Miguel", ""], ["Willetts", "Matthew", ""]]}, {"id": "2001.11399", "submitter": "Bojan Kostic", "authors": "Bojan Kostic, Romain Crastes dit Sourd, Stephane Hess, Joachim\n  Scheiner, Christian Holz-Rau, Francisco C. Pereira", "title": "Uncovering life-course patterns with causal discovery and survival\n  analysis", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel approach and an exploratory study for modelling life event\nchoices and occurrence from a probabilistic perspective through causal\ndiscovery and survival analysis. Our approach is formulated as a bi-level\nproblem. In the upper level, we build the life events graph, using causal\ndiscovery tools. In the lower level, for the pairs of life events,\ntime-to-event modelling through survival analysis is applied to model\ntime-dependent transition probabilities. Several life events were analysed,\nsuch as getting married, buying a new car, child birth, home relocation and\ndivorce, together with the socio-demographic attributes for survival modelling,\nsome of which are age, nationality, number of children, number of cars and home\nownership. The data originates from a survey conducted in Dortmund, Germany,\nwith the questionnaire containing a series of retrospective questions about\nresidential and employment biography, travel behaviour and holiday trips, as\nwell as socio-economic characteristic. Although survival analysis has been used\nin the past to analyse life-course data, this is the first time that a bi-level\nmodel has been formulated. The inclusion of a causal discovery algorithm in the\nupper-level allows us to first identify causal relationships between\nlife-course events and then understand the factors that might influence\ntransition rates between events. This is very different from more classic\nchoice models where causal relationships are subject to expert interpretations\nbased on model results.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:30:16 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kostic", "Bojan", ""], ["Sourd", "Romain Crastes dit", ""], ["Hess", "Stephane", ""], ["Scheiner", "Joachim", ""], ["Holz-Rau", "Christian", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2001.11409", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Attila Schulc, Elnar Hajiyev and Stefanos Zafeiriou", "title": "Analysing Affective Behavior in the First ABAW 2020 Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Affective Behavior Analysis in-the-wild (ABAW) 2020 Competition is the\nfirst Competition aiming at automatic analysis of the three main behavior tasks\nof valence-arousal estimation, basic expression recognition and action unit\ndetection. It is split into three Challenges, each one addressing a respective\nbehavior task. For the Challenges, we provide a common benchmark database,\nAff-Wild2, which is a large scale in-the-wild database and the first one\nannotated for all these three tasks. In this paper, we describe this\nCompetition, to be held in conjunction with the IEEE Conference on Face and\nGesture Recognition, May 2020, in Buenos Aires, Argentina. We present the three\nChallenges, with the utilized Competition corpora. We outline the evaluation\nmetrics, present both the baseline system and the top-3 performing teams'\nmethodologies per Challenge and finally present their obtained results. More\ninformation regarding the Competition, the leaderboard of each Challenge and\ndetails for accessing the utilized database, are provided in the Competition\nsite:\nhttp://ibug.doc.ic.ac.uk/resources/fg-2020-competition-affective-behavior-analysis.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:41:14 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 14:05:59 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Schulc", "Attila", ""], ["Hajiyev", "Elnar", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2001.11411", "submitter": "Maxim Panov", "authors": "Aleksandr Artemenkov and Maxim Panov", "title": "NCVis: Noise Contrastive Approach for Scalable Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern methods for data visualization via dimensionality reduction, such as\nt-SNE, usually have performance issues that prohibit their application to large\namounts of high-dimensional data. In this work, we propose NCVis -- a\nhigh-performance dimensionality reduction method built on a sound statistical\nbasis of noise contrastive estimation. We show that NCVis outperforms\nstate-of-the-art techniques in terms of speed while preserving the\nrepresentation quality of other methods. In particular, the proposed approach\nsuccessfully proceeds a large dataset of more than 1 million news headlines in\nseveral minutes and presents the underlying structure in a human-readable way.\nMoreover, it provides results consistent with classical methods like t-SNE on\nmore straightforward datasets like images of hand-written digits. We believe\nthat the broader usage of such software can significantly simplify the\nlarge-scale data analysis and lower the entry barrier to this area.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:43:50 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Artemenkov", "Aleksandr", ""], ["Panov", "Maxim", ""]]}, {"id": "2001.11443", "submitter": "Huy Tuan Pham", "authors": "Phan-Minh Nguyen, Huy Tuan Pham", "title": "A Rigorous Framework for the Mean Field Limit of Multilayer Neural\n  Networks", "comments": "116 pages. This version incorporates the content of the companion\n  note arXiv:2006.09355 (June 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a mathematically rigorous framework for multilayer neural networks\nin the mean field regime. As the network's widths increase, the network's\nlearning trajectory is shown to be well captured by a meaningful and\ndynamically nonlinear limit (the \\textit{mean field} limit), which is\ncharacterized by a system of ODEs. Our framework applies to a broad range of\nnetwork architectures, learning dynamics and network initializations. Central\nto the framework is the new idea of a \\textit{neuronal embedding}, which\ncomprises of a non-evolving probability space that allows to embed neural\nnetworks of arbitrary widths.\n  Using our framework, we prove several properties of large-width multilayer\nneural networks. Firstly we show that independent and identically distributed\ninitializations cause strong degeneracy effects on the network's learning\ntrajectory when the network's depth is at least four. Secondly we obtain\nseveral global convergence guarantees for feedforward multilayer networks under\na number of different setups. These include two-layer and three-layer networks\nwith independent and identically distributed initializations, and multilayer\nnetworks of arbitrary depths with a special type of correlated initializations\nthat is motivated by the new concept of \\textit{bidirectional diversity}.\nUnlike previous works that rely on convexity, our results admit non-convex\nlosses and hinge on a certain universal approximation property, which is a\ndistinctive feature of infinite-width neural networks and is shown to hold\nthroughout the training process. Aside from being the first known results for\nglobal convergence of multilayer networks in the mean field regime, they\ndemonstrate flexibility of our framework and incorporate several new ideas and\ninsights that depart from the conventional convex optimization wisdom.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 16:43:34 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 17:44:02 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Nguyen", "Phan-Minh", ""], ["Pham", "Huy Tuan", ""]]}, {"id": "2001.11466", "submitter": "Laura Maria Palomino Marino", "authors": "Agust\\'in Alejandro Ortiz-D\\'iaz, Fabiano Baldo, Laura Mar\\'ia\n  Palomino Mari\\~no and Alberto Verdecia Cabrera", "title": "Fase-AL -- Adaptation of Fast Adaptive Stacking of Ensembles for\n  Supporting Active Learning", "comments": "10 pages, 6 figures", "journal-ref": "AIRCC, Volume 10, Number 01, January 2020. 7th International\n  Conference on Computer Science and Information Technology (CoSIT 2020). ISBN\n  : 978-1-925953-15-2", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms to mine data stream have been extensively studied\nin recent years. However, a lot of these algorithms are designed for supervised\nlearning which requires labeled instances. Nevertheless, the labeling of the\ndata is costly and time-consuming. Because of this, alternative learning\nparadigms have been proposed to reduce the cost of the labeling process without\nsignificant loss of model performance. Active learning is one of these\nparadigms, whose main objective is to build classification models that request\nthe lowest possible number of labeled examples achieving adequate levels of\naccuracy. Therefore, this work presents the FASE-AL algorithm which induces\nclassification models with non-labeled instances using Active Learning. FASE-AL\nis based on the algorithm Fast Adaptive Stacking of Ensembles (FASE). FASE is\nan ensemble algorithm that detects and adapts the model when the input data\nstream has concept drift. FASE-AL was compared with four different strategies\nof active learning found in the literature. Real and synthetic databases were\nused in the experiments. The algorithm achieves promising results in terms of\nthe percentage of correctly classified instances.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:25:47 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ortiz-D\u00edaz", "Agust\u00edn Alejandro", ""], ["Baldo", "Fabiano", ""], ["Mari\u00f1o", "Laura Mar\u00eda Palomino", ""], ["Cabrera", "Alberto Verdecia", ""]]}, {"id": "2001.11473", "submitter": "Gonzalo Rios", "authors": "Gonzalo Rios", "title": "Transport Gaussian Processes for Regression", "comments": "19 pages, 2 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) priors are non-parametric generative models with\nappealing modelling properties for Bayesian inference: they can model\nnon-linear relationships through noisy observations, have closed-form\nexpressions for training and inference, and are governed by interpretable\nhyperparameters. However, GP models rely on Gaussianity, an assumption that\ndoes not hold in several real-world scenarios, e.g., when observations are\nbounded or have extreme-value dependencies, a natural phenomenon in physics,\nfinance and social sciences. Although beyond-Gaussian stochastic processes have\ncaught the attention of the GP community, a principled definition and rigorous\ntreatment is still lacking. In this regard, we propose a methodology to\nconstruct stochastic processes, which include GPs, warped GPs, Student-t\nprocesses and several others under a single unified approach. We also provide\nformulas and algorithms for training and inference of the proposed models in\nthe regression problem. Our approach is inspired by layers-based models, where\neach proposed layer changes a specific property over the generated stochastic\nprocess. That, in turn, allows us to push-forward a standard Gaussian white\nnoise prior towards other more expressive stochastic processes, for which\nmarginals and copulas need not be Gaussian, while retaining the appealing\nproperties of GPs. We validate the proposed model through experiments with\nreal-world data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:44:21 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rios", "Gonzalo", ""]]}, {"id": "2001.11486", "submitter": "Siham Tabik", "authors": "S. Tabik, R.F. Alvear-Sandoval, M.M. Ruiz, J.L. Sancho-G\\'omez, A.R.\n  Figueiras-Vidal, F. Herrera", "title": "MNIST-NET10: A heterogeneous deep networks fusion based on the degree of\n  certainty to reach 0.1 error rate. Ensembles overview and proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods have been widely used for improving the results of the best\nsingle classificationmodel. A large body of works have achieved better\nperformance mainly by applying one specific ensemble method. However, very few\nworks have explored complex fusion schemes using het-erogeneous ensembles with\nnew aggregation strategies. This paper is three-fold: 1) It provides an\noverview of the most popular ensemble methods, 2) analyzes several fusion\nschemes using MNIST as guiding thread and 3) introduces MNIST-NET10, a complex\nheterogeneous fusion architecture based on a degree of certainty aggregation\napproach; it combines two heterogeneous schemes from the perspective of data,\nmodel and fusion strategy. MNIST-NET10 reaches a new record in MNISTwith only\n10 misclassified images. Our analysis shows that such complex heterogeneous\nfusionarchitectures based on the degree of certainty can be considered as a way\nof taking benefit fromdiversity.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:13:28 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 15:19:48 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Tabik", "S.", ""], ["Alvear-Sandoval", "R. F.", ""], ["Ruiz", "M. M.", ""], ["Sancho-G\u00f3mez", "J. L.", ""], ["Figueiras-Vidal", "A. R.", ""], ["Herrera", "F.", ""]]}, {"id": "2001.11495", "submitter": "Rishabh Singh", "authors": "Rishabh Singh and Jose C. Principe", "title": "Towards a Kernel based Uncertainty Decomposition Framework for Data and\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new framework for quantifying predictive uncertainty\nfor both data and models that relies on projecting the data into a Gaussian\nreproducing kernel Hilbert space (RKHS) and transforming the data probability\ndensity function (PDF) in a way that quantifies the flow of its gradient as a\ntopological potential field quantified at all points in the sample space. This\nenables the decomposition of the PDF gradient flow by formulating it as a\nmoment decomposition problem using operators from quantum physics, specifically\nthe Schrodinger's formulation. We experimentally show that the higher order\nmodes systematically cluster the different tail regions of the PDF, thereby\nproviding unprecedented discriminative resolution of data regions having high\nepistemic uncertainty. In essence, this approach decomposes local realizations\nof the data PDF in terms of uncertainty moments. We apply this framework as a\nsurrogate tool for predictive uncertainty quantification of point-prediction\nneural network models, overcoming various limitations of conventional Bayesian\nbased uncertainty quantification methods. Experimental comparisons with some\nestablished methods illustrate performance advantages exhibited by our\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:35:36 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 10:21:43 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 06:24:31 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 14:42:13 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Singh", "Rishabh", ""], ["Principe", "Jose C.", ""]]}, {"id": "2001.11499", "submitter": "Jana \\v{C}avojsk\\'a", "authors": "Jana \\v{C}avojsk\\'a (1), Julian Petrasch (1), Nicolas J. Lehmann (1),\n  Agn\\`es Voisard (1), Peter B\\\"ottcher (2) ((1) Freie Universit\\\"at Berlin,\n  Institute of Computer Science, 14195 Berlin, Germany, (2) Freie Universit\\\"at\n  Berlin, Clinic for Small Animals, 14163 Berlin, Germany)", "title": "Estimating and abstracting the 3D structure of bones using neural\n  networks on X-ray (2D) images", "comments": "13 pages, 5 figures, 1 table, submitted to Communications Biology", "journal-ref": "Communications biology, 2020, 3(1), pp.1-13", "doi": "10.1038/s42003-020-1057-3", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep-learning based method for estimating the 3D\nstructure of a bone from a pair of 2D X-ray images. Our triplet loss-trained\nneural network selects the most closely matching 3D bone shape from a\npredefined set of shapes. Our predictions have an average root mean square\n(RMS) distance of 1.08 mm between the predicted and true shapes, making it more\naccurate than the average error achieved by eight other examined 3D bone\nreconstruction approaches. The prediction process that we use is fully\nautomated and unlike many competing approaches, it does not rely on any\nprevious knowledge about bone geometry. Additionally, our neural network can\ndetermine the identity of a bone based only on its X-ray image. It computes a\nlow-dimensional representation (\"embedding\") of each 2D X-ray image and\nhenceforth compares different X-ray images based only on their embeddings. An\nembedding holds enough information to uniquely identify the bone CT belonging\nto the input X-ray image with a 100% accuracy and can therefore serve as a kind\nof fingerprint for that bone. Possible applications include faster, image\ncontent-based bone database searches for forensic purposes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:41:17 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["\u010cavojsk\u00e1", "Jana", ""], ["Petrasch", "Julian", ""], ["Lehmann", "Nicolas J.", ""], ["Voisard", "Agn\u00e8s", ""], ["B\u00f6ttcher", "Peter", ""]]}, {"id": "2001.11542", "submitter": "Ritwik Giri", "authors": "Bahareh Tolooshams, Ritwik Giri, Andrew H. Song, Umut Isik, Arvindh\n  Krishnaswamy", "title": "Channel-Attention Dense U-Net for Multichannel Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep learning has gained significant attention for speech\nenhancement recently. The state-of-the-art deep learning methods perform the\ntask by learning a ratio/binary mask that is applied to the mixture in the\ntime-frequency domain to produce the clean speech. Despite the great\nperformance in the single-channel setting, these frameworks lag in performance\nin the multichannel setting as the majority of these methods a) fail to exploit\nthe available spatial information fully, and b) still treat the deep\narchitecture as a black box which may not be well-suited for multichannel audio\nprocessing. This paper addresses these drawbacks, a) by utilizing complex ratio\nmasking instead of masking on the magnitude of the spectrogram, and more\nimportantly, b) by introducing a channel-attention mechanism inside the deep\narchitecture to mimic beamforming. We propose Channel-Attention Dense U-Net, in\nwhich we apply the channel-attention unit recursively on feature maps at every\nlayer of the network, enabling the network to perform non-linear beamforming.\nWe demonstrate the superior performance of the network against the\nstate-of-the-art approaches on the CHiME-3 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 19:56:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Giri", "Ritwik", ""], ["Song", "Andrew H.", ""], ["Isik", "Umut", ""], ["Krishnaswamy", "Arvindh", ""]]}, {"id": "2001.11548", "submitter": "Damian Brzyski", "authors": "Damian Brzyski, Xixi Hu, Joaquin Goni, Beau Ances, Timothy W.\n  Randolph, Jaroslaw Harezlak", "title": "A Sparsity Inducing Nuclear-Norm Estimator (SpINNEr) for Matrix-Variate\n  Regression in Brain Connectivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical scalar-response regression methods treat covariates as a vector and\nestimate a corresponding vector of regression coefficients. In medical\napplications, however, regressors are often in a form of multi-dimensional\narrays. For example, one may be interested in using MRI imaging to identify\nwhich brain regions are associated with a health outcome. Vectorizing the\ntwo-dimensional image arrays is an unsatisfactory approach since it destroys\nthe inherent spatial structure of the images and can be computationally\nchallenging. We present an alternative approach - regularized matrix regression\n- where the matrix of regression coefficients is defined as a solution to the\nspecific optimization problem. The method, called SParsity Inducing Nuclear\nNorm EstimatoR (SpINNEr), simultaneously imposes two penalty types on the\nregression coefficient matrix---the nuclear norm and the lasso norm---to\nencourage a low rank matrix solution that also has entry-wise sparsity. A\nspecific implementation of the alternating direction method of multipliers\n(ADMM) is used to build a fast and efficient numerical solver. Our simulations\nshow that SpINNEr outperforms other methods in estimation accuracy when the\nresponse-related entries (representing the brain's functional connectivity) are\narranged in well-connected communities. SpINNEr is applied to investigate\nassociations between HIV-related outcomes and functional connectivity in the\nhuman brain.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 20:10:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Brzyski", "Damian", ""], ["Hu", "Xixi", ""], ["Goni", "Joaquin", ""], ["Ances", "Beau", ""], ["Randolph", "Timothy W.", ""], ["Harezlak", "Jaroslaw", ""]]}, {"id": "2001.11552", "submitter": "Amir Karami", "authors": "Amir Karami, Cynthia Nicole White, Kayla Ford, Suzanne Swan, Melek\n  Yildiz Spinel", "title": "Unwanted Advances in Higher Education: Uncovering Sexual Harassment\n  Experiences in Academia with Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexual harassment in academia is often a hidden problem because victims are\nusually reluctant to report their experiences. Recently, a web survey was\ndeveloped to provide an opportunity to share thousands of sexual harassment\nexperiences in academia. Using an efficient approach, this study collected and\ninvestigated more than 2,000 sexual harassment experiences to better understand\nthese unwanted advances in higher education. This paper utilized text mining to\ndisclose hidden topics and explore their weight across three variables:\nharasser gender, institution type, and victim's field of study. We mapped the\ntopics on five themes drawn from the sexual harassment literature and found\nthat more than 50% of the topics were assigned to the unwanted sexual attention\ntheme. Fourteen percent of the topics were in the gender harassment theme, in\nwhich insulting, sexist, or degrading comments or behavior was directed towards\nwomen. Five percent of the topics involved sexual coercion (a benefit is\noffered in exchange for sexual favors), 5% involved sex discrimination, and 7%\nof the topics discussed retaliation against the victim for reporting the\nharassment, or for simply not complying with the harasser. Findings highlight\nthe power differential between faculty and students, and the toll on students\nwhen professors abuse their power. While some topics did differ based on type\nof institution, there were no differences between the topics based on gender of\nharasser or field of study. This research can be beneficial to researchers in\nfurther investigation of this paper's dataset, and to policymakers in improving\nexisting policies to create a safe and supportive environment in academia.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:37:45 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Karami", "Amir", ""], ["White", "Cynthia Nicole", ""], ["Ford", "Kayla", ""], ["Swan", "Suzanne", ""], ["Spinel", "Melek Yildiz", ""]]}, {"id": "2001.11568", "submitter": "Edgar Minasyan", "authors": "Elad Hazan and Edgar Minasyan", "title": "Faster Projection-free Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many online learning problems the computational bottleneck for\ngradient-based methods is the projection operation. For this reason, in many\nproblems the most efficient algorithms are based on the Frank-Wolfe method,\nwhich replaces projections by linear optimization. In the general case,\nhowever, online projection-free methods require more iterations than\nprojection-based methods: the best known regret bound scales as $T^{3/4}$.\nDespite significant work on various variants of the Frank-Wolfe method, this\nbound has remained unchanged for a decade. In this paper we give an efficient\nprojection-free algorithm that guarantees $T^{2/3}$ regret for general online\nconvex optimization with smooth cost functions and one linear optimization\ncomputation per iteration. As opposed to previous Frank-Wolfe approaches, our\nalgorithm is derived using the Follow-the-Perturbed-Leader method and is\nanalyzed using an online primal-dual framework.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:18:39 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:36:31 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Hazan", "Elad", ""], ["Minasyan", "Edgar", ""]]}, {"id": "2001.11572", "submitter": "Christos Thrampoulidis", "authors": "Ganesh Kini and Christos Thrampoulidis", "title": "Analytic Study of Double Descent in Binary Classification: The Impact of\n  Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive empirical evidence reveals that, for a wide range of different\nlearning methods and datasets, the risk curve exhibits a double-descent (DD)\ntrend as a function of the model size. In a recent paper\n[Zeyu,Kammoun,Thrampoulidis,2019] the authors studied binary linear\nclassification models and showed that the test error of gradient descent (GD)\nwith logistic loss undergoes a DD. In this paper, we complement these results\nby extending them to GD with square loss. We show that the DD phenomenon\npersists, but we also identify several differences compared to logistic loss.\nThis emphasizes that crucial features of DD curves (such as their transition\nthreshold and global minima) depend both on the training data and on the\nlearning algorithm. We further study the dependence of DD curves on the size of\nthe training set. Similar to our earlier work, our results are analytic: we\nplot the DD curves by first deriving sharp asymptotics for the test error under\nGaussian features. Albeit simple, the models permit a principled study of DD\nfeatures, the outcomes of which theoretically corroborate related empirical\nfindings occurring in more complex learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:29:03 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kini", "Ganesh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2001.11578", "submitter": "Diego Marcondes", "authors": "Diego Marcondes, Adilson Simonis and Junior Barrera", "title": "Learning the Hypotheses Space from data Part II: Convergence and\n  Feasibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In part \\textit{I} we proposed a structure for a general Hypotheses Space\n$\\mathcal{H}$, the Learning Space $\\mathbb{L}(\\mathcal{H})$, which can be\nemployed to avoid \\textit{overfitting} when estimating in a complex space with\nrelative shortage of examples. Also, we presented the U-curve property, which\ncan be taken advantage of in order to select a Hypotheses Space without\nexhaustively searching $\\mathbb{L}(\\mathcal{H})$. In this paper, we carry\nfurther our agenda, by showing the consistency of a model selection framework\nbased on Learning Spaces, in which one selects from data the Hypotheses Space\non which to learn. The method developed in this paper adds to the\nstate-of-the-art in model selection, by extending Vapnik-Chervonenkis Theory to\n\\textit{random} Hypotheses Spaces, i.e., Hypotheses Spaces learned from data.\nIn this framework, one estimates a random subspace $\\hat{\\mathcal{M}} \\in\n\\mathbb{L}(\\mathcal{H})$ which converges with probability one to a target\nHypotheses Space $\\mathcal{M}^{\\star} \\in \\mathbb{L}(\\mathcal{H})$ with desired\nproperties. As the convergence implies asymptotic unbiased estimators, we have\na consistent framework for model selection, showing that it is feasible to\nlearn the Hypotheses Space from data. Furthermore, we show that the\ngeneralization errors of learning on $\\hat{\\mathcal{M}}$ are lesser than those\nwe commit when learning on $\\mathcal{H}$, so it is more efficient to learn on a\nsubspace learned from data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:48:37 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Marcondes", "Diego", ""], ["Simonis", "Adilson", ""], ["Barrera", "Junior", ""]]}, {"id": "2001.11595", "submitter": "Matteo Pirotta", "authors": "Jian Qian, Ronan Fruit, Matteo Pirotta, Alessandro Lazaric", "title": "Concentration Inequalities for Multinoulli Random Variables", "comments": "Tutorial at ALT'19 on Regret Minimization in Infinite-Horizon Finite\n  Markov Decision Processes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate concentration inequalities for Dirichlet and Multinomial\nrandom variables.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 22:44:15 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Qian", "Jian", ""], ["Fruit", "Ronan", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2001.11628", "submitter": "Ryo Okumura", "authors": "Ryo Okumura, Masashi Okada and Tadahiro Taniguchi", "title": "Domain-Adversarial and Conditional State Space Model for Imitation\n  Learning", "comments": "Published at IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State representation learning (SRL) in partially observable Markov decision\nprocesses has been studied to learn abstract features of data useful for robot\ncontrol tasks. For SRL, acquiring domain-agnostic states is essential for\nachieving efficient imitation learning. Without these states, imitation\nlearning is hampered by domain-dependent information useless for control.\nHowever, existing methods fail to remove such disturbances from the states when\nthe data from experts and agents show large domain shifts. To overcome this\nissue, we propose a domain-adversarial and conditional state space model\n(DAC-SSM) that enables control systems to obtain domain-agnostic and task- and\ndynamics-aware states. DAC-SSM jointly optimizes the state inference,\nobservation reconstruction, forward dynamics, and reward models. To remove\ndomain-dependent information from the states, the model is trained with domain\ndiscriminators in an adversarial manner, and the reconstruction is conditioned\non domain labels. We experimentally evaluated the model predictive control\nperformance via imitation learning for continuous control of sparse reward\ntasks in simulators and compared it with the performance of the existing SRL\nmethod. The agents from DAC-SSM achieved performance comparable to experts and\nmore than twice the baselines. We conclude domain-agnostic states are essential\nfor imitation learning that has large domain shifts and can be obtained using\nDAC-SSM.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:39:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 06:51:25 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Okumura", "Ryo", ""], ["Okada", "Masashi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2001.11651", "submitter": "Yuguang Wang", "authors": "Kai Yi, Yi Guo, Yanan Fan, Jan Hamann, Yu Guang Wang", "title": "CosmoVAE: Variational Autoencoder for CMB Image Inpainting", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cosmic microwave background radiation (CMB) is critical to the understanding\nof the early universe and precise estimation of cosmological constants. Due to\nthe contamination of thermal dust noise in the galaxy, the CMB map that is an\nimage on the two-dimensional sphere has missing observations, mainly\nconcentrated on the equatorial region. The noise of the CMB map has a\nsignificant impact on the estimation precision for cosmological parameters.\nInpainting the CMB map can effectively reduce the uncertainty of parametric\nestimation. In this paper, we propose a deep learning-based variational\nautoencoder --- CosmoVAE, to restoring the missing observations of the CMB map.\nThe input and output of CosmoVAE are square images. To generate training,\nvalidation, and test data sets, we segment the full-sky CMB map into many small\nimages by Cartesian projection. CosmoVAE assigns physical quantities to the\nparameters of the VAE network by using the angular power spectrum of the\nGaussian random field as latent variables. CosmoVAE adopts a new loss function\nto improve the learning performance of the model, which consists of $\\ell_1$\nreconstruction loss, Kullback-Leibler divergence between the posterior\ndistribution of encoder network and the prior distribution of latent variables,\nperceptual loss, and total-variation regularizer. The proposed model achieves\nstate of the art performance for Planck \\texttt{Commander} 2018 CMB map\ninpainting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:54:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Yi", "Kai", ""], ["Guo", "Yi", ""], ["Fan", "Yanan", ""], ["Hamann", "Jan", ""], ["Wang", "Yu Guang", ""]]}, {"id": "2001.11653", "submitter": "Yuguang Wang", "authors": "Nicole Hallett, Kai Yi, Josef Dick, Christopher Hodge, Gerard Sutton,\n  Yu Guang Wang, Jingjing You", "title": "Deep Learning Based Unsupervised and Semi-supervised Classification for\n  Keratoconus", "comments": "7 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transparent cornea is the window of the eye, facilitating the entry of\nlight rays and controlling focusing the movement of the light within the eye.\nThe cornea is critical, contributing to 75% of the refractive power of the eye.\nKeratoconus is a progressive and multifactorial corneal degenerative disease\naffecting 1 in 2000 individuals worldwide. Currently, there is no cure for\nkeratoconus other than corneal transplantation for advanced stage keratoconus\nor corneal cross-linking, which can only halt KC progression. The ability to\naccurately identify subtle KC or KC progression is of vital clinical\nsignificance. To date, there has been little consensus on a useful model to\nclassify KC patients, which therefore inhibits the ability to predict disease\nprogression accurately.\n  In this paper, we utilised machine learning to analyse data from 124 KC\npatients, including topographical and clinical variables. Both supervised\nmultilayer perceptron and unsupervised variational autoencoder models were used\nto classify KC patients with reference to the existing Amsler-Krumeich (A-K)\nclassification system. Both methods result in high accuracy, with the\nunsupervised method showing better performance. The result showed that the\nunsupervised method with a selection of 29 variables could be a powerful tool\nto provide an automatic classification tool for clinicians. These outcomes\nprovide a platform for additional analysis for the progression and treatment of\nkeratoconus.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:56:12 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hallett", "Nicole", ""], ["Yi", "Kai", ""], ["Dick", "Josef", ""], ["Hodge", "Christopher", ""], ["Sutton", "Gerard", ""], ["Wang", "Yu Guang", ""], ["You", "Jingjing", ""]]}, {"id": "2001.11659", "submitter": "Ben Letham", "authors": "Benjamin Letham, Roberto Calandra, Akshara Rai, Eytan Bakshy", "title": "Re-Examining Linear Embeddings for High-Dimensional Bayesian\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular approach to optimize\nexpensive-to-evaluate black-box functions. A significant challenge in BO is to\nscale to high-dimensional parameter spaces while retaining sample efficiency. A\nsolution considered in existing literature is to embed the high-dimensional\nspace in a lower-dimensional manifold, often via a random linear embedding. In\nthis paper, we identify several crucial issues and misconceptions about the use\nof linear embeddings for BO. We study the properties of linear embeddings from\nthe literature and show that some of the design choices in current approaches\nadversely impact their performance. We show empirically that properly\naddressing these issues significantly improves the efficacy of linear\nembeddings for BO on a range of problems, including learning a gait policy for\nrobot locomotion.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:02:34 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 18:30:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Letham", "Benjamin", ""], ["Calandra", "Roberto", ""], ["Rai", "Akshara", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2001.11668", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "On the Convergence of Stochastic Gradient Descent with Low-Rank\n  Projections for Convex Low-Rank Matrix Problems", "comments": "Accepted to Conference on Learning Theory 2020 (COLT 2020). This\n  version fixes some minor errors in previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the use of Stochastic Gradient Descent (SGD) for solving convex\noptimization problems that serve as highly popular convex relaxations for many\nimportant low-rank matrix recovery problems such as \\textit{matrix completion},\n\\textit{phase retrieval}, and more. The computational limitation of applying\nSGD to solving these relaxations in large-scale is the need to compute a\npotentially high-rank singular value decomposition (SVD) on each iteration in\norder to enforce the low-rank-promoting constraint. We begin by considering a\nsimple and natural sufficient condition so that these relaxations indeed admit\nlow-rank solutions. This condition is also necessary for a certain notion of\nlow-rank-robustness to hold. Our main result shows that under this condition\nwhich involves the eigenvalues of the gradient vector at optimal points, SGD\nwith mini-batches, when initialized with a \"warm-start\" point, produces\niterates that are low-rank with high probability, and hence only a low-rank SVD\ncomputation is required on each iteration. This suggests that SGD may indeed be\npractically applicable to solving large-scale convex relaxations of low-rank\nmatrix recovery problems. Our theoretical results are accompanied with\nsupporting preliminary empirical evidence. As a side benefit, our analysis is\nquite simple and short.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 06:00:34 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 14:26:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "2001.11704", "submitter": "Shay Moran", "authors": "Noga Alon and Alon Gonen and Elad Hazan and Shay Moran", "title": "Boosting Simple Learners", "comments": "A minor revision according to STOC reviews", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a celebrated machine learning approach which is based on the idea\nof combining weak and moderately inaccurate hypotheses to a strong and accurate\none. We study boosting under the assumption that the weak hypotheses belong to\na class of bounded capacity. This assumption is inspired by the common\nconvention that weak hypotheses are \"rules-of-thumbs\" from an \"easy-to-learn\nclass\". (Schapire and Freund '12, Shalev-Shwartz and Ben-David '14.) Formally,\nwe assume the class of weak hypotheses has a bounded VC dimension. We focus on\ntwo main questions: (i) Oracle Complexity: How many weak hypotheses are needed\nin order to produce an accurate hypothesis? We design a novel boosting\nalgorithm and demonstrate that it circumvents a classical lower bound by Freund\nand Schapire ('95, '12). Whereas the lower bound shows that\n$\\Omega({1}/{\\gamma^2})$ weak hypotheses with $\\gamma$-margin are sometimes\nnecessary, our new method requires only $\\tilde{O}({1}/{\\gamma})$ weak\nhypothesis, provided that they belong to a class of bounded VC dimension.\nUnlike previous boosting algorithms which aggregate the weak hypotheses by\nmajority votes, the new boosting algorithm uses more complex (\"deeper\")\naggregation rules. We complement this result by showing that complex\naggregation rules are in fact necessary to circumvent the aforementioned lower\nbound. (ii) Expressivity: Which tasks can be learned by boosting weak\nhypotheses from a bounded VC class? Can complex concepts that are \"far away\"\nfrom the class be learned? Towards answering the first question we identify a\ncombinatorial-geometric parameter which captures the expressivity of\nbase-classes in boosting. As a corollary we provide an affirmative answer to\nthe second question for many well-studied classes, including half-spaces and\ndecision stumps. Along the way, we establish and exploit connections with\nDiscrepancy Theory.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:34:56 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 04:37:17 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 07:10:41 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Alon", "Noga", ""], ["Gonen", "Alon", ""], ["Hazan", "Elad", ""], ["Moran", "Shay", ""]]}, {"id": "2001.11713", "submitter": "Ruoxuan Xiong", "authors": "Kun Kuang, Ruoxuan Xiong, Peng Cui, Susan Athey, Bo Li", "title": "Stable Prediction with Model Misspecification and Agnostic Distribution\n  Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many machine learning algorithms, two main assumptions are required to\nguarantee performance. One is that the test data are drawn from the same\ndistribution as the training data, and the other is that the model is correctly\nspecified. In real applications, however, we often have little prior knowledge\non the test data and on the underlying true model. Under model\nmisspecification, agnostic distribution shift between training and test data\nleads to inaccuracy of parameter estimation and instability of prediction\nacross unknown test data. To address these problems, we propose a novel\nDecorrelated Weighting Regression (DWR) algorithm which jointly optimizes a\nvariable decorrelation regularizer and a weighted regression model. The\nvariable decorrelation regularizer estimates a weight for each sample such that\nvariables are decorrelated on the weighted training data. Then, these weights\nare used in the weighted regression to improve the accuracy of estimation on\nthe effect of each variable, thus help to improve the stability of prediction\nacross unknown test data. Extensive experiments clearly demonstrate that our\nDWR algorithm can significantly improve the accuracy of parameter estimation\nand stability of prediction with model misspecification and agnostic\ndistribution shift.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:56:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kuang", "Kun", ""], ["Xiong", "Ruoxuan", ""], ["Cui", "Peng", ""], ["Athey", "Susan", ""], ["Li", "Bo", ""]]}, {"id": "2001.11718", "submitter": "Tsubasa Takahashi", "authors": "Hajime Ono and Tsubasa Takahashi", "title": "Locally Private Distributed Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study locally differentially private algorithms for reinforcement learning\nto obtain a robust policy that performs well across distributed private\nenvironments. Our algorithm protects the information of local agents' models\nfrom being exploited by adversarial reverse engineering. Since a local policy\nis strongly being affected by the individual environment, the output of the\nagent may release the private information unconsciously. In our proposed\nalgorithm, local agents update the model in their environments and report noisy\ngradients designed to satisfy local differential privacy (LDP) that gives a\nrigorous local privacy guarantee. By utilizing a set of reported noisy\ngradients, a central aggregator updates its model and delivers it to different\nlocal agents. In our empirical evaluation, we demonstrate how our method\nperforms well under LDP. To the best of our knowledge, this is the first work\nthat actualizes distributed reinforcement learning under LDP. This work enables\nus to obtain a robust agent that performs well across distributed private\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:03:23 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ono", "Hajime", ""], ["Takahashi", "Tsubasa", ""]]}, {"id": "2001.11739", "submitter": "Jonathan Bac", "authors": "Jonathan Bac, Andrei Zinovyev", "title": "Local intrinsic dimensionality estimators based on concentration of\n  measure", "comments": "to be published in the International Joint Conference On Neural\n  Networks (IJCNN) held as part of the IEEE World Congress On Computational\n  Intelligence (WCCI), July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic dimensionality (ID) is one of the most fundamental characteristics\nof multi-dimensional data point clouds. Knowing ID is crucial to choose the\nappropriate machine learning approach as well as to understand its behavior and\nvalidate it. ID can be computed globally for the whole data point distribution,\nor computed locally in different regions of the data space. In this paper, we\nintroduce new local estimators of ID based on linear separability of\nmulti-dimensional data point clouds, which is one of the manifestations of\nconcentration of measure. We empirically study the properties of these\nestimators and compare them with other recently introduced ID estimators\nexploiting various effects of measure concentration. Observed differences\nbetween estimators can be used to anticipate their behaviour in practical\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:49:09 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 15:41:08 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 10:54:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bac", "Jonathan", ""], ["Zinovyev", "Andrei", ""]]}, {"id": "2001.11757", "submitter": "Giorgio Visani Mr", "authors": "Giorgio Visani, Enrico Bagli, Federico Chesani, Alessandro Poluzzi and\n  Davide Capuzzo", "title": "Statistical stability indices for LIME: obtaining reliable explanations\n  for Machine Learning models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays we are witnessing a transformation of the business processes towards\na more computation driven approach. The ever increasing usage of Machine\nLearning techniques is the clearest example of such trend.\n  This sort of revolution is often providing advantages, such as an increase in\nprediction accuracy and a reduced time to obtain the results. However, these\nmethods present a major drawback: it is very difficult to understand on what\ngrounds the algorithm took the decision.\n  To address this issue we consider the LIME method. We give a general\nbackground on LIME then, we focus on the stability issue: employing the method\nrepeated times, under the same conditions, may yield to different explanations.\n  Two complementary indices are proposed, to measure LIME stability. It is\nimportant for the practitioner to be aware of the issue, as well as to have a\ntool for spotting it. Stability guarantees LIME explanations to be reliable,\ntherefore a stability assessment, made through the proposed indices, is\ncrucial.\n  As a case study, we apply both Machine Learning and classical statistical\ntechniques to Credit Risk data. We test LIME on the Machine Learning algorithm\nand check its stability. Eventually, we examine the goodness of the\nexplanations returned.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:39:46 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 09:30:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Visani", "Giorgio", ""], ["Bagli", "Enrico", ""], ["Chesani", "Federico", ""], ["Poluzzi", "Alessandro", ""], ["Capuzzo", "Davide", ""]]}, {"id": "2001.11760", "submitter": "Prashant Singh", "authors": "Mattias {\\AA}kesson, Prashant Singh, Fredrik Wrede, Andreas Hellander", "title": "Convolutional Neural Networks as Summary Statistics for Approximate\n  Bayesian Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation is widely used in systems biology for\ninferring parameters in stochastic gene regulatory network models. Its\nperformance hinges critically on the ability to summarize high-dimensional\nsystem responses such as time series into a few informative, low-dimensional\nsummary statistics. The quality of those statistics acutely impacts the\naccuracy of the inference task. Existing methods to select the best subset out\nof a pool of candidate statistics do not scale well with large pools of several\ntens to hundreds of candidate statistics. Since high quality statistics are\nimperative for good performance, this becomes a serious bottleneck when\nperforming inference on complex and high-dimensional problems. This paper\nproposes a convolutional neural network architecture for automatically learning\ninformative summary statistics of temporal responses. We show that the proposed\nnetwork can effectively circumvent the statistics selection problem of the\npreprocessing step for ABC inference. The proposed approach is demonstrated on\ntwo benchmark problem and one challenging inference problem learning parameters\nin a high-dimensional stochastic genetic oscillator. We also study the impact\nof experimental design on network performance by comparing different data\nrichness and data acquisition strategies.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:46:30 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:07:49 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 22:24:44 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 11:59:18 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 10:23:42 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["\u00c5kesson", "Mattias", ""], ["Singh", "Prashant", ""], ["Wrede", "Fredrik", ""], ["Hellander", "Andreas", ""]]}, {"id": "2001.11767", "submitter": "Johannes Hofmanninger", "authors": "Johannes Hofmanninger, Florian Prayer, Jeanny Pan, Sebastian Rohrich,\n  Helmut Prosch and Georg Langs", "title": "Automatic lung segmentation in routine imaging is primarily a data\n  diversity problem, not a methodology problem", "comments": "10 pages, 5 figures, 5 tables", "journal-ref": "Eur Radiol Exp 4, 50 (2020)", "doi": "10.1186/s41747-020-00173-2", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated segmentation of anatomical structures is a crucial step in image\nanalysis. For lung segmentation in computed tomography, a variety of approaches\nexist, involving sophisticated pipelines trained and validated on different\ndatasets. However, the clinical applicability of these approaches across\ndiseases remains limited. We compared four generic deep learning approaches\ntrained on various datasets and two readily available lung segmentation\nalgorithms. We performed evaluation on routine imaging data with more than six\ndifferent disease patterns and three published data sets. Using different deep\nlearning approaches, mean Dice similarity coefficients (DSCs) on test datasets\nvaried not over 0.02. When trained on a diverse routine dataset (n = 36) a\nstandard approach (U-net) yields a higher DSC (0.97 $\\pm$ 0.05) compared to\ntraining on public datasets such as Lung Tissue Research Consortium (0.94 $\\pm$\n0.13, p = 0.024) or Anatomy 3 (0.92 $\\pm$ 0.15, p = 0.001). Trained on routine\ndata (n = 231) covering multiple diseases, U-net compared to reference methods\nyields a DSC of 0.98 $\\pm$ 0.03 versus 0.94 $\\pm$ 0.12 (p = 0.024).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:01:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 15:02:26 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Hofmanninger", "Johannes", ""], ["Prayer", "Florian", ""], ["Pan", "Jeanny", ""], ["Rohrich", "Sebastian", ""], ["Prosch", "Helmut", ""], ["Langs", "Georg", ""]]}, {"id": "2001.11771", "submitter": "Antonio Carta", "authors": "Antonio Carta, Alessandro Sperduti, Davide Bacciu", "title": "Encoding-based Memory Modules for Recurrent Neural Networks", "comments": "preprint submitted at Elsevier Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to solve sequential tasks with recurrent models requires the ability\nto memorize long sequences and to extract task-relevant features from them. In\nthis paper, we study the memorization subtask from the point of view of the\ndesign and training of recurrent neural networks. We propose a new model, the\nLinear Memory Network, which features an encoding-based memorization component\nbuilt with a linear autoencoder for sequences. We extend the memorization\ncomponent with a modular memory that encodes the hidden state sequence at\ndifferent sampling frequencies. Additionally, we provide a specialized training\nalgorithm that initializes the memory to efficiently encode the hidden\nactivations of the network. The experimental results on synthetic and\nreal-world datasets show that specializing the training algorithm to train the\nmemorization component always improves the final performance whenever the\nmemorization of long sequences is necessary to solve the problem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:14:27 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Carta", "Antonio", ""], ["Sperduti", "Alessandro", ""], ["Bacciu", "Davide", ""]]}, {"id": "2001.11775", "submitter": "Hye Won Chung", "authors": "Daesung Kim and Hye Won Chung", "title": "Binary Classification with XOR Queries: Fundamental Limits and An\n  Efficient Algorithm", "comments": "Accepted to IEEE Transactions on Information Theory. 37 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a query-based data acquisition problem for binary classification\nof unknown labels, which has diverse applications in communications,\ncrowdsourcing, recommender systems and active learning. To ensure reliable\nrecovery of unknown labels with as few number of queries as possible, we\nconsider an effective query type that asks \"group attribute\" of a chosen subset\nof objects. In particular, we consider the problem of classifying $m$ binary\nlabels with XOR queries that ask whether the number of objects having a given\nattribute in the chosen subset of size $d$ is even or odd. The subset size $d$,\nwhich we call query degree, can be varying over queries. We consider a general\nnoise model where the accuracy of answers on queries changes depending both on\nthe worker (the data provider) and query degree $d$. For this general model, we\ncharacterize the information-theoretic limit on the optimal number of queries\nto reliably recover $m$ labels in terms of a given combination of degree-$d$\nqueries and noise parameters. Further, we propose an efficient inference\nalgorithm that achieves this limit even when the noise parameters are unknown.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:23:02 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 05:39:42 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Kim", "Daesung", ""], ["Chung", "Hye Won", ""]]}, {"id": "2001.11801", "submitter": "Allard Hendriksen", "authors": "Allard A. Hendriksen, Daniel M. Pelt and K. Joost Batenburg", "title": "Noise2Inverse: Self-supervised deep convolutional denoising for\n  tomography", "comments": "This paper appears in: IEEE Transactions on Computational Imaging On\n  page(s): 1320-1335 Print ISSN: 2333-9403 Online ISSN: 2333-9403 Digital\n  Object Identifier: 10.1109/TCI.2020.3019647", "journal-ref": null, "doi": "10.1109/TCI.2020.3019647", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a high-quality image from noisy indirect measurements is an\nimportant problem with many applications. For such inverse problems, supervised\ndeep convolutional neural network (CNN)-based denoising methods have shown\nstrong results, but the success of these supervised methods critically depends\non the availability of a high-quality training dataset of similar measurements.\nFor image denoising, methods are available that enable training without a\nseparate training dataset by assuming that the noise in two different pixels is\nuncorrelated. However, this assumption does not hold for inverse problems,\nresulting in artifacts in the denoised images produced by existing methods.\nHere, we propose Noise2Inverse, a deep CNN-based denoising method for linear\nimage reconstruction algorithms that does not require any additional clean or\nnoisy data. Training a CNN-based denoiser is enabled by exploiting the noise\nmodel to compute multiple statistically independent reconstructions. We develop\na theoretical framework which shows that such training indeed obtains a\ndenoising CNN, assuming the measured noise is element-wise independent and\nzero-mean. On simulated CT datasets, Noise2Inverse demonstrates an improvement\nin peak signal-to-noise ratio and structural similarity index compared to\nstate-of-the-art image denoising methods and conventional reconstruction\nmethods, such as Total-Variation Minimization. We also demonstrate that the\nmethod is able to significantly reduce noise in challenging real-world\nexperimental datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:50:24 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:25:56 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 08:27:07 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Hendriksen", "Allard A.", ""], ["Pelt", "Daniel M.", ""], ["Batenburg", "K. Joost", ""]]}, {"id": "2001.11802", "submitter": "Adonis Bogris", "authors": "Stavros Deligiannidis, Adonis Bogris, Charis Mesaritakis, Yannis\n  Kopsinis", "title": "Compensation of Fiber Nonlinearities in Digital Coherent Systems\n  Leveraging Long Short-Term Memory Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JLT.2020.3007919", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce for the first time the utilization of Long short-term memory\n(LSTM) neural network architectures for the compensation of fiber\nnonlinearities in digital coherent systems. We conduct numerical simulations\nconsidering either C-band or O-band transmission systems for single channel and\nmulti-channel 16-QAM modulation format with polarization multiplexing. A\ndetailed analysis regarding the effect of the number of hidden units and the\nlength of the word of symbols that trains the LSTM algorithm and corresponds to\nthe considered channel memory is conducted in order to reveal the limits of\nLSTM based receiver with respect to performance and complexity. The numerical\nresults show that LSTM Neural Networks can be very efficient as post processors\nof optical receivers which classify data that have undergone non-linear\nimpairments in fiber and provide superior performance compared to digital back\npropagation, especially in the multi-channel transmission scenario. The\ncomplexity analysis shows that LSTM becomes more complex as the number of\nhidden units and the channel memory increase can be less complex than DBP in\nlong distances (> 1000 km).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:50:48 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:27:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Deligiannidis", "Stavros", ""], ["Bogris", "Adonis", ""], ["Mesaritakis", "Charis", ""], ["Kopsinis", "Yannis", ""]]}, {"id": "2001.11818", "submitter": "Tzu-Chi Yen", "authors": "Tzu-Chi Yen, Daniel B. Larremore", "title": "Community Detection in Bipartite Networks with Stochastic Blockmodels", "comments": "17 pages, 6 figures. Code is available at\n  https://github.com/junipertcy/bipartiteSBM and a documentation at\n  https://docs.netscied.tw/bipartiteSBM/index.html", "journal-ref": "Phys. Rev. E 102, 032309 (2020)", "doi": "10.1103/PhysRevE.102.032309", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In bipartite networks, community structures are restricted to being\ndisassortative, in that nodes of one type are grouped according to common\npatterns of connection with nodes of the other type. This makes the stochastic\nblock model (SBM), a highly flexible generative model for networks with block\nstructure, an intuitive choice for bipartite community detection. However,\ntypical formulations of the SBM do not make use of the special structure of\nbipartite networks. Here we introduce a Bayesian nonparametric formulation of\nthe SBM and a corresponding algorithm to efficiently find communities in\nbipartite networks which parsimoniously chooses the number of communities. The\nbiSBM improves community detection results over general SBMs when data are\nnoisy, improves the model resolution limit by a factor of $\\sqrt{2}$, and\nexpands our understanding of the complicated optimization landscape associated\nwith community detection tasks. A direct comparison of certain terms of the\nprior distributions in the biSBM and a related high-resolution hierarchical SBM\nalso reveals a counterintuitive regime of community detection problems,\npopulated by smaller and sparser networks, where nonhierarchical models\noutperform their more flexible counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 05:58:19 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 07:38:24 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Yen", "Tzu-Chi", ""], ["Larremore", "Daniel B.", ""]]}, {"id": "2001.11819", "submitter": "Dan Piponi", "authors": "Dan Piponi, Dave Moore, Joshua V. Dillon", "title": "Joint Distributions for TensorFlow Probability", "comments": "Based on extended abstract submitted to PROBPROG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central tenet of probabilistic programming is that a model is specified\nexactly once in a canonical representation which is usable by inference\nalgorithms. We describe JointDistributions, a family of declarative\nrepresentations of directed graphical models in TensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 01:00:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Piponi", "Dan", ""], ["Moore", "Dave", ""], ["Dillon", "Joshua V.", ""]]}, {"id": "2001.11841", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Tim Verbelen, Johannes Nauta, Cedric De Boom and Bart\n  Dhoedt", "title": "Learning Perception and Planning with Deep Active Inference", "comments": "Accepted on ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference is a process theory of the brain that states that all living\norganisms infer actions in order to minimize their (expected) free energy.\nHowever, current experiments are limited to predefined, often discrete, state\nspaces. In this paper we use recent advances in deep learning to learn the\nstate space and approximate the necessary probability distributions to engage\nin active inference.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:27:05 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 12:50:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Verbelen", "Tim", ""], ["Nauta", "Johannes", ""], ["De Boom", "Cedric", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2001.11842", "submitter": "Li Zhang", "authors": "Li Zhang, Yifeng Gao, Jessica Lin", "title": "Semantic Discord: Finding Unusual Local Patterns for Time Series", "comments": "Accepted by SDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding anomalous subsequence in a long time series is a very important but\ndifficult problem. Existing state-of-the-art methods have been focusing on\nsearching for the subsequence that is the most dissimilar to the rest of the\nsubsequences; however, they do not take into account the background patterns\nthat contain the anomalous candidates. As a result, such approaches are likely\nto miss local anomalies. We introduce a new definition named \\textit{semantic\ndiscord}, which incorporates the context information from larger subsequences\ncontaining the anomaly candidates. We propose an efficient algorithm with a\nderived lower bound that is up to 3 orders of magnitude faster than the brute\nforce algorithm in real world data. We demonstrate that our method\nsignificantly outperforms the state-of-the-art methods in locating anomalies by\nextensive experiments. We further explain the interpretability of semantic\ndiscord.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 07:38:17 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 04:38:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Li", ""], ["Gao", "Yifeng", ""], ["Lin", "Jessica", ""]]}, {"id": "2001.11846", "submitter": "Marcos Eduardo Valle", "authors": "Marcos Eduardo Valle and Rodolfo Anibal Lobo", "title": "Quaternion-Valued Recurrent Projection Neural Networks on Unit\n  Quaternions", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.09227", "journal-ref": null, "doi": "10.1016/j.tcs.2020.08.033", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypercomplex-valued neural networks, including quaternion-valued neural\nnetworks, can treat multi-dimensional data as a single entity. In this paper,\nwe present the quaternion-valued recurrent projection neural networks (QRPNNs).\nBriefly, QRPNNs are obtained by combining the non-local projection learning\nwith the quaternion-valued recurrent correlation neural network (QRCNNs). We\nshow that QRPNNs overcome the cross-talk problem of QRCNNs. Thus, they are\nappropriate to implement associative memories. Furthermore, computational\nexperiments reveal that QRPNNs exhibit greater storage capacity and noise\ntolerance than their corresponding QRCNNs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:25:45 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Valle", "Marcos Eduardo", ""], ["Lobo", "Rodolfo Anibal", ""]]}, {"id": "2001.11905", "submitter": "Laurens Devos", "authors": "Laurens Devos, Wannes Meert, Jesse Davis", "title": "Verifying Tree Ensembles by Reasoning about Potential Instances", "comments": "Devos, Laurens, Wannes Meert, and Jesse Davis. \"Verifying tree\n  ensembles by reasoning about potential instances.\" Proceedings of the 2021\n  SIAM International Conference on Data Mining (SDM). Society for Industrial\n  and Applied Mathematics, 2021", "journal-ref": null, "doi": "10.1137/1.9781611976700.51", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine being able to ask questions to a black box model such as \"Which\nadversarial examples exist?\", \"Does a specific attribute have a\ndisproportionate effect on the model's prediction?\" or \"What kind of\npredictions could possibly be made for a partially described example?\" This\nlast question is particularly important if your partial description does not\ncorrespond to any observed example in your data, as it provides insight into\nhow the model will extrapolate to unseen data. These capabilities would be\nextremely helpful as they would allow a user to better understand the model's\nbehavior, particularly as it relates to issues such as robustness, fairness,\nand bias. In this paper, we propose such an approach for an ensemble of trees.\nSince, in general, this task is intractable we present a strategy that (1) can\nprune part of the input space given the question asked to simplify the problem;\nand (2) follows a divide and conquer approach that is incremental and can\nalways return some answers and indicates which parts of the input domains are\nstill uncertain. The usefulness of our approach is shown on a diverse set of\nuse cases.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:31:23 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 13:45:19 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 12:54:32 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Devos", "Laurens", ""], ["Meert", "Wannes", ""], ["Davis", "Jesse", ""]]}, {"id": "2001.11930", "submitter": "Erik Scharw\\\"achter", "authors": "Erik Scharw\\\"achter and Emmanuel M\\\"uller", "title": "Two-Sample Testing for Event Impacts in Time Series", "comments": "SIAM International Conference on Data Mining (SDM 2020) preprint,\n  source code and supplementary material is available at\n  https://github.com/diozaka/eitest", "journal-ref": "Proceedings of the 2020 SIAM International Conference on Data\n  Mining, pp. 10-18", "doi": "10.1137/1.9781611976236.2", "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application domains, time series are monitored to detect extreme\nevents like technical faults, natural disasters, or disease outbreaks.\nUnfortunately, it is often non-trivial to select both a time series that is\ninformative about events and a powerful detection algorithm: detection may fail\nbecause the detection algorithm is not suitable, or because there is no shared\ninformation between the time series and the events of interest. In this work,\nwe thus propose a non-parametric statistical test for shared information\nbetween a time series and a series of observed events. Our test allows\nidentifying time series that carry information on event occurrences without\ncommitting to a specific event detection methodology. In a nutshell, we test\nfor divergences of the value distributions of the time series at increasing\nlags after event occurrences with a multiple two-sample testing approach. In\ncontrast to related tests, our approach is applicable for time series over\narbitrary domains, including multivariate numeric, strings or graphs. We\nperform a large-scale simulation study to show that it outperforms or is on par\nwith related tests on our task for univariate time series. We also demonstrate\nthe real-world applicability of our approach on datasets from social media and\nsmart home environments.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:13:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Scharw\u00e4chter", "Erik", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "2001.11936", "submitter": "Amir Andalib", "authors": "Amir Andalib, Vahid Tabataba Vakili", "title": "An Autonomous Intrusion Detection System Using an Ensemble of Advanced\n  Learners", "comments": "5 pages", "journal-ref": "2020 28th Iranian Conference on Electrical Engineering (ICEE)", "doi": "10.1109/ICEE50131.2020.9260808", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intrusion detection system (IDS) is a vital security component of modern\ncomputer networks. With the increasing amount of sensitive services that use\ncomputer network-based infrastructures, IDSs need to be more intelligent and\nautonomous. Aside from autonomy, another important feature for an IDS is its\nability to detect zero-day attacks. To address these issues, in this paper, we\npropose an IDS which reduces the amount of manual interaction and needed expert\nknowledge and is able to yield acceptable performance under zero-day attacks.\nOur approach is to use three learning techniques in parallel: gated recurrent\nunit (GRU), convolutional neural network as deep techniques and random forest\nas an ensemble technique. These systems are trained in parallel and the results\nare combined under two logics: majority vote and \"OR\" logic. We use the NSL-KDD\ndataset to verify the proficiency of our proposed system. Simulation results\nshow that the system has the potential to operate with a very low technician\ninteraction under the zero-day attacks. We achieved 87:28% accuracy on the\nNSL-KDD's \"KDDTest+\" dataset and 76:61% accuracy on the challenging\n\"KDDTest-21\" with lower training time and lower needed computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:27:29 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 15:25:32 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Andalib", "Amir", ""], ["Vakili", "Vahid Tabataba", ""]]}, {"id": "2001.11940", "submitter": "Basil Saeed", "authors": "Basil Saeed, Snigdha Panigrahi, Caroline Uhler", "title": "Causal Structure Discovery from Distributions Arising from Mixtures of\n  DAGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributions arising from a mixture of causal models, where each\nmodel is represented by a directed acyclic graph (DAG). We provide a graphical\nrepresentation of such mixture distributions and prove that this representation\nencodes the conditional independence relations of the mixture distribution. We\nthen consider the problem of structure learning based on samples from such\ndistributions. Since the mixing variable is latent, we consider causal\nstructure discovery algorithms such as FCI that can deal with latent variables.\nWe show that such algorithms recover a \"union\" of the component DAGs and can\nidentify variables whose conditional distribution across the component DAGs\nvary. We demonstrate our results on synthetic and real data showing that the\ninferred graph identifies nodes that vary between the different mixture\ncomponents. As an immediate application, we demonstrate how retrieval of this\ncausal information can be used to cluster samples according to each mixture\ncomponent.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:33:26 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 15:40:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Saeed", "Basil", ""], ["Panigrahi", "Snigdha", ""], ["Uhler", "Caroline", ""]]}, {"id": "2001.11988", "submitter": "Philippe S\\\"unnen", "authors": "Massimo Fornasier, Hui Huang, Lorenzo Pareschi, Philippe S\\\"unnen", "title": "Consensus-Based Optimization on the Sphere: Convergence to Global\n  Minimizers and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.AP math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the implementation of a new stochastic Kuramoto-Vicsek-type\nmodel for global optimization of nonconvex functions on the sphere. This model\nbelongs to the class of Consensus-Based Optimization. In fact, particles move\non the sphere driven by a drift towards an instantaneous consensus point, which\nis computed as a convex combination of particle locations, weighted by the cost\nfunction according to Laplace's principle, and it represents an approximation\nto a global minimizer. The dynamics is further perturbed by a random vector\nfield to favor exploration, whose variance is a function of the distance of the\nparticles to the consensus point. In particular, as soon as the consensus is\nreached the stochastic component vanishes. The main results of this paper are\nabout the proof of convergence of the numerical scheme to global minimizers\nprovided conditions of well-preparation of the initial datum. The proof\ncombines previous results of mean-field limit with a novel asymptotic analysis,\nand classical convergence results of numerical methods for SDE. We present\nseveral numerical experiments, which show that the algorithm proposed in the\npresent paper scales well with the dimension and is extremely versatile. To\nquantify the performances of the new approach, we show that the algorithm is\nable to perform essentially as good as ad hoc state of the art methods in\nchallenging problems in signal processing and machine learning, namely the\nphase retrieval problem and the robust subspace detection.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:23:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 11:37:45 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 12:56:59 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 10:52:08 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 09:03:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fornasier", "Massimo", ""], ["Huang", "Hui", ""], ["Pareschi", "Lorenzo", ""], ["S\u00fcnnen", "Philippe", ""]]}, {"id": "2001.11990", "submitter": "Serena Wang", "authors": "Serena Wang and Maya Gupta", "title": "Deontological Ethics By Monotonicity Shape Constraints", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how easy it is for modern machine-learned systems to violate\ncommon deontological ethical principles and social norms such as \"favor the\nless fortunate,\" and \"do not penalize good attributes.\" We propose that in some\ncases such ethical principles can be incorporated into a machine-learned model\nby adding shape constraints that constrain the model to respond only positively\nto relevant inputs. We analyze the relationship between these deontological\nconstraints that act on individuals and the consequentialist group-based\nfairness goals of one-sided statistical parity and equal opportunity. This\nstrategy works with sensitive attributes that are Boolean or real-valued such\nas income and age, and can help produce more responsible and trustworthy AI.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:27:27 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 00:20:00 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wang", "Serena", ""], ["Gupta", "Maya", ""]]}, {"id": "2001.12004", "submitter": "Joseph Suarez", "authors": "Joseph Suarez, Yilun Du, Igor Mordatch, Phillip Isola", "title": "Neural MMO v1.3: A Massively Multiagent Game Environment for Training\n  and Evaluating Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in multiagent intelligence research is fundamentally limited by the\nnumber and quality of environments available for study. In recent years,\nsimulated games have become a dominant research platform within reinforcement\nlearning, in part due to their accessibility and interpretability. Previous\nworks have targeted and demonstrated success on arcade, first person shooter\n(FPS), real-time strategy (RTS), and massive online battle arena (MOBA) games.\nOur work considers massively multiplayer online role-playing games (MMORPGs or\nMMOs), which capture several complexities of real-world learning that are not\nwell modeled by any other game genre. We present Neural MMO, a massively\nmultiagent game environment inspired by MMOs and discuss our progress on two\nmore general challenges in multiagent systems engineering for AI research:\ndistributed infrastructure and game IO. We further demonstrate that standard\npolicy gradient methods and simple baseline models can learn interesting\nemergent exploration and specialization behaviors in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:50:02 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 01:58:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Suarez", "Joseph", ""], ["Du", "Yilun", ""], ["Mordatch", "Igor", ""], ["Isola", "Phillip", ""]]}, {"id": "2001.12006", "submitter": "Hrushikesh Mhaskar", "authors": "Charles K. Chui, Ningning Han, Hrushikesh N. Mhaskar", "title": "Theory inspired deep network for instantaneous-frequency extraction and\n  signal components recovery from discrete blind-source data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the inverse problem of recovering the unknown\nsignal components, along with extraction of their instantaneous frequencies\n(IFs), governed by the adaptive harmonic model (AHM), from discrete (and\npossibly non-uniform) samples of the blind-source composite signal.\n  None of the existing decomposition methods and algorithms, including the most\npopular empirical mode decomposition (EMD) computational scheme and its current\nmodifications, is capable of solving this inverse problem.\n  In order to meet the AHM formulation and to extract the IFs of the decomposed\ncomponents, called intrinsic mode functions (IMFs), each IMF of EMD is extended\nto an analytic function in the upper half of the complex plane via the Hilbert\ntransform, followed by taking the real part of the polar form of the analytic\nextension.\n  Unfortunately, this approach most often fails to resolve the inverse problem\nsatisfactorily.\n  More recently, to resolve the inverse problem, the notion of synchrosqueezed\nwavelet transform (SST) was proposed by Daubechies and Maes, and further\ndeveloped in many other papers, while a more direct method, called signal\nseparation operation (SSO), was proposed and developed in our previous work\npublished in the journal, Applied and Computational Harmonic Analysis, vol.\n30(2):243-261, 2016.\n  In the present paper, we propose a synthesis of SSO using a deep neural\nnetwork, based directly on a discrete sample set, that may be non-uniformly\nsampled, of the blind-source signal.\n  Our method is localized, as illustrated by a number of numerical examples,\nincluding components with different signal arrival and departure times.\n  It also yields short-term prediction of the signal components, along with\ntheir IFs.\n  Our neural networks are inspired by theory, designed so that they do not\nrequire any training in the traditional sense.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:54:00 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chui", "Charles K.", ""], ["Han", "Ningning", ""], ["Mhaskar", "Hrushikesh N.", ""]]}, {"id": "2001.12010", "submitter": "Jun-Jie Huang", "authors": "Jun-Jie Huang and Pier Luigi Dragotti", "title": "Learning Deep Analysis Dictionaries for Image Super-Resolution", "comments": "Accepted by IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.3036902", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent success of deep neural networks and the recent efforts\nto develop multi-layer dictionary models, we propose a Deep Analysis dictionary\nModel (DeepAM) which is optimized to address a specific regression task known\nas single image super-resolution. Contrary to other multi-layer dictionary\nmodels, our architecture contains L layers of analysis dictionary and\nsoft-thresholding operators to gradually extract high-level features and a\nlayer of synthesis dictionary which is designed to optimize the regression task\nat hand. In our approach, each analysis dictionary is partitioned into two\nsub-dictionaries: an Information Preserving Analysis Dictionary (IPAD) and a\nClustering Analysis Dictionary (CAD). The IPAD together with the corresponding\nsoft-thresholds is designed to pass the key information from the previous layer\nto the next layer, while the CAD together with the corresponding\nsoft-thresholding operator is designed to produce a sparse feature\nrepresentation of its input data that facilitates discrimination of key\nfeatures. DeepAM uses both supervised and unsupervised setup. Simulation\nresults show that the proposed deep analysis dictionary model achieves better\nperformance compared to a deep neural network that has the same structure and\nis optimized using back-propagation when training datasets are small.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:59:35 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:37:37 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Huang", "Jun-Jie", ""], ["Dragotti", "Pier Luigi", ""]]}]