[{"id": "2008.00025", "submitter": "Rafael Gomes Mantovani", "authors": "Rafael Gomes Mantovani, Andr\\'e Luis Debiaso Rossi, Edesio\n  Alcoba\\c{c}a, Jadson Castro Gertrudes, Sylvio Barbon Junior, Andr\\'e Carlos\n  Ponce de Leon Ferreira de Carvalho", "title": "Rethinking Default Values: a Low Cost and Efficient Strategy to Define\n  Hyperparameters", "comments": "44 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms have been increasingly applied to problems\nfrom several different areas. Despite their growing popularity, their\npredictive performance is usually affected by the values assigned to their\nhyperparameters (HPs). As consequence, researchers and practitioners face the\nchallenge of how to set these values. Many users have limited knowledge about\nML algorithms and the effect of their HP values and, therefore, do not take\nadvantage of suitable settings. They usually define the HP values by trial and\nerror, which is very subjective, not guaranteed to find good values and\ndependent on the user experience. Tuning techniques search for HP values able\nto maximize the predictive performance of induced models for a given dataset,\nbut have the drawback of a high computational cost. Thus, practitioners use\ndefault values suggested by the algorithm developer or by tools implementing\nthe algorithm. Although default values usually result in models with acceptable\npredictive performance, different implementations of the same algorithm can\nsuggest distinct default values. To maintain a balance between tuning and using\ndefault values, we propose a strategy to generate new optimized default values.\nOur approach is grounded on a small set of optimized values able to obtain\npredictive performance values better than default settings provided by popular\ntools. After performing a large experiment and a careful analysis of the\nresults, we concluded that our approach delivers better default values.\nBesides, it leads to competitive solutions when compared to tuned values,\nmaking it easier to use and having a lower cost. We also extracted simple rules\nto guide practitioners in deciding whether to use our new methodology or a HP\ntuning approach.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:23:35 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 18:36:38 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 15:41:53 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mantovani", "Rafael Gomes", ""], ["Rossi", "Andr\u00e9 Luis Debiaso", ""], ["Alcoba\u00e7a", "Edesio", ""], ["Gertrudes", "Jadson Castro", ""], ["Junior", "Sylvio Barbon", ""], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""]]}, {"id": "2008.00029", "submitter": "Ben Adlam", "authors": "Ben Adlam, Jasper Snoek, and Samuel L. Smith", "title": "Cold Posteriors and Aleatoric Uncertainty", "comments": "5 pages, 3 figures", "journal-ref": "ICML workshop on Uncertainty and Robustness in Deep Learning\n  (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has observed that one can outperform exact inference in Bayesian\nneural networks by tuning the \"temperature\" of the posterior on a validation\nset (the \"cold posterior\" effect). To help interpret this phenomenon, we argue\nthat commonly used priors in Bayesian neural networks can significantly\noverestimate the aleatoric uncertainty in the labels on many classification\ndatasets. This problem is particularly pronounced in academic benchmarks like\nMNIST or CIFAR, for which the quality of the labels is high. For the special\ncase of Gaussian process regression, any positive temperature corresponds to a\nvalid posterior under a modified prior, and tuning this temperature is directly\nanalogous to empirical Bayes. On classification tasks, there is no direct\nequivalence between modifying the prior and tuning the temperature, however\nreducing the temperature can lead to models which better reflect our belief\nthat one gains little information by relabeling existing examples in the\ntraining set. Therefore although cold posteriors do not always correspond to an\nexact inference procedure, we believe they may often better reflect our true\nprior beliefs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:37:31 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Adlam", "Ben", ""], ["Snoek", "Jasper", ""], ["Smith", "Samuel L.", ""]]}, {"id": "2008.00047", "submitter": "Bingyin Zhao", "authors": "Bingyin Zhao, Yingjie Lao", "title": "Class-Oriented Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks on machine learning systems compromise the model\nperformance by deliberately injecting malicious samples in the training dataset\nto influence the training process. Prior works focus on either availability\nattacks (i.e., lowering the overall model accuracy) or integrity attacks (i.e.,\nenabling specific instance based backdoor). In this paper, we advance the\nadversarial objectives of the availability attacks to a per-class basis, which\nwe refer to as class-oriented poisoning attacks. We demonstrate that the\nproposed attack is capable of forcing the corrupted model to predict in two\nspecific ways: (i) classify unseen new images to a targeted \"supplanter\" class,\nand (ii) misclassify images from a \"victim\" class while maintaining the\nclassification accuracy on other non-victim classes. To maximize the\nadversarial effect, we propose a gradient-based framework that manipulates the\nlogits to retain/eliminate the desired/undesired feature information in the\ngenerated poisoning images. Using newly defined metrics at the class level, we\nillustrate the effectiveness of the proposed class-oriented poisoning attacks\non various models (e.g., LeNet-5, Vgg-9, and ResNet-50) over a wide range of\ndatasets (e.g., MNIST, CIFAR-10, and ImageNet-ILSVRC2012).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:27:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Bingyin", ""], ["Lao", "Yingjie", ""]]}, {"id": "2008.00051", "submitter": "Sebastian U. Stich", "authors": "Ahmad Ajalloeian and Sebastian U. Stich", "title": "On the Convergence of SGD with Biased Gradients", "comments": "Accepted to ICML 2020 Workshop \"Beyond First Order Methods in ML\n  Systems\", updated 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the complexity of biased stochastic gradient methods (SGD), where\nindividual updates are corrupted by deterministic, i.e. biased error terms. We\nderive convergence results for smooth (non-convex) functions and give improved\nrates under the Polyak-Lojasiewicz condition. We quantify how the magnitude of\nthe bias impacts the attainable accuracy and the convergence rates (sometimes\nleading to divergence).\n  Our framework covers many applications where either only biased gradient\nupdates are available, or preferred, over unbiased ones for performance\nreasons. For instance, in the domain of distributed learning, biased gradient\ncompression techniques such as top-k compression have been proposed as a tool\nto alleviate the communication bottleneck and in derivative-free optimization,\nonly biased gradient estimators can be queried. We discuss a few guiding\nexamples that show the broad applicability of our analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:37:59 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 19:49:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ajalloeian", "Ahmad", ""], ["Stich", "Sebastian U.", ""]]}, {"id": "2008.00103", "submitter": "Peter Christen", "authors": "David J. Hand, Peter Christen, Nishadi Kirielle", "title": "F*: An Interpretable Transformation of the F-measure", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-measure, also known as the F1-score, is widely used to assess the\nperformance of classification algorithms. However, some researchers find it\nlacking in intuitive interpretation, questioning the appropriateness of\ncombining two aspects of performance as conceptually distinct as precision and\nrecall, and also questioning whether the harmonic mean is the best way to\ncombine them. To ease this concern, we describe a simple transformation of the\nF-measure, which we call F* (F-star), which has an immediate practical\ninterpretation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:37:08 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 22:26:20 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 02:03:47 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hand", "David J.", ""], ["Christen", "Peter", ""], ["Kirielle", "Nishadi", ""]]}, {"id": "2008.00104", "submitter": "Elliot Creager", "authors": "Martin Mladenov, Elliot Creager, Omer Ben-Porat, Kevin Swersky,\n  Richard Zemel, Craig Boutilier", "title": "Optimizing Long-term Social Welfare in Recommender Systems: A\n  Constrained Matching Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recommender systems (RS) research assumes that a user's utility can be\nmaximized independently of the utility of the other agents (e.g., other users,\ncontent providers). In realistic settings, this is often not true---the\ndynamics of an RS ecosystem couple the long-term utility of all agents. In this\nwork, we explore settings in which content providers cannot remain viable\nunless they receive a certain level of user engagement. We formulate the\nrecommendation problem in this setting as one of equilibrium selection in the\ninduced dynamical system, and show that it can be solved as an optimal\nconstrained matching problem. Our model ensures the system reaches an\nequilibrium with maximal social welfare supported by a sufficiently diverse set\nof viable providers. We demonstrate that even in a simple, stylized dynamical\nRS model, the standard myopic approach to recommendation---always matching a\nuser to the best provider---performs poorly. We develop several scalable\ntechniques to solve the matching problem, and also draw connections to various\nnotions of user regret and fairness, arguing that these outcomes are fairer in\na utilitarian sense.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:40:47 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 20:57:28 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Mladenov", "Martin", ""], ["Creager", "Elliot", ""], ["Ben-Porat", "Omer", ""], ["Swersky", "Kevin", ""], ["Zemel", "Richard", ""], ["Boutilier", "Craig", ""]]}, {"id": "2008.00123", "submitter": "Dane Taylor", "authors": "N. Benjamin Erichson, Dane Taylor, Qixuan Wu and Michael W. Mahoney", "title": "Noise-Response Analysis of Deep Neural Networks Quantifies Robustness\n  and Fingerprints Structural Malware", "comments": "9 pages, 7 figures, accepted to the SIAM International Conference on\n  Data Mining (SDM 21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of deep neural networks (DNNs), cloud-based training, and\ntransfer learning is giving rise to a new cybersecurity frontier in which\nunsecure DNNs have `structural malware' (i.e., compromised weights and\nactivation pathways). In particular, DNNs can be designed to have backdoors\nthat allow an adversary to easily and reliably fool an image classifier by\nadding a pattern of pixels called a trigger. It is generally difficult to\ndetect backdoors, and existing detection methods are computationally expensive\nand require extensive resources (e.g., access to the training data). Here, we\npropose a rapid feature-generation technique that quantifies the robustness of\na DNN, `fingerprints' its nonlinearity, and allows us to detect backdoors (if\npresent). Our approach involves studying how a DNN responds to noise-infused\nimages with varying noise intensity, which we summarize with titration curves.\nWe find that DNNs with backdoors are more sensitive to input noise and respond\nin a characteristic way that reveals the backdoor and where it leads (its\n`target'). Our empirical results demonstrate that we can accurately detect\nbackdoors with high confidence orders-of-magnitude faster than existing\napproaches (seconds versus hours).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:52:58 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 19:51:30 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Taylor", "Dane", ""], ["Wu", "Qixuan", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2008.00138", "submitter": "Alexander Wong", "authors": "Hossein Aboutalebi, Mohammad Javad Shafiee, Michelle Karg, Christian\n  Scharfenberger, and Alexander Wong", "title": "Vulnerability Under Adversarial Machine Learning: Bias or Variance?", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior studies have unveiled the vulnerability of the deep neural networks in\nthe context of adversarial machine learning, leading to great recent attention\ninto this area. One interesting question that has yet to be fully explored is\nthe bias-variance relationship of adversarial machine learning, which can\npotentially provide deeper insights into this behaviour. The notion of bias and\nvariance is one of the main approaches to analyze and evaluate the\ngeneralization and reliability of a machine learning model. Although it has\nbeen extensively used in other machine learning models, it is not well explored\nin the field of deep learning and it is even less explored in the area of\nadversarial machine learning.\n  In this study, we investigate the effect of adversarial machine learning on\nthe bias and variance of a trained deep neural network and analyze how\nadversarial perturbations can affect the generalization of a network. We derive\nthe bias-variance trade-off for both classification and regression applications\nbased on two main loss functions: (i) mean squared error (MSE), and (ii)\ncross-entropy. Furthermore, we perform quantitative analysis with both\nsimulated and real data to empirically evaluate consistency with the derived\nbias-variance tradeoffs. Our analysis sheds light on why the deep neural\nnetworks have poor performance under adversarial perturbation from a\nbias-variance point of view and how this type of perturbation would change the\nperformance of a network. Moreover, given these new theoretical findings, we\nintroduce a new adversarial machine learning algorithm with lower computational\ncomplexity than well-known adversarial machine learning strategies (e.g., PGD)\nwhile providing a high success rate in fooling deep neural networks in lower\nperturbation magnitudes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 00:58:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Shafiee", "Mohammad Javad", ""], ["Karg", "Michelle", ""], ["Scharfenberger", "Christian", ""], ["Wong", "Alexander", ""]]}, {"id": "2008.00163", "submitter": "Avanti Athreya", "authors": "Konstantinos Pantazis, Avanti Athreya, Jes\\'us Arroyo, William N.\n  Frost, Evan S. Hill, and Vince Lyzinski", "title": "The Importance of Being Correlated: Implications of Dependence in Joint\n  Spectral Inference across Multiple Networks", "comments": "44 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral inference on multiple networks is a rapidly-developing subfield of\ngraph statistics. Recent work has demonstrated that joint, or simultaneous,\nspectral embedding of multiple independent networks can deliver more accurate\nestimation than individual spectral decompositions of those same networks. Such\ninference procedures typically rely heavily on independence assumptions across\nthe multiple network realizations, and even in this case, little attention has\nbeen paid to the induced network correlation in such joint embeddings. Here, we\npresent a generalized omnibus embedding methodology and provide a detailed\nanalysis of this embedding across both independent and correlated networks, the\nlatter of which significantly extends the reach of such procedures. We describe\nhow this omnibus embedding can itself induce correlation, leading us to\ndistinguish between inherent correlation -- the correlation that arises\nnaturally in multisample network data -- and induced correlation, which is an\nartifice of the joint embedding methodology. We show that the generalized\nomnibus embedding procedure is flexible and robust, and prove both consistency\nand a central limit theorem for the embedded points. We examine how induced and\ninherent correlation can impact inference for network time series data, and we\nprovide network analogues of classical questions such as the effective sample\nsize for more generally correlated data. Further, we show how an appropriately\ncalibrated generalized omnibus embedding can detect changes in real biological\nnetworks that previous embedding procedures could not discern, confirming that\nthe effect of inherent and induced correlation can be subtle and\ntransformative, with import in theory and practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:43:52 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 05:19:14 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 17:10:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Pantazis", "Konstantinos", ""], ["Athreya", "Avanti", ""], ["Arroyo", "Jes\u00fas", ""], ["Frost", "William N.", ""], ["Hill", "Evan S.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "2008.00177", "submitter": "Xin Li", "authors": "Jiahuang Lin, Xin Li, Gennady Pekhimenko", "title": "Multi-node Bert-pretraining: Cost-efficient Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large scale Transformer-based language models such as BERT, GPT-2,\nand XLNet have brought about exciting leaps in state-of-the-art results for\nmany Natural Language Processing (NLP) tasks. One of the common trends in these\nrecent models is a significant increase in model complexity, which introduces\nboth more weights and computation. Moreover, with the advent of large-scale\nunsupervised datasets, training time is further extended due to the increased\namount of data samples within a single training epoch. As a result, to train\nthese models within a reasonable time, machine learning (ML) programmers often\nrequire advanced hardware setups such as the premium GPU-enabled NVIDIA DGX\nworkstations or specialized accelerators such as Google's TPU Pods. Our work\naddresses this limitation and demonstrates that the BERT pre-trained model can\nbe trained within 2 weeks on an academic-size cluster of widely available GPUs\nthrough careful algorithmic and software optimizations. In this paper, we\npresent these optimizations on how to improve single device training\nthroughput, distribute the training workload over multiple nodes and GPUs, and\novercome the communication bottleneck introduced by the large data exchanges\nover the network. We show that we are able to perform pre-training on BERT\nwithin a reasonable time budget (12 days) in an academic setting, but with a\nmuch less expensive and less aggressive hardware resource requirement than in\npreviously demonstrated industrial settings based on NVIDIA DGX machines or\nGoogle's TPU Pods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:49:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lin", "Jiahuang", ""], ["Li", "Xin", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "2008.00234", "submitter": "Fabio Angelo Maccheroni", "authors": "Carlo Baldassi, Fabio Maccheroni, Massimo Marinacci, Marco Pirazzini", "title": "Ergodic Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.TH math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulated Annealing is the crowning glory of Markov Chain Monte Carlo Methods\nfor the solution of NP-hard optimization problems in which the cost function is\nknown. Here, by replacing the Metropolis engine of Simulated Annealing with a\nreinforcement learning variation -- that we call Macau Algorithm -- we show\nthat the Simulated Annealing heuristic can be very effective also when the cost\nfunction is unknown and has to be learned by an artificial agent.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 10:17:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Baldassi", "Carlo", ""], ["Maccheroni", "Fabio", ""], ["Marinacci", "Massimo", ""], ["Pirazzini", "Marco", ""]]}, {"id": "2008.00235", "submitter": "Alessandra Cabassi", "authors": "Alessandra Cabassi, Denis Seyres, Mattia Frontini, Paul D. W. Kirk", "title": "Two-step penalised logistic regression for multi-omic data with an\n  application to cardiometabolic syndrome", "comments": "Manuscript: 22 pages, 6 figures. Supplement: 24 pages, 20 figures.\n  For associated R code, see\n  https://github.com/acabassi/logistic-regression-for-multi-omic-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building classification models that predict a binary class label on the basis\nof high dimensional multi-omics datasets poses several challenges, due to the\ntypically widely differing characteristics of the data layers in terms of\nnumber of predictors, type of data, and levels of noise. Previous research has\nshown that applying classical logistic regression with elastic-net penalty to\nthese datasets can lead to poor results (Liu et al., 2018). We implement a\ntwo-step approach to multi-omic logistic regression in which variable selection\nis performed on each layer separately and a predictive model is then built\nusing the variables selected in the first step. Here, our approach is compared\nto other methods that have been developed for the same purpose, and we adapt\nexisting software for multi-omic linear regression (Zhao and Zucknick, 2020) to\nthe logistic regression setting. Extensive simulation studies show that our\napproach should be preferred if the goal is to select as many relevant\npredictors as possible, as well as achieving prediction performances comparable\nto those of the best competitors. Our motivating example is a cardiometabolic\nsyndrome dataset comprising eight 'omic data types for 2 extreme phenotype\ngroups (10 obese and 10 lipodystrophy individuals) and 185 blood donors. Our\nproposed approach allows us to identify features that characterise\ncardiometabolic syndrome at the molecular level. R code is available at\nhttps://github.com/acabassi/logistic-regression-for-multi-omic-data.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 10:36:27 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cabassi", "Alessandra", ""], ["Seyres", "Denis", ""], ["Frontini", "Mattia", ""], ["Kirk", "Paul D. W.", ""]]}, {"id": "2008.00311", "submitter": "Aria HasanzadeZonuzy", "authors": "Aria HasanzadeZonuzy, Archana Bura, Dileep Kalathil and Srinivas\n  Shakkottai", "title": "Learning with Safety Constraints: Sample Complexity of Reinforcement\n  Learning for Constrained MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many physical systems have underlying safety considerations that require that\nthe policy employed ensures the satisfaction of a set of constraints. The\nanalytical formulation usually takes the form of a Constrained Markov Decision\nProcess (CMDP). We focus on the case where the CMDP is unknown, and RL\nalgorithms obtain samples to discover the model and compute an optimal\nconstrained policy. Our goal is to characterize the relationship between safety\nconstraints and the number of samples needed to ensure a desired level of\naccuracy -- both objective maximization and constraint satisfaction -- in a PAC\nsense. We explore two classes of RL algorithms, namely, (i) a generative model\nbased approach, wherein samples are taken initially to estimate a model, and\n(ii) an online approach, wherein the model is updated as samples are obtained.\nOur main finding is that compared to the best known bounds of the unconstrained\nregime, the sample complexity of constrained RL algorithms are increased by a\nfactor that is logarithmic in the number of constraints, which suggests that\nthe approach may be easily utilized in real systems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 18:17:08 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 03:06:54 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 20:51:27 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["HasanzadeZonuzy", "Aria", ""], ["Bura", "Archana", ""], ["Kalathil", "Dileep", ""], ["Shakkottai", "Srinivas", ""]]}, {"id": "2008.00323", "submitter": "David Burt", "authors": "David R. Burt and Carl Edward Rasmussen and Mark van der Wilk", "title": "Convergence of Sparse Variational Inference in Gaussian Processes\n  Regression", "comments": "Extended version of http://proceedings.mlr.press/v97/burt19a.html\n  (arxiv version: arXiv:1903.03571 ). Published in Journal of Machine Learning\n  Research: http://jmlr.org/papers/v21/19-1015.html. Code available at:\n  https://github.com/markvdw/RobustGP", "journal-ref": "Journal of Machine Learning Research, 21(131), 1-63 (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are distributions over functions that are versatile and\nmathematically convenient priors in Bayesian modelling. However, their use is\noften impeded for data with large numbers of observations, $N$, due to the\ncubic (in $N$) cost of matrix operations used in exact inference. Many\nsolutions have been proposed that rely on $M \\ll N$ inducing variables to form\nan approximation at a cost of $\\mathcal{O}(NM^2)$. While the computational cost\nappears linear in $N$, the true complexity depends on how $M$ must scale with\n$N$ to ensure a certain quality of the approximation. In this work, we\ninvestigate upper and lower bounds on how $M$ needs to grow with $N$ to ensure\nhigh quality approximations. We show that we can make the KL-divergence between\nthe approximate model and the exact posterior arbitrarily small for a\nGaussian-noise regression model with $M\\ll N$. Specifically, for the popular\nsquared exponential kernel and $D$-dimensional Gaussian distributed covariates,\n$M=\\mathcal{O}((\\log N)^D)$ suffice and a method with an overall computational\ncost of $\\mathcal{O}(N(\\log N)^{2D}(\\log\\log N)^2)$ can be used to perform\ninference.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 19:23:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Burt", "David R.", ""], ["Rasmussen", "Carl Edward", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2008.00325", "submitter": "Corey Nolet", "authors": "Corey J. Nolet, Victor Lafargue, Edward Raff, Thejaswi Nanditale, Tim\n  Oates, John Zedlewski, Joshua Patterson", "title": "Bringing UMAP Closer to the Speed of Light with GPU Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Uniform Manifold Approximation and Projection (UMAP) algorithm has become\nwidely popular for its ease of use, quality of results, and support for\nexploratory, unsupervised, supervised, and semi-supervised learning. While many\nalgorithms can be ported to a GPU in a simple and direct fashion, such efforts\nhave resulted in inefficient and inaccurate versions of UMAP. We show a number\nof techniques that can be used to make a faster and more faithful GPU version\nof UMAP, and obtain speedups of up to 100x in practice. Many of these design\nchoices/lessons are general purpose and may inform the conversion of other\ngraph and manifold learning algorithms to use GPUs. Our implementation has been\nmade publicly available as part of the open source RAPIDS cuML library\n(https://github.com/rapidsai/cuml).\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 19:35:56 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 02:27:07 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 09:15:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Nolet", "Corey J.", ""], ["Lafargue", "Victor", ""], ["Raff", "Edward", ""], ["Nanditale", "Thejaswi", ""], ["Oates", "Tim", ""], ["Zedlewski", "John", ""], ["Patterson", "Joshua", ""]]}, {"id": "2008.00331", "submitter": "Anupama Nandi", "authors": "Raef Bassily, Shay Moran and Anupama Nandi", "title": "Learning from Mixtures of Private and Public Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of a new model of supervised learning under privacy\nconstraints. Imagine a medical study where a dataset is sampled from a\npopulation of both healthy and unhealthy individuals. Suppose healthy\nindividuals have no privacy concerns (in such case, we call their data\n\"public\") while the unhealthy individuals desire stringent privacy protection\nfor their data. In this example, the population (data distribution) is a\nmixture of private (unhealthy) and public (healthy) sub-populations that could\nbe very different.\n  Inspired by the above example, we consider a model in which the population\n$\\mathcal{D}$ is a mixture of two sub-populations: a private sub-population\n$\\mathcal{D}_{\\sf priv}$ of private and sensitive data, and a public\nsub-population $\\mathcal{D}_{\\sf pub}$ of data with no privacy concerns. Each\nexample drawn from $\\mathcal{D}$ is assumed to contain a privacy-status bit\nthat indicates whether the example is private or public. The goal is to design\na learning algorithm that satisfies differential privacy only with respect to\nthe private examples.\n  Prior works in this context assumed a homogeneous population where private\nand public data arise from the same distribution, and in particular designed\nsolutions which exploit this assumption. We demonstrate how to circumvent this\nassumption by considering, as a case study, the problem of learning linear\nclassifiers in $\\mathbb{R}^d$. We show that in the case where the privacy\nstatus is correlated with the target label (as in the above example), linear\nclassifiers in $\\mathbb{R}^d$ can be learned, in the agnostic as well as the\nrealizable setting, with sample complexity which is comparable to that of the\nclassical (non-private) PAC-learning. It is known that this task is impossible\nif all the data is considered private.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:11:50 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bassily", "Raef", ""], ["Moran", "Shay", ""], ["Nandi", "Anupama", ""]]}, {"id": "2008.00357", "submitter": "Aria Khademi", "authors": "Aria Khademi, Vasant Honavar", "title": "A Causal Lens for Peeking into Black Box Predictive Models: Predictive\n  Model Interpretation via Causal Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of predictive models trained using machine\nlearning across a wide range of high-stakes applications, e.g., health care,\nsecurity, criminal justice, finance, and education, there is a growing need for\neffective techniques for explaining such models and their predictions. We aim\nto address this problem in settings where the predictive model is a black box;\nThat is, we can only observe the response of the model to various inputs, but\nhave no knowledge about the internal structure of the predictive model, its\nparameters, the objective function, and the algorithm used to optimize the\nmodel. We reduce the problem of interpreting a black box predictive model to\nthat of estimating the causal effects of each of the model inputs on the model\noutput, from observations of the model inputs and the corresponding outputs. We\nestimate the causal effects of model inputs on model output using variants of\nthe Rubin Neyman potential outcomes framework for estimating causal effects\nfrom observational data. We show how the resulting causal attribution of\nresponsibility for model output to the different model inputs can be used to\ninterpret the predictive model and to explain its predictions. We present\nresults of experiments that demonstrate the effectiveness of our approach to\nthe interpretation of black box predictive models via causal attribution in the\ncase of deep neural network models trained on one synthetic data set (where the\ninput variables that impact the output variable are known by design) and two\nreal-world data sets: Handwritten digit classification, and Parkinson's disease\nseverity prediction. Because our approach does not require knowledge about the\npredictive model algorithm and is free of assumptions regarding the black box\npredictive model except that its input-output responses be observable, it can\nbe applied, in principle, to any black box predictive model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 23:20:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Khademi", "Aria", ""], ["Honavar", "Vasant", ""]]}, {"id": "2008.00386", "submitter": "Franck Dernoncourt", "authors": "Lidan Wang, Franck Dernoncourt, Trung Bui", "title": "Bayesian Optimization for Selecting Efficient Machine Learning Models", "comments": "Published at CIKM MoST-Rec 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The performance of many machine learning models depends on their\nhyper-parameter settings. Bayesian Optimization has become a successful tool\nfor hyper-parameter optimization of machine learning algorithms, which aims to\nidentify optimal hyper-parameters during an iterative sequential process.\nHowever, most of the Bayesian Optimization algorithms are designed to select\nmodels for effectiveness only and ignore the important issue of model training\nefficiency. Given that both model effectiveness and training time are important\nfor real-world applications, models selected for effectiveness may not meet the\nstrict training time requirements necessary to deploy in a production\nenvironment. In this work, we present a unified Bayesian Optimization framework\nfor jointly optimizing models for both prediction effectiveness and training\nefficiency. We propose an objective that captures the tradeoff between these\ntwo metrics and demonstrate how we can jointly optimize them in a principled\nBayesian Optimization framework. Experiments on model selection for\nrecommendation tasks indicate models selected this way significantly improves\nmodel training efficiency while maintaining strong effectiveness as compared to\nstate-of-the-art Bayesian Optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 02:56:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Lidan", ""], ["Dernoncourt", "Franck", ""], ["Bui", "Trung", ""]]}, {"id": "2008.00404", "submitter": "Yixin Su", "authors": "Yixin Su, Rui Zhang, Sarah Erfani, Zhenghua Xu", "title": "Detecting Beneficial Feature Interactions for Recommender Systems", "comments": "14 pages, 7 figures, 5 tables, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature interactions are essential for achieving high accuracy in recommender\nsystems. Many studies take into account the interaction between every pair of\nfeatures. However, this is suboptimal because some feature interactions may not\nbe that relevant to the recommendation result, and taking them into account may\nintroduce noise and decrease recommendation accuracy. To make the best out of\nfeature interactions, we propose a graph neural network approach to effectively\nmodel them, together with a novel technique to automatically detect those\nfeature interactions that are beneficial in terms of recommendation accuracy.\nThe automatic feature interaction detection is achieved via edge prediction\nwith an L0 activation regularization. Our proposed model is proved to be\neffective through the information bottleneck principle and statistical\ninteraction theory. Experimental results show that our model (i) outperforms\nexisting baselines in terms of accuracy, and (ii) automatically identifies\nbeneficial feature interactions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:08:23 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 04:51:57 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 02:23:31 GMT"}, {"version": "v4", "created": "Sat, 2 Jan 2021 06:37:45 GMT"}, {"version": "v5", "created": "Tue, 30 Mar 2021 00:47:40 GMT"}, {"version": "v6", "created": "Tue, 18 May 2021 11:57:21 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Su", "Yixin", ""], ["Zhang", "Rui", ""], ["Erfani", "Sarah", ""], ["Xu", "Zhenghua", ""]]}, {"id": "2008.00410", "submitter": "Yashesh Dhebar", "authors": "Yashesh Dhebar and Kalyanmoy Deb", "title": "Interpretable Rule Discovery Through Bilevel Optimization of Split-Rules\n  of Nonlinear Decision Trees for Classification Problems", "comments": "Total 26 pages and 30 figures. Main Paper: 12 pages, 12 figures.\n  Supplementary Document: 14 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For supervised classification problems involving design, control, other\npractical purposes, users are not only interested in finding a highly accurate\nclassifier, but they also demand that the obtained classifier be easily\ninterpretable. While the definition of interpretability of a classifier can\nvary from case to case, here, by a humanly interpretable classifier we restrict\nit to be expressed in simplistic mathematical terms. As a novel approach, we\nrepresent a classifier as an assembly of simple mathematical rules using a\nnon-linear decision tree (NLDT). Each conditional (non-terminal) node of the\ntree represents a non-linear mathematical rule (split-rule) involving features\nin order to partition the dataset in the given conditional node into two\nnon-overlapping subsets. This partitioning is intended to minimize the impurity\nof the resulting child nodes. By restricting the structure of split-rule at\neach conditional node and depth of the decision tree, the interpretability of\nthe classifier is assured. The non-linear split-rule at a given conditional\nnode is obtained using an evolutionary bilevel optimization algorithm, in which\nwhile the upper-level focuses on arriving at an interpretable structure of the\nsplit-rule, the lower-level achieves the most appropriate weights\n(coefficients) of individual constituents of the rule to minimize the net\nimpurity of two resulting child nodes. The performance of the proposed\nalgorithm is demonstrated on a number of controlled test problems, existing\nbenchmark problems, and industrial problems. Results on two to 500-feature\nproblems are encouraging and open up further scopes of applying the proposed\napproach to more challenging and complex classification tasks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:35:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Dhebar", "Yashesh", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2008.00422", "submitter": "Themistoklis Botsas", "authors": "Themistoklis Botsas, Lachlan R. Mason and Indranil Pan", "title": "Rule-based Bayesian regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel rule-based approach for handling regression problems.\nThe new methodology carries elements from two frameworks: (i) it provides\ninformation about the uncertainty of the parameters of interest using Bayesian\ninference, and (ii) it allows the incorporation of expert knowledge through\nrule-based systems. The blending of those two different frameworks can be\nparticularly beneficial for various domains (e.g. engineering), where, even\nthough the significance of uncertainty quantification motivates a Bayesian\napproach, there is no simple way to incorporate researcher intuition into the\nmodel. We validate our models by applying them to synthetic applications: a\nsimple linear regression problem and two more complex structures based on\npartial differential equations. Finally, we review the advantages of our\nmethodology, which include the simplicity of the implementation, the\nuncertainty reduction due to the added information and, in some occasions, the\nderivation of better point predictions, and we address limitations, mainly from\nthe computational complexity perspective, such as the difficulty in choosing an\nappropriate algorithm and the added computational burden.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 07:20:45 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Botsas", "Themistoklis", ""], ["Mason", "Lachlan R.", ""], ["Pan", "Indranil", ""]]}, {"id": "2008.00444", "submitter": "Pablo Montero Manso", "authors": "Pablo Montero-Manso and Rob J Hyndman", "title": "Principles and Algorithms for Forecasting Groups of Time Series:\n  Locality and Globality", "comments": "version preprint IJF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting groups of time series is of increasing practical importance, e.g.\nforecasting the demand for multiple products offered by a retailer or server\nloads within a data center. The local approach to this problem considers each\ntime series separately and fits a function or model to each series. The global\napproach fits a single function to all series. For groups of similar time\nseries, global methods outperform the more established local methods. However,\nrecent results show good performance of global models even in heterogeneous\ndatasets. This suggests a more general applicability of global methods,\npotentially leading to more accurate tools and new scenarios to study.\n  Formalizing the setting of forecasting a set of time series with local and\nglobal methods, we provide the following contributions:\n  1) Global methods are not more restrictive than local methods, both can\nproduce the same forecasts without any assumptions about similarity of the\nseries. Global models can succeed in a wider range of problems than previously\nthought.\n  2) Basic generalization bounds for local and global algorithms. The\ncomplexity of local methods grows with the size of the set while it remains\nconstant for global methods. In large datasets, a global algorithm can afford\nto be quite complex and still benefit from better generalization. These bounds\nserve to clarify and support recent experimental results in the field, and\nguide the design of new algorithms. For the class of autoregressive models,\nthis implies that global models can have much larger memory than local methods.\n  3) In an extensive empirical study, purposely naive algorithms derived from\nthese principles, such as global linear models or deep networks result in\nsuperior accuracy.\n  In particular, global linear models can provide competitive accuracy with two\norders of magnitude fewer parameters than local methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 10:22:05 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 07:37:02 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 23:34:48 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Montero-Manso", "Pablo", ""], ["Hyndman", "Rob J", ""]]}, {"id": "2008.00483", "submitter": "Zuyue Fu", "authors": "Zuyue Fu, Zhuoran Yang, Zhaoran Wang", "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the global convergence and global optimality of actor-critic, one of\nthe most popular families of reinforcement learning algorithms. While most\nexisting works on actor-critic employ bi-level or two-timescale updates, we\nfocus on the more practical single-timescale setting, where the actor and\ncritic are updated simultaneously. Specifically, in each iteration, the critic\nupdate is obtained by applying the Bellman evaluation operator only once while\nthe actor is updated in the policy gradient direction computed using the\ncritic. Moreover, we consider two function approximation settings where both\nthe actor and critic are represented by linear or deep neural networks. For\nboth cases, we prove that the actor sequence converges to a globally optimal\npolicy at a sublinear $O(K^{-1/2})$ rate, where $K$ is the number of\niterations. To the best of our knowledge, we establish the rate of convergence\nand global optimality of single-timescale actor-critic with linear function\napproximation for the first time. Moreover, under the broader scope of policy\noptimization with nonlinear function approximation, we prove that actor-critic\nwith deep neural network finds the globally optimal policy at a sublinear rate\nfor the first time.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 14:01:49 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 05:25:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fu", "Zuyue", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2008.00500", "submitter": "Zhide Wang", "authors": "Yanling Chang and Alfredo Garcia and Zhide Wang", "title": "Dynamic Discrete Choice Estimation with Partially Observable States and\n  Hidden Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic discrete choice models are used to estimate the intertemporal\npreferences of an agent as described by a reward function based upon observable\nhistories of states and implemented actions. However, in many applications,\nsuch as reliability and healthcare, the system state is only partially\nobservable or hidden (e.g., the level of deterioration of an engine, the\ncondition of a disease), and the decision maker only has access to information\nimperfectly correlated with the true value of the hidden state. In this paper,\nwe consider the estimation of a dynamic discrete choice model with state\nvariables and system dynamics hidden to both the agent and the modeler, thus\ngeneralizing the model in Rust(1987) to partially observable cases. We examine\nthe structural properties of the model and prove that this model is still\nidentifiable if the cardinality of the state space, the discount factor, the\ndistribution of random shocks, and the rewards for a given (reference) action\nare given. We analyze both theoretically and numerically the potential\nmis-specification errors that may be incurred when the Rust's model is\nimproperly used in partially observable settings. We further apply the model to\na subset of dataset in Rust(1987) for bus engine mileage and replacement\ndecisions. The results show that our model can improve model fit as measured by\nthe $\\log$-likelihood function by $17.73\\%$ and the $\\log$-likelihood ratio\ntest shows that our model statistically outperforms the Rust's model.\nInterestingly, our hidden state model also reveals an economically meaningful\nroute assignment behavior in the dataset which was hitherto ignored, i.e.\nroutes with lower mileage are assigned to buses believed to be in worse\ncondition.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 15:04:27 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 20:22:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chang", "Yanling", ""], ["Garcia", "Alfredo", ""], ["Wang", "Zhide", ""]]}, {"id": "2008.00504", "submitter": "John Martin Jr", "authors": "John D. Martin, Kevin Doherty, Caralyn Cyr, Brendan Englot, John\n  Leonard", "title": "Variational Filtering with Copula Models for SLAM", "comments": "Published at the 2020 International Conference on Intelligent Robots\n  and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to infer map variables and estimate pose is crucial to the\noperation of autonomous mobile robots. In most cases the shared dependency\nbetween these variables is modeled through a multivariate Gaussian\ndistribution, but there are many situations where that assumption is\nunrealistic. Our paper shows how it is possible to relax this assumption and\nperform simultaneous localization and mapping (SLAM) with a larger class of\ndistributions, whose multivariate dependency is represented with a copula\nmodel. We integrate the distribution model with copulas into a Sequential Monte\nCarlo estimator and show how unknown model parameters can be learned through\ngradient-based optimization. We demonstrate our approach is effective in\nsettings where Gaussian assumptions are clearly violated, such as environments\nwith uncertain data association and nonlinear transition models.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 15:38:23 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Martin", "John D.", ""], ["Doherty", "Kevin", ""], ["Cyr", "Caralyn", ""], ["Englot", "Brendan", ""], ["Leonard", "John", ""]]}, {"id": "2008.00511", "submitter": "Andrea Bassich", "authors": "Andrea Bassich, Francesco Foglino, Matteo Leonetti and Daniel Kudenko", "title": "Curriculum Learning with a Progression Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum Learning for Reinforcement Learning is an increasingly popular\ntechnique that involves training an agent on a defined sequence of intermediate\ntasks, called a Curriculum, to increase the agent's performance and learning\nspeed. This paper introduces a novel paradigm for automatic curriculum\ngeneration based on a progression of task complexity. Different progression\nfunctions are introduced, including an autonomous online task progression based\non the performance of the agent. The progression function also determines how\nlong the agent should train on each intermediate task, which is an open problem\nin other task-based curriculum approaches. The benefits and wide applicability\nof our approach are shown by empirically comparing its performance to two\nstate-of-the-art Curriculum Learning algorithms on a grid world and on a\ncomplex simulated navigation domain.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 16:18:41 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bassich", "Andrea", ""], ["Foglino", "Francesco", ""], ["Leonetti", "Matteo", ""], ["Kudenko", "Daniel", ""]]}, {"id": "2008.00546", "submitter": "Janith C. Petangoda", "authors": "Janith Petangoda, Nick A. M. Monk and Marc Peter Deisenroth", "title": "A Foliated View of Transfer Learning", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning considers a learning process where a new task is solved by\ntransferring relevant knowledge from known solutions to related tasks. While\nthis has been studied experimentally, there lacks a foundational description of\nthe transfer learning problem that exposes what related tasks are, and how they\ncan be exploited. In this work, we present a definition for relatedness between\ntasks and identify foliations as a mathematical framework to represent such\nrelationships.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 19:30:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Petangoda", "Janith", ""], ["Monk", "Nick A. M.", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2008.00565", "submitter": "Georgios Arvanitidis", "authors": "Georgios Arvanitidis, S{\\o}ren Hauberg, Bernhard Sch\\\"olkopf", "title": "Geometrically Enriched Latent Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in generative models is that the generator immerses the\nlatent space into a Euclidean ambient space. Instead, we consider the ambient\nspace to be a Riemannian manifold, which allows for encoding domain knowledge\nthrough the associated Riemannian metric. Shortest paths can then be defined\naccordingly in the latent space to both follow the learned manifold and respect\nthe ambient geometry. Through careful design of the ambient metric we can\nensure that shortest paths are well-behaved even for deterministic generators\nthat otherwise would exhibit a misleading bias. Experimentally we show that our\napproach improves interpretability of learned representations both using\nstochastic and deterministic generators.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 20:57:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Arvanitidis", "Georgios", ""], ["Hauberg", "S\u00f8ren", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2008.00614", "submitter": "Xingyu Lu", "authors": "Xingyu Lu, Kimin Lee, Pieter Abbeel, Stas Tiomkin", "title": "Dynamics Generalization via Information Bottleneck in Deep Reinforcement\n  Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress of deep reinforcement learning (RL) in\nsolving sequential decision making problems, RL agents often overfit to\ntraining environments and struggle to adapt to new, unseen environments. This\nprevents robust applications of RL in real world situations, where system\ndynamics may deviate wildly from the training settings. In this work, our\nprimary contribution is to propose an information theoretic regularization\nobjective and an annealing-based optimization method to achieve better\ngeneralization ability in RL agents. We demonstrate the extreme generalization\nbenefits of our approach in different domains ranging from maze navigation to\nrobotic tasks; for the first time, we show that agents can generalize to test\nparameters more than 10 standard deviations away from the training parameter\ndistribution. This work provides a principled way to improve generalization in\nRL by gradually removing information that is redundant for task-solving; it\nopens doors for the systematic study of generalization from training to\nextremely different testing settings, focusing on the established connections\nbetween information theory and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 02:24:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lu", "Xingyu", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Tiomkin", "Stas", ""]]}, {"id": "2008.00638", "submitter": "Dibakar Gope", "authors": "Dibakar Gope, Jesse Beu, Matthew Mattina", "title": "High Throughput Matrix-Matrix Multiplication between Asymmetric\n  Bit-Width Operands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix multiplications between asymmetric bit-width operands, especially\nbetween 8- and 4-bit operands are likely to become a fundamental kernel of many\nimportant workloads including neural networks and machine learning. While\nexisting SIMD matrix multiplication instructions for symmetric bit-width\noperands can support operands of mixed precision by zero- or sign-extending the\nnarrow operand to match the size of the other operands, they cannot exploit the\nbenefit of narrow bit-width of one of the operands. We propose a new SIMD\nmatrix multiplication instruction that uses mixed precision on its inputs (8-\nand 4-bit operands) and accumulates product values into narrower 16-bit output\naccumulators, in turn allowing the SIMD operation at 128-bit vector width to\nprocess a greater number of data elements per instruction to improve processing\nthroughput and memory bandwidth utilization without increasing the register\nread- and write-port bandwidth in CPUs. The proposed asymmetric-operand-size\nSIMD instruction offers 2x improvement in throughput of matrix multiplication\nin comparison to throughput obtained using existing symmetric-operand-size\ninstructions while causing negligible (0.05%) overflow from 16-bit accumulators\nfor representative machine learning workloads. The asymmetric-operand-size\ninstruction not only can improve matrix multiplication throughput in CPUs, but\nalso can be effective to support multiply-and-accumulate (MAC) operation\nbetween 8- and 4-bit operands in state-of-the-art DNN hardware accelerators\n(e.g., systolic array microarchitecture in Google TPU, etc.) and offer similar\nimprovement in matrix multiply performance seamlessly without violating the\nvarious implementation constraints. We demonstrate how a systolic array\narchitecture designed for symmetric-operand-size instructions could be modified\nto support an asymmetric-operand-sized instruction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 04:12:31 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gope", "Dibakar", ""], ["Beu", "Jesse", ""], ["Mattina", "Matthew", ""]]}, {"id": "2008.00645", "submitter": "Zhenghang Cui", "authors": "Zhenghang Cui, Issei Sato", "title": "Active Classification with Uncertainty Comparison Queries", "comments": "Code and Dataset: https://github.com/zchenry/uncertainty-comparison", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy pairwise comparison feedback has been incorporated to improve the\noverall query complexity of interactively learning binary classifiers. The\n\\textit{positivity comparison oracle} is used to provide feedback on which is\nmore likely to be positive given a pair of data points. Because it is\nimpossible to infer accurate labels using this oracle alone \\textit{without\nknowing the classification threshold}, existing methods still rely on the\ntraditional \\textit{explicit labeling oracle}, which directly answers the label\ngiven a data point. Existing methods conduct sorting on all data points and use\nexplicit labeling oracle to find the classification threshold. The current\nmethods, however, have two drawbacks: (1) they needs unnecessary sorting for\nlabel inference; (2) quick sort is naively adapted to noisy feedback and\nnegatively affects practical performance. In order to avoid this inefficiency\nand acquire information of the classification threshold, we propose a new\npairwise comparison oracle concerning uncertainties. This oracle receives two\ndata points as input and answers which one has higher uncertainty. We then\npropose an efficient adaptive labeling algorithm using the proposed oracle and\nthe positivity comparison oracle. In addition, we also address the situation\nwhere the labeling budget is insufficient compared to the dataset size, which\ncan be dealt with by plugging the proposed algorithm into an active learning\nalgorithm. Furthermore, we confirm the feasibility of the proposed oracle and\nthe performance of the proposed algorithm theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 04:57:01 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 11:07:02 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Cui", "Zhenghang", ""], ["Sato", "Issei", ""]]}, {"id": "2008.00646", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Chun-Liang Li, Jinsung Yoon, Rajarishi Sinha, Arkady\n  Epshteyn, Long T. Le, Vikas Menon, Shashank Singh, Leyou Zhang, Nate Yoder,\n  Martin Nikoltchev, Yash Sonthalia, Hootan Nakhost, Elli Kanal and Tomas\n  Pfister", "title": "Interpretable Sequence Learning for COVID-19 Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach that integrates machine learning into\ncompartmental disease modeling to predict the progression of COVID-19. Our\nmodel is explainable by design as it explicitly shows how different\ncompartments evolve and it uses interpretable encoders to incorporate\ncovariates and improve performance. Explainability is valuable to ensure that\nthe model's forecasts are credible to epidemiologists and to instill confidence\nin end-users such as policy makers and healthcare institutions. Our model can\nbe applied at different geographic resolutions, and here we demonstrate it for\nstates and counties in the United States. We show that our model provides more\naccurate forecasts, in metrics averaged across the entire US, than\nstate-of-the-art alternatives, and that it provides qualitatively meaningful\nexplanatory insights. Lastly, we analyze the performance of our model for\ndifferent subgroups based on the subgroup distributions within the counties.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 05:02:57 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 16:48:42 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Arik", "Sercan O.", ""], ["Li", "Chun-Liang", ""], ["Yoon", "Jinsung", ""], ["Sinha", "Rajarishi", ""], ["Epshteyn", "Arkady", ""], ["Le", "Long T.", ""], ["Menon", "Vikas", ""], ["Singh", "Shashank", ""], ["Zhang", "Leyou", ""], ["Yoder", "Nate", ""], ["Nikoltchev", "Martin", ""], ["Sonthalia", "Yash", ""], ["Nakhost", "Hootan", ""], ["Kanal", "Elli", ""], ["Pfister", "Tomas", ""]]}, {"id": "2008.00720", "submitter": "Dominik Alfke", "authors": "Dominik Alfke, Martin Stoll", "title": "Pseudoinverse Graph Convolutional Networks: Fast Filters Tailored for\n  Large Eigengaps of Dense Graphs and Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have proven to be successful tools for\nsemi-supervised classification on graph-based datasets. We propose a new GCN\nvariant whose three-part filter space is targeted at dense graphs. Examples\ninclude Gaussian graphs for 3D point clouds with an increased focus on\nnon-local information, as well as hypergraphs based on categorical data. These\ngraphs differ from the common sparse benchmark graphs in terms of the spectral\nproperties of their graph Laplacian. Most notably we observe large eigengaps,\nwhich are unfavorable for popular existing GCN architectures. Our method\novercomes these issues by utilizing the pseudoinverse of the Laplacian. Another\nkey ingredient is a low-rank approximation of the convolutional matrix,\nensuring computational efficiency and increasing accuracy at the same time. We\noutline how the necessary eigeninformation can be computed efficiently in each\napplications and discuss the appropriate choice of the only metaparameter, the\napproximation rank. We finally showcase our method's performance regarding\nruntime and accuracy in various experiments with real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:48:41 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 10:36:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Alfke", "Dominik", ""], ["Stoll", "Martin", ""]]}, {"id": "2008.00727", "submitter": "Alykhan Tejani", "authors": "Dalin Guo, Sofia Ira Ktena, Ferenc Huszar, Pranay Kumar Myana, Wenzhe\n  Shi, Alykhan Tejani", "title": "Deep Bayesian Bandits: Exploring in Online Personalized Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems trained in a continuous learning fashion are plagued by\nthe feedback loop problem, also known as algorithmic bias. This causes a newly\ntrained model to act greedily and favor items that have already been engaged by\nusers. This behavior is particularly harmful in personalised ads\nrecommendations, as it can also cause new campaigns to remain unexplored.\nExploration aims to address this limitation by providing new information about\nthe environment, which encompasses user preference, and can lead to higher\nlong-term reward. In this work, we formulate a display advertising recommender\nas a contextual bandit and implement exploration techniques that require\nsampling from the posterior distribution of click-through-rates in a\ncomputationally tractable manner. Traditional large-scale deep learning models\ndo not provide uncertainty estimates by default. We approximate these\nuncertainty measurements of the predictions by employing a bootstrapped model\nwith multiple heads and dropout units. We benchmark a number of different\nmodels in an offline simulation environment using a publicly available dataset\nof user-ads engagements. We test our proposed deep Bayesian bandits algorithm\nin the offline simulation and online AB setting with large-scale production\ntraffic, where we demonstrate a positive gain of our exploration model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:58:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guo", "Dalin", ""], ["Ktena", "Sofia Ira", ""], ["Huszar", "Ferenc", ""], ["Myana", "Pranay Kumar", ""], ["Shi", "Wenzhe", ""], ["Tejani", "Alykhan", ""]]}, {"id": "2008.00741", "submitter": "Ivan Anokhin", "authors": "Ivan Anokhin, Dmitry Yarotsky", "title": "Low-loss connection of weight vectors: distribution-based approaches", "comments": "accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that sublevel sets of the loss surfaces of\noverparameterized networks are connected, exactly or approximately. We describe\nand compare experimentally a panel of methods used to connect two low-loss\npoints by a low-loss curve on this surface. Our methods vary in accuracy and\ncomplexity. Most of our methods are based on \"macroscopic\" distributional\nassumptions, and some are insensitive to the detailed properties of the points\nto be connected. Some methods require a prior training of a \"global connection\nmodel\" which can then be applied to any pair of points. The accuracy of the\nmethod generally correlates with its complexity and sensitivity to the endpoint\ndetail.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 09:42:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Anokhin", "Ivan", ""], ["Yarotsky", "Dmitry", ""]]}, {"id": "2008.00742", "submitter": "L\\^e-Nguy\\^en Hoang", "authors": "El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui, Arsany\n  Guirguis, L\\^e Nguy\\^en Hoang, S\\'ebastien Rouault", "title": "Collaborative Learning in the Jungle", "comments": "34 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Byzantine collaborative learning, where $n$ nodes seek to\ncollectively learn from each others' local data. The data distribution may vary\nfrom one node to another. No node is trusted, and $f < n$ nodes can behave\narbitrarily. We prove that collaborative learning is equivalent to a new form\nof agreement, which we call averaging agreement. In this problem, nodes start\neach with an initial vector and seek to approximately agree on a common vector,\nwhich is close to the average of honest nodes' initial vectors. We present two\nasynchronous solutions to averaging agreement, each we prove optimal according\nto some dimension. The first, based on the minimum-diameter averaging, requires\n$ n \\geq 6f+1$, but achieves asymptotically the best-possible averaging\nconstant up to a multiplicative constant. The second, based on reliable\nbroadcast and coordinate-wise trimmed mean, achieves optimal Byzantine\nresilience, i.e., $n \\geq 3f+1$. Each of these algorithms induces an optimal\nByzantine collaborative learning protocol. In particular, our equivalence\nyields new impossibility theorems on what any collaborative learning algorithm\ncan achieve in adversarial and heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 09:44:07 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 09:56:27 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 16:30:24 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 15:05:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Farhadkhani", "Sadegh", ""], ["Guerraoui", "Rachid", ""], ["Guirguis", "Arsany", ""], ["Hoang", "L\u00ea Nguy\u00ean", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "2008.00748", "submitter": "Shuqiang Wang", "authors": "Wen Yu, Baiying Lei, Michael K.Ng, Albert C.Cheung, Yanyan Shen,\n  Shuqiang Wang", "title": "Tensorizing GAN with High-Order Pooling for Alzheimer's Disease\n  Assessment", "comments": "15 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of great significance to apply deep learning for the early diagnosis of\nAlzheimer's Disease (AD). In this work, a novel tensorizing GAN with high-order\npooling is proposed to assess Mild Cognitive Impairment (MCI) and AD. By\ntensorizing a three-player cooperative game based framework, the proposed model\ncan benefit from the structural information of the brain. By incorporating the\nhigh-order pooling scheme into the classifier, the proposed model can make full\nuse of the second-order statistics of the holistic Magnetic Resonance Imaging\n(MRI) images. To the best of our knowledge, the proposed Tensor-train,\nHigh-pooling and Semi-supervised learning based GAN (THS-GAN) is the first work\nto deal with classification on MRI images for AD diagnosis. Extensive\nexperimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI)\ndataset are reported to demonstrate that the proposed THS-GAN achieves superior\nperformance compared with existing methods, and to show that both tensor-train\nand high-order pooling can enhance classification performance. The\nvisualization of generated samples also shows that the proposed model can\ngenerate plausible samples for semi-supervised learning purpose.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:04:09 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yu", "Wen", ""], ["Lei", "Baiying", ""], ["Ng", "Michael K.", ""], ["Cheung", "Albert C.", ""], ["Shen", "Yanyan", ""], ["Wang", "Shuqiang", ""]]}, {"id": "2008.00759", "submitter": "Marco Maggipinto", "authors": "Marco Maggipinto and Gian Antonio Susto and Pratik Chaudhari", "title": "Proximal Deterministic Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces two simple techniques to improve off-policy\nReinforcement Learning (RL) algorithms. First, we formulate off-policy RL as a\nstochastic proximal point iteration. The target network plays the role of the\nvariable of optimization and the value network computes the proximal operator.\nSecond, we exploits the two value functions commonly employed in\nstate-of-the-art off-policy algorithms to provide an improved action value\nestimate through bootstrapping with limited increase of computational\nresources. Further, we demonstrate significant performance improvement over\nstate-of-the-art algorithms on standard continuous-control RL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:19:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Maggipinto", "Marco", ""], ["Susto", "Gian Antonio", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2008.00760", "submitter": "Marco Maggipinto", "authors": "Marco Maggipinto and Matteo Terzi and Gian Antonio Susto", "title": "IntroVAC: Introspective Variational Classifiers for Learning\n  Interpretable Latent Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning useful representations of complex data has been the subject of\nextensive research for many years. With the diffusion of Deep Neural Networks,\nVariational Autoencoders have gained lots of attention since they provide an\nexplicit model of the data distribution based on an encoder/decoder\narchitecture which is able to both generate images and encode them in a\nlow-dimensional subspace. However, the latent space is not easily interpretable\nand the generation capabilities show some limitations since images typically\nlook blurry and lack details. In this paper, we propose the Introspective\nVariational Classifier (IntroVAC), a model that learns interpretable latent\nsubspaces by exploiting information from an additional label and provides\nimproved image quality thanks to an adversarial training strategy.We show that\nIntroVAC is able to learn meaningful directions in the latent space enabling\nfine-grained manipulation of image attributes. We validate our approach on the\nCelebA dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:21:41 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 07:23:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Maggipinto", "Marco", ""], ["Terzi", "Matteo", ""], ["Susto", "Gian Antonio", ""]]}, {"id": "2008.00807", "submitter": "Christos Matsoukas", "authors": "Christos Matsoukas, Albert Bou I Hernandez, Yue Liu, Karin Dembrower,\n  Gisele Miranda, Emir Konuk, Johan Fredin Haslum, Athanasios Zouzos, Peter\n  Lindholm, Fredrik Strand, Kevin Smith", "title": "Adding Seemingly Uninformative Labels Helps in Low Data Regimes", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence suggests that networks trained on large datasets generalize well not\nsolely because of the numerous training examples, but also class diversity\nwhich encourages learning of enriched features. This raises the question of\nwhether this remains true when data is scarce - is there an advantage to\nlearning with additional labels in low-data regimes? In this work, we consider\na task that requires difficult-to-obtain expert annotations: tumor segmentation\nin mammography images. We show that, in low-data settings, performance can be\nimproved by complementing the expert annotations with seemingly uninformative\nlabels from non-expert annotators, turning the task into a multi-class problem.\nWe reveal that these gains increase when less expert data is available, and\nuncover several interesting properties through further studies. We demonstrate\nour findings on CSAW-S, a new dataset that we introduce here, and confirm them\non two public datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 17:38:59 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 10:52:43 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Matsoukas", "Christos", ""], ["Hernandez", "Albert Bou I", ""], ["Liu", "Yue", ""], ["Dembrower", "Karin", ""], ["Miranda", "Gisele", ""], ["Konuk", "Emir", ""], ["Haslum", "Johan Fredin", ""], ["Zouzos", "Athanasios", ""], ["Lindholm", "Peter", ""], ["Strand", "Fredrik", ""], ["Smith", "Kevin", ""]]}, {"id": "2008.00892", "submitter": "Shikun Liu", "authors": "Shikun Liu, Zhe Lin, Yilin Wang, Jianming Zhang, Federico Perazzi,\n  Edward Johns", "title": "Shape Adaptor: A Learnable Resizing Module", "comments": "Published at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel resizing module for neural networks: shape adaptor, a\ndrop-in enhancement built on top of traditional resizing layers, such as\npooling, bilinear sampling, and strided convolution. Whilst traditional\nresizing layers have fixed and deterministic reshaping factors, our module\nallows for a learnable reshaping factor. Our implementation enables shape\nadaptors to be trained end-to-end without any additional supervision, through\nwhich network architectures can be optimised for each individual task, in a\nfully automated way. We performed experiments across seven image classification\ndatasets, and results show that by simply using a set of our shape adaptors\ninstead of the original resizing layers, performance increases consistently\nover human-designed networks, across all datasets. Additionally, we show the\neffectiveness of shape adaptors on two other applications: network compression\nand transfer learning. The source code is available at:\nhttps://github.com/lorenmt/shape-adaptor.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:15:52 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 13:10:50 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Shikun", ""], ["Lin", "Zhe", ""], ["Wang", "Yilin", ""], ["Zhang", "Jianming", ""], ["Perazzi", "Federico", ""], ["Johns", "Edward", ""]]}, {"id": "2008.00938", "submitter": "Aristide Baratin", "authors": "Aristide Baratin, Thomas George, C\\'esar Laurent, R Devon Hjelm,\n  Guillaume Lajoie, Pascal Vincent, Simon Lacoste-Julien", "title": "Implicit Regularization via Neural Feature Alignment", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the problem of implicit regularization in deep learning from a\ngeometrical viewpoint. We highlight a regularization effect induced by a\ndynamical alignment of the neural tangent features introduced by Jacot et al,\nalong a small number of task-relevant directions. This can be interpreted as a\ncombined mechanism of feature selection and compression. By extrapolating a new\nanalysis of Rademacher complexity bounds for linear models, we motivate and\nstudy a heuristic complexity measure that captures this phenomenon, in terms of\nsequences of tangent kernel classes along optimization paths.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:18:07 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:04:22 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 00:57:56 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Baratin", "Aristide", ""], ["George", "Thomas", ""], ["Laurent", "C\u00e9sar", ""], ["Hjelm", "R Devon", ""], ["Lajoie", "Guillaume", ""], ["Vincent", "Pascal", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2008.00942", "submitter": "Mingkui Tan", "authors": "Jiezhang Cao, Yong Guo, Qingyao Wu, Chunhua Shen, Junzhou Huang,\n  Mingkui Tan", "title": "Improving Generative Adversarial Networks with Local Coordinate Coding", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown remarkable success in\ngenerating realistic data from some predefined prior distribution (e.g.,\nGaussian noises). However, such prior distribution is often independent of real\ndata and thus may lose semantic information (e.g., geometric structure or\ncontent in images) of data. In practice, the semantic information might be\nrepresented by some latent distribution learned from data. However, such latent\ndistribution may incur difficulties in data sampling for GANs. In this paper,\nrather than sampling from the predefined prior distribution, we propose an\nLCCGAN model with local coordinate coding (LCC) to improve the performance of\ngenerating data. First, we propose an LCC sampling method in LCCGAN to sample\nmeaningful points from the latent manifold. With the LCC sampling method, we\ncan exploit the local information on the latent manifold and thus produce new\ndata with promising quality. Second, we propose an improved version, namely\nLCCGAN++, by introducing a higher-order term in the generator approximation.\nThis term is able to achieve better approximation and thus further improve the\nperformance. More critically, we derive the generalization bound for both\nLCCGAN and LCCGAN++ and prove that a low-dimensional input is sufficient to\nachieve good generalization performance. Extensive experiments on four\nbenchmark datasets demonstrate the superiority of the proposed method over\nexisting GANs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 09:17:50 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cao", "Jiezhang", ""], ["Guo", "Yong", ""], ["Wu", "Qingyao", ""], ["Shen", "Chunhua", ""], ["Huang", "Junzhou", ""], ["Tan", "Mingkui", ""]]}, {"id": "2008.00946", "submitter": "Etienne Goffinet Mr", "authors": "Etienne Goffinet, Anthony Coutant, Mustapha Lebbah, Hanane Azzag and\n  Lo\\\"ic Giraldi", "title": "Conditional Latent Block Model: a Multivariate Time Series Clustering\n  Approach for Autonomous Driving Validation", "comments": "17 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving systems validation remains one of the biggest challenges\ncar manufacturers must tackle in order to provide safe driverless cars. The\nhigh complexity stems from several factors: the multiplicity of vehicles,\nembedded systems, use cases, and the very high required level of reliability\nfor the driving system to be at least as safe as a human driver. In order to\ncircumvent these issues, large scale simulations reproducing this huge variety\nof physical conditions are intensively used to test driverless cars. Therefore,\nthe validation step produces a massive amount of data, including many\ntime-indexed ones, to be processed. In this context, building a structure in\nthe feature space is mandatory to interpret the various scenarios. In this\nwork, we propose a new co-clustering approach adapted to high-dimensional time\nseries analysis, that extends the standard model-based co-clustering. The\nFunCLBM model extends the recently proposed Functional Latent Block Model and\nallows to create a dependency structure between row and column clusters. This\nstructured partition acts as a feature selection method, that provides several\nclustering views of a dataset, while discriminating irrelevant features. In\nthis workflow, times series are projected onto a common interpolated\nlow-dimensional frequency space, which allows to optimize the projection basis.\nIn addition, FunCLBM refines the definition of each latent block by performing\nblock-wise dimension reduction and feature selection. We propose a SEM-Gibbs\nalgorithm to infer this model, as well as a dedicated criterion to select the\noptimal nested partition. Experiments on both simulated and real-case Renault\ndatasets shows the effectiveness of the proposed tools and the adequacy to our\nuse case.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:26:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Goffinet", "Etienne", ""], ["Coutant", "Anthony", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["Giraldi", "Lo\u00efc", ""]]}, {"id": "2008.01036", "submitter": "Lin Chen", "authors": "Lin Chen, Yifei Min, Mikhail Belkin, Amin Karbasi", "title": "Multiple Descent: Design Your Own Generalization Curve", "comments": "Improved presentation of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the generalization loss of linear regression in variably\nparameterized families of models, both under-parameterized and\nover-parameterized. We show that the generalization curve can have an arbitrary\nnumber of peaks, and moreover, locations of those peaks can be explicitly\ncontrolled. Our results highlight the fact that both classical U-shaped\ngeneralization curve and the recently observed double descent curve are not\nintrinsic properties of the model family. Instead, their emergence is due to\nthe interaction between the properties of the data and the inductive biases of\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:22:21 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 16:38:35 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:25:39 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 18:06:02 GMT"}, {"version": "v5", "created": "Tue, 9 Feb 2021 00:45:00 GMT"}, {"version": "v6", "created": "Tue, 1 Jun 2021 17:03:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chen", "Lin", ""], ["Min", "Yifei", ""], ["Belkin", "Mikhail", ""], ["Karbasi", "Amin", ""]]}, {"id": "2008.01062", "submitter": "Jianhao Wang", "authors": "Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang", "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based multi-agent reinforcement learning (MARL) in the\npopular paradigm of centralized training with decentralized execution (CTDE).\nCTDE has an important concept, Individual-Global-Max (IGM) principle, which\nrequires the consistency between joint and local action selections to support\nefficient local decision-making. However, in order to achieve scalability,\nexisting MARL methods either limit representation expressiveness of their value\nfunction classes or relax the IGM consistency, which may suffer from\ninstability risk or lead to poor performance. This paper presents a novel MARL\napproach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a\nduplex dueling network architecture to factorize the joint value function. This\nduplex dueling structure encodes the IGM principle into the neural network\narchitecture and thus enables efficient value function learning. Theoretical\nanalysis shows that QPLEX achieves a complete IGM function class. Empirical\nexperiments on StarCraft II micromanagement tasks demonstrate that QPLEX\nsignificantly outperforms state-of-the-art baselines in both online and offline\ndata collection settings, and also reveal that QPLEX achieves high sample\nefficiency and can benefit from offline datasets without additional online\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:52:09 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:13:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Jianhao", ""], ["Ren", "Zhizhou", ""], ["Liu", "Terry", ""], ["Yu", "Yang", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2008.01064", "submitter": "Qi Lei", "authors": "Jason D. Lee, Qi Lei, Nikunj Saunshi, Jiacheng Zhuo", "title": "Predicting What You Already Know Helps: Provable Self-Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning solves auxiliary prediction tasks\n(known as pretext tasks), that do not require labeled data, to learn semantic\nrepresentations. These pretext tasks are created solely using the input\nfeatures, such as predicting a missing image patch, recovering the color\nchannels of an image from context, or predicting missing words, yet predicting\nthis $known\\ $information helps in learning representations effective for\ndownstream prediction tasks. This paper posits a mechanism based on conditional\nindependence to formalize how solving certain pretext tasks can learn\nrepresentations that provably decreases the sample complexity of downstream\nsupervised tasks. Formally, we quantify how approximate independence between\nthe components of the pretext task (conditional on the label and latent\nvariables) allows us to learn representations that can solve the downstream\ntask with drastically reduced sample complexity by just training a linear layer\non top of the learned representation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:56:13 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lee", "Jason D.", ""], ["Lei", "Qi", ""], ["Saunshi", "Nikunj", ""], ["Zhuo", "Jiacheng", ""]]}, {"id": "2008.01066", "submitter": "Xiu Yang", "authors": "Yixiang Deng, Guang Lin and Xiu Yang", "title": "Multifidelity Data Fusion via Gradient-Enhanced Gaussian Process\n  Regression", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0151", "report-no": null, "categories": "cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data fusion method based on multi-fidelity Gaussian process\nregression (GPR) framework. This method combines available data of the quantity\nof interest (QoI) and its gradients with different fidelity levels, namely, it\nis a Gradient-enhanced Cokriging method (GE-Cokriging). It provides the\napproximations of both the QoI and its gradients simultaneously with\nuncertainty estimates. We compare this method with the conventional\nmulti-fidelity Cokriging method that does not use gradients information, and\nthe result suggests that GE-Cokriging has a better performance in predicting\nboth QoI and its gradients. Moreover, GE-Cokriging even shows better\ngeneralization result in some cases where Cokriging performs poorly due to the\nsingularity of the covariance matrix. We demonstrate the application of\nGE-Cokriging in several practical cases including reconstructing the\ntrajectories and velocity of an underdamped oscillator with respect to time\nsimultaneously, and investigating the sensitivity of power factor of a load bus\nwith respect to varying power inputs of a generator bus in a large scale power\nsystem. We also show that though GE-Cokriging method requires a little bit\nhigher computational cost than Cokriging method, the result of accuracy\ncomparison shows that this cost is usually worth it.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:57:12 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Deng", "Yixiang", ""], ["Lin", "Guang", ""], ["Yang", "Xiu", ""]]}, {"id": "2008.01132", "submitter": "Suyun Liu", "authors": "Suyun Liu and Luis Nunes Vicente", "title": "Accuracy and Fairness Trade-offs in Machine Learning: A Stochastic\n  Multi-Objective Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the application of machine learning to real-life decision-making systems,\ne.g., credit scoring and criminal justice, the prediction outcomes might\ndiscriminate against people with sensitive attributes, leading to unfairness.\nThe commonly used strategy in fair machine learning is to include fairness as a\nconstraint or a penalization term in the minimization of the prediction loss,\nwhich ultimately limits the information given to decision-makers. In this\npaper, we introduce a new approach to handle fairness by formulating a\nstochastic multi-objective optimization problem for which the corresponding\nPareto fronts uniquely and comprehensively define the accuracy-fairness\ntrade-offs. We have then applied a stochastic approximation-type method to\nefficiently obtain well-spread and accurate Pareto fronts, and by doing so we\ncan handle training data arriving in a streaming way.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 18:51:24 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 18:51:35 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Liu", "Suyun", ""], ["Vicente", "Luis Nunes", ""]]}, {"id": "2008.01160", "submitter": "Alexey Gritsenko", "authors": "Alexey A. Gritsenko, Tim Salimans, Rianne van den Berg, Jasper Snoek,\n  Nal Kalchbrenner", "title": "A Spectral Energy Distance for Parallel Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech synthesis is an important practical generative modeling problem that\nhas seen great progress over the last few years, with likelihood-based\nautoregressive neural models now outperforming traditional concatenative\nsystems. A downside of such autoregressive models is that they require\nexecuting tens of thousands of sequential operations per second of generated\naudio, making them ill-suited for deployment on specialized deep learning\nhardware. Here, we propose a new learning method that allows us to train highly\nparallel models of speech, without requiring access to an analytical likelihood\nfunction. Our approach is based on a generalized energy distance between the\ndistributions of the generated and real audio. This spectral energy distance is\na proper scoring rule with respect to the distribution over\nmagnitude-spectrograms of the generated waveform audio and offers statistical\nconsistency guarantees. The distance can be calculated from minibatches without\nbias, and does not involve adversarial learning, yielding a stable and\nconsistent method for training implicit generative models. Empirically, we\nachieve state-of-the-art generation quality among implicit generative models,\nas judged by the recently-proposed cFDSD metric. When combining our method with\nadversarial techniques, we also improve upon the recently-proposed GAN-TTS\nmodel in terms of Mean Opinion Score as judged by trained human evaluators.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 19:56:04 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:44:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gritsenko", "Alexey A.", ""], ["Salimans", "Tim", ""], ["Berg", "Rianne van den", ""], ["Snoek", "Jasper", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "2008.01170", "submitter": "Syed Afaq Ali Shah", "authors": "Devante Ayris, Kye Horbury, Blake Williams, Mitchell Blackney, Celine\n  Shi Hui See, Maleeha Imtiaz, Syed Afaq Ali Shah", "title": "Deep Learning Models for Early Detection and Prediction of the spread of\n  Novel Coronavirus (COVID-19)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SARS-CoV2, which causes coronavirus disease (COVID-19) is continuing to\nspread globally and has become a pandemic. People have lost their lives due to\nthe virus and the lack of counter measures in place. Given the increasing\ncaseload and uncertainty of spread, there is an urgent need to develop machine\nlearning techniques to predict the spread of COVID-19. Prediction of the spread\ncan allow counter measures and actions to be implemented to mitigate the spread\nof COVID-19. In this paper, we propose a deep learning technique, called Deep\nSequential Prediction Model (DSPM) and machine learning based Non-parametric\nRegression Model (NRM) to predict the spread of COVID-19. Our proposed models\nwere trained and tested on novel coronavirus 2019 dataset, which contains 19.53\nMillion confirmed cases of COVID-19. Our proposed models were evaluated by\nusing Mean Absolute Error and compared with baseline method. Our experimental\nresults, both quantitative and qualitative, demonstrate the superior prediction\nperformance of the proposed models.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 10:14:11 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:45:37 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ayris", "Devante", ""], ["Horbury", "Kye", ""], ["Williams", "Blake", ""], ["Blackney", "Mitchell", ""], ["See", "Celine Shi Hui", ""], ["Imtiaz", "Maleeha", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2008.01171", "submitter": "Ralf Gulde", "authors": "Ralf Gulde, Marc Tuscher, Akos Csiszar, Oliver Riedel and Alexander\n  Verl", "title": "Deep Reinforcement Learning using Cyclical Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) methods often rely on the meticulous tuning\nof hyperparameters to successfully resolve problems. One of the most\ninfluential parameters in optimization procedures based on stochastic gradient\ndescent (SGD) is the learning rate. We investigate cyclical learning and\npropose a method for defining a general cyclical learning rate for various DRL\nproblems. In this paper we present a method for cyclical learning applied to\ncomplex DRL problems. Our experiments show that, utilizing cyclical learning\nachieves similar or even better results than highly tuned fixed learning rates.\nThis paper presents the first application of cyclical learning rates in DRL\nsettings and is a step towards overcoming manual hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 10:06:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gulde", "Ralf", ""], ["Tuscher", "Marc", ""], ["Csiszar", "Akos", ""], ["Riedel", "Oliver", ""], ["Verl", "Alexander", ""]]}, {"id": "2008.01175", "submitter": "Renato Cordeiro de Amorim", "authors": "Renato Cordeiro de Amorim and Carlos David Lopez Ruiz", "title": "Identifying meaningful clusters in malware data", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2021.114971", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Finding meaningful clusters in drive-by-download malware data is a\nparticularly difficult task. Malware data tends to contain overlapping clusters\nwith wide variations of cardinality. This happens because there can be\nconsiderable similarity between malware samples (some are even said to belong\nto the same family), and these tend to appear in bursts. Clustering algorithms\nare usually applied to normalised data sets. However, the process of\nnormalisation aims at setting features with different range values to have a\nsimilar contribution to the clustering. It does not favour more meaningful\nfeatures over those that are less meaningful, an effect one should perhaps\nexpect of the data pre-processing stage.\n  In this paper we introduce a method to deal precisely with the problem above.\nThis is an iterative data pre-processing method capable of aiding to increase\nthe separation between clusters. It does so by calculating the within-cluster\ndegree of relevance of each feature, and then it uses these as a data rescaling\nfactor. By repeating this until convergence our malware data was separated in\nclear clusters, leading to a higher average silhouette width.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 12:36:08 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["de Amorim", "Renato Cordeiro", ""], ["Ruiz", "Carlos David Lopez", ""]]}, {"id": "2008.01190", "submitter": "SeungHeon Doh", "authors": "Seungheon Doh, Jongpil Lee, Tae Hong Park, Juhan Nam", "title": "Musical Word Embedding: Bridging the Gap between Listening Contexts and\n  Music", "comments": "Machine Learning for Media Discovery Workshop, International\n  Conference on Machine Learning (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding pioneered by Mikolov et al. is a staple technique for word\nrepresentations in natural language processing (NLP) research which has also\nfound popularity in music information retrieval tasks. Depending on the type of\ntext data for word embedding, however, vocabulary size and the degree of\nmusical pertinence can significantly vary. In this work, we (1) train the\ndistributed representation of words using combinations of both general text\ndata and music-specific data and (2) evaluate the system in terms of how they\nassociate listening contexts with musical compositions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 06:42:45 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Doh", "Seungheon", ""], ["Lee", "Jongpil", ""], ["Park", "Tae Hong", ""], ["Nam", "Juhan", ""]]}, {"id": "2008.01192", "submitter": "Kamal Berahmand", "authors": "Saman Forouzandeh, Mehrdad Rostami, Kamal Berahmand", "title": "Presentation of a Recommender System with Ensemble Learning and Graph\n  Embedding: A Case on MovieLens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information technology has spread widely, and extraordinarily large amounts\nof data have been made accessible to users, which has made it challenging to\nselect data that are in accordance with user needs. For the resolution of the\nabove issue, recommender systems have emerged, which much help users go through\nthe process of decision-making and selecting relevant data. A recommender\nsystem predicts users behavior to be capable of detecting their interests and\nneeds, and it often uses the classification technique for this purpose. It may\nnot be sufficiently accurate to employ individual classification, where not all\ncases can be examined, which makes the method inappropriate to specific\nproblems. In this research, group classification and the ensemble learning\ntechnique were used for increasing prediction accuracy in recommender systems.\nAnother issue that is raised here concerns user analysis. Given the large size\nof the data and a large number of users, the process of user needs analysis and\nprediction (using a graph in most cases, representing the relations between\nusers and their selected items) is complicated and cumbersome in recommender\nsystems. Graph embedding was also proposed for resolution of this issue, where\nall or part of user behavior can be simulated through the generation of several\nvectors, resolving the problem of user behavior analysis to a large extent\nwhile maintaining high efficiency. In this research, individuals most similar\nto the target user were classified using ensemble learning, fuzzy rules, and\nthe decision tree, and relevant recommendations were then made to each user\nwith a heterogeneous knowledge graph and embedding vectors. This study was\nperformed on the MovieLens datasets, and the obtained results indicated the\nhigh efficiency of the presented method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 12:52:15 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Forouzandeh", "Saman", ""], ["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""]]}, {"id": "2008.01204", "submitter": "Ivan Papusha", "authors": "Ivan Papusha, Rosa Wu, Joshua Brul\\'e, Yanni Kouskoulas, Daniel Genin,\n  Aurora Schmidt", "title": "Incorrect by Construction: Fine Tuning Neural Networks for Guaranteed\n  Performance on Finite Sets of Examples", "comments": "Part of 3rd Workshop on Formal Methods for ML-Enabled Autonomous\n  Systems (FoMLAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is great interest in using formal methods to guarantee the reliability\nof deep neural networks. However, these techniques may also be used to implant\ncarefully selected input-output pairs. We present initial results on a novel\ntechnique for using SMT solvers to fine tune the weights of a ReLU neural\nnetwork to guarantee outcomes on a finite set of particular examples. This\nprocedure can be used to ensure performance on key examples, but it could also\nbe used to insert difficult-to-find incorrect examples that trigger unexpected\nperformance. We demonstrate this approach by fine tuning an MNIST network to\nincorrectly classify a particular image and discuss the potential for the\napproach to compromise reliability of freely-shared machine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:29:53 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Papusha", "Ivan", ""], ["Wu", "Rosa", ""], ["Brul\u00e9", "Joshua", ""], ["Kouskoulas", "Yanni", ""], ["Genin", "Daniel", ""], ["Schmidt", "Aurora", ""]]}, {"id": "2008.01205", "submitter": "Zachary Robertson", "authors": "Zachary W. Robertson, Matthew R. Walter", "title": "Concurrent Training Improves the Performance of Behavioral Cloning from\n  Observation", "comments": "13 pages, 2 figures, Submitted to the 4th Conference on Robot\n  Learning (CoRL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration is widely used as an efficient way for robots to\nacquire new skills. However, it typically requires that demonstrations provide\nfull access to the state and action sequences. In contrast, learning from\nobservation offers a way to utilize unlabeled demonstrations (e.g., video) to\nperform imitation learning. One approach to this is behavioral cloning from\nobservation (BCO). The original implementation of BCO proceeds by first\nlearning an inverse dynamics model and then using that model to estimate action\nlabels, thereby reducing the problem to behavioral cloning. However, existing\napproaches to BCO require a large number of initial interactions in the first\nstep. Here, we provide a novel theoretical analysis of BCO, introduce a\nmodification BCO*, and show that in the semi-supervised setting, BCO* can\nconcurrently improve both its estimate for the inverse dynamics model and the\nexpert policy. This result allows us to eliminate the dependence on initial\ninteractions and dramatically improve the sample complexity of BCO. We evaluate\nthe effectiveness of our algorithm through experiments on various benchmark\ndomains. The results demonstrate that concurrent training not only improves\nover the performance of BCO but also results in performance that is competitive\nwith state-of-the-art imitation learning methods such as GAIL and Value-Dice.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:30:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Robertson", "Zachary W.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "2008.01214", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Generalized Zero-Shot Domain Adaptation via Coupled Conditional\n  Variational Autoencoders", "comments": "Durham University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation approaches aim to exploit useful information from the\nsource domain where supervised learning examples are easier to obtain to\naddress a learning problem in the target domain where there is no or limited\navailability of such examples. In classification problems, domain adaptation\nhas been studied under varying supervised, unsupervised and semi-supervised\nconditions. However, a common situation when the labelled samples are available\nfor a subset of target domain classes has been overlooked. In this paper, we\nformulate this particular domain adaptation problem within a generalized\nzero-shot learning framework by treating the labelled source domain samples as\nsemantic representations for zero-shot learning. For this particular problem,\nneither conventional domain adaptation approaches nor zero-shot learning\nalgorithms directly apply. To address this generalized zero-shot domain\nadaptation problem, we present a novel Coupled Conditional Variational\nAutoencoder (CCVAE) which can generate synthetic target domain features for\nunseen classes from their source domain counterparts. Extensive experiments\nhave been conducted on three domain adaptation datasets including a bespoke\nX-ray security checkpoint dataset to simulate a real-world application in\naviation security. The results demonstrate the effectiveness of our proposed\napproach both against established benchmarks and in terms of real-world\napplicability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:48:50 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2008.01215", "submitter": "Laurent Callot", "authors": "Valentin Flunkert, Quentin Rebjock, Joel Castellon, Laurent Callot,\n  Tim Januschowski", "title": "A simple and effective predictive resource scaling heuristic for\n  large-scale cloud applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective policy for the predictive auto-scaling of\nhorizontally scalable applications running in cloud environments, where compute\nresources can only be added with a delay, and where the deployment throughput\nis limited. Our policy uses a probabilistic forecast of the workload to make\nscaling decisions dependent on the risk aversion of the application owner. We\nshow in our experiments using real-world and synthetic data that this policy\ncompares favorably to mathematically more sophisticated approaches as well as\nto simple benchmark policies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:50:14 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Flunkert", "Valentin", ""], ["Rebjock", "Quentin", ""], ["Castellon", "Joel", ""], ["Callot", "Laurent", ""], ["Januschowski", "Tim", ""]]}, {"id": "2008.01217", "submitter": "Piotr Zielinski", "authors": "Satrajit Chatterjee, Piotr Zielinski", "title": "Making Coherence Out of Nothing At All: Measuring the Evolution of\n  Gradient Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new metric ($m$-coherence) to experimentally study the alignment\nof per-example gradients during training. Intuitively, given a sample of size\n$m$, $m$-coherence is the number of examples in the sample that benefit from a\nsmall step along the gradient of any one example on average. We show that\ncompared to other commonly used metrics, $m$-coherence is more interpretable,\ncheaper to compute ($O(m)$ instead of $O(m^2)$) and mathematically cleaner. (We\nnote that $m$-coherence is closely connected to gradient diversity, a quantity\npreviously used in some theoretical bounds.) Using $m$-coherence, we study the\nevolution of alignment of per-example gradients in ResNet and Inception models\non ImageNet and several variants with label noise, particularly from the\nperspective of the recently proposed Coherent Gradients (CG) theory that\nprovides a simple, unified explanation for memorization and generalization\n[Chatterjee, ICLR 20]. Although we have several interesting takeaways, our most\nsurprising result concerns memorization. Naively, one might expect that when\ntraining with completely random labels, each example is fitted independently,\nand so $m$-coherence should be close to 1. However, this is not the case:\n$m$-coherence reaches much higher values during training (100s), indicating\nthat over-parameterized neural networks find common patterns even in scenarios\nwhere generalization is not possible. A detailed analysis of this phenomenon\nprovides both a deeper confirmation of CG, but at the same point puts into\nsharp relief what is missing from the theory in order to provide a complete\nexplanation of generalization in neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:51:24 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chatterjee", "Satrajit", ""], ["Zielinski", "Piotr", ""]]}, {"id": "2008.01245", "submitter": "Alexander Cloninger", "authors": "Alexander Cloninger, Hrushikesh Mhaskar", "title": "Cautious Active Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classification of points sampled from an unknown\nprobability measure on a Euclidean space. We study the question of querying the\nclass label at a very small number of judiciously chosen points so as to be\nable to attach the appropriate class label to every point in the set. Our\napproach is to consider the unknown probability measure as a convex combination\nof the conditional probabilities for each class. Our technique involves the use\nof a highly localized kernel constructed from Hermite polynomials, in order to\ncreate a hierarchical estimate of the supports of the constituent probability\nmeasures. We do not need to make any assumptions on the nature of any of the\nprobability measures nor know in advance the number of classes involved. We\ngive theoretical guarantees measured by the $F$-score for our classification\nscheme. Examples include classification in hyper-spectral images and MNIST\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 23:47:31 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:41:49 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Cloninger", "Alexander", ""], ["Mhaskar", "Hrushikesh", ""]]}, {"id": "2008.01291", "submitter": "Ke Chen", "authors": "Ke Chen, Cheng-i Wang, Taylor Berg-Kirkpatrick, Shlomo Dubnov", "title": "Music SketchNet: Controllable Music Generation via Factorized\n  Representations of Pitch and Rhythm", "comments": "8 pages, 8 figures, Proceedings of the 21st International Society for\n  Music Information Retrieval Conference, ISMIR 2020", "journal-ref": "21st International Society for Music Information Retrieval\n  Conference, ISMIR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drawing an analogy with automatic image completion systems, we propose Music\nSketchNet, a neural network framework that allows users to specify partial\nmusical ideas guiding automatic music generation. We focus on generating the\nmissing measures in incomplete monophonic musical pieces, conditioned on\nsurrounding context, and optionally guided by user-specified pitch and rhythm\nsnippets. First, we introduce SketchVAE, a novel variational autoencoder that\nexplicitly factorizes rhythm and pitch contour to form the basis of our\nproposed model. Then we introduce two discriminative architectures,\nSketchInpainter and SketchConnector, that in conjunction perform the guided\nmusic completion, filling in representations for the missing measures\nconditioned on surrounding context and user-specified snippets. We evaluate\nSketchNet on a standard dataset of Irish folk music and compare with models\nfrom recent works. When used for music completion, our approach outperforms the\nstate-of-the-art both in terms of objective metrics and subjective listening\ntests. Finally, we demonstrate that our model can successfully incorporate\nuser-specified snippets during the generation process.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 02:49:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Ke", ""], ["Wang", "Cheng-i", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Dubnov", "Shlomo", ""]]}, {"id": "2008.01296", "submitter": "Feihu Huang", "authors": "Feihu Huang, Songcan Chen, Heng Huang", "title": "Faster Stochastic Alternating Direction Method of Multipliers for\n  Nonconvex Optimization", "comments": "Published in ICML 2019, 43 pages. arXiv admin note: text overlap with\n  arXiv:1907.13463", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a faster stochastic alternating direction method of\nmultipliers (ADMM) for nonconvex optimization by using a new stochastic\npath-integrated differential estimator (SPIDER), called as SPIDER-ADMM.\nMoreover, we prove that the SPIDER-ADMM achieves a record-breaking incremental\nfirst-order oracle (IFO) complexity of $\\mathcal{O}(n+n^{1/2}\\epsilon^{-1})$\nfor finding an $\\epsilon$-approximate stationary point, which improves the\ndeterministic ADMM by a factor $\\mathcal{O}(n^{1/2})$, where $n$ denotes the\nsample size. As one of major contribution of this paper, we provide a new\ntheoretical analysis framework for nonconvex stochastic ADMM methods with\nproviding the optimal IFO complexity. Based on this new analysis framework, we\nstudy the unsolved optimal IFO complexity of the existing non-convex SVRG-ADMM\nand SAGA-ADMM methods, and prove they have the optimal IFO complexity of\n$\\mathcal{O}(n+n^{2/3}\\epsilon^{-1})$. Thus, the SPIDER-ADMM improves the\nexisting stochastic ADMM methods by a factor of $\\mathcal{O}(n^{1/6})$.\nMoreover, we extend SPIDER-ADMM to the online setting, and propose a faster\nonline SPIDER-ADMM. Our theoretical analysis shows that the online SPIDER-ADMM\nhas the IFO complexity of $\\mathcal{O}(\\epsilon^{-\\frac{3}{2}})$, which\nimproves the existing best results by a factor of\n$\\mathcal{O}(\\epsilon^{-\\frac{1}{2}})$. Finally, the experimental results on\nbenchmark datasets validate that the proposed algorithms have faster\nconvergence rate than the existing ADMM algorithms for nonconvex optimization.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 02:59:42 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 14:44:23 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 03:20:17 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Huang", "Feihu", ""], ["Chen", "Songcan", ""], ["Huang", "Heng", ""]]}, {"id": "2008.01304", "submitter": "Naoki Hayashi", "authors": "Naoki Hayashi", "title": "The Exact Asymptotic Form of Bayesian Generalization Error in Latent\n  Dirichlet Allocation", "comments": "20 pages, 3 figures, 2 tables. Accepted at Neural Networks (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet allocation (LDA) obtains essential information from data by\nusing Bayesian inference. It is applied to knowledge discovery via dimension\nreducing and clustering in many fields. However, its generalization error had\nnot been yet clarified since it is a singular statistical model where there is\nno one-to-one mapping from parameters to probability distributions. In this\npaper, we give the exact asymptotic form of its generalization error and\nmarginal likelihood, by theoretical analysis of its learning coefficient using\nalgebraic geometry. The theoretical result shows that the Bayesian\ngeneralization error in LDA is expressed in terms of that in matrix\nfactorization and a penalty from the simplex restriction of LDA's parameter\nregion. A numerical experiment is consistent to the theoretical result.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:26:16 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 15:49:34 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hayashi", "Naoki", ""]]}, {"id": "2008.01305", "submitter": "Raksha Ramakrishna", "authors": "Raksha Ramakrishna, Hoi-To Wai, Anna Scaglione", "title": "A User Guide to Low-Pass Graph Signal Processing and its Applications", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1109/MSP.2020.3014590", "report-no": null, "categories": "eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of graph filters can be used to define generative models for graph\ndata. In fact, the data obtained from many examples of network dynamics may be\nviewed as the output of a graph filter. With this interpretation, classical\nsignal processing tools such as frequency analysis have been successfully\napplied with analogous interpretation to graph data, generating new insights\nfor data science. What follows is a user guide on a specific class of graph\ndata, where the generating graph filters are low-pass, i.e., the filter\nattenuates contents in the higher graph frequencies while retaining contents in\nthe lower frequencies. Our choice is motivated by the prevalence of low-pass\nmodels in application domains such as social networks, financial markets, and\npower systems. We illustrate how to leverage properties of low-pass graph\nfilters to learn the graph topology or identify its community structure;\nefficiently represent graph data through sampling, recover missing\nmeasurements, and de-noise graph data; the low-pass property is also used as\nthe baseline to detect anomalies.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:27:17 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ramakrishna", "Raksha", ""], ["Wai", "Hoi-To", ""], ["Scaglione", "Anna", ""]]}, {"id": "2008.01342", "submitter": "Yuwen Xiong", "authors": "Yuwen Xiong, Mengye Ren, Raquel Urtasun", "title": "LoCo: Local Contrastive Representation Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural nets typically perform end-to-end backpropagation to learn the\nweights, a procedure that creates synchronization constraints in the weight\nupdate step across layers and is not biologically plausible. Recent advances in\nunsupervised contrastive representation learning point to the question of\nwhether a learning algorithm can also be made local, that is, the updates of\nlower layers do not directly depend on the computation of upper layers. While\nGreedy InfoMax separately learns each block with a local objective, we found\nthat it consistently hurts readout accuracy in state-of-the-art unsupervised\ncontrastive learning algorithms, possibly due to the greedy objective as well\nas gradient isolation. In this work, we discover that by overlapping local\nblocks stacking on top of each other, we effectively increase the decoder depth\nand allow upper blocks to implicitly send feedbacks to lower blocks. This\nsimple design closes the performance gap between local learning and end-to-end\ncontrastive learning algorithms for the first time. Aside from standard\nImageNet experiments, we also show results on complex downstream tasks such as\nobject detection and instance segmentation directly using readout features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:41:29 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 08:54:06 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Xiong", "Yuwen", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2008.01352", "submitter": "Jean-Yves Franceschi", "authors": "J\\'er\\'emie Don\\`a (MLIA), Jean-Yves Franceschi (MLIA), Sylvain\n  Lamprier (MLIA), Patrick Gallinari (MLIA)", "title": "PDE-Driven Spatiotemporal Disentanglement", "comments": null, "journal-ref": "The Ninth International Conference on Learning Representations,\n  International Conference on Representation Learning, May 2021, Vienne,\n  Austria", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work in the machine learning community addresses the problem\nof predicting high-dimensional spatiotemporal phenomena by leveraging specific\ntools from the differential equations theory. Following this direction, we\npropose in this article a novel and general paradigm for this task based on a\nresolution method for partial differential equations: the separation of\nvariables. This inspiration allows us to introduce a dynamical interpretation\nof spatiotemporal disentanglement. It induces a principled model based on\nlearning disentangled spatial and temporal representations of a phenomenon to\naccurately predict future observations. We experimentally demonstrate the\nperformance and broad applicability of our method against prior\nstate-of-the-art models on physical and synthetic video datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 06:10:30 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 09:18:31 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 09:44:40 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Don\u00e0", "J\u00e9r\u00e9mie", "", "MLIA"], ["Franceschi", "Jean-Yves", "", "MLIA"], ["Lamprier", "Sylvain", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2008.01362", "submitter": "Jong Chul Ye", "authors": "Hyungjin Chung, Eunju Cha, Leonard Sunwoo, and Jong Chul Ye", "title": "Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without\n  Matched Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-of-flight magnetic resonance angiography (TOF-MRA) is one of the most\nwidely used non-contrast MR imaging methods to visualize blood vessels, but due\nto the 3-D volume acquisition highly accelerated acquisition is necessary.\nAccordingly, high quality reconstruction from undersampled TOF-MRA is an\nimportant research topic for deep learning. However, most existing deep\nlearning works require matched reference data for supervised training, which\nare often difficult to obtain. By extending the recent theoretical\nunderstanding of cycleGAN from the optimal transport theory, here we propose a\nnovel two-stage unsupervised deep learning approach, which is composed of the\nmulti-coil reconstruction network along the coronal plane followed by a\nmulti-planar refinement network along the axial plane. Specifically, the first\nnetwork is trained in the square-root of sum of squares (SSoS) domain to\nachieve high quality parallel image reconstruction, whereas the second\nrefinement network is designed to efficiently learn the characteristics of\nhighly-activated blood flow using double-headed max-pool discriminator.\nExtensive experiments demonstrate that the proposed learning process without\nmatched reference exceeds performance of state-of-the-art compressed sensing\n(CS)-based method and provides comparable or even better results than\nsupervised learning approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 06:36:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chung", "Hyungjin", ""], ["Cha", "Eunju", ""], ["Sunwoo", "Leonard", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.01375", "submitter": "Hongsong Yuan", "authors": "Fengnan Gao, Zongming Ma, Hongsong Yuan", "title": "Community detection in sparse latent space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a simple community detection algorithm originated from\nstochastic blockmodel literature achieves consistency, and even optimality, for\na broad and flexible class of sparse latent space models. The class of models\nincludes latent eigenmodels (arXiv:0711.1146). The community detection\nalgorithm is based on spectral clustering followed by local refinement via\nnormalized edge counting.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:12:15 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gao", "Fengnan", ""], ["Ma", "Zongming", ""], ["Yuan", "Hongsong", ""]]}, {"id": "2008.01377", "submitter": "Stefan Heid", "authors": "Stefan Heid, Marcel Wever, Eyke H\\\"ullermeier", "title": "Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued\n  Prediction", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a\nkey requirement for both linguistic research and subsequent automated natural\nlanguage processing (NLP) tasks. This problem is commonly tackled using machine\nlearning methods, i.e., by training a POS tagger on a sufficiently large corpus\nof labeled data. While the problem of POS tagging can essentially be considered\nas solved for modern languages, historical corpora turn out to be much more\ndifficult, especially due to the lack of native speakers and sparsity of\ntraining data. Moreover, most texts have no sentences as we know them today,\nnor a common orthography. These irregularities render the task of automated POS\ntagging more difficult and error-prone. Under these circumstances, instead of\nforcing the POS tagger to predict and commit to a single tag, it should be\nenabled to express its uncertainty. In this paper, we consider POS tagging\nwithin the framework of set-valued prediction, which allows the POS tagger to\nexpress its uncertainty via predicting a set of candidate POS tags instead of\nguessing a single one. The goal is to guarantee a high confidence that the\ncorrect POS tag is included while keeping the number of candidates small. In\nour experimental study, we find that extending state-of-the-art POS taggers to\nset-valued prediction yields more precise and robust taggings, especially for\nunknown words, i.e., words not occurring in the training data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:21:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 12:59:57 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Heid", "Stefan", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2008.01389", "submitter": "Jogendra Nath Kundu", "authors": "Jogendra Nath Kundu, Rahul Mysore Venkatesh, Naveen Venkat, Ambareesh\n  Revanur, R. Venkatesh Babu", "title": "Class-Incremental Domain Adaptation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a practical Domain Adaptation (DA) paradigm called\nClass-Incremental Domain Adaptation (CIDA). Existing DA methods tackle\ndomain-shift but are unsuitable for learning novel target-domain classes.\nMeanwhile, class-incremental (CI) methods enable learning of new classes in\nabsence of source training data but fail under a domain-shift without labeled\nsupervision. In this work, we effectively identify the limitations of these\napproaches in the CIDA paradigm. Motivated by theoretical and empirical\nobservations, we propose an effective method, inspired by prototypical\nnetworks, that enables classification of target samples into both shared and\nnovel (one-shot) target classes, even under a domain-shift. Our approach yields\nsuperior performance as compared to both DA and CI methods in the CIDA\nparadigm.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:55:03 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Kundu", "Jogendra Nath", ""], ["Venkatesh", "Rahul Mysore", ""], ["Venkat", "Naveen", ""], ["Revanur", "Ambareesh", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2008.01411", "submitter": "Xi Li", "authors": "Hanbin Zhao, Hui Wang, Yongjian Fu, Fei Wu, Xi Li", "title": "Memory Efficient Class-Incremental Learning for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the memory-resource-limited constraints, class-incremental learning\n(CIL) usually suffers from the \"catastrophic forgetting\" problem when updating\nthe joint classification model on the arrival of newly added classes. To cope\nwith the forgetting problem, many CIL methods transfer the knowledge of old\nclasses by preserving some exemplar samples into the size-constrained memory\nbuffer. To utilize the memory buffer more efficiently, we propose to keep more\nauxiliary low-fidelity exemplar samples rather than the original real\nhigh-fidelity exemplar samples. Such a memory-efficient exemplar preserving\nscheme makes the old-class knowledge transfer more effective. However, the\nlow-fidelity exemplar samples are often distributed in a different domain away\nfrom that of the original exemplar samples, that is, a domain shift. To\nalleviate this problem, we propose a duplet learning scheme that seeks to\nconstruct domain-compatible feature extractors and classifiers, which greatly\nnarrows down the above domain gap. As a result, these low-fidelity auxiliary\nexemplar samples have the ability to moderately replace the original exemplar\nsamples with a lower memory cost. In addition, we present a robust classifier\nadaptation scheme, which further refines the biased classifier (learned with\nthe samples containing distillation label knowledge about old classes) with the\nhelp of the samples of pure true class labels. Experimental results demonstrate\nthe effectiveness of this work against the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:39:40 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 13:32:08 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhao", "Hanbin", ""], ["Wang", "Hui", ""], ["Fu", "Yongjian", ""], ["Wu", "Fei", ""], ["Li", "Xi", ""]]}, {"id": "2008.01425", "submitter": "Thijs Vogels", "authors": "Thijs Vogels and Sai Praneeth Karimireddy and Martin Jaggi", "title": "PowerGossip: Practical Low-Rank Communication Compression in\n  Decentralized Deep Learning", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy gradient compression has become a practical tool to overcome the\ncommunication bottleneck in centrally coordinated distributed training of\nmachine learning models. However, algorithms for decentralized training with\ncompressed communication over arbitrary connected networks have been more\ncomplicated, requiring additional memory and hyperparameters. We introduce a\nsimple algorithm that directly compresses the model differences between\nneighboring workers using low-rank linear compressors applied on model\ndifferences. Inspired by the PowerSGD algorithm for centralized deep learning,\nthis algorithm uses power iteration steps to maximize the information\ntransferred per bit. We prove that our method requires no additional\nhyperparameters, converges faster than prior methods, and is asymptotically\nindependent of both the network and the compression. Out of the box, these\ncompressors perform on par with state-of-the-art tuned compression algorithms\nin a series of deep learning benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 09:14:52 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:07:50 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Vogels", "Thijs", ""], ["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""]]}, {"id": "2008.01454", "submitter": "Feng Liu", "authors": "Yiyang Zhang, Feng Liu, Zhen Fang, Bo Yuan, Guangquan Zhang, Jie Lu", "title": "Learning from a Complementary-label Source Domain: Theory and Algorithms", "comments": "arXiv admin note: text overlap with arXiv:2007.14612", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In unsupervised domain adaptation (UDA), a classifier for the target domain\nis trained with massive true-label data from the source domain and unlabeled\ndata from the target domain. However, collecting fully-true-label data in the\nsource domain is high-cost and sometimes impossible. Compared to the true\nlabels, a complementary label specifies a class that a pattern does not belong\nto, hence collecting complementary labels would be less laborious than\ncollecting true labels. Thus, in this paper, we propose a novel setting that\nthe source domain is composed of complementary-label data, and a theoretical\nbound for it is first proved. We consider two cases of this setting, one is\nthat the source domain only contains complementary-label data (completely\ncomplementary unsupervised domain adaptation, CC-UDA), and the other is that\nthe source domain has plenty of complementary-label data and a small amount of\ntrue-label data (partly complementary unsupervised domain adaptation, PC-UDA).\nTo this end, a complementary label adversarial network} (CLARINET) is proposed\nto solve CC-UDA and PC-UDA problems. CLARINET maintains two deep networks\nsimultaneously, where one focuses on classifying complementary-label source\ndata and the other takes care of source-to-target distributional adaptation.\nExperiments show that CLARINET significantly outperforms a series of competent\nbaselines on handwritten-digits-recognition and objects-recognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:49:35 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhang", "Yiyang", ""], ["Liu", "Feng", ""], ["Fang", "Zhen", ""], ["Yuan", "Bo", ""], ["Zhang", "Guangquan", ""], ["Lu", "Jie", ""]]}, {"id": "2008.01468", "submitter": "Kai Fabi", "authors": "Kai Fabi, Jonas Schneider", "title": "On Feature Relevance Uncertainty: A Monte Carlo Dropout Sampling\n  Approach", "comments": "18 pages, 15 figures", "journal-ref": null, "doi": "10.5281/zenodo.3970396", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding decisions made by neural networks is key for the deployment of\nintelligent systems in real world applications. However, the opaque decision\nmaking process of these systems is a disadvantage where interpretability is\nessential. Many feature-based explanation techniques have been introduced over\nthe last few years in the field of machine learning to better understand\ndecisions made by neural networks and have become an important component to\nverify their reasoning capabilities. However, existing methods do not allow\nstatements to be made about the uncertainty regarding a feature's relevance for\nthe prediction. In this paper, we introduce Monte Carlo Relevance Propagation\n(MCRP) for feature relevance uncertainty estimation. A simple but powerful\nmethod based on Monte Carlo estimation of the feature relevance distribution to\ncompute feature relevance uncertainty scores that allow a deeper understanding\nof a neural network's perception and reasoning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 11:31:16 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Fabi", "Kai", ""], ["Schneider", "Jonas", ""]]}, {"id": "2008.01487", "submitter": "Yacov Hel-Or", "authors": "Alon Oring and Zohar Yakhini and Yacov Hel-Or", "title": "Autoencoder Image Interpolation by Shaping the Latent Space", "comments": "Submitted Sept 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders represent an effective approach for computing the underlying\nfactors characterizing datasets of different types. The latent representation\nof autoencoders have been studied in the context of enabling interpolation\nbetween data points by decoding convex combinations of latent vectors. This\ninterpolation, however, often leads to artifacts or produces unrealistic\nresults during reconstruction. We argue that these incongruities are due to the\nstructure of the latent space and because such naively interpolated latent\nvectors deviate from the data manifold. In this paper, we propose a\nregularization technique that shapes the latent representation to follow a\nmanifold that is consistent with the training images and that drives the\nmanifold to be smooth and locally convex. This regularization not only enables\nfaithful interpolation between data points, as we show herein, but can also be\nused as a general regularization technique to avoid overfitting or to produce\nnew samples for data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 12:32:54 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 02:03:08 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Oring", "Alon", ""], ["Yakhini", "Zohar", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2008.01503", "submitter": "Ming-Wei Li", "authors": "Ming-Wei Li, Qing-Yuan Jiang, Wu-Jun Li", "title": "Multiple Code Hashing for Efficient Image Retrieval", "comments": "12 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its low storage cost and fast query speed, hashing has been widely\nused in large-scale image retrieval tasks. Hash bucket search returns data\npoints within a given Hamming radius to each query, which can enable search at\na constant or sub-linear time cost. However, existing hashing methods cannot\nachieve satisfactory retrieval performance for hash bucket search in complex\nscenarios, since they learn only one hash code for each image. More\nspecifically, by using one hash code to represent one image, existing methods\nmight fail to put similar image pairs to the buckets with a small Hamming\ndistance to the query when the semantic information of images is complex. As a\nresult, a large number of hash buckets need to be visited for retrieving\nsimilar images, based on the learned codes. This will deteriorate the\nefficiency of hash bucket search. In this paper, we propose a novel hashing\nframework, called multiple code hashing (MCH), to improve the performance of\nhash bucket search. The main idea of MCH is to learn multiple hash codes for\neach image, with each code representing a different region of the image.\nFurthermore, we propose a deep reinforcement learning algorithm to learn the\nparameters in MCH. To the best of our knowledge, this is the first work that\nproposes to learn multiple hash codes for each image in image retrieval.\nExperiments demonstrate that MCH can achieve a significant improvement in hash\nbucket search, compared with existing methods that learn only one hash code for\neach image.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:18:19 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Li", "Ming-Wei", ""], ["Jiang", "Qing-Yuan", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2008.01505", "submitter": "Charlie Dickens", "authors": "Charlie Dickens, Eric Meissner, Pablo G. Moreno, Tom Diethe", "title": "Interpretable Anomaly Detection with Mondrian P{\\'o}lya Forests on Data\n  Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection at scale is an extremely challenging problem of great\npracticality. When data is large and high-dimensional, it can be difficult to\ndetect which observations do not fit the expected behaviour. Recent work has\ncoalesced on variations of (random) $k$\\emph{d-trees} to summarise data for\nanomaly detection. However, these methods rely on ad-hoc score functions that\nare not easy to interpret, making it difficult to asses the severity of the\ndetected anomalies or select a reasonable threshold in the absence of labelled\nanomalies. To solve these issues, we contextualise these methods in a\nprobabilistic framework which we call the Mondrian \\Polya{} Forest for\nestimating the underlying probability density function generating the data and\nenabling greater interpretability than prior work. In addition, we develop a\nmemory efficient variant able to operate in the modern streaming environments.\nOur experiments show that these methods achieves state-of-the-art performance\nwhile providing statistically interpretable anomaly scores.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:19:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dickens", "Charlie", ""], ["Meissner", "Eric", ""], ["Moreno", "Pablo G.", ""], ["Diethe", "Tom", ""]]}, {"id": "2008.01524", "submitter": "Deepak Ravikumar", "authors": "Deepak Ravikumar, Sangamesh Kodge, Isha Garg, Kaushik Roy", "title": "TREND: Transferability based Robust ENsemble Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning models hold state-of-the-art performance in many fields, but\ntheir vulnerability to adversarial examples poses threat to their ubiquitous\ndeployment in practical settings. Additionally, adversarial inputs generated on\none classifier have been shown to transfer to other classifiers trained on\nsimilar data, which makes the attacks possible even if model parameters are not\nrevealed to the adversary. This property of transferability has not yet been\nsystematically studied, leading to a gap in our understanding of robustness of\nneural networks to adversarial inputs. In this work, we study the effect of\nnetwork architecture, initialization, optimizer, input, weight and activation\nquantization on transferability of adversarial samples. We also study the\neffect of different attacks on transferability. Our experiments reveal that\ntransferability is significantly hampered by input quantization and\narchitectural mismatch between source and target, is unaffected by\ninitialization but the choice of optimizer turns out to be critical. We observe\nthat transferability is architecture-dependent for both weight and activation\nquantized models. To quantify transferability, we use simple metric and\ndemonstrate the utility of the metric in designing a methodology to build\nensembles with improved adversarial robustness. When attacking ensembles we\nobserve that \"gradient domination\" by a single ensemble member model hampers\nexisting attacks. To combat this we propose a new state-of-the-art ensemble\nattack. We compare the proposed attack with existing attack techniques to show\nits effectiveness. Finally, we show that an ensemble consisting of carefully\nchosen diverse networks achieves better adversarial robustness than would\notherwise be possible with a single network.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:38:14 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 17:00:39 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ravikumar", "Deepak", ""], ["Kodge", "Sangamesh", ""], ["Garg", "Isha", ""], ["Roy", "Kaushik", ""]]}, {"id": "2008.01531", "submitter": "Maren Awiszus", "authors": "Maren Awiszus, Frederik Schubert, Bodo Rosenhahn", "title": "TOAD-GAN: Coherent Style Level Generation from a Single Example", "comments": "7 pages, 7 figures. AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment (AIIDE) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present TOAD-GAN (Token-based One-shot Arbitrary Dimension\nGenerative Adversarial Network), a novel Procedural Content Generation (PCG)\nalgorithm that generates token-based video game levels. TOAD-GAN follows the\nSinGAN architecture and can be trained using only one example. We demonstrate\nits application for Super Mario Bros. levels and are able to generate new\nlevels of similar style in arbitrary sizes. We achieve state-of-the-art results\nin modeling the patterns of the training level and provide a comparison with\ndifferent baselines under several metrics. Additionally, we present an\nextension of the method that allows the user to control the generation process\nof certain token structures to ensure a coherent global level layout. We\nprovide this tool to the community to spur further research by publishing our\nsource code.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:44:50 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Awiszus", "Maren", ""], ["Schubert", "Frederik", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2008.01543", "submitter": "Joppe Wouts", "authors": "Joppe Valentijn Wouts", "title": "Text-based classification of interviews for mental health -- juxtaposing\n  the state of the art", "comments": "33 pages, 7 figures, belabBERT is available on\n  http://github.com/Joppewouts/belabBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the state of the art for classification of psychiatric illness is\nbased on audio-based classification. This thesis aims to design and evaluate a\nstate of the art text classification network on this challenge. The hypothesis\nis that a well designed text-based approach poses a strong competition against\nthe state-of-the-art audio based approaches. Dutch natural language models are\nbeing limited by the scarcity of pre-trained monolingual NLP models, as a\nresult Dutch natural language models have a low capture of long range semantic\ndependencies over sentences. For this issue, this thesis presents belabBERT, a\nnew Dutch language model extending the RoBERTa[15] architecture. belabBERT is\ntrained on a large Dutch corpus (+32GB) of web crawled texts. After this thesis\nevaluates the strength of text-based classification, a brief exploration is\ndone, extending the framework to a hybrid text- and audio-based classification.\nThe goal of this hybrid framework is to show the principle of hybridisation\nwith a very basic audio-classification network. The overall goal is to create\nthe foundations for a hybrid psychiatric illness classification, by proving\nthat the new text-based classification is already a strong stand-alone\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:19:30 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wouts", "Joppe Valentijn", ""]]}, {"id": "2008.01558", "submitter": "Yanmin Gong", "authors": "Rui Hu and Yanmin Gong and Yuanxiong Guo", "title": "Federated Learning with Sparsification-Amplified Privacy and Adaptive\n  Optimization", "comments": "Accepted in IJCAI 2021, this is the full version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables distributed agents to collaboratively learn a\ncentralized model without sharing their raw data with each other. However, data\nlocality does not provide sufficient privacy protection, and it is desirable to\nfacilitate FL with rigorous differential privacy (DP) guarantee. Existing DP\nmechanisms would introduce random noise with magnitude proportional to the\nmodel size, which can be quite large in deep neural networks. In this paper, we\npropose a new FL framework with sparsification-amplified privacy. Our approach\nintegrates random sparsification with gradient perturbation on each agent to\namplify privacy guarantee. Since sparsification would increase the number of\ncommunication rounds required to achieve a certain target accuracy, which is\nunfavorable for DP guarantee, we further introduce acceleration techniques to\nhelp reduce the privacy cost. We rigorously analyze the convergence of our\napproach and utilize Renyi DP to tightly account the end-to-end DP guarantee.\nExtensive experiments on benchmark datasets validate that our approach\noutperforms previous differentially-private FL approaches in both privacy\nguarantee and communication efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:22:57 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 20:18:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hu", "Rui", ""], ["Gong", "Yanmin", ""], ["Guo", "Yuanxiong", ""]]}, {"id": "2008.01571", "submitter": "Sabina Tomkins", "authors": "Sabina Tomkins, Peng Liao, Predrag Klasnja and Susan Murphy", "title": "IntelligentPooling: Practical Thompson Sampling for mHealth", "comments": "arXiv admin note: text overlap with arXiv:2002.09971", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile health (mHealth) smart devices deliver behavioral treatments\nrepeatedly over time to a user with the goal of helping the user adopt and\nmaintain healthy behaviors. Reinforcement learning appears ideal for learning\nhow to optimally make these sequential treatment decisions. However,\nsignificant challenges must be overcome before reinforcement learning can be\neffectively deployed in a mobile healthcare setting. In this work we are\nconcerned with the following challenges: 1) individuals who are in the same\ncontext can exhibit differential response to treatments 2) only a limited\namount of data is available for learning on any one individual, and 3)\nnon-stationary responses to treatment. To address these challenges we\ngeneralize Thompson-Sampling bandit algorithms to develop IntelligentPooling.\nIntelligentPooling learns personalized treatment policies thus addressing\nchallenge one. To address the second challenge, IntelligentPooling updates each\nuser's degree of personalization while making use of available data on other\nusers to speed up learning. Lastly, IntelligentPooling allows responsivity to\nvary as a function of a user's time since beginning treatment, thus addressing\nchallenge three. We show that IntelligentPooling achieves an average of 26%\nlower regret than state-of-the-art. We demonstrate the promise of this approach\nand its ability to learn from even a small group of users in a live clinical\ntrial.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:03:09 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 21:30:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tomkins", "Sabina", ""], ["Liao", "Peng", ""], ["Klasnja", "Predrag", ""], ["Murphy", "Susan", ""]]}, {"id": "2008.01593", "submitter": "Junchi Liang", "authors": "Junchi Liang and Abdeslam Boularias", "title": "Learning Transition Models with Time-delayed Causal Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an algorithm for discovering implicit and delayed\ncausal relations between events observed by a robot at arbitrary times, with\nthe objective of improving data-efficiency and interpretability of model-based\nreinforcement learning (RL) techniques. The proposed algorithm initially\npredicts observations with the Markov assumption, and incrementally introduces\nnew hidden variables to explain and reduce the stochasticity of the\nobservations. The hidden variables are memory units that keep track of\npertinent past events. Such events are systematically identified by their\ninformation gains. The learned transition and reward models are then used for\nplanning. Experiments on simulated and real robotic tasks show that this method\nsignificantly improves over current RL techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:35:11 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liang", "Junchi", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "2008.01604", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "Adaptive Physics-Informed Neural Networks for Markov-Chain Monte Carlo", "comments": "arXiv admin note: text overlap with arXiv:1806.02957", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Adaptive Physics-Informed Neural Networks\n(APINNs) for accurate and efficient simulation-free Bayesian parameter\nestimation via Markov-Chain Monte Carlo (MCMC). We specifically focus on a\nclass of parameter estimation problems for which computing the likelihood\nfunction requires solving a PDE. The proposed method consists of: (1)\nconstructing an offline PINN-UQ model as an approximation to the forward model;\nand (2) refining this approximate model on the fly using samples generated from\nthe MCMC sampler. The proposed APINN method constantly refines this approximate\nmodel on the fly and guarantees that the approximation error is always less\nthan a user-defined residual error threshold. We numerically demonstrate the\nperformance of the proposed APINN method in solving a parameter estimation\nproblem for a system governed by the Poisson equation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:25:10 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "2008.01613", "submitter": "Haotian Li", "authors": "Haotian Li, Huan Wei, Yong Wang, Yangqiu Song, Huamin Qu", "title": "Peer-inspired Student Performance Prediction in Interactive Online\n  Question Pools with Graph Neural Network", "comments": "8 pages, 8 figures. Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412733", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student performance prediction is critical to online education. It can\nbenefit many downstream tasks on online learning platforms, such as estimating\ndropout rates, facilitating strategic intervention, and enabling adaptive\nonline learning. Interactive online question pools provide students with\ninteresting interactive questions to practice their knowledge in online\neducation. However, little research has been done on student performance\nprediction in interactive online question pools. Existing work on student\nperformance prediction targets at online learning platforms with predefined\ncourse curriculum and accurate knowledge labels like MOOC platforms, but they\nare not able to fully model knowledge evolution of students in interactive\nonline question pools. In this paper, we propose a novel approach using Graph\nNeural Networks (GNNs) to achieve better student performance prediction in\ninteractive online question pools. Specifically, we model the relationship\nbetween students and questions using student interactions to construct the\nstudent-interaction-question network and further present a new GNN model,\ncalled R^2GCN, which intrinsically works for the heterogeneous networks, to\nachieve generalizable student performance prediction in interactive online\nquestion pools. We evaluate the effectiveness of our approach on a real-world\ndataset consisting of 104,113 mouse trajectories generated in the\nproblem-solving process of over 4000 students on 1631 questions. The experiment\nresults show that our approach can achieve a much higher accuracy of student\nperformance prediction than both traditional machine learning approaches and\nGNN models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:55:32 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 07:47:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Li", "Haotian", ""], ["Wei", "Huan", ""], ["Wang", "Yong", ""], ["Song", "Yangqiu", ""], ["Qu", "Huamin", ""]]}, {"id": "2008.01623", "submitter": "Mohcine Madkour", "authors": "Mohcine Madkour, Keith Butler, Eric Mercer, Ali Bahrami, Cui Tao", "title": "Semantic based model of Conceptual Work Products for formal verification\n  of complex interactive systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many clinical workflows depend on interactive computer systems for highly\ntechnical, conceptual work products, such as diagnoses, treatment plans, care\ncoordination, and case management. We describe an automatic logic reasoner to\nverify objective specifications for these highly technical, but abstract, work\nproducts that are essential to care. The conceptual work products\nspecifications serve as a fundamental output requirement, which must be clearly\nstated, correct and solvable. There is strategic importance for such\nspecifications because, in turn, they enable system model checking to verify\nthat machine functions taken with user procedures are actually able to achieve\nthese abstract products. We chose case management of Multiple Sclerosis (MS)\noutpatients as our use case for its challenging complexity. As a first step, we\nillustrate how graphical class and state diagrams from UML can be developed and\ncritiqued with subject matter experts to serve as specifications of the\nconceptual work product of case management. A key feature is that the\nspecification must be declarative and thus independent of any process or\ntechnology. Our Work Domain Ontology with tools from Semantic Web is needed to\ntranslate UML class and state diagrams for verification of solvability with\nautomatic reasoning. The solvable model will then be ready for subsequent use\nwith model checking on the system of human procedures and machine functions. We\nused the expressive rule language SPARQL Inferencing Notation (SPIN) to develop\nformal representations of the UML class diagram, the state machine, and their\ninteractions. Using SPIN, we proved the consistency of the interactions of\nstatic and dynamic concepts. We discussed how the new SPIN rule engine could be\nincorporated in the Object Management Group (OMG) Ontology Definition Metamodel\n(ODM)\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:10:44 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Madkour", "Mohcine", ""], ["Butler", "Keith", ""], ["Mercer", "Eric", ""], ["Bahrami", "Ali", ""], ["Tao", "Cui", ""]]}, {"id": "2008.01664", "submitter": "Alastair Flynn Mr", "authors": "Alastair Flynn", "title": "Inducing game rules from varying quality game play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  General Game Playing (GGP) is a framework in which an artificial intelligence\nprogram is required to play a variety of games successfully. It acts as a test\nbed for AI and motivator of research. The AI is given a random game description\nat runtime which it then plays. The framework includes repositories of game\nrules. The Inductive General Game Playing (IGGP) problem challenges machine\nlearning systems to learn these GGP game rules by watching the game being\nplayed. In other words, IGGP is the problem of inducing general game rules from\nspecific game observations. Inductive Logic Programming (ILP) has shown to be a\npromising approach to this problem though it has been demonstrated that it is\nstill a hard problem for ILP systems. Existing work on IGGP has always assumed\nthat the game player being observed makes random moves. This is not\nrepresentative of how a human learns to play a game. With random gameplay\nsituations that would normally be encountered when humans play are not present.\nTo address this limitation, we analyse the effect of using intelligent versus\nrandom gameplay traces as well as the effect of varying the number of traces in\nthe training set. We use Sancho, the 2014 GGP competition winner, to generate\nintelligent game traces for a large number of games. We then use the ILP\nsystems, Metagol, Aleph and ILASP to induce game rules from the traces. We\ntrain and test the systems on combinations of intelligent and random data\nincluding a mixture of both. We also vary the volume of training data. Our\nresults show that whilst some games were learned more effectively in some of\nthe experiments than others no overall trend was statistically significant. The\nimplications of this work are that varying the quality of training data as\ndescribed in this paper has strong effects on the accuracy of the learned game\nrules; however one solution does not work for all games.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:46:57 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Flynn", "Alastair", ""]]}, {"id": "2008.01670", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Chin-Chia Michael Yeh, Liang Wang, Wei Zhang,\n  Junpeng Wang", "title": "Multi-stream RNN for Merchant Transaction Prediction", "comments": "Accepted by KDD 2020 Workshop on Machine Learning in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, digital payment systems have significantly changed people's\nlifestyles. New challenges have surfaced in monitoring and guaranteeing the\nintegrity of payment processing systems. One important task is to predict the\nfuture transaction statistics of each merchant. These predictions can thus be\nused to steer other tasks, ranging from fraud detection to recommendation. This\nproblem is challenging as we need to predict not only multivariate time series\nbut also multi-steps into the future. In this work, we propose a multi-stream\nRNN model for multi-step merchant transaction predictions tailored to these\nrequirements. The proposed multi-stream RNN summarizes transaction data in\ndifferent granularity and makes predictions for multiple steps in the future.\nOur extensive experimental results have demonstrated that the proposed model is\ncapable of outperforming existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 01:20:48 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Yeh", "Chin-Chia Michael", ""], ["Wang", "Liang", ""], ["Zhang", "Wei", ""], ["Wang", "Junpeng", ""]]}, {"id": "2008.01674", "submitter": "Janak Parmar", "authors": "Janak Parmar, Pritikana Das, Sanjaykumar Dave", "title": "A Machine Learning Approach for Modelling Parking Duration in Urban\n  Land-use", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications, 2021", "doi": "10.1016/j.physa.2021.125873", "report-no": null, "categories": "stat.ML cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parking is an inevitable issue in the fast-growing developing countries.\nIncreasing number of vehicles require more and more urban land to be allocated\nfor parking. However, a little attention has been conferred to the parking\nissues in developing countries like India. This study proposes a model for\nanalysing the influence of car users' socioeconomic and travel characteristics\non parking duration. Specifically, artificial neural networks (ANNs) is\ndeployed to capture the interrelationship between driver characteristics and\nparking duration. ANNs are highly efficient in learning and recognizing\nconnections between parameters for best prediction of an outcome. Since,\nutility of ANNs has been critically limited due to its Black Box nature, the\nstudy involves the use of Garson algorithm and Local interpretable\nmodel-agnostic explanations (LIME) for model interpretations. LIME shows the\nprediction for any classification, by approximating it locally with the\ndeveloped interpretable model. This study is based on microdata collected\non-site through interview surveys considering two land-uses: office-business\nand market/shopping. Results revealed the higher probability of prediction\nthrough LIME and therefore, the methodology can be adopted ubiquitously.\nFurther, the policy implications are discussed based on the results for both\nland-uses. This unique study could lead to enhanced parking policy and\nmanagement to achieve the sustainability goals.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:05:59 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Parmar", "Janak", ""], ["Das", "Pritikana", ""], ["Dave", "Sanjaykumar", ""]]}, {"id": "2008.01683", "submitter": "Marco Scutari", "authors": "Laura Azzimonti, Giorgio Corani and Marco Scutari", "title": "A Bayesian Hierarchical Score for Structure Learning from Related Data\n  Sets", "comments": null, "journal-ref": "Proceedings of Machine Learning Research (138, PGM 2020), 5-16", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score functions for learning the structure of Bayesian networks in the\nliterature assume that data are a homogeneous set of observations; whereas it\nis often the case that they comprise different related, but not homogeneous,\ndata sets collected in different ways. In this paper we propose a new Bayesian\nDirichlet score, which we call Bayesian Hierarchical Dirichlet (BHD). The\nproposed score is based on a hierarchical model that pools information across\ndata sets to learn a single encompassing network structure, while taking into\naccount the differences in their probabilistic structures. We derive a\nclosed-form expression for BHD using a variational approximation of the\nmarginal likelihood, we study the associated computational cost and we evaluate\nits performance using simulated data. We find that, when data comprise multiple\nrelated data sets, BHD outperforms the Bayesian Dirichlet equivalent uniform\n(BDeu) score in terms of reconstruction accuracy as measured by the Structural\nHamming distance, and that it is as accurate as BDeu when data are homogeneous.\nThis improvement is particularly clear when either the number of variables in\nthe network or the number of observations is large. Moreover, the estimated\nnetworks are sparser and therefore more interpretable than those obtained with\nBDeu thanks to a lower number of false positive arcs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:41:05 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 16:25:21 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 16:32:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Azzimonti", "Laura", ""], ["Corani", "Giorgio", ""], ["Scutari", "Marco", ""]]}, {"id": "2008.01684", "submitter": "Christian B\\\"ohm", "authors": "Christian B\\\"ohm", "title": "Space-filling Curves for High-performance Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-filling curves like the Hilbert-curve, Peano-curve and Z-order map\nnatural or real numbers from a two or higher dimensional space to a one\ndimensional space preserving locality. They have numerous applications like\nsearch structures, computer graphics, numerical simulation, cryptographics and\ncan be used to make various algorithms cache-oblivious. In this paper, we\ndescribe some details of the Hilbert-curve. We define the Hilbert-curve in\nterms of a finite automaton of Mealy-type which determines from the\ntwo-dimensional coordinate space the Hilbert order value and vice versa in a\nlogarithmic number of steps. And we define a context-free grammar to generate\nthe whole curve in a time which is linear in the number of generated\ncoordinate/order value pairs, i.e. a constant time per coordinate pair or order\nvalue. We also review two different strategies which enable the generation of\ncurves without the usual restriction to square-like grids where the side-length\nis a power of two. Finally, we elaborate on a few applications, namely matrix\nmultiplication, Cholesky decomposition, the Floyd-Warshall algorithm, k-Means\nclustering, and the similarity join.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:41:16 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["B\u00f6hm", "Christian", ""]]}, {"id": "2008.01686", "submitter": "Assaf Ben-Yishai", "authors": "Assaf Ben-Yishai and Ofer Shayevitz", "title": "Simple Modulo can Significantly Outperform Deep Learning-based Deepcode", "comments": "Technical Report, 4 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepcode (H.Kim et al.2018) is a recently suggested Deep Learning-based\nscheme for communication over the AWGN channel with noisy feedback, claimed to\nbe superior to all previous schemes in the literature. Deepcode's use of\nnonlinear coding (via Deep Learning) has been inspired by known shortcomings\n(Y.-H. Kim et al 2007) of linear feedback schemes. In 2014, we presented a\nnonlinear feedback coding scheme based on a combination of the classical SK\nscheme and modulo-arithmetic, using a small number of elementary operations\nwithout any type of neural network. This Modulo-SK scheme has been omitted from\nthe performance comparisons made in the Deepcode paper, due to its use of\ncommon randomness (dither), and in a later version since it was incorrectly\ninterpreted as a variable-length coding scheme. However, the dither in\nModulo-SK was used only for the standard purpose of tractable performance\nanalysis, and is not required in practice. In this short note, we show that a\nfully-deterministic Modulo-SK (without dithering) can outperform Deepcode. For\nexample, to attain an error probability of 10^(-4) at rate 1/3 Modulo-SK\nrequires 3dB less feedback SNR than Deepcode. To attain an error probability of\n10^(-6) with noiseless feedback, Deepcode requires 150 rounds of communication,\nwhereas Modulo-SK requires only 15 rounds, even if the feedback is noisy (with\n27dB SNR).\n  We further address the numerical stability issues of the original SK scheme\nreported in the Deepcode paper, and explain how they can be avoided. We augment\nthis report with an online-available, fully-functional Matlab simulation for\nboth the classical and Modulo-SK schemes. Finally, note that Modulo-SK is by no\nmeans claimed to be the best possible solution; in particular, using deep\nlearning in conjunction with modulo-arithmetic might lead to better designs,\nand remains a fascinating direction for future research.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:43:26 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 16:58:35 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Ben-Yishai", "Assaf", ""], ["Shayevitz", "Ofer", ""]]}, {"id": "2008.01687", "submitter": "Claudio Nordio", "authors": "A. R. Provenzano, D. Trifir\\`o, A. Datteo, L. Giada, N. Jean, A.\n  Riciputi, G. Le Pera, M. Spadaccino, L. Massaron and C. Nordio", "title": "Machine Learning approach for Credit Scoring", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we build a stack of machine learning models aimed at composing a\nstate-of-the-art credit rating and default prediction system, obtaining\nexcellent out-of-sample performances. Our approach is an excursion through the\nmost recent ML / AI concepts, starting from natural language processes (NLP)\napplied to economic sectors' (textual) descriptions using embedding and\nautoencoders (AE), going through the classification of defaultable firms on the\nbase of a wide range of economic features using gradient boosting machines\n(GBM) and calibrating their probabilities paying due attention to the treatment\nof unbalanced samples. Finally we assign credit ratings through genetic\nalgorithms (differential evolution, DE). Model interpretability is achieved by\nimplementing recent techniques such as SHAP and LIME, which explain predictions\nlocally in features' space.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 21:29:06 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Provenzano", "A. R.", ""], ["Trifir\u00f2", "D.", ""], ["Datteo", "A.", ""], ["Giada", "L.", ""], ["Jean", "N.", ""], ["Riciputi", "A.", ""], ["Pera", "G. Le", ""], ["Spadaccino", "M.", ""], ["Massaron", "L.", ""], ["Nordio", "C.", ""]]}, {"id": "2008.01710", "submitter": "Saba Ahmadi", "authors": "Saba Ahmadi, Hedyeh Beyhaghi, Avrim Blum, Keziah Naggita", "title": "The Strategic Perceptron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Perceptron algorithm provides a simple and elegant procedure\nfor learning a linear classifier. In each step, the algorithm observes the\nsample's position and label and updates the current predictor accordingly if it\nmakes a mistake. However, in presence of strategic agents that desire to be\nclassified as positive and that are able to modify their position by a limited\namount, the classifier may not be able to observe the true position of agents\nbut rather a position where the agent pretends to be. Unlike the original\nsetting with perfect knowledge of positions, in this situation the Perceptron\nalgorithm fails to achieve its guarantees, and we illustrate examples with the\npredictor oscillating between two solutions forever, making an unbounded number\nof mistakes even though a perfect large-margin linear classifier exists. Our\nmain contribution is providing a modified Perceptron-style algorithm which\nmakes a bounded number of mistakes in presence of strategic agents with both\n$\\ell_2$ and weighted $\\ell_1$ manipulation costs. In our baseline model,\nknowledge of the manipulation costs (i.e., the extent to which an agent may\nmanipulate) is assumed. In our most general model, we relax this assumption and\nprovide an algorithm which learns and refines both the classifier and its cost\nestimates to achieve good mistake bounds even when manipulation costs are\nunknown.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:20:24 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 21:50:17 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Ahmadi", "Saba", ""], ["Beyhaghi", "Hedyeh", ""], ["Blum", "Avrim", ""], ["Naggita", "Keziah", ""]]}, {"id": "2008.01712", "submitter": "Gabriel Kalweit", "authors": "Gabriel Kalweit, Maria Huegle, Moritz Werling, Joschka Boedecker", "title": "Deep Inverse Q-learning with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular Maximum Entropy Inverse Reinforcement Learning approaches require the\ncomputation of expected state visitation frequencies for the optimal policy\nunder an estimate of the reward function. This usually requires intermediate\nvalue estimation in the inner loop of the algorithm, slowing down convergence\nconsiderably. In this work, we introduce a novel class of algorithms that only\nneeds to solve the MDP underlying the demonstrated behavior once to recover the\nexpert policy. This is possible through a formulation that exploits a\nprobabilistic behavior assumption for the demonstrations within the structure\nof Q-learning. We propose Inverse Action-value Iteration which is able to fully\nrecover an underlying reward of an external agent in closed-form analytically.\nWe further provide an accompanying class of sampling-based variants which do\nnot depend on a model of the environment. We show how to extend this class of\nalgorithms to continuous state-spaces via function approximation and how to\nestimate a corresponding action-value function, leading to a policy as close as\npossible to the policy of the external agent, while optionally satisfying a\nlist of predefined hard constraints. We evaluate the resulting algorithms\ncalled Inverse Action-value Iteration, Inverse Q-learning and Deep Inverse\nQ-learning on the Objectworld benchmark, showing a speedup of up to several\norders of magnitude compared to (Deep) Max-Entropy algorithms. We further apply\nDeep Constrained Inverse Q-learning on the task of learning autonomous\nlane-changes in the open-source simulator SUMO achieving competent driving\nafter training on data corresponding to 30 minutes of demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:21:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Kalweit", "Gabriel", ""], ["Huegle", "Maria", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "2008.01714", "submitter": "Philippe Goulet Coulombe", "authors": "Philippe Goulet Coulombe, Maxime Leroux, Dalibor Stevanovic,\n  St\\'ephane Surprenant", "title": "Macroeconomic Data Transformations Matter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a low-dimensional linear regression setup, considering linear\ntransformations/combinations of predictors does not alter predictions. However,\nwhen the forecasting technology either uses shrinkage or is nonlinear, it does.\nThis is precisely the fabric of the machine learning (ML) macroeconomic\nforecasting environment. Pre-processing of the data translates to an alteration\nof the regularization -- explicit or implicit -- embedded in ML algorithms. We\nreview old transformations and propose new ones, then empirically evaluate\ntheir merits in a substantial pseudo-out-sample exercise. It is found that\ntraditional factors should almost always be included as predictors and moving\naverage rotations of the data can provide important gains for various\nforecasting targets. Also, we note that while predicting directly the average\ngrowth rate is equivalent to averaging separate horizon forecasts when using\nOLS-based techniques, the latter can substantially improve on the former when\nregularization and/or nonparametric nonlinearities are involved.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:34:43 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 16:37:56 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Coulombe", "Philippe Goulet", ""], ["Leroux", "Maxime", ""], ["Stevanovic", "Dalibor", ""], ["Surprenant", "St\u00e9phane", ""]]}, {"id": "2008.01722", "submitter": "Kevin Tian", "authors": "Jerry Li, Aaron Sidford, Kevin Tian, Huishuai Zhang", "title": "Well-Conditioned Methods for Ill-Conditioned Systems: Linear Regression\n  with Semi-Random Noise", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical iterative algorithms for linear system solving and regression are\nbrittle to the condition number of the data matrix. Even a semi-random\nadversary, constrained to only give additional consistent information, can\narbitrarily hinder the resulting computational guarantees of existing solvers.\nWe show how to overcome this barrier by developing a framework which takes\nstate-of-the-art solvers and \"robustifies\" them to achieve comparable\nguarantees against a semi-random adversary. Given a matrix which contains an\n(unknown) well-conditioned submatrix, our methods obtain computational and\nstatistical guarantees as if the entire matrix was well-conditioned. We\ncomplement our theoretical results with preliminary experimental evidence,\nshowing that our methods are effective in practice.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:53:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Li", "Jerry", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""], ["Zhang", "Huishuai", ""]]}, {"id": "2008.01724", "submitter": "Bingyan Wang", "authors": "Yuxin Chen, Jianqing Fan, Bingyan Wang, Yuling Yan", "title": "Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy\n  Blind Deconvolution under Random Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effectiveness of convex relaxation and nonconvex\noptimization in solving bilinear systems of equations under two different\ndesigns (i.e.$~$a sort of random Fourier design and Gaussian design). Despite\nthe wide applicability, the theoretical understanding about these two paradigms\nremains largely inadequate in the presence of random noise. The current paper\nmakes two contributions by demonstrating that: (1) a two-stage nonconvex\nalgorithm attains minimax-optimal accuracy within a logarithmic number of\niterations. (2) convex relaxation also achieves minimax-optimal statistical\naccuracy vis-\\`a-vis random noise. Both results significantly improve upon the\nstate-of-the-art theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:57:02 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 01:56:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""], ["Wang", "Bingyan", ""], ["Yan", "Yuling", ""]]}, {"id": "2008.01761", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang", "title": "Can Adversarial Weight Perturbations Inject Neural Backdoors?", "comments": "Accepted as a conference paper at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412130", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial machine learning has exposed several security hazards of neural\nmodels and has become an important research topic in recent times. Thus far,\nthe concept of an \"adversarial perturbation\" has exclusively been used with\nreference to the input space referring to a small, imperceptible change which\ncan cause a ML model to err. In this work we extend the idea of \"adversarial\nperturbations\" to the space of model weights, specifically to inject backdoors\nin trained DNNs, which exposes a security risk of using publicly available\ntrained models. Here, injecting a backdoor refers to obtaining a desired\noutcome from the model when a trigger pattern is added to the input, while\nretaining the original model predictions on a non-triggered input. From the\nperspective of an adversary, we characterize these adversarial perturbations to\nbe constrained within an $\\ell_{\\infty}$ norm around the original model\nweights. We introduce adversarial perturbations in the model weights using a\ncomposite loss on the predictions of the original model and the desired trigger\nthrough projected gradient descent. We empirically show that these adversarial\nweight perturbations exist universally across several computer vision and\nnatural language processing tasks. Our results show that backdoors can be\nsuccessfully injected with a very small average relative change in model weight\nvalues for several applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:26:13 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 04:58:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Garg", "Siddhant", ""], ["Kumar", "Adarsh", ""], ["Goel", "Vibhor", ""], ["Liang", "Yingyu", ""]]}, {"id": "2008.01767", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama, Alejandro Ribeiro", "title": "Graph Neural Networks: Architectures, Stability and Transferability", "comments": "Accepted for publication in the Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are information processing architectures for\nsignals supported on graphs. They are presented here as generalizations of\nconvolutional neural networks (CNNs) in which individual layers contain banks\nof graph convolutional filters instead of banks of classical convolutional\nfilters. Otherwise, GNNs operate as CNNs. Filters are composed with pointwise\nnonlinearities and stacked in layers. It is shown that GNN architectures\nexhibit equivariance to permutation and stability to graph deformations. These\nproperties help explain the good performance of GNNs that can be observed\nempirically. It is also shown that if graphs converge to a limit object, a\ngraphon, GNNs converge to a corresponding limit object, a graphon neural\nnetwork. This convergence justifies the transferability of GNNs across networks\nwith different number of nodes. Concepts are illustrated by the application of\nGNNs to recommendation systems, decentralized collaborative control, and\nwireless communication networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:57:36 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 14:19:33 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 18:52:54 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2008.01772", "submitter": "Ryan Pyle", "authors": "Justin Sahs, Ryan Pyle, Aneel Damaraju, Josue Ortega Caro, Onur\n  Tavaslioglu, Andy Lu, Ankit Patel", "title": "Shallow Univariate ReLu Networks as Splines: Initialization, Loss\n  Surface, Hessian, & Gradient Flow Dynamics", "comments": "14 pages, 4 figures in main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the learning dynamics and inductive bias of neural networks\n(NNs) is hindered by the opacity of the relationship between NN parameters and\nthe function represented. We propose reparametrizing ReLU NNs as continuous\npiecewise linear splines. Using this spline lens, we study learning dynamics in\nshallow univariate ReLU NNs, finding unexpected insights and explanations for\nseveral perplexing phenomena. We develop a surprisingly simple and transparent\nview of the structure of the loss surface, including its critical and fixed\npoints, Hessian, and Hessian spectrum. We also show that standard weight\ninitializations yield very flat functions, and that this flatness, together\nwith overparametrization and the initial weight scale, is responsible for the\nstrength and type of implicit regularization, consistent with recent work\narXiv:1906.05827. Our implicit regularization results are complementary to\nrecent work arXiv:1906.07842, done independently, which showed that\ninitialization scale critically controls implicit regularization via a\nkernel-based argument. Our spline-based approach reproduces their key implicit\nregularization results but in a far more intuitive and transparent manner.\nGoing forward, our spline-based approach is likely to extend naturally to the\nmultivariate and deep settings, and will play a foundational role in efforts to\nunderstand neural networks. Videos of learning dynamics using a spline-based\nvisualization are available at http://shorturl.at/tFWZ2.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:19:49 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Sahs", "Justin", ""], ["Pyle", "Ryan", ""], ["Damaraju", "Aneel", ""], ["Caro", "Josue Ortega", ""], ["Tavaslioglu", "Onur", ""], ["Lu", "Andy", ""], ["Patel", "Ankit", ""]]}, {"id": "2008.01798", "submitter": "Yu Huang", "authors": "Yu Huang, Yufei Tang, Hanqi Zhuang, James VanZwieten, Laurent Cherubin", "title": "Physics-informed Tensor-train ConvLSTM for Volumetric Velocity\n  Forecasting", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the National Academies, a weekly forecast of velocity, vertical\nstructure, and duration of the Loop Current (LC) and its eddies is critical for\nunderstanding the oceanography and ecosystem, and for mitigating outcomes of\nanthropogenic and natural disasters in the Gulf of Mexico (GoM). However, this\nforecast is a challenging problem since the LC behaviour is dominated by\nlong-range spatial connections across multiple timescales. In this paper, we\nextend spatiotemporal predictive learning, showing its effectiveness beyond\nvideo prediction, to a 4D model, i.e., a novel Physics-informed Tensor-train\nConvLSTM (PITT-ConvLSTM) for temporal sequences of 3D geospatial data\nforecasting. Specifically, we propose 1) a novel 4D higher-order recurrent\nneural network with empirical orthogonal function analysis to capture the\nhidden uncorrelated patterns of each hierarchy, 2) a convolutional tensor-train\ndecomposition to capture higher-order space-time correlations, and 3) to\nincorporate prior physic knowledge that is provided from domain experts by\ninforming the learning in latent space. The advantage of our proposed method is\nclear: constrained by physical laws, it simultaneously learns good\nrepresentations for frame dependencies (both short-term and long-term\nhigh-level dependency) and inter-hierarchical relations within each time frame.\nExperiments on geospatial data collected from the GoM demonstrate that\nPITT-ConvLSTM outperforms the state-of-the-art methods in forecasting the\nvolumetric velocity of the LC and its eddies for a period of over one week.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:55:57 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Huang", "Yu", ""], ["Tang", "Yufei", ""], ["Zhuang", "Hanqi", ""], ["VanZwieten", "James", ""], ["Cherubin", "Laurent", ""]]}, {"id": "2008.01805", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani, Michael Field", "title": "Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale\n  of Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization problem associated with fitting two-layers ReLU\nnetworks with respect to the squared loss, where labels are generated by a\ntarget network. We leverage the rich symmetry structure to analytically\ncharacterize the Hessian at various families of spurious minima in the natural\nregime where the number of inputs $d$ and the number of hidden neurons $k$ is\nfinite. In particular, we prove that for $d\\ge k$ standard Gaussian inputs: (a)\nof the $dk$ eigenvalues of the Hessian, $dk - O(d)$ concentrate near zero, (b)\n$\\Omega(d)$ of the eigenvalues grow linearly with $k$. Although this phenomenon\nof extremely skewed spectrum has been observed many times before, to our\nknowledge, this is the first time it has been established {rigorously}. Our\nanalytic approach uses techniques, new to the field, from symmetry breaking and\nrepresentation theory, and carries important implications for our ability to\nargue about statistical generalization through local curvature.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:08:35 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 22:53:35 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Arjevani", "Yossi", ""], ["Field", "Michael", ""]]}, {"id": "2008.01807", "submitter": "Riccardo Galanti", "authors": "Riccardo Galanti, Bernat Coma-Puig, Massimiliano de Leoni, Josep\n  Carmona, Nicol\\`o Navarin", "title": "Explainable Predictive Process Monitoring", "comments": "Galanti, R., Coma-Puig, B., de Leoni, M., Carmona, J., Navarin, N.:\n  Explainable Predictive Process Monitoring, the International Conference on\n  Process Mining (ICPM 2020), IEEE Computational Intelligence Society, 2020.\n  Article accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive Business Process Monitoring is becoming an essential aid for\norganizations, providing online operational support of their processes. This\npaper tackles the fundamental problem of equipping predictive business process\nmonitoring with explanation capabilities, so that not only the what but also\nthe why is reported when predicting generic KPIs like remaining time, or\nactivity execution. We use the game theory of Shapley Values to obtain robust\nexplanations of the predictions. The approach has been implemented and tested\non real-life benchmarks, showing for the first time how explanations can be\ngiven in the field of predictive business process monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:09:32 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:03:08 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Galanti", "Riccardo", ""], ["Coma-Puig", "Bernat", ""], ["de Leoni", "Massimiliano", ""], ["Carmona", "Josep", ""], ["Navarin", "Nicol\u00f2", ""]]}, {"id": "2008.01818", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Zichen Miao, Qiang Qiu", "title": "Graph Convolution with Low-rank Learnable Local Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric variations like rotation, scaling, and viewpoint changes pose a\nsignificant challenge to visual understanding. One common solution is to\ndirectly model certain intrinsic structures, e.g., using landmarks. However, it\nthen becomes non-trivial to build effective deep models, especially when the\nunderlying non-Euclidean grid is irregular and coarse. Recent deep models using\ngraph convolutions provide an appropriate framework to handle such\nnon-Euclidean data, but many of them, particularly those based on global graph\nLaplacians, lack expressiveness to capture local features required for\nrepresentation of signals lying on the non-Euclidean grid. The current paper\nintroduces a new type of graph convolution with learnable low-rank local\nfilters, which is provably more expressive than previous spectral graph\nconvolution methods. The model also provides a unified framework for both\nspectral and spatial graph convolutions. To improve model robustness,\nregularization by local graph Laplacians is introduced. The representation\nstability against input graph data perturbation is theoretically proved, making\nuse of the graph filter locality and the local graph regularization.\nExperiments on spherical mesh data, real-world facial expression\nrecognition/skeleton-based action recognition data, and data with simulated\ngraph noise show the empirical advantage of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:34:59 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 17:07:57 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Miao", "Zichen", ""], ["Qiu", "Qiang", ""]]}, {"id": "2008.01825", "submitter": "Eugene Vinitsky", "authors": "Eugene Vinitsky and Yuqing Du and Kanaad Parvate and Kathy Jang and\n  Pieter Abbeel and Alexandre Bayen", "title": "Robust Reinforcement Learning using Adversarial Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is an effective tool for controller design but\ncan struggle with issues of robustness, failing catastrophically when the\nunderlying system dynamics are perturbed. The Robust RL formulation tackles\nthis by adding worst-case adversarial noise to the dynamics and constructing\nthe noise distribution as the solution to a zero-sum minimax game. However,\nexisting work on learning solutions to the Robust RL formulation has primarily\nfocused on training a single RL agent against a single adversary. In this work,\nwe demonstrate that using a single adversary does not consistently yield\nrobustness to dynamics variations under standard parametrizations of the\nadversary; the resulting policy is highly exploitable by new adversaries. We\npropose a population-based augmentation to the Robust RL formulation in which\nwe randomly initialize a population of adversaries and sample from the\npopulation uniformly during training. We empirically validate across robotics\nbenchmarks that the use of an adversarial population results in a more robust\npolicy that also improves out-of-distribution generalization. Finally, we\ndemonstrate that this approach provides comparable robustness and\ngeneralization as domain randomization on these benchmarks while avoiding a\nubiquitous domain randomization failure mode.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:57:32 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:41:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Vinitsky", "Eugene", ""], ["Du", "Yuqing", ""], ["Parvate", "Kanaad", ""], ["Jang", "Kathy", ""], ["Abbeel", "Pieter", ""], ["Bayen", "Alexandre", ""]]}, {"id": "2008.01839", "submitter": "Philip Schniter", "authors": "R\\'emi Gribonval and Antoine Chatalic and Nicolas Keriven and Vincent\n  Schellekens and Laurent Jacques and Philip Schniter", "title": "Sketching Datasets for Large-Scale Learning (long version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers \"compressive learning,\" an approach to large-scale\nmachine learning where datasets are massively compressed before learning (e.g.,\nclustering, classification, or regression) is performed. In particular, a\n\"sketch\" is first constructed by computing carefully chosen nonlinear random\nfeatures (e.g., random Fourier features) and averaging them over the whole\ndataset. Parameters are then learned from the sketch, without access to the\noriginal dataset. This article surveys the current state-of-the-art in\ncompressive learning, including the main concepts and algorithms, their\nconnections with established signal-processing methods, existing theoretical\nguarantees -- on both information preservation and privacy preservation, and\nimportant open problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:29:05 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 20:41:41 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 21:36:36 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Gribonval", "R\u00e9mi", ""], ["Chatalic", "Antoine", ""], ["Keriven", "Nicolas", ""], ["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""], ["Schniter", "Philip", ""]]}, {"id": "2008.01868", "submitter": "Hao-Ren Yao", "authors": "Hao-Ren Yao, Der-Chen Chang, Ophir Frieder, Wendy Huang, I-Chia Liang\n  and Chi-Feng Hung", "title": "Cross-Global Attention Graph Kernel Network Prediction of Drug\n  Prescription", "comments": "ACM-BCB 2020 (Full paper)", "journal-ref": "Proceedings of the 11th ACM International Conference on\n  Bioinformatics, Computational Biology and Health Informatics (BCB '20),\n  September 21-24, 2020, Virtual Event, USA", "doi": "10.1145/3388440.3412459", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end, interpretable, deep-learning architecture to learn\na graph kernel that predicts the outcome of chronic disease drug prescription.\nThis is achieved through a deep metric learning collaborative with a Support\nVector Machine objective using a graphical representation of Electronic Health\nRecords. We formulate the predictive model as a binary graph classification\nproblem with an adaptive learned graph kernel through novel cross-global\nattention node matching between patient graphs, simultaneously computing on\nmultiple graphs without training pair or triplet generation. Results using the\nTaiwanese National Health Insurance Research Database demonstrate that our\napproach outperforms current start-of-the-art models both in terms of accuracy\nand interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 22:36:46 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Yao", "Hao-Ren", ""], ["Chang", "Der-Chen", ""], ["Frieder", "Ophir", ""], ["Huang", "Wendy", ""], ["Liang", "I-Chia", ""], ["Hung", "Chi-Feng", ""]]}, {"id": "2008.01883", "submitter": "Masanori Koyama", "authors": "Masanori Koyama and Shoichiro Yamaguchi", "title": "When is invariance useful in an Out-of-Distribution Generalization\n  problem ?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Out-of-Distribution (OOD) generalization problem is to train a\npredictor that generalizes on all environments. Popular approaches in this\nfield use the hypothesis that such a predictor shall be an \\textit{invariant\npredictor} that captures the mechanism that remains constant across\nenvironments. While these approaches have been experimentally successful in\nvarious case studies, there is still much room for the theoretical validation\nof this hypothesis. This paper presents a new set of theoretical conditions\nnecessary for an invariant predictor to achieve the OOD optimality. Our theory\nnot only applies to non-linear cases, but also generalizes the necessary\ncondition used in \\citet{rojas2018invariant}. We also derive Inter Gradient\nAlignment algorithm from our theory and demonstrate its competitiveness on\nMNIST-derived benchmark datasets as well as on two of the three\n\\textit{Invariance Unit Tests} proposed by \\citet{aubinlinear}.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 23:57:11 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 12:07:52 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 09:18:51 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Koyama", "Masanori", ""], ["Yamaguchi", "Shoichiro", ""]]}, {"id": "2008.01897", "submitter": "Hong-Gyu Jung", "authors": "Sin-Han Kang, Hong-Gyu Jung, Dong-Ok Won, Seong-Whan Lee", "title": "Counterfactual Explanation Based on Gradual Construction for Deep\n  Networks", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the black-box characteristics of deep networks, counterfactual\nexplanation that deduces not only the important features of an input space but\nalso how those features should be modified to classify input as a target class\nhas gained an increasing interest. The patterns that deep networks have learned\nfrom a training dataset can be grasped by observing the feature variation among\nvarious classes. However, current approaches perform the feature modification\nto increase the classification probability for the target class irrespective of\nthe internal characteristics of deep networks. This often leads to unclear\nexplanations that deviate from real-world data distributions. To address this\nproblem, we propose a counterfactual explanation method that exploits the\nstatistics learned from a training dataset. Especially, we gradually construct\nan explanation by iterating over masking and composition steps. The masking\nstep aims to select an important feature from the input data to be classified\nas a target class. Meanwhile, the composition step aims to optimize the\npreviously selected feature by ensuring that its output score is close to the\nlogit space of the training data that are classified as the target class.\nExperimental results show that our method produces human-friendly\ninterpretations on various classification datasets and verify that such\ninterpretations can be achieved with fewer feature modification.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 01:18:31 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kang", "Sin-Han", ""], ["Jung", "Hong-Gyu", ""], ["Won", "Dong-Ok", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2008.01915", "submitter": "Liu Yang", "authors": "Liu Yang, Constantinos Daskalakis, George Em Karniadakis", "title": "Generative Ensemble Regression: Learning Particle Dynamics from\n  Observations of Ensembles with Physics-Informed Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for inferring the governing stochastic ordinary\ndifferential equations (SODEs) by observing particle ensembles at discrete and\nsparse time instants, i.e., multiple \"snapshots\". Particle coordinates at a\nsingle time instant, possibly noisy or truncated, are recorded in each snapshot\nbut are unpaired across the snapshots. By training a physics-informed\ngenerative model that generates \"fake\" sample paths, we aim to fit the observed\nparticle ensemble distributions with a curve in the probability measure space,\nwhich is induced from the inferred particle dynamics. We employ different\nmetrics to quantify the differences between distributions, e.g., the sliced\nWasserstein distances and the adversarial losses in generative adversarial\nnetworks (GANs). We refer to this method as generative \"ensemble-regression\"\n(GER), in analogy to the classic \"point-regression\", where we infer the\ndynamics by performing regression in the Euclidean space. We illustrate the GER\nby learning the drift and diffusion terms of particle ensembles governed by\nSODEs with Brownian motions and Levy processes up to 100 dimensions. We also\ndiscuss how to treat cases with noisy or truncated observations. Apart from\nsystems consisting of independent particles, we also tackle nonlocal\ninteracting particle systems with unknown interaction potential parameters by\nconstructing a physics-informed loss function. Finally, we investigate\nscenarios of paired observations and discuss how to reduce the dimensionality\nin such cases by proving a convergence theorem that provides theoretical\nsupport.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:06:40 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 02:06:01 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Yang", "Liu", ""], ["Daskalakis", "Constantinos", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2008.01916", "submitter": "Dayong Ye", "authors": "Tianqing Zhu and Dayong Ye and Wei Wang and Wanlei Zhou and Philip S.\n  Yu", "title": "More Than Privacy: Applying Differential Privacy in Key Areas of\n  Artificial Intelligence", "comments": null, "journal-ref": "IEEE Tranactions on Knowledge and Data Engineering 2020", "doi": "10.1109/TKDE.2020.3014246", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has attracted a great deal of attention in\nrecent years. However, alongside all its advancements, problems have also\nemerged, such as privacy violations, security issues and model fairness.\nDifferential privacy, as a promising mathematical model, has several attractive\nproperties that can help solve these problems, making it quite a valuable tool.\nFor this reason, differential privacy has been broadly applied in AI but to\ndate, no study has documented which differential privacy mechanisms can or have\nbeen leveraged to overcome its issues or the properties that make this\npossible. In this paper, we show that differential privacy can do more than\njust privacy preservation. It can also be used to improve security, stabilize\nlearning, build fair models, and impose composition in selected areas of AI.\nWith a focus on regular machine learning, distributed machine learning, deep\nlearning, and multi-agent systems, the purpose of this article is to deliver a\nnew view on many possibilities for improving AI performance with differential\nprivacy techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:07:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhu", "Tianqing", ""], ["Ye", "Dayong", ""], ["Wang", "Wei", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.01951", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong, Ke Chen, Julian McAuley, Taylor Berg-Kirkpatrick", "title": "MusPy: A Toolkit for Symbolic Music Generation", "comments": "Accepted by International Society for Music Information Retrieval\n  Conference (ISMIR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present MusPy, an open source Python library for symbolic\nmusic generation. MusPy provides easy-to-use tools for essential components in\na music generation system, including dataset management, data I/O, data\npreprocessing and model evaluation. In order to showcase its potential, we\npresent statistical analysis of the eleven datasets currently supported by\nMusPy. Moreover, we conduct a cross-dataset generalizability experiment by\ntraining an autoregressive model on each dataset and measuring held-out\nlikelihood on the others---a process which is made easier by MusPy's dataset\nmanagement system. The results provide a map of domain overlap between various\ncommonly used datasets and show that some datasets contain more representative\ncross-genre samples than others. Along with the dataset analysis, these results\nmight serve as a guide for choosing datasets in future research. Source code\nand documentation are available at https://github.com/salu133445/muspy .\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 06:16:13 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Chen", "Ke", ""], ["McAuley", "Julian", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2008.01967", "submitter": "Heye Zhang", "authors": "Jingyu Hao and Chengjia Wang and Heye Zhang and Guang Yang", "title": "Annealing Genetic GAN for Minority Oversampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to overcome class imbalance problems is to capture the distribution\nof minority class accurately. Generative Adversarial Networks (GANs) have shown\nsome potentials to tackle class imbalance problems due to their capability of\nreproducing data distributions given ample training data samples. However, the\nscarce samples of one or more classes still pose a great challenge for GANs to\nlearn accurate distributions for the minority classes. In this work, we propose\nan Annealing Genetic GAN (AGGAN) method, which aims to reproduce the\ndistributions closest to the ones of the minority classes using only limited\ndata samples. Our AGGAN renovates the training of GANs as an evolutionary\nprocess that incorporates the mechanism of simulated annealing. In particular,\nthe generator uses different training strategies to generate multiple offspring\nand retain the best. Then, we use the Metropolis criterion in the simulated\nannealing to decide whether we should update the best offspring for the\ngenerator. As the Metropolis criterion allows a certain chance to accept the\nworse solutions, it enables our AGGAN steering away from the local optimum.\nAccording to both theoretical analysis and experimental studies on multiple\nimbalanced image datasets, we prove that the proposed training strategy can\nenable our AGGAN to reproduce the distributions of minority classes from scarce\nsamples and provide an effective and robust solution for the class imbalance\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:19:47 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Hao", "Jingyu", ""], ["Wang", "Chengjia", ""], ["Zhang", "Heye", ""], ["Yang", "Guang", ""]]}, {"id": "2008.01976", "submitter": "Tuomas Oikarinen", "authors": "Tuomas Oikarinen, Tsui-Wei Weng, Luca Daniel", "title": "Robust Deep Reinforcement Learning through Adversarial Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including reinforcement learning agents, have been\nproven vulnerable to small adversarial changes in the input, thus making\ndeploying such networks in the real world problematic. In this paper, we\npropose RADIAL-RL, a method to train reinforcement learning agents with\nimproved robustness against any $l_p$-bounded adversarial attack. By simply\nminimizing an upper bound of the loss functions under worst case adversarial\nperturbation derived from efficient robustness verification methods, we\nsignificantly improve robustness of RL-agents trained on Atari-2600 games and\nshow that RADIAL-RL can beat state-of-the-art robust training algorithms when\nevaluated against PGD-attacks. We also propose a new evaluation method, Greedy\nWorst-Case Reward (GWC), for measuring attack agnostic robustness of RL agents.\nGWC can be evaluated efficiently and it serves as a good estimate of the reward\nunder the worst possible sequence of adversarial attacks; in particular, GWC\naccounts for the importance of each action and their temporal dependency,\nimproving upon previous approaches that only evaluate whether each single\naction can change under input perturbations. Our code is available at\nhttps://github.com/tuomaso/radial_rl.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:49:42 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Oikarinen", "Tuomas", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""]]}, {"id": "2008.01989", "submitter": "Sinan Yildirim", "authors": "Nurdan Kuru, \\c{S}. \\.Ilker Birbil, Mert Gurbuzbalaban, and Sinan\n  Yildirim", "title": "Differentially Private Accelerated Optimization Algorithms", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two classes of differentially private optimization algorithms\nderived from the well-known accelerated first-order methods. The first\nalgorithm is inspired by Polyak's heavy ball method and employs a smoothing\napproach to decrease the accumulated noise on the gradient steps required for\ndifferential privacy. The second class of algorithms are based on Nesterov's\naccelerated gradient method and its recent multi-stage variant. We propose a\nnoise dividing mechanism for the iterations of Nesterov's method in order to\nimprove the error behavior of the algorithm. The convergence rate analyses are\nprovided for both the heavy ball and the Nesterov's accelerated gradient method\nwith the help of the dynamical system analysis techniques. Finally, we conclude\nwith our numerical experiments showing that the presented algorithms have\nadvantages over the well-known differentially private algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:23:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kuru", "Nurdan", ""], ["Birbil", "\u015e. \u0130lker", ""], ["Gurbuzbalaban", "Mert", ""], ["Yildirim", "Sinan", ""]]}, {"id": "2008.01998", "submitter": "Valentin Li\\'evin", "authors": "Valentin Li\\'evin, Andrea Dittadi, Anders Christensen, Ole Winther", "title": "Optimal Variance Control of the Score Function Gradient Estimator for\n  Importance Weighted Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces novel results for the score function gradient estimator\nof the importance weighted variational bound (IWAE). We prove that in the limit\nof large $K$ (number of importance samples) one can choose the control variate\nsuch that the Signal-to-Noise ratio (SNR) of the estimator grows as $\\sqrt{K}$.\nThis is in contrast to the standard pathwise gradient estimator where the SNR\ndecreases as $1/\\sqrt{K}$. Based on our theoretical findings we develop a novel\ncontrol variate that extends on VIMCO. Empirically, for the training of both\ncontinuous and discrete generative models, the proposed method yields superior\nvariance reduction, resulting in an SNR for IWAE that increases with $K$\nwithout relying on the reparameterization trick. The novel estimator is\ncompetitive with state-of-the-art reparameterization-free gradient estimators\nsuch as Reweighted Wake-Sleep (RWS) and the thermodynamic variational objective\n(TVO) when training generative models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:41:46 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 21:09:28 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Li\u00e9vin", "Valentin", ""], ["Dittadi", "Andrea", ""], ["Christensen", "Anders", ""], ["Winther", "Ole", ""]]}, {"id": "2008.02014", "submitter": "Yijiang Lian", "authors": "Yijiang Lian, Zhijie Chen, Xin Pei, Shuang Li, Yifei Wang, Yuefeng\n  Qiu, Zhiheng Zhang, Zhipeng Tao, Liang Yuan, Hanju Guan, Kefeng Zhang,\n  Zhigang Li, Xiaochun Liu", "title": "Optimizing AD Pruning of Sponsored Search with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial sponsored search system (SSS) can be logically divided into three\nmodules: keywords matching, ad retrieving, and ranking. During ad retrieving,\nthe ad candidates grow exponentially. A query with high commercial value might\nretrieve a great deal of ad candidates such that the ranking module could not\nafford. Due to limited latency and computing resources, the candidates have to\nbe pruned earlier. Suppose we set a pruning line to cut SSS into two parts:\nupstream and downstream. The problem we are going to address is: how to pick\nout the best $K$ items from $N$ candidates provided by the upstream to maximize\nthe total system's revenue. Since the industrial downstream is very complicated\nand updated quickly, a crucial restriction in this problem is that the\nselection scheme should get adapted to the downstream. In this paper, we\npropose a novel model-free reinforcement learning approach to fixing this\nproblem. Our approach considers downstream as a black-box environment, and the\nagent sequentially selects items and finally feeds into the downstream, where\nrevenue would be estimated and used as a reward to improve the selection\npolicy. To the best of our knowledge, this is first time to consider the system\noptimization from a downstream adaption view. It is also the first time to use\nreinforcement learning techniques to tackle this problem. The idea has been\nsuccessfully realized in Baidu's sponsored search system, and online long time\nA/B test shows remarkable improvements on revenue.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:19:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Lian", "Yijiang", ""], ["Chen", "Zhijie", ""], ["Pei", "Xin", ""], ["Li", "Shuang", ""], ["Wang", "Yifei", ""], ["Qiu", "Yuefeng", ""], ["Zhang", "Zhiheng", ""], ["Tao", "Zhipeng", ""], ["Yuan", "Liang", ""], ["Guan", "Hanju", ""], ["Zhang", "Kefeng", ""], ["Li", "Zhigang", ""], ["Liu", "Xiaochun", ""]]}, {"id": "2008.02043", "submitter": "Jonghwa Yim", "authors": "Jonghwa Yim, Sang Hwan Kim", "title": "Learning Boost by Exploiting the Auxiliary Task in Multi-task Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning two tasks in a single shared function has some benefits. Firstly by\nacquiring information from the second task, the shared function leverages\nuseful information that could have been neglected or underestimated in the\nfirst task. Secondly, it helps to generalize the function that can be learned\nusing generally applicable information for both tasks. To fully enjoy these\nbenefits, Multi-task Learning (MTL) has long been researched in various domains\nsuch as computer vision, language understanding, and speech synthesis. While\nMTL benefits from the positive transfer of information from multiple tasks, in\na real environment, tasks inevitably have a conflict between them during the\nlearning phase, called negative transfer. The negative transfer hampers\nfunction from achieving the optimality and degrades the performance. To solve\nthe problem of the task conflict, previous works only suggested partial\nsolutions that are not fundamental, but ad-hoc. A common approach is using a\nweighted sum of losses. The weights are adjusted to induce positive transfer.\nParadoxically, this kind of solution acknowledges the problem of negative\ntransfer and cannot remove it unless the weight of the task is set to zero.\nTherefore, these previous methods had limited success. In this paper, we\nintroduce a novel approach that can drive positive transfer and suppress\nnegative transfer by leveraging class-wise weights in the learning process. The\nweights act as an arbitrator of the fundamental unit of information to\ndetermine its positive or negative status to the main task.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:56:56 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Yim", "Jonghwa", ""], ["Kim", "Sang Hwan", ""]]}, {"id": "2008.02046", "submitter": "Peter Rousseeuw", "authors": "Joachim Schreurs, Iwein Vranckx, Mia Hubert, Johan A.K. Suykens, Peter\n  J. Rousseeuw", "title": "Outlier detection in non-elliptical data by kernel MRCD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum regularized covariance determinant method (MRCD) is a robust\nestimator for multivariate location and scatter, which detects outliers by\nfitting a robust covariance matrix to the data. Its regularization ensures that\nthe covariance matrix is well-conditioned in any dimension. The MRCD assumes\nthat the non-outlying observations are roughly elliptically distributed, but\nmany datasets are not of that form. Moreover, the computation time of MRCD\nincreases substantially when the number of variables goes up, and nowadays\ndatasets with many variables are common. The proposed Kernel Minimum\nRegularized Covariance Determinant (KMRCD) estimator addresses both issues. It\nis not restricted to elliptical data because it implicitly computes the MRCD\nestimates in a kernel induced feature space. A fast algorithm is constructed\nthat starts from kernel-based initial estimates and exploits the kernel trick\nto speed up the subsequent computations. Based on the KMRCD estimates, a rule\nis proposed to flag outliers. The KMRCD algorithm performs well in simulations,\nand is illustrated on real-life data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 11:09:08 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 22:23:14 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Schreurs", "Joachim", ""], ["Vranckx", "Iwein", ""], ["Hubert", "Mia", ""], ["Suykens", "Johan A. K.", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2008.02066", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Giovanni Montana", "title": "Follow the Object: Curriculum Learning for Manipulation Tasks with\n  Imagined Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot manipulation through deep reinforcement learning in\nenvironments with sparse rewards is a challenging task. In this paper we\naddress this problem by introducing a notion of imaginary object goals. For a\ngiven manipulation task, the object of interest is first trained to reach a\ndesired target position on its own, without being manipulated, through\nphysically realistic simulations. The object policy is then leveraged to build\na predictive model of plausible object trajectories providing the robot with a\ncurriculum of incrementally more difficult object goals to reach during\ntraining. The proposed algorithm, Follow the Object (FO), has been evaluated on\n7 MuJoCo environments requiring increasing degree of exploration, and has\nachieved higher success rates compared to alternative algorithms. In\nparticularly challenging learning scenarios, e.g. where the object's initial\nand target positions are far apart, our approach can still learn a policy\nwhereas competing methods currently fail.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:19:14 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Montana", "Giovanni", ""]]}, {"id": "2008.02069", "submitter": "Gabriel Meseguer-Brocal", "authors": "Gabriel Meseguer-Brocal, Rachel Bittner, Simon Durand and Brian Brost", "title": "Data Cleansing with Contrastive Learning for Vocal Note Event\n  Annotations", "comments": "21st International Society for Music Information Retrieval Conference\n  11-15 October 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data cleansing is a well studied strategy for cleaning erroneous labels in\ndatasets, which has not yet been widely adopted in Music Information Retrieval.\nPreviously proposed data cleansing models do not consider structured (e.g. time\nvarying) labels, such as those common to music data. We propose a novel data\ncleansing model for time-varying, structured labels which exploits the local\nstructure of the labels, and demonstrate its usefulness for vocal note event\nannotations in music. %Our model is trained in a contrastive learning manner by\nautomatically creating local deformations of likely correct labels. Our model\nis trained in a contrastive learning manner by automatically contrasting likely\ncorrect labels pairs against local deformations of them. We demonstrate that\nthe accuracy of a transcription model improves greatly when trained using our\nproposed strategy compared with the accuracy when trained using the original\ndataset. Additionally we use our model to estimate the annotation error rates\nin the DALI dataset, and highlight other potential uses for this type of model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:24:37 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 10:15:04 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 10:19:17 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Meseguer-Brocal", "Gabriel", ""], ["Bittner", "Rachel", ""], ["Durand", "Simon", ""], ["Brost", "Brian", ""]]}, {"id": "2008.02087", "submitter": "Jiangwei Zhang", "authors": "Jiangwei Zhang, Li Zhang, Vigneshwaran Raveendran, Ziv Ben-Zuk, and\n  Leonard Lu", "title": "PriceAggregator: An Intelligent System for Hotel Price Fetching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the hotel price aggregation system - PriceAggregator,\ndeployed at Agoda, a global online travel agency for hotels, vacation rentals,\nflights and airport transfer. Agoda aggregates non-direct suppliers' hotel\nrooms to ensure that Agoda's customers always have the widest selection of\nhotels, room types and packages. As of today, Agoda aggregates millions of\nhotels. The major challenge is that each supplier only allows Agoda to fetch\nfor the hotel price with a limited amount of Queries Per Second (QPS). Due to\nthe sheer volume of Agoda's user search traffic, this limited amount of QPS is\nnever enough to cover all user searches. Inevitably, many user searches have to\nbe ignored. Hence, booking lost. To overcome the challenge, we built\nPriceAggregator. PriceAggregator intelligently determines when, how and what to\nsend to the suppliers to fetch for price. In this paper, we not only prove\nPriceAggregator is optimal theoretically but also demonstrate that\nPriceAggregator performs well in practice. PriceAggregator has been deployed in\nAgoda. Extensive online A/B experimentation have shown that PriceAggregator\nincreases Agoda's bookings significantly.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:28:25 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhang", "Jiangwei", ""], ["Zhang", "Li", ""], ["Raveendran", "Vigneshwaran", ""], ["Ben-Zuk", "Ziv", ""], ["Lu", "Leonard", ""]]}, {"id": "2008.02122", "submitter": "Jingxing Jiang", "authors": "Jingxing Jiang, Zhubin Wang, Fei Fang, Binqiang Zhao", "title": "TPG-DNN: A Method for User Intent Prediction Based on Total Probability\n  Formula and GRU Loss with Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The E-commerce platform has become the principal battleground where people\nsearch, browse and pay for whatever they want. Critical as is to improve the\nonline shopping experience for customers and merchants, how to find a proper\napproach for user intent prediction are paid great attention in both industry\nand academia. In this paper, we propose a novel user intent prediction model,\nTPG-DNN, to complete the challenging task, which is based on adaptive gated\nrecurrent unit (GRU) loss function with multi-task learning. We creatively use\nthe GRU structure and total probability formula as the loss function to model\nthe users' whole online purchase process. Besides, the multi-task weight\nadjustment mechanism can make the final loss function dynamically adjust the\nimportance between different tasks through data variance. According to the test\nresult of experiments conducted on Taobao daily and promotion data sets, the\nproposed model performs much better than existing click through rate (CTR)\nmodels. At present, the proposed user intent prediction model has been widely\nused for the coupon allocation, advertisement and recommendation on Taobao\nplatform, which greatly improve the user experience and shopping efficiency,\nand benefit the gross merchandise volume (GMV) promotion as well.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 13:25:53 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Jiang", "Jingxing", ""], ["Wang", "Zhubin", ""], ["Fang", "Fei", ""], ["Zhao", "Binqiang", ""]]}, {"id": "2008.02144", "submitter": "Seyedeh Fatemeh Razavi", "authors": "Seyedeh Fatemeh Razavi and Reshad Hosseini", "title": "FRMDN: Flow-based Recurrent Mixture Density Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Mixture Density Networks (RMDNs) are consisted of two main parts: a\nRecurrent Neural Network (RNN) and a Gaussian Mixture Model (GMM), in which a\nkind of RNN (almost LSTM) is used to find the parameters of a GMM in every time\nstep. While available RMDNs have been faced with different difficulties. The\nmost important of them is high$-$dimensional problems. Since estimating the\ncovariance matrix for the high$-$dimensional problems is more difficult, due to\nexisting correlation between dimensions and satisfying the positive definition\ncondition. Consequently, the available methods have usually used RMDN with a\ndiagonal covariance matrix for high$-$dimensional problems by supposing\nindependence among dimensions. Hence, in this paper with inspiring a common\napproach in the literature of GMM, we consider a tied configuration for each\nprecision matrix (inverse of the covariance matrix) in RMDN as $(\\(\\Sigma _k^{\n- 1} = U{D_k}U\\))$ to enrich GMM rather than considering a diagonal form for\nit. But due to simplicity, we assume $\\(U\\)$ be an Identity matrix and\n$\\(D_k\\)$ is a specific diagonal matrix for $\\(k^{th}\\)$ component. Until now,\nwe only have a diagonal matrix and it does not differ with available diagonal\nRMDNs. Besides, Flow$-$based neural networks are a new group of generative\nmodels that are able to transform a distribution to a simpler distribution and\nvice versa, through a sequence of invertible functions. Therefore, we applied a\ndiagonal GMM on transformed observations. At every time step, the next\nobservation, $\\({y_{t + 1}}\\)$, has been passed through a flow$-$based neural\nnetwork to obtain a much simpler distribution. Experimental results for a\nreinforcement learning problem verify the superiority of the proposed method to\nthe base$-$line method in terms of Negative Log$-$Likelihood (NLL) for RMDN and\nthe cumulative reward for a controller with fewer population size.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:05:37 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Razavi", "Seyedeh Fatemeh", ""], ["Hosseini", "Reshad", ""]]}, {"id": "2008.02171", "submitter": "Cedric Schockaert", "authors": "Cedric Schockaert", "title": "A Causal-based Framework for Multimodal Multivariate Time Series\n  Validation Enhanced by Unsupervised Deep Learning as an Enabler for Industry\n  4.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An advanced conceptual validation framework for multimodal multivariate time\nseries defines a multi-level contextual anomaly detection ranging from an\nunivariate context definition, to a multimodal abstract context representation\nlearnt by an Autoencoder from heterogeneous data (images, time series, sounds,\netc.) associated to an industrial process. Each level of the framework is\neither applicable to historical data and/or live data. The ultimate level is\nbased on causal discovery to identify causal relations in observational data in\norder to exclude biased data to train machine learning models and provide means\nto the domain expert to discover unknown causal relations in the underlying\nprocess represented by the data sample. A Long Short-Term Memory Autoencoder is\nsuccessfully evaluated on multivariate time series to validate the learnt\nrepresentation of abstract contexts associated to multiple assets of a blast\nfurnace. A research roadmap is identified to combine causal discovery and\nrepresentation learning as an enabler for unsupervised Root Cause Analysis\napplied to the process industry.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:48:02 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Schockaert", "Cedric", ""]]}, {"id": "2008.02200", "submitter": "Howard Heaton", "authors": "Howard Heaton, Samy Wu Fung, Alex Tong Lin, Stanley Osher, Wotao Yin", "title": "Wasserstein-based Projections with Applications to Inverse Problems", "comments": "Revised version uploaded on April 14, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems consist of recovering a signal from a collection of noisy\nmeasurements. These are typically cast as optimization problems, with classic\napproaches using a data fidelity term and an analytic regularizer that\nstabilizes recovery. Recent Plug-and-Play (PnP) works propose replacing the\noperator for analytic regularization in optimization methods by a data-driven\ndenoiser. These schemes obtain state of the art results, but at the cost of\nlimited theoretical guarantees. To bridge this gap, we present a new algorithm\nthat takes samples from the manifold of true data as input and outputs an\napproximation of the projection operator onto this manifold. Under standard\nassumptions, we prove this algorithm generates a learned operator, called\nWasserstein-based projection (WP), that approximates the true projection with\nhigh probability. Thus, WPs can be inserted into optimization methods in the\nsame manner as PnP, but now with theoretical guarantees. Provided numerical\nexamples show WPs obtain state of the art results for unsupervised PnP signal\nrecovery.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:58:55 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 17:29:35 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 16:25:43 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Heaton", "Howard", ""], ["Fung", "Samy Wu", ""], ["Lin", "Alex Tong", ""], ["Osher", "Stanley", ""], ["Yin", "Wotao", ""]]}, {"id": "2008.02211", "submitter": "Bo Shen", "authors": "Bo Shen, Zhenyu (James) Kong", "title": "Robust Tensor Principal Component Analysis: Exact Recovery via\n  Deterministic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor, also known as multi-dimensional array, arises from many applications\nin signal processing, manufacturing processes, healthcare, among others. As one\nof the most popular methods in tensor literature, Robust tensor principal\ncomponent analysis (RTPCA) is a very effective tool to extract the low rank and\nsparse components in tensors. In this paper, a new method to analyze RTPCA is\nproposed based on the recently developed tensor-tensor product and tensor\nsingular value decomposition (t-SVD). Specifically, it aims to solve a convex\noptimization problem whose objective function is a weighted combination of the\ntensor nuclear norm and the l1-norm. In most of literature of RTPCA, the exact\nrecovery is built on the tensor incoherence conditions and the assumption of a\nuniform model on the sparse support. Unlike this conventional way, in this\npaper, without any assumption of randomness, the exact recovery can be achieved\nin a completely deterministic fashion by characterizing the tensor\nrank-sparsity incoherence, which is an uncertainty principle between the\nlow-rank tensor spaces and the pattern of sparse tensor.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:26:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Shen", "Bo", "", "James"], ["Zhenyu", "", "", "James"], ["Kong", "", ""]]}, {"id": "2008.02216", "submitter": "Matej Petkovi\\'c", "authors": "Matej Petkovi\\'c, Bla\\v{z} \\v{S}krlj, Dragi Kocev, Nikola Simidjievski", "title": "Fuzzy Jaccard Index: A robust comparison of ordered lists", "comments": "29 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Fuzzy Jaccard Index (FUJI) -- a scale-invariant score for\nassessment of the similarity between two ranked/ordered lists. FUJI improves\nupon the Jaccard index by incorporating a membership function which takes into\naccount the particular ranks, thus producing both more stable and more accurate\nsimilarity estimates. We provide theoretical insights into the properties of\nthe FUJI score as well as propose an efficient algorithm for computing it. We\nalso present empirical evidence of its performance on different synthetic\nscenarios. Finally, we demonstrate its utility in a typical machine learning\nsetting -- comparing feature ranking lists relevant to a given machine learning\ntask. In real-life, and in particular high-dimensional domains, where only a\nsmall percentage of the whole feature space might be relevant, a robust and\nconfident feature ranking leads to interpretable findings as well as efficient\ncomputation and good predictive performance. In such cases, FUJI correctly\ndistinguishes between existing feature ranking approaches, while being more\nrobust and efficient than the benchmark similarity scores.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:33:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Petkovi\u0107", "Matej", ""], ["\u0160krlj", "Bla\u017e", ""], ["Kocev", "Dragi", ""], ["Simidjievski", "Nikola", ""]]}, {"id": "2008.02217", "submitter": "Hubert Ramsauer", "authors": "Hubert Ramsauer, Bernhard Sch\\\"afl, Johannes Lehner, Philipp Seidl,\n  Michael Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner, Milena\n  Pavlovi\\'c, Geir Kjetil Sandve, Victor Greiff, David Kreil, Michael Kopp,\n  G\\\"unter Klambauer, Johannes Brandstetter, Sepp Hochreiter", "title": "Hopfield Networks is All You Need", "comments": "10 pages (+ appendix); 12 figures; Blog:\n  https://ml-jku.github.io/hopfield-layers/; GitHub:\n  https://github.com/ml-jku/hopfield-layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a modern Hopfield network with continuous states and a\ncorresponding update rule. The new Hopfield network can store exponentially\n(with the dimension of the associative space) many patterns, retrieves the\npattern with one update, and has exponentially small retrieval errors. It has\nthree types of energy minima (fixed points of the update): (1) global fixed\npoint averaging over all patterns, (2) metastable states averaging over a\nsubset of patterns, and (3) fixed points which store a single pattern. The new\nupdate rule is equivalent to the attention mechanism used in transformers. This\nequivalence enables a characterization of the heads of transformer models.\nThese heads perform in the first layers preferably global averaging and in\nhigher layers partial averaging via metastable states. The new modern Hopfield\nnetwork can be integrated into deep learning architectures as layers to allow\nthe storage of and access to raw input data, intermediate results, or learned\nprototypes. These Hopfield layers enable new ways of deep learning, beyond\nfully-connected, convolutional, or recurrent networks, and provide pooling,\nmemory, association, and attention mechanisms. We demonstrate the broad\napplicability of the Hopfield layers across various domains. Hopfield layers\nimproved state-of-the-art on three out of four considered multiple instance\nlearning problems as well as on immune repertoire classification with several\nhundreds of thousands of instances. On the UCI benchmark collections of small\nclassification tasks, where deep learning methods typically struggle, Hopfield\nlayers yielded a new state-of-the-art when compared to different machine\nlearning methods. Finally, Hopfield layers achieved state-of-the-art on two\ndrug design datasets. The implementation is available at:\nhttps://github.com/ml-jku/hopfield-layers\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 17:52:37 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:16:15 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 07:24:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Ramsauer", "Hubert", ""], ["Sch\u00e4fl", "Bernhard", ""], ["Lehner", "Johannes", ""], ["Seidl", "Philipp", ""], ["Widrich", "Michael", ""], ["Adler", "Thomas", ""], ["Gruber", "Lukas", ""], ["Holzleitner", "Markus", ""], ["Pavlovi\u0107", "Milena", ""], ["Sandve", "Geir Kjetil", ""], ["Greiff", "Victor", ""], ["Kreil", "David", ""], ["Kopp", "Michael", ""], ["Klambauer", "G\u00fcnter", ""], ["Brandstetter", "Johannes", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2008.02219", "submitter": "Raghavan Krishnan", "authors": "R. Krishnan, Prasanna Balaprakash", "title": "Meta Continual Learning via Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta continual learning algorithms seek to train a model when faced with\nsimilar tasks observed in a sequential manner. Despite promising methodological\nadvancements, there is a lack of theoretical frameworks that enable analysis of\nlearning challenges such as generalization and catastrophic forgetting. To that\nend, we develop a new theoretical approach for meta continual learning~(MCL)\nwhere we mathematically model the learning dynamics using dynamic programming,\nand we establish conditions of optimality for the MCL problem. Moreover, using\nthe theoretical framework, we derive a new dynamic-programming-based MCL method\nthat adopts stochastic-gradient-driven alternating optimization to balance\ngeneralization and catastrophic forgetting. We show that, on MCL benchmark data\nsets, our theoretically grounded method achieves accuracy better than or\ncomparable to that of existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:36:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 15:41:22 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Krishnan", "R.", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.02269", "submitter": "Alexander Wein", "authors": "Tselil Schramm and Alexander S. Wein", "title": "Computational Barriers to Estimation from Low-Degree Polynomials", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fundamental goal of high-dimensional statistics is to detect or recover\nstructure from noisy data. In many cases, the data can be faithfully modeled by\na planted structure (such as a low-rank matrix) perturbed by random noise. But\neven for these simple models, the computational complexity of estimation is\nsometimes poorly understood. A growing body of work studies low-degree\npolynomials as a proxy for computational complexity: it has been demonstrated\nin various settings that low-degree polynomials of the data can match the\nstatistical performance of the best known polynomial-time algorithms for\ndetection. While prior work has studied the power of low-degree polynomials for\nthe task of detecting the presence of hidden structures, it has failed to\naddress the estimation problem in settings where detection is qualitatively\neasier than estimation.\n  In this work, we extend the method of low-degree polynomials to address\nproblems of estimation and recovery. For a large class of \"signal plus noise\"\nproblems, we give a user-friendly lower bound for the best possible mean\nsquared error achievable by any degree-D polynomial. To our knowledge, this is\nthe first instance in which the low-degree polynomial method can establish\nlow-degree hardness of recovery problems where the associated detection problem\nis easy. As applications, we give a tight characterization of the low-degree\nminimum mean squared error for the planted submatrix and planted dense subgraph\nproblems, resolving (in the low-degree framework) open problems about the\ncomputational complexity of recovery in both cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:52:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Schramm", "Tselil", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2008.02320", "submitter": "Varun Mannam", "authors": "Varun Mannam, Yide Zhang, Xiaotong Yuan, Cara Ravasio and Scott S.\n  Howard", "title": "Machine learning for faster and smarter fluorescence lifetime imaging\n  microscopy", "comments": null, "journal-ref": null, "doi": "10.1088/2515-7647/abac1a", "report-no": "042005", "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluorescence lifetime imaging microscopy (FLIM) is a powerful technique in\nbiomedical research that uses the fluorophore decay rate to provide additional\ncontrast in fluorescence microscopy. However, at present, the calculation,\nanalysis, and interpretation of FLIM is a complex, slow, and computationally\nexpensive process. Machine learning (ML) techniques are well suited to extract\nand interpret measurements from multi-dimensional FLIM data sets with\nsubstantial improvement in speed over conventional methods. In this topical\nreview, we first discuss the basics of FILM and ML. Second, we provide a\nsummary of lifetime extraction strategies using ML and its applications in\nclassifying and segmenting FILM images with higher accuracy compared to\nconventional methods. Finally, we discuss two potential directions to improve\nFLIM with ML with proof of concept demonstrations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:59:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mannam", "Varun", ""], ["Zhang", "Yide", ""], ["Yuan", "Xiaotong", ""], ["Ravasio", "Cara", ""], ["Howard", "Scott S.", ""]]}, {"id": "2008.02327", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Fadi Salo, Ali Bou Nassif, Aleksander Essex,\n  Abdallah Shami", "title": "Bayesian Optimization with Machine Learning Algorithms Towards Anomaly\n  Detection", "comments": "6 pages, 7 Figures, 2 tables, Published in 2018 IEEE Global\n  Communications Conference (GLOBECOM)", "journal-ref": null, "doi": "10.1109/GLOCOM.2018.8647714", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network attacks have been very prevalent as their rate is growing\ntremendously. Both organization and individuals are now concerned about their\nconfidentiality, integrity and availability of their critical information which\nare often impacted by network attacks. To that end, several previous machine\nlearning-based intrusion detection methods have been developed to secure\nnetwork infrastructure from such attacks. In this paper, an effective anomaly\ndetection framework is proposed utilizing Bayesian Optimization technique to\ntune the parameters of Support Vector Machine with Gaussian Kernel (SVM-RBF),\nRandom Forest (RF), and k-Nearest Neighbor (k-NN) algorithms. The performance\nof the considered algorithms is evaluated using the ISCX 2012 dataset.\nExperimental results show the effectiveness of the proposed framework in term\nof accuracy rate, precision, low-false alarm rate, and recall.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 19:29:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Salo", "Fadi", ""], ["Nassif", "Ali Bou", ""], ["Essex", "Aleksander", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.02355", "submitter": "Prasanna Date", "authors": "Prasanna Date, Thomas Potok", "title": "Adiabatic Quantum Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in machine learning is the computational expense of\ntraining these models. Model training can be viewed as a form of optimization\nused to fit a machine learning model to a set of data, which can take up\nsignificant amount of time on classical computers. Adiabatic quantum computers\nhave been shown to excel at solving optimization problems, and therefore, we\nbelieve, present a promising alternative to improve machine learning training\ntimes. In this paper, we present an adiabatic quantum computing approach for\ntraining a linear regression model. In order to do this, we formulate the\nregression problem as a quadratic unconstrained binary optimization (QUBO)\nproblem. We analyze our quantum approach theoretically, test it on the D-Wave\n2000Q adiabatic quantum computer and compare its performance to a classical\napproach that uses the Scikit-learn library in Python. Our analysis shows that\nthe quantum approach attains up to 2.8x speedup over the classical approach on\nlarger datasets, and performs at par with the classical approach on the\nregression error metric.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:40:41 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Date", "Prasanna", ""], ["Potok", "Thomas", ""]]}, {"id": "2008.02369", "submitter": "Prasanna Date", "authors": "Prasanna Date, Davis Arthur, Lauren Pusey-Nazzaro", "title": "QUBO Formulations for Training Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models on classical computers is usually a time and\ncompute intensive process. With Moore's law coming to an end and ever\nincreasing demand for large-scale data analysis using machine learning, we must\nleverage non-conventional computing paradigms like quantum computing to train\nmachine learning models efficiently. Adiabatic quantum computers like the\nD-Wave 2000Q can approximately solve NP-hard optimization problems, such as the\nquadratic unconstrained binary optimization (QUBO), faster than classical\ncomputers. Since many machine learning problems are also NP-hard, we believe\nadiabatic quantum computers might be instrumental in training machine learning\nmodels efficiently in the post Moore's law era. In order to solve a problem on\nadiabatic quantum computers, it must be formulated as a QUBO problem, which is\na challenging task in itself. In this paper, we formulate the training problems\nof three machine learning models---linear regression, support vector machine\n(SVM) and equal-sized k-means clustering---as QUBO problems so that they can be\ntrained on adiabatic quantum computers efficiently. We also analyze the time\nand space complexities of our formulations and compare them to the\nstate-of-the-art classical algorithms for training these machine learning\nmodels. We show that the time and space complexities of our formulations are\nbetter (in the case of SVM and equal-sized k-means clustering) or equivalent\n(in case of linear regression) to their classical counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 21:16:05 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Date", "Prasanna", ""], ["Arthur", "Davis", ""], ["Pusey-Nazzaro", "Lauren", ""]]}, {"id": "2008.02386", "submitter": "Panagiotis Tsilifis", "authors": "Panagiotis Tsilifis, Piyush Pandita, Sayan Ghosh, Valeria Andreoli,\n  Thomas Vandeputte, Liping Wang", "title": "Bayesian learning of orthogonal embeddings for multi-fidelity Gaussian\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian approach to identify optimal transformations that map\nmodel input points to low dimensional latent variables. The \"projection\"\nmapping consists of an orthonormal matrix that is considered a priori unknown\nand needs to be inferred jointly with the GP parameters, conditioned on the\navailable training data. The proposed Bayesian inference scheme relies on a\ntwo-step iterative algorithm that samples from the marginal posteriors of the\nGP parameters and the projection matrix respectively, both using Markov Chain\nMonte Carlo (MCMC) sampling. In order to take into account the orthogonality\nconstraints imposed on the orthonormal projection matrix, a Geodesic Monte\nCarlo sampling algorithm is employed, that is suitable for exploiting\nprobability measures on manifolds. We extend the proposed framework to\nmulti-fidelity models using GPs including the scenarios of training multiple\noutputs together. We validate our framework on three synthetic problems with a\nknown lower-dimensional subspace. The benefits of our proposed framework, are\nillustrated on the computationally challenging three-dimensional aerodynamic\noptimization of a last-stage blade for an industrial gas turbine, where we\nstudy the effect of an 85-dimensional airfoil shape parameterization on two\noutput quantities of interest, specifically on the aerodynamic efficiency and\nthe degree of reaction.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 22:28:53 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Tsilifis", "Panagiotis", ""], ["Pandita", "Piyush", ""], ["Ghosh", "Sayan", ""], ["Andreoli", "Valeria", ""], ["Vandeputte", "Thomas", ""], ["Wang", "Liping", ""]]}, {"id": "2008.02389", "submitter": "N. Benjamin Erichson", "authors": "Alejandro F. Queiruga, N. Benjamin Erichson, Dane Taylor and Michael\n  W. Mahoney", "title": "Continuous-in-Depth Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has attempted to interpret residual networks (ResNets) as one\nstep of a forward Euler discretization of an ordinary differential equation,\nfocusing mainly on syntactic algebraic similarities between the two systems.\nDiscrete dynamical integrators of continuous dynamical systems, however, have a\nmuch richer structure. We first show that ResNets fail to be meaningful\ndynamical integrators in this richer sense. We then demonstrate that neural\nnetwork models can learn to represent continuous dynamical systems, with this\nricher structure and properties, by embedding them into higher-order numerical\nintegration schemes, such as the Runge Kutta schemes. Based on these insights,\nwe introduce ContinuousNet as a continuous-in-depth generalization of ResNet\narchitectures. ContinuousNets exhibit an invariance to the particular\ncomputational graph manifestation. That is, the continuous-in-depth model can\nbe evaluated with different discrete time step sizes, which changes the number\nof layers, and different numerical integration schemes, which changes the graph\nconnectivity. We show that this can be used to develop an incremental-in-depth\ntraining scheme that improves model quality, while significantly decreasing\ntraining time. We also show that, once trained, the number of units in the\ncomputational graph can even be decreased, for faster inference with\nlittle-to-no accuracy drop.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 22:54:09 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Queiruga", "Alejandro F.", ""], ["Erichson", "N. Benjamin", ""], ["Taylor", "Dane", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2008.02430", "submitter": "Xiao Ma", "authors": "Xiao Ma, Siwei Chen, David Hsu, Wee Sun Lee", "title": "Contrastive Variational Reinforcement Learning for Complex Observations", "comments": "CoRL 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved significant success in various\nrobot tasks: manipulation, navigation, etc. However, complex visual\nobservations in natural environments remains a major challenge. This paper\npresents Contrastive Variational Reinforcement Learning (CVRL), a model-based\nmethod that tackles complex visual observations in DRL. CVRL learns a\ncontrastive variational model by maximizing the mutual information between\nlatent states and observations discriminatively, through contrastive learning.\nIt avoids modeling the complex observation space unnecessarily, as the commonly\nused generative observation model often does, and is significantly more robust.\nCVRL achieves comparable performance with state-of-the-art model-based DRL\nmethods on standard Mujoco tasks. It significantly outperforms them on Natural\nMujoco tasks and a robot box-pushing task with complex observations, e.g.,\ndynamic shadows. The CVRL code is available publicly at\nhttps://github.com/Yusufma03/CVRL.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:25:51 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:35:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ma", "Xiao", ""], ["Chen", "Siwei", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2008.02437", "submitter": "Yuetian Luo", "authors": "Yuetian Luo and Garvesh Raskutti and Ming Yuan and Anru R. Zhang", "title": "A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we develop novel perturbation bounds for the high-order\northogonal iteration (HOOI) [DLDMV00b]. Under mild regularity conditions, we\nestablish blockwise tensor perturbation bounds for HOOI with guarantees for\nboth tensor reconstruction in Hilbert-Schmidt norm $\\|\\widehat{\\bcT} - \\bcT\n\\|_{\\tHS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\\|\n\\sin \\Theta (\\widehat{\\U}_k, \\U_k) \\|_q$ for any $q \\geq 1$. We show the upper\nbounds of mode-$k$ singular subspace estimation are unilateral and converge\nlinearly to a quantity characterized by blockwise errors of the perturbation\nand signal strength. For the tensor reconstruction error bound, we express the\nbound through a simple quantity $\\xi$, which depends only on perturbation and\nthe multilinear rank of the underlying signal. Rate matching deterministic\nlower bound for tensor reconstruction, which demonstrates the optimality of\nHOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI\nwith only a single iteration) is also optimal in terms of tensor reconstruction\nand can be used to lower the computational cost. The perturbation results are\nalso extended to the case that only partial modes of $\\bcT$ have low-rank\nstructure. We support our theoretical results by extensive numerical studies.\nFinally, we apply the novel perturbation bounds of HOOI on two applications,\ntensor denoising and tensor co-clustering, from machine learning and\nstatistics, which demonstrates the superiority of the new perturbation results.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 03:01:28 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 20:34:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Luo", "Yuetian", ""], ["Raskutti", "Garvesh", ""], ["Yuan", "Ming", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2008.02447", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Yingyu Liang", "title": "Functional Regularization for Representation Learning: A Unified\n  Theoretical Perspective", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised and self-supervised learning approaches have become a crucial\ntool to learn representations for downstream prediction tasks. While these\napproaches are widely used in practice and achieve impressive empirical gains,\ntheir theoretical understanding largely lags behind. Towards bridging this gap,\nwe present a unifying perspective where several such approaches can be viewed\nas imposing a regularization on the representation via a learnable function\nusing unlabeled data. We propose a discriminative theoretical framework for\nanalyzing the sample complexity of these approaches, which generalizes the\nframework of (Balcan and Blum, 2010) to allow learnable regularization\nfunctions. Our sample complexity bounds show that, with carefully chosen\nhypothesis classes to exploit the structure in the data, these learnable\nregularization functions can prune the hypothesis space, and help reduce the\namount of labeled data needed. We then provide two concrete examples of\nfunctional regularization, one using auto-encoders and the other using masked\nself-supervision, and apply our framework to quantify the reduction in the\nsample complexity bound of labeled data. We also provide complementary\nempirical results to support our analysis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:06:04 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:30:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 00:54:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Garg", "Siddhant", ""], ["Liang", "Yingyu", ""]]}, {"id": "2008.02450", "submitter": "AprilPyone MaungMaung", "authors": "MaungMaung AprilPyone and Hitoshi Kiya", "title": "Training DNN Model with Secret Key for Model Protection", "comments": "to appear in 2020 IEEE 9th Global Conference on Consumer Electronics\n  (GCCE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model protection method by using block-wise pixel\nshuffling with a secret key as a preprocessing technique to input images for\nthe first time. The protected model is built by training with such preprocessed\nimages. Experiment results show that the performance of the protected model is\nclose to that of non-protected models when the key is correct, while the\naccuracy is severely dropped when an incorrect key is given, and the proposed\nmodel protection is robust against not only brute-force attacks but also\nfine-tuning attacks, while maintaining almost the same performance accuracy as\nthat of using a non-protected model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:25:59 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2008.02452", "submitter": "Dimitrios Dimitriadis", "authors": "Dimitrios Dimitriadis, Kenichi Kumatani, Robert Gmyr, Yashesh Gaur and\n  Sefik Emre Eskimez", "title": "Federated Transfer Learning with Dynamic Gradient Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a Federated Learning (FL) simulation platform is introduced.\nThe target scenario is Acoustic Model training based on this platform. To our\nknowledge, this is the first attempt to apply FL techniques to Speech\nRecognition tasks due to the inherent complexity. The proposed FL platform can\nsupport different tasks based on the adopted modular design. As part of the\nplatform, a novel hierarchical optimization scheme and two gradient aggregation\nmethods are proposed, leading to almost an order of magnitude improvement in\ntraining convergence speed compared to other distributed or FL training\nalgorithms like BMUF and FedAvg. The hierarchical optimization offers\nadditional flexibility in the training pipeline besides the enhanced\nconvergence speed. On top of the hierarchical optimization, a dynamic gradient\naggregation algorithm is proposed, based on a data-driven weight inference.\nThis aggregation algorithm acts as a regularizer of the gradient quality.\nFinally, an unsupervised training pipeline tailored to FL is presented as a\nseparate training scenario. The experimental validation of the proposed system\nis based on two tasks: first, the LibriSpeech task showing a speed-up of 7x and\n6% Word Error Rate reduction (WERR) compared to the baseline results. The\nsecond task is based on session adaptation providing an improvement of 20% WERR\nover a competitive production-ready LAS model. The proposed Federated Learning\nsystem is shown to outperform the golden standard of distributed training in\nboth convergence speed and overall model performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:29:01 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Dimitriadis", "Dimitrios", ""], ["Kumatani", "Kenichi", ""], ["Gmyr", "Robert", ""], ["Gaur", "Yashesh", ""], ["Eskimez", "Sefik Emre", ""]]}, {"id": "2008.02464", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Chi Wang, Ben Liao, Richard Peng, Jie Tang", "title": "A Matrix Chernoff Bound for Markov Chains and Its Application to\n  Co-occurrence Matrices", "comments": "Accepted at NeurIPS'20, 25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a Chernoff-type bound for sums of matrix-valued random variables\nsampled via a regular (aperiodic and irreducible) finite Markov chain.\nSpecially, consider a random walk on a regular Markov chain and a Hermitian\nmatrix-valued function on its state space. Our result gives exponentially\ndecreasing bounds on the tail distributions of the extreme eigenvalues of the\nsample mean matrix. Our proof is based on the matrix expander (regular\nundirected graph) Chernoff bound [Garg et al. STOC '18] and scalar\nChernoff-Hoeffding bounds for Markov chains [Chung et al. STACS '12].\n  Our matrix Chernoff bound for Markov chains can be applied to analyze the\nbehavior of co-occurrence statistics for sequential data, which have been\ncommon and important data signals in machine learning. We show that given a\nregular Markov chain with $n$ states and mixing time $\\tau$, we need a\ntrajectory of length $O(\\tau (\\log{(n)}+\\log{(\\tau)})/\\epsilon^2)$ to achieve\nan estimator of the co-occurrence matrix with error bound $\\epsilon$. We\nconduct several experiments and the experimental results are consistent with\nthe exponentially fast convergence rate from theoretical analysis. Our result\ngives the first bound on the convergence rate of the co-occurrence matrix and\nthe first sample complexity analysis in graph representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 05:44:54 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 14:01:27 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Wang", "Chi", ""], ["Liao", "Ben", ""], ["Peng", "Richard", ""], ["Tang", "Jie", ""]]}, {"id": "2008.02467", "submitter": "Wei Liu", "authors": "Lior Lukov, Sanjay Chawla, Wei Liu, Brett Church, and Gaurav Pandey", "title": "Unravelling the Architecture of Membrane Proteins with Conditional\n  Random Fields", "comments": "See the originally compiled PDF of this paper at:\n  https://drive.google.com/file/d/1IYF52Wk8m96KIlrQHUVtEBdm0Kw3M40c", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will show that the recently introduced graphical model:\nConditional Random Fields (CRF) provides a template to integrate micro-level\ninformation about biological entities into a mathematical model to understand\ntheir macro-level behavior. More specifically, we will apply the CRF model to\nan important classification problem in protein science, namely the secondary\nstructure prediction of proteins based on the observed primary structure. A\ncomparison on benchmark data sets against twenty-eight other methods shows that\nnot only does the CRF model lead to extremely accurate predictions but the\nmodular nature of the model and the freedom to integrate disparate, overlapping\nand non-independent sources of information, makes the model an extremely\nversatile tool to potentially solve many other problems in bioinformatics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 05:57:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Lukov", "Lior", ""], ["Chawla", "Sanjay", ""], ["Liu", "Wei", ""], ["Church", "Brett", ""], ["Pandey", "Gaurav", ""]]}, {"id": "2008.02479", "submitter": "Mikkel Slot Nielsen", "authors": "Richard A. Davis and Mikkel S. Nielsen", "title": "Modeling of time series using random forests: theoretical developments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study asymptotic properties of random forests within the\nframework of nonlinear time series modeling. While random forests have been\nsuccessfully applied in various fields, the theoretical justification has not\nbeen considered for their use in a time series setting. Under mild conditions,\nwe prove a uniform concentration inequality for regression trees built on\nnonlinear autoregressive processes and, subsequently, we use this result to\nprove consistency for a large class of random forests. The results are\nsupported by various simulations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:02:10 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Davis", "Richard A.", ""], ["Nielsen", "Mikkel S.", ""]]}, {"id": "2008.02517", "submitter": "Mario Lezcano-Casado", "authors": "Mario Lezcano-Casado", "title": "Curvature-Dependant Global Convergence Rates for Optimization on\n  Manifolds of Bounded Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.DG math.NA stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We give curvature-dependant convergence rates for the optimization of weakly\nconvex functions defined on a manifold of 1-bounded geometry via Riemannian\ngradient descent and via the dynamic trivialization algorithm. In order to do\nthis, we give a tighter bound on the norm of the Hessian of the Riemannian\nexponential than the previously known. We compute these bounds explicitly for\nsome manifolds commonly used in the optimization literature such as the special\northogonal group and the real Grassmannian. Along the way, we present\nself-contained proofs of fully general bounds on the norm of the differential\nof the exponential map and certain cosine inequalities on manifolds, which are\ncommonly used in optimization on manifolds.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:30:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Lezcano-Casado", "Mario", ""]]}, {"id": "2008.02528", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Anita Gierbl, Bernd Reimer and Damian\n  Borth", "title": "Learning Sampling in Financial Statement Audits using Vector Quantised\n  Autoencoder Neural Networks", "comments": "8 pages, 5 figures, 3 tables, to appear in Proceedings of the ACM's\n  International Conference on AI in Finance (ICAIF'20), this paper is the\n  initial accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The audit of financial statements is designed to collect reasonable assurance\nthat an issued statement is free from material misstatement 'true and fair\npresentation'. International audit standards require the assessment of a\nstatements' underlying accounting relevant transactions referred to as 'journal\nentries' to detect potential misstatements. To efficiently audit the increasing\nquantities of such entries, auditors regularly conduct a sample-based\nassessment referred to as 'audit sampling'. However, the task of audit sampling\nis often conducted early in the overall audit process. Often at a stage, in\nwhich an auditor might be unaware of all generative factors and their dynamics\nthat resulted in the journal entries in-scope of the audit. To overcome this\nchallenge, we propose the application of Vector Quantised-Variational\nAutoencoder (VQ-VAE) neural networks. We demonstrate, based on two real-world\ncity payment datasets, that such artificial neural networks are capable of\nlearning a quantised representation of accounting data. We show that the\nlearned quantisation uncovers (i) the latent factors of variation and (ii) can\nbe utilised as a highly representative audit sample in financial statement\naudits.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 09:02:02 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Gierbl", "Anita", ""], ["Reimer", "Bernd", ""], ["Borth", "Damian", ""]]}, {"id": "2008.02545", "submitter": "Timo Klock", "authors": "Alexander Cloninger and Timo Klock", "title": "A deep network construction that adapts to intrinsic dimensionality\n  beyond the domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of two-layer compositions $f(x) = g(\\phi(x))$ via\ndeep networks with ReLU activation, where $\\phi$ is a geometrically intuitive,\ndimensionality reducing feature map. We focus on two intuitive and practically\nrelevant choices for $\\phi$: the projection onto a low-dimensional embedded\nsubmanifold and a distance to a collection of low-dimensional sets. We achieve\nnear optimal approximation rates, which depend only on the complexity of the\ndimensionality reducing map $\\phi$ rather than the ambient dimension. Since\n$\\phi$ encapsulates all nonlinear features that are material to the function\n$f$, this suggests that deep nets are faithful to an intrinsic dimension\ngoverned by $f$ rather than the complexity of the domain of $f$. In particular,\nthe prevalent assumption of approximating functions on low-dimensional\nmanifolds can be significantly relaxed using functions of type $f(x) =\ng(\\phi(x))$ with $\\phi$ representing an orthogonal projection onto the same\nmanifold.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 09:50:29 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 10:24:45 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 09:05:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cloninger", "Alexander", ""], ["Klock", "Timo", ""]]}, {"id": "2008.02598", "submitter": "Ron Dorfman", "authors": "Ron Dorfman, Idan Shenfeld, Aviv Tamar", "title": "Offline Meta Learning of Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following instance of the Offline Meta Reinforcement Learning\n(OMRL) problem: given the complete training logs of $N$ conventional RL agents,\ntrained on $N$ different tasks, design a meta-agent that can quickly maximize\nreward in a new, unseen task from the same task distribution. In particular,\nwhile each conventional RL agent explored and exploited its own different task,\nthe meta-agent must identify regularities in the data that lead to effective\nexploration/exploitation in the unseen task. Here, we take a Bayesian RL (BRL)\nview, and seek to learn a Bayes-optimal policy from the offline data. Building\non the recent VariBAD BRL approach, we develop an off-policy BRL method that\nlearns to plan an exploration strategy based on an adaptive neural belief\nestimate. However, learning to infer such a belief from offline data brings a\nnew identifiability issue we term MDP ambiguity. We characterize the problem,\nand suggest resolutions via data collection and modification procedures.\nFinally, we evaluate our framework on a diverse set of domains, including\ndifficult sparse reward tasks, and demonstrate learning of effective\nexploration behavior that is qualitatively different from the exploration used\nby any RL agent in the data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:09:18 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 10:48:55 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 08:17:23 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Dorfman", "Ron", ""], ["Shenfeld", "Idan", ""], ["Tamar", "Aviv", ""]]}, {"id": "2008.02608", "submitter": "Jihong Park", "authors": "Jihong Park, Sumudu Samarakoon, Anis Elgabli, Joongheon Kim, Mehdi\n  Bennis, Seong-Lyun Kim, M\\'erouane Debbah", "title": "Communication-Efficient and Distributed Learning Over Wireless Networks:\n  Principles and Applications", "comments": "20 pages, 14 figures; This article has been submitted to IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is a promising enabler for the fifth generation (5G)\ncommunication systems and beyond. By imbuing intelligence into the network\nedge, edge nodes can proactively carry out decision-making, and thereby react\nto local environmental changes and disturbances while experiencing zero\ncommunication latency. To achieve this goal, it is essential to cater for high\nML inference accuracy at scale under time-varying channel and network dynamics,\nby continuously exchanging fresh data and ML model updates in a distributed\nway. Taming this new kind of data traffic boils down to improving the\ncommunication efficiency of distributed learning by optimizing communication\npayload types, transmission techniques, and scheduling, as well as ML\narchitectures, algorithms, and data processing methods. To this end, this\narticle aims to provide a holistic overview of relevant communication and ML\nprinciples, and thereby present communication-efficient and distributed\nlearning frameworks with selected use cases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:37:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Park", "Jihong", ""], ["Samarakoon", "Sumudu", ""], ["Elgabli", "Anis", ""], ["Kim", "Joongheon", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "2008.02627", "submitter": "Francesco Verdoja", "authors": "Francesco Verdoja, Ville Kyrki", "title": "Notes on the Behavior of MC Dropout", "comments": "Presented at the ICML 2021 Workshop on \"Uncertainty and Robustness in\n  Deep Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the various options to estimate uncertainty in deep neural networks,\nMonte-Carlo dropout is widely popular for its simplicity and effectiveness.\nHowever the quality of the uncertainty estimated through this method varies and\nchoices in architecture design and in training procedures have to be carefully\nconsidered and tested to obtain satisfactory results. In this paper we present\na study offering a different point of view on the behavior of Monte-Carlo\ndropout, which enables us to observe a few interesting properties of the\ntechnique to keep in mind when considering its use for uncertainty estimation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:09:03 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 10:40:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Verdoja", "Francesco", ""], ["Kyrki", "Ville", ""]]}, {"id": "2008.02641", "submitter": "Benjamin Coleman", "authors": "Louis Abraham, Gary Becigneul, Benjamin Coleman, Bernhard Scholkopf,\n  Anshumali Shrivastava, Alexander Smola", "title": "Bloom Origami Assays: Practical Group Testing", "comments": "arXiv admin note: text overlap with arXiv:2005.06413", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem usually referred to as group testing in the context of\nCOVID-19. Given n samples collected from patients, how should we select and\ntest mixtures of samples to maximize information and minimize the number of\ntests? Group testing is a well-studied problem with several appealing\nsolutions, but recent biological studies impose practical constraints for\nCOVID-19 that are incompatible with traditional methods. Furthermore, existing\nmethods use unnecessarily restrictive solutions, which were devised for\nsettings with more memory and compute constraints than the problem at hand.\nThis results in poor utility. In the new setting, we obtain strong solutions\nfor small values of n using evolutionary strategies. We then develop a new\nmethod combining Bloom filters with belief propagation to scale to larger\nvalues of n (more than 100) with good empirical results. We also present a more\naccurate decoding algorithm that is tailored for specific COVID-19 settings.\nThis work demonstrates the practical gap between dedicated algorithms and\nwell-known generic solutions. Our efforts results in a new and practical\nmultiplex method yielding strong empirical performance without mixing more than\na chosen number of patients into the same probe. Finally, we briefly discuss\nadaptive methods, casting them into the framework of adaptive sub-modularity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 19:31:41 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Abraham", "Louis", ""], ["Becigneul", "Gary", ""], ["Coleman", "Benjamin", ""], ["Scholkopf", "Bernhard", ""], ["Shrivastava", "Anshumali", ""], ["Smola", "Alexander", ""]]}, {"id": "2008.02648", "submitter": "Xueya Zhang", "authors": "Xueya Zhang and Tong Zhang and Xiaobin Hong and Zhen Cui and Jian Yang", "title": "Graph Wasserstein Correlation Analysis for Movie Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Movie graphs play an important role to bridge heterogenous modalities of\nvideos and texts in human-centric retrieval. In this work, we propose Graph\nWasserstein Correlation Analysis (GWCA) to deal with the core issue therein,\ni.e, cross heterogeneous graph comparison. Spectral graph filtering is\nintroduced to encode graph signals, which are then embedded as probability\ndistributions in a Wasserstein space, called graph Wasserstein metric learning.\nSuch a seamless integration of graph signal filtering together with metric\nlearning results in a surprise consistency on both learning processes, in which\nthe goal of metric learning is just to optimize signal filters or vice versa.\nFurther, we derive the solution of the graph comparison model as a classic\ngeneralized eigenvalue decomposition problem, which has an exactly closed-form\nsolution. Finally, GWCA together with movie/text graphs generation are unified\ninto the framework of movie retrieval to evaluate our proposed method.\nExtensive experiments on MovieGrpahs dataset demonstrate the effectiveness of\nour GWCA as well as the entire framework.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:30:47 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Zhang", "Xueya", ""], ["Zhang", "Tong", ""], ["Hong", "Xiaobin", ""], ["Cui", "Zhen", ""], ["Yang", "Jian", ""]]}, {"id": "2008.02651", "submitter": "Rogier Van Dalen", "authors": "Filip Granqvist, Matt Seigel, Rogier van Dalen, \\'Aine Cahill, Stephen\n  Shum, Matthias Paulik", "title": "Improving on-device speaker verification using federated learning with\n  privacy", "comments": "To appear in proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information on speaker characteristics can be useful as side information in\nimproving speaker recognition accuracy. However, such information is often\nprivate. This paper investigates how privacy-preserving learning can improve a\nspeaker verification system, by enabling the use of privacy-sensitive speaker\ndata to train an auxiliary classification model that predicts vocal\ncharacteristics of speakers. In particular, this paper explores the utility\nachieved by approaches which combine different federated learning and\ndifferential privacy mechanisms. These approaches make it possible to train a\ncentral model while protecting user privacy, with users' data remaining on\ntheir devices. Furthermore, they make learning on a large population of\nspeakers possible, ensuring good coverage of speaker characteristics when\ntraining a model. The auxiliary model described here uses features extracted\nfrom phrases which trigger a speaker verification system. From these features,\nthe model predicts speaker characteristic labels considered useful as side\ninformation. The knowledge of the auxiliary model is distilled into a speaker\nverification system using multi-task learning, with the side information labels\npredicted by this auxiliary model being the additional task. This approach\nresults in a 6% relative improvement in equal error rate over a baseline\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:37:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Granqvist", "Filip", ""], ["Seigel", "Matt", ""], ["van Dalen", "Rogier", ""], ["Cahill", "\u00c1ine", ""], ["Shum", "Stephen", ""], ["Paulik", "Matthias", ""]]}, {"id": "2008.02663", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei Kang,\n  Christoph Bergmeir", "title": "Improving the Accuracy of Global Forecasting Models using Time Series\n  Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting models that are trained across sets of many time series, known as\nGlobal Forecasting Models (GFM), have shown recently promising results in\nforecasting competitions and real-world applications, outperforming many\nstate-of-the-art univariate forecasting techniques. In most cases, GFMs are\nimplemented using deep neural networks, and in particular Recurrent Neural\nNetworks (RNN), which require a sufficient amount of time series to estimate\ntheir numerous model parameters. However, many time series databases have only\na limited number of time series. In this study, we propose a novel, data\naugmentation based forecasting framework that is capable of improving the\nbaseline accuracy of the GFM models in less data-abundant settings. We use\nthree time series augmentation techniques: GRATIS, moving block bootstrap\n(MBB), and dynamic time warping barycentric averaging (DBA) to synthetically\ngenerate a collection of time series. The knowledge acquired from these\naugmented time series is then transferred to the original dataset using two\ndifferent approaches: the pooled approach and the transfer learning approach.\nWhen building GFMs, in the pooled approach, we train a model on the augmented\ntime series alongside the original time series dataset, whereas in the transfer\nlearning approach, we adapt a pre-trained model to the new dataset. In our\nevaluation on competition and real-world time series datasets, our proposed\nvariants can significantly improve the baseline accuracy of GFM models and\noutperform state-of-the-art univariate forecasting methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:52:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bandara", "Kasun", ""], ["Hewamalage", "Hansika", ""], ["Liu", "Yuan-Hao", ""], ["Kang", "Yanfei", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "2008.02672", "submitter": "Alex Gorodetsky", "authors": "Alex Gorodetsky and John D. Jakeman and Gianluca Geraci", "title": "MFNets: Learning network representations for multifidelity surrogate\n  modeling", "comments": "21 pages,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for constructing multifidelity surrogate\nmodels to simultaneously represent, and learn representations of, multiple\ninformation sources. The approach formulates a network of surrogate models\nwhose relationships are defined via localized scalings and shifts. The network\ncan have general structure, and can represent a significantly greater variety\nof modeling relationships than the hierarchical/recursive networks used in the\ncurrent state of the art. We show empirically that this flexibility achieves\ngreatest gains in the low-data regime, where the network structure must more\nefficiently leverage the connections between data sources to yield accurate\npredictions. We demonstrate our approach on four examples ranging from\nsynthetic to physics-based simulation models. For the numerical test cases\nadopted here, we obtained an order-of-magnitude reduction in errors compared to\nmultifidelity hierarchical and single-fidelity approaches.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:21:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Gorodetsky", "Alex", ""], ["Jakeman", "John D.", ""], ["Geraci", "Gianluca", ""]]}, {"id": "2008.02676", "submitter": "Yang Li", "authors": "Yang Li, Haidong Yi, Christopher M. Bender, Siyuan Shan, Junier B.\n  Oliva", "title": "Exchangeable Neural ODE for Set Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over an instance composed of a set of vectors, like a point cloud,\nrequires that one accounts for intra-set dependent features among elements.\nHowever, since such instances are unordered, the elements' features should\nremain unchanged when the input's order is permuted. This property, permutation\nequivariance, is a challenging constraint for most neural architectures. While\nrecent work has proposed global pooling and attention-based solutions, these\nmay be limited in the way that intradependencies are captured in practice. In\nthis work we propose a more general formulation to achieve permutation\nequivariance through ordinary differential equations (ODE). Our proposed\nmodule, Exchangeable Neural ODE (ExNODE), can be seamlessly applied for both\ndiscriminative and generative tasks. We also extend set modeling in the\ntemporal dimension and propose a VAE based model for temporal set modeling.\nExtensive experiments demonstrate the efficacy of our method over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:11:36 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Li", "Yang", ""], ["Yi", "Haidong", ""], ["Bender", "Christopher M.", ""], ["Shan", "Siyuan", ""], ["Oliva", "Junier B.", ""]]}, {"id": "2008.02714", "submitter": "Yuan Yao", "authors": "Yuan Yao, Xutao Li, Yu Zhang, and Yunming Ye", "title": "Multi-source Heterogeneous Domain Adaptation with Conditional Weighting\n  Adversarial Network", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous domain adaptation (HDA) tackles the learning of cross-domain\nsamples with both different probability distributions and feature\nrepresentations. Most of existing HDA studies focus on the single-source\nscenario. In reality, however, it is not uncommon to obtain samples from\nmultiple heterogeneous domains. In this paper, we study the multi-source\nheterogeneous domain adaptation problem, and propose a Conditional Weighting\nAdversarial Network (CWAN) to address it. The proposed CWAN adversarially\nlearns a feature transformer, a label classifier, and a domain discriminator.\nTo quantify the importance of different source domains, CWAN introduces a\nsophisticated conditional weighting scheme to calculate the weights of the\nsource domains according to the conditional distribution divergence between the\nsource and target domains. Different from existing weighting schemes, the\nproposed conditional weighting scheme not only weights the source domains but\nalso implicitly aligns the conditional distributions during the optimization\nprocess. Experimental results clearly demonstrate that the proposed CWAN\nperforms much better than several state-of-the-art methods on three real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:31:44 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Yao", "Yuan", ""], ["Li", "Xutao", ""], ["Zhang", "Yu", ""], ["Ye", "Yunming", ""]]}, {"id": "2008.02731", "submitter": "Siddharth Srivastava", "authors": "Ayush Khaneja, Siddharth Srivastava, Astha Rai, A S Cheema, P K\n  Srivastava", "title": "Analysing Risk of Coronary Heart Disease through Discriminative Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of data mining, machine learning and artificial intelligence\ntechniques in the field of diagnostics is not a new concept, and these\ntechniques have been very successfully applied in a variety of applications,\nespecially in dermatology and cancer research. But, in the case of medical\nproblems that involve tests resulting in true or false (binary classification),\nthe data generally has a class imbalance with samples majorly belonging to one\nclass (ex: a patient undergoes a regular test and the results are false). Such\ndisparity in data causes problems when trying to model predictive systems on\nthe data. In critical applications like diagnostics, this class imbalance\ncannot be overlooked and must be given extra attention. In our research, we\ndepict how we can handle this class imbalance through neural networks using a\ndiscriminative model and contrastive loss using a Siamese neural network\nstructure. Such a model does not work on a probability-based approach to\nclassify samples into labels. Instead it uses a distance-based approach to\ndifferentiate between samples classified under different labels. The code is\navailable at https://tinyurl.com/DiscriminativeCHD/\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 06:30:00 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Khaneja", "Ayush", ""], ["Srivastava", "Siddharth", ""], ["Rai", "Astha", ""], ["Cheema", "A S", ""], ["Srivastava", "P K", ""]]}, {"id": "2008.02775", "submitter": "Elizaveta Kharlova", "authors": "Elizaveta Kharlova, Daniel May, Petr Musilek (University of Alberta)", "title": "Forecasting Photovoltaic Power Production using a Deep Learning Sequence\n  to Sequence Model with Attention", "comments": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-7", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207573", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rising penetration levels of (residential) photovoltaic (PV) power as\ndistributed energy resource pose a number of challenges to the electricity\ninfrastructure. High quality, general tools to provide accurate forecasts of\npower production are urgently needed. In this article, we propose a supervised\ndeep learning model for end-to-end forecasting of PV power production. The\nproposed model is based on two seminal concepts that led to significant\nperformance improvements of deep learning approaches in other sequence-related\nfields, but not yet in the area of time series prediction: the sequence to\nsequence architecture and attention mechanism as a context generator. The\nproposed model leverages numerical weather predictions and high-resolution\nhistorical measurements to forecast a binned probability distribution over the\nprognostic time intervals, rather than the expected values of the prognostic\nvariable. This design offers significant performance improvements compared to\ncommon baseline approaches, such as fully connected neural networks and\none-block long short-term memory architectures. Using normalized root mean\nsquare error based forecast skill score as a performance indicator, the\nproposed approach is compared to other models. The results show that the new\ndesign performs at or above the current state of the art of PV power\nforecasting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:20:08 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 19:23:29 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kharlova", "Elizaveta", "", "University of Alberta"], ["May", "Daniel", "", "University of Alberta"], ["Musilek", "Petr", "", "University of Alberta"]]}, {"id": "2008.02790", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Aditi Raghunathan, Percy Liang, Chelsea Finn", "title": "Decoupling Exploration and Exploitation for Meta-Reinforcement Learning\n  without Sacrifices", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of meta-reinforcement learning (meta-RL) is to build agents that can\nquickly learn new tasks by leveraging prior experience on related tasks.\nLearning a new task often requires both exploring to gather task-relevant\ninformation and exploiting this information to solve the task. In principle,\noptimal exploration and exploitation can be learned end-to-end by simply\nmaximizing task performance. However, such meta-RL approaches struggle with\nlocal optima due to a chicken-and-egg problem: learning to explore requires\ngood exploitation to gauge the exploration's utility, but learning to exploit\nrequires information gathered via exploration. Optimizing separate objectives\nfor exploration and exploitation can avoid this problem, but prior meta-RL\nexploration objectives yield suboptimal policies that gather information\nirrelevant to the task. We alleviate both concerns by constructing an\nexploitation objective that automatically identifies task-relevant information\nand an exploration objective to recover only this information. This avoids\nlocal optima in end-to-end training, without sacrificing optimal exploration.\nEmpirically, DREAM substantially outperforms existing approaches on complex\nmeta-RL problems, such as sparse-reward 3D visual navigation. Videos of DREAM:\nhttps://ezliu.github.io/dream/\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:57:36 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:54:30 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 17:53:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Raghunathan", "Aditi", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2008.02839", "submitter": "Subhadip Mukherjee", "authors": "Subhadip Mukherjee, S\\\"oren Dittmer, Zakhar Shumaylov, Sebastian Lunz,\n  Ozan \\\"Oktem, and Carola-Bibiane Sch\\\"onlieb", "title": "Learned convex regularizers for inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the variational reconstruction framework for inverse problems and\npropose to learn a data-adaptive input-convex neural network (ICNN) as the\nregularization functional. The ICNN-based convex regularizer is trained\nadversarially to discern ground-truth images from unregularized\nreconstructions. Convexity of the regularizer is desirable since (i) one can\nestablish analytical convergence guarantees for the corresponding variational\nreconstruction problem and (ii) devise efficient and provable algorithms for\nreconstruction. In particular, we show that the optimal solution to the\nvariational problem converges to the ground-truth if the penalty parameter\ndecays sub-linearly with respect to the norm of the noise. Further, we prove\nthe existence of a sub-gradient-based algorithm that leads to a monotonically\ndecreasing error in the parameter space with iterations. To demonstrate the\nperformance of our approach for solving inverse problems, we consider the tasks\nof deblurring natural images and reconstructing images in computed tomography\n(CT), and show that the proposed convex regularizer is at least competitive\nwith and sometimes superior to state-of-the-art data-driven techniques for\ninverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:58:35 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 18:56:30 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mukherjee", "Subhadip", ""], ["Dittmer", "S\u00f6ren", ""], ["Shumaylov", "Zakhar", ""], ["Lunz", "Sebastian", ""], ["\u00d6ktem", "Ozan", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2008.02840", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Sergey Levine, Anca D. Dragan", "title": "Assisted Perception: Optimizing Observations to Communicate State", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to help users estimate the state of the world in tasks like robotic\nteleoperation and navigation with visual impairments, where users may have\nsystematic biases that lead to suboptimal behavior: they might struggle to\nprocess observations from multiple sensors simultaneously, receive delayed\nobservations, or overestimate distances to obstacles. While we cannot directly\nchange the user's internal beliefs or their internal state estimation process,\nour insight is that we can still assist them by modifying the user's\nobservations. Instead of showing the user their true observations, we\nsynthesize new observations that lead to more accurate internal state estimates\nwhen processed by the user. We refer to this method as assistive state\nestimation (ASE): an automated assistant uses the true observations to infer\nthe state of the world, then generates a modified observation for the user to\nconsume (e.g., through an augmented reality interface), and optimizes the\nmodification to induce the user's new beliefs to match the assistant's current\nbeliefs. We evaluate ASE in a user study with 12 participants who each perform\nfour tasks: two tasks with known user biases -- bandwidth-limited image\nclassification and a driving video game with observation delay -- and two with\nunknown biases that our method has to learn -- guided 2D navigation and a lunar\nlander teleoperation video game. A different assistance strategy emerges in\neach domain, such as quickly revealing informative pixels to speed up image\nclassification, using a dynamics model to undo observation delay in driving,\nidentifying nearby landmarks for navigation, and exaggerating a visual\nindicator of tilt in the lander game. The results show that ASE substantially\nimproves the task performance of users with bandwidth constraints, observation\ndelay, and other unknown biases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 19:08:05 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Reddy", "Siddharth", ""], ["Levine", "Sergey", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2008.02852", "submitter": "Andrew Miller", "authors": "Andrew C. Miller and Nicholas J. Foti and Emily Fox", "title": "Learning Insulin-Glucose Dynamics in the Wild", "comments": "Machine Learning for Healthcare 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new model of insulin-glucose dynamics for forecasting blood\nglucose in type 1 diabetics. We augment an existing biomedical model by\nintroducing time-varying dynamics driven by a machine learning sequence model.\nOur model maintains a physiologically plausible inductive bias and clinically\ninterpretable parameters -- e.g., insulin sensitivity -- while inheriting the\nflexibility of modern pattern recognition algorithms. Critical to modeling\nsuccess are the flexible, but structured representations of subject variability\nwith a sequence model. In contrast, less constrained models like the LSTM fail\nto provide reliable or physiologically plausible forecasts. We conduct an\nextensive empirical study. We show that allowing biomedical model dynamics to\nvary in time improves forecasting at long time horizons, up to six hours, and\nproduces forecasts consistent with the physiological effects of insulin and\ncarbohydrates.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 19:47:00 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Miller", "Andrew C.", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily", ""]]}, {"id": "2008.02856", "submitter": "Kushal Chakrabarti", "authors": "Kushal Chakrabarti, Nirupam Gupta, Nikhil Chopra", "title": "Iterative Pre-Conditioning for Expediting the Gradient-Descent Method:\n  The Distributed Linear Least-Squares Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the multi-agent linear least-squares problem in a\nserver-agent network. In this problem, the system comprises multiple agents,\neach having a set of local data points, that are connected to a server. The\ngoal for the agents is to compute a linear mathematical model that optimally\nfits the collective data points held by all the agents, without sharing their\nindividual local data points. This goal can be achieved, in principle, using\nthe server-agent variant of the traditional iterative gradient-descent method.\nThe gradient-descent method converges linearly to a solution, and its rate of\nconvergence is lower bounded by the conditioning of the agents' collective data\npoints. If the data points are ill-conditioned, the gradient-descent method may\nrequire a large number of iterations to converge.\n  We propose an iterative pre-conditioning technique that mitigates the\ndeleterious effect of the conditioning of data points on the rate of\nconvergence of the gradient-descent method. We rigorously show that the\nresulting pre-conditioned gradient-descent method, with the proposed iterative\npre-conditioning, achieves superlinear convergence when the least-squares\nproblem has a unique solution. In general, the convergence is linear with\nimproved rate of convergence in comparison to the traditional gradient-descent\nmethod and the state-of-the-art accelerated gradient-descent methods. We\nfurther illustrate the improved rate of convergence of our proposed algorithm\nthrough experiments on different real-world least-squares problems in both\nnoise-free and noisy computation environment.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:01:18 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Chakrabarti", "Kushal", ""], ["Gupta", "Nirupam", ""], ["Chopra", "Nikhil", ""]]}, {"id": "2008.02871", "submitter": "Yang Bai", "authors": "Yang Bai, Yu Guan, Wan-Fai Ng", "title": "Fatigue Assessment using ECG and Actigraphy Sensors", "comments": "accepted by ISWC 2020", "journal-ref": null, "doi": "10.1145/3410531.3414308", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatigue is one of the key factors in the loss of work efficiency and\nhealth-related quality of life, and most fatigue assessment methods were based\non self-reporting, which may suffer from many factors such as recall bias. To\naddress this issue, we developed an automated system using wearable sensing and\nmachine learning techniques for objective fatigue assessment. ECG/Actigraphy\ndata were collected from subjects in free-living environments. Preprocessing\nand feature engineering methods were applied, before interpretable solution and\ndeep learning solution were introduced. Specifically, for interpretable\nsolution, we proposed a feature selection approach which can select less\ncorrelated and high informative features for better understanding system's\ndecision-making process. For deep learning solution, we used state-of-the-art\nself-attention model, based on which we further proposed a consistency\nself-attention (CSA) mechanism for fatigue assessment. Extensive experiments\nwere conducted, and very promising results were achieved.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:04:33 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:15:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Bai", "Yang", ""], ["Guan", "Yu", ""], ["Ng", "Wan-Fai", ""]]}, {"id": "2008.02883", "submitter": "Kaiwen Wu", "authors": "Kaiwen Wu and Allen Houze Wang and Yaoliang Yu", "title": "Stronger and Faster Wasserstein Adversarial Attacks", "comments": "30 pages, accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models, while being extremely flexible and accurate, are surprisingly\nvulnerable to \"small, imperceptible\" perturbations known as adversarial\nattacks. While the majority of existing attacks focus on measuring\nperturbations under the $\\ell_p$ metric, Wasserstein distance, which takes\ngeometry in pixel space into account, has long been known to be a suitable\nmetric for measuring image quality and has recently risen as a compelling\nalternative to the $\\ell_p$ metric in adversarial attacks. However,\nconstructing an effective attack under the Wasserstein metric is\ncomputationally much more challenging and calls for better optimization\nalgorithms. We address this gap in two ways: (a) we develop an exact yet\nefficient projection operator to enable a stronger projected gradient attack;\n(b) we show that the Frank-Wolfe method equipped with a suitable linear\nminimization oracle works extremely fast under Wasserstein constraints. Our\nalgorithms not only converge faster but also generate much stronger attacks.\nFor instance, we decrease the accuracy of a residual network on CIFAR-10 to\n$3.4\\%$ within a Wasserstein perturbation ball of radius $0.005$, in contrast\nto $65.6\\%$ using the previous Wasserstein attack based on an\n\\emph{approximate} projection operator. Furthermore, employing our stronger\nattacks in adversarial training significantly improves the robustness of\nadversarially trained models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:36:12 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wu", "Kaiwen", ""], ["Wang", "Allen Houze", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2008.02897", "submitter": "Abhinav Mehrotra", "authors": "Abhinav Mehrotra, {\\L}ukasz Dudziak, Jinsu Yeo, Young-yoon Lee,\n  Ravichander Vipperla, Mohamed S. Abdelfattah, Sourav Bhattacharya, Samin\n  Ishtiaq, Alberto Gil C. P. Ramos, SangJeong Lee, Daehyun Kim, Nicholas D.\n  Lane", "title": "Iterative Compression of End-to-End ASR Model using AutoML", "comments": null, "journal-ref": "INTERSPEECH 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing demand for on-device Automatic Speech Recognition (ASR) systems\nhas resulted in renewed interests in developing automatic model compression\ntechniques. Past research have shown that AutoML-based Low Rank Factorization\n(LRF) technique, when applied to an end-to-end Encoder-Attention-Decoder style\nASR model, can achieve a speedup of up to 3.7x, outperforming laborious manual\nrank-selection approaches. However, we show that current AutoML-based search\ntechniques only work up to a certain compression level, beyond which they fail\nto produce compressed models with acceptable word error rates (WER). In this\nwork, we propose an iterative AutoML-based LRF approach that achieves over 5x\ncompression without degrading the WER, thereby advancing the state-of-the-art\nin ASR compression.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 22:33:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mehrotra", "Abhinav", ""], ["Dudziak", "\u0141ukasz", ""], ["Yeo", "Jinsu", ""], ["Lee", "Young-yoon", ""], ["Vipperla", "Ravichander", ""], ["Abdelfattah", "Mohamed S.", ""], ["Bhattacharya", "Sourav", ""], ["Ishtiaq", "Samin", ""], ["Ramos", "Alberto Gil C. P.", ""], ["Lee", "SangJeong", ""], ["Kim", "Daehyun", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.02901", "submitter": "Zhu Li", "authors": "Zhu Li, Weijie Su, Dino Sejdinovic", "title": "Benign Overfitting and Noisy Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning often operates in the regime where the number of\nparameters is much higher than the number of data points, with zero training\nloss and yet good generalization, thereby contradicting the classical\nbias-variance trade-off. This \\textit{benign overfitting} phenomenon has\nrecently been characterized using so called \\textit{double descent} curves\nwhere the risk undergoes another descent (in addition to the classical U-shaped\nlearning curve when the number of parameters is small) as we increase the\nnumber of parameters beyond a certain threshold. In this paper, we examine the\nconditions under which \\textit{Benign Overfitting} occurs in the random feature\n(RF) models, i.e. in a two-layer neural network with fixed first layer weights.\nWe adopt a new view of random feature and show that \\textit{benign overfitting}\narises due to the noise which resides in such features (the noise may already\nbe present in the data and propagate to the features or it may be added by the\nuser to the features directly) and plays an important implicit regularization\nrole in the phenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 23:30:43 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 19:59:39 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Li", "Zhu", ""], ["Su", "Weijie", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2008.02930", "submitter": "Ellie Chio", "authors": "Tao Wu, Ellie Ka-In Chio, Heng-Tze Cheng, Yu Du, Steffen Rendle, Dima\n  Kuzmin, Ritesh Agarwal, Li Zhang, John Anderson, Sarvjeet Singh, Tushar\n  Chandra, Ed H. Chi, Wen Li, Ankit Kumar, Xiang Ma, Alex Soares, Nitin Jindal,\n  Pei Cao", "title": "Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to\n  Cold-Start Search Retrieval", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412752", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in neural information retrieval models, which predict\ntop-K items given a query, learn directly from a large training set of (query,\nitem) pairs. However, they are often insufficient when there are many\npreviously unseen (query, item) combinations, often referred to as the cold\nstart problem. Furthermore, the search system can be biased towards items that\nare frequently shown to a query previously, also known as the 'rich get richer'\n(a.k.a. feedback loop) problem. In light of these problems, we observed that\nmost online content platforms have both a search and a recommender system that,\nwhile having heterogeneous input spaces, can be connected through their common\noutput item space and a shared semantic representation. In this paper, we\npropose a new Zero-Shot Heterogeneous Transfer Learning framework that\ntransfers learned knowledge from the recommender system component to improve\nthe search component of a content platform. First, it learns representations of\nitems and their natural-language features by predicting (item, item)\ncorrelation graphs derived from the recommender system as an auxiliary task.\nThen, the learned representations are transferred to solve the target search\nretrieval task, performing query-to-item prediction without having seen any\n(query, item) pairs in training. We conduct online and offline experiments on\none of the world's largest search and recommender systems from Google, and\npresent the results and lessons learned. We demonstrate that the proposed\napproach can achieve high performance on offline search retrieval tasks, and\nmore importantly, achieved significant improvements on relevance and user\ninteractions over the highly-optimized production system in online experiments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:22:56 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:16:40 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Wu", "Tao", ""], ["Chio", "Ellie Ka-In", ""], ["Cheng", "Heng-Tze", ""], ["Du", "Yu", ""], ["Rendle", "Steffen", ""], ["Kuzmin", "Dima", ""], ["Agarwal", "Ritesh", ""], ["Zhang", "Li", ""], ["Anderson", "John", ""], ["Singh", "Sarvjeet", ""], ["Chandra", "Tushar", ""], ["Chi", "Ed H.", ""], ["Li", "Wen", ""], ["Kumar", "Ankit", ""], ["Ma", "Xiang", ""], ["Soares", "Alex", ""], ["Jindal", "Nitin", ""], ["Cao", "Pei", ""]]}, {"id": "2008.02953", "submitter": "Yoonho Lee", "authors": "Yoonho Lee, Juho Lee, Sung Ju Hwang, Eunho Yang, Seungjin Choi", "title": "Neural Complexity Measures", "comments": "Published in Thirty-fourth Conference on Neural Information\n  Processing Systems (NeurIPS 2020) Code is available at\n  https://github.com/yoonholee/neural-complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While various complexity measures for deep neural networks exist, specifying\nan appropriate measure capable of predicting and explaining generalization in\ndeep networks has proven challenging. We propose Neural Complexity (NC), a\nmeta-learning framework for predicting generalization. Our model learns a\nscalar complexity measure through interactions with many heterogeneous tasks in\na data-driven way. The trained NC model can be added to the standard training\nloss to regularize any task learner in a standard supervised learning scenario.\nWe contrast NC's approach against existing manually-designed complexity\nmeasures and other meta-learning models, and we validate NC's performance on\nmultiple regression and classification tasks\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:12:10 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 07:06:55 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lee", "Yoonho", ""], ["Lee", "Juho", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""], ["Choi", "Seungjin", ""]]}, {"id": "2008.02956", "submitter": "Yoonho Lee", "authors": "Juho Lee, Yoonho Lee, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, Yee\n  Whye Teh", "title": "Bootstrapping Neural Processes", "comments": "Published in Thirty-fourth Conference on Neural Information\n  Processing Systems (NeurIPS 2020) Code is available at\n  https://github.com/juho-lee/bnp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike in the traditional statistical modeling for which a user typically\nhand-specify a prior, Neural Processes (NPs) implicitly define a broad class of\nstochastic processes with neural networks. Given a data stream, NP learns a\nstochastic process that best describes the data. While this \"data-driven\" way\nof learning stochastic processes has proven to handle various types of data,\nNPs still rely on an assumption that uncertainty in stochastic processes is\nmodeled by a single latent variable, which potentially limits the flexibility.\nTo this end, we propose the Boostrapping Neural Process (BNP), a novel\nextension of the NP family using the bootstrap. The bootstrap is a classical\ndata-driven technique for estimating uncertainty, which allows BNP to learn the\nstochasticity in NPs without assuming a particular form. We demonstrate the\nefficacy of BNP on various types of data and its robustness in the presence of\nmodel-data mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:23:34 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 04:06:35 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Juho", ""], ["Lee", "Yoonho", ""], ["Kim", "Jungtaek", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2008.02961", "submitter": "Gia Ngo", "authors": "Gia H. Ngo, Meenakshi Khosla, Keith Jamison, Amy Kuceyeski, Mert R.\n  Sabuncu", "title": "From Connectomic to Task-evoked Fingerprints: Individualized Prediction\n  of Task Contrasts from Resting-state Functional Connectivity", "comments": "Accepted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional MRI (rsfMRI) yields functional connectomes that can\nserve as cognitive fingerprints of individuals. Connectomic fingerprints have\nproven useful in many machine learning tasks, such as predicting\nsubject-specific behavioral traits or task-evoked activity. In this work, we\npropose a surface-based convolutional neural network (BrainSurfCNN) model to\npredict individual task contrasts from their resting-state fingerprints. We\nintroduce a reconstructive-contrastive loss that enforces subject-specificity\nof model outputs while minimizing predictive error. The proposed approach\nsignificantly improves the accuracy of predicted contrasts over a\nwell-established baseline. Furthermore, BrainSurfCNN's prediction also\nsurpasses test-retest benchmark in a subject identification task.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:44:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ngo", "Gia H.", ""], ["Khosla", "Meenakshi", ""], ["Jamison", "Keith", ""], ["Kuceyeski", "Amy", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "2008.02964", "submitter": "Tian Lan", "authors": "Tian Lan, Xian-Ling Mao, Wei Wei, Heyan Huang", "title": "Which Kind Is Better in Open-domain Multi-turn Dialog,Hierarchical or\n  Non-hierarchical Models? An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, open-domain generative dialog systems have attracted considerable\nattention in academia and industry. Despite the success of single-turn dialog\ngeneration, multi-turn dialog generation is still a big challenge. So far,\nthere are two kinds of models for open-domain multi-turn dialog generation:\nhierarchical and non-hierarchical models. Recently, some works have shown that\nthe hierarchical models are better than non-hierarchical models under their\nexperimental settings; meanwhile, some works also demonstrate the opposite\nconclusion. Due to the lack of adequate comparisons, it's not clear which kind\nof models are better in open-domain multi-turn dialog generation. Thus, in this\npaper, we will measure systematically nearly all representative hierarchical\nand non-hierarchical models over the same experimental settings to check which\nkind is better. Through extensive experiments, we have the following three\nimportant conclusions: (1) Nearly all hierarchical models are worse than\nnon-hierarchical models in open-domain multi-turn dialog generation, except for\nthe HRAN model. Through further analysis, the excellent performance of HRAN\nmainly depends on its word-level attention mechanism; (2) The performance of\nother hierarchical models will also obtain a great improvement if integrating\nthe word-level attention mechanism into these models. The modified hierarchical\nmodels even significantly outperform the non-hierarchical models; (3) The\nreason why the word-level attention mechanism is so powerful for hierarchical\nmodels is because it can leverage context information more effectively,\nespecially the fine-grained information. Besides, we have implemented all of\nthe models and already released the codes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:54:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Lan", "Tian", ""], ["Mao", "Xian-Ling", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "2008.02965", "submitter": "Ziquan Liu", "authors": "Ziquan Liu, Yufei Cui, Antoni B. Chan", "title": "Improve Generalization and Robustness of Neural Networks via Weight\n  Scale Shifting Invariant Regularizations", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using weight decay to penalize the L2 norms of weights in neural networks has\nbeen a standard training practice to regularize the complexity of networks. In\nthis paper, we show that a family of regularizers, including weight decay, is\nineffective at penalizing the intrinsic norms of weights for networks with\npositively homogeneous activation functions, such as linear, ReLU and\nmax-pooling functions. As a result of homogeneity, functions specified by the\nnetworks are invariant to the shifting of weight scales between layers. The\nineffective regularizers are sensitive to such shifting and thus poorly\nregularize the model capacity, leading to overfitting. To address this\nshortcoming, we propose an improved regularizer that is invariant to weight\nscale shifting and thus effectively constrains the intrinsic norm of a neural\nnetwork. The derived regularizer is an upper bound for the input gradient of\nthe network so minimizing the improved regularizer also benefits the\nadversarial robustness. Residual connections are also considered and we show\nthat our regularizer also forms an upper bound to input gradients of such a\nresidual network. We demonstrate the efficacy of our proposed regularizer on\nvarious datasets and neural network architectures at improving generalization\nand adversarial robustness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:55:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Liu", "Ziquan", ""], ["Cui", "Yufei", ""], ["Chan", "Antoni B.", ""]]}, {"id": "2008.02976", "submitter": "Shankar Kumar", "authors": "Jared Lichtarge and Chris Alberti and Shankar Kumar", "title": "Data Weighted Training Strategies for Grammatical Error Correction", "comments": "Accepted to TACL (Transactions of the Association for Computational\n  Linguistics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in the task of Grammatical Error Correction (GEC) has been\ndriven by addressing data sparsity, both through new methods for generating\nlarge and noisy pretraining data and through the publication of small and\nhigher-quality finetuning data in the BEA-2019 shared task. Building upon\nrecent work in Neural Machine Translation (NMT), we make use of both kinds of\ndata by deriving example-level scores on our large pretraining data based on a\nsmaller, higher-quality dataset. In this work, we perform an empirical study to\ndiscover how to best incorporate delta-log-perplexity, a type of example\nscoring, into a training schedule for GEC. In doing so, we perform experiments\nthat shed light on the function and applicability of delta-log-perplexity.\nModels trained on scored data achieve state-of-the-art results on common GEC\ntest sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 03:30:14 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 13:58:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lichtarge", "Jared", ""], ["Alberti", "Chris", ""], ["Kumar", "Shankar", ""]]}, {"id": "2008.02995", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang, Wenxuan Zhong, Ping Ma", "title": "A Review on Modern Computational Optimal Transport Methods with\n  Applications in Biomedical Research", "comments": "22 pages, 7 figures, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport has been one of the most exciting subjects in mathematics,\nstarting from the 18th century. As a powerful tool to transport between two\nprobability measures, optimal transport methods have been reinvigorated\nnowadays in a remarkable proliferation of modern data science applications. To\nmeet the big data challenges, various computational tools have been developed\nin the recent decade to accelerate the computation for optimal transport\nmethods. In this review, we present some cutting-edge computational optimal\ntransport methods with a focus on the regularization-based methods and the\nprojection-based methods. We discuss their real-world applications in\nbiomedical research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 05:33:54 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 09:29:51 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 09:39:21 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zhang", "Jingyi", ""], ["Zhong", "Wenxuan", ""], ["Ma", "Ping", ""]]}, {"id": "2008.03033", "submitter": "Timo Dimitriadis", "authors": "Timo Dimitriadis, Tilmann Gneiting, Alexander I. Jordan", "title": "Evaluating probabilistic classifiers: Reliability diagrams and score\n  decompositions revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probability forecast or probabilistic classifier is reliable or calibrated\nif the predicted probabilities are matched by ex post observed frequencies, as\nexamined visually in reliability diagrams. The classical binning and counting\napproach to plotting reliability diagrams has been hampered by a lack of\nstability under unavoidable, ad hoc implementation decisions. Here we introduce\nthe CORP approach, which generates provably statistically Consistent, Optimally\nbinned, and Reproducible reliability diagrams in an automated way. CORP is\nbased on non-parametric isotonic regression and implemented via the\nPool-adjacent-violators (PAV) algorithm - essentially, the CORP reliability\ndiagram shows the graph of the PAV- (re)calibrated forecast probabilities. The\nCORP approach allows for uncertainty quantification via either resampling\ntechniques or asymptotic theory, furnishes a new numerical measure of\nmiscalibration, and provides a CORP based Brier score decomposition that\ngeneralizes to any proper scoring rule. We anticipate that judicious uses of\nthe PAV algorithm yield improved tools for diagnostics and inference for a very\nwide range of statistical and machine learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:22:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Dimitriadis", "Timo", ""], ["Gneiting", "Tilmann", ""], ["Jordan", "Alexander I.", ""]]}, {"id": "2008.03038", "submitter": "Subhro Ghosh", "authors": "Subhroshekhar Ghosh, Krishnakumar Balasubramanian, Xiaochuan Yang", "title": "Fractal Gaussian Networks: A sparse random graph model based on Gaussian\n  Multiplicative Chaos", "comments": "Part of this work has been accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel stochastic network model, called Fractal Gaussian Network\n(FGN), that embodies well-defined and analytically tractable fractal\nstructures. Such fractal structures have been empirically observed in diverse\napplications. FGNs interpolate continuously between the popular purely random\ngeometric graphs (a.k.a. the Poisson Boolean network), and random graphs with\nincreasingly fractal behavior. In fact, they form a parametric family of sparse\nrandom geometric graphs that are parametrized by a fractality parameter $\\nu$\nwhich governs the strength of the fractal structure. FGNs are driven by the\nlatent spatial geometry of Gaussian Multiplicative Chaos (GMC), a canonical\nmodel of fractality in its own right. We asymptotically characterize the\nexpected number of edges and triangle in FGNs. We then examine the natural\nquestion of detecting the presence of fractality and the problem of parameter\nestimation based on observed network data, in addition to fundamental\nproperties of the FGN as a random graph model. We also explore fractality in\ncommunity structures by unveiling a natural stochastic block model in the\nsetting of FGNs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:37:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ghosh", "Subhroshekhar", ""], ["Balasubramanian", "Krishnakumar", ""], ["Yang", "Xiaochuan", ""]]}, {"id": "2008.03039", "submitter": "Nicolas Cofre", "authors": "Nicolas Cofre", "title": "A boosted outlier detection method based on the spectrum of the\n  Laplacian matrix of a graph", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new outlier detection algorithm based on the spectrum\nof the Laplacian matrix of a graph. Taking advantage of boosting together with\nsparse-data based learners. The sparcity of the Laplacian matrix significantly\ndecreases the computational burden, enabling a spectrum based outlier detection\nmethod to be applied to larger datasets compared to spectral clustering. The\nmethod is competitive on synthetic datasets with commonly used outlier\ndetection algorithms like Isolation Forest and Local Outlier Factor.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:37:56 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 10:47:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Cofre", "Nicolas", ""]]}, {"id": "2008.03069", "submitter": "Thomas Uriot Tu", "authors": "Thomas Uriot, Dario Izzo, Lu\\'is F. Sim{\\~o}es, Rasit Abay, Nils\n  Einecke, Sven Rebhan, Jose Martinez-Heras, Francesca Letizia, Jan Siminski,\n  Klaus Merz", "title": "Spacecraft Collision Avoidance Challenge: design and results of a\n  machine learning competition", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spacecraft collision avoidance procedures have become an essential part of\nsatellite operations. Complex and constantly updated estimates of the collision\nrisk between orbiting objects inform the various operators who can then plan\nrisk mitigation measures. Such measures could be aided by the development of\nsuitable machine learning models predicting, for example, the evolution of the\ncollision risk in time. In an attempt to study this opportunity, the European\nSpace Agency released, in October 2019, a large curated dataset containing\ninformation about close approach events, in the form of Conjunction Data\nMessages (CDMs), collected from 2015 to 2019. This dataset was used in the\nSpacecraft Collision Avoidance Challenge, a machine learning competition where\nparticipants had to build models to predict the final collision risk between\norbiting objects. This paper describes the design and results of the\ncompetition and discusses the challenges and lessons learned when applying\nmachine learning methods to this problem domain.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:05:20 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:30:31 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Uriot", "Thomas", ""], ["Izzo", "Dario", ""], ["Sim{\u00f5}es", "Lu\u00eds F.", ""], ["Abay", "Rasit", ""], ["Einecke", "Nils", ""], ["Rebhan", "Sven", ""], ["Martinez-Heras", "Jose", ""], ["Letizia", "Francesca", ""], ["Siminski", "Jan", ""], ["Merz", "Klaus", ""]]}, {"id": "2008.03072", "submitter": "Philip Sperl", "authors": "Philip Sperl and Konstantin B\\\"ottinger", "title": "Optimizing Information Loss Towards Robust Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) are vulnerable to adversarial examples. Such inputs\ndiffer only slightly from their benign counterparts yet provoke\nmisclassifications of the attacked NNs. The required perturbations to craft the\nexamples are often negligible and even human imperceptible. To protect deep\nlearning-based systems from such attacks, several countermeasures have been\nproposed with adversarial training still being considered the most effective.\nHere, NNs are iteratively retrained using adversarial examples forming a\ncomputational expensive and time consuming process often leading to a\nperformance decrease. To overcome the downsides of adversarial training while\nstill providing a high level of security, we present a new training approach we\ncall \\textit{entropic retraining}. Based on an information-theoretic-inspired\nanalysis, entropic retraining mimics the effects of adversarial training\nwithout the need of the laborious generation of adversarial examples. We\nempirically show that entropic retraining leads to a significant increase in\nNNs' security and robustness while only relying on the given original data.\nWith our prototype implementation we validate and show the effectiveness of our\napproach for various NN architectures and data sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:12:31 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 14:28:06 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sperl", "Philip", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2008.03096", "submitter": "Devang S Ram Mohan", "authors": "Devang S Ram Mohan, Raphael Lenain, Lorenzo Foglianti, Tian Huey Teh,\n  Marlene Staib, Alexandra Torresquintero, Jiameng Gao", "title": "Incremental Text to Speech for Neural Sequence-to-Sequence Models using\n  Reinforcement Learning", "comments": "To be published in Interspeech 2020. 5 pages, 4 figures", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1822", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern approaches to text to speech require the entire input character\nsequence to be processed before any audio is synthesised. This latency limits\nthe suitability of such models for time-sensitive tasks like simultaneous\ninterpretation. Interleaving the action of reading a character with that of\nsynthesising audio reduces this latency. However, the order of this sequence of\ninterleaved actions varies across sentences, which raises the question of how\nthe actions should be chosen. We propose a reinforcement learning based\nframework to train an agent to make this decision. We compare our performance\nagainst that of deterministic, rule-based systems. Our results demonstrate that\nour agent successfully balances the trade-off between the latency of audio\ngeneration and the quality of synthesised audio. More broadly, we show that\nneural sequence-to-sequence models can be adapted to run in an incremental\nmanner.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 11:48:05 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mohan", "Devang S Ram", ""], ["Lenain", "Raphael", ""], ["Foglianti", "Lorenzo", ""], ["Teh", "Tian Huey", ""], ["Staib", "Marlene", ""], ["Torresquintero", "Alexandra", ""], ["Gao", "Jiameng", ""]]}, {"id": "2008.03110", "submitter": "Matthias Stierle", "authors": "Matthias Stierle, Sven Weinzierl, Maximilian Harl, Martin Matzner", "title": "A Technique for Determining Relevance Scores of Process Activities using\n  Graph-based Neural Networks", "comments": null, "journal-ref": "Decision Support Systems, 2021", "doi": "10.1016/j.dss.2021.113511", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Process models generated through process mining depict the as-is state of a\nprocess. Through annotations with metrics such as the frequency or duration of\nactivities, these models provide generic information to the process analyst. To\nimprove business processes with respect to performance measures, process\nanalysts require further guidance from the process model. In this study, we\ndesign Graph Relevance Miner (GRM), a technique based on graph neural networks,\nto determine the relevance scores for process activities with respect to\nperformance measures. Annotating process models with such relevance scores\nfacilitates a problem-focused analysis of the business process, placing these\nproblems at the centre of the analysis. We quantitatively evaluate the\npredictive quality of our technique using four datasets from different domains,\nto demonstrate the faithfulness of the relevance scores. Furthermore, we\npresent the results of a case study, which highlight the utility of the\ntechnique for organisations. Our work has important implications both for\nresearch and business applications, because process model-based analyses\nfeature shortcomings that need to be urgently addressed to realise successful\nprocess mining at an enterprise level.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:15:30 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 08:57:52 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Stierle", "Matthias", ""], ["Weinzierl", "Sven", ""], ["Harl", "Maximilian", ""], ["Matzner", "Martin", ""]]}, {"id": "2008.03130", "submitter": "Caglar Demir", "authors": "Caglar Demir and Axel-Cyrille Ngonga Ngomo", "title": "Convolutional Complex Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:49:01 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 11:57:04 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 12:25:01 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Demir", "Caglar", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2008.03135", "submitter": "Babacar Mbaye Ndiaye", "authors": "Babacar Mbaye Ndiaye, Mouhamadou A.M.T. Balde, Diaraf Seck", "title": "Visualization and machine learning for forecasting of COVID-19 in\n  Senegal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we give visualization and different machine learning\ntechnics for two weeks and 40 days ahead forecast based on public data. On July\n15, 2020, Senegal reopened its airspace doors, while the number of confirmed\ncases is still increasing. The population no longer respects hygiene measures,\nsocial distancing as at the beginning of the contamination. Negligence or\ntiredness to always wear the masks? We make forecasting on the inflection point\nand possible ending time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:50:30 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ndiaye", "Babacar Mbaye", ""], ["Balde", "Mouhamadou A. M. T.", ""], ["Seck", "Diaraf", ""]]}, {"id": "2008.03156", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Akshat Shrivastava, Anchit Gupta, Naman Goyal, Luke\n  Zettlemoyer, Sonal Gupta", "title": "Better Fine-Tuning by Reducing Representational Collapse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although widely adopted, existing approaches for fine-tuning pre-trained\nlanguage models have been shown to be unstable across hyper-parameter settings,\nmotivating recent work on trust region methods. In this paper, we present a\nsimplified and efficient method rooted in trust region theory that replaces\npreviously used adversarial objectives with parametric noise (sampling from\neither a normal or uniform distribution), thereby discouraging representation\nchange during fine-tuning when possible without hurting performance. We also\nintroduce a new analysis to motivate the use of trust region methods more\ngenerally, by studying representational collapse; the degradation of\ngeneralizable representations from pre-trained models as they are fine-tuned\nfor a specific end task. Extensive experiments show that our fine-tuning method\nmatches or exceeds the performance of previous trust region methods on a range\nof understanding and generation tasks (including DailyMail/CNN, Gigaword,\nReddit TIFU, and the GLUE benchmark), while also being much faster. We also\nshow that it is less prone to representation collapse; the pre-trained models\nmaintain more generalizable representations every time they are fine-tuned.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:13:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Shrivastava", "Akshat", ""], ["Gupta", "Anchit", ""], ["Goyal", "Naman", ""], ["Zettlemoyer", "Luke", ""], ["Gupta", "Sonal", ""]]}, {"id": "2008.03175", "submitter": "Tomoyuki Obuchi", "authors": "Kao Hayashi, Tomoyuki Obuchi, Yoshiyuki Kabashima", "title": "Reconstructing Sparse Signals via Greedy Monte-Carlo Search", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.7566/JPSJ.89.124802", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Monte-Carlo-based method for reconstructing sparse signals in\nthe formulation of sparse linear regression in a high-dimensional setting. The\nbasic idea of this algorithm is to explicitly select variables or covariates to\nrepresent a given data vector or responses and accept randomly generated\nupdates of that selection if and only if the energy or cost function decreases.\nThis algorithm is called the greedy Monte-Carlo (GMC) search algorithm. Its\nperformance is examined via numerical experiments, which suggests that in the\nnoiseless case, GMC can achieve perfect reconstruction in undersampling\nsituations of a reasonable level: it can outperform the $\\ell_1$ relaxation but\ndoes not reach the algorithmic limit of MC-based methods theoretically\nclarified by an earlier analysis. The necessary computational time is also\nexamined and compared with that of an algorithm using simulated annealing.\nAdditionally, experiments on the noisy case are conducted on synthetic datasets\nand on a real-world dataset, supporting the practicality of GMC.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:36:57 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 03:24:43 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 09:05:13 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Hayashi", "Kao", ""], ["Obuchi", "Tomoyuki", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "2008.03194", "submitter": "Lijun Sun Mr", "authors": "Xinyu Chen, Yixian Chen, Nicolas Saunier, Lijun Sun", "title": "Scalable Low-Rank Tensor Learning for Spatiotemporal Traffic Data\n  Imputation", "comments": null, "journal-ref": "Transportation Research Part C Emerging Technologies (2021)\n  129:103226", "doi": "10.1016/j.trc.2021.103226", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing value problem in spatiotemporal traffic data has long been a\nchallenging topic, in particular for large-scale and high-dimensional data with\ncomplex missing mechanisms and diverse degrees of missingness. Recent studies\nbased on tensor nuclear norm have demonstrated the superiority of tensor\nlearning in imputation tasks by effectively characterizing the complex\ncorrelations/dependencies in spatiotemporal data. However, despite the\npromising results, these approaches do not scale well to large data tensors. In\nthis paper, we focus on addressing the missing data imputation problem for\nlarge-scale spatiotemporal traffic data. To achieve both high accuracy and\nefficiency, we develop a scalable tensor learning model -- Low-Tubal-Rank\nSmoothing Tensor Completion (LSTC-Tubal) -- based on the existing framework of\nLow-Rank Tensor Completion, which is well-suited for spatiotemporal traffic\ndata that is characterized by multidimensional structure of location$\\times$\ntime of day $\\times$ day. In particular, the proposed LSTC-Tubal model involves\na scalable tensor nuclear norm minimization scheme by integrating linear\nunitary transformation. Therefore, tensor nuclear norm minimization can be\nsolved by singular value thresholding on the transformed matrix of each day\nwhile the day-to-day correlation can be effectively preserved by the unitary\ntransform matrix. We compare LSTC-Tubal with state-of-the-art baseline models,\nand find that LSTC-Tubal can achieve competitive accuracy with a significantly\nlower computational cost. In addition, the LSTC-Tubal will also benefit other\ntasks in modeling large-scale spatiotemporal traffic data, such as\nnetwork-level traffic forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:19:07 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 12:58:48 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 17:19:07 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Xinyu", ""], ["Chen", "Yixian", ""], ["Saunier", "Nicolas", ""], ["Sun", "Lijun", ""]]}, {"id": "2008.03209", "submitter": "Sina D\\\"aubener", "authors": "Sina D\\\"aubener and Asja Fischer", "title": "Investigating maximum likelihood based training of infinite mixtures for\n  uncertainty quantification", "comments": null, "journal-ref": "Presented at the uncertainty workshop of ECML PKDD 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification in neural networks gained a lot of attention in\nthe past years. The most popular approaches, Bayesian neural networks (BNNs),\nMonte Carlo dropout, and deep ensembles have one thing in common: they are all\nbased on some kind of mixture model. While the BNNs build infinite mixture\nmodels and are derived via variational inference, the latter two build finite\nmixtures trained with the maximum likelihood method. In this work we\ninvestigate the effect of training an infinite mixture distribution with the\nmaximum likelihood method instead of variational inference. We find that the\nproposed objective leads to stochastic networks with an increased predictive\nvariance, which improves uncertainty based identification of\nmiss-classification and robustness against adversarial attacks in comparison to\na standard BNN with equivalent network structure. The new model also displays\nhigher entropy on out-of-distribution data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:55:53 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:57:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["D\u00e4ubener", "Sina", ""], ["Fischer", "Asja", ""]]}, {"id": "2008.03221", "submitter": "Zsigmond Benk\\H{o}", "authors": "Zsigmond Benk\\H{o}, Marcell Stippinger, Roberta Rehus, Attila Bencze,\n  D\\'aniel Fab\\'o, Bogl\\'arka Hajnal, Lor\\'and Er\\H{o}ss, Andr\\'as Telcs,\n  Zolt\\'an Somogyv\\'ari", "title": "Manifold-adaptive dimension estimation revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data dimensionality informs us about data complexity and sets limit on the\nstructure of successful signal processing pipelines. In this work we revisit\nand improve the manifold-adaptive Farahmand-Szepesv\\'ari-Audibert (FSA)\ndimension estimator, making it one of the best nearest neighbor-based dimension\nestimators available. We compute the probability density function of local FSA\nestimates, if the local manifold density is uniform. Based on the probability\ndensity function, we propose to use the median of local estimates as a basic\nglobal measure of intrinsic dimensionality, and we demonstrate the advantages\nof this asymptotically unbiased estimator over the previously proposed\nstatistics: the mode and the mean. Additionally, from the probability density\nfunction, we derive the maximum likelihood formula for global intrinsic\ndimensionality, if i.i.d. holds. We tackle edge and finite-sample effects with\nan exponential correction formula, calibrated on hypercube datasets. We compare\nthe performance of the corrected-median-FSA estimator with kNN estimators:\nmaximum likelihood (ML, Levina-Bickel) and two implementations of DANCo (R and\nmatlab). We show that corrected-median-FSA estimator beats the ML estimator and\nit is on equal footing with DANCo for standard synthetic benchmarks according\nto mean percentage error and error rate metrics. With the median-FSA algorithm,\nwe reveal diverse changes in the neural dynamics while resting state and during\nepileptic seizures. We identify brain areas with lower-dimensional dynamics\nthat are possible causal sources and candidates for being seizure onset zones.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:27:26 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 10:04:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Benk\u0151", "Zsigmond", ""], ["Stippinger", "Marcell", ""], ["Rehus", "Roberta", ""], ["Bencze", "Attila", ""], ["Fab\u00f3", "D\u00e1niel", ""], ["Hajnal", "Bogl\u00e1rka", ""], ["Er\u0151ss", "Lor\u00e1nd", ""], ["Telcs", "Andr\u00e1s", ""], ["Somogyv\u00e1ri", "Zolt\u00e1n", ""]]}, {"id": "2008.03226", "submitter": "Ryan-Rhys Griffiths", "authors": "Aditya R. Thawani, Ryan-Rhys Griffiths, Arian Jamasb, Anthony\n  Bourached, Penelope Jones, William McCorkindale, Alexander A. Aldrick, Alpha\n  A. Lee", "title": "The Photoswitch Dataset: A Molecular Machine Learning Benchmark for the\n  Advancement of Synthetic Chemistry", "comments": "Prior version accepted to the 2020 ICLR Workshop on Fundamental\n  Science in the Era of AI. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The space of synthesizable molecules is greater than $10^{60}$, meaning only\na vanishingly small fraction of these molecules have ever been realized in the\nlab. In order to prioritize which regions of this space to explore next,\nsynthetic chemists need access to accurate molecular property predictions.\nWhile great advances in molecular machine learning have been made, there is a\ndearth of benchmarks featuring properties that are useful for the synthetic\nchemist. Focussing directly on the needs of the synthetic chemist, we introduce\nthe Photoswitch Dataset, a new benchmark for molecular machine learning where\nimprovements in model performance can be immediately observed in the throughput\nof promising molecules synthesized in the lab. Photoswitches are a versatile\nclass of molecule for medical and renewable energy applications where a\nmolecule's efficacy is governed by its electronic transition wavelengths. We\ndemonstrate superior performance in predicting these wavelengths compared to\nboth time-dependent density functional theory (TD-DFT), the incumbent first\nprinciples quantum mechanical approach, as well as a panel of human experts.\nOur baseline models are currently being deployed in the lab as part of the\ndecision process for candidate synthesis. It is our hope that this benchmark\ncan drive real discoveries in photoswitch chemistry and that future benchmarks\ncan be introduced to pivot learning algorithm development to benefit more\nexpansive areas of synthetic chemistry.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 20:59:03 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Thawani", "Aditya R.", ""], ["Griffiths", "Ryan-Rhys", ""], ["Jamasb", "Arian", ""], ["Bourached", "Anthony", ""], ["Jones", "Penelope", ""], ["McCorkindale", "William", ""], ["Aldrick", "Alexander A.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "2008.03230", "submitter": "Shohreh Deldari", "authors": "Shohreh Deldari, Daniel V. Smith, Amin Sadri, Flora D. Salim", "title": "ESPRESSO: Entropy and ShaPe awaRe timE-Series SegmentatiOn for\n  processing heterogeneous sensor data", "comments": "23 pages, 11 figures, accepted at IMWUT Volume(4) issue(3)", "journal-ref": null, "doi": "10.1145/3411832", "report-no": null, "categories": "cs.LG cs.CV cs.DB cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting informative and meaningful temporal segments from high-dimensional\nwearable sensor data, smart devices, or IoT data is a vital preprocessing step\nin applications such as Human Activity Recognition (HAR), trajectory\nprediction, gesture recognition, and lifelogging. In this paper, we propose\nESPRESSO (Entropy and ShaPe awaRe timE-Series SegmentatiOn), a hybrid\nsegmentation model for multi-dimensional time-series that is formulated to\nexploit the entropy and temporal shape properties of time-series. ESPRESSO\ndiffers from existing methods that focus upon particular statistical or\ntemporal properties of time-series exclusively. As part of model development, a\nnovel temporal representation of time-series $WCAC$ was introduced along with a\ngreedy search approach that estimate segments based upon the entropy metric.\nESPRESSO was shown to offer superior performance to four state-of-the-art\nmethods across seven public datasets of wearable and wear-free sensing. In\naddition, we undertake a deeper investigation of these datasets to understand\nhow ESPRESSO and its constituent methods perform with respect to different\ndataset characteristics. Finally, we provide two interesting case-studies to\nshow how applying ESPRESSO can assist in inferring daily activity routines and\nthe emotional state of humans.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 10:41:20 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Deldari", "Shohreh", ""], ["Smith", "Daniel V.", ""], ["Sadri", "Amin", ""], ["Salim", "Flora D.", ""]]}, {"id": "2008.03235", "submitter": "Thibaud Rahier", "authors": "Thibaud Rahier, Am\\'elie H\\'eliou, Matthieu Martin, Christophe\n  Renaudin and Eustache Diemert", "title": "Individual Treatment Prescription Effect Estimation in a Low Compliance\n  Setting", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual Treatment Effect (ITE) estimation is an extensively researched\nproblem, with applications in various domains. We model the case where there\nexists heterogeneous non-compliance to a randomly assigned treatment, a typical\nsituation in health (because of non-compliance to prescription) or digital\nadvertising (because of competition and ad blockers for instance). The lower\nthe compliance, the more the effect of treatment prescription, or individual\nprescription effect (IPE), signal fades away and becomes hard to estimate. We\npropose a new approach for the estimation of the IPE that takes advantage of\nobserved compliance information to prevent signal fading. Using the Structural\nCausal Model framework and do-calculus, we define a general mediated causal\neffect setting and propose a corresponding estimator which consistently\nrecovers the IPE with asymptotic variance guarantees. Finally, we conduct\nexperiments on both synthetic and real-world datasets that highlight the\nbenefit of the approach, which consistently improves state-of-the-art in low\ncompliance settings\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:53:00 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 15:30:12 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Rahier", "Thibaud", ""], ["H\u00e9liou", "Am\u00e9lie", ""], ["Martin", "Matthieu", ""], ["Renaudin", "Christophe", ""], ["Diemert", "Eustache", ""]]}, {"id": "2008.03273", "submitter": "Kyriakos Polymenakos", "authors": "Kyriakos Polymenakos, Nikitas Rontsis, Alessandro Abate and Stephen\n  Roberts", "title": "SafePILCO: a software tool for safe and data-efficient policy synthesis", "comments": "Shorter Version published as a software tool demonstration at QEST\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SafePILCO is a software tool for safe and data-efficient policy search with\nreinforcement learning. It extends the known PILCO algorithm, originally\nwritten in MATLAB, to support safe learning. We provide a Python implementation\nand leverage existing libraries that allow the codebase to remain short and\nmodular, which is appropriate for wider use by the verification, reinforcement\nlearning, and control communities.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:17:30 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Polymenakos", "Kyriakos", ""], ["Rontsis", "Nikitas", ""], ["Abate", "Alessandro", ""], ["Roberts", "Stephen", ""]]}, {"id": "2008.03288", "submitter": "Lin Liu L", "authors": "Lin Liu and Rajarshi Mukherjee and James M. Robins", "title": "Rejoinder: On nearly assumption-free tests of nominal confidence\n  interval coverage for causal parameters estimated by machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the rejoinder to the discussion by Kennedy, Balakrishnan and\nWasserman on the paper \"On nearly assumption-free tests of nominal confidence\ninterval coverage for causal parameters estimated by machine learning\"\npublished in Statistical Science.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:38:54 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Liu", "Lin", ""], ["Mukherjee", "Rajarshi", ""], ["Robins", "James M.", ""]]}, {"id": "2008.03312", "submitter": "Stephen Green", "authors": "Stephen R. Green, Jonathan Gair", "title": "Complete parameter inference for GW150914 using deep learning", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "LIGO-P2000282", "categories": "astro-ph.IM gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The LIGO and Virgo gravitational-wave observatories have detected many\nexciting events over the past five years. As the rate of detections grows with\ndetector sensitivity, this poses a growing computational challenge for data\nanalysis. With this in mind, in this work we apply deep learning techniques to\nperform fast likelihood-free Bayesian inference for gravitational waves. We\ntrain a neural-network conditional density estimator to model posterior\nprobability distributions over the full 15-dimensional space of binary black\nhole system parameters, given detector strain data from multiple detectors. We\nuse the method of normalizing flows---specifically, a neural spline normalizing\nflow---which allows for rapid sampling and density estimation. Training the\nnetwork is likelihood-free, requiring samples from the data generative process,\nbut no likelihood evaluations. Through training, the network learns a global\nset of posteriors: it can generate thousands of independent posterior samples\nper second for any strain data consistent with the prior and detector noise\ncharacteristics used for training. By training with the detector noise power\nspectral density estimated at the time of GW150914, and conditioning on the\nevent strain data, we use the neural network to generate accurate posterior\nsamples consistent with analyses using conventional sampling techniques.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:00:02 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Green", "Stephen R.", ""], ["Gair", "Jonathan", ""]]}, {"id": "2008.03326", "submitter": "Marco Mondelli", "authors": "Marco Mondelli, Christos Thrampoulidis and Ramji Venkataramanan", "title": "Optimal Combination of Linear and Spectral Estimators for Generalized\n  Linear Models", "comments": "49 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering an unknown signal $\\boldsymbol x$ given\nmeasurements obtained from a generalized linear model with a Gaussian sensing\nmatrix. Two popular solutions are based on a linear estimator $\\hat{\\boldsymbol\nx}^{\\rm L}$ and a spectral estimator $\\hat{\\boldsymbol x}^{\\rm s}$. The former\nis a data-dependent linear combination of the columns of the measurement\nmatrix, and its analysis is quite simple. The latter is the principal\neigenvector of a data-dependent matrix, and a recent line of work has studied\nits performance. In this paper, we show how to optimally combine\n$\\hat{\\boldsymbol x}^{\\rm L}$ and $\\hat{\\boldsymbol x}^{\\rm s}$. At the heart\nof our analysis is the exact characterization of the joint empirical\ndistribution of $(\\boldsymbol x, \\hat{\\boldsymbol x}^{\\rm L}, \\hat{\\boldsymbol\nx}^{\\rm s})$ in the high-dimensional limit. This allows us to compute the\nBayes-optimal combination of $\\hat{\\boldsymbol x}^{\\rm L}$ and\n$\\hat{\\boldsymbol x}^{\\rm s}$, given the limiting distribution of the signal\n$\\boldsymbol x$. When the distribution of the signal is Gaussian, then the\nBayes-optimal combination has the form $\\theta\\hat{\\boldsymbol x}^{\\rm\nL}+\\hat{\\boldsymbol x}^{\\rm s}$ and we derive the optimal combination\ncoefficient. In order to establish the limiting distribution of $(\\boldsymbol\nx, \\hat{\\boldsymbol x}^{\\rm L}, \\hat{\\boldsymbol x}^{\\rm s})$, we design and\nanalyze an Approximate Message Passing (AMP) algorithm whose iterates give\n$\\hat{\\boldsymbol x}^{\\rm L}$ and approach $\\hat{\\boldsymbol x}^{\\rm s}$.\nNumerical simulations demonstrate the improvement of the proposed combination\nwith respect to the two methods considered separately.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:20:05 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 14:24:56 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 07:15:43 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Mondelli", "Marco", ""], ["Thrampoulidis", "Christos", ""], ["Venkataramanan", "Ramji", ""]]}, {"id": "2008.03364", "submitter": "Xuanqing Liu", "authors": "Jiachen Zhong, Xuanqing Liu, Cho-Jui Hsieh", "title": "Improving the Speed and Quality of GAN by Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have shown remarkable results in image\ngeneration tasks. High fidelity class-conditional GAN methods often rely on\nstabilization techniques by constraining the global Lipschitz continuity. Such\nregularization leads to less expressive models and slower convergence speed;\nother techniques, such as the large batch training, require unconventional\ncomputing power and are not widely accessible. In this paper, we develop an\nefficient algorithm, namely FastGAN (Free AdverSarial Training), to improve the\nspeed and quality of GAN training based on the adversarial training technique.\nWe benchmark our method on CIFAR10, a subset of ImageNet, and the full ImageNet\ndatasets. We choose strong baselines such as SNGAN and SAGAN; the results\ndemonstrate that our training algorithm can achieve better generation quality\n(in terms of the Inception score and Frechet Inception distance) with less\noverall training time. Most notably, our training algorithm brings ImageNet\ntraining to the broader public by requiring 2-4 GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:21:31 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhong", "Jiachen", ""], ["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2008.03368", "submitter": "Hamid Usefi", "authors": "Hamid Usefi", "title": "Clustering, multicollinearity, and singular vectors", "comments": "Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a matrix with its pseudo-matrix $A^{\\dagger}$ and set\n$S=I-A^{\\dagger}A$. We prove that, after re-ordering the columns of $A$, the\nmatrix $S$ has a block-diagonal form where each block corresponds to a set of\nlinearly dependent columns. This allows us to identify redundant columns in\n$A$. We explore some applications in supervised and unsupervised learning,\nspecially feature selection, clustering, and sensitivity of solutions of least\nsquares solutions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:32:34 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Usefi", "Hamid", ""]]}, {"id": "2008.03371", "submitter": "Ang Li", "authors": "Ang Li, Jingwei Sun, Binghui Wang, Lin Duan, Sicheng Li, Yiran Chen,\n  Hai Li", "title": "LotteryFL: Personalized and Communication-Efficient Federated Learning\n  with Lottery Ticket Hypothesis on Non-IID Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a popular distributed machine learning paradigm with\nenhanced privacy. Its primary goal is learning a global model that offers good\nperformance for the participants as many as possible. The technology is rapidly\nadvancing with many unsolved challenges, among which statistical heterogeneity\n(i.e., non-IID) and communication efficiency are two critical ones that hinder\nthe development of federated learning. In this work, we propose LotteryFL -- a\npersonalized and communication-efficient federated learning framework via\nexploiting the Lottery Ticket hypothesis. In LotteryFL, each client learns a\nlottery ticket network (i.e., a subnetwork of the base model) by applying the\nLottery Ticket hypothesis, and only these lottery networks will be communicated\nbetween the server and clients. Rather than learning a shared global model in\nclassic federated learning, each client learns a personalized model via\nLotteryFL; the communication cost can be significantly reduced due to the\ncompact size of lottery networks. To support the training and evaluation of our\nframework, we construct non-IID datasets based on MNIST, CIFAR-10 and EMNIST by\ntaking feature distribution skew, label distribution skew and quantity skew\ninto consideration. Experiments on these non-IID datasets demonstrate that\nLotteryFL significantly outperforms existing solutions in terms of\npersonalization and communication cost.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:45:12 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Li", "Ang", ""], ["Sun", "Jingwei", ""], ["Wang", "Binghui", ""], ["Duan", "Lin", ""], ["Li", "Sicheng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "2008.03399", "submitter": "Yongquan Fu", "authors": "Yongquan Fu", "title": "Nystr\\\"om Approximation with Nonnegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the needs of estimating the proximity clustering with partial\ndistance measurements from vantage points or landmarks for remote networked\nsystems, we show that the proximity clustering problem can be effectively\nformulated as the Nystr\\\"om approximation problem, which solves the kernel\nK-means clustering problem in the complex space. We implement the Nystr\\\"om\napproximation based on a landmark based Nonnegative Matrix Factorization (NMF)\nprocess. Evaluation results show that the proposed method finds nearly optimal\nclustering quality on both synthetic and real-world data sets as we vary the\nrange of parameter choices and network conditions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:52:59 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fu", "Yongquan", ""]]}, {"id": "2008.03400", "submitter": "Hideitsu Hino", "authors": "Keishi Sando and Hideitsu Hino", "title": "Modal Principal Component Analysis", "comments": "33 pages, 5 figures. to appear in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a widely used method for data\nprocessing, such as for dimension reduction and visualization. Standard PCA is\nknown to be sensitive to outliers, and thus, various robust PCA methods have\nbeen proposed. It has been shown that the robustness of many statistical\nmethods can be improved using mode estimation instead of mean estimation,\nbecause mode estimation is not significantly affected by the presence of\noutliers. Thus, this study proposes a modal principal component analysis\n(MPCA), which is a robust PCA method based on mode estimation. The proposed\nmethod finds the minor component by estimating the mode of the projected data\npoints. As theoretical contribution, probabilistic convergence property,\ninfluence function, finite-sample breakdown point and its lower bound for the\nproposed MPCA are derived. The experimental results show that the proposed\nmethod has advantages over the conventional methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:59:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sando", "Keishi", ""], ["Hino", "Hideitsu", ""]]}, {"id": "2008.03408", "submitter": "Bo Wang", "authors": "Bo Wang, Yue Wu, Niall Taylor, Terry Lyons, Maria Liakata, Alejo J\n  Nevado-Holgado, Kate E A Saunders", "title": "Learning to Detect Bipolar Disorder and Borderline Personality Disorder\n  with Language and Speech in Non-Clinical Interviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bipolar disorder (BD) and borderline personality disorder (BPD) are both\nchronic psychiatric disorders. However, their overlapping symptoms and common\ncomorbidity make it challenging for the clinicians to distinguish the two\nconditions on the basis of a clinical interview. In this work, we first present\na new multi-modal dataset containing interviews involving individuals with BD\nor BPD being interviewed about a non-clinical topic . We investigate the\nautomatic detection of the two conditions, and demonstrate a good linear\nclassifier that can be learnt using a down-selected set of features from the\ndifferent aspects of the interviews and a novel approach of summarising these\nfeatures. Finally, we find that different sets of features characterise BD and\nBPD, thus providing insights into the difference between the automatic\nscreening of the two conditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 00:48:59 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 04:23:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Bo", ""], ["Wu", "Yue", ""], ["Taylor", "Niall", ""], ["Lyons", "Terry", ""], ["Liakata", "Maria", ""], ["Nevado-Holgado", "Alejo J", ""], ["Saunders", "Kate E A", ""]]}, {"id": "2008.03433", "submitter": "John Halloran", "authors": "John T. Halloran and David M. Rocke", "title": "GPU-Accelerated Primal Learning for Extremely Fast Large-Scale\n  Classification", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most efficient methods to solve L2-regularized primal problems,\nsuch as logistic regression and linear support vector machine (SVM)\nclassification, is the widely used trust region Newton algorithm, TRON. While\nTRON has recently been shown to enjoy substantial speedups on shared-memory\nmulti-core systems, exploiting graphical processing units (GPUs) to speed up\nthe method is significantly more difficult, owing to the highly complex and\nheavily sequential nature of the algorithm. In this work, we show that using\njudicious GPU-optimization principles, TRON training time for different losses\nand feature representations may be drastically reduced. For sparse feature\nsets, we show that using GPUs to train logistic regression classifiers in\nLIBLINEAR is up to an order-of-magnitude faster than solely using\nmultithreading. For dense feature sets--which impose far more stringent memory\nconstraints--we show that GPUs substantially reduce the lengthy SVM learning\ntimes required for state-of-the-art proteomics analysis, leading to dramatic\nimprovements over recently proposed speedups. Furthermore, we show how GPU\nspeedups may be mixed with multithreading to enable such speedups when the\ndataset is too large for GPU memory requirements; on a massive dense proteomics\ndataset of nearly a quarter-billion data instances, these mixed-architecture\nspeedups reduce SVM analysis time from over half a week to less than a single\nday while using limited GPU memory.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:40:27 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 03:16:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Halloran", "John T.", ""], ["Rocke", "David M.", ""]]}, {"id": "2008.03452", "submitter": "Shiying Li", "authors": "Akram Aldroubi, Shiying Li, Gustavo K. Rohde", "title": "Partitioning signal classes using transport transforms for data analysis\n  and machine learning", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relatively new set of transport-based transforms (CDT, R-CDT, LOT) have\nshown their strength and great potential in various image and data processing\ntasks such as parametric signal estimation, classification, cancer detection\namong many others. It is hence worthwhile to elucidate some of the mathematical\nproperties that explain the successes of these transforms when they are used as\ntools in data analysis, signal processing or data classification. In\nparticular, we give conditions under which classes of signals that are created\nby algebraic generative models are transformed into convex sets by the\ntransport transforms. Such convexification of the classes simplify the\nclassification and other data analysis and processing problems when viewed in\nthe transform domain. More specifically, we study the extent and limitation of\nthe convexification ability of these transforms under an algebraic generative\nmodeling framework. We hope that this paper will serve as an introduction to\nthese transforms and will encourage mathematicians and other researchers to\nfurther explore the theoretical underpinnings and algorithmic tools that will\nhelp understand the successes of these transforms and lay the groundwork for\nfurther successful applications.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 06:12:10 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 12:48:08 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Aldroubi", "Akram", ""], ["Li", "Shiying", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "2008.03454", "submitter": "Daniel Fryer Mr", "authors": "Daniel Fryer, Hien Nguyen, Pascal Castellazzi", "title": "$k$-means on Positive Definite Matrices, and an Application to\n  Clustering in Radar Image Sequences", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We state theoretical properties for $k$-means clustering of Symmetric\nPositive Definite (SPD) matrices, in a non-Euclidean space, that provides a\nnatural and favourable representation of these data. We then provide a novel\napplication for this method, to time-series clustering of pixels in a sequence\nof Synthetic Aperture Radar images, via their finite-lag autocovariance\nmatrices.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 06:21:43 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 03:11:48 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Fryer", "Daniel", ""], ["Nguyen", "Hien", ""], ["Castellazzi", "Pascal", ""]]}, {"id": "2008.03501", "submitter": "Ilona Kulikovskikh", "authors": "Ilona Kulikovskikh and Tarzan Legovi\\'c", "title": "Why to \"grow\" and \"harvest\" deep learning models?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current expectations from training deep learning models with gradient-based\nmethods include: 1) transparency; 2) high convergence rates; 3) high inductive\nbiases. While the state-of-art methods with adaptive learning rate schedules\nare fast, they still fail to meet the other two requirements. We suggest\nreconsidering neural network models in terms of single-species population\ndynamics where adaptation comes naturally from open-ended processes of \"growth\"\nand \"harvesting\". We show that the stochastic gradient descent (SGD) with two\nbalanced pre-defined values of per capita growth and harvesting rates\noutperform the most common adaptive gradient methods in all of the three\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 11:55:24 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kulikovskikh", "Ilona", ""], ["Legovi\u0107", "Tarzan", ""]]}, {"id": "2008.03525", "submitter": "Oleg Arenz", "authors": "Oleg Arenz and Gerhard Neumann", "title": "Non-Adversarial Imitation Learning and its Connections to Adversarial\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.RO math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern methods for imitation learning and inverse reinforcement\nlearning, such as GAIL or AIRL, are based on an adversarial formulation. These\nmethods apply GANs to match the expert's distribution over states and actions\nwith the implicit state-action distribution induced by the agent's policy.\nHowever, by framing imitation learning as a saddle point problem, adversarial\nmethods can suffer from unstable optimization, and convergence can only be\nshown for small policy updates. We address these problems by proposing a\nframework for non-adversarial imitation learning. The resulting algorithms are\nsimilar to their adversarial counterparts and, thus, provide insights for\nadversarial imitation learning methods. Most notably, we show that AIRL is an\ninstance of our non-adversarial formulation, which enables us to greatly\nsimplify its derivations and obtain stronger convergence guarantees. We also\nshow that our non-adversarial formulation can be used to derive novel\nalgorithms by presenting a method for offline imitation learning that is\ninspired by the recent ValueDice algorithm, but does not rely on small policy\nupdates for convergence. In our simulated robot experiments, our offline method\nfor non-adversarial imitation learning seems to perform best when using many\nupdates for policy and discriminator at each iteration and outperforms\nbehavioral cloning and ValueDice.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:43:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Arenz", "Oleg", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2008.03529", "submitter": "Zhiwen Zuo", "authors": "Zhiwen Zuo, Lei Zhao, Zhizhong Wang, Haibo Chen, Ailin Li, Qijiang Xu,\n  Wei Xing, Dongming Lu", "title": "Multimodal Image-to-Image Translation via Mutual Information Estimation\n  and Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal image-to-image translation (I2IT) aims to learn a conditional\ndistribution that explores multiple possible images in the target domain given\nan input image in the source domain. Conditional generative adversarial\nnetworks (cGANs) are often adopted for modeling such a conditional\ndistribution. However, cGANs are prone to ignore the latent code and learn a\nunimodal distribution in conditional image synthesis, which is also known as\nthe mode collapse issue of GANs. To solve the problem, we propose a simple yet\neffective method that explicitly estimates and maximizes the mutual information\nbetween the latent code and the output image in cGANs by using a deep mutual\ninformation neural estimator in this paper. Maximizing the mutual information\nstrengthens the statistical dependency between the latent code and the output\nimage, which prevents the generator from ignoring the latent code and\nencourages cGANs to fully utilize the latent code for synthesizing diverse\nresults. Our method not only provides a new perspective from information theory\nto improve diversity for I2IT but also achieves disentanglement between the\nsource domain content and the target domain style for free.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 14:09:23 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 15:34:46 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 08:29:29 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 04:08:50 GMT"}, {"version": "v5", "created": "Tue, 1 Sep 2020 10:49:43 GMT"}, {"version": "v6", "created": "Sun, 6 Sep 2020 04:17:36 GMT"}, {"version": "v7", "created": "Sat, 8 May 2021 14:15:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zuo", "Zhiwen", ""], ["Zhao", "Lei", ""], ["Wang", "Zhizhong", ""], ["Chen", "Haibo", ""], ["Li", "Ailin", ""], ["Xu", "Qijiang", ""], ["Xing", "Wei", ""], ["Lu", "Dongming", ""]]}, {"id": "2008.03534", "submitter": "Raphael Gautier", "authors": "Raphael Gautier, Piyush Pandita, Sayan Ghosh, Dimitri Mavris", "title": "A Fully Bayesian Gradient-Free Supervised Dimension Reduction Method\n  using Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern day engineering problems are ubiquitously characterized by\nsophisticated computer codes that map parameters or inputs to an underlying\nphysical process. In other situations, experimental setups are used to model\nthe physical process in a laboratory, ensuring high precision while being\ncostly in materials and logistics. In both scenarios, only limited amount of\ndata can be generated by querying the expensive information source at a finite\nnumber of inputs or designs. This problem is compounded further in the presence\nof a high-dimensional input space. State-of-the-art parameter space dimension\nreduction methods, such as active subspace, aim to identify a subspace of the\noriginal input space that is sufficient to explain the output response. These\nmethods are restricted by their reliance on gradient evaluations or copious\ndata, making them inadequate to expensive problems without direct access to\ngradients. The proposed methodology is gradient-free and fully Bayesian, as it\nquantifies uncertainty in both the low-dimensional subspace and the surrogate\nmodel parameters. This enables a full quantification of epistemic uncertainty\nand robustness to limited data availability. It is validated on multiple\ndatasets from engineering and science and compared to two other\nstate-of-the-art methods based on four aspects: a) recovery of the active\nsubspace, b) deterministic prediction accuracy, c) probabilistic prediction\naccuracy, and d) training time. The comparison shows that the proposed method\nimproves the active subspace recovery and predictive accuracy, in both the\ndeterministic and probabilistic sense, when only few model observations are\navailable for training, at the cost of increased training time.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 14:24:25 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:59:07 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gautier", "Raphael", ""], ["Pandita", "Piyush", ""], ["Ghosh", "Sayan", ""], ["Mavris", "Dimitri", ""]]}, {"id": "2008.03543", "submitter": "Kamal Berahmand", "authors": "Mehrdad Rostami, Kamal Berahmand, Saman Forouzandeh", "title": "A Novel Community Detection Based Genetic Algorithm for Feature\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The selection of features is an essential data preprocessing stage in data\nmining. The core principle of feature selection seems to be to pick a subset of\npossible features by excluding features with almost no predictive information\nas well as highly associated redundant features. In the past several years, a\nvariety of meta-heuristic methods were introduced to eliminate redundant and\nirrelevant features as much as possible from high-dimensional datasets. Among\nthe main disadvantages of present meta-heuristic based approaches is that they\nare often neglecting the correlation between a set of selected features. In\nthis article, for the purpose of feature selection, the authors propose a\ngenetic algorithm based on community detection, which functions in three steps.\nThe feature similarities are calculated in the first step. The features are\nclassified by community detection algorithms into clusters throughout the\nsecond step. In the third step, features are picked by a genetic algorithm with\na new community-based repair operation. Nine benchmark classification problems\nwere analyzed in terms of the performance of the presented approach. Also, the\nauthors have compared the efficiency of the proposed approach with the findings\nfrom four available algorithms for feature selection. The findings indicate\nthat the new approach continuously yields improved classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:39:30 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""], ["Forouzandeh", "Saman", ""]]}, {"id": "2008.03582", "submitter": "Anand Ramakrishnan", "authors": "Anand Ramakrishnan, Warren B.Jackson and Kent Evans", "title": "Error Autocorrelation Objective Function for Improved System Modeling", "comments": "7 pages, 3 Figures, 8 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models are trained to minimize the error between the model's\noutput and the actual values. The typical cost function, the Mean Squared Error\n(MSE), arises from maximizing the log-likelihood of additive independent,\nidentically distributed Gaussian noise. However, minimizing MSE fails to\nminimize the residuals' cross-correlations, leading to over-fitting and poor\nextrapolation of the model outside the training set (generalization). In this\npaper, we introduce a \"whitening\" cost function, the Ljung-Box statistic, which\nnot only minimizes the error but also minimizes the correlations between\nerrors, ensuring that the fits enforce compatibility with an independent and\nidentically distributed (i.i.d) gaussian noise model. The results show\nsignificant improvement in generalization for recurrent neural networks (RNNs)\n(1d) and image autoencoders (2d). Specifically, we look at both temporal\ncorrelations for system-id in simulated and actual mechanical systems. We also\nlook at spatial correlation in vision autoencoders to demonstrate that the\nwhitening objective functions lead to much better extrapolation--a property\nvery desirable for reliable control systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 19:20:32 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 15:34:38 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ramakrishnan", "Anand", ""], ["Jackson", "Warren B.", ""], ["Evans", "Kent", ""]]}, {"id": "2008.03590", "submitter": "Alexey Sholokhov", "authors": "Alexey Sholokhov, Tomi Kinnunen, Ville Vestman, Kong Aik Lee", "title": "Extrapolating false alarm rates in automatic speaker verification", "comments": "Accepted for publication to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification (ASV) vendors and corpus providers would both\nbenefit from tools to reliably extrapolate performance metrics for large\nspeaker populations without collecting new speakers. We address false alarm\nrate extrapolation under a worst-case model whereby an adversary identifies the\nclosest impostor for a given target speaker from a large population. Our models\nare generative and allow sampling new speakers. The models are formulated in\nthe ASV detection score space to facilitate analysis of arbitrary ASV systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 20:31:57 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sholokhov", "Alexey", ""], ["Kinnunen", "Tomi", ""], ["Vestman", "Ville", ""], ["Lee", "Kong Aik", ""]]}, {"id": "2008.03600", "submitter": "Andrii Babii", "authors": "Andrii Babii and Ryan T. Ball and Eric Ghysels and Jonas Striaukas", "title": "Machine Learning Panel Data Regressions with an Application to\n  Nowcasting Price Earnings Ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces structured machine learning regressions for prediction\nand nowcasting with panel data consisting of series sampled at different\nfrequencies. Motivated by the empirical problem of predicting corporate\nearnings for a large cross-section of firms with macroeconomic, financial, and\nnews time series sampled at different frequencies, we focus on the sparse-group\nLASSO regularization. This type of regularization can take advantage of the\nmixed frequency time series panel data structures and we find that it\nempirically outperforms the unstructured machine learning methods. We obtain\noracle inequalities for the pooled and fixed effects sparse-group LASSO panel\ndata estimators recognizing that financial and economic data exhibit heavier\nthan Gaussian tails. To that end, we leverage on a novel Fuk-Nagaev\nconcentration inequality for panel data consisting of heavy-tailed\n$\\tau$-mixing processes which may be of independent interest in other\nhigh-dimensional panel data settings.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 21:12:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Babii", "Andrii", ""], ["Ball", "Ryan T.", ""], ["Ghysels", "Eric", ""], ["Striaukas", "Jonas", ""]]}, {"id": "2008.03606", "submitter": "Sai Praneeth Karimireddy", "authors": "Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri,\n  Sashank J. Reddi, Sebastian U. Stich, Ananda Theertha Suresh", "title": "Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning", "comments": "Version 2 provides stronger theoretical results and more thorough\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a challenging setting for optimization due to the\nheterogeneity of the data across different clients which gives rise to the\nclient drift phenomenon. In fact, obtaining an algorithm for FL which is\nuniformly better than simple centralized training has been a major open problem\nthus far. In this work, we propose a general algorithmic framework, Mime, which\ni) mitigates client drift and ii) adapts arbitrary centralized optimization\nalgorithms such as momentum and Adam to the cross-device federated learning\nsetting. Mime uses a combination of control-variates and server-level\nstatistics (e.g. momentum) at every client-update step to ensure that each\nlocal update mimics that of the centralized method run on iid data. We prove a\nreduction result showing that Mime can translate the convergence of a generic\nalgorithm in the centralized setting into convergence in the federated setting.\nFurther, we show that when combined with momentum based variance reduction,\nMime is provably faster than any centralized method--the first such result. We\nalso perform a thorough experimental exploration of Mime's performance on real\nworld datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 21:55:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 08:14:57 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""], ["Kale", "Satyen", ""], ["Mohri", "Mehryar", ""], ["Reddi", "Sashank J.", ""], ["Stich", "Sebastian U.", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2008.03626", "submitter": "Loc Tran H", "authors": "Loc Hoang Tran, Linh Hoang Tran", "title": "Directed hypergraph neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with irregular data structure, graph convolution neural networks have\nbeen developed by a lot of data scientists. However, data scientists just have\nconcentrated primarily on developing deep neural network method for un-directed\ngraph. In this paper, we will present the novel neural network method for\ndirected hypergraph. In the other words, we will develop not only the novel\ndirected hypergraph neural network method but also the novel directed\nhypergraph based semi-supervised learning method. These methods are employed to\nsolve the node classification task. The two datasets that are used in the\nexperiments are the cora and the citeseer datasets. Among the classic directed\ngraph based semi-supervised learning method, the novel directed hypergraph\nbased semi-supervised learning method, the novel directed hypergraph neural\nnetwork method that are utilized to solve this node classification task, we\nrecognize that the novel directed hypergraph neural network achieves the\nhighest accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 01:39:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tran", "Loc Hoang", ""], ["Tran", "Linh Hoang", ""]]}, {"id": "2008.03650", "submitter": "Khashayar Gatmiry", "authors": "Khashayar Gatmiry (1), Maryam Aliakbarpour (1), Stefanie Jegelka (1)\n  ((1) Massachusetts Institute of Technology)", "title": "Testing Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are popular probabilistic models of\ndiversity. In this paper, we investigate DPPs from a new perspective: property\ntesting of distributions. Given sample access to an unknown distribution $q$\nover the subsets of a ground set, we aim to distinguish whether $q$ is a DPP\ndistribution, or $\\epsilon$-far from all DPP distributions in\n$\\ell_1$-distance. In this work, we propose the first algorithm for testing\nDPPs. Furthermore, we establish a matching lower bound on the sample complexity\nof DPP testing. This lower bound also extends to showing a new hardness result\nfor the problem of testing the more general class of log-submodular\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:45:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gatmiry", "Khashayar", "", "Massachusetts Institute of Technology"], ["Aliakbarpour", "Maryam", "", "Massachusetts Institute of Technology"], ["Jegelka", "Stefanie", "", "Massachusetts Institute of Technology"]]}, {"id": "2008.03652", "submitter": "Tianxi Li", "authors": "Tianxi Li, Elizaveta Levina, Ji Zhu", "title": "Community models for networks observed through edge nominations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communities are a common and widely studied structure in networks, typically\nunder the assumption that the network is fully and correctly observed. In\npractice, network data are often collected by querying nodes about their\nconnections. In some settings, all edges of a sampled node will be recorded,\nand in others, a node may be asked to name its connections. These sampling\nmechanisms introduce noise and bias which can obscure the community structure\nand invalidate assumptions underlying standard community detection methods. We\npropose a general model for a class of network sampling mechanisms based on\nrecording edges via querying nodes, designed to improve community detection for\nnetwork data collected in this fashion. We model edge sampling probabilities as\na function of both individual preferences and community parameters, and show\ncommunity detection can be performed by spectral clustering under this general\nclass of models. We also propose, as a special case of the general framework, a\nparametric model for directed networks we call the nomination stochastic block\nmodel, which allows for meaningful parameter interpretations and can be fitted\nby the method of moments. Both spectral clustering and the method of moments in\nthis case are computationally efficient and come with theoretical guarantees of\nconsistency. We evaluate the proposed model in simulation studies on both\nunweighted and weighted networks and apply it to a faculty hiring dataset,\ndiscovering a meaningful hierarchy of communities among US business schools.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:53:13 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 03:25:11 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Li", "Tianxi", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "2008.03655", "submitter": "Tejas Bhojraj", "authors": "Lanston Hau Man Chu, Tejas Bhojraj, Rui Huang", "title": "Global Optimum Search in Quantum Deep Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to solve machine learning optimization problem by using\nquantum circuit. Two approaches, namely the average approach and the Partial\nSwap Test Cut-off method (PSTC) was proposed to search for the global\nminimum/maximum of two different objective functions. The current cost is\n$O(\\sqrt{|\\Theta|} N)$, but there is potential to improve PSTC further to\n$O(\\sqrt{|\\Theta|} \\cdot sublinear \\ N)$ by enhancing the checking process.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 05:01:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Chu", "Lanston Hau Man", ""], ["Bhojraj", "Tejas", ""], ["Huang", "Rui", ""]]}, {"id": "2008.03658", "submitter": "Nitin Rathi", "authors": "Nitin Rathi, Kaushik Roy", "title": "DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization\n  in Deep Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired spiking neural networks (SNNs), operating with asynchronous\nbinary signals (or spikes) distributed over time, can potentially lead to\ngreater computational efficiency on event-driven hardware. The state-of-the-art\nSNNs suffer from high inference latency, resulting from inefficient input\nencoding, and sub-optimal settings of the neuron parameters (firing threshold,\nand membrane leak). We propose DIET-SNN, a low-latency deep spiking network\nthat is trained with gradient descent to optimize the membrane leak and the\nfiring threshold along with other network parameters (weights). The membrane\nleak and threshold for each layer of the SNN are optimized with end-to-end\nbackpropagation to achieve competitive accuracy at reduced latency. The analog\npixel values of an image are directly applied to the input layer of DIET-SNN\nwithout the need to convert to spike-train. The first convolutional layer is\ntrained to convert inputs into spikes where leaky-integrate-and-fire (LIF)\nneurons integrate the weighted inputs and generate an output spike when the\nmembrane potential crosses the trained firing threshold. The trained membrane\nleak controls the flow of input information and attenuates irrelevant inputs to\nincrease the activation sparsity in the convolutional and dense layers of the\nnetwork. The reduced latency combined with high activation sparsity provides\nlarge improvements in computational efficiency. We evaluate DIET-SNN on image\nclassification tasks from CIFAR and ImageNet datasets on VGG and ResNet\narchitectures. We achieve top-1 accuracy of 69% with 5 timesteps (inference\nlatency) on the ImageNet dataset with 12x less compute energy than an\nequivalent standard ANN. Additionally, DIET-SNN performs 20-500x faster\ninference compared to other state-of-the-art SNN models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 05:07:17 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 23:14:39 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 02:55:31 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Rathi", "Nitin", ""], ["Roy", "Kaushik", ""]]}, {"id": "2008.03662", "submitter": "Anjin Liu", "authors": "Anjin Liu, Jie Lu, Guangquan Zhang", "title": "Concept Drift Detection: Dealing with MissingValues via Fuzzy Distance\n  Estimations", "comments": "Accepted by IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data streams, the data distribution of arriving observations at different\ntime points may change - a phenomenon called concept drift. While detecting\nconcept drift is a relatively mature area of study, solutions to the\nuncertainty introduced by observations with missing values have only been\nstudied in isolation. No one has yet explored whether or how these solutions\nmight impact drift detection performance. We, however, believe that data\nimputation methods may actually increase uncertainty in the data rather than\nreducing it. We also conjecture that imputation can introduce bias into the\nprocess of estimating distribution changes during drift detection, which can\nmake it more difficult to train a learning model. Our idea is to focus on\nestimating the distance between observations rather than estimating the missing\nvalues, and to define membership functions that allocate observations to\nhistogram bins according to the estimation errors. Our solution comprises a\nnovel masked distance learning (MDL) algorithm to reduce the cumulative errors\ncaused by iteratively estimating each missing value in an observation and a\nfuzzy-weighted frequency (FWF) method for identifying discrepancies in the data\ndistribution. The concept drift detection algorithm proposed in this paper is a\nsingular and unified algorithm that can handle missing values, but not an\nimputation algorithm combined with a concept drift detection algorithm.\nExperiments on both synthetic and real-world data sets demonstrate the\nadvantages of this method and show its robustness in detecting drift in data\nwith missing values. These findings reveal that missing values exert a profound\nimpact on concept drift detection, but using fuzzy set theory to model\nobservations can produce more reliable results than imputation.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 05:25:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Anjin", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2008.03703", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Chiyuan Zhang", "title": "What Neural Networks Memorize and Why: Discovering the Long Tail via\n  Influence Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms are well-known to have a propensity for fitting the\ntraining data very well and often fit even outliers and mislabeled data points.\nSuch fitting requires memorization of training data labels, a phenomenon that\nhas attracted significant research interest but has not been given a compelling\nexplanation so far. A recent work of Feldman (2019) proposes a theoretical\nexplanation for this phenomenon based on a combination of two insights. First,\nnatural image and data distributions are (informally) known to be long-tailed,\nthat is have a significant fraction of rare and atypical examples. Second, in a\nsimple theoretical model such memorization is necessary for achieving\nclose-to-optimal generalization error when the data distribution is\nlong-tailed. However, no direct empirical evidence for this explanation or even\nan approach for obtaining such evidence were given.\n  In this work we design experiments to test the key ideas in this theory. The\nexperiments require estimation of the influence of each training example on the\naccuracy at each test example as well as memorization values of training\nexamples. Estimating these quantities directly is computationally prohibitive\nbut we show that closely-related subsampled influence and memorization values\ncan be estimated much more efficiently. Our experiments demonstrate the\nsignificant benefits of memorization for generalization on several standard\nbenchmarks. They also provide quantitative and visually compelling evidence for\nthe theory put forth in (Feldman, 2019).\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 10:12:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Feldman", "Vitaly", ""], ["Zhang", "Chiyuan", ""]]}, {"id": "2008.03712", "submitter": "Liangyu Zhang", "authors": "Jiadong Liang, Liangyu Zhang, Cheng Zhang and Zhihua Zhang", "title": "Intervention Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach for stabilizing the training\nprocess of Generative Adversarial Networks as well as alleviating the mode\ncollapse problem. The main idea is to introduce a regularization term that we\ncall intervention loss into the objective. We refer to the resulting generative\nmodel as Intervention Generative Adversarial Networks (IVGAN). By perturbing\nthe latent representations of real images obtained from an auxiliary encoder\nnetwork with Gaussian invariant interventions and penalizing the dissimilarity\nof the distributions of the resulting generated images, the intervention loss\nprovides more informative gradient for the generator, significantly improving\nGAN's training stability. We demonstrate the effectiveness and efficiency of\nour methods via solid theoretical analysis and thorough evaluation on standard\nreal-world datasets as well as the stacked MNIST dataset.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 11:51:54 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liang", "Jiadong", ""], ["Zhang", "Liangyu", ""], ["Zhang", "Cheng", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2008.03776", "submitter": "Zhi Huang", "authors": "Zhi Huang, Paul Salama, Wei Shao, Jie Zhang, Kun Huang", "title": "Low-Rank Reorganization via Proportional Hazards Non-negative Matrix\n  Factorization Unveils Survival Associated Gene Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central goals in precision health is the understanding and\ninterpretation of high-dimensional biological data to identify genes and\nmarkers associated with disease initiation, development, and outcomes. Though\nsignificant effort has been committed to harness gene expression data for\nmultiple analyses while accounting for time-to-event modeling by including\nsurvival times, many traditional analyses have focused separately on\nnon-negative matrix factorization (NMF) of the gene expression data matrix and\nsurvival regression with Cox proportional hazards model. In this work, Cox\nproportional hazards regression is integrated with NMF by imposing survival\nconstraints. This is accomplished by jointly optimizing the Frobenius norm and\npartial log likelihood for events such as death or relapse. Simulation results\non synthetic data demonstrated the superiority of the proposed method, when\ncompared to other algorithms, in finding survival associated gene clusters. In\naddition, using human cancer gene expression data, the proposed technique can\nunravel critical clusters of cancer genes. The discovered gene clusters reflect\nrich biological implications and can help identify survival-related biomarkers.\nTowards the goal of precision health and cancer treatments, the proposed\nalgorithm can help understand and interpret high-dimensional heterogeneous\ngenomics data with accurate identification of survival-associated gene\nclusters.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 17:59:30 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 07:52:45 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Huang", "Zhi", ""], ["Salama", "Paul", ""], ["Shao", "Wei", ""], ["Zhang", "Jie", ""], ["Huang", "Kun", ""]]}, {"id": "2008.03813", "submitter": "Xudong Wang", "authors": "Xudong Wang, Ziwei Liu, Stella X. Yu", "title": "Unsupervised Feature Learning by Cross-Level Instance-Group\n  Discrimination", "comments": "Accepted at CVPR 2021; Project page:\n  http://people.eecs.berkeley.edu/~xdwang/projects/CLD/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised feature learning has made great strides with contrastive\nlearning based on instance discrimination and invariant mapping, as benchmarked\non curated class-balanced datasets. However, natural data could be highly\ncorrelated and long-tail distributed. Natural between-instance similarity\nconflicts with the presumed instance distinction, causing unstable training and\npoor performance.\n  Our idea is to discover and integrate between-instance similarity into\ncontrastive learning, not directly by instance grouping, but by cross-level\ndiscrimination (CLD) between instances and local instance groups. While\ninvariant mapping of each instance is imposed by attraction within its\naugmented views, between-instance similarity could emerge from common repulsion\nagainst instance groups.\n  Our batch-wise and cross-view comparisons also greatly improve the\npositive/negative sample ratio of contrastive learning and achieve better\ninvariant mapping. To effect both grouping and discrimination objectives, we\nimpose them on features separately derived from a shared representation. In\naddition, we propose normalized projection heads and unsupervised\nhyper-parameter tuning for the first time.\n  Our extensive experimentation demonstrates that CLD is a lean and powerful\nadd-on to existing methods such as NPID, MoCo, InfoMin, and BYOL on highly\ncorrelated, long-tail, or balanced datasets. It not only achieves new\nstate-of-the-art on self-supervision, semi-supervision, and transfer learning\nbenchmarks, but also beats MoCo v2 and SimCLR on every reported performance\nattained with a much larger compute. CLD effectively brings unsupervised\nlearning closer to natural data and real-world applications. Our code is\npublicly available at: https://github.com/frank-xwang/CLD-UnsupervisedLearning.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 21:13:13 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:00:23 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 08:16:51 GMT"}, {"version": "v4", "created": "Thu, 3 Dec 2020 06:43:35 GMT"}, {"version": "v5", "created": "Sun, 16 May 2021 03:11:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Xudong", ""], ["Liu", "Ziwei", ""], ["Yu", "Stella X.", ""]]}, {"id": "2008.03820", "submitter": "Pengsheng Ji", "authors": "Zhe Wang, Yingbin Liang and Pengsheng Ji", "title": "Spectral Algorithms for Community Detection in Directed Networks", "comments": "Journal of Machine Learning Research 2020, to appear", "journal-ref": "Journal of Machine Learning Research 2020. (153):1-45,", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection in large social networks is affected by degree\nheterogeneity of nodes. The D-SCORE algorithm for directed networks was\nintroduced to reduce this effect by taking the element-wise ratios of the\nsingular vectors of the adjacency matrix before clustering. Meaningful results\nwere obtained for the statistician citation network, but rigorous analysis on\nits performance was missing. First, this paper establishes theoretical\nguarantee for this algorithm and its variants for the directed degree-corrected\nblock model (Directed-DCBM). Second, this paper provides significant\nimprovements for the original D-SCORE algorithms by attaching the nodes outside\nof the community cores using the information of the original network instead of\nthe singular vectors.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 21:43:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Zhe", ""], ["Liang", "Yingbin", ""], ["Ji", "Pengsheng", ""]]}, {"id": "2008.03825", "submitter": "Manie Tadayon", "authors": "Manie Tadayon, Greg Pottie", "title": "Comparative Analysis of the Hidden Markov Model and LSTM: A Simulative\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series and sequential data have gained significant attention recently\nsince many real-world processes in various domains such as finance, education,\nbiology, and engineering can be modeled as time series. Although many\nalgorithms and methods such as the Kalman filter, hidden Markov model, and long\nshort term memory (LSTM) are proposed to make inferences and predictions for\nthe data, their usage significantly depends on the application, type of the\nproblem, available data, and sufficient accuracy or loss. In this paper, we\ncompare the supervised and unsupervised hidden Markov model to LSTM in terms of\nthe amount of data needed for training, complexity, and forecasting accuracy.\nMoreover, we propose various techniques to discretize the observations and\nconvert the problem to a discrete hidden Markov model under stationary and\nnon-stationary situations. Our results indicate that even an unsupervised\nhidden Markov model can outperform LSTM when a massive amount of labeled data\nis not available. Furthermore, we show that the hidden Markov model can still\nbe an effective method to process the sequence data even when the first-order\nMarkov assumption is not satisfied.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 22:13:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tadayon", "Manie", ""], ["Pottie", "Greg", ""]]}, {"id": "2008.03869", "submitter": "Hossein Estiri", "authors": "Hossein Estiri, Zachary H. Strasser, Shawn N. Murphy", "title": "Individualized Prediction of COVID-19 Adverse outcomes with MLHO", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-021-84781-x", "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed MLHO (pronounced as melo), an end-to-end Machine Learning\nframework that leverages iterative feature and algorithm selection to predict\nHealth Outcomes. MLHO implements iterative sequential representation mining,\nand feature and model selection, for predicting the patient-level risk of\nhospitalization, ICU admission, need for mechanical ventilation, and death. It\nbases this prediction on data from patients' past medical records (before their\nCOVID-19 infection). MLHO's architecture enables a parallel and\noutcome-oriented model calibration, in which different statistical learning\nalgorithms and vectors of features are simultaneously tested to improve the\nprediction of health outcomes. Using clinical and demographic data from a large\ncohort of over 13,000 COVID-19-positive patients, we modeled the four adverse\noutcomes utilizing about 600 features representing patients' pre-COVID health\nrecords and demographics. The mean AUC ROC for mortality prediction was 0.91,\nwhile the prediction performance ranged between 0.80 and 0.81 for the ICU,\nhospitalization, and ventilation. We broadly describe the clusters of features\nthat were utilized in modeling and their relative influence for predicting each\noutcome. Our results demonstrated that while demographic variables (namely age)\nare important predictors of adverse outcomes after a COVID-19 infection, the\nincorporation of the past clinical records are vital for a reliable prediction\nmodel. As the COVID-19 pandemic unfolds around the world, adaptable and\ninterpretable machine learning frameworks (like MLHO) are crucial to improve\nour readiness for confronting the potential future waves of COVID-19, as well\nas other novel infectious diseases that may emerge.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 02:44:52 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 14:55:52 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Estiri", "Hossein", ""], ["Strasser", "Zachary H.", ""], ["Murphy", "Shawn N.", ""]]}, {"id": "2008.03901", "submitter": "Fanghui Xue", "authors": "Fanghui Xue, Yingyong Qi, Jack Xin", "title": "RARTS: a Relaxed Architecture Search Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable architecture search (DARTS) is an effective method for\ndata-driven neural network design based on solving a bilevel optimization\nproblem. In this paper, we formulate a single level alternative and a relaxed\narchitecture search (RARTS) method that utilizes training and validation\ndatasets in architecture learning without involving mixed second derivatives of\nthe corresponding loss functions. Through weight/architecture variable\nsplitting and Gauss-Seidel iterations, the core algorithm outperforms DARTS\nsignificantly in accuracy and search efficiency, as shown in both a solvable\nmodel and CIFAR-10 based architecture search. Our model continues to\nout-perform DARTS upon transfer to ImageNet and is on par with recent variants\nof DARTS even though our innovation is purely on the training algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 04:55:51 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xue", "Fanghui", ""], ["Qi", "Yingyong", ""], ["Xin", "Jack", ""]]}, {"id": "2008.03911", "submitter": "Weijie Fu", "authors": "Meng Wang, Weijie Fu, Xiangnan He, Shijie Hao, Xindong Wu", "title": "A Survey on Large-scale Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can provide deep insights into data, allowing machines to\nmake high-quality predictions and having been widely used in real-world\napplications, such as text mining, visual classification, and recommender\nsystems. However, most sophisticated machine learning approaches suffer from\nhuge time costs when operating on large-scale data. This issue calls for the\nneed of {Large-scale Machine Learning} (LML), which aims to learn patterns from\nbig data with comparable performance efficiently. In this paper, we offer a\nsystematic survey on existing LML methods to provide a blueprint for the future\ndevelopments of this area. We first divide these LML methods according to the\nways of improving the scalability: 1) model simplification on computational\ncomplexities, 2) optimization approximation on computational efficiency, and 3)\ncomputation parallelism on computational capabilities. Then we categorize the\nmethods in each perspective according to their targeted scenarios and introduce\nrepresentative methods in line with intrinsic strategies. Lastly, we analyze\ntheir limitations and discuss potential directions as well as open issues that\nare promising to address in the future.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 06:07:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Meng", ""], ["Fu", "Weijie", ""], ["He", "Xiangnan", ""], ["Hao", "Shijie", ""], ["Wu", "Xindong", ""]]}, {"id": "2008.03920", "submitter": "Houman Owhadi", "authors": "Houman Owhadi", "title": "Do ideas have shape? Plato's theory of forms as the continuous limit of\n  artificial neural networks", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that ResNets converge, in the infinite depth limit, to a\ngeneralization of image registration algorithms. In this generalization, images\nare replaced by abstractions (ideas) living in high dimensional RKHS spaces,\nand material points are replaced by data points. Whereas computational anatomy\naligns images via deformations of the material space, this generalization\naligns ideas by via transformations of their RKHS. This identification of\nResNets as idea registration algorithms has several remarkable consequences.\nThe search for good architectures can be reduced to that of good kernels, and\nwe show that the composition of idea registration blocks with reduced\nequivariant multi-channel kernels (introduced here) recovers and generalizes\nCNNs to arbitrary spaces and groups of transformations. Minimizers of $L_2$\nregularized ResNets satisfy a discrete least action principle implying the near\npreservation of the norm of weights and biases across layers. The parameters of\ntrained ResNets can be identified as solutions of an autonomous Hamiltonian\nsystem defined by the activation function and the architecture of the ANN.\nMomenta variables provide a sparse representation of the parameters of a\nResNet. The registration regularization strategy provides a provably robust\nalternative to Dropout for ANNs. Pointwise RKHS error estimates lead to\ndeterministic error estimates for ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 06:46:43 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 15:55:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Owhadi", "Houman", ""]]}, {"id": "2008.03936", "submitter": "Moritz Firsching", "authors": "Thomas Fischbacher and Iulia M. Comsa and Krzysztof Potempa and Moritz\n  Firsching and Luca Versari and Jyrki Alakuijala", "title": "Intelligent Matrix Exponentiation", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel machine learning architecture that uses the exponential of\na single input-dependent matrix as its only nonlinearity. The mathematical\nsimplicity of this architecture allows a detailed analysis of its behaviour,\nproviding robustness guarantees via Lipschitz bounds. Despite its simplicity, a\nsingle matrix exponential layer already provides universal approximation\nproperties and can learn fundamental functions of the input, such as periodic\nfunctions or multivariate polynomials. This architecture outperforms other\ngeneral-purpose architectures on benchmark problems, including CIFAR-10, using\nsubstantially fewer parameters.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 07:49:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fischbacher", "Thomas", ""], ["Comsa", "Iulia M.", ""], ["Potempa", "Krzysztof", ""], ["Firsching", "Moritz", ""], ["Versari", "Luca", ""], ["Alakuijala", "Jyrki", ""]]}, {"id": "2008.03937", "submitter": "Matej Petkovi\\'c", "authors": "Matej Petkovi\\'c, Sa\\v{s}o D\\v{z}eroski, Dragi Kocev", "title": "Feature Ranking for Semi-supervised Learning", "comments": "Submitted to: Special Issue on Discovery Science of the Machine\n  Learning Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The data made available for analysis are becoming more and more complex along\nseveral directions: high dimensionality, number of examples and the amount of\nlabels per example. This poses a variety of challenges for the existing machine\nlearning methods: coping with dataset with a large number of examples that are\ndescribed in a high-dimensional space and not all examples have labels\nprovided. For example, when investigating the toxicity of chemical compounds\nthere are a lot of compounds available, that can be described with information\nrich high-dimensional representations, but not all of the compounds have\ninformation on their toxicity. To address these challenges, we propose\nsemi-supervised learning of feature ranking. The feature rankings are learned\nin the context of classification and regression as well as in the context of\nstructured output prediction (multi-label classification, hierarchical\nmulti-label classification and multi-target regression). To the best of our\nknowledge, this is the first work that treats the task of feature ranking\nwithin the semi-supervised structured output prediction context. More\nspecifically, we propose two approaches that are based on tree ensembles and\nthe Relief family of algorithms. The extensive evaluation across 38 benchmark\ndatasets reveals the following: Random Forests perform the best for the\nclassification-like tasks, while for the regression-like tasks Extra-PCTs\nperform the best, Random Forests are the most efficient method considering\ninduction times across all tasks, and semi-supervised feature rankings\noutperform their supervised counterpart across a majority of the datasets from\nthe different tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 07:50:50 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Petkovi\u0107", "Matej", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Kocev", "Dragi", ""]]}, {"id": "2008.03959", "submitter": "Nadav Merlis", "authors": "Nadav Merlis, Shie Mannor", "title": "Lenient Regret for Multi-Armed Bandits", "comments": "Accepted to AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Multi-Armed Bandit (MAB) problem, where an agent sequentially\nchooses actions and observes rewards for the actions it took. While the\nmajority of algorithms try to minimize the regret, i.e., the cumulative\ndifference between the reward of the best action and the agent's action, this\ncriterion might lead to undesirable results. For example, in large problems, or\nwhen the interaction with the environment is brief, finding an optimal arm is\ninfeasible, and regret-minimizing algorithms tend to over-explore. To overcome\nthis issue, algorithms for such settings should instead focus on playing\nnear-optimal arms. To this end, we suggest a new, more lenient, regret\ncriterion that ignores suboptimality gaps smaller than some $\\epsilon$. We then\npresent a variant of the Thompson Sampling (TS) algorithm, called\n$\\epsilon$-TS, and prove its asymptotic optimality in terms of the lenient\nregret. Importantly, we show that when the mean of the optimal arm is high\nenough, the lenient regret of $\\epsilon$-TS is bounded by a constant. Finally,\nwe show that $\\epsilon$-TS can be applied to improve the performance when the\nagent knows a lower bound of the suboptimality gaps.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:30:52 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 07:45:54 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 13:15:49 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "2008.03961", "submitter": "Yexu Zhou", "authors": "Yexu Zhou, Yuting Gao, Yiran Huang, Michael Hefenbrock, Till Riedel,\n  and Michael Beigl", "title": "Automatic Remaining Useful Life Estimation Framework with Embedded\n  Convolutional LSTM as the Backbone", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential task in predictive maintenance is the prediction of the\nRemaining Useful Life (RUL) through the analysis of multivariate time series.\nUsing the sliding window method, Convolutional Neural Network (CNN) and\nconventional Recurrent Neural Network (RNN) approaches have produced impressive\nresults on this matter, due to their ability to learn optimized features.\nHowever, sequence information is only partially modeled by CNN approaches. Due\nto the flatten mechanism in conventional RNNs, like Long Short Term Memories\n(LSTM), the temporal information within the window is not fully preserved. To\nexploit the multi-level temporal information, many approaches are proposed\nwhich combine CNN and RNN models. In this work, we propose a new LSTM variant\ncalled embedded convolutional LSTM (ECLSTM). In ECLSTM a group of different 1D\nconvolutions is embedded into the LSTM structure. Through this, the temporal\ninformation is preserved between and within windows. Since the hyper-parameters\nof models require careful tuning, we also propose an automated prediction\nframework based on the Bayesian optimization with hyperband optimizer, which\nallows for efficient optimization of the network architecture. Finally, we show\nthe superiority of our proposed ECLSTM approach over the state-of-the-art\napproaches on several widely used benchmark data sets for RUL Estimation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:34:20 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhou", "Yexu", ""], ["Gao", "Yuting", ""], ["Huang", "Yiran", ""], ["Hefenbrock", "Michael", ""], ["Riedel", "Till", ""], ["Beigl", "Michael", ""]]}, {"id": "2008.04042", "submitter": "Ahmed Frikha", "authors": "Ahmed Frikha, Denis Krompa{\\ss} and Volker Tresp", "title": "ARCADe: A Rapid Continual Anomaly Detector", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although continual learning and anomaly detection have separately been\nwell-studied in previous works, their intersection remains rather unexplored.\nThe present work addresses a learning scenario where a model has to\nincrementally learn a sequence of anomaly detection tasks, i.e. tasks from\nwhich only examples from the normal (majority) class are available for\ntraining. We define this novel learning problem of continual anomaly detection\n(CAD) and formulate it as a meta-learning problem. Moreover, we propose A Rapid\nContinual Anomaly Detector (ARCADe), an approach to train neural networks to be\nrobust against the major challenges of this new learning problem, namely\ncatastrophic forgetting and overfitting to the majority class. The results of\nour experiments on three datasets show that, in the CAD problem setting, ARCADe\nsubstantially outperforms baselines from the continual learning and anomaly\ndetection literature. Finally, we provide deeper insights into the learning\nstrategy yielded by the proposed meta-learning algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 11:59:32 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 17:34:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Frikha", "Ahmed", ""], ["Krompa\u00df", "Denis", ""], ["Tresp", "Volker", ""]]}, {"id": "2008.04059", "submitter": "Jie Chen", "authors": "Linwei Hu, Jie Chen, Joel Vaughan, Hanyu Yang, Kelly Wang, Agus\n  Sudjianto, Vijayan N. Nair", "title": "Supervised Machine Learning Techniques: An Overview with Applications to\n  Banking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an overview of Supervised Machine Learning (SML) with a\nfocus on applications to banking. The SML techniques covered include Bagging\n(Random Forest or RF), Boosting (Gradient Boosting Machine or GBM) and Neural\nNetworks (NNs). We begin with an introduction to ML tasks and techniques. This\nis followed by a description of: i) tree-based ensemble algorithms including\nBagging with RF and Boosting with GBMs, ii) Feedforward NNs, iii) a discussion\nof hyper-parameter optimization techniques, and iv) machine learning\ninterpretability. The paper concludes with a comparison of the features of\ndifferent ML algorithms. Examples taken from credit risk modeling in banking\nare used throughout the paper to illustrate the techniques and interpret the\nresults of the algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 23:39:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hu", "Linwei", ""], ["Chen", "Jie", ""], ["Vaughan", "Joel", ""], ["Yang", "Hanyu", ""], ["Wang", "Kelly", ""], ["Sudjianto", "Agus", ""], ["Nair", "Vijayan N.", ""]]}, {"id": "2008.04063", "submitter": "Yanbo Xu", "authors": "Shenda Hong, Yanbo Xu, Alind Khare, Satria Priambada, Kevin Maher,\n  Alaa Aljiffry, Jimeng Sun and Alexey Tumanov", "title": "HOLMES: Health OnLine Model Ensemble Serving for Deep Learning Models in\n  Intensive Care Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved expert-level performance in healthcare\nwith an exclusive focus on training accurate models. However, in many clinical\nenvironments such as intensive care unit (ICU), real-time model serving is\nequally if not more important than accuracy, because in ICU patient care is\nsimultaneously more urgent and more expensive. Clinical decisions and their\ntimeliness, therefore, directly affect both the patient outcome and the cost of\ncare. To make timely decisions, we argue the underlying serving system must be\nlatency-aware. To compound the challenge, health analytic applications often\nrequire a combination of models instead of a single model, to better specialize\nindividual models for different targets, multi-modal data, different prediction\nwindows, and potentially personalized predictions. To address these challenges,\nwe propose HOLMES-an online model ensemble serving framework for healthcare\napplications. HOLMES dynamically identifies the best performing set of models\nto ensemble for highest accuracy, while also satisfying sub-second latency\nconstraints on end-to-end prediction. We demonstrate that HOLMES is able to\nnavigate the accuracy/latency tradeoff efficiently, compose the ensemble, and\nserve the model ensemble pipeline, scaling to simultaneously streaming data\nfrom 100 patients, each producing waveform data at 250~Hz. HOLMES outperforms\nthe conventional offline batch-processed inference for the same clinical task\nin terms of accuracy and latency (by order of magnitude). HOLMES is tested on\nrisk prediction task on pediatric cardio ICU data with above 95% prediction\naccuracy and sub-second latency on 64-bed simulation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 12:38:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hong", "Shenda", ""], ["Xu", "Yanbo", ""], ["Khare", "Alind", ""], ["Priambada", "Satria", ""], ["Maher", "Kevin", ""], ["Aljiffry", "Alaa", ""], ["Sun", "Jimeng", ""], ["Tumanov", "Alexey", ""]]}, {"id": "2008.04068", "submitter": "Param Vir Singh", "authors": "Runshan Fu, Yan Huang and Param Vir Singh", "title": "Crowd, Lending, Machine, and Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data and machine learning (ML) algorithms are key drivers of many fintech\ninnovations. While it may be obvious that replacing humans with machine would\nincrease efficiency, it is not clear whether and where machines can make better\ndecisions than humans. We answer this question in the context of crowd lending,\nwhere decisions are traditionally made by a crowd of investors. Using data from\nProsper.com, we show that a reasonably sophisticated ML algorithm predicts\nlisting default probability more accurately than crowd investors. The dominance\nof the machine over the crowd is more pronounced for highly risky listings. We\nthen use the machine to make investment decisions, and find that the machine\nbenefits not only the lenders but also the borrowers. When machine prediction\nis used to select loans, it leads to a higher rate of return for investors and\nmore funding opportunities for borrowers with few alternative funding options.\nWe also find suggestive evidence that the machine is biased in gender and race\neven when it does not use gender and race information as input. We propose a\ngeneral and effective \"debasing\" method that can be applied to any prediction\nfocused ML applications, and demonstrate its use in our context. We show that\nthe debiased ML algorithm, which suffers from lower prediction accuracy, still\nleads to better investment decisions compared with the crowd. These results\nindicate that ML can help crowd lending platforms better fulfill the promise of\nproviding access to financial resources to otherwise underserved individuals\nand ensure fairness in the allocation of these resources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 01:26:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fu", "Runshan", ""], ["Huang", "Yan", ""], ["Singh", "Param Vir", ""]]}, {"id": "2008.04101", "submitter": "Rishabh Dudeja", "authors": "Rishabh Dudeja and Daniel Hsu", "title": "Statistical Query Lower Bounds for Tensor PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Tensor PCA problem introduced by Richard and Montanari (2014), one is\ngiven a dataset consisting of $n$ samples $\\mathbf{T}_{1:n}$ of i.i.d. Gaussian\ntensors of order $k$ with the promise that $\\mathbb{E}\\mathbf{T}_1$ is a rank-1\ntensor and $\\|\\mathbb{E} \\mathbf{T}_1\\| = 1$. The goal is to estimate\n$\\mathbb{E} \\mathbf{T}_1$. This problem exhibits a large conjectured hard phase\nwhen $k>2$: When $d \\lesssim n \\ll d^{\\frac{k}{2}}$ it is information\ntheoretically possible to estimate $\\mathbb{E} \\mathbf{T}_1$, but no polynomial\ntime estimator is known. We provide a sharp analysis of the optimal sample\ncomplexity in the Statistical Query (SQ) model and show that SQ algorithms with\npolynomial query complexity not only fail to solve Tensor PCA in the\nconjectured hard phase, but also have a strictly sub-optimal sample complexity\ncompared to some polynomial time estimators such as the Richard-Montanari\nspectral estimator. Our analysis reveals that the optimal sample complexity in\nthe SQ model depends on whether $\\mathbb{E} \\mathbf{T}_1$ is symmetric or not.\nFor symmetric, even order tensors, we also isolate a sample size regime in\nwhich it is possible to test if $\\mathbb{E} \\mathbf{T}_1 = \\mathbf{0}$ or\n$\\mathbb{E}\\mathbf{T}_1 \\neq \\mathbf{0}$ with polynomially many queries but not\nestimate $\\mathbb{E}\\mathbf{T}_1$. Our proofs rely on the Fourier analytic\napproach of Feldman, Perkins and Vempala (2018) to prove sharp SQ lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:14:34 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 19:00:15 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dudeja", "Rishabh", ""], ["Hsu", "Daniel", ""]]}, {"id": "2008.04103", "submitter": "Kamal Berahmand", "authors": "Mehrdad Rostami, Kamal Berahmand, Saman Forouzandeh", "title": "Review of Swarm Intelligence-based Feature Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the past decades, the rapid growth of computer and database technologies\nhas led to the rapid growth of large-scale datasets. On the other hand, data\nmining applications with high dimensional datasets that require high speed and\naccuracy are rapidly increasing. An important issue with these applications is\nthe curse of dimensionality, where the number of features is much higher than\nthe number of patterns. One of the dimensionality reduction approaches is\nfeature selection that can increase the accuracy of the data mining task and\nreduce its computational complexity. The feature selection method aims at\nselecting a subset of features with the lowest inner similarity and highest\nrelevancy to the target class. It reduces the dimensionality of the data by\neliminating irrelevant, redundant, or noisy data. In this paper, a comparative\nanalysis of different feature selection methods is presented, and a general\ncategorization of these methods is performed. Moreover, in this paper,\nstate-of-the-art swarm intelligence are studied, and the recent feature\nselection methods based on these algorithms are reviewed. Furthermore, the\nstrengths and weaknesses of the different studied swarm intelligence-based\nfeature selection methods are evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 05:18:58 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""], ["Forouzandeh", "Saman", ""]]}, {"id": "2008.04109", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz and Ghulam Mohiuddin Bhat", "title": "Deep Q-Network Based Multi-agent Reinforcement Learning with Binary\n  Action Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Network (DQN) based multi-agent systems (MAS) for reinforcement\nlearning (RL) use various schemes where in the agents have to learn and\ncommunicate. The learning is however specific to each agent and communication\nmay be satisfactorily designed for the agents. As more complex Deep QNetworks\ncome to the fore, the overall complexity of the multi-agent system increases\nleading to issues like difficulty in training, need for higher resources and\nmore training time, difficulty in fine-tuning, etc. To address these issues we\npropose a simple but efficient DQN based MAS for RL which uses shared state and\nrewards, but agent-specific actions, for updation of the experience replay pool\nof the DQNs, where each agent is a DQN. The benefits of the approach are\noverall simplicity, faster convergence and better performance as compared to\nconventional DQN based approaches. It should be noted that the method can be\nextended to any DQN. As such we use simple DQN and DDQN (Double Q-learning)\nrespectively on three separate tasks i.e. Cartpole-v1 (OpenAI Gym environment)\n, LunarLander-v2 (OpenAI Gym environment) and Maze Traversal (customized\nenvironment). The proposed approach outperforms the baseline on these tasks by\ndecent margins respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:16:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Bhat", "Ghulam Mohiuddin", ""]]}, {"id": "2008.04137", "submitter": "Abhishek Singh", "authors": "Iker Ceballos, Vivek Sharma, Eduardo Mugica, Abhishek Singh, Alberto\n  Roman, Praneeth Vepakomma, Ramesh Raskar", "title": "SplitNN-driven Vertical Partitioning", "comments": "First version, please provide feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce SplitNN-driven Vertical Partitioning, a\nconfiguration of a distributed deep learning method called SplitNN to\nfacilitate learning from vertically distributed features. SplitNN does not\nshare raw data or model details with collaborating institutions. The proposed\nconfiguration allows training among institutions holding diverse sources of\ndata without the need of complex encryption algorithms or secure computation\nprotocols. We evaluate several configurations to merge the outputs of the split\nmodels, and compare performance and resource efficiency. The method is flexible\nand allows many different configurations to tackle the specific challenges\nposed by vertically split datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:41:42 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ceballos", "Iker", ""], ["Sharma", "Vivek", ""], ["Mugica", "Eduardo", ""], ["Singh", "Abhishek", ""], ["Roman", "Alberto", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2008.04175", "submitter": "Jonas Rauber", "authors": "Jonas Rauber, Matthias Bethge, Wieland Brendel", "title": "EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX,\n  and NumPy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EagerPy is a Python framework that lets you write code that automatically\nworks natively with PyTorch, TensorFlow, JAX, and NumPy. Library developers no\nlonger need to choose between supporting just one of these frameworks or\nreimplementing the library for each framework and dealing with code\nduplication. Users of such libraries can more easily switch frameworks without\nbeing locked in by a specific 3rd party library. Beyond multi-framework\nsupport, EagerPy also brings comprehensive type annotations and consistent\nsupport for method chaining to any framework. The latest documentation is\navailable online at https://eagerpy.jonasrauber.de and the code can be found on\nGitHub at https://github.com/jonasrauber/eagerpy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:57:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rauber", "Jonas", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "2008.04195", "submitter": "Usman Khan", "authors": "Ran Xin, Usman A. Khan, and Soummya Kar", "title": "An improved convergence analysis for decentralized online stochastic\n  non-convex optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3062553", "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study decentralized online stochastic non-convex\noptimization over a network of nodes. Integrating a technique called gradient\ntracking in decentralized stochastic gradient descent, we show that the\nresulting algorithm, GT-DSGD, enjoys certain desirable characteristics towards\nminimizing a sum of smooth non-convex functions. In particular, for general\nsmooth non-convex functions, we establish non-asymptotic characterizations of\nGT-DSGD and derive the conditions under which it achieves network-independent\nperformances that match the centralized minibatch SGD. In contrast, the\nexisting results suggest that GT-DSGD is always network-dependent and is\ntherefore strictly worse than the centralized minibatch SGD. When the global\nnon-convex function additionally satisfies the Polyak-Lojasiewics (PL)\ncondition, we establish the linear convergence of GT-DSGD up to a steady-state\nerror with appropriate constant step-sizes. Moreover, under stochastic\napproximation step-sizes, we establish, for the first time, the optimal global\nsublinear convergence rate on almost every sample path, in addition to the\nasymptotically optimal sublinear rate in expectation. Since strongly convex\nfunctions are a special case of the functions satisfying the PL condition, our\nresults are not only immediately applicable but also improve the currently\nknown best convergence rates and their dependence on problem parameters.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:29:13 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:20:10 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.04216", "submitter": "Issa Annamoradnejad", "authors": "Jafar Habibi, Amir Fazelinia, Issa Annamoradnejad", "title": "Using Experts' Opinions in Machine Learning Tasks", "comments": "6 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In machine learning tasks, especially in the tasks of prediction, scientists\ntend to rely solely on available historical data and disregard unproven\ninsights, such as experts' opinions, polls, and betting odds. In this paper, we\npropose a general three-step framework for utilizing experts' insights in\nmachine learning tasks and build four concrete models for a sports game\nprediction case study. For the case study, we have chosen the task of\npredicting NCAA Men's Basketball games, which has been the focus of a group of\nKaggle competitions in recent years. Results highly suggest that the good\nperformance and high scores of the past models are a result of chance, and not\nbecause of a good-performing and stable model. Furthermore, our proposed models\ncan achieve more steady results with lower log loss average (best at 0.489)\ncompared to the top solutions of the 2019 competition (>0.503), and reach the\ntop 1%, 10% and 1% in the 2017, 2018 and 2019 leaderboards, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:48:49 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 10:44:40 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Habibi", "Jafar", ""], ["Fazelinia", "Amir", ""], ["Annamoradnejad", "Issa", ""]]}, {"id": "2008.04254", "submitter": "Baifeng Shi", "authors": "Baifeng Shi, Dinghuai Zhang, Qi Dai, Zhanxing Zhu, Yadong Mu, Jingdong\n  Wang", "title": "Informative Dropout for Robust Representation Learning: A Shape-bias\n  Perspective", "comments": "Accepted to ICML2020. Code is available at\n  https://github.com/bfshi/InfoDrop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are known to rely more on local texture\nrather than global shape when making decisions. Recent work also indicates a\nclose relationship between CNN's texture-bias and its robustness against\ndistribution shift, adversarial perturbation, random corruption, etc. In this\nwork, we attempt at improving various kinds of robustness universally by\nalleviating CNN's texture bias. With inspiration from the human visual system,\nwe propose a light-weight model-agnostic method, namely Informative Dropout\n(InfoDrop), to improve interpretability and reduce texture bias. Specifically,\nwe discriminate texture from shape based on local self-information in an image,\nand adopt a Dropout-like algorithm to decorrelate the model output from the\nlocal texture. Through extensive experiments, we observe enhanced robustness\nunder various scenarios (domain generalization, few-shot classification, image\ncorruption, and adversarial perturbation). To the best of our knowledge, this\nwork is one of the earliest attempts to improve different kinds of robustness\nin a unified model, shedding new light on the relationship between shape-bias\nand robustness, also on new approaches to trustworthy machine learning\nalgorithms. Code is available at https://github.com/bfshi/InfoDrop.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 16:52:24 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shi", "Baifeng", ""], ["Zhang", "Dinghuai", ""], ["Dai", "Qi", ""], ["Zhu", "Zhanxing", ""], ["Mu", "Yadong", ""], ["Wang", "Jingdong", ""]]}, {"id": "2008.04267", "submitter": "Suyash Gupta", "authors": "Maxime Cauchois, Suyash Gupta, Alnur Ali and John C. Duchi", "title": "Robust Validation: Confident Predictions Even When Distributions Shift", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the traditional viewpoint in machine learning and statistics assumes\ntraining and testing samples come from the same population, practice belies\nthis fiction. One strategy---coming from robust statistics and\noptimization---is thus to build a model robust to distributional perturbations.\nIn this paper, we take a different approach to describe procedures for robust\npredictive inference, where a model provides uncertainty estimates on its\npredictions rather than point predictions. We present a method that produces\nprediction sets (almost exactly) giving the right coverage level for any test\ndistribution in an $f$-divergence ball around the training population. The\nmethod, based on conformal inference, achieves (nearly) valid coverage in\nfinite samples, under only the condition that the training data be\nexchangeable. An essential component of our methodology is to estimate the\namount of expected future data shift and build robustness to it; we develop\nestimators and prove their consistency for protection and validity of\nuncertainty estimates under shifts. By experimenting on several large-scale\nbenchmark datasets, including Recht et al.'s CIFAR-v4 and ImageNet-V2 datasets,\nwe provide complementary empirical results that highlight the importance of\nrobust predictive validity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:09:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Cauchois", "Maxime", ""], ["Gupta", "Suyash", ""], ["Ali", "Alnur", ""], ["Duchi", "John C.", ""]]}, {"id": "2008.04278", "submitter": "Dustin Mixon", "authors": "Jameson Cahill, Dustin G. Mixon, Hans Parshall", "title": "Lie PCA: Density estimation for symmetric manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension to local principal component analysis for learning\nsymmetric manifolds. In particular, we use a spectral method to approximate the\nLie algebra corresponding to the symmetry group of the underlying manifold. We\nderive the sample complexity of our method for a variety of manifolds before\napplying it to various data sets for improved density estimation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:19:57 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 20:15:39 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Cahill", "Jameson", ""], ["Mixon", "Dustin G.", ""], ["Parshall", "Hans", ""]]}, {"id": "2008.04295", "submitter": "Henry Wilde", "authors": "Henry Wilde and Vincent Knight and Jonathan Gillard and Kendal Smith", "title": "Segmentation analysis and the recovery of queuing parameters via the\n  Wasserstein distance: a study of administrative data for patients with\n  chronic obstructive pulmonary disease", "comments": "24 pages, 11 figures (19 including subfigures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work uses a data-driven approach to analyse how the resource\nrequirements of patients with chronic obstructive pulmonary disease (COPD) may\nchange, quantifying how those changes impact the hospital system with which the\npatients interact. This approach is composed of a novel combination of often\ndistinct modes of analysis: segmentation, operational queuing theory, and the\nrecovery of parameters from incomplete data. By combining these methods as\npresented here, this work demonstrates that potential limitations around the\navailability of fine-grained data can be overcome. Thus, finding useful\noperational results despite using only administrative data. The paper begins by\nfinding a useful clustering of the population from this granular data that\nfeeds into a multi-class M/M/c model, whose parameters are recovered from the\ndata via parameterisation and the Wasserstein distance. This model is then used\nto conduct an informative analysis of the underlying queuing system and the\nneeds of the population under study through several what-if scenarios. The\nanalyses used to form and study this model consider, in effect, all types of\npatient arrivals and how those types impact the system. With that, this study\nfinds that there are no quick solutions to reduce the impact of COPD patients\non the system, including adding capacity to the system. In this analysis, the\nonly effective intervention to reduce the strain caused by those presenting\nwith COPD is to enact external policies which directly improve the overall\nhealth of the COPD population before they arrive at the hospital.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:47:34 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 17:15:00 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 11:43:00 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Wilde", "Henry", ""], ["Knight", "Vincent", ""], ["Gillard", "Jonathan", ""], ["Smith", "Kendal", ""]]}, {"id": "2008.04387", "submitter": "Karthik Devarajan", "authors": "Majid Asadi, Karthik Devarajan, Nader Ebrahimi, Ehsan Soofi, Lauren\n  Spirko-Burns", "title": "Probability Link Models with Symmetric Information Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces link functions for transforming one probability\ndistribution to another such that the Kullback-Leibler and R\\'enyi divergences\nbetween the two distributions are symmetric. Two general classes of link models\nare proposed. The first model links two survival functions and is applicable to\nmodels such as the proportional odds and change point, which are used in\nsurvival analysis and reliability modeling. A prototype application involving\nthe proportional odds model demonstrates advantages of symmetric divergence\nmeasures over asymmetric measures for assessing the efficacy of features and\nfor model averaging purposes. The advantages include providing unique ranks for\nmodels and unique information weights for model averaging with one-half as much\ncomputation requirement of asymmetric divergences. The second model links two\ncumulative probability distribution functions. This model produces a\ngeneralized location model which are continuous counterparts of the binary\nprobability models such as probit and logit models. Examples include the\ngeneralized probit and logit models which have appeared in the survival\nanalysis literature, and a generalized Laplace model and a generalized\nStudent-$t$ model, which are survival time models corresponding to the\nrespective binary probability models. Lastly, extensions to symmetric\ndivergence between survival functions and conditions for copula dependence\ninformation are presented.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:49:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Asadi", "Majid", ""], ["Devarajan", "Karthik", ""], ["Ebrahimi", "Nader", ""], ["Soofi", "Ehsan", ""], ["Spirko-Burns", "Lauren", ""]]}, {"id": "2008.04388", "submitter": "Grgur Kova\\v{c}", "authors": "Grgur Kova\\v{c}, Adrien Laversanne-Finot, Pierre-Yves Oudeyer", "title": "GRIMGEP: Learning Progress for Robust Goal Sampling in Visual Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agents, capable of learning autonomously a wide range of skills is\ncritical in order to increase the scope of reinforcement learning. It will both\nincrease the diversity of learned skills and reduce the burden of manually\ndesigning reward functions for each skill. Self-supervised agents, setting\ntheir own goals, and trying to maximize the diversity of those goals have shown\ngreat promise towards this end. However, a currently known limitation of agents\ntrying to maximize the diversity of sampled goals is that they tend to get\nattracted to noise or more generally to parts of the environments that cannot\nbe controlled (distractors). When agents have access to predefined goal\nfeatures or expert knowledge, absolute Learning Progress (ALP) provides a way\nto distinguish between regions that can be controlled and those that cannot.\nHowever, those methods often fall short when the agents are only provided with\nraw sensory inputs such as images. In this work we extend those concepts to\nunsupervised image-based goal exploration. We propose a framework that allows\nagents to autonomously identify and ignore noisy distracting regions while\nsearching for novelty in the learnable regions to both improve overall\nperformance and avoid catastrophic forgetting. Our framework can be combined\nwith any state-of-the-art novelty seeking goal exploration approaches. We\nconstruct a rich 3D image based environment with distractors. Experiments on\nthis environment show that agents using our framework successfully identify\ninteresting regions of the environment, resulting in drastically improved\nperformances. The source code is available at\nhttps://sites.google.com/view/grimgep.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:50:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 11:54:09 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kova\u010d", "Grgur", ""], ["Laversanne-Finot", "Adrien", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2008.04391", "submitter": "Guillaume Alain", "authors": "Guillaume Alain, Maxime Chevalier-Boisvert, Frederic Osterrath, Remi\n  Piche-Taillefer", "title": "DeepDrummer : Generating Drum Loops using Deep Learning and a Human in\n  the Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepDrummer is a drum loop generation tool that uses active learning to learn\nthe preferences (or current artistic intentions) of a human user from a small\nnumber of interactions. The principal goal of this tool is to enable an\nefficient exploration of new musical ideas. We train a deep neural network\nclassifier on audio data and show how it can be used as the core component of a\nsystem that generates drum loops based on few prior beliefs as to how these\nloops should be structured.\n  We aim to build a system that can converge to meaningful results even with a\nlimited number of interactions with the user. This property enables our method\nto be used from a cold start situation (no pre-existing dataset), or starting\nfrom a collection of audio samples provided by the user. In a proof of concept\nstudy with 25 participants, we empirically demonstrate that DeepDrummer is able\nto converge towards the preference of our subjects after a small number of\ninteractions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:04:15 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 21:09:23 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Alain", "Guillaume", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Osterrath", "Frederic", ""], ["Piche-Taillefer", "Remi", ""]]}, {"id": "2008.04443", "submitter": "Olivier Binette", "authors": "Olivier Binette and Rebecca C. Steorts", "title": "(Almost) All of Entity Resolution", "comments": "53 pages, includes supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether the goal is to estimate the number of people that live in a\ncongressional district, to estimate the number of individuals that have died in\nan armed conflict, or to disambiguate individual authors using bibliographic\ndata, all these applications have a common theme - integrating information from\nmultiple sources. Before such questions can be answered, databases must be\ncleaned and integrated in a systematic and accurate way, commonly known as\nrecord linkage, de-duplication, or entity resolution. In this article, we\nreview motivational applications and seminal papers that have led to the growth\nof this area. Specifically, we review the foundational work that began in the\n1940's and 50's that have led to modern probabilistic record linkage. We review\nclustering approaches to entity resolution, semi- and fully supervised methods,\nand canonicalization, which are being used throughout industry and academia in\napplications such as human rights, official statistics, medicine, citation\nnetworks, among others. Finally, we discuss current research topics of\npractical importance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 22:41:20 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Binette", "Olivier", ""], ["Steorts", "Rebecca C.", ""]]}, {"id": "2008.04448", "submitter": "Athar Kharal", "authors": "Athar Kharal", "title": "Explainable Artificial Intelligence Based Fault Diagnosis and Insight\n  Harvesting for Steel Plates Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Industry 4.0, Data Science and Explainable Artificial\nIntelligence (XAI) has received considerable intrest in recent literature.\nHowever, the entry threshold into XAI, in terms of computer coding and the\nrequisite mathematical apparatus, is really high. For fault diagnosis of steel\nplates, this work reports on a methodology of incorporating XAI based insights\ninto the Data Science process of development of high precision classifier.\nUsing Synthetic Minority Oversampling Technique (SMOTE) and notion of medoids,\ninsights from XAI tools viz. Ceteris Peribus profiles, Partial Dependence and\nBreakdown profiles have been harvested. Additionally, insights in the form of\nIF-THEN rules have also been extracted from an optimized Random Forest and\nAssociation Rule Mining. Incorporating all the insights into a single ensemble\nclassifier, a 10 fold cross validated performance of 94% has been achieved. In\nsum total, this work makes three main contributions viz.: methodology based\nupon utilization of medoids and SMOTE, of gleaning insights and incorporating\ninto model development process. Secondly the insights themselves are\ncontribution, as they benefit the human experts of steel manufacturing\nindustry, and thirdly a high precision fault diagnosis classifier has been\ndeveloped.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:04:21 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kharal", "Athar", ""]]}, {"id": "2008.04470", "submitter": "M. Umut Isik", "authors": "Umut Isik, Ritwik Giri, Neerad Phansalkar, Jean-Marc Valin, Karim\n  Helwani, Arvindh Krishnaswamy", "title": "PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings,\n  Semi-Supervised Conversational Data, and Biased Loss", "comments": "5 pages, 3 figures, INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network applications generally benefit from larger-sized models, but\nfor current speech enhancement models, larger scale networks often suffer from\ndecreased robustness to the variety of real-world use cases beyond what is\nencountered in training data. We introduce several innovations that lead to\nbetter large neural networks for speech enhancement. The novel PoCoNet\narchitecture is a convolutional neural network that, with the use of\nfrequency-positional embeddings, is able to more efficiently build\nfrequency-dependent features in the early layers. A semi-supervised method\nhelps increase the amount of conversational training data by pre-enhancing\nnoisy datasets, improving performance on real recordings. A new loss function\nbiased towards preserving speech quality helps the optimization better match\nhuman perceptual opinions on speech quality. Ablation experiments and objective\nand human opinion metrics show the benefits of the proposed improvements.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 01:24:45 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Isik", "Umut", ""], ["Giri", "Ritwik", ""], ["Phansalkar", "Neerad", ""], ["Valin", "Jean-Marc", ""], ["Helwani", "Karim", ""], ["Krishnaswamy", "Arvindh", ""]]}, {"id": "2008.04473", "submitter": "Yu-Min Chung", "authors": "Whitney K. Huang, Yu-Min Chung, Yu-Bo Wang, Jeff E. Mandel, and\n  Hau-Tieng Wu", "title": "Airflow recovery from thoracic and abdominal movements using\n  Synchrosqueezing Transform and Locally Stationary Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airflow signal encodes rich information about respiratory system. While the\ngold standard for measuring airflow is to use a spirometer with an occlusive\nseal, this is not practical for ambulatory monitoring of patients. Advances in\nsensor technology have made measurement of motion of the thorax and abdomen\nfeasible with small inexpensive devices, but estimation of airflow from these\ntime series is challenging. We propose to use the nonlinear-type time-frequency\nanalysis tool, synchrosqueezing transform, to properly represent the thoracic\nand abdominal movement signals as the features, which are used to recover the\nairflow by the locally stationary Gaussian process. We show that, using a\ndataset that contains respiratory signals under normal sleep conditions, an\naccurate prediction can be achieved by fitting the proposed model in the\nfeature space both in the intra- and inter-subject setups. We also apply our\nmethod to a more challenging case, where subjects under general anesthesia\nunderwent transitions from pressure support to unassisted ventilation to\nfurther demonstrate the utility of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 01:37:38 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Huang", "Whitney K.", ""], ["Chung", "Yu-Min", ""], ["Wang", "Yu-Bo", ""], ["Mandel", "Jeff E.", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2008.04489", "submitter": "Jack Goetz", "authors": "Jack Goetz, Ambuj Tewari", "title": "Federated Learning via Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows for the training of a model using data on multiple\nclients without the clients transmitting that raw data. However the standard\nmethod is to transmit model parameters (or updates), which for modern neural\nnetworks can be on the scale of millions of parameters, inflicting significant\ncomputational costs on the clients. We propose a method for federated learning\nwhere instead of transmitting a gradient update back to the server, we instead\ntransmit a small amount of synthetic `data'. We describe the procedure and show\nsome experimental results suggesting this procedure has potential, providing\nmore than an order of magnitude reduction in communication costs with minimal\nmodel degradation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 02:41:12 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 17:54:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Goetz", "Jack", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2008.04500", "submitter": "Jingyi Wang", "authors": "Jiahao Ding and Jingyi Wang and Guannan Liang and Jinbo Bi and Miao\n  Pan", "title": "Towards Plausible Differentially Private ADMM Based Distributed Machine\n  Learning", "comments": "Comments: Accepted for publication in CIKM'20", "journal-ref": null, "doi": "10.1145/3340531.3411860", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alternating Direction Method of Multipliers (ADMM) and its distributed\nversion have been widely used in machine learning. In the iterations of ADMM,\nmodel updates using local private data and model exchanges among agents impose\ncritical privacy concerns. Despite some pioneering works to relieve such\nconcerns, differentially private ADMM still confronts many research challenges.\nFor example, the guarantee of differential privacy (DP) relies on the premise\nthat the optimality of each local problem can be perfectly attained in each\nADMM iteration, which may never happen in practice. The model trained by DP\nADMM may have low prediction accuracy. In this paper, we address these concerns\nby proposing a novel (Improved) Plausible differentially Private ADMM\nalgorithm, called PP-ADMM and IPP-ADMM. In PP-ADMM, each agent approximately\nsolves a perturbed optimization problem that is formulated from its local\nprivate data in an iteration, and then perturbs the approximate solution with\nGaussian noise to provide the DP guarantee. To further improve the model\naccuracy and convergence, an improved version IPP-ADMM adopts sparse vector\ntechnique (SVT) to determine if an agent should update its neighbors with the\ncurrent perturbed solution. The agent calculates the difference of the current\nsolution from that in the last iteration, and if the difference is larger than\na threshold, it passes the solution to neighbors; or otherwise the solution\nwill be discarded. Moreover, we propose to track the total privacy loss under\nthe zero-concentrated DP (zCDP) and provide a generalization performance\nanalysis. Experiments on real-world datasets demonstrate that under the same\nprivacy guarantee, the proposed algorithms are superior to the state of the art\nin terms of model accuracy and convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:40:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ding", "Jiahao", ""], ["Wang", "Jingyi", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""], ["Pan", "Miao", ""]]}, {"id": "2008.04510", "submitter": "Han Zhao", "authors": "Han Zhao, Junjie Hu, Andrej Risteski", "title": "On Learning Language-Invariant Representations for Universal Machine\n  Translation", "comments": "Appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of universal machine translation is to learn to translate between\nany pair of languages, given a corpus of paired translated documents for\n\\emph{a small subset} of all pairs of languages. Despite impressive empirical\nresults and an increasing interest in massively multilingual models,\ntheoretical analysis on translation errors made by such universal machine\ntranslation models is only nascent. In this paper, we formally prove certain\nimpossibilities of this endeavour in general, as well as prove positive results\nin the presence of additional (but natural) structure of data.\n  For the former, we derive a lower bound on the translation error in the\nmany-to-many translation setting, which shows that any algorithm aiming to\nlearn shared sentence representations among multiple language pairs has to make\na large translation error on at least one of the translation tasks, if no\nassumption on the structure of the languages is made. For the latter, we show\nthat if the paired documents in the corpus follow a natural\n\\emph{encoder-decoder} generative process, we can expect a natural notion of\n``generalization'': a linear number of language pairs, rather than quadratic,\nsuffices to learn a good representation. Our theory also explains what kinds of\nconnection graphs between pairs of languages are better suited: ones with\nlonger paths result in worse sample complexity in terms of the total number of\ndocuments per language pair needed. We believe our theoretical insights and\nimplications contribute to the future algorithmic design of universal machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 04:45:33 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhao", "Han", ""], ["Hu", "Junjie", ""], ["Risteski", "Andrej", ""]]}, {"id": "2008.04538", "submitter": "Kenta Nagura", "authors": "Kenta Nagura, Song Bian and Takashi Sato", "title": "FedNNNN: Norm-Normalized Neural Network Aggregation for Fast and\n  Accurate Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a distributed learning protocol in which a server\nneeds to aggregate a set of models learned some independent clients to proceed\nthe learning process. At present, model averaging, known as FedAvg, is one of\nthe most widely adapted aggregation techniques. However, it is known to yield\nthe models with degraded prediction accuracy and slow convergence. In this\nwork, we find out that averaging models from different clients significantly\ndiminishes the norm of the update vectors, resulting in slow learning rate and\nlow prediction accuracy. Therefore, we propose a new aggregation method called\nFedNNNN. Instead of simple model averaging, we adjust the norm of the update\nvector and introduce momentum control techniques to improve the aggregation\neffectiveness of FL. As a demonstration, we evaluate FedNNNN on multiple\ndatasets and scenarios with different neural network models, and observe up to\n5.4% accuracy improvement.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:21:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Nagura", "Kenta", ""], ["Bian", "Song", ""], ["Sato", "Takashi", ""]]}, {"id": "2008.04555", "submitter": "Andi Han", "authors": "Andi Han, Junbin Gao", "title": "Riemannian stochastic recursive momentum method for non-convex\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic recursive momentum method for Riemannian non-convex\noptimization that achieves a near-optimal complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ to find $\\epsilon$-approximate solution\nwith one sample. That is, our method requires $\\mathcal{O}(1)$ gradient\nevaluations per iteration and does not require restarting with a large batch\ngradient, which is commonly used to obtain the faster rate. Extensive\nexperiment results demonstrate the superiority of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:05:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Han", "Andi", ""], ["Gao", "Junbin", ""]]}, {"id": "2008.04563", "submitter": "Masahiro Sato", "authors": "Masahiro Sato, Sho Takemori, Janmajay Singh, Tomoko Ohkuma", "title": "Unbiased Learning for the Causal Effect of Recommendation", "comments": "accepted at RecSys 2020, updated several experiments", "journal-ref": null, "doi": "10.1145/3383313.3412261", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing users' positive interactions, such as purchases or clicks, is an\nimportant objective of recommender systems. Recommenders typically aim to\nselect items that users will interact with. If the recommended items are\npurchased, an increase in sales is expected. However, the items could have been\npurchased even without recommendation. Thus, we want to recommend items that\nresults in purchases caused by recommendation. This can be formulated as a\nranking problem in terms of the causal effect. Despite its importance, this\nproblem has not been well explored in the related research. It is challenging\nbecause the ground truth of causal effect is unobservable, and estimating the\ncausal effect is prone to the bias arising from currently deployed\nrecommenders. This paper proposes an unbiased learning framework for the causal\neffect of recommendation. Based on the inverse propensity scoring technique,\nthe proposed framework first constructs unbiased estimators for ranking\nmetrics. Then, it conducts empirical risk minimization on the estimators with\npropensity capping, which reduces variance under finite training samples. Based\non the framework, we develop an unbiased learning method for the causal effect\nextension of a ranking metric. We theoretically analyze the unbiasedness of the\nproposed method and empirically demonstrate that the proposed method\noutperforms other biased learning methods in various settings.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:30:44 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 04:34:11 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 11:15:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Sato", "Masahiro", ""], ["Takemori", "Sho", ""], ["Singh", "Janmajay", ""], ["Ohkuma", "Tomoko", ""]]}, {"id": "2008.04572", "submitter": "Megha Srivastava", "authors": "Megha Srivastava, Besmira Nushi, Ece Kamar, Shital Shah, Eric Horvitz", "title": "An Empirical Analysis of Backward Compatibility in Machine Learning\n  Systems", "comments": "KDD 2020, 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of machine learning (ML), updates are performed with the\ngoal of enhancing model performance. However, current practices for updating\nmodels rely solely on isolated, aggregate performance analyses, overlooking\nimportant dependencies, expectations, and needs in real-world deployments. We\nconsider how updates, intended to improve ML models, can introduce new errors\nthat can significantly affect downstream systems and users. For example,\nupdates in models used in cloud-based classification services, such as image\nrecognition, can cause unexpected erroneous behavior in systems that make calls\nto the services. Prior work has shown the importance of \"backward\ncompatibility\" for maintaining human trust. We study challenges with backward\ncompatibility across different ML architectures and datasets, focusing on\ncommon settings including data shifts with structured noise and ML employed in\ninferential pipelines. Our results show that (i) compatibility issues arise\neven without data shift due to optimization stochasticity, (ii) training on\nlarge-scale noisy datasets often results in significant decreases in backward\ncompatibility even when model accuracy increases, and (iii) distributions of\nincompatible points align with noise bias, motivating the need for\ncompatibility aware de-noising and robustness methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:10:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Srivastava", "Megha", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Shah", "Shital", ""], ["Horvitz", "Eric", ""]]}, {"id": "2008.04575", "submitter": "Peter Meltzer", "authors": "Peter Meltzer, Marcelo Daniel Gutierrez Mallea and Peter J. Bentley", "title": "PiNet: Attention Pooling for Graph Classification", "comments": "4 pages, 3 figures 1 table", "journal-ref": "Neural Information Processing Systems (NIPS): Graph Representation\n  Learning Workshop 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PiNet, a generalised differentiable attention-based pooling\nmechanism for utilising graph convolution operations for graph level\nclassification. We demonstrate high sample efficiency and superior performance\nover other graph neural networks in distinguishing isomorphic graph classes, as\nwell as competitive results with state of the art methods on standard\nchemo-informatics datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:17:14 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Meltzer", "Peter", ""], ["Mallea", "Marcelo Daniel Gutierrez", ""], ["Bentley", "Peter J.", ""]]}, {"id": "2008.04598", "submitter": "Subhayan De", "authors": "Subhayan De", "title": "Uncertainty Quantification of Locally Nonlinear Dynamical Systems using\n  Neural Networks", "comments": "26 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models are often given in terms of differential equations to represent\nphysical systems. In the presence of uncertainty, accurate prediction of the\nbehavior of these systems using the models requires understanding the effect of\nuncertainty in the response. In uncertainty quantification, statistics such as\nmean and variance of the response of these physical systems are sought. To\nestimate these statistics sampling-based methods like Monte Carlo often require\nmany evaluations of the models' governing equations for multiple realizations\nof the uncertainty. However, for large complex engineering systems, these\nmethods become computationally burdensome. In structural engineering, often an\notherwise linear structure contains spatially local nonlinearities with\nuncertainty present in them. A standard nonlinear solver for them with\nsampling-based methods for uncertainty quantification incurs significant\ncomputational cost for estimating the statistics of the response. To ease this\ncomputational burden of uncertainty quantification of large-scale locally\nnonlinear dynamical systems, a method is proposed herein, which decomposes the\nresponse into two parts -- response of a nominal linear system and a corrective\nterm. This corrective term is the response from a pseudoforce that contains the\nnonlinearity and uncertainty information. In this paper, neural network, a\nrecently popular tool for universal function approximation in the scientific\nmachine learning community due to the advancement of computational capability\nas well as the availability of open-sourced packages like PyTorch and\nTensorFlow is used to estimate the pseudoforce. Since only the nonlinear and\nuncertain pseudoforce is modeled using the neural networks the same network can\nbe used to predict a different response of the system and hence no new network\nis required to train if the statistic of a different response is sought.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:30:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["De", "Subhayan", ""]]}, {"id": "2008.04644", "submitter": "Daniel Jung", "authors": "Daniel Jung", "title": "Residual Generation Using Physically-Based Grey-Box Recurrent Neural\n  Networks For Engine Fault Diagnosis", "comments": "12 pages, 22 figures, Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven fault diagnosis is complicated by unknown fault classes and\nlimited training data from different fault realizations. In these situations,\nconventional multi-class classification approaches are not suitable for fault\ndiagnosis. One solution is the use of anomaly classifiers that are trained\nusing only nominal data. Anomaly classifiers can be used to detect when a fault\noccurs but give little information about its root cause. Hybrid fault diagnosis\nmethods combining physically-based models and available training data have\nshown promising results to improve fault classification performance and\nidentify unknown fault classes. Residual generation using grey-box recurrent\nneural networks can be used for anomaly classification where physical insights\nabout the monitored system are incorporated into the design of the machine\nlearning algorithm. In this work, an automated residual design is developed\nusing a bipartite graph representation of the system model to design grey-box\nrecurrent neural networks and evaluated using a real industrial case study.\nData from an internal combustion engine test bench is used to illustrate the\npotentials of combining machine learning and model-based fault diagnosis\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:59:48 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Jung", "Daniel", ""]]}, {"id": "2008.04662", "submitter": "Yang Yang", "authors": "Yang Yang, Zhen-Qiang Sun, Hui Xiong, Jian Yang", "title": "S2OSC: A Holistic Semi-Supervised Approach for Open Set Classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open set classification (OSC) tackles the problem of determining whether the\ndata are in-class or out-of-class during inference, when only provided with a\nset of in-class examples at training time. Traditional OSC methods usually\ntrain discriminative or generative models with in-class data, then utilize the\npre-trained models to classify test data directly. However, these methods\nalways suffer from embedding confusion problem, i.e., partial out-of-class\ninstances are mixed with in-class ones of similar semantics, making it\ndifficult to classify. To solve this problem, we unify semi-supervised learning\nto develop a novel OSC algorithm, S2OSC, that incorporates out-of-class\ninstances filtering and model re-training in a transductive manner. In detail,\ngiven a pool of newly coming test data, S2OSC firstly filters distinct\nout-of-class instances using the pre-trained model, and annotates super-class\nfor them. Then, S2OSC trains a holistic classification model by combing\nin-class and out-of-class labeled data and remaining unlabeled test data in\nsemi-supervised paradigm, which also integrates pre-trained model for knowledge\ndistillation to further separate mixed instances. Despite its simplicity, the\nexperimental results show that S2OSC achieves state-of-the-art performance\nacross a variety of OSC tasks, including 85.4% of F1 on CIFAR-10 with only 300\npseudo-labels. We also demonstrate how S2OSC can be expanded to incremental OSC\nsetting effectively with streaming data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 12:26:00 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Yang", "Yang", ""], ["Sun", "Zhen-Qiang", ""], ["Xiong", "Hui", ""], ["Yang", "Jian", ""]]}, {"id": "2008.04679", "submitter": "Brian Groenke", "authors": "Brian Groenke, Luke Madaus, Claire Monteleoni", "title": "ClimAlign: Unsupervised statistical downscaling of climate variables via\n  normalizing flows", "comments": "8 pages, submitted as journal paper to the 10th International\n  Conference on Climate Informatics (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Downscaling is a landmark task in climate science and meteorology in which\nthe goal is to use coarse scale, spatio-temporal data to infer values at finer\nscales. Statistical downscaling aims to approximate this task using statistical\npatterns gleaned from an existing dataset of downscaled values, often obtained\nfrom observations or physical models. In this work, we investigate the\napplication of deep latent variable learning to the task of statistical\ndownscaling. We present ClimAlign, a novel method for unsupervised, generative\ndownscaling using adaptations of recent work in normalizing flows for\nvariational inference. We evaluate the viability of our method using several\ndifferent metrics on two datasets consisting of daily temperature and\nprecipitation values gridded at low (1 degree latitude/longitude) and high (1/4\nand 1/8 degree) resolutions. We show that our method achieves comparable\npredictive performance to existing supervised statistical downscaling methods\nwhile simultaneously allowing for both conditional and unconditional sampling\nfrom the joint distribution over high and low resolution spatial fields. We\nprovide publicly accessible implementations of our method, as well as the\nbaselines used for comparison, on GitHub.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:01:53 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Groenke", "Brian", ""], ["Madaus", "Luke", ""], ["Monteleoni", "Claire", ""]]}, {"id": "2008.04699", "submitter": "Shuo Liu", "authors": "Nirupam Gupta, Shuo Liu and Nitin H. Vaidya", "title": "Byzantine Fault-Tolerant Distributed Machine Learning Using Stochastic\n  Gradient Descent (SGD) and Norm-Based Comparative Gradient Elimination (CGE)", "comments": "The report includes 52 pages, and 16 figures. Extension of our prior\n  work on Byzantine fault-tolerant distribution optimization (arXiv:1903.08752\n  and doi:10.1145/3382734.3405748) to Byzantine fault-tolerant distributed\n  machine learning; Updated to the full version of workshop paper in DSN-DSML\n  '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the Byzantine fault-tolerance problem in distributed\nstochastic gradient descent (D-SGD) method - a popular algorithm for\ndistributed multi-agent machine learning. In this problem, each agent samples\ndata points independently from a certain data-generating distribution. In the\nfault-free case, the D-SGD method allows all the agents to learn a mathematical\nmodel best fitting the data collectively sampled by all agents. We consider the\ncase when a fraction of agents may be Byzantine faulty. Such faulty agents may\nnot follow a prescribed algorithm correctly, and may render traditional D-SGD\nmethod ineffective by sharing arbitrary incorrect stochastic gradients. We\npropose a norm-based gradient-filter, named comparative gradient elimination\n(CGE), that robustifies the D-SGD method against Byzantine agents. We show that\nthe CGE gradient-filter guarantees fault-tolerance against a bounded fraction\nof Byzantine agents under standard stochastic assumptions, and is\ncomputationally simpler compared to many existing gradient-filters such as\nmulti-KRUM, geometric median-of-means, and the spectral filters. We empirically\nshow, by simulating distributed learning on neural networks, that the\nfault-tolerance of CGE is comparable to that of existing gradient-filters. We\nalso empirically show that exponential averaging of stochastic gradients\nimproves the fault-tolerance of a generic gradient-filter.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:51:16 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 00:56:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gupta", "Nirupam", ""], ["Liu", "Shuo", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "2008.04733", "submitter": "Zheng Zhao", "authors": "Zheng Zhao and Muhammad Emzir and Simo S\\\"arkk\\\"a", "title": "Deep State-Space Gaussian Processes", "comments": "Submitted to Statistics and Computing. The code will be revealed at\n  https://github.com/zgbkdlm/SS-DGP upon acceptance", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with a state-space approach to deep Gaussian process\n(DGP) regression. We construct the DGP by hierarchically putting transformed\nGaussian process (GP) priors on the length scales and magnitudes of the next\nlevel of Gaussian processes in the hierarchy. The idea of the state-space\napproach is to represent the DGP as a non-linear hierarchical system of linear\nstochastic differential equations (SDEs), where each SDE corresponds to a\nconditional GP. The DGP regression problem then becomes a state estimation\nproblem, and we can estimate the state efficiently with sequential methods by\nusing the Markov property of the state-space DGP. The computational complexity\nscales linearly with respect to the number of measurements. Based on this, we\nformulate state-space MAP as well as Bayesian filtering and smoothing solutions\nto the DGP regression problem. We demonstrate the performance of the proposed\nmodels and methods on synthetic non-stationary signals and apply the\nstate-space DGP to detection of the gravitational waves from LIGO measurements.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:50:07 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhao", "Zheng", ""], ["Emzir", "Muhammad", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2008.04734", "submitter": "Xinyu Zhang", "authors": "Xinyu Zhang", "title": "Error Bounds for Generalized Group Sparsity", "comments": "23 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:2006.06172", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional statistical inference, sparsity regularizations have\nshown advantages in consistency and convergence rates for coefficient\nestimation. We consider a generalized version of Sparse-Group Lasso which\ncaptures both element-wise sparsity and group-wise sparsity simultaneously. We\nstate one universal theorem which is proved to obtain results on consistency\nand convergence rates for different forms of double sparsity regularization.\nThe universality of the results lies in an generalization of various\nconvergence rates for single regularization cases such as LASSO and group LASSO\nand also double regularization cases such as sparse-group LASSO. Our analysis\nidentifies a generalized norm of $\\epsilon$-norm, which provides a dual\nformulation for our double sparsity regularization.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:52:05 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhang", "Xinyu", ""]]}, {"id": "2008.04847", "submitter": "Hadi Meidani", "authors": "Amir Kazemi and Hadi Meidani", "title": "IGANI: Iterative Generative Adversarial Networks for Imputation with\n  Application to Traffic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing use of sensor data in intelligent transportation systems calls for\naccurate imputation algorithms that can enable reliable traffic management in\nthe occasional absence of data. As one of the effective imputation approaches,\ngenerative adversarial networks (GANs) are implicit generative models that can\nbe used for data imputation, which is formulated as an unsupervised learning\nproblem. This work introduces a novel iterative GAN architecture, called\nIterative Generative Adversarial Networks for Imputation (IGANI), for data\nimputation. IGANI imputes data in two steps and maintains the invertibility of\nthe generative imputer, which will be shown to be a sufficient condition for\nthe convergence of the proposed GAN-based imputation. The performance of our\nproposed method is evaluated on (1) the imputation of traffic speed data\ncollected in the city of Guangzhou in China, and the training of short-term\ntraffic prediction models using imputed data, and (2) the imputation of\nmulti-variable traffic data of highways in Portland-Vancouver metropolitan\nregion which includes volume, occupancy, and speed with different missing rates\nfor each of them. It is shown that our proposed algorithm mostly produces more\naccurate results compared to those of previous GAN-based imputation\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:46:02 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 19:47:56 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 16:37:58 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Kazemi", "Amir", ""], ["Meidani", "Hadi", ""]]}, {"id": "2008.04859", "submitter": "Dimitris Tsipras", "authors": "Shibani Santurkar, Dimitris Tsipras, Aleksander Madry", "title": "BREEDS: Benchmarks for Subpopulation Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a methodology for assessing the robustness of models to\nsubpopulation shift---specifically, their ability to generalize to novel data\nsubpopulations that were not observed during training. Our approach leverages\nthe class structure underlying existing datasets to control the data\nsubpopulations that comprise the training and test distributions. This enables\nus to synthesize realistic distribution shifts whose sources can be precisely\ncontrolled and characterized, within existing large-scale datasets. Applying\nthis methodology to the ImageNet dataset, we create a suite of subpopulation\nshift benchmarks of varying granularity. We then validate that the\ncorresponding shifts are tractable by obtaining human baselines for them.\nFinally, we utilize these benchmarks to measure the sensitivity of standard\nmodel architectures as well as the effectiveness of off-the-shelf train-time\nrobustness interventions. Code and data available at\nhttps://github.com/MadryLab/BREEDS-Benchmarks .\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:04:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Madry", "Aleksander", ""]]}, {"id": "2008.04876", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Hongyi Wen, Ke Wang", "title": "Revisiting Adversarially Learned Injection Attacks Against Recommender\n  Systems", "comments": "Accepted at Recsys 20", "journal-ref": null, "doi": "10.1145/3383313.3412243", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play an important role in modern information and\ne-commerce applications. While increasing research is dedicated to improving\nthe relevance and diversity of the recommendations, the potential risks of\nstate-of-the-art recommendation models are under-explored, that is, these\nmodels could be subject to attacks from malicious third parties, through\ninjecting fake user interactions to achieve their purposes. This paper revisits\nthe adversarially-learned injection attack problem, where the injected fake\nuser `behaviors' are learned locally by the attackers with their own model --\none that is potentially different from the model under attack, but shares\nsimilar properties to allow attack transfer. We found that most existing works\nin literature suffer from two major limitations: (1) they do not solve the\noptimization problem precisely, making the attack less harmful than it could\nbe, (2) they assume perfect knowledge for the attack, causing the lack of\nunderstanding for realistic attack capabilities. We demonstrate that the exact\nsolution for generating fake users as an optimization problem could lead to a\nmuch larger impact. Our experiments on a real-world dataset reveal important\nproperties of the attack, including attack transferability and its limitations.\nThese findings can inspire useful defensive methods against this possible\nexisting attack.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:30:02 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 05:03:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tang", "Jiaxi", ""], ["Wen", "Hongyi", ""], ["Wang", "Ke", ""]]}, {"id": "2008.04882", "submitter": "Tryambak Gangopadhyay", "authors": "Tryambak Gangopadhyay, Sin Yong Tan, Zhanhong Jiang, Rui Meng, Soumik\n  Sarkar", "title": "Spatiotemporal Attention for Multivariate Time Series Prediction and\n  Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series modeling and prediction problems are abundant in\nmany machine learning application domains. Accurate interpretation of such\nprediction outcomes from a machine learning model that explicitly captures\ntemporal correlations can significantly benefit the domain experts. In this\ncontext, temporal attention has been successfully applied to isolate the\nimportant time steps for the input time series. However, in multivariate time\nseries problems, spatial interpretation is also critical to understand the\ncontributions of different variables on the model outputs. We propose a novel\ndeep learning architecture, called spatiotemporal attention mechanism (STAM)\nfor simultaneous learning of the most important time steps and variables. STAM\nis a causal (i.e., only depends on past inputs and does not use future inputs)\nand scalable (i.e., scales well with an increase in the number of variables)\napproach that is comparable to the state-of-the-art models in terms of\ncomputational tractability. We demonstrate our models' performance on two\npopular public datasets and a domain-specific dataset. When compared with the\nbaseline models, the results show that STAM maintains state-of-the-art\nprediction accuracy while offering the benefit of accurate spatiotemporal\ninterpretability. The learned attention weights are validated from a domain\nknowledge perspective for these real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:34:55 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:32:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Gangopadhyay", "Tryambak", ""], ["Tan", "Sin Yong", ""], ["Jiang", "Zhanhong", ""], ["Meng", "Rui", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2008.04948", "submitter": "Jean-Gabriel Young", "authors": "Jean-Gabriel Young, Giovanni Petri, Tiago P. Peixoto", "title": "Hypergraph reconstruction from network data", "comments": "13 pages, 7 figures. Code is available at\n  https://graph-tool.skewed.de/", "journal-ref": "Communication Physics 4, 135 (2021)", "doi": "10.1038/s42005-021-00637-w", "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks can describe the structure of a wide variety of complex systems by\nspecifying which pairs of entities in the system are connected. While such\npairwise representations are flexible, they are not necessarily appropriate\nwhen the fundamental interactions involve more than two entities at the same\ntime. Pairwise representations nonetheless remain ubiquitous, because\nhigher-order interactions are often not recorded explicitly in network data.\nHere, we introduce a Bayesian approach to reconstruct latent higher-order\ninteractions from ordinary pairwise network data. Our method is based on the\nprinciple of parsimony and only includes higher-order structures when there is\nsufficient statistical evidence for them. We demonstrate its applicability to a\nwide range of datasets, both synthetic and empirical.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:30:06 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 19:01:58 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 17:31:31 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Young", "Jean-Gabriel", ""], ["Petri", "Giovanni", ""], ["Peixoto", "Tiago P.", ""]]}, {"id": "2008.04975", "submitter": "Ping Li", "authors": "Farzin Haddadpour, Belhal Karimi, Ping Li, Xiaoyun Li", "title": "FedSKETCH: Communication-Efficient and Private Federated Learning via\n  Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication complexity and privacy are the two key challenges in Federated\nLearning where the goal is to perform a distributed learning through a large\nvolume of devices. In this work, we introduce FedSKETCH and FedSKETCHGATE\nalgorithms to address both challenges in Federated learning jointly, where\nthese algorithms are intended to be used for homogeneous and heterogeneous data\ndistribution settings respectively. The key idea is to compress the\naccumulation of local gradients using count sketch, therefore, the server does\nnot have access to the gradients themselves which provides privacy.\nFurthermore, due to the lower dimension of sketching used, our method exhibits\ncommunication-efficiency property as well. We provide, for the aforementioned\nschemes, sharp convergence guarantees.\n  Finally, we back up our theory with various set of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:22:48 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Karimi", "Belhal", ""], ["Li", "Ping", ""], ["Li", "Xiaoyun", ""]]}, {"id": "2008.04988", "submitter": "Rui Liu", "authors": "Rui Liu and Alex Olshevsky", "title": "Asymptotic Convergence Rate of Alternating Minimization for Rank One\n  Matrix Completion", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study alternating minimization for matrix completion in the simplest\npossible setting: completing a rank-one matrix from a revealed subset of the\nentries. We bound the asymptotic convergence rate by the variational\ncharacterization of eigenvalues of a reversible consensus problem. This leads\nto a polynomial upper bound on the asymptotic rate in terms of number of nodes\nas well as the largest degree of the graph of revealed entries.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:56:35 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Liu", "Rui", ""], ["Olshevsky", "Alex", ""]]}, {"id": "2008.04990", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Nan Jiang", "title": "Batch Value-function Approximation with Only Realizability", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make progress in a long-standing problem of batch reinforcement learning\n(RL): learning $Q^\\star$ from an exploratory and polynomial-sized dataset,\nusing a realizable and otherwise arbitrary function class. In fact, all\nexisting algorithms demand function-approximation assumptions stronger than\nrealizability, and the mounting negative evidence has led to a conjecture that\nsample-efficient learning is impossible in this setting (Chen and Jiang, 2019).\nOur algorithm, BVFT, breaks the hardness conjecture (albeit under a stronger\nnotion of exploratory data) via a tournament procedure that reduces the\nlearning problem to pairwise comparison, and solves the latter with the help of\na state-action partition constructed from the compared functions. We also\ndiscuss how BVFT can be applied to model selection among other extensions and\nopen problems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 20:09:37 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 05:01:21 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 04:41:20 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xie", "Tengyang", ""], ["Jiang", "Nan", ""]]}, {"id": "2008.05000", "submitter": "Javier Fernandez-Marques", "authors": "Shyam A. Tailor, Javier Fernandez-Marques, Nicholas D. Lane", "title": "Degree-Quant: Quantization-Aware Training for Graph Neural Networks", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have demonstrated strong performance on a wide\nvariety of tasks due to their ability to model non-uniform structured data.\nDespite their promise, there exists little research exploring methods to make\nthem more efficient at inference time. In this work, we explore the viability\nof training quantized GNNs, enabling the usage of low precision integer\narithmetic during inference. We identify the sources of error that uniquely\narise when attempting to quantize GNNs, and propose an architecturally-agnostic\nmethod, Degree-Quant, to improve performance over existing quantization-aware\ntraining baselines commonly used on other architectures, such as CNNs. We\nvalidate our method on six datasets and show, unlike previous attempts, that\nmodels generalize to unseen graphs. Models trained with Degree-Quant for INT8\nquantization perform as well as FP32 models in most cases; for INT4 models, we\nobtain up to 26% gains over the baselines. Our work enables up to 4.7x speedups\non CPU when using INT8 arithmetic.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 20:53:50 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 15:29:16 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 15:27:59 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Tailor", "Shyam A.", ""], ["Fernandez-Marques", "Javier", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.05004", "submitter": "Shaojie Tang", "authors": "Shaojie Tang", "title": "Beyond Pointwise Submodularity: Non-Monotone Adaptive Submodular\n  Maximization in Linear Time", "comments": "22 pages, accepted to TCS. This version subsumes our preliminary\n  results presented arXiv:2007.04214", "journal-ref": "Theoretical Computer Science, Volume 850, 4 January 2021, Pages\n  249-261", "doi": "10.1016/j.tcs.2020.11.007", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the non-monotone adaptive submodular maximization\nproblem subject to a cardinality constraint. We first revisit the adaptive\nrandom greedy algorithm proposed in \\citep{gotovos2015non}, where they show\nthat this algorithm achieves a $1/e$ approximation ratio if the objective\nfunction is adaptive submodular and pointwise submodular. It is not clear\nwhether the same guarantee holds under adaptive submodularity (without\nresorting to pointwise submodularity) or not. Our first contribution is to show\nthat the adaptive random greedy algorithm achieves a $1/e$ approximation ratio\nunder adaptive submodularity. One limitation of the adaptive random greedy\nalgorithm is that it requires $O(n\\times k)$ value oracle queries, where $n$ is\nthe size of the ground set and $k$ is the cardinality constraint. Our second\ncontribution is to develop the first linear-time algorithm for the non-monotone\nadaptive submodular maximization problem. Our algorithm achieves a\n$1/e-\\epsilon$ approximation ratio (this bound is improved to $1-1/e-\\epsilon$\nfor monotone case), using only $O(n\\epsilon^{-2}\\log \\epsilon^{-1})$ value\noracle queries. Notably, $O(n\\epsilon^{-2}\\log \\epsilon^{-1})$ is independent\nof the cardinality constraint. For the monotone case, we propose a faster\nalgorithm that achieves a $1-1/e-\\epsilon$ approximation ratio in expectation\nwith $O(n \\log \\frac{1}{\\epsilon})$ value oracle queries. We also generalize\nour study by considering a partition matroid constraint, and develop a\nlinear-time algorithm for monotone and fully adaptive submodular functions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 21:06:52 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 13:36:50 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 16:48:49 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 18:41:15 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Tang", "Shaojie", ""]]}, {"id": "2008.05030", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sophie Hilgard, Sameer Singh, Himabindu Lakkaraju", "title": "Reliable Post hoc Explanations: Modeling Uncertainty in Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As black box explanations are increasingly being employed to establish model\ncredibility in high stakes settings, it is important to ensure that these\nexplanations are accurate and reliable. However, prior work demonstrates that\nexplanations generated by state-of-the-art techniques are inconsistent,\nunstable, and provide very little insight into their correctness and\nreliability. In addition, these methods are also computationally inefficient,\nand require significant hyper-parameter tuning. In this paper, we address the\naforementioned challenges by developing a novel Bayesian framework for\ngenerating local explanations along with their associated uncertainty. We\ninstantiate this framework to obtain Bayesian versions of LIME and KernelSHAP\nwhich output credible intervals for the feature importances, capturing the\nassociated uncertainty. The resulting explanations not only enable us to make\nconcrete inferences about their quality (e.g., there is a 95\\% chance that the\nfeature importance lies within the given range), but are also highly consistent\nand stable. We carry out a detailed theoretical analysis that leverages the\naforementioned uncertainty to estimate how many perturbations to sample, and\nhow to sample for faster convergence. This work makes the first attempt at\naddressing several critical issues with popular explanation methods in one\nshot, thereby generating consistent, stable, and reliable explanations with\nguarantees in a computationally efficient manner. Experimental evaluation with\nmultiple real world datasets and user studies demonstrate that the efficacy of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 22:52:21 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 18:55:01 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 01:50:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Slack", "Dylan", ""], ["Hilgard", "Sophie", ""], ["Singh", "Sameer", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2008.05052", "submitter": "Sisi Ma", "authors": "Sisi Ma, Roshan Tourani", "title": "Predictive and Causal Implications of using Shapley Value for Model\n  Interpretation", "comments": "Accepted by KDD CD workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley value is a concept from game theory. Recently, it has been used for\nexplaining complex models produced by machine learning techniques. Although the\nmathematical definition of Shapley value is straight-forward, the implication\nof using it as a model interpretation tool is yet to be described. In the\ncurrent paper, we analyzed Shapley value in the Bayesian network framework. We\nestablished the relationship between Shapley value and conditional\nindependence, a key concept in both predictive and causal modeling. Our results\nindicate that, eliminating a variable with high Shapley value from a model do\nnot necessarily impair predictive performance, whereas eliminating a variable\nwith low Shapley value from a model could impair performance. Therefore, using\nShapley value for feature selection do not result in the most parsimonious and\npredictively optimal model in the general case. More importantly, Shapley value\nof a variable do not reflect their causal relationship with the target of\ninterest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:08:08 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ma", "Sisi", ""], ["Tourani", "Roshan", ""]]}, {"id": "2008.05060", "submitter": "Mona Jalal", "authors": "Won Hwa Kim, Mona Jalal, Seongjae Hwang, Sterling C. Johnson, Vikas\n  Singh", "title": "Online Graph Completion: Multivariate Signal Recovery in Computer Vision", "comments": "9 pages, 7 figures, CVPR 2017 Conference", "journal-ref": null, "doi": "10.1109/CVPR.2017.533", "report-no": null, "categories": "cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of \"human-in-the-loop\" paradigms in computer vision and machine\nlearning is leading to various applications where the actual data acquisition\n(e.g., human supervision) and the underlying inference algorithms are closely\ninterwined. While classical work in active learning provides effective\nsolutions when the learning module involves classification and regression\ntasks, many practical issues such as partially observed measurements, financial\nconstraints and even additional distributional or structural aspects of the\ndata typically fall outside the scope of this treatment. For instance, with\nsequential acquisition of partial measurements of data that manifest as a\nmatrix (or tensor), novel strategies for completion (or collaborative\nfiltering) of the remaining entries have only been studied recently. Motivated\nby vision problems where we seek to annotate a large dataset of images via a\ncrowdsourced platform or alternatively, complement results from a\nstate-of-the-art object detector using human feedback, we study the\n\"completion\" problem defined on graphs, where requests for additional\nmeasurements must be made sequentially. We design the optimization model in the\nFourier domain of the graph describing how ideas based on adaptive\nsubmodularity provide algorithms that work well in practice. On a large set of\nimages collected from Imgur, we see promising results on images that are\notherwise difficult to categorize. We also show applications to an experimental\ndesign problem in neuroimaging.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:34:21 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kim", "Won Hwa", ""], ["Jalal", "Mona", ""], ["Hwang", "Seongjae", ""], ["Johnson", "Sterling C.", ""], ["Singh", "Vikas", ""]]}, {"id": "2008.05089", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dinh Phung", "title": "Quaternion Graph Neural Networks", "comments": "The extended abstract has been accepted to NeurIPS 2020 Workshop on\n  Differential Geometry meets Deep Learning (DiffGeo4DL). The code in Pytorch\n  and Tensorflow is available at: https://github.com/daiquocnguyen/QGNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, graph neural networks (GNNs) become a principal research direction\nto learn low-dimensional continuous embeddings of nodes and graphs to predict\nnode and graph labels, respectively. However, Euclidean embeddings have high\ndistortion when using GNNs to model complex graphs such as social networks.\nFurthermore, existing GNNs are not very efficient with the high number of model\nparameters when increasing the number of hidden layers. Therefore, we move\nbeyond the Euclidean space to a hyper-complex vector space to improve graph\nrepresentation quality and reduce the number of model parameters. To this end,\nwe propose quaternion graph neural networks (QGNN) to generalize GCNs within\nthe Quaternion space to learn quaternion embeddings for nodes and graphs. The\nQuaternion space, a hyper-complex vector space, provides highly meaningful\ncomputations through Hamilton product compared to the Euclidean and complex\nvector spaces. As a result, our QGNN can reduce the model size up to four times\nand enhance learning better graph representations. Experimental results show\nthat the proposed QGNN produces state-of-the-art accuracies on a range of\nwell-known benchmark datasets for three downstream tasks, including graph\nclassification, semi-supervised node classification, and text (node)\nclassification. Our code is available at: https://github.com/daiquocnguyen/QGNN\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 03:41:03 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 18:30:29 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 15:20:22 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "2008.05095", "submitter": "Jianye Pang", "authors": "Jianye Pang, Kai Yi, Wanguang Yin, Min Xu", "title": "Experimental Analysis of Legendre Decomposition in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we analyze Legendre decomposition for non-negative\ntensor in theory and application. In theory, the properties of dual parameters\nand dually flat manifold in Legendre decomposition are reviewed, and the\nprocess of tensor projection and parameter updating is analyzed. In\napplication, a series of verification experiments and clustering experiments\nwith parameters on submanifold were carried out, hoping to find an effective\nlower dimensional representation of the input tensor. The experimental results\nshow that the parameters on submanifold have no ability to be directly used as\nlow-rank representations. Combined with analysis, we connect Legendre\ndecomposition with neural networks and low-rank representation applications,\nand put forward some promising prospects.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 04:11:17 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 14:08:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pang", "Jianye", ""], ["Yi", "Kai", ""], ["Yin", "Wanguang", ""], ["Xu", "Min", ""]]}, {"id": "2008.05104", "submitter": "Sina Baghal", "authors": "Sina Baghal", "title": "A matrix concentration inequality for products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-asymptotic concentration inequality for the random matrix\nproduct \\begin{equation}\\label{eq:Zn} Z_n = \\left(I_d-\\alpha\nX_n\\right)\\left(I_d-\\alpha X_{n-1}\\right)\\cdots \\left(I_d-\\alpha X_1\\right),\n\\end{equation} where $\\left\\{X_k \\right\\}_{k=1}^{+\\infty}$ is a sequence of\nbounded independent random positive semidefinite matrices with common\nexpectation $\\mathbb{E}\\left[X_k\\right]=\\Sigma$. Under these assumptions, we\nshow that, for small enough positive $\\alpha$, $Z_n$ satisfies the\nconcentration inequality \\begin{equation}\\label{eq:CTbound}\n\\mathbb{P}\\left(\\left\\Vert Z_n-\\mathbb{E}\\left[Z_n\\right]\\right\\Vert \\geq\nt\\right) \\leq 2d^2\\cdot\\exp\\left(\\frac{-t^2}{\\alpha \\sigma^2} \\right) \\quad\n\\text{for all } t\\geq 0, \\end{equation} where $\\sigma^2$ denotes a variance\nparameter.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 04:39:12 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 22:16:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Baghal", "Sina", ""]]}, {"id": "2008.05124", "submitter": "Manuele Rusci Mr.", "authors": "Manuele Rusci, Marco Fariselli, Alessandro Capotondi, Luca Benini", "title": "Leveraging Automated Mixed-Low-Precision Quantization for tiny edge\n  microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The severe on-chip memory limitations are currently preventing the deployment\nof the most accurate Deep Neural Network (DNN) models on tiny MicroController\nUnits (MCUs), even if leveraging an effective 8-bit quantization scheme. To\ntackle this issue, in this paper we present an automated mixed-precision\nquantization flow based on the HAQ framework but tailored for the memory and\ncomputational characteristics of MCU devices. Specifically, a Reinforcement\nLearning agent searches for the best uniform quantization levels, among 2, 4, 8\nbits, of individual weight and activation tensors, under the tight constraints\non RAM and FLASH embedded memory sizes. We conduct an experimental analysis on\nMobileNetV1, MobileNetV2 and MNasNet models for Imagenet classification.\nConcerning the quantization policy search, the RL agent selects quantization\npolicies that maximize the memory utilization. Given an MCU-class memory bound\nof 2MB for weight-only quantization, the compressed models produced by the\nmixed-precision engine result as accurate as the state-of-the-art solutions\nquantized with a non-uniform function, which is not tailored for CPUs featuring\ninteger-only arithmetic. This denotes the viability of uniform quantization,\nrequired for MCU deployments, for deep weights compression. When also limiting\nthe activation memory budget to 512kB, the best MobileNetV1 model scores up to\n68.4% on Imagenet thanks to the found quantization policy, resulting to be 4%\nmore accurate than the other 8-bit networks fitting the same memory\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:09:58 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Rusci", "Manuele", ""], ["Fariselli", "Marco", ""], ["Capotondi", "Alessandro", ""], ["Benini", "Luca", ""]]}, {"id": "2008.05129", "submitter": "Xin Sun", "authors": "Xin Sun, Chi Zhang, Guosheng Lin and Keck-Voon Ling", "title": "Open Set Recognition with Conditional Probabilistic Generative Models", "comments": "Extended version of CGDL arXiv:2003.08823 in CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have made breakthroughs in a wide range of visual\nunderstanding tasks. A typical challenge that hinders their real-world\napplications is that unknown samples may be fed into the system during the\ntesting phase, but traditional deep neural networks will wrongly recognize\nthese unknown samples as one of the known classes. Open set recognition (OSR)\nis a potential solution to overcome this problem, where the open set classifier\nshould have the flexibility to reject unknown samples and meanwhile maintain\nhigh classification accuracy in known classes. Probabilistic generative models,\nsuch as Variational Autoencoders (VAE) and Adversarial Autoencoders (AAE), are\npopular methods to detect unknowns, but they cannot provide discriminative\nrepresentations for known classification. In this paper, we propose a novel\nframework, called Conditional Probabilistic Generative Models (CPGM), for open\nset recognition. The core insight of our work is to add discriminative\ninformation into the probabilistic generative models, such that the proposed\nmodels can not only detect unknown samples but also classify known classes by\nforcing different latent features to approximate conditional Gaussian\ndistributions. We discuss many model variants and provide comprehensive\nexperiments to study their characteristics. Experiment results on multiple\nbenchmark datasets reveal that the proposed method significantly outperforms\nthe baselines and achieves new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:23:49 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:18:43 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sun", "Xin", ""], ["Zhang", "Chi", ""], ["Lin", "Guosheng", ""], ["Ling", "Keck-Voon", ""]]}, {"id": "2008.05163", "submitter": "Rudolf Jagdhuber", "authors": "Rudolf Jagdhuber and J\\\"org Rahnenf\\\"uhrer", "title": "Implications on Feature Detection when using the Benefit-Cost Ratio", "comments": "v2: Added ancillary files and corrected floating of figures. 10\n  pages, 2 figures, submitted to SN Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical machine learning applications, there are two objectives:\none is to maximize predictive accuracy and the other is to minimize costs of\nthe resulting model. These costs of individual features may be financial costs,\nbut can also refer to other aspects, like for example evaluation time. Feature\nselection addresses both objectives, as it reduces the number of features and\ncan improve the generalization ability of the model. If costs differ between\nfeatures, the feature selection needs to trade-off the individual benefit and\ncost of each feature. A popular trade-off choice is the ratio of both, the BCR\n(benefit-cost ratio). In this paper we analyze implications of using this\nmeasure with special focus to the ability to distinguish relevant features from\nnoise. We perform a simulation study for different cost and data settings and\nobtain detection rates of relevant features and empirical distributions of the\ntrade-off ratio. Our simulation study exposed a clear impact of the cost\nsetting on the detection rate. In situations with large cost differences and\nsmall effect sizes, the BCR missed relevant features and preferred cheap noise\nfeatures. We conclude that a trade-off between predictive performance and costs\nwithout a controlling hyperparameter can easily overemphasize very cheap noise\nfeatures. While the simple benefit-cost ratio offers an easy solution to\nincorporate costs, it is important to be aware of its risks. Avoiding costs\nclose to 0, rescaling large cost differences, or using a hyperparameter\ntrade-off are ways to counteract the adverse effects exposed in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:25:42 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 16:30:15 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jagdhuber", "Rudolf", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2008.05171", "submitter": "Erich Schubert", "authors": "Erich Schubert and Peter J. Rousseeuw", "title": "Fast and Eager k-Medoids Clustering: O(k) Runtime Improvement of the\n  PAM, CLARA, and CLARANS Algorithms", "comments": null, "journal-ref": "Information Systems, 2021", "doi": "10.1016/j.is.2021.101804", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering non-Euclidean data is difficult, and one of the most used\nalgorithms besides hierarchical clustering is the popular algorithm\nPartitioning Around Medoids (PAM), also simply referred to as k-medoids\nclustering. In Euclidean geometry the mean-as used in k-means-is a good\nestimator for the cluster center, but this does not exist for arbitrary\ndissimilarities. PAM uses the medoid instead, the object with the smallest\ndissimilarity to all others in the cluster. This notion of centrality can be\nused with any (dis-)similarity, and thus is of high relevance to many domains\nand applications. A key issue with PAM is its high run time cost. We propose\nmodifications to the PAM algorithm that achieve an O(k)-fold speedup in the\nsecond (\"SWAP\") phase of the algorithm, but will still find the same results as\nthe original PAM algorithm. If we relax the choice of swaps performed (while\nretaining comparable quality), we can further accelerate the algorithm by\neagerly performing additional swaps in each iteration. With the substantially\nfaster SWAP, we can now explore faster initialization strategies, because (i)\nthe classic (\"BUILD\") initialization now becomes the bottleneck, and (ii) our\nswap is fast enough to compensate for worse starting conditions. We also show\nhow the CLARA and CLARANS algorithms benefit from the proposed modifications.\nWhile we do not study the parallelization of our approach in this work, it can\neasily be combined with earlier approaches to use PAM and CLARA on big data\n(some of which use PAM as a subroutine, hence can immediately benefit from\nthese improvements), where the performance with high k becomes increasingly\nimportant. In experiments on real data with k=100,200, we observed a 458x\nrespectively 1191x speedup compared to the original PAM SWAP algorithm, making\nPAM applicable to larger data sets, and in particular to higher k.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:37:50 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 08:16:45 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Schubert", "Erich", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2008.05214", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "REMAX: Relational Representation for Multi-Agent Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a multi-agent reinforcement learning (MARL) model is generally\ndifficult because there are numerous combinations of complex interactions among\nagents that induce certain reward signals. Especially when there is a sparse\nreward signal, the training becomes more difficult. Previous studies have tried\nto resolve this issue by employing an intrinsic reward, which is a signal\nspecifically designed for inducing the interactions among agents, to boost the\nMARL model training. However, this approach requires extensive prior knowledge\nto design an intrinsic reward. To optimize the training of an MARL model, we\npropose a learning-based exploration strategy to generate the initial states of\na game. The proposed method adopts a variational graph autoencoder to represent\na state of a game such that (1) the state can be compactly encoded to the\nlatent representation by considering the relationship among agents, and (2) the\nlatent representation can be used as an effective input to the surrogate model\npredicting the exploration score. The proposed method determines the latent\nrepresentations that maximize the surrogate model and decodes these\nrepresentations to generate the initial states from which the MARL model starts\ntraining. Empirically, we demonstrate that the generated states improve the\ntraining and performance of MARL more than the existing exploration methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:23:35 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2008.05247", "submitter": "Alex Serban", "authors": "Alex Serban, Erik Poll, Joost Visser", "title": "Learning to Learn from Mistakes: Robust Optimization for Adversarial\n  Noise", "comments": "Published at ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sensitivity to adversarial noise hinders deployment of machine learning\nalgorithms in security-critical applications. Although many adversarial\ndefenses have been proposed, robustness to adversarial noise remains an open\nproblem. The most compelling defense, adversarial training, requires a\nsubstantial increase in processing time and it has been shown to overfit on the\ntraining data. In this paper, we aim to overcome these limitations by training\nrobust models in low data regimes and transfer adversarial knowledge between\ndifferent models. We train a meta-optimizer which learns to robustly optimize a\nmodel using adversarial examples and is able to transfer the knowledge learned\nto new models, without the need to generate new adversarial examples.\nExperimental results show the meta-optimizer is consistent across different\narchitectures and data sets, suggesting it is possible to automatically patch\nadversarial vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:44:01 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Serban", "Alex", ""], ["Poll", "Erik", ""], ["Visser", "Joost", ""]]}, {"id": "2008.05248", "submitter": "Thomas Kehrenberg", "authors": "Thomas Kehrenberg, Myles Bartlett, Oliver Thomas, Novi Quadrianto", "title": "Null-sampling for Interpretable and Fair Representations", "comments": "Published as a conference paper at the 16th European Conference on\n  Computer Vision (ECCV), Glasgow, UK, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to learn invariant representations, in the data domain, to achieve\ninterpretability in algorithmic fairness. Invariance implies a selectivity for\nhigh level, relevant correlations w.r.t. class label annotations, and a\nrobustness to irrelevant correlations with protected characteristics such as\nrace or gender. We introduce a non-trivial setup in which the training set\nexhibits a strong bias such that class label annotations are irrelevant and\nspurious correlations cannot be distinguished. To address this problem, we\nintroduce an adversarially trained model with a null-sampling procedure to\nproduce invariant representations in the data domain. To enable\ndisentanglement, a partially-labelled representative set is used. By placing\nthe representations into the data domain, the changes made by the model are\neasily examinable by human auditors. We show the effectiveness of our method on\nboth image and tabular datasets: Coloured MNIST, the CelebA and the Adult\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:49:01 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kehrenberg", "Thomas", ""], ["Bartlett", "Myles", ""], ["Thomas", "Oliver", ""], ["Quadrianto", "Novi", ""]]}, {"id": "2008.05341", "submitter": "Shuyang Ling", "authors": "Shuyang Ling", "title": "Near-Optimal Performance Bounds for Orthogonal and Permutation Group\n  Synchronization via Spectral Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group synchronization asks to recover group elements from their pairwise\nmeasurements. It has found numerous applications across various scientific\ndisciplines. In this work, we focus on orthogonal and permutation group\nsynchronization which are widely used in computer vision such as object\nmatching and Structure from Motion. Among many available approaches, spectral\nmethods have enjoyed great popularity due to its efficiency and convenience. We\nwill study the performance guarantees of spectral methods in solving these two\nsynchronization problems by investigating how well the computed eigenvectors\napproximate each group element individually. We establish our theory by\napplying the recent popular~\\emph{leave-one-out} technique and derive\na~\\emph{block-wise} performance bound for the recovery of each group element\nvia eigenvectors. In particular, for orthogonal group synchronization, we\nobtain a near-optimal performance bound for the group recovery in presence of\nGaussian noise. For permutation group synchronization under random corruption,\nwe show that the widely-used two-step procedure (spectral method plus rounding)\ncan recover all the group elements exactly if the SNR (signal-to-noise ratio)\nis close to the information theoretical limit. Our numerical experiments\nconfirm our theory and indicate a sharp phase transition for the exact group\nrecovery.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:20:16 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:44:22 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ling", "Shuyang", ""]]}, {"id": "2008.05367", "submitter": "Wei Deng", "authors": "Wei Deng, Qi Feng, Liyao Gao, Faming Liang, Guang Lin", "title": "Non-convex Learning via Replica Exchange Stochastic Gradient MCMC", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replica exchange Monte Carlo (reMC), also known as parallel tempering, is an\nimportant technique for accelerating the convergence of the conventional Markov\nChain Monte Carlo (MCMC) algorithms. However, such a method requires the\nevaluation of the energy function based on the full dataset and is not scalable\nto big data. The na\\\"ive implementation of reMC in mini-batch settings\nintroduces large biases, which cannot be directly extended to the stochastic\ngradient MCMC (SGMCMC), the standard sampling method for simulating from deep\nneural networks (DNNs). In this paper, we propose an adaptive replica exchange\nSGMCMC (reSGMCMC) to automatically correct the bias and study the corresponding\nproperties. The analysis implies an acceleration-accuracy trade-off in the\nnumerical discretization of a Markov jump process in a stochastic environment.\nEmpirically, we test the algorithm through extensive experiments on various\nsetups and obtain the state-of-the-art results on CIFAR10, CIFAR100, and SVHN\nin both supervised learning and semi-supervised learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:02:59 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 02:28:35 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 15:55:25 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Deng", "Wei", ""], ["Feng", "Qi", ""], ["Gao", "Liyao", ""], ["Liang", "Faming", ""], ["Lin", "Guang", ""]]}, {"id": "2008.05427", "submitter": "Kostas Kolomvatsos", "authors": "Kostas Kolomvatsos, Christos Anagnostopoulos", "title": "An Intelligent Edge-Centric Queries Allocation Scheme based on Ensemble\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Internet of Things (IoT) and Edge Computing (EC) can\nassist in the delivery of novel applications that will facilitate end users\nactivities. Data collected by numerous devices present in the IoT\ninfrastructure can be hosted into a set of EC nodes becoming the subject of\nprocessing tasks for the provision of analytics. Analytics are derived as the\nresult of various queries defined by end users or applications. Such queries\ncan be executed in the available EC nodes to limit the latency in the provision\nof responses. In this paper, we propose a meta-ensemble learning scheme that\nsupports the decision making for the allocation of queries to the appropriate\nEC nodes. Our learning model decides over queries' and nodes' characteristics.\nWe provide the description of a matching process between queries and nodes\nafter concluding the contextual information for each envisioned characteristic\nadopted in our meta-ensemble scheme. We rely on widely known ensemble models,\ncombine them and offer an additional processing layer to increase the\nperformance. The aim is to result a subset of EC nodes that will host each\nincoming query. Apart from the description of the proposed model, we report on\nits evaluation and the corresponding results. Through a large set of\nexperiments and a numerical analysis, we aim at revealing the pros and cons of\nthe proposed scheme.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:32:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kolomvatsos", "Kostas", ""], ["Anagnostopoulos", "Christos", ""]]}, {"id": "2008.05437", "submitter": "Meraj Hashemizadeh", "authors": "Meraj Hashemizadeh and Michelle Liu and Jacob Miller and Guillaume\n  Rabusseau", "title": "Adaptive Learning of Tensor Network Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor Networks (TN) offer a powerful framework to efficiently represent very\nhigh-dimensional objects. TN have recently shown their potential for machine\nlearning applications and offer a unifying view of common tensor decomposition\nmodels such as Tucker, tensor train (TT) and tensor ring (TR). However,\nidentifying the best tensor network structure from data for a given task is\nchallenging. In this work, we leverage the TN formalism to develop a generic\nand efficient adaptive algorithm to jointly learn the structure and the\nparameters of a TN from data. Our method is based on a simple greedy approach\nstarting from a rank one tensor and successively identifying the most promising\ntensor network edges for small rank increments. Our algorithm can adaptively\nidentify TN structures with small number of parameters that effectively\noptimize any differentiable objective function. Experiments on tensor\ndecomposition, tensor completion and model compression tasks demonstrate the\neffectiveness of the proposed algorithm. In particular, our method outperforms\nthe state-of-the-art evolutionary topology search [Li and Sun, 2020] for tensor\ndecomposition of images (while being orders of magnitude faster) and finds\nefficient tensor network structures to compress neural networks outperforming\npopular TT based approaches [Novikov et al., 2015].\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:41:56 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 18:46:43 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Hashemizadeh", "Meraj", ""], ["Liu", "Michelle", ""], ["Miller", "Jacob", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2008.05454", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammad Esmaeilpour, Raymel Alfonso Sallo, Olivier St-Georges,\n  Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Improving Stability of LS-GANs for Audio and Speech Signals", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the instability issue of generative adversarial\nnetwork (GAN) by proposing a new similarity metric in unitary space of Schur\ndecomposition for 2D representations of audio and speech signals. We show that\nencoding departure from normality computed in this vector space into the\ngenerator optimization formulation helps to craft more comprehensive\nspectrograms. We demonstrate the effectiveness of binding this metric for\nenhancing stability in training with less mode collapse compared to baseline\nGANs. Experimental results on subsets of UrbanSound8k and Mozilla common voice\ndatasets have shown considerable improvements on the quality of the generated\nsamples measured by the Fr\\'echet inception distance. Moreover, reconstructed\nsignals from these samples, have achieved higher signal to noise ratio compared\nto regular LS-GANs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:41:25 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Sallo", "Raymel Alfonso", ""], ["St-Georges", "Olivier", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "2008.05456", "submitter": "Gurtej Kanwar", "authors": "Denis Boyda, Gurtej Kanwar, S\\'ebastien Racani\\`ere, Danilo Jimenez\n  Rezende, Michael S. Albergo, Kyle Cranmer, Daniel C. Hackett, Phiala E.\n  Shanahan", "title": "Sampling using $SU(N)$ gauge equivariant flows", "comments": "24 pages, 19 figures", "journal-ref": "Phys. Rev. D 103, 074504 (2021)", "doi": "10.1103/PhysRevD.103.074504", "report-no": "MIT-CTP/5228", "categories": "hep-lat cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a flow-based sampling algorithm for $SU(N)$ lattice gauge theories\nthat is gauge-invariant by construction. Our key contribution is constructing a\nclass of flows on an $SU(N)$ variable (or on a $U(N)$ variable by a simple\nalternative) that respect matrix conjugation symmetry. We apply this technique\nto sample distributions of single $SU(N)$ variables and to construct flow-based\nsamplers for $SU(2)$ and $SU(3)$ lattice gauge theory in two dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:43:39 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 18:39:15 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Boyda", "Denis", ""], ["Kanwar", "Gurtej", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Rezende", "Danilo Jimenez", ""], ["Albergo", "Michael S.", ""], ["Cranmer", "Kyle", ""], ["Hackett", "Daniel C.", ""], ["Shanahan", "Phiala E.", ""]]}, {"id": "2008.05459", "submitter": "Jun Qi", "authors": "Jun Qi, Jun Du, Sabato Marco Siniscalchi, Xiaoli Ma, Chin-Hui Lee", "title": "Analyzing Upper Bounds on Mean Absolute Errors for Deep Neural Network\n  Based Vector-to-Vector Regression", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, Vol 68, pp. 3411-3422,\n  2020", "doi": "10.1109/TSP.2020.2993164", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that, in vector-to-vector regression utilizing deep\nneural networks (DNNs), a generalized loss of mean absolute error (MAE) between\nthe predicted and expected feature vectors is upper bounded by the sum of an\napproximation error, an estimation error, and an optimization error. Leveraging\nupon error decomposition techniques in statistical learning theory and\nnon-convex optimization theory, we derive upper bounds for each of the three\naforementioned errors and impose necessary constraints on DNN models. Moreover,\nwe assess our theoretical results through a set of image de-noising and speech\nenhancement experiments. Our proposed upper bounds of MAE for DNN based\nvector-to-vector regression are corroborated by the experimental results and\nthe upper bounds are valid with and without the \"over-parametrization\"\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:39:41 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qi", "Jun", ""], ["Du", "Jun", ""], ["Siniscalchi", "Sabato Marco", ""], ["Ma", "Xiaoli", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2008.05523", "submitter": "Paula Gradu", "authors": "Paula Gradu and John Hallman and Elad Hazan", "title": "Non-Stochastic Control with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of controlling a linear dynamical system with\nadversarial perturbations where the only feedback available to the controller\nis the scalar loss, and the loss function itself is unknown. For this problem,\nwith either a known or unknown system, we give an efficient sublinear regret\nalgorithm. The main algorithmic difficulty is the dependence of the loss on\npast controls. To overcome this issue, we propose an efficient algorithm for\nthe general setting of bandit convex optimization for loss functions with\nmemory, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:40:00 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gradu", "Paula", ""], ["Hallman", "John", ""], ["Hazan", "Elad", ""]]}, {"id": "2008.05533", "submitter": "Phillip Swazinna", "authors": "Phillip Swazinna, Steffen Udluft, Thomas Runkler", "title": "Overcoming Model Bias for Robust Offline Deep Reinforcement Learning", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence, Volume 104,\n  2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art reinforcement learning algorithms mostly rely on being\nallowed to directly interact with their environment to collect millions of\nobservations. This makes it hard to transfer their success to industrial\ncontrol problems, where simulations are often very costly or do not exist, and\nexploring in the real environment can potentially lead to catastrophic events.\nRecently developed, model-free, offline RL algorithms, can learn from a single\ndataset (containing limited exploration) by mitigating extrapolation error in\nvalue functions. However, the robustness of the training process is still\ncomparatively low, a problem known from methods using value functions. To\nimprove robustness and stability of the learning process, we use dynamics\nmodels to assess policy performance instead of value functions, resulting in\nMOOSE (MOdel-based Offline policy Search with Ensembles), an algorithm which\nensures low model bias by keeping the policy within the support of the data. We\ncompare MOOSE with state-of-the-art model-free, offline RL algorithms { BRAC,}\nBEAR and BCQ on the Industrial Benchmark and MuJoCo continuous control tasks in\nterms of robust performance, and find that MOOSE outperforms its model-free\ncounterparts in almost all considered cases, often even by far.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:08:55 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 12:22:38 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 14:27:51 GMT"}, {"version": "v4", "created": "Thu, 22 Jul 2021 13:43:12 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Swazinna", "Phillip", ""], ["Udluft", "Steffen", ""], ["Runkler", "Thomas", ""]]}, {"id": "2008.05552", "submitter": "Martin J{\\o}rgensen", "authors": "Martin J{\\o}rgensen and S{\\o}ren Hauberg", "title": "Reparametrization Invariance in non-parametric Causal Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery estimates the underlying physical process that generates the\nobserved data: does X cause Y or does Y cause X? Current methodologies use\nstructural conditions to turn the causal query into a statistical query, when\nonly observational data is available. But what if these statistical queries are\nsensitive to causal invariants? This study investigates one such invariant: the\ncausal relationship between X and Y is invariant to the marginal distributions\nof X and Y. We propose an algorithm that uses a non-parametric estimator that\nis robust to changes in the marginal distributions. This way we may marginalize\nthe marginals, and inspect what relationship is intrinsically there. The\nresulting causal estimator is competitive with current methodologies and has\nhigh emphasis on the uncertainty in the causal query; an aspect just as\nimportant as the query itself.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:00:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["J\u00f8rgensen", "Martin", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2008.05556", "submitter": "Gabriel Dulac-Arnold", "authors": "Arthur Argenson, Gabriel Dulac-Arnold", "title": "Model-Based Offline Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline learning is a key part of making reinforcement learning (RL) useable\nin real systems. Offline RL looks at scenarios where there is data from a\nsystem's operation, but no direct access to the system when learning a policy.\nRecent work on training RL policies from offline data has shown results both\nwith model-free policies learned directly from the data, or with planning on\ntop of learnt models of the data. Model-free policies tend to be more\nperformant, but are more opaque, harder to command externally, and less easy to\nintegrate into larger systems. We propose an offline learner that generates a\nmodel that can be used to control the system directly through planning. This\nallows us to have easily controllable policies directly from data, without ever\ninteracting with the system. We show the performance of our algorithm,\nModel-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and\ndemonstrate its ability leverage planning to respect environmental constraints.\nWe are able to find near-optimal polices for certain simulated systems from as\nlittle as 50 seconds of real-time system interaction, and create zero-shot\ngoal-conditioned policies on a series of environments. An accompanying video\ncan be found here: https://youtu.be/nxGGHdZOFts\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:06:52 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 16:41:47 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 17:22:51 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Argenson", "Arthur", ""], ["Dulac-Arnold", "Gabriel", ""]]}, {"id": "2008.05587", "submitter": "Corentin Lonjarret", "authors": "Corentin Lonjarret, Roch Auburtin, C\\'eline Robardet and Marc\n  Plantevit", "title": "Sequential recommendation with metric models based on frequent sequences", "comments": "25 pages, 6 figures, submitted to DAMI (under review)", "journal-ref": "Data Min Knowl Disc (2021)", "doi": "10.1007/s10618-021-00744-w", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling user preferences (long-term history) and user dynamics (short-term\nhistory) is of greatest importance to build efficient sequential recommender\nsystems. The challenge lies in the successful combination of the whole user's\nhistory and his recent actions (sequential dynamics) to provide personalized\nrecommendations. Existing methods capture the sequential dynamics of a user\nusing fixed-order Markov chains (usually first order chains) regardless of the\nuser, which limits both the impact of the past of the user on the\nrecommendation and the ability to adapt its length to the user profile. In this\narticle, we propose to use frequent sequences to identify the most relevant\npart of the user history for the recommendation. The most salient items are\nthen used in a unified metric model that embeds items based on user preferences\nand sequential dynamics. Extensive experiments demonstrate that our method\noutperforms state-of-the-art, especially on sparse datasets. We show that\nconsidering sequences of varying lengths improves the recommendations and we\nalso emphasize that these sequences provide explanations on the recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:08:04 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Lonjarret", "Corentin", ""], ["Auburtin", "Roch", ""], ["Robardet", "C\u00e9line", ""], ["Plantevit", "Marc", ""]]}, {"id": "2008.05621", "submitter": "Chao Ma", "authors": "Chao Ma, Lei Wu, Weinan E", "title": "The Slow Deterioration of the Generalization Error of the Random Feature\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random feature model exhibits a kind of resonance behavior when the\nnumber of parameters is close to the training sample size. This behavior is\ncharacterized by the appearance of large generalization gap, and is due to the\noccurrence of very small eigenvalues for the associated Gram matrix. In this\npaper, we examine the dynamic behavior of the gradient descent algorithm in\nthis regime. We show, both theoretically and experimentally, that there is a\ndynamic self-correction mechanism at work: The larger the eventual\ngeneralization gap, the slower it develops, both because of the small\neigenvalues. This gives us ample time to stop the training process and obtain\nsolutions with good generalization property.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 00:35:49 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ma", "Chao", ""], ["Wu", "Lei", ""], ["E", "Weinan", ""]]}, {"id": "2008.05660", "submitter": "Nathan Gavenski", "authors": "Nathan Gavenski and Juarez Monteiro and Roger Granada and Felipe\n  Meneguzzi and Rodrigo C. Barros", "title": "Imitating Unknown Policies via Exploration", "comments": "This paper has been accepted in the British Machine Vision Virtual\n  Conference (BMVC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral cloning is an imitation learning technique that teaches an agent\nhow to behave through expert demonstrations. Recent approaches use\nself-supervision of fully-observable unlabeled snapshots of the states to\ndecode state-pairs into actions. However, the iterative learning scheme from\nthese techniques are prone to getting stuck into bad local minima. We address\nthese limitations incorporating a two-phase model into the original framework,\nwhich learns from unlabeled observations via exploration, substantially\nimproving traditional behavioral cloning by exploiting (i) a sampling mechanism\nto prevent bad local minima, (ii) a sampling mechanism to improve exploration,\nand (iii) self-attention modules to capture global features. The resulting\ntechnique outperforms the previous state-of-the-art in four different\nenvironments by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:03:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gavenski", "Nathan", ""], ["Monteiro", "Juarez", ""], ["Granada", "Roger", ""], ["Meneguzzi", "Felipe", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "2008.05687", "submitter": "Weituo Hao", "authors": "Weituo Hao, Nikhil Mehta, Kevin J Liang, Pengyu Cheng, Mostafa\n  El-Khamy, Lawrence Carin", "title": "WAFFLe: Weight Anonymized Factorization for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domains where data are sensitive or private, there is great value in\nmethods that can learn in a distributed manner without the data ever leaving\nthe local devices. In light of this need, federated learning has emerged as a\npopular training paradigm. However, many federated learning approaches trade\ntransmitting data for communicating updated weight parameters for each local\ndevice. Therefore, a successful breach that would have otherwise directly\ncompromised the data instead grants whitebox access to the local model, which\nopens the door to a number of attacks, including exposing the very data\nfederated learning seeks to protect. Additionally, in distributed scenarios,\nindividual client devices commonly exhibit high statistical heterogeneity. Many\ncommon federated approaches learn a single global model; while this may do well\non average, performance degrades when the i.i.d. assumption is violated,\nunderfitting individuals further from the mean, and raising questions of\nfairness. To address these issues, we propose Weight Anonymized Factorization\nfor Federated Learning (WAFFLe), an approach that combines the Indian Buffet\nProcess with a shared dictionary of weight factors for neural networks.\nExperiments on MNIST, FashionMNIST, and CIFAR-10 demonstrate WAFFLe's\nsignificant improvement to local test performance and fairness while\nsimultaneously providing an extra layer of security.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 04:26:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hao", "Weituo", ""], ["Mehta", "Nikhil", ""], ["Liang", "Kevin J", ""], ["Cheng", "Pengyu", ""], ["El-Khamy", "Mostafa", ""], ["Carin", "Lawrence", ""]]}, {"id": "2008.05753", "submitter": "Jong Chul Ye", "authors": "Jawook Gu, Jong Chul Ye", "title": "AdaIN-Switchable CycleGAN for Efficient Unsupervised Low-Dose CT\n  Denoising", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recently, deep learning approaches have been extensively studied for low-dose\nCT denoising thanks to its superior performance despite the fast computational\ntime. In particular, cycleGAN has been demonstrated as a powerful unsupervised\nlearning scheme to improve the low-dose CT image quality without requiring\nmatched high-dose reference data. Unfortunately, one of the main limitations of\nthe cycleGAN approach is that it requires two deep neural network generators at\nthe training phase, although only one of them is used at the inference phase.\nThe secondary auxiliary generator is needed to enforce the cycle-consistency,\nbut the additional memory requirement and increases of the learnable parameters\nare the main huddles for cycleGAN training. To address this issue, here we\npropose a novel cycleGAN architecture using a single switchable generator. In\nparticular, a single generator is implemented using adaptive instance\nnormalization (AdaIN) layers so that the baseline generator converting a\nlow-dose CT image to a routine-dose CT image can be switched to a generator\nconverting high-dose to low-dose by simply changing the AdaIN code. Thanks to\nthe shared baseline network, the additional memory requirement and weight\nincreases are minimized, and the training can be done more stably even with\nsmall training data. Experimental results show that the proposed method\noutperforms the previous cycleGAN approaches while using only about half the\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:30:23 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gu", "Jawook", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.05756", "submitter": "Enrico Bagli", "authors": "Margherita Grandini, Enrico Bagli, Giorgio Visani", "title": "Metrics for Multi-Class Classification: an Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification tasks in machine learning involving more than two classes are\nknown by the name of \"multi-class classification\". Performance indicators are\nvery useful when the aim is to evaluate and compare different classification\nmodels or machine learning techniques. Many metrics come in handy to test the\nability of a multi-class classifier. Those metrics turn out to be useful at\ndifferent stage of the development process, e.g. comparing the performance of\ntwo different models or analysing the behaviour of the same model by tuning\ndifferent parameters. In this white paper we review a list of the most\npromising multi-class metrics, we highlight their advantages and disadvantages\nand show their possible usages during the development of a classification\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:41:44 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Grandini", "Margherita", ""], ["Bagli", "Enrico", ""], ["Visani", "Giorgio", ""]]}, {"id": "2008.05767", "submitter": "Jihun Oh", "authors": "Jihun Oh, SangJeong Lee, Meejeong Park, Pooni Walagaurav and Kiseok\n  Kwon", "title": "Weight Equalizing Shift Scaler-Coupled Post-training Quantization", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-training, layer-wise quantization is preferable because it is free from\nretraining and is hardware-friendly. Nevertheless, accuracy degradation has\noccurred when a neural network model has a big difference of per-out-channel\nweight ranges. In particular, the MobileNet family has a tragedy drop in top-1\naccuracy from 70.60% ~ 71.87% to 0.1% on the ImageNet dataset after 8-bit\nweight quantization. To mitigate this significant accuracy reduction, we\npropose a new weight equalizing shift scaler, i.e. rescaling the weight range\nper channel by a 4-bit binary shift, prior to a layer-wise quantization. To\nrecover the original output range, inverse binary shifting is efficiently fused\nto the existing per-layer scale compounding in the fixed-computing\nconvolutional operator of the custom neural processing unit. The binary shift\nis a key feature of our algorithm, which significantly improved the accuracy\nperformance without impeding the memory footprint. As a result, our proposed\nmethod achieved a top-1 accuracy of 69.78% ~ 70.96% in MobileNets and showed\nrobust performance in varying network models and tasks, which is competitive to\nchannel-wise quantization results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:19:57 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Oh", "Jihun", ""], ["Lee", "SangJeong", ""], ["Park", "Meejeong", ""], ["Walagaurav", "Pooni", ""], ["Kwon", "Kiseok", ""]]}, {"id": "2008.05772", "submitter": "Jong Chul Ye", "authors": "Boah Kim, Dong Hwan Kim, Seong Ho Park, Jieun Kim, June-Goo Lee, Jong\n  Chul Ye", "title": "CycleMorph: Cycle Consistent Unsupervised Deformable Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is a fundamental task in medical image analysis. Recently,\ndeep learning based image registration methods have been extensively\ninvestigated due to their excellent performance despite the ultra-fast\ncomputational time. However, the existing deep learning methods still have\nlimitation in the preservation of original topology during the deformation with\nregistration vector fields. To address this issues, here we present a\ncycle-consistent deformable image registration. The cycle consistency enhances\nimage registration performance by providing an implicit regularization to\npreserve topology during the deformation. The proposed method is so flexible\nthat can be applied for both 2D and 3D registration problems for various\napplications, and can be easily extended to multi-scale implementation to deal\nwith the memory issues in large volume registration. Experimental results on\nvarious datasets from medical and non-medical applications demonstrate that the\nproposed method provides effective and accurate registration on diverse image\npairs within a few seconds. Qualitative and quantitative evaluations on\ndeformation fields also verify the effectiveness of the cycle consistency of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:30:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Kim", "Boah", ""], ["Kim", "Dong Hwan", ""], ["Park", "Seong Ho", ""], ["Kim", "Jieun", ""], ["Lee", "June-Goo", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.05788", "submitter": "Erik Scharw\\\"achter", "authors": "Erik Scharw\\\"achter and Emmanuel M\\\"uller", "title": "Statistical Evaluation of Anomaly Detectors for Sequences", "comments": "5 pages, 6 figures, accepted at the 6th KDD Workshop on Mining and\n  Learning from Time Series (KDD MiLeTS 2020), source code available at\n  https://github.com/diozaka/anomaly-eval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although precision and recall are standard performance measures for anomaly\ndetection, their statistical properties in sequential detection settings are\npoorly understood. In this work, we formalize a notion of precision and recall\nwith temporal tolerance for point-based anomaly detection in sequential data.\nThese measures are based on time-tolerant confusion matrices that may be used\nto compute time-tolerant variants of many other standard measures. However,\ncare has to be taken to preserve interpretability. We perform a statistical\nsimulation study to demonstrate that precision and recall may overestimate the\nperformance of a detector, when computed with temporal tolerance. To alleviate\nthis problem, we show how to obtain null distributions for the two measures to\nassess the statistical significance of reported results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:07:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Scharw\u00e4chter", "Erik", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "2008.05803", "submitter": "Joao Marques-Silva", "authors": "Joao Marques-Silva, Thomas Gerspacher, Martin C. Cooper, Alexey\n  Ignatiev, Nina Narodytska", "title": "Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time\n  and Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work proposed the computation of so-called PI-explanations of Naive\nBayes Classifiers (NBCs). PI-explanations are subset-minimal sets of\nfeature-value pairs that are sufficient for the prediction, and have been\ncomputed with state-of-the-art exact algorithms that are worst-case exponential\nin time and space. In contrast, we show that the computation of one\nPI-explanation for an NBC can be achieved in log-linear time, and that the same\nresult also applies to the more general class of linear classifiers.\nFurthermore, we show that the enumeration of PI-explanations can be obtained\nwith polynomial delay. Experimental results demonstrate the performance gains\nof the new algorithms when compared with earlier work. The experimental results\nalso investigate ways to measure the quality of heuristic explanations\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:25:30 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 09:48:14 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Gerspacher", "Thomas", ""], ["Cooper", "Martin C.", ""], ["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""]]}, {"id": "2008.05808", "submitter": "Yuyan Wang", "authors": "Yuyan Wang, Zhe Zhao, Bo Dai, Christopher Fifty, Dong Lin, Lichan\n  Hong, Ed H. Chi", "title": "Small Towers Make Big Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning aims at solving multiple machine learning tasks at the\nsame time. A good solution to a multi-task learning problem should be\ngeneralizable in addition to being Pareto optimal. In this paper, we provide\nsome insights on understanding the trade-off between Pareto efficiency and\ngeneralization as a result of parameterization in multi-task deep learning\nmodels. As a multi-objective optimization problem, enough parameterization is\nneeded for handling task conflicts in a constrained solution space; however,\nfrom a multi-task generalization perspective, over-parameterization undermines\nthe benefit of learning a shared representation which helps harder tasks or\ntasks with limited training examples. A delicate balance between multi-task\ngeneralization and multi-objective optimization is therefore needed for finding\na better trade-off between efficiency and generalization. To this end, we\npropose a method of under-parameterized self-auxiliaries for multi-task models\nto achieve the best of both worlds. It is task-agnostic and works with other\nmulti-task learning algorithms. Empirical results show that small towers of\nunder-parameterized self-auxiliaries can make big differences in improving\nPareto efficiency in various multi-task applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:45:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Yuyan", ""], ["Zhao", "Zhe", ""], ["Dai", "Bo", ""], ["Fifty", "Christopher", ""], ["Lin", "Dong", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""]]}, {"id": "2008.05823", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Training Faster with Compressed Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the distributed machine learning methods show the potential for the\nspeed-up of training large deep neural networks, the communication cost has\nbeen the notorious bottleneck to constrain the performance. To address this\nchallenge, the gradient compression based communication-efficient distributed\nlearning methods were designed to reduce the communication cost, and more\nrecently the local error feedback was incorporated to compensate for the\nperformance loss. However, in this paper, we will show the \"gradient mismatch\"\nproblem of the local error feedback in centralized distributed training and\nthis issue can lead to degraded performance compared with full-precision\ntraining. To solve this critical problem, we propose two novel techniques: 1)\nstep ahead; 2) error averaging. Both our theoretical and empirical results show\nthat our new methods can alleviate the \"gradient mismatch\" problem. Experiments\nshow that we can even train \\textbf{faster with compressed gradient} than\nfull-precision training \\textbf{regarding training epochs}.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:21:07 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "2008.05825", "submitter": "Thorsten Gl\\\"usenkamp", "authors": "Thorsten Gl\\\"usenkamp", "title": "Unifying supervised learning and VAEs -- automating statistical\n  inference in high-energy physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.HE astro-ph.IM hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A KL-divergence objective of the joint distribution of data and labels allows\nto unify supervised learning, variational autoencoders (VAEs) and\nsemi-supervised learning under one umbrella of variational inference. This\nviewpoint has several advantages. For VAEs, it clarifies the interpretation of\nencoder and decoder parts. For supervised learning, it re-iterates that the\ntraining procedure approximates the true posterior over labels and can always\nbe viewed as approximate likelihood-free inference. This is typically not\ndiscussed, even though the derivation is well-known in the literature. In the\ncontext of semi-supervised learning it motivates an extended supervised scheme\nwhich allows to calculate a goodness-of-fit p-value using posterior predictive\nsimulations. Flow-based networks with a standard normal base distribution are\ncrucial. We discuss how they allow to rigorously define coverage for arbitrary\njoint posteriors on $\\mathbb{R}^n \\times \\mathcal{S}^m$, which encompasses\nposteriors over directions. Finally, systematic uncertainties are naturally\nincluded in the variational viewpoint. With the three ingredients of (1)\nsystematics, (2) coverage and (3) goodness-of-fit, flow-based neural networks\nhave the potential to replace a large part of the statistical toolbox of the\ncontemporary high-energy physicist.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:28:57 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:27:11 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gl\u00fcsenkamp", "Thorsten", ""]]}, {"id": "2008.05859", "submitter": "Luciano Sbaiz", "authors": "Thomas Fischbacher and Luciano Sbaiz", "title": "Single-Photon Image Classification", "comments": "See ancillary files for training code and pre-trained models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing-based machine learning mainly focuses on quantum computing\nhardware that is experimentally challenging to realize due to requiring quantum\ngates that operate at very low temperature. Instead, we demonstrate the\nexistence of a lower performance and much lower effort island on the\naccuracy-vs-qubits graph that may well be experimentally accessible with room\ntemperature optics. This high temperature \"quantum computing toy model\" is\nnevertheless interesting to study as it allows rather accessible explanations\nof key concepts in quantum computing, in particular interference, entanglement,\nand the measurement process.\n  We specifically study the problem of classifying an example from the MNIST\nand Fashion-MNIST datasets, subject to the constraint that we have to make a\nprediction after the detection of the very first photon that passed a\ncoherently illuminated filter showing the example. Whereas a classical set-up\nin which a photon is detected after falling on one of the $28\\times 28$ image\npixels is limited to a (maximum likelihood estimation) accuracy of $21.27\\%$\nfor MNIST, respectively $18.27\\%$ for Fashion-MNIST, we show that the\ntheoretically achievable accuracy when exploiting inference by optically\ntransforming the quantum state of the photon is at least $41.27\\%$ for MNIST,\nrespectively $36.14\\%$ for Fashion-MNIST.\n  We show in detail how to train the corresponding transformation with\nTensorFlow and also explain how this example can serve as a teaching tool for\nthe measurement process in quantum mechanics.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:37:21 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 14:23:07 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Fischbacher", "Thomas", ""], ["Sbaiz", "Luciano", ""]]}, {"id": "2008.05903", "submitter": "Stefan Klus", "authors": "Kateryna Melnyk, Stefan Klus, Gr\\'egoire Montavon, Tim Conrad", "title": "GraphKKE: Graph Kernel Koopman Embedding for Human Microbiome Analysis", "comments": null, "journal-ref": null, "doi": "10.1007/s41109-020-00339-2", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more diseases have been found to be strongly correlated with\ndisturbances in the microbiome constitution, e.g., obesity, diabetes, or some\ncancer types. Thanks to modern high-throughput omics technologies, it becomes\npossible to directly analyze human microbiome and its influence on the health\nstatus. Microbial communities are monitored over long periods of time and the\nassociations between their members are explored. These relationships can be\ndescribed by a time-evolving graph. In order to understand responses of the\nmicrobial community members to a distinct range of perturbations such as\nantibiotics exposure or diseases and general dynamical properties, the\ntime-evolving graph of the human microbial communities has to be analyzed. This\nbecomes especially challenging due to dozens of complex interactions among\nmicrobes and metastable dynamics. The key to solving this problem is the\nrepresentation of the time-evolving graphs as fixed-length feature vectors\npreserving the original dynamics. We propose a method for learning the\nembedding of the time-evolving graph that is based on the spectral analysis of\ntransfer operators and graph kernels. We demonstrate that our method can\ncapture temporary changes in the time-evolving graph on both created synthetic\ndata and real-world data. Our experiments demonstrate the efficacy of the\nmethod. Furthermore, we show that our method can be applied to human microbiome\ndata to study dynamic processes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:57:02 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 09:35:33 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 12:06:13 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Melnyk", "Kateryna", ""], ["Klus", "Stefan", ""], ["Montavon", "Gr\u00e9goire", ""], ["Conrad", "Tim", ""]]}, {"id": "2008.05906", "submitter": "Md Fahimuzzman Sohan", "authors": "Md Fahimuzzman Sohan", "title": "So You Need Datasets for Your COVID-19 Detection Research Using Machine\n  Learning?", "comments": "6 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of people are infected by the coronavirus disease 2019 (COVID19)\naround the world. Machine Learning (ML) techniques are being used for COVID19\ndetection research from the beginning of the epidemic. This article represents\nthe detailed information on frequently used datasets in COVID19 detection using\nMachine Learning (ML). We investigated 96 papers on COVID19 detection between\nJanuary 2020 and June 2020. We extracted the information about used datasets\nfrom the articles and represented them here simultaneously. This investigation\nwill help future researchers to find the COVID19 datasets without difficulty.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:25:09 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 09:21:10 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sohan", "Md Fahimuzzman", ""]]}, {"id": "2008.05912", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "A statistical theory of cold posteriors in deep neural networks", "comments": "Published at ICLR 2021 (https://openreview.net/forum?id=Rd138pWXMvG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To get Bayesian neural networks to perform comparably to standard neural\nnetworks it is usually necessary to artificially reduce uncertainty using a\n\"tempered\" or \"cold\" posterior. This is extremely concerning: if the prior is\naccurate, Bayes inference/decision theory is optimal, and any artificial\nchanges to the posterior should harm performance. While this suggests that the\nprior may be at fault, here we argue that in fact, BNNs for image\nclassification use the wrong likelihood. In particular, standard image\nbenchmark datasets such as CIFAR-10 are carefully curated. We develop a\ngenerative model describing curation which gives a principled Bayesian account\nof cold posteriors, because the likelihood under this new generative model\nclosely matches the tempered likelihoods used in past work.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 13:46:58 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 14:33:30 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "2008.05913", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "A statistical theory of semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We currently lack a solid statistical understanding of semi-supervised\nlearning methods, instead treating them as a collection of highly effective\ntricks. This precludes the principled combination e.g. of Bayesian methods and\nsemi-supervised learning, as semi-supervised learning objectives are not\ncurrently formulated as likelihoods for an underlying generative model of the\ndata. Here, we note that standard image benchmark datasets such as CIFAR-10 are\ncarefully curated, and we provide a generative model describing the curation\nprocess. Under this generative model, several state-of-the-art semi-supervised\nlearning techniques, including entropy minimization, pseudo-labelling and the\nFixMatch family emerge naturally as variational lower-bounds on the\nlog-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 13:50:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "2008.05926", "submitter": "Berent {\\AA}nund Str{\\o}mnes Lunde", "authors": "Berent {\\AA}nund Str{\\o}mnes Lunde, Tore Selland Kleppe, Hans Julius\n  Skaug", "title": "An information criterion for automatic gradient tree boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An information theoretic approach to learning the complexity of\nclassification and regression trees and the number of trees in gradient tree\nboosting is proposed. The optimism (test loss minus training loss) of the\ngreedy leaf splitting procedure is shown to be the maximum of a\nCox-Ingersoll-Ross process, from which a generalization-error based information\ncriterion is formed. The proposed procedure allows fast local model selection\nwithout cross validation based hyper parameter tuning, and hence efficient and\nautomatic comparison among the large number of models performed during each\nboosting iteration. Relative to xgboost, speedups on numerical experiments\nranges from around 10 to about 1400, at similar predictive-power measured in\nterms of test-loss.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:24:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Lunde", "Berent \u00c5nund Str\u00f8mnes", ""], ["Kleppe", "Tore Selland", ""], ["Skaug", "Hans Julius", ""]]}, {"id": "2008.05930", "submitter": "Sergio Casas", "authors": "Abbas Sadat, Sergio Casas, Mengye Ren, Xinyu Wu, Pranaab Dhawan,\n  Raquel Urtasun", "title": "Perceive, Predict, and Plan: Safe Motion Planning Through Interpretable\n  Semantic Representations", "comments": "European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel end-to-end learnable network that performs\njoint perception, prediction and motion planning for self-driving vehicles and\nproduces interpretable intermediate representations. Unlike existing neural\nmotion planners, our motion planning costs are consistent with our perception\nand prediction estimates. This is achieved by a novel differentiable semantic\noccupancy representation that is explicitly used as cost by the motion planning\nprocess. Our network is learned end-to-end from human demonstrations. The\nexperiments in a large-scale manual-driving dataset and closed-loop simulation\nshow that the proposed model significantly outperforms state-of-the-art\nplanners in imitating the human behaviors while producing much safer\ntrajectories.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:40:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Sadat", "Abbas", ""], ["Casas", "Sergio", ""], ["Ren", "Mengye", ""], ["Wu", "Xinyu", ""], ["Dhawan", "Pranaab", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2008.05952", "submitter": "Stephen Tu", "authors": "Nicholas M. Boffi and Stephen Tu and Nikolai Matni and Jean-Jacques E.\n  Slotine and Vikas Sindhwani", "title": "Learning Stability Certificates from Data", "comments": "Fixes an error in the statement and proof of Theorem 5.1, Theorem\n  5.2, and Proposition D.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing tools in nonlinear control theory for establishing stability or\nsafety of a dynamical system can be distilled to the construction of a\ncertificate function that guarantees a desired property. However, algorithms\nfor synthesizing certificate functions typically require a closed-form\nanalytical expression of the underlying dynamics, which rules out their use on\nmany modern robotic platforms. To circumvent this issue, we develop algorithms\nfor learning certificate functions only from trajectory data. We establish\nbounds on the generalization error - the probability that a certificate will\nnot certify a new, unseen trajectory - when learning from trajectories, and we\nconvert such generalization error bounds into global stability guarantees. We\ndemonstrate empirically that certificates for complex dynamics can be\nefficiently learned, and that the learned certificates can be used for\ndownstream tasks such as adaptive control.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:58:42 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:47:06 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Boffi", "Nicholas M.", ""], ["Tu", "Stephen", ""], ["Matni", "Nikolai", ""], ["Slotine", "Jean-Jacques E.", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "2008.05966", "submitter": "Manaar Alam", "authors": "Manaar Alam and Sayandeep Saha and Debdeep Mukhopadhyay and Sandip\n  Kundu", "title": "Deep-Lock: Secure Authorization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained Deep Neural Network (DNN) models are considered valuable Intellectual\nProperties (IP) in several business models. Prevention of IP theft and\nunauthorized usage of such DNN models has been raised as of significant concern\nby industry. In this paper, we address the problem of preventing unauthorized\nusage of DNN models by proposing a generic and lightweight key-based\nmodel-locking scheme, which ensures that a locked model functions correctly\nonly upon applying the correct secret key. The proposed scheme, known as\nDeep-Lock, utilizes S-Boxes with good security properties to encrypt each\nparameter of a trained DNN model with secret keys generated from a master key\nvia a key scheduling algorithm. The resulting dense network of encrypted\nweights is found robust against model fine-tuning attacks. Finally, Deep-Lock\ndoes not require any intervention in the structure and training of the DNN\nmodels, making it applicable for all existing software and hardware\nimplementations of DNN.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:22:49 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Alam", "Manaar", ""], ["Saha", "Sayandeep", ""], ["Mukhopadhyay", "Debdeep", ""], ["Kundu", "Sandip", ""]]}, {"id": "2008.05969", "submitter": "Tong Yang", "authors": "Tong Yang, Long Sha, Pengyu Hong", "title": "Variance Regularization for Accelerating Stochastic Optimization", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While nowadays most gradient-based optimization methods focus on exploring\nthe high-dimensional geometric features, the random error accumulated in a\nstochastic version of any algorithm implementation has not been stressed yet.\nIn this work, we propose a universal principle which reduces the random error\naccumulation by exploiting statistic information hidden in mini-batch\ngradients. This is achieved by regularizing the learning-rate according to\nmini-batch variances. Due to the complementarity of our perspective, this\nregularization could provide a further improvement for stochastic\nimplementation of generic 1st order approaches. With empirical results, we\ndemonstrated the variance regularization could speed up the convergence as well\nas stabilize the stochastic optimization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:34:01 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Yang", "Tong", ""], ["Sha", "Long", ""], ["Hong", "Pengyu", ""]]}, {"id": "2008.06006", "submitter": "Quan Wang", "authors": "Shaojin Ding, Ye Jia, Ke Hu, Quan Wang", "title": "Textual Echo Cancellation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Textual Echo Cancellation (TEC) - a framework for\ncancelling the text-to-speech (TTS) playback echo from overlapping speech\nrecordings. Such a system can largely improve speech recognition performance\nand user experience for intelligent devices such as smart speakers, as the user\ncan talk to the device while the device is still playing the TTS signal\nresponding to the previous query. We implement this system by using a novel\nsequence-to-sequence model with multi-source attention that takes both the\nmicrophone mixture signal and source text of the TTS playback as inputs, and\npredicts the enhanced audio. Experiments show that the textual information of\nthe TTS playback is critical to enhancement performance. Besides, the text\nsequence is much smaller in size compared with the raw acoustic signal of the\nTTS playback, and can be immediately transmitted to the device or ASR server\neven before the playback is synthesized. Therefore, our proposed approach\neffectively reduces Internet communication and latency compared with\nalternative approaches such as acoustic echo cancellation (AEC).\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:47:30 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:18:42 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 17:23:53 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ding", "Shaojin", ""], ["Jia", "Ye", ""], ["Hu", "Ke", ""], ["Wang", "Quan", ""]]}, {"id": "2008.06035", "submitter": "Srikrishna Karanam", "authors": "Meng Zheng and Srikrishna Karanam and Terrence Chen and Richard J.\n  Radke and Ziyan Wu", "title": "Towards Visually Explaining Similarity Models", "comments": "13 pages, 10 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1911.07381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of visually explaining similarity models, i.e.,\nexplaining why a model predicts two images to be similar in addition to\nproducing a scalar score. While much recent work in visual model\ninterpretability has focused on gradient-based attention, these methods rely on\na classification module to generate visual explanations. Consequently, they\ncannot readily explain other kinds of models that do not use or need\nclassification-like loss functions (e.g., similarity models trained with a\nmetric learning loss). In this work, we bridge this crucial gap, presenting a\nmethod to generate gradient-based visual attention for image similarity\npredictors. By relying solely on the learned feature embedding, we show that\nour approach can be applied to any kind of CNN-based similarity architecture,\nan important step towards generic visual explainability. We show that our\nresulting attention maps serve more than just interpretability; they can be\ninfused into the model learning process itself with new trainable constraints.\nWe show that the resulting similarity models perform, and can be visually\nexplained, better than the corresponding baseline models trained without these\nconstraints. We demonstrate our approach using extensive experiments on three\ndifferent kinds of tasks: generic image retrieval, person re-identification,\nand low-shot semantic segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:47:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 17:00:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Radke", "Richard J.", ""], ["Wu", "Ziyan", ""]]}, {"id": "2008.06036", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Nadav Merlis, Shie Mannor", "title": "Reinforcement Learning with Trajectory Feedback", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard feedback model of reinforcement learning requires revealing the\nreward of every visited state-action pair. However, in practice, it is often\nthe case that such frequent feedback is not available. In this work, we take a\nfirst step towards relaxing this assumption and require a weaker form of\nfeedback, which we refer to as \\emph{trajectory feedback}. Instead of observing\nthe reward obtained after every action, we assume we only receive a score that\nrepresents the quality of the whole trajectory observed by the agent, namely,\nthe sum of all rewards obtained over this trajectory. We extend reinforcement\nlearning algorithms to this setting, based on least-squares estimation of the\nunknown reward, for both the known and unknown transition model cases, and\nstudy the performance of these algorithms by analyzing their regret. For cases\nwhere the transition model is unknown, we offer a hybrid optimistic-Thompson\nSampling approach that results in a tractable algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:49:18 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 20:04:50 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Efroni", "Yonathan", ""], ["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "2008.06043", "submitter": "Eric A Mitchell", "authors": "Eric Mitchell, Rafael Rafailov, Xue Bin Peng, Sergey Levine, Chelsea\n  Finn", "title": "Offline Meta-Reinforcement Learning with Advantage Weighting", "comments": "ICML 2021; for code & project info, see\n  http://sites.google.com/view/macaw-metarl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the offline meta-reinforcement learning (offline\nmeta-RL) problem setting and proposes an algorithm that performs well in this\nsetting. Offline meta-RL is analogous to the widely successful supervised\nlearning strategy of pre-training a model on a large batch of fixed,\npre-collected data (possibly from various tasks) and fine-tuning the model to a\nnew task with relatively little data. That is, in offline meta-RL, we\nmeta-train on fixed, pre-collected data from several tasks in order to adapt to\na new task with a very small amount (less than 5 trajectories) of data from the\nnew task. By nature of being offline, algorithms for offline meta-RL can\nutilize the largest possible pool of training data available and eliminate\npotentially unsafe or costly data collection during meta-training. This setting\ninherits the challenges of offline RL, but it differs significantly because\noffline RL does not generally consider a) transfer to new tasks or b) limited\ndata from the test task, both of which we face in offline meta-RL. Targeting\nthe offline meta-RL setting, we propose Meta-Actor Critic with Advantage\nWeighting (MACAW), an optimization-based meta-learning algorithm that uses\nsimple, supervised regression objectives for both the inner and outer loop of\nmeta-training. On offline variants of common meta-RL benchmarks, we empirically\nfind that this approach enables fully offline meta-reinforcement learning and\nachieves notable gains over prior methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:35:24 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 17:33:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Mitchell", "Eric", ""], ["Rafailov", "Rafael", ""], ["Peng", "Xue Bin", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "2008.06081", "submitter": "Jiameng Fan", "authors": "Jiameng Fan, Wenchao Li", "title": "Adversarial Training and Provable Robustness: A Tale of Two Objectives", "comments": "Accepted at AAAI 2021", "journal-ref": "Vol. 35 No. 8: AAAI-2021 Technical Tracks 8", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a principled framework that combines adversarial training and\nprovable robustness verification for training certifiably robust neural\nnetworks. We formulate the training problem as a joint optimization problem\nwith both empirical and provable robustness objectives and develop a novel\ngradient-descent technique that can eliminate bias in stochastic\nmulti-gradients. We perform both theoretical analysis on the convergence of the\nproposed technique and experimental comparison with state-of-the-arts. Results\non MNIST and CIFAR-10 show that our method can consistently match or outperform\nprior approaches for provable l infinity robustness. Notably, we achieve 6.60%\nverified test error on MNIST at epsilon = 0.3, and 66.57% on CIFAR-10 with\nepsilon = 8/255.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:49:15 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:56:34 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 18:07:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Fan", "Jiameng", ""], ["Li", "Wenchao", ""]]}, {"id": "2008.06082", "submitter": "Usman Khan", "authors": "Muhammad I. Qureshi and Ran Xin and Soummya Kar and Usman A. Khan", "title": "Push-SAGA: A decentralized stochastic algorithm with variance reduction\n  over directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Push-SAGA, a decentralized stochastic first-order\nmethod for finite-sum minimization over a directed network of nodes. Push-SAGA\ncombines node-level variance reduction to remove the uncertainty caused by\nstochastic gradients, network-level gradient tracking to address the\ndistributed nature of the data, and push-sum consensus to tackle the challenge\nof directed communication links. We show that Push-SAGA achieves linear\nconvergence to the exact solution for smooth and strongly convex problems and\nis thus the first linearly-convergent stochastic algorithm over arbitrary\nstrongly connected directed graphs. We also characterize the regimes in which\nPush-SAGA achieves a linear speed-up compared to its centralized counterpart\nand achieves a network-independent convergence rate. We illustrate the behavior\nand convergence properties of Push-SAGA with the help of numerical experiments\non strongly convex and non-convex problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:52:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:46:52 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Qureshi", "Muhammad I.", ""], ["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2008.06110", "submitter": "Brian Hartman", "authors": "Marie-Pier Cote, Brian Hartman, Olivier Mercier, Joshua Meyers, Jared\n  Cummings, Elijah Harmon", "title": "Synthesizing Property & Casualty Ratemaking Datasets using Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to confidentiality issues, it can be difficult to access or share\ninteresting datasets for methodological development in actuarial science, or\nother fields where personal data are important. We show how to design three\ndifferent types of generative adversarial networks (GANs) that can build a\nsynthetic insurance dataset from a confidential original dataset. The goal is\nto obtain synthetic data that no longer contains sensitive information but\nstill has the same structure as the original dataset and retains the\nmultivariate relationships. In order to adequately model the specific\ncharacteristics of insurance data, we use GAN architectures adapted for\nmulti-categorical data: a Wassertein GAN with gradient penalty (MC-WGAN-GP), a\nconditional tabular GAN (CTGAN) and a Mixed Numerical and Categorical\nDifferentially Private GAN (MNCDP-GAN). For transparency, the approaches are\nillustrated using a public dataset, the French motor third party liability\ndata. We compare the three different GANs on various aspects: ability to\nreproduce the original data structure and predictive models, privacy, and ease\nof use. We find that the MC-WGAN-GP synthesizes the best data, the CTGAN is the\neasiest to use, and the MNCDP-GAN guarantees differential privacy.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 21:02:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Cote", "Marie-Pier", ""], ["Hartman", "Brian", ""], ["Mercier", "Olivier", ""], ["Meyers", "Joshua", ""], ["Cummings", "Jared", ""], ["Harmon", "Elijah", ""]]}, {"id": "2008.06120", "submitter": "Gabriel Bender", "authors": "Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang Cheng,\n  Pieter-Jan Kindermans, Quoc Le", "title": "Can weight sharing outperform random architecture search? An\n  investigation with TuNAS", "comments": "Published at CVPR 2020", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2020, pp. 14323-14332", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Neural Architecture Search methods based on weight sharing have\nshown good promise in democratizing Neural Architecture Search for computer\nvision models. There is, however, an ongoing debate whether these efficient\nmethods are significantly better than random search. Here we perform a thorough\ncomparison between efficient and random search methods on a family of\nprogressively larger and more challenging search spaces for image\nclassification and detection on ImageNet and COCO. While the efficacies of both\nmethods are problem-dependent, our experiments demonstrate that there are\nlarge, realistic tasks where efficient search methods can provide substantial\ngains over random search. In addition, we propose and evaluate techniques which\nimprove the quality of searched architectures and reduce the need for manual\nhyper-parameter tuning.\n  Source code and experiment data are available at\nhttps://github.com/google-research/google-research/tree/master/tunas\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 21:32:40 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Bender", "Gabriel", ""], ["Liu", "Hanxiao", ""], ["Chen", "Bo", ""], ["Chu", "Grace", ""], ["Cheng", "Shuyang", ""], ["Kindermans", "Pieter-Jan", ""], ["Le", "Quoc", ""]]}, {"id": "2008.06141", "submitter": "Trevor Avant", "authors": "Trevor Avant, Kristi A. Morgansen", "title": "Analytical bounds on the local Lipschitz constants of affine-ReLU\n  functions", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we determine analytical bounds on the local Lipschitz\nconstants of of affine functions composed with rectified linear units (ReLUs).\nAffine-ReLU functions represent a widely used layer in deep neural networks,\ndue to the fact that convolution, fully-connected, and normalization functions\nare all affine, and are often followed by a ReLU activation function. Using an\nanalytical approach, we mathematically determine upper bounds on the local\nLipschitz constant of an affine-ReLU function, show how these bounds can be\ncombined to determine a bound on an entire network, and discuss how the bounds\ncan be efficiently computed, even for larger layers and networks. We show\nseveral examples by applying our results to AlexNet, as well as several smaller\nnetworks based on the MNIST and CIFAR-10 datasets. The results show that our\nmethod produces tighter bounds than the standard conservative bound (i.e. the\nproduct of the spectral norms of the layers' linear matrices), especially for\nsmall perturbations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 00:23:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Avant", "Trevor", ""], ["Morgansen", "Kristi A.", ""]]}, {"id": "2008.06197", "submitter": "Bin Gu", "authors": "Bin Gu, Zhiyuan Dang, Xiang Li, Heng Huang", "title": "Federated Doubly Stochastic Kernel Learning for Vertically Partitioned\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a lot of real-world data mining and machine learning applications, data\nare provided by multiple providers and each maintains private records of\ndifferent feature sets about common entities. It is challenging to train these\nvertically partitioned data effectively and efficiently while keeping data\nprivacy for traditional data mining and machine learning algorithms. In this\npaper, we focus on nonlinear learning with kernels, and propose a federated\ndoubly stochastic kernel learning (FDSKL) algorithm for vertically partitioned\ndata. Specifically, we use random features to approximate the kernel mapping\nfunction and use doubly stochastic gradients to update the solutions, which are\nall computed federatedly without the disclosure of data. Importantly, we prove\nthat FDSKL has a sublinear convergence rate, and can guarantee the data\nsecurity under the semi-honest assumption. Extensive experimental results on a\nvariety of benchmark datasets show that FDSKL is significantly faster than\nstate-of-the-art federated learning methods when dealing with kernels, while\nretaining the similar generalization performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 05:46:56 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gu", "Bin", ""], ["Dang", "Zhiyuan", ""], ["Li", "Xiang", ""], ["Huang", "Heng", ""]]}, {"id": "2008.06199", "submitter": "Xinghua Qu", "authors": "Xinghua Qu, Yew-Soon Ong, Abhishek Gupta, Zhu Sun", "title": "Adversary Agnostic Robust Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) policies have been shown to be deceived by\nperturbations (e.g., random noise or intensional adversarial attacks) on state\nobservations that appear at test time but are unknown during training. To\nincrease the robustness of DRL policies, previous approaches assume that the\nknowledge of adversaries can be added into the training process to achieve the\ncorresponding generalization ability on these perturbed observations. However,\nsuch an assumption not only makes the robustness improvement more expensive but\nmay also leave a model less effective to other kinds of attacks in the wild. In\ncontrast, we propose an adversary agnostic robust DRL paradigm that does not\nrequire learning from adversaries. To this end, we first theoretically derive\nthat robustness could indeed be achieved independently of the adversaries based\non a policy distillation setting. Motivated by this finding, we propose a new\npolicy distillation loss with two terms: 1) a prescription gap maximization\nloss aiming at simultaneously maximizing the likelihood of the action selected\nby the teacher policy and the entropy over the remaining actions; 2) a\ncorresponding Jacobian regularization loss that minimizes the magnitude of the\ngradient with respect to the input state. The theoretical analysis shows that\nour distillation loss guarantees to increase the prescription gap and the\nadversarial robustness. Furthermore, experiments on five Atari games firmly\nverify the superiority of our approach in terms of boosting adversarial\nrobustness compared to other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 06:04:15 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 06:38:19 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Qu", "Xinghua", ""], ["Ong", "Yew-Soon", ""], ["Gupta", "Abhishek", ""], ["Sun", "Zhu", ""]]}, {"id": "2008.06217", "submitter": "Lixu Wang", "authors": "Lixu Wang, Shichao Xu, Xiao Wang, Qi Zhu", "title": "Addressing Class Imbalance in Federated Learning", "comments": "17 pages, Accept by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising approach for training decentralized\ndata located on local client devices while improving efficiency and privacy.\nHowever, the distribution and quantity of the training data on the clients'\nside may lead to significant challenges such as class imbalance and non-IID\n(non-independent and identically distributed) data, which could greatly impact\nthe performance of the common model. While much effort has been devoted to\nhelping FL models converge when encountering non-IID data, the imbalance issue\nhas not been sufficiently addressed. In particular, as FL training is executed\nby exchanging gradients in an encrypted form, the training data is not\ncompletely observable to either clients or servers, and previous methods for\nclass imbalance do not perform well for FL. Therefore, it is crucial to design\nnew methods for detecting class imbalance in FL and mitigating its impact. In\nthis work, we propose a monitoring scheme that can infer the composition of\ntraining data for each FL round, and design a new loss function --\n\\textbf{Ratio Loss} to mitigate the impact of the imbalance. Our experiments\ndemonstrate the importance of acknowledging class imbalance and taking measures\nas early as possible in FL training, and the effectiveness of our method in\nmitigating the impact. Our method is shown to significantly outperform previous\nmethods, while maintaining client privacy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:28:08 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 01:56:21 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Wang", "Lixu", ""], ["Xu", "Shichao", ""], ["Wang", "Xiao", ""], ["Zhu", "Qi", ""]]}, {"id": "2008.06218", "submitter": "Wonyoung Shin", "authors": "Wonyoung Shin, Jung-Woo Ha, Shengzhe Li, Yongwoo Cho, Hoyean Song,\n  Sunyoung Kwon", "title": "Which Strategies Matter for Noisy Label Classification? Insight into\n  Loss and Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label noise is a critical factor that degrades the generalization performance\nof deep neural networks, thus leading to severe issues in real-world problems.\nExisting studies have employed strategies based on either loss or uncertainty\nto address noisy labels, and ironically some strategies contradict each other:\nemphasizing or discarding uncertain samples or concentrating on high or low\nloss samples. To elucidate how opposing strategies can enhance model\nperformance and offer insights into training with noisy labels, we present\nanalytical results on how loss and uncertainty values of samples change\nthroughout the training process. From the in-depth analysis, we design a new\nrobust training method that emphasizes clean and informative samples, while\nminimizing the influence of noise using both loss and uncertainty. We\ndemonstrate the effectiveness of our method with extensive experiments on\nsynthetic and real-world datasets for various deep learning models. The results\nshow that our method significantly outperforms other state-of-the-art methods\nand can be used generally regardless of neural network architectures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:34:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Shin", "Wonyoung", ""], ["Ha", "Jung-Woo", ""], ["Li", "Shengzhe", ""], ["Cho", "Yongwoo", ""], ["Song", "Hoyean", ""], ["Kwon", "Sunyoung", ""]]}, {"id": "2008.06220", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Kernel Methods for Cooperative Multi-Agent Contextual Bandits", "comments": "19 pages including supplement, camera-ready at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent decision making involves a group of agents\ncooperatively solving learning problems while communicating over a network with\ndelays. In this paper, we consider the kernelised contextual bandit problem,\nwhere the reward obtained by an agent is an arbitrary linear function of the\ncontexts' images in the related reproducing kernel Hilbert space (RKHS), and a\ngroup of agents must cooperate to collectively solve their unique decision\nproblems. For this problem, we propose \\textsc{Coop-KernelUCB}, an algorithm\nthat provides near-optimal bounds on the per-agent regret, and is both\ncomputationally and communicatively efficient. For special cases of the\ncooperative problem, we also provide variants of \\textsc{Coop-KernelUCB} that\nprovides optimal per-agent regret. In addition, our algorithm generalizes\nseveral existing results in the multi-agent bandit setting. Finally, on a\nseries of both synthetic and real-world multi-agent network benchmarks, we\ndemonstrate that our algorithm significantly outperforms existing benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:37:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2008.06233", "submitter": "Bin Gu", "authors": "Bin Gu, An Xu, Zhouyuan Huo, Cheng Deng, Heng Huang", "title": "Privacy-Preserving Asynchronous Federated Learning Algorithms for\n  Multi-Party Vertically Collaborative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The privacy-preserving federated learning for vertically partitioned data has\nshown promising results as the solution of the emerging multi-party joint\nmodeling application, in which the data holders (such as government branches,\nprivate finance and e-business companies) collaborate throughout the learning\nprocess rather than relying on a trusted third party to hold data. However,\nexisting federated learning algorithms for vertically partitioned data are\nlimited to synchronous computation. To improve the efficiency when the\nunbalanced computation/communication resources are common among the parties in\nthe federated learning system, it is essential to develop asynchronous training\nalgorithms for vertically partitioned data while keeping the data privacy. In\nthis paper, we propose an asynchronous federated SGD (AFSGD-VP) algorithm and\nits SVRG and SAGA variants on the vertically partitioned data. Moreover, we\nprovide the convergence analyses of AFSGD-VP and its SVRG and SAGA variants\nunder the condition of strong convexity. We also discuss their model privacy,\ndata privacy, computational complexities and communication costs. To the best\nof our knowledge, AFSGD-VP and its SVRG and SAGA variants are the first\nasynchronous federated learning algorithms for vertically partitioned data.\nExtensive experimental results on a variety of vertically partitioned datasets\nnot only verify the theoretical results of AFSGD-VP and its SVRG and SAGA\nvariants, but also show that our algorithms have much higher efficiency than\nthe corresponding synchronous algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:08:15 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gu", "Bin", ""], ["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Deng", "Cheng", ""], ["Huang", "Heng", ""]]}, {"id": "2008.06234", "submitter": "Peter B\\\"uhlmann", "authors": "Peter B\\\"uhlmann, Domagoj \\'Cevid", "title": "Deconfounding and Causal Regularization for Stability and External\n  Validity", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some recent work on removing hidden confounding and causal\nregularization from a unified viewpoint. We describe how simple and\nuser-friendly techniques improve stability, replicability and distributional\nrobustness in heterogeneous data. In this sense, we provide additional thoughts\nto the issue on concept drift, raised by Efron (2020), when the data generating\ndistribution is changing.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:08:41 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["B\u00fchlmann", "Peter", ""], ["\u0106evid", "Domagoj", ""]]}, {"id": "2008.06242", "submitter": "Mingsheng Long", "authors": "Yuchen Zhang, Mingsheng Long, Jianmin Wang, Michael I. Jordan", "title": "On Localized Discrepancy for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the discrepancy-based generalization theories for unsupervised\ndomain adaptation. Previous theories introduced distribution discrepancies\ndefined as the supremum over complete hypothesis space. The hypothesis space\nmay contain hypotheses that lead to unnecessary overestimation of the risk\nbound. This paper studies the localized discrepancies defined on the hypothesis\nspace after localization. First, we show that these discrepancies have\ndesirable properties. They could be significantly smaller than the pervious\ndiscrepancies. Their values will be different if we exchange the two domains,\nthus can reveal asymmetric transfer difficulties. Next, we derive improved\ngeneralization bounds with these discrepancies. We show that the discrepancies\ncould influence the rate of the sample complexity. Finally, we further extend\nthe localized discrepancies for achieving super transfer and derive\ngeneralization bounds that could be even more sample-efficient on source\ndomain.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:30:02 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhang", "Yuchen", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2008.06244", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Cooperative Multi-Agent Bandits with Heavy Tails", "comments": "26 pages including appendix, camera-ready for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the heavy-tailed stochastic bandit problem in the cooperative\nmulti-agent setting, where a group of agents interact with a common bandit\nproblem, while communicating on a network with delays. Existing algorithms for\nthe stochastic bandit in this setting utilize confidence intervals arising from\nan averaging-based communication protocol known as~\\textit{running consensus},\nthat does not lend itself to robust estimation for heavy-tailed settings. We\npropose \\textsc{MP-UCB}, a decentralized multi-agent algorithm for the\ncooperative stochastic bandit that incorporates robust estimation with a\nmessage-passing protocol. We prove optimal regret bounds for \\textsc{MP-UCB}\nfor several problem settings, and also demonstrate its superiority to existing\nmethods. Furthermore, we establish the first lower bounds for the cooperative\nbandit problem, in addition to providing efficient algorithms for robust bandit\nestimation of location.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:34:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2008.06246", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Yijia Zheng, Ruxin Wang, Yunpeng Cai and Hongyan Wu", "title": "Graph Polish: A Novel Graph Generation Paradigm for Molecular\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular optimization, which transforms a given input molecule X into\nanother Y with desirable properties, is essential in molecular drug discovery.\nThe traditional translating approaches, generating the molecular graphs from\nscratch by adding some substructures piece by piece, prone to error because of\nthe large set of candidate substructures in a large number of steps to the\nfinal target. In this study, we present a novel molecular optimization\nparadigm, Graph Polish, which changes molecular optimization from the\ntraditional \"two-language translating\" task into a \"single-language polishing\"\ntask. The key to this optimization paradigm is to find an optimization center\nsubject to the conditions that the preserved areas around it ought to be\nmaximized and thereafter the removed and added regions should be minimized. We\nthen propose an effective and efficient learning framework T&S polish to\ncapture the long-term dependencies in the optimization steps. The T component\nautomatically identifies and annotates the optimization centers and the\npreservation, removal and addition of some parts of the molecule, and the S\ncomponent learns these behaviors and applies these actions to a new molecule.\nFurthermore, the proposed paradigm can offer an intuitive interpretation for\neach molecular optimization result. Experiments with multiple optimization\ntasks are conducted on four benchmark datasets. The proposed T&S polish\napproach achieves significant advantage over the five state-of-the-art baseline\nmethods on all the tasks. In addition, extensive studies are conducted to\nvalidate the effectiveness, explainability and time saving of the novel\noptimization paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:36:13 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Ji", "Chaojie", ""], ["Zheng", "Yijia", ""], ["Wang", "Ruxin", ""], ["Cai", "Yunpeng", ""], ["Wu", "Hongyan", ""]]}, {"id": "2008.06293", "submitter": "Dmitri Goldenberg", "authors": "Dmitri Goldenberg, Javier Albert, Lucas Bernardi and Pablo Estevez", "title": "Free Lunch! Retrospective Uplift Modeling for Dynamic Promotions\n  Recommendation within ROI Constraints", "comments": "Accepted to Fourteenth ACM Conference on Recommender Systems, Brazil,\n  September, 2020", "journal-ref": "2020. In Fourteenth ACM Conference on Recommender Systems (RecSys\n  '20). Association for Computing Machinery, New York, NY, USA, 486-491", "doi": "10.1145/3383313.3412215", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promotions and discounts have become key components of modern e-commerce\nplatforms. For online travel platforms (OTPs), popular promotions include room\nupgrades, free meals and transportation services. By offering these promotions,\ncustomers can get more value for their money, while both the OTP and its travel\npartners may grow their loyal customer base. However, the promotions usually\nincur a cost that, if uncontrolled, can become unsustainable. Consequently, for\na promotion to be viable, its associated costs must be balanced by incremental\nrevenue within set financial constraints. Personalized treatment assignment can\nbe used to satisfy such constraints.\n  This paper introduces a novel uplift modeling technique, relying on the\nKnapsack Problem formulation, that dynamically optimizes the incremental\ntreatment outcome subject to the required Return on Investment (ROI)\nconstraints. The technique leverages Retrospective Estimation, a modeling\napproach that relies solely on data from positive outcome examples. The method\nalso addresses training data bias, long term effects, and seasonality\nchallenges via online-dynamic calibration. This approach was tested via offline\nexperiments and online randomized controlled trials at Booking .com - a leading\nOTP with millions of customers worldwide, resulting in a significant increase\nin the target outcome while staying within the required financial constraints\nand outperforming other approaches.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:13:58 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 06:31:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Goldenberg", "Dmitri", ""], ["Albert", "Javier", ""], ["Bernardi", "Lucas", ""], ["Estevez", "Pablo", ""]]}, {"id": "2008.06294", "submitter": "Maria H\\\"ugle", "authors": "Maria H\\\"ugle, Gabriel Kalweit, Thomas Huegle and Joschka Boedecker", "title": "A Dynamic Deep Neural Network For Multimodal Clinical Data Analysis", "comments": "Accepted at the AAAI 2020 International Workshop on Health\n  Intelligence", "journal-ref": null, "doi": "10.1007/978-3-030-53352-6", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical data from electronic medical records, registries or trials provide a\nlarge source of information to apply machine learning methods in order to\nfoster precision medicine, e.g. by finding new disease phenotypes or performing\nindividual disease prediction. However, to take full advantage of deep learning\nmethods on clinical data, architectures are necessary that 1) are robust with\nrespect to missing and wrong values, and 2) can deal with highly variable-sized\nlists and long-term dependencies of individual diagnosis, procedures,\nmeasurements and medication prescriptions. In this work, we elaborate\nlimitations of fully-connected neural networks and classical machine learning\nmethods in this context and propose AdaptiveNet, a novel recurrent neural\nnetwork architecture, which can deal with multiple lists of different events,\nalleviating the aforementioned limitations. We employ the architecture to the\nproblem of disease progression prediction in rheumatoid arthritis using the\nSwiss Clinical Quality Management registry, which contains over 10.000 patients\nand more than 65.000 patient visits. Our proposed approach leads to more\ncompact representations and outperforms the classical baselines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:19:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["H\u00fcgle", "Maria", ""], ["Kalweit", "Gabriel", ""], ["Huegle", "Thomas", ""], ["Boedecker", "Joschka", ""]]}, {"id": "2008.06296", "submitter": "Zeng Li", "authors": "Zeng Li, Chuanlong Xie, Qinwen Wang", "title": "Provable More Data Hurt in High Dimensional Least Squares Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the finite-sample prediction risk of the\nhigh-dimensional least squares estimator. We derive the central limit theorem\nfor the prediction risk when both the sample size and the number of features\ntend to infinity. Furthermore, the finite-sample distribution and the\nconfidence interval of the prediction risk are provided. Our theoretical\nresults demonstrate the sample-wise nonmonotonicity of the prediction risk and\nconfirm \"more data hurt\" phenomenon.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:33:30 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Li", "Zeng", ""], ["Xie", "Chuanlong", ""], ["Wang", "Qinwen", ""]]}, {"id": "2008.06298", "submitter": "Rudolf Jagdhuber", "authors": "Rudolf Jagdhuber, Michel Lang and J\\\"org Rahnenf\\\"uhrer", "title": "Feature Selection Methods for Cost-Constrained Classification in Random\n  Forests", "comments": "Corrected minor typo in Figure 1, Added ancillary files", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cost-sensitive feature selection describes a feature selection problem, where\nfeatures raise individual costs for inclusion in a model. These costs allow to\nincorporate disfavored aspects of features, e.g. failure rates of as measuring\ndevice, or patient harm, in the model selection process. Random Forests define\na particularly challenging problem for feature selection, as features are\ngenerally entangled in an ensemble of multiple trees, which makes a post hoc\nremoval of features infeasible. Feature selection methods therefore often\neither focus on simple pre-filtering methods, or require many Random Forest\nevaluations along their optimization path, which drastically increases the\ncomputational complexity. To solve both issues, we propose Shallow Tree\nSelection, a novel fast and multivariate feature selection method that selects\nfeatures from small tree structures. Additionally, we also adapt three standard\nfeature selection algorithms for cost-sensitive learning by introducing a\nhyperparameter-controlled benefit-cost ratio criterion (BCR) for each method.\nIn an extensive simulation study, we assess this criterion, and compare the\nproposed methods to multiple performance-based baseline alternatives on four\nartificial data settings and seven real-world data settings. We show that all\nmethods using a hyperparameterized BCR criterion outperform the baseline\nalternatives. In a direct comparison between the proposed methods, each method\nindicates strengths in certain settings, but no one-fits-all solution exists.\nOn a global average, we could identify preferable choices among our BCR based\nmethods. Nevertheless, we conclude that a practical analysis should never rely\non a single method only, but always compare different approaches to obtain the\nbest results.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:39:52 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 04:25:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jagdhuber", "Rudolf", ""], ["Lang", "Michel", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2008.06332", "submitter": "Beate Sick", "authors": "Lisa Herzog, Elvis Murina, Oliver D\\\"urr, Susanne Wegener, Beate Sick", "title": "Integrating uncertainty in deep neural networks for MRI based stroke\n  analysis", "comments": "21 pages, 13 figures", "journal-ref": "Medical Image Analysis (2020): 101790", "doi": "10.1016/j.media.2020.101790", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the majority of the proposed Deep Learning (DL) methods provide\npoint predictions without quantifying the models uncertainty. However, a\nquantification of the reliability of automated image analysis is essential, in\nparticular in medicine when physicians rely on the results for making critical\ntreatment decisions. In this work, we provide an entire framework to diagnose\nischemic stroke patients incorporating Bayesian uncertainty into the analysis\nprocedure. We present a Bayesian Convolutional Neural Network (CNN) yielding a\nprobability for a stroke lesion on 2D Magnetic Resonance (MR) images with\ncorresponding uncertainty information about the reliability of the prediction.\nFor patient-level diagnoses, different aggregation methods are proposed and\nevaluated, which combine the single image-level predictions. Those methods take\nadvantage of the uncertainty in image predictions and report model uncertainty\nat the patient-level. In a cohort of 511 patients, our Bayesian CNN achieved an\naccuracy of 95.33% at the image-level representing a significant improvement of\n2% over a non-Bayesian counterpart. The best patient aggregation method yielded\n95.89% of accuracy. Integrating uncertainty information about image predictions\nin aggregation models resulted in higher uncertainty measures to false patient\nclassifications, which enabled to filter critical patient diagnoses that are\nsupposed to be closer examined by a medical doctor. We therefore recommend\nusing Bayesian approaches not only for improved image-level prediction and\nuncertainty estimation but also for the detection of uncertain aggregations at\nthe patient-level.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:50:17 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Herzog", "Lisa", ""], ["Murina", "Elvis", ""], ["D\u00fcrr", "Oliver", ""], ["Wegener", "Susanne", ""], ["Sick", "Beate", ""]]}, {"id": "2008.06334", "submitter": "Grant Rotskoff", "authors": "Grant M. Rotskoff and Andrew R. Mitchell and Eric Vanden-Eijnden", "title": "Active Importance Sampling for Variational Objectives Dominated by Rare\n  Events: Consequences for Optimization and Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, when optimized with sufficient data, provide accurate\nrepresentations of high-dimensional functions; in contrast, function\napproximation techniques that have predominated in scientific computing do not\nscale well with dimensionality. As a result, many high-dimensional sampling and\napproximation problems once thought intractable are being revisited through the\nlens of machine learning. While the promise of unparalleled accuracy may\nsuggest a renaissance for applications that require parameterizing\nrepresentations of complex systems, in many applications gathering sufficient\ndata to develop such a representation remains a significant challenge. Here we\nintroduce an approach that combines rare events sampling techniques with neural\nnetwork optimization to optimize objective functions that are dominated by rare\nevents. We show that importance sampling reduces the asymptotic variance of the\nsolution to a learning problem, suggesting benefits for generalization. We\nstudy our algorithm in the context of learning dynamical transition pathways\nbetween two states of a system, a problem with applications in statistical\nphysics and implications in machine learning theory. Our numerical experiments\ndemonstrate that we can successfully learn even with the compounding\ndifficulties of high-dimension and rare data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 23:38:09 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 03:06:51 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Rotskoff", "Grant M.", ""], ["Mitchell", "Andrew R.", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2008.06344", "submitter": "Maria D. Ruiz-Medina", "authors": "A. Torres-Signes, M.P. Fr\\'ias and M.D. Ruiz-Medina", "title": "COVID-19 mortality analysis from soft-data multivariate curve regression\n  and machine learning", "comments": "This paper is currently submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multiple objective space-time forecasting approach is presented involving\ncyclical curve log-regression, and multivariate time series spatial residual\ncorrelation analysis. Specifically, the mean quadratic loss function is\nminimized in the framework of trigonometric regression. While, in our\nsubsequent spatial residual correlation analysis, maximization of the\nlikelihood allows us to compute the posterior mode in a Bayesian multivariate\ntime series soft-data framework. The presented approach is applied to the\nanalysis of COVID-19 mortality in the first wave affecting the Spanish\nCommunities, since March, 8, 2020 until May, 13, 2020. An empirical comparative\nstudy with Machine Learning (ML) regression, based on random k-fold\ncross-validation, and bootstrapping confidence interval and probability density\nestimation, is carried out. This empirical analysis also investigates the\nperformance of ML regression models in a hard- and soft- data frameworks. The\nresults could be extrapolated to other counts, countries, and posterior\nCOVID-19 waves.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:59:10 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 12:09:21 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 08:11:31 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Torres-Signes", "A.", ""], ["Fr\u00edas", "M. P.", ""], ["Ruiz-Medina", "M. D.", ""]]}, {"id": "2008.06376", "submitter": "Jason Armitage", "authors": "Jason Armitage, Endri Kacupaj, Golsa Tahmasebzadeh, Swati, Maria\n  Maleshkova, Ralph Ewerth, Jens Lehmann", "title": "MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages\n  and Modalities", "comments": null, "journal-ref": "Proceedings of the 29th ACM International Conference on\n  Information & Knowledge Management, pp. 2967-2974. 2020", "doi": "10.1145/3340531.3412783", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the MLM (Multiple Languages and Modalities)\ndataset - a new resource to train and evaluate multitask systems on samples in\nmultiple modalities and three languages. The generation process and inclusion\nof semantic data provide a resource that further tests the ability for\nmultitask systems to learn relationships between entities. The dataset is\ndesigned for researchers and developers who build applications that perform\nmultiple tasks on data encountered on the web and in digital archives. A second\nversion of MLM provides a geo-representative subset of the data with weighted\nsamples for countries of the European Union. We demonstrate the value of the\nresource in developing novel applications in the digital humanities with a\nmotivating use case and specify a benchmark set of tasks to retrieve modalities\nand locate entities in the dataset. Evaluation of baseline multitask and single\ntask systems on the full and geo-representative versions of MLM demonstrate the\nchallenges of generalising on diverse data. In addition to the digital\nhumanities, we expect the resource to contribute to research in multimodal\nrepresentation learning, location estimation, and scene understanding.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:00:05 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 10:00:43 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 16:10:28 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Armitage", "Jason", ""], ["Kacupaj", "Endri", ""], ["Tahmasebzadeh", "Golsa", ""], ["Swati", "", ""], ["Maleshkova", "Maria", ""], ["Ewerth", "Ralph", ""], ["Lehmann", "Jens", ""]]}, {"id": "2008.06388", "submitter": "Michael Roberts", "authors": "Michael Roberts, Derek Driggs, Matthew Thorpe, Julian Gilbey, Michael\n  Yeung, Stephan Ursprung, Angelica I. Aviles-Rivero, Christian Etmann, Cathal\n  McCague, Lucian Beer, Jonathan R. Weir-McCall, Zhongzhao Teng, Effrossyni\n  Gkrania-Klotsas, James H.F. Rudd, Evis Sala, Carola-Bibiane Sch\\\"onlieb (on\n  behalf of the AIX-COVNET collaboration)", "title": "Common pitfalls and recommendations for using machine learning to detect\n  and prognosticate for COVID-19 using chest radiographs and CT scans", "comments": "35 pages, 3 figures, 2 tables, updated to the period 1 January 2020 -\n  3 October 2020", "journal-ref": "Nature Machine Intelligence 3, 199-217 (2021)", "doi": "10.1038/s42256-021-00307-0", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods offer great promise for fast and accurate detection\nand prognostication of COVID-19 from standard-of-care chest radiographs (CXR)\nand computed tomography (CT) images. Many articles have been published in 2020\ndescribing new machine learning-based models for both of these tasks, but it is\nunclear which are of potential clinical utility. In this systematic review, we\nsearch EMBASE via OVID, MEDLINE via PubMed, bioRxiv, medRxiv and arXiv for\npublished papers and preprints uploaded from January 1, 2020 to October 3, 2020\nwhich describe new machine learning models for the diagnosis or prognosis of\nCOVID-19 from CXR or CT images. Our search identified 2,212 studies, of which\n415 were included after initial screening and, after quality screening, 61\nstudies were included in this systematic review. Our review finds that none of\nthe models identified are of potential clinical use due to methodological flaws\nand/or underlying biases. This is a major weakness, given the urgency with\nwhich validated COVID-19 models are needed. To address this, we give many\nrecommendations which, if followed, will solve these issues and lead to higher\nquality model development and well documented manuscripts.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:25:21 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 08:10:35 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 13:56:25 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 19:41:55 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Roberts", "Michael", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Driggs", "Derek", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Thorpe", "Matthew", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Gilbey", "Julian", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Yeung", "Michael", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Ursprung", "Stephan", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Aviles-Rivero", "Angelica I.", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Etmann", "Christian", "", "on\n  behalf of the AIX-COVNET collaboration"], ["McCague", "Cathal", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Beer", "Lucian", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Weir-McCall", "Jonathan R.", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Teng", "Zhongzhao", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Gkrania-Klotsas", "Effrossyni", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Rudd", "James H. F.", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Sala", "Evis", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Sch\u00f6nlieb", "Carola-Bibiane", "", "on\n  behalf of the AIX-COVNET collaboration"]]}, {"id": "2008.06389", "submitter": "Cristina Pinneri", "authors": "Cristina Pinneri, Shambhuraj Sawant, Sebastian Blaes, Jan Achterhold,\n  Joerg Stueckler, Michal Rolinek and Georg Martius", "title": "Sample-efficient Cross-Entropy Method for Real-time Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory optimizers for model-based reinforcement learning, such as the\nCross-Entropy Method (CEM), can yield compelling results even in\nhigh-dimensional control tasks and sparse-reward environments. However, their\nsampling inefficiency prevents them from being used for real-time planning and\ncontrol. We propose an improved version of the CEM algorithm for fast planning,\nwith novel additions including temporally-correlated actions and memory,\nrequiring 2.7-22x less samples and yielding a performance increase of 1.2-10x\nin high-dimensional control problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:25:59 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Pinneri", "Cristina", ""], ["Sawant", "Shambhuraj", ""], ["Blaes", "Sebastian", ""], ["Achterhold", "Jan", ""], ["Stueckler", "Joerg", ""], ["Rolinek", "Michal", ""], ["Martius", "Georg", ""]]}, {"id": "2008.06395", "submitter": "Francesco Mannella", "authors": "Francesco Mannella", "title": "Supervised Topological Maps", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling the internal representation space of a neural network is a\ndesirable feature because it allows to generate new data in a supervised\nmanner. In this paper we will show how this can be achieved while building a\nlow-dimensional mapping of the input stream, by deriving a generalized\nalgorithm starting from Self Organizing Maps (SOMs). SOMs are a kind of neural\nnetwork which can be trained with unsupervised learning to produce a\nlow-dimensional discretized mapping of the input space. They can be used for\nthe generation of new data through backward propagation of interpolations made\nfrom the mapping grid. Unfortunately the final topology of the mapping space of\na SOM is not known before learning, so interpolating new data in a supervised\nway is not an easy task. Here we will show a variation from the SOM algorithm\nconsisting in constraining the update of prototypes so that it is also a\nfunction of the distance of its prototypes from extrinsically given targets in\nthe mapping space. We will demonstrate how such variants, that we will call\nSupervised Topological Maps (STMs), allow for a supervised mapping where the\nposition of internal representations in the mapping space is determined by the\nexperimenter. Controlling the internal representation space in STMs reveals to\nbe an easier task than what is currently done using other algorithms such as\nvariational or adversarial autoencoders.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:30:16 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 21:50:10 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 09:30:22 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mannella", "Francesco", ""]]}, {"id": "2008.06402", "submitter": "Stefanos Laskaridis", "authors": "Stefanos Laskaridis, Stylianos I. Venieris, Mario Almeida, Ilias\n  Leontiadis, Nicholas D. Lane", "title": "SPINN: Synergistic Progressive Inference of Neural Networks over Device\n  and Cloud", "comments": "Accepted at the 26th Annual International Conference on Mobile\n  Computing and Networking (MobiCom), 2020", "journal-ref": null, "doi": "10.1145/3372224.3419194", "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the soaring use of convolutional neural networks (CNNs) in mobile\napplications, uniformly sustaining high-performance inference on mobile has\nbeen elusive due to the excessive computational demands of modern CNNs and the\nincreasing diversity of deployed devices. A popular alternative comprises\noffloading CNN processing to powerful cloud-based servers. Nevertheless, by\nrelying on the cloud to produce outputs, emerging mission-critical and\nhigh-mobility applications, such as drone obstacle avoidance or interactive\napplications, can suffer from the dynamic connectivity conditions and the\nuncertain availability of the cloud. In this paper, we propose SPINN, a\ndistributed inference system that employs synergistic device-cloud computation\ntogether with a progressive inference method to deliver fast and robust CNN\ninference across diverse settings. The proposed system introduces a novel\nscheduler that co-optimises the early-exit policy and the CNN splitting at run\ntime, in order to adapt to dynamic conditions and meet user-defined\nservice-level requirements. Quantitative evaluation illustrates that SPINN\noutperforms its state-of-the-art collaborative inference counterparts by up to\n2x in achieved throughput under varying network conditions, reduces the server\ncost by up to 6.8x and improves accuracy by 20.7% under latency constraints,\nwhile providing robust operation under uncertain connectivity conditions and\nsignificant energy savings compared to cloud-centric execution.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:00:19 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 10:24:41 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Laskaridis", "Stefanos", ""], ["Venieris", "Stylianos I.", ""], ["Almeida", "Mario", ""], ["Leontiadis", "Ilias", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.06423", "submitter": "Rajbir-Singh Nirwan", "authors": "Rajbir-Singh Nirwan, Nils Bertschinger", "title": "Bayesian Quantile Matching Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increased awareness of data protection and corresponding laws many\ndata, especially involving sensitive personal information, are not publicly\naccessible. Accordingly, many data collecting agencies only release aggregated\ndata, e.g. providing the mean and selected quantiles of population\ndistributions. Yet, research and scientific understanding, e.g. for medical\ndiagnostics or policy advice, often relies on data access. To overcome this\ntension, we propose a Bayesian method for learning from quantile information.\nBeing based on order statistics of finite samples our method adequately and\ncorrectly reflects the uncertainty of empirical quantiles. After outlining the\ntheory, we apply our method to simulated as well as real world examples.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:39:51 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Nirwan", "Rajbir-Singh", ""], ["Bertschinger", "Nils", ""]]}, {"id": "2008.06431", "submitter": "David E. Shaw", "authors": "John J. Cherian, Andrew G. Taube, Robert T. McGibbon, Panagiotis\n  Angelikopoulos, Guy Blanc, Michael Snarski, Daniel D. Richman, John L.\n  Klepeis, David E. Shaw", "title": "Efficient hyperparameter optimization by way of PAC-Bayes bound\n  minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying optimal values for a high-dimensional set of hyperparameters is a\nproblem that has received growing attention given its importance to large-scale\nmachine learning applications such as neural architecture search. Recently\ndeveloped optimization methods can be used to select thousands or even millions\nof hyperparameters. Such methods often yield overfit models, however, leading\nto poor performance on unseen data. We argue that this overfitting results from\nusing the standard hyperparameter optimization objective function. Here we\npresent an alternative objective that is equivalent to a Probably Approximately\nCorrect-Bayes (PAC-Bayes) bound on the expected out-of-sample error. We then\ndevise an efficient gradient-based algorithm to minimize this objective; the\nproposed method has asymptotic space and time complexity equal to or better\nthan other gradient-based hyperparameter optimization methods. We show that\nthis new method significantly reduces out-of-sample error when applied to\nhyperparameter optimization problems known to be prone to overfitting.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:54:51 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Cherian", "John J.", ""], ["Taube", "Andrew G.", ""], ["McGibbon", "Robert T.", ""], ["Angelikopoulos", "Panagiotis", ""], ["Blanc", "Guy", ""], ["Snarski", "Michael", ""], ["Richman", "Daniel D.", ""], ["Klepeis", "John L.", ""], ["Shaw", "David E.", ""]]}, {"id": "2008.06434", "submitter": "Paul Baggenstoss", "authors": "Paul M Baggenstoss", "title": "The Projected Belief Network Classfier : both Generative and\n  Discriminative", "comments": null, "journal-ref": "EUSIPCO 2020, Amsterdam (Jan 2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The projected belief network (PBN) is a layered generative network with\ntractable likelihood function, and is based on a feed-forward neural network\n(FF-NN). It can therefore share an embodiment with a discriminative classifier\nand can inherit the best qualities of both types of network. In this paper, a\nconvolutional PBN is constructed that is both fully discriminative and fully\ngenerative and is tested on spectrograms of spoken commands. It is shown that\nthe network displays excellent qualities from either the discriminative or\ngenerative viewpoint. Random data synthesis and visible data reconstruction\nfrom low-dimensional hidden variables are shown, while classifier performance\napproaches that of a regularized discriminative network. Combination with a\nconventional discriminative CNN is also demonstrated.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:00:54 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Baggenstoss", "Paul M", ""]]}, {"id": "2008.06456", "submitter": "Salem Lahlou", "authors": "Lucas Willems, Salem Lahlou, Yoshua Bengio", "title": "Mastering Rate based Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent automatic curriculum learning algorithms, and in particular\nTeacher-Student algorithms, rely on the notion of learning progress, making the\nassumption that the good next tasks are the ones on which the learner is making\nthe fastest progress or digress. In this work, we first propose a simpler and\nimproved version of these algorithms. We then argue that the notion of learning\nprogress itself has several shortcomings that lead to a low sample efficiency\nfor the learner. We finally propose a new algorithm, based on the notion of\nmastering rate, that significantly outperforms learning progress-based\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:34:01 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Willems", "Lucas", ""], ["Lahlou", "Salem", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2008.06457", "submitter": "Avinash Kori", "authors": "Avinash Kori, Parth Natekar, Ganapathy Krishnamurthi, Balaji\n  Srinivasan", "title": "Abstracting Deep Neural Networks into Concept Graphs for Concept Level\n  Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The black-box nature of deep learning models prevents them from being\ncompletely trusted in domains like biomedicine. Most explainability techniques\ndo not capture the concept-based reasoning that human beings follow. In this\nwork, we attempt to understand the behavior of trained models that perform\nimage processing tasks in the medical domain by building a graphical\nrepresentation of the concepts they learn. Extracting such a graphical\nrepresentation of the model's behavior on an abstract, higher conceptual level\nwould unravel the learnings of these models and would help us to evaluate the\nsteps taken by the model for predictions. We show the application of our\nproposed implementation on two biomedical problems - brain tumor segmentation\nand fundus image classification. We provide an alternative graphical\nrepresentation of the model by formulating a concept level graph as discussed\nabove, which makes the problem of intervention to find active inference trails\nmore tractable. Understanding these trails would provide an understanding of\nthe hierarchy of the decision-making process followed by the model. [As well as\noverall nature of model]. Our framework is available at\nhttps://github.com/koriavinash1/BioExp\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:34:32 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 07:12:01 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kori", "Avinash", ""], ["Natekar", "Parth", ""], ["Krishnamurthi", "Ganapathy", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "2008.06461", "submitter": "Alicia Curth", "authors": "Alicia Curth and Ahmed M. Alaa and Mihaela van der Schaar", "title": "Estimating Structural Target Functions using Machine Learning and\n  Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to construct a class of learning algorithms that are of practical\nvalue to applied researchers in fields such as biostatistics, epidemiology and\neconometrics, where the need to learn from incompletely observed information is\nubiquitous. We propose a new framework for statistical machine learning of\ntarget functions arising as identifiable functionals from statistical models,\nwhich we call `IF-learning' due to its reliance on influence functions (IFs).\nThis framework is problem- and model-agnostic and can be used to estimate a\nbroad variety of target parameters of interest in applied statistics: we can\nconsider any target function for which an IF of a population-averaged version\nexists in analytic form. Throughout, we put particular focus on so-called\ncoarsening at random/doubly robust problems with partially unobserved\ninformation. This includes problems such as treatment effect estimation and\ninference in the presence of missing outcome data. Within this framework, we\npropose two general learning algorithms that build on the idea of nonparametric\nplug-in bias removal via IFs: the 'IF-learner' which uses pseudo-outcomes\nmotivated by uncentered IFs for regression in large samples and outputs entire\ntarget functions without confidence bands, and the 'Group-IF-learner', which\noutputs only approximations to a function but can give confidence estimates if\nsufficient information on coarsening mechanisms is available. We apply both in\na simulation study on inferring treatment effects.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:48:29 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 16:27:18 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 13:15:52 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Curth", "Alicia", ""], ["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2008.06495", "submitter": "Yuandong Tian", "authors": "Yuandong Tian, Qucheng Gong, Tina Jiang", "title": "Joint Policy Search for Multi-agent Collaboration with Imperfect\n  Information", "comments": "Minor fix of the algorithm block", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn good joint policies for multi-agent collaboration with imperfect\ninformation remains a fundamental challenge. While for two-player zero-sum\ngames, coordinate-ascent approaches (optimizing one agent's policy at a time,\ne.g., self-play) work with guarantees, in multi-agent cooperative setting they\noften converge to sub-optimal Nash equilibrium. On the other hand, directly\nmodeling joint policy changes in imperfect information game is nontrivial due\nto complicated interplay of policies (e.g., upstream updates affect downstream\nstate reachability). In this paper, we show global changes of game values can\nbe decomposed to policy changes localized at each information set, with a novel\nterm named policy-change density. Based on this, we propose Joint Policy\nSearch(JPS) that iteratively improves joint policies of collaborative agents in\nimperfect information games, without re-evaluating the entire game. On\nmulti-agent collaborative tabular games, JPS is proven to never worsen\nperformance and can improve solutions provided by unilateral approaches (e.g,\nCFR), outperforming algorithms designed for collaborative policy learning (e.g.\nBAD). Furthermore, for real-world games, JPS has an online form that naturally\nlinks with gradient updates. We test it to Contract Bridge, a 4-player\nimperfect-information game where a team of $2$ collaborates to compete against\nthe other. In its bidding phase, players bid in turn to find a good contract\nthrough a limited information channel. Based on a strong baseline agent that\nbids competitive bridge purely through domain-agnostic self-play, JPS improves\ncollaboration of team players and outperforms WBridge5, a championship-winning\nsoftware, by $+0.63$ IMPs (International Matching Points) per board over 1k\ngames, substantially better than previous SoTA ($+0.41$ IMPs/b) under\nDouble-Dummy evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:58:47 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 02:35:56 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:14:14 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 20:09:48 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 01:10:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tian", "Yuandong", ""], ["Gong", "Qucheng", ""], ["Jiang", "Tina", ""]]}, {"id": "2008.06529", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Jiachun Liao, Flavio P. Calmon, Oliver Kosut, and\n  Lalitha Sankar", "title": "Three Variants of Differential Privacy: Lossless Conversion and\n  Applications", "comments": "To appear in IEEE Journal on Selected Areas in Information Theory,\n  Special Issue on Privacy and Security of Information Systems. arXiv admin\n  note: text overlap with arXiv:2001.05990", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CR math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three different variants of differential privacy (DP), namely\napproximate DP, R\\'enyi DP (RDP), and hypothesis test DP. In the first part, we\ndevelop a machinery for optimally relating approximate DP to RDP based on the\njoint range of two $f$-divergences that underlie the approximate DP and RDP. In\nparticular, this enables us to derive the optimal approximate DP parameters of\na mechanism that satisfies a given level of RDP. As an application, we apply\nour result to the moments accountant framework for characterizing privacy\nguarantees of noisy stochastic gradient descent (SGD). When compared to the\nstate-of-the-art, our bounds may lead to about 100 more stochastic gradient\ndescent iterations for training deep learning models for the same privacy\nbudget. In the second part, we establish a relationship between RDP and\nhypothesis test DP which allows us to translate the RDP constraint into a\ntradeoff between type I and type II error probabilities of a certain binary\nhypothesis test. We then demonstrate that for noisy SGD our result leads to\ntighter privacy guarantees compared to the recently proposed $f$-DP framework\nfor some range of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:23:50 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 19:34:51 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Liao", "Jiachun", ""], ["Calmon", "Flavio P.", ""], ["Kosut", "Oliver", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2008.06542", "submitter": "Quanming Yao", "authors": "Yaqing Wang and Quanming Yao and James T. Kwok", "title": "A Scalable, Adaptive and Sound Nonconvex Regularizer for Low-rank Matrix\n  Completion", "comments": "WebConf 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix learning is at the core of many machine learning problems. A number of\nreal-world applications such as collaborative filtering and text mining\n  can be formulated as a low-rank matrix completion problem, which recovers\nincomplete matrix using low-rank assumptions. To ensure that the matrix\nsolution has a low rank, a recent trend is to use nonconvex regularizers that\nadaptively penalize singular values. They offer good recovery performance and\nhave nice theoretical properties, but are computationally expensive due to\nrepeated access to individual singular values. In this paper, based on the key\ninsight that adaptive shrinkage on singular values improve empirical\nperformance, we propose a new nonconvex low-rank regularizer called \"nuclear\nnorm minus Frobenius norm\" regularizer, which is scalable, adaptive and sound.\nWe first show it provably holds the adaptive shrinkage property. Further, we\ndiscover its factored form which bypasses the computation of singular values\nand allows fast optimization by general optimization algorithms. Stable\nrecovery and convergence are guaranteed. Extensive low-rank matrix completion\nexperiments on a number of synthetic and real-world data sets show that the\nproposed method obtains state-of-the-art recovery performance while being the\nfastest in comparison to existing low-rank matrix learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:47:58 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 18:17:04 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 17:21:17 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 07:54:12 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Yaqing", ""], ["Yao", "Quanming", ""], ["Kwok", "James T.", ""]]}, {"id": "2008.06545", "submitter": "Sascha Diefenbacher", "authors": "Anja Butter, Sascha Diefenbacher, Gregor Kasieczka, Benjamin Nachman,\n  and Tilman Plehn", "title": "GANplifying Event Samples", "comments": "15 pages, 7 figures, fixed two equations, extended acknowledgments,\n  addressed referee comments, improved figure readability", "journal-ref": "SciPost Phys. 10, 139 (2021)", "doi": "10.21468/SciPostPhys.10.6.139", "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical question concerning generative networks applied to event\ngeneration in particle physics is if the generated events add statistical\nprecision beyond the training sample. We show for a simple example with\nincreasing dimensionality how generative networks indeed amplify the training\nstatistics. We quantify their impact through an amplification factor or\nequivalent numbers of sampled events.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:00:21 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 15:31:52 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 17:34:25 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Butter", "Anja", ""], ["Diefenbacher", "Sascha", ""], ["Kasieczka", "Gregor", ""], ["Nachman", "Benjamin", ""], ["Plehn", "Tilman", ""]]}, {"id": "2008.06555", "submitter": "Lalit Jain", "authors": "Lalit Jain, Kevin Jamieson", "title": "A New Perspective on Pool-Based Active Classification and\n  False-Discovery Control", "comments": null, "journal-ref": "Published at Neurips 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific settings there is a need for adaptive experimental design\nto guide the process of identifying regions of the search space that contain as\nmany true positives as possible subject to a low rate of false discoveries\n(i.e. false alarms). Such regions of the search space could differ drastically\nfrom a predicted set that minimizes 0/1 error and accurate identification could\nrequire very different sampling strategies. Like active learning for binary\nclassification, this experimental design cannot be optimally chosen a priori,\nbut rather the data must be taken sequentially and adaptively. However, unlike\nclassification with 0/1 error, collecting data adaptively to find a set with\nhigh true positive rate and low false discovery rate (FDR) is not as well\nunderstood. In this paper we provide the first provably sample efficient\nadaptive algorithm for this problem. Along the way we highlight connections\nbetween classification, combinatorial bandits, and FDR control making\ncontributions to each.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:49:19 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jain", "Lalit", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2008.06556", "submitter": "Waad Subber", "authors": "Waad Subber, Sayan Ghosh, Piyush Pandita, Yiming Zhang, Liping Wang", "title": "Data-Informed Decomposition for Localized Uncertainty Quantification of\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial dynamical systems often exhibit multi-scale response due to\nmaterial heterogeneities, operation conditions and complex environmental\nloadings. In such problems, it is the case that the smallest length-scale of\nthe systems dynamics controls the numerical resolution required to effectively\nresolve the embedded physics. In practice however, high numerical resolutions\nis only required in a confined region of the system where fast dynamics or\nlocalized material variability are exhibited, whereas a coarser discretization\ncan be sufficient in the rest majority of the system. To this end, a unified\ncomputational scheme with uniform spatio-temporal resolutions for uncertainty\nquantification can be very computationally demanding. Partitioning the complex\ndynamical system into smaller easier-to-solve problems based of the localized\ndynamics and material variability can reduce the overall computational cost.\nHowever, identifying the region of interest for high-resolution and intensive\nuncertainty quantification can be a problem dependent. The region of interest\ncan be specified based on the localization features of the solution, user\ninterest, and correlation length of the random material properties. For\nproblems where a region of interest is not evident, Bayesian inference can\nprovide a feasible solution. In this work, we employ a Bayesian framework to\nupdate our prior knowledge on the localized region of interest using\nmeasurements and system response. To address the computational cost of the\nBayesian inference, we construct a Gaussian process surrogate for the forward\nmodel. Once, the localized region of interest is identified, we use polynomial\nchaos expansion to propagate the localization uncertainty. We demonstrate our\nframework through numerical experiments on a three-dimensional elastodynamic\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:49:32 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Subber", "Waad", ""], ["Ghosh", "Sayan", ""], ["Pandita", "Piyush", ""], ["Zhang", "Yiming", ""], ["Wang", "Liping", ""]]}, {"id": "2008.06570", "submitter": "Monica Ribero", "authors": "Peter Kairouz, M\\'onica Ribero, Keith Rush, Abhradeep Thakurta", "title": "Fast Dimension Independent Private AdaGrad on Publicly Estimated\n  Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of empirical risk minimziation (ERM) with differential\nprivacy. We show that noisy AdaGrad, given appropriate knowledge and conditions\non the subspace from which gradients can be drawn, achieves a regret comparable\nto traditional AdaGrad plus a well-controlled term due to noise. We show a\nconvergence rate of $O(\\text{Tr}(G_T)/T)$, where $G_T$ captures the geometry of\nthe gradient subspace. Since $\\text{Tr}(G_T)=O(\\sqrt{T})$ we can obtain faster\nrates for convex and Lipschitz functions, compared to the $O(1/\\sqrt{T})$ rate\nachieved by known versions of noisy (stochastic) gradient descent with\ncomparable noise variance. In particular, we show that if the gradients lie in\na known constant rank subspace, and assuming algorithmic access to an envelope\nwhich bounds decaying sensitivity, one can achieve faster convergence to an\nexcess empirical risk of $\\tilde O(1/\\epsilon n)$, where $\\epsilon$ is the\nprivacy budget and $n$ the number of samples. Letting $p$ be the problem\ndimension, this result implies that, by running noisy Adagrad, we can bypass\nthe DP-SGD bound $\\tilde O(\\sqrt{p}/\\epsilon n)$ in $T=(\\epsilon\nn)^{2/(1+2\\alpha)}$ iterations, where $\\alpha \\geq 0$ is a parameter\ncontrolling gradient norm decay, instead of the rate achieved by SGD of\n$T=\\epsilon^2n^2$. Our results operate with general convex functions in both\nconstrained and unconstrained minimization.\n  Along the way, we do a perturbation analysis of noisy AdaGrad of independent\ninterest. Our utility guarantee for the private ERM problem follows as a\ncorollary to the regret guarantee of noisy AdaGrad.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 20:46:38 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 23:34:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kairouz", "Peter", ""], ["Ribero", "M\u00f3nica", ""], ["Rush", "Keith", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "2008.06622", "submitter": "Jesse Zhang", "authors": "Jesse Zhang, Brian Cheung, Chelsea Finn, Sergey Levine, Dinesh\n  Jayaraman", "title": "Cautious Adaptation For Reinforcement Learning in Safety-Critical\n  Settings", "comments": "15 pages, 8 figures, ICML 2020. Website with code:\n  https://sites.google.com/berkeley.edu/carl", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:11055-11065, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in real-world safety-critical target settings\nlike urban driving is hazardous, imperiling the RL agent, other agents, and the\nenvironment. To overcome this difficulty, we propose a \"safety-critical\nadaptation\" task setting: an agent first trains in non-safety-critical \"source\"\nenvironments such as in a simulator, before it adapts to the target environment\nwhere failures carry heavy costs. We propose a solution approach, CARL, that\nbuilds on the intuition that prior experience in diverse environments equips an\nagent to estimate risk, which in turn enables relative safety through\nrisk-averse, cautious adaptation. CARL first employs model-based RL to train a\nprobabilistic model to capture uncertainty about transition dynamics and\ncatastrophic states across varied source environments. Then, when exploring a\nnew safety-critical environment with unknown dynamics, the CARL agent plans to\navoid actions that could lead to catastrophic states. In experiments on car\ndriving, cartpole balancing, half-cheetah locomotion, and robotic object\nmanipulation, CARL successfully acquires cautious exploration behaviors,\nyielding higher rewards with fewer failures than strong RL adaptation\nbaselines. Website at https://sites.google.com/berkeley.edu/carl.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 01:40:59 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhang", "Jesse", ""], ["Cheung", "Brian", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Jayaraman", "Dinesh", ""]]}, {"id": "2008.06631", "submitter": "Yue Xing", "authors": "Yue Xing, Qifan Song, Guang Cheng", "title": "On the Generalization Properties of Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning and deep learning models are shown to be vulnerable\nwhen testing data are slightly perturbed. Existing theoretical studies of\nadversarial training algorithms mostly focus on either adversarial training\nlosses or local convergence properties. In contrast, this paper studies the\ngeneralization performance of a generic adversarial training algorithm.\nSpecifically, we consider linear regression models and two-layer neural\nnetworks (with lazy training) using squared loss under low-dimensional and\nhigh-dimensional regimes. In the former regime, after overcoming the\nnon-smoothness of adversarial training, the adversarial risk of the trained\nmodels can converge to the minimal adversarial risk. In the latter regime, we\ndiscover that data interpolation prevents the adversarially robust estimator\nfrom being consistent. Therefore, inspired by successes of the least absolute\nshrinkage and selection operator (LASSO), we incorporate the L1 penalty in the\nhigh dimensional adversarial learning and show that it leads to consistent\nadversarially robust estimation. A series of numerical studies are conducted to\ndemonstrate how the smoothness and L1 penalization help improve the adversarial\nrobustness of DNN models.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:32:09 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 14:19:31 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2008.06635", "submitter": "Chengcheng Wan", "authors": "Chengcheng Wan, Henry Hoffmann, Shan Lu, Michael Maire", "title": "Orthogonalized SGD and Nested Architectures for Anytime Neural Networks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel variant of SGD customized for training network\narchitectures that support anytime behavior: such networks produce a series of\nincreasingly accurate outputs over time. Efficient architectural designs for\nthese networks focus on re-using internal state; subnetworks must produce\nrepresentations relevant for both immediate prediction as well as refinement by\nsubsequent network stages. We consider traditional branched networks as well as\na new class of recursively nested networks. Our new optimizer, Orthogonalized\nSGD, dynamically re-balances task-specific gradients when training a multitask\nnetwork. In the context of anytime architectures, this optimizer projects\ngradients from later outputs onto a parameter subspace that does not interfere\nwith those from earlier outputs. Experiments demonstrate that training with\nOrthogonalized SGD significantly improves generalization accuracy of anytime\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 03:06:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wan", "Chengcheng", ""], ["Hoffmann", "Henry", ""], ["Lu", "Shan", ""], ["Maire", "Michael", ""]]}, {"id": "2008.06653", "submitter": "Alireza Makhzani", "authors": "Sicong Huang, Alireza Makhzani, Yanshuai Cao, Roger Grosse", "title": "Evaluating Lossy Compression Rates of Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep generative modeling has succeeded in producing\nastonishingly realistic-seeming images and audio, but quantitative evaluation\nremains a challenge. Log-likelihood is an appealing metric due to its grounding\nin statistics and information theory, but it can be challenging to estimate for\nimplicit generative models, and scalar-valued metrics give an incomplete\npicture of a model's quality. In this work, we propose to use rate distortion\n(RD) curves to evaluate and compare deep generative models. While estimating RD\ncurves is seemingly even more computationally demanding than log-likelihood\nestimation, we show that we can approximate the entire RD curve using nearly\nthe same computations as were previously used to achieve a single\nlog-likelihood estimate. We evaluate lossy compression rates of VAEs, GANs, and\nadversarial autoencoders (AAEs) on the MNIST and CIFAR10 datasets. Measuring\nthe entire RD curve gives a more complete picture than scalar-valued metrics,\nand we arrive at a number of insights not obtainable from log-likelihoods\nalone.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 05:08:28 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Huang", "Sicong", ""], ["Makhzani", "Alireza", ""], ["Cao", "Yanshuai", ""], ["Grosse", "Roger", ""]]}, {"id": "2008.06662", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou", "title": "Compositional Generalization via Neural-Symbolic Stack Machines", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving tremendous success, existing deep learning models have\nexposed limitations in compositional generalization, the capability to learn\ncompositional rules and apply them to unseen cases in a systematic manner. To\ntackle this issue, we propose the Neural-Symbolic Stack Machine (NeSS). It\ncontains a neural network to generate traces, which are then executed by a\nsymbolic stack machine enhanced with sequence manipulation operations. NeSS\ncombines the expressive power of neural sequence models with the recursion\nsupported by the symbolic stack machine. Without training supervision on\nexecution traces, NeSS achieves 100% generalization performance in four\ndomains: the SCAN benchmark of language-driven navigation tasks, the task of\nfew-shot learning of compositional instructions, the compositional machine\ntranslation benchmark, and context-free grammar parsing tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 06:23:20 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:16:10 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Xinyun", ""], ["Liang", "Chen", ""], ["Yu", "Adams Wei", ""], ["Song", "Dawn", ""], ["Zhou", "Denny", ""]]}, {"id": "2008.06668", "submitter": "Yihao Feng", "authors": "Yihao Feng, Tongzheng Ren, Ziyang Tang, Qiang Liu", "title": "Accountable Off-Policy Evaluation With Kernel Bellman Statistics", "comments": "22 pages, 4 figures, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy evaluation (OPE), which evaluates the performance of a\nnew policy from observed data collected from previous experiments, without\nrequiring the execution of the new policy. This finds important applications in\nareas with high execution cost or safety concerns, such as medical diagnosis,\nrecommendation systems and robotics. In practice, due to the limited\ninformation from off-policy data, it is highly desirable to construct rigorous\nconfidence intervals, not just point estimation, for the policy performance. In\nthis work, we propose a new variational framework which reduces the problem of\ncalculating tight confidence bounds in OPE into an optimization problem on a\nfeasible set that catches the true state-action value function with high\nprobability. The feasible set is constructed by leveraging statistical\nproperties of a recently proposed kernel Bellman loss (Feng et al., 2019). We\ndesign an efficient computational approach for calculating our bounds, and\nextend it to perform post-hoc diagnosis and correction for existing estimators.\nEmpirical results show that our method yields tight confidence intervals in\ndifferent settings.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 07:24:38 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Feng", "Yihao", ""], ["Ren", "Tongzheng", ""], ["Tang", "Ziyang", ""], ["Liu", "Qiang", ""]]}, {"id": "2008.06677", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli, Dario Azzimonti, Dario Piga", "title": "Preferential Bayesian optimisation with Skew Gaussian Processes", "comments": "arXiv admin note: text overlap with arXiv:2012.06846", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferential Bayesian optimisation (PBO) deals with optimisation problems\nwhere the objective function can only be accessed via preference judgments,\nsuch as \"this is better than that\" between two candidate solutions (like in A/B\ntests or recommender systems). The state-of-the-art approach to PBO uses a\nGaussian process to model the preference function and a Bernoulli likelihood to\nmodel the observed pairwise comparisons. Laplace's method is then employed to\ncompute posterior inferences and, in particular, to build an appropriate\nacquisition function. In this paper, we prove that the true posterior\ndistribution of the preference function is a Skew Gaussian Process (SkewGP),\nwith highly skewed pairwise marginals and, thus, show that Laplace's method\nusually provides a very poor approximation. We then derive an efficient method\nto compute the exact SkewGP posterior and use it as surrogate model for PBO\nemploying standard acquisition functions (Upper Credible Bound, etc.). We\nillustrate the benefits of our exact PBO-SkewGP in a variety of experiments, by\nshowing that it consistently outperforms PBO based on Laplace's approximation\nboth in terms of convergence speed and computational time. We also show that\nour framework can be extended to deal with mixed preferential-categorical BO,\nwhere binary judgments (valid or non-valid) together with preference judgments\nare available.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 08:23:17 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 12:17:27 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 17:46:11 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Benavoli", "Alessio", ""], ["Azzimonti", "Dario", ""], ["Piga", "Dario", ""]]}, {"id": "2008.06687", "submitter": "Csongor V\\'arady", "authors": "Csongor V\\'arady (1 and 2), Riccardo Volpi (1) and Luigi Malag\\`o (1)\n  and Nihat Ay (2) ((1) Romanian Institute for Science and Technology\n  University, Cluj-Napoca, Romania, (2) Max Planck Institute for Mathematics in\n  the Sciences, Leipzig, Germany)", "title": "Natural Wake-Sleep Algorithm", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefits of using the natural gradient are well known in a wide range of\noptimization problems. However, for the training of common neural networks the\nresulting increase in computational complexity sets a limitation to its\npractical application. Helmholtz Machines are a particular type of generative\nmodel composed of two Sigmoid Belief Networks (SBNs), acting as an encoder and\na decoder, commonly trained using the Wake-Sleep (WS) algorithm and its\nreweighted version RWS. For SBNs, it has been shown how the locality of the\nconnections in the graphical structure induces sparsity in the Fisher\ninformation matrix. The resulting block diagonal structure can be efficiently\nexploited to reduce the computational complexity of the Fisher matrix inversion\nand thus compute the natural gradient exactly, without the need of\napproximations. We present a geometric adaptation of well-known methods from\nthe literature, introducing the Natural Wake-Sleep (NWS) and the Natural\nReweighted Wake-Sleep (NRWS) algorithms. We present an experimental analysis of\nthe novel geometrical algorithms based on the convergence speed and the value\nof the log-likelihood, both with respect to the number of iterations and the\ntime complexity and demonstrating improvements on these aspects over their\nrespective non-geometric baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 09:25:32 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["V\u00e1rady", "Csongor", "", "1 and 2"], ["Volpi", "Riccardo", ""], ["Malag\u00f2", "Luigi", ""], ["Ay", "Nihat", ""]]}, {"id": "2008.06716", "submitter": "Evgeny Frolov", "authors": "Leyla Mirvakhabova, Evgeny Frolov, Valentin Khrulkov, Ivan Oseledets,\n  Alexander Tuzhilin", "title": "Performance of Hyperbolic Geometry Models on Top-N Recommendation Tasks", "comments": "Accepted at ACM RecSys 2020; 7 pages", "journal-ref": null, "doi": "10.1145/3383313.3412219", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple autoencoder based on hyperbolic geometry for solving\nstandard collaborative filtering problem. In contrast to many modern deep\nlearning techniques, we build our solution using only a single hidden layer.\nRemarkably, even with such a minimalistic approach, we not only outperform the\nEuclidean counterpart but also achieve a competitive performance with respect\nto the current state-of-the-art. We additionally explore the effects of space\ncurvature on the quality of hyperbolic models and propose an efficient\ndata-driven method for estimating its optimal value.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 13:21:10 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mirvakhabova", "Leyla", ""], ["Frolov", "Evgeny", ""], ["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2008.06729", "submitter": "Hector Javier Hortua", "authors": "Hector J. Hortua, Luigi Malago, Riccardo Volpi", "title": "Reliable Uncertainties for Bayesian Neural Networks using\n  Alpha-divergences", "comments": "Accepted at the ICML 2020: Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNNs) often result uncalibrated after training,\nusually tending towards overconfidence. Devising effective calibration methods\nwith low impact in terms of computational complexity is thus of central\ninterest. In this paper we present calibration methods for BNNs based on the\nalpha divergences from Information Geometry. We compare the use of alpha\ndivergence in training and in calibration, and we show how the use in\ncalibration provides better calibrated uncertainty estimates for specific\nchoices of alpha and is more efficient especially for complex network\narchitectures. We empirically demonstrate the advantages of alpha calibration\nin regression problems involving parameter estimation and inferred correlations\nbetween output uncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:03:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Hortua", "Hector J.", ""], ["Malago", "Luigi", ""], ["Volpi", "Riccardo", ""]]}, {"id": "2008.06731", "submitter": "S. Ashwin Renganathan", "authors": "S. Ashwin Renganathan, Romit Maulik and, Jai Ahuja", "title": "Enhanced data efficiency using deep neural networks and Gaussian\n  processes for aerodynamic design optimization", "comments": "25 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adjoint-based optimization methods are attractive for aerodynamic shape\ndesign primarily due to their computational costs being independent of the\ndimensionality of the input space and their ability to generate high-fidelity\ngradients that can then be used in a gradient-based optimizer. This makes them\nvery well suited for high-fidelity simulation based aerodynamic shape\noptimization of highly parametrized geometries such as aircraft wings. However,\nthe development of adjoint-based solvers involve careful mathematical treatment\nand their implementation require detailed software development. Furthermore,\nthey can become prohibitively expensive when multiple optimization problems are\nbeing solved, each requiring multiple restarts to circumvent local optima. In\nthis work, we propose a machine learning enabled, surrogate-based framework\nthat replaces the expensive adjoint solver, without compromising on predicting\npredictive accuracy. Specifically, we first train a deep neural network (DNN)\nfrom training data generated from evaluating the high-fidelity simulation model\non a model-agnostic, design of experiments on the geometry shape parameters.\nThe optimum shape may then be computed by using a gradient-based optimizer\ncoupled with the trained DNN. Subsequently, we also perform a gradient-free\nBayesian optimization, where the trained DNN is used as the prior mean. We\nobserve that the latter framework (DNN-BO) improves upon the DNN-only based\noptimization strategy for the same computational cost. Overall, this framework\npredicts the true optimum with very high accuracy, while requiring far fewer\nhigh-fidelity function calls compared to the adjoint-based method. Furthermore,\nwe show that multiple optimization problems can be solved with the same machine\nlearning model with high accuracy, to amortize the offline costs associated\nwith constructing our models.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:09:21 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Renganathan", "S. Ashwin", ""], ["and", "Romit Maulik", ""], ["Ahuja", "Jai", ""]]}, {"id": "2008.06736", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Vladimir Braverman, Lin F. Yang", "title": "Obtaining Adjustable Regularization for Free via Iterate Averaging", "comments": "ICML 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization for optimization is a crucial technique to avoid overfitting\nin machine learning. In order to obtain the best performance, we usually train\na model by tuning the regularization parameters. It becomes costly, however,\nwhen a single round of training takes significant amount of time. Very\nrecently, Neu and Rosasco show that if we run stochastic gradient descent (SGD)\non linear regression problems, then by averaging the SGD iterates properly, we\nobtain a regularized solution. It left open whether the same phenomenon can be\nachieved for other optimization problems and algorithms. In this paper, we\nestablish an averaging scheme that provably converts the iterates of SGD on an\narbitrary strongly convex and smooth objective function to its regularized\ncounterpart with an adjustable regularization parameter. Our approaches can be\nused for accelerated and preconditioned optimization methods as well. We\nfurther show that the same methods work empirically on more general\noptimization objectives including neural networks. In sum, we obtain adjustable\nregularization for free for a large class of optimization problems and resolve\nan open question raised by Neu and Rosasco.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:28:05 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wu", "Jingfeng", ""], ["Braverman", "Vladimir", ""], ["Yang", "Lin F.", ""]]}, {"id": "2008.06738", "submitter": "Brahma Pavse", "authors": "Brahma Pavse, Ishan Durugkar, Josiah Hanna, Peter Stone", "title": "Reducing Sampling Error in Batch Temporal Difference Learning", "comments": "Accepted to International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is one of the main foundations of modern\nreinforcement learning. This paper studies the use of TD(0), a canonical TD\nalgorithm, to estimate the value function of a given policy from a batch of\ndata. In this batch setting, we show that TD(0) may converge to an inaccurate\nvalue function because the update following an action is weighted according to\nthe number of times that action occurred in the batch -- not the true\nprobability of the action under the given policy. To address this limitation,\nwe introduce \\textit{policy sampling error corrected}-TD(0) (PSEC-TD(0)).\nPSEC-TD(0) first estimates the empirical distribution of actions in each state\nin the batch and then uses importance sampling to correct for the mismatch\nbetween the empirical weighting and the correct weighting for updates following\neach action. We refine the concept of a certainty-equivalence estimate and\nargue that PSEC-TD(0) is a more data efficient estimator than TD(0) for a fixed\nbatch of data. Finally, we conduct an empirical evaluation of PSEC-TD(0) on\nthree batch value function learning tasks, with a hyperparameter sensitivity\nanalysis, and show that PSEC-TD(0) produces value function estimates with lower\nmean squared error than TD(0).\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:30:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pavse", "Brahma", ""], ["Durugkar", "Ishan", ""], ["Hanna", "Josiah", ""], ["Stone", "Peter", ""]]}, {"id": "2008.06767", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, Di Wang, Chenchen Liu,\n  Zhi Tian, Xiang Chen", "title": "Heterogeneous Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning learns from scattered data by fusing collaborative models\nfrom local nodes. However, due to chaotic information distribution, the model\nfusion may suffer from structural misalignment with regard to unmatched\nparameters. In this work, we propose a novel federated learning framework to\nresolve this issue by establishing a firm structure-information alignment\nacross collaborative models. Specifically, we design a feature-oriented\nregulation method ({$\\Psi$-Net}) to ensure explicit feature information\nallocation in different neural network structures. Applying this regulating\nmethod to collaborative models, matchable structures with similar feature\ninformation can be initialized at the very early training stage. During the\nfederated learning process under either IID or non-IID scenarios, dedicated\ncollaboration schemes further guarantee ordered information distribution with\ndefinite structure matching, so as the comprehensive model alignment.\nEventually, this framework effectively enhances the federated learning\napplicability to extensive heterogeneous settings, while providing excellent\nconvergence speed, accuracy, and computation/communication efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 19:06:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yu", "Fuxun", ""], ["Zhang", "Weishan", ""], ["Qin", "Zhuwei", ""], ["Xu", "Zirui", ""], ["Wang", "Di", ""], ["Liu", "Chenchen", ""], ["Tian", "Zhi", ""], ["Chen", "Xiang", ""]]}, {"id": "2008.06775", "submitter": "Karan Goel", "authors": "Karan Goel, Albert Gu, Yixuan Li and Christopher R\\'e", "title": "Model Patching: Closing the Subgroup Performance Gap with Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers in machine learning are often brittle when deployed. Particularly\nconcerning are models with inconsistent performance on specific subgroups of a\nclass, e.g., exhibiting disparities in skin cancer classification in the\npresence or absence of a spurious bandage. To mitigate these performance\ndifferences, we introduce model patching, a two-stage framework for improving\nrobustness that encourages the model to be invariant to subgroup differences,\nand focus on class information shared by subgroups. Model patching first models\nsubgroup features within a class and learns semantic transformations between\nthem, and then trains a classifier with data augmentations that deliberately\nmanipulate subgroup features. We instantiate model patching with CAMEL, which\n(1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and\n(2) balances subgroup performance using a theoretically-motivated subgroup\nconsistency regularizer, accompanied by a new robust objective. We demonstrate\nCAMEL's effectiveness on 3 benchmark datasets, with reductions in robust error\nof up to 33% relative to the best baseline. Lastly, CAMEL successfully patches\na model that fails due to spurious features on a real-world skin cancer\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:01:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Goel", "Karan", ""], ["Gu", "Albert", ""], ["Li", "Yixuan", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2008.06780", "submitter": "Francesco La Rosa", "authors": "Francesco La Rosa, Erin S Beck, Ahmed Abdulkadir, Jean-Philippe\n  Thiran, Daniel S Reich, Pascal Sati, Meritxell Bach Cuadra", "title": "Automated Detection of Cortical Lesions in Multiple Sclerosis Patients\n  with 7T MRI", "comments": "Accepted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated detection of cortical lesions (CLs) in patients with multiple\nsclerosis (MS) is a challenging task that, despite its clinical relevance, has\nreceived very little attention. Accurate detection of the small and scarce\nlesions requires specialized sequences and high or ultra-high field MRI. For\nsupervised training based on multimodal structural MRI at 7T, two experts\ngenerated ground truth segmentation masks of 60 patients with 2014 CLs. We\nimplemented a simplified 3D U-Net with three resolution levels (3D U-Net-). By\nincreasing the complexity of the task (adding brain tissue segmentation), while\nrandomly dropping input channels during training, we improved the performance\ncompared to the baseline. Considering a minimum lesion size of 0.75 {\\mu}L, we\nachieved a lesion-wise cortical lesion detection rate of 67% and a false\npositive rate of 42%. However, 393 (24%) of the lesions reported as false\npositives were post-hoc confirmed as potential or definite lesions by an\nexpert. This indicates the potential of the proposed method to support experts\nin the tedious process of CL manual segmentation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:35:12 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["La Rosa", "Francesco", ""], ["Beck", "Erin S", ""], ["Abdulkadir", "Ahmed", ""], ["Thiran", "Jean-Philippe", ""], ["Reich", "Daniel S", ""], ["Sati", "Pascal", ""], ["Cuadra", "Meritxell Bach", ""]]}, {"id": "2008.06786", "submitter": "Ben Adlam", "authors": "Ben Adlam and Jeffrey Pennington", "title": "The Neural Tangent Kernel in High Dimensions: Triple Descent and a\n  Multi-Scale Theory of Generalization", "comments": "Published as a conference paper in the Proceedings of the 37th\n  International Conference on Machine Learning; 31 pages; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning models employ considerably more parameters than required\nto fit the training data. Whereas conventional statistical wisdom suggests such\nmodels should drastically overfit, in practice these models generalize\nremarkably well. An emerging paradigm for describing this unexpected behavior\nis in terms of a \\emph{double descent} curve, in which increasing a model's\ncapacity causes its test error to first decrease, then increase to a maximum\nnear the interpolation threshold, and then decrease again in the\noverparameterized regime. Recent efforts to explain this phenomenon\ntheoretically have focused on simple settings, such as linear regression or\nkernel regression with unstructured random features, which we argue are too\ncoarse to reveal important nuances of actual neural networks. We provide a\nprecise high-dimensional asymptotic analysis of generalization under kernel\nregression with the Neural Tangent Kernel, which characterizes the behavior of\nwide neural networks optimized with gradient descent. Our results reveal that\nthe test error has non-monotonic behavior deep in the overparameterized regime\nand can even exhibit additional peaks and descents when the number of\nparameters scales quadratically with the dataset size.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:55:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Adlam", "Ben", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2008.06808", "submitter": "Jayden Ooi", "authors": "Henry Tsai, Jayden Ooi, Chun-Sung Ferng, Hyung Won Chung, Jason Riesa", "title": "Finding Fast Transformers: One-Shot Neural Architecture Search by\n  Component Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformer-based models have achieved stateof-the-art results in many tasks\nin natural language processing. However, such models are usually slow at\ninference time, making deployment difficult. In this paper, we develop an\nefficient algorithm to search for fast models while maintaining model quality.\nWe describe a novel approach to decompose the Transformer architecture into\nsmaller components, and propose a sampling-based one-shot architecture search\nmethod to find an optimal model for inference. The model search process is more\nefficient than alternatives, adding only a small overhead to training time. By\napplying our methods to BERT-base architectures, we achieve 10% to 30% speedup\nfor pre-trained BERT and 70% speedup on top of a previous state-of-the-art\ndistilled BERT model on Cloud TPU-v2 with a generally acceptable drop in\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 23:12:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tsai", "Henry", ""], ["Ooi", "Jayden", ""], ["Ferng", "Chun-Sung", ""], ["Chung", "Hyung Won", ""], ["Riesa", "Jason", ""]]}, {"id": "2008.06845", "submitter": "Weichen Wang", "authors": "Weichen Wang, Jiequn Han, Zhuoran Yang and Zhaoran Wang", "title": "Global Convergence of Policy Gradient for Linear-Quadratic Mean-Field\n  Control/Game in Continuous Time", "comments": "28 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a powerful tool to learn the optimal policy of\npossibly multiple agents by interacting with the environment. As the number of\nagents grow to be very large, the system can be approximated by a mean-field\nproblem. Therefore, it has motivated new research directions for mean-field\ncontrol (MFC) and mean-field game (MFG). In this paper, we study the policy\ngradient method for the linear-quadratic mean-field control and game, where we\nassume each agent has identical linear state transitions and quadratic cost\nfunctions. While most of the recent works on policy gradient for MFC and MFG\nare based on discrete-time models, we focus on the continuous-time models where\nsome analyzing techniques can be interesting to the readers. For both MFC and\nMFG, we provide policy gradient update and show that it converges to the\noptimal solution at a linear rate, which is verified by a synthetic simulation.\nFor MFG, we also provide sufficient conditions for the existence and uniqueness\nof the Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 06:34:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Weichen", ""], ["Han", "Jiequn", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2008.06853", "submitter": "Ce Ju", "authors": "Ce Ju", "title": "Geometric Foundations of Data Reduction", "comments": "79 pages, Suvery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to write a complete survey of the (spectral)\nmanifold learning methods and nonlinear dimensionality reduction (NLDR) in data\nreduction. The first two NLDR methods in history were respectively published in\nScience in 2000 in which they solve the similar reduction problem of\nhigh-dimensional data endowed with the intrinsic nonlinear structure. The\nintrinsic nonlinear structure is always interpreted as a concept in manifolds\nfrom geometry and topology in theoretical mathematics by computer scientists\nand theoretical physicists. In 2001, the concept of Manifold Learning first\nappears as an NLDR method called Laplacian Eigenmaps purposed by Belkin and\nNiyogi. In the typical manifold learning setup, the data set, also called the\nobservation set, is distributed on or near a low dimensional manifold $M$\nembedded in $\\mathbb{R}^D$, which yields that each observation has a\n$D$-dimensional representation. The goal of (spectral) manifold learning is to\nreduce these observations as a compact lower-dimensional representation based\non the geometric information. The reduction procedure is called the (spectral)\nmanifold learning method. In this paper, we derive each (spectral) manifold\nlearning method with the matrix and operator representation, and we then\ndiscuss the convergence behavior of each method in a geometric uniform\nlanguage. Hence, we name the survey Geometric Foundations of Data Reduction.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 07:59:22 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ju", "Ce", ""]]}, {"id": "2008.06856", "submitter": "Guy Amit", "authors": "Guy Amit, Moshe Levy, Ishai Rosenberg, Asaf Shabtai, Yuval Elovici", "title": "FOOD: Fast Out-Of-Distribution Detector", "comments": "Guy Amit and Moshe Levy contributed equally to this paper Updated\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) perform well at classifying inputs associated\nwith the classes they have been trained on, which are known as in distribution\ninputs. However, out-of-distribution (OOD) inputs pose a great challenge to\nDNNs and consequently represent a major risk when DNNs are implemented in\nsafety-critical systems. Extensive research has been performed in the domain of\nOOD detection. However, current state-of-the-art methods for OOD detection\nsuffer from at least one of the following limitations: (1) increased inference\ntime - this limits existing methods' applicability to many real-world\napplications, and (2) the need for OOD training data - such data can be\ndifficult to acquire and may not be representative enough, thus limiting the\nability of the OOD detector to generalize. In this paper, we propose FOOD --\nFast Out-Of-Distribution detector -- an extended DNN classifier capable of\nefficiently detecting OOD samples with minimal inference time overhead. Our\narchitecture features a DNN with a final Gaussian layer combined with the log\nlikelihood ratio statistical test and an additional output neuron for OOD\ndetection. Instead of using real OOD data, we use a novel method to craft\nartificial OOD samples from in-distribution data, which are used to train our\nOOD detector neuron. We evaluate FOOD's detection performance on the SVHN,\nCIFAR-10, and CIFAR-100 datasets. Our results demonstrate that in addition to\nachieving state-of-the-art performance, FOOD is fast and applicable to\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 08:22:43 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 11:48:23 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 15:41:10 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 16:19:52 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Amit", "Guy", ""], ["Levy", "Moshe", ""], ["Rosenberg", "Ishai", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2008.06885", "submitter": "Tsuyoshi Kato", "authors": "Takahiko Henmi, Esmeraldo Ronnie Rey Zara, Yoshihiro Hirohashi,\n  Tsuyoshi Kato", "title": "Adaptive Signal Variances: CNN Initialization Through Modern\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) have achieved the unwavering\nconfidence in its performance on image processing tasks. The CNN architecture\nconstitutes a variety of different types of layers including the convolution\nlayer and the max-pooling layer. CNN practitioners widely understand the fact\nthat the stability of learning depends on how to initialize the model\nparameters in each layer. Nowadays, no one doubts that the de facto standard\nscheme for initialization is the so-called Kaiming initialization that has been\ndeveloped by He et al. The Kaiming scheme was derived from a much simpler model\nthan the currently used CNN structure having evolved since the emergence of the\nKaiming scheme. The Kaiming model consists only of the convolution and fully\nconnected layers, ignoring the max-pooling layer and the global average pooling\nlayer. In this study, we derived the initialization scheme again not from the\nsimplified Kaiming model, but precisely from the modern CNN architectures, and\nempirically investigated how the new initialization method performs compared to\nthe de facto standard ones that are widely used today.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:26:29 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 06:11:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Henmi", "Takahiko", ""], ["Zara", "Esmeraldo Ronnie Rey", ""], ["Hirohashi", "Yoshihiro", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "2008.06933", "submitter": "Anna Bogomolova", "authors": "Anna Bogomolova, Kseniia Kingsep and Boris Voskresenskii", "title": "The reinforcement learning-based multi-agent cooperative approach for\n  the adaptive speed regulation on a metallurgical pickling line", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a holistic data-driven approach to the problem of productivity\nincrease on the example of a metallurgical pickling line. The proposed approach\ncombines mathematical modeling as a base algorithm and a cooperative\nMulti-Agent Reinforcement Learning (MARL) system implemented such as to enhance\nthe performance by multiple criteria while also meeting safety and reliability\nrequirements and taking into account the unexpected volatility of certain\ntechnological processes. We demonstrate how Deep Q-Learning can be applied to a\nreal-life task in a heavy industry, resulting in significant improvement of\npreviously existing automation systems.The problem of input data scarcity is\nsolved by a two-step combination of LSTM and CGAN, which helps to embrace both\nthe tabular representation of the data and its sequential properties. Offline\nRL training, a necessity in this setting, has become possible through the\nsophisticated probabilistic kinematic environment.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 15:10:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bogomolova", "Anna", ""], ["Kingsep", "Kseniia", ""], ["Voskresenskii", "Boris", ""]]}, {"id": "2008.06952", "submitter": "Aaron Zweig", "authors": "Aaron Zweig, Joan Bruna", "title": "A Functional Perspective on Learning Symmetric Functions with Neural\n  Networks", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric functions, which take as input an unordered, fixed-size set, are\nknown to be universally representable by neural networks that enforce\npermutation invariance. These architectures only give guarantees for fixed\ninput sizes, yet in many practical applications, including point clouds and\nparticle physics, a relevant notion of generalization should include varying\nthe input size. In this work we treat symmetric functions (of any size) as\nfunctions over probability measures, and study the learning and representation\nof neural networks defined on measures. By focusing on shallow architectures,\nwe establish approximation and generalization bounds under different choices of\nregularization (such as RKHS and variation norms), that capture a hierarchy of\nfunctional spaces with increasing degree of non-linear learning. The resulting\nmodels can be learned efficiently and enjoy generalization guarantees that\nextend across input sizes, as we verify empirically.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 16:34:33 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 15:50:04 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 22:50:58 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zweig", "Aaron", ""], ["Bruna", "Joan", ""]]}, {"id": "2008.06973", "submitter": "Mansoor Rezghi", "authors": "S. Amirreza Badran, Mansoor Rezghi", "title": "An adaptive synchronization approach for weights of deep reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Q-Networks (DQN) is one of the most well-known methods of deep\nreinforcement learning, which uses deep learning to approximate the\naction-value function. Solving numerous Deep reinforcement learning challenges\nsuch as moving targets problem and the correlation between samples are the main\nadvantages of this model. Although there have been various extensions of DQN in\nrecent years, they all use a similar method to DQN to overcome the problem of\nmoving targets. Despite the advantages mentioned, synchronizing the network\nweight in a fixed step size, independent of the agent's behavior, may in some\ncases cause the loss of some properly learned networks. These lost networks may\nlead to states with more rewards, hence better samples stored in the replay\nmemory for future training. In this paper, we address this problem from the DQN\nfamily and provide an adaptive approach for the synchronization of the neural\nweights used in DQN. In this method, the synchronization of weights is done\nbased on the recent behavior of the agent, which is measured by a criterion at\nthe end of the intervals. To test this method, we adjusted the DQN and rainbow\nmethods with the proposed adaptive synchronization method. We compared these\nadjusted methods with their standard form on well-known games, which results\nconfirm the quality of our synchronization methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 18:49:35 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Badran", "S. Amirreza", ""], ["Rezghi", "Mansoor", ""]]}, {"id": "2008.06996", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov, John Hopfield", "title": "Large Associative Memory Problem in Neurobiology and Machine Learning", "comments": "Accepted for publication at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or modern Hopfield networks permit storage and\nreliable retrieval of an exponentially large (in the dimension of feature\nspace) number of memories. At the same time, their naive implementation is\nnon-biological, since it seemingly requires the existence of many-body synaptic\njunctions between the neurons. We show that these models are effective\ndescriptions of a more microscopic (written in terms of biological degrees of\nfreedom) theory that has additional (hidden) neurons and only requires two-body\ninteractions between them. For this reason our proposed microscopic theory is a\nvalid model of large associative memory with a degree of biological\nplausibility. The dynamics of our network and its reduced dimensional\nequivalent both minimize energy (Lyapunov) functions. When certain dynamical\nvariables (hidden neurons) are integrated out from our microscopic theory, one\ncan recover many of the models that were previously discussed in the\nliterature, e.g. the model presented in \"Hopfield Networks is All You Need\"\npaper. We also provide an alternative derivation of the energy function and the\nupdate rule proposed in the aforementioned paper and clarify the relationships\nbetween various models of this class.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:03:52 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 20:06:50 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 22:20:05 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Krotov", "Dmitry", ""], ["Hopfield", "John", ""]]}, {"id": "2008.07007", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "Towards Faithful and Meaningful Interpretable Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable representations are the backbone of many black-box explainers.\nThey translate the low-level data representation necessary for good predictive\nperformance into high-level human-intelligible concepts used to convey the\nexplanation. Notably, the explanation type and its cognitive complexity are\ndirectly controlled by the interpretable representation, allowing to target a\nparticular audience and use case. However, many explainers that rely on\ninterpretable representations overlook their merit and fall back on default\nsolutions, which may introduce implicit assumptions, thereby degrading the\nexplanatory power of such techniques. To address this problem, we study\nproperties of interpretable representations that encode presence and absence of\nhuman-comprehensible concepts. We show how they are operationalised for\ntabular, image and text data, discussing their strengths and weaknesses.\nFinally, we analyse their explanatory properties in the context of tabular\ndata, where a linear model is used to quantify the importance of interpretable\nconcepts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:44:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2008.07009", "submitter": "Lucas N. Ferreira", "authors": "Lucas N. Ferreira, Levi H. S. Lelis and Jim Whitehead", "title": "Computer-Generated Music for Tabletop Role-Playing Games", "comments": "To be published in the 16th AAAI Conference ON Artificial\n  Intelligence and Interactive Digital Entertainment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present Bardo Composer, a system to generate background\nmusic for tabletop role-playing games. Bardo Composer uses a speech recognition\nsystem to translate player speech into text, which is classified according to a\nmodel of emotion. Bardo Composer then uses Stochastic Bi-Objective Beam Search,\na variant of Stochastic Beam Search that we introduce in this paper, with a\nneural model to generate musical pieces conveying the desired emotion. We\nperformed a user study with 116 participants to evaluate whether people are\nable to correctly identify the emotion conveyed in the pieces generated by the\nsystem. In our study we used pieces generated for Call of the Wild, a Dungeons\nand Dragons campaign available on YouTube. Our results show that human subjects\ncould correctly identify the emotion of the generated music pieces as\naccurately as they were able to identify the emotion of pieces written by\nhumans.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:53:49 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ferreira", "Lucas N.", ""], ["Lelis", "Levi H. S.", ""], ["Whitehead", "Jim", ""]]}, {"id": "2008.07029", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Uncertainty aware Search Framework for Multi-Objective Bayesian\n  Optimization with Constraints", "comments": "9 pages, 2 figures, 1 table", "journal-ref": "7th ICML Workshop on Automated Machine Learning (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constrained multi-objective (MO) blackbox\noptimization using expensive function evaluations, where the goal is to\napproximate the true Pareto set of solutions satisfying a set of constraints\nwhile minimizing the number of function evaluations. We propose a novel\nframework named Uncertainty-aware Search framework for Multi-Objective\nOptimization with Constraints (USeMOC) to efficiently select the sequence of\ninputs for evaluation to solve this problem. The selection method of USeMOC\nconsists of solving a cheap constrained MO optimization problem via surrogate\nmodels of the true functions to identify the most promising candidates and\npicking the best candidate based on a measure of uncertainty. We applied this\nframework to optimize the design of a multi-output switched-capacitor voltage\nregulator via expensive simulations. Our experimental results show that USeMOC\nis able to achieve more than 90 % reduction in the number of simulations needed\nto uncover optimized circuits.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 23:34:09 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 04:53:56 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2008.07032", "submitter": "Zhe Chen", "authors": "Zhe Chen, Yuyan Wang, Dong Lin, Derek Zhiyuan Cheng, Lichan Hong, Ed\n  H. Chi, Claire Cui", "title": "Beyond Point Estimate: Inferring Ensemble Prediction Variation from\n  Neuron Activation Strength in Recommender Systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite deep neural network (DNN)'s impressive prediction performance in\nvarious domains, it is well known now that a set of DNN models trained with the\nsame model specification and the same data can produce very different\nprediction results. Ensemble method is one state-of-the-art benchmark for\nprediction uncertainty estimation. However, ensembles are expensive to train\nand serve for web-scale traffic.\n  In this paper, we seek to advance the understanding of prediction variation\nestimated by the ensemble method. Through empirical experiments on two widely\nused benchmark datasets MovieLens and Criteo in recommender systems, we observe\nthat prediction variations come from various randomness sources, including\ntraining data shuffling, and parameter random initialization. By introducing\nmore randomness into model training, we notice that ensemble's mean predictions\ntend to be more accurate while the prediction variations tend to be higher.\nMoreover, we propose to infer prediction variation from neuron activation\nstrength and demonstrate the strong prediction power from activation strength\nfeatures. Our experiment results show that the average R squared on MovieLens\nis as high as 0.56 and on Criteo is 0.81. Our method performs especially well\nwhen detecting the lowest and highest variation buckets, with 0.92 AUC and 0.89\nAUC respectively. Our approach provides a simple way for prediction variation\nestimation, which opens up new opportunities for future work in many\ninteresting areas (e.g.,model-based reinforcement learning) without relying on\nserving expensive ensemble models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 00:08:27 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Zhe", ""], ["Wang", "Yuyan", ""], ["Lin", "Dong", ""], ["Cheng", "Derek Zhiyuan", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""], ["Cui", "Claire", ""]]}, {"id": "2008.07044", "submitter": "Liangyuan Hu", "authors": "Liangyuan Hu, Jiayi Ji, Fan Li", "title": "Estimating heterogeneous survival treatment effect in observational data\n  using machine learning", "comments": "23 pages, 5 figures, 3 tables", "journal-ref": "Statistics in Medicine,2021;00:1-23 (2021)", "doi": "10.1002/sim.9090", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Methods for estimating heterogeneous treatment effect in observational data\nhave largely focused on continuous or binary outcomes, and have been relatively\nless vetted with survival outcomes. Using flexible machine learning methods in\nthe counterfactual framework is a promising approach to address challenges due\nto complex individual characteristics, to which treatments need to be tailored.\nTo evaluate the operating characteristics of recent survival machine learning\nmethods for the estimation of treatment effect heterogeneity and inform better\npractice, we carry out a comprehensive simulation study presenting a wide range\nof settings describing confounded heterogeneous survival treatment effects and\nvarying degrees of covariate overlap. Our results suggest that the\nnonparametric Bayesian Additive Regression Trees within the framework of\naccelerated failure time model (AFT-BART-NP) consistently yields the best\nperformance, in terms of bias, precision and expected regret. Moreover, the\ncredible interval estimators from AFT-BART-NP provide close to nominal\nfrequentist coverage for the individual survival treatment effect when the\ncovariate overlap is at least moderate. Including a non-parametrically\nestimated propensity score as an additional fixed covariate in the AFT-BART-NP\nmodel formulation can further improve its efficiency and frequentist coverage.\nFinally, we demonstrate the application of flexible causal machine learning\nestimators through a comprehensive case study examining the heterogeneous\nsurvival effects of two radiotherapy approaches for localized high-risk\nprostate cancer.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 01:02:14 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:09:58 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 19:38:10 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 15:54:08 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Hu", "Liangyuan", ""], ["Ji", "Jiayi", ""], ["Li", "Fan", ""]]}, {"id": "2008.07055", "submitter": "Mark Herbster", "authors": "Mark Herbster, Stephen Pasteris, Lisa Tse", "title": "Online Multitask Learning with Long-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel online multitask setting. In this setting each task is\npartitioned into a sequence of segments that is unknown to the learner.\nAssociated with each segment is a hypothesis from some hypothesis class. We\ngive algorithms that are designed to exploit the scenario where there are many\nsuch segments but significantly fewer associated hypotheses. We prove regret\nbounds that hold for any segmentation of the tasks and any association of\nhypotheses to the segments. In the single-task setting this is equivalent to\nswitching with long-term memory in the sense of [Bousquet and Warmuth; 2003].\nWe provide an algorithm that predicts on each trial in time linear in the\nnumber of hypotheses when the hypothesis class is finite. We also consider\ninfinite hypothesis classes from reproducing kernel Hilbert spaces for which we\ngive an algorithm whose per trial time complexity is cubic in the number of\ncumulative trials. In the single-task special case this is the first example of\nan efficient regret-bounded switching algorithm with long-term memory for a\nnon-parametric hypothesis class.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 01:43:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Herbster", "Mark", ""], ["Pasteris", "Stephen", ""], ["Tse", "Lisa", ""]]}, {"id": "2008.07063", "submitter": "Philippe Goulet Coulombe", "authors": "Philippe Goulet Coulombe", "title": "To Bag is to Prune", "comments": "added references; corrected typos; added NN discussions and results,\n  new experiments and discussion on double descent", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is notoriously difficult to build a bad Random Forest (RF). Concurrently,\nRF blatantly overfits in-sample without any apparent consequence out-of-sample.\nStandard arguments, like the classic bias-variance trade-off or double descent,\ncannot rationalize this paradox. I propose a new explanation: bootstrap\naggregation and model perturbation as implemented by RF automatically prune a\nlatent \"true\" tree. More generally, randomized ensembles of greedily optimized\nlearners implicitly perform optimal early stopping out-of-sample. So there is\nno need to tune the stopping point. By construction, novel variants of Boosting\nand MARS are also eligible for automatic tuning. I empirically demonstrate the\nproperty, with simulated and real data, by reporting that these new completely\noverfitting ensembles perform similarly to their tuned counterparts -- or\nbetter.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 02:45:32 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 04:10:02 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 16:54:07 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 21:54:35 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Coulombe", "Philippe Goulet", ""]]}, {"id": "2008.07079", "submitter": "Quentin Gendre", "authors": "Quentin Gendre, Tomoyuki Kaneko", "title": "Playing Catan with Cross-dimensional Neural Network", "comments": "12 pages, 5 tables and 10 figures; submitted to the ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catan is a strategic board game having interesting properties, including\nmulti-player, imperfect information, stochastic, complex state space structure\n(hexagonal board where each vertex, edge and face has its own features, cards\nfor each player, etc), and a large action space (including negotiation).\nTherefore, it is challenging to build AI agents by Reinforcement Learning (RL\nfor short), without domain knowledge nor heuristics. In this paper, we\nintroduce cross-dimensional neural networks to handle a mixture of information\nsources and a wide variety of outputs, and empirically demonstrate that the\nnetwork dramatically improves RL in Catan. We also show that, for the first\ntime, a RL agent can outperform jsettler, the best heuristic agent available.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:09:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Gendre", "Quentin", ""], ["Kaneko", "Tomoyuki", ""]]}, {"id": "2008.07081", "submitter": "Xiaoyi Chen", "authors": "Xiaoyi Chen, Pratik Chaudhari", "title": "MIDAS: Multi-agent Interaction-aware Decision-making with Adaptive\n  Strategies for Urban Autonomous Navigation", "comments": "Code available at https://github.com/sherrychen1120/MIDAS. To be\n  presented at IEEE International Conference on Robotics and Automation (ICRA),\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous navigation in crowded, complex urban environments requires\ninteracting with other agents on the road. A common solution to this problem is\nto use a prediction model to guess the likely future actions of other agents.\nWhile this is reasonable, it leads to overly conservative plans because it does\nnot explicitly model the mutual influence of the actions of interacting agents.\nThis paper builds a reinforcement learning-based method named MIDAS where an\nego-agent learns to affect the control actions of other cars in urban driving\nscenarios. MIDAS uses an attention-mechanism to handle an arbitrary number of\nother agents and includes a \"driver-type\" parameter to learn a single policy\nthat works across different planning objectives. We build a simulation\nenvironment that enables diverse interaction experiments with a large number of\nagents and methods for quantitatively studying the safety, efficiency, and\ninteraction among vehicles. MIDAS is validated using extensive experiments and\nwe show that it (i) can work across different road geometries, (ii) results in\nan adaptive ego policy that can be tuned easily to satisfy performance criteria\nsuch as aggressive or cautious driving, (iii) is robust to changes in the\ndriving policies of external agents, and (iv) is more efficient and safer than\nexisting approaches to interaction-aware decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:34:25 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 05:05:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Chen", "Xiaoyi", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2008.07085", "submitter": "Soham Deshmukh", "authors": "Soham Deshmukh, Bhiksha Raj, Rita Singh", "title": "Multi-Task Learning for Interpretable Weakly Labelled Sound Event\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly Labelled learning has garnered lot of attention in recent years due to\nits potential to scale Sound Event Detection (SED) and is formulated as\nMultiple Instance Learning (MIL) problem. This paper proposes a Multi-Task\nLearning (MTL) framework for learning from Weakly Labelled Audio data which\nencompasses the traditional MIL setup. To show the utility of proposed\nframework, we use the input TimeFrequency representation (T-F) reconstruction\nas the auxiliary task. We show that the chosen auxiliary task de-noises\ninternal T-F representation and improves SED performance under noisy\nrecordings. Our second contribution is introducing two step Attention Pooling\nmechanism. By having 2-steps in attention mechanism, the network retains better\nT-F level information without compromising SED performance. The visualisation\nof first step and second step attention weights helps in localising the\naudio-event in T-F domain. For evaluating the proposed framework, we remix the\nDCASE 2019 task 1 acoustic scene data with DCASE 2018 Task 2 sounds event data\nunder 0, 10 and 20 db SNR resulting in a multi-class Weakly labelled SED\nproblem. The proposed total framework outperforms existing benchmark models\nover all SNRs, specifically 22.3 %, 12.8 %, 5.9 % improvement over benchmark\nmodel on 0, 10 and 20 dB SNR respectively. We carry out ablation study to\ndetermine the contribution of each auxiliary task and 2-step Attention Pooling\nto the SED performance improvement. The code is publicly released\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:46:25 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:22:09 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Deshmukh", "Soham", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "2008.07087", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Yuke Zhu, Jure Leskovec, Anima Anandkumar, Animesh Garg", "title": "OCEAN: Online Task Inference for Compositional Tasks with Context\n  Adaptation", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world tasks often exhibit a compositional structure that contains a\nsequence of simpler sub-tasks. For instance, opening a door requires reaching,\ngrasping, rotating, and pulling the door knob. Such compositional tasks require\nan agent to reason about the sub-task at hand while orchestrating global\nbehavior accordingly. This can be cast as an online task inference problem,\nwhere the current task identity, represented by a context variable, is\nestimated from the agent's past experiences with probabilistic inference.\nPrevious approaches have employed simple latent distributions, e.g., Gaussian,\nto model a single context for the entire task. However, this formulation lacks\nthe expressiveness to capture the composition and transition of the sub-tasks.\nWe propose a variational inference framework OCEAN to perform online task\ninference for compositional tasks. OCEAN models global and local context\nvariables in a joint latent space, where the global variables represent a\nmixture of sub-tasks required for the task, while the local variables capture\nthe transitions between the sub-tasks. Our framework supports flexible latent\ndistributions based on prior knowledge of the task structure and can be trained\nin an unsupervised manner. Experimental results show that OCEAN provides more\neffective task inference with sequential context adaptation and thus leads to a\nperformance boost on complex, multi-stage tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:50:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ren", "Hongyu", ""], ["Zhu", "Yuke", ""], ["Leskovec", "Jure", ""], ["Anandkumar", "Anima", ""], ["Garg", "Animesh", ""]]}, {"id": "2008.07092", "submitter": "Mahima Chaudhary", "authors": "Mahima Chaudhary, Sumona Mukhopadhyay, Marin Litoiu, Lauren E Sergio,\n  Meaghan S Adams", "title": "Understanding Brain Dynamics for Color Perception using Wearable EEG\n  headband", "comments": "10 pages,10 figures, Conference- EVOKE CASCON 2020", "journal-ref": "Proceedings of 30th Annual International Conference on Computer\n  Science and Software Engineering 2020", "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The perception of color is an important cognitive feature of the human brain.\nThe variety of colors that impinge upon the human eye can trigger changes in\nbrain activity which can be captured using electroencephalography (EEG). In\nthis work, we have designed a multiclass classification model to detect the\nprimary colors from the features of raw EEG signals. In contrast to previous\nresearch, our method employs spectral power features, statistical features as\nwell as correlation features from the signal band power obtained from\ncontinuous Morlet wavelet transform instead of raw EEG, for the classification\ntask. We have applied dimensionality reduction techniques such as Forward\nFeature Selection and Stacked Autoencoders to reduce the dimension of data\neventually increasing the model's efficiency. Our proposed methodology using\nForward Selection and Random Forest Classifier gave the best overall accuracy\nof 80.6\\% for intra-subject classification. Our approach shows promise in\ndeveloping techniques for cognitive tasks using color cues such as controlling\nInternet of Thing (IoT) devices by looking at primary colors for individuals\nwith restricted motor abilities.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 05:25:16 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Chaudhary", "Mahima", ""], ["Mukhopadhyay", "Sumona", ""], ["Litoiu", "Marin", ""], ["Sergio", "Lauren E", ""], ["Adams", "Meaghan S", ""]]}, {"id": "2008.07097", "submitter": "Jiaying Liu", "authors": "Jiaying Liu, Feng Xia, Lei Wang, Bo Xu, Xiangjie Kong, Hanghang Tong,\n  and Irwin King", "title": "Shifu2: A Network Representation Learning Based Model for\n  Advisor-advisee Relationship Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advisor-advisee relationship represents direct knowledge heritage, and\nsuch relationship may not be readily available from academic libraries and\nsearch engines. This work aims to discover advisor-advisee relationships hidden\nbehind scientific collaboration networks. For this purpose, we propose a novel\nmodel based on Network Representation Learning (NRL), namely Shifu2, which\ntakes the collaboration network as input and the identified advisor-advisee\nrelationship as output. In contrast to existing NRL models, Shifu2 considers\nnot only the network structure but also the semantic information of nodes and\nedges. Shifu2 encodes nodes and edges into low-dimensional vectors\nrespectively, both of which are then utilized to identify advisor-advisee\nrelationships. Experimental results illustrate improved stability and\neffectiveness of the proposed model over state-of-the-art methods. In addition,\nwe generate a large-scale academic genealogy dataset by taking advantage of\nShifu2.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 05:40:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Liu", "Jiaying", ""], ["Xia", "Feng", ""], ["Wang", "Lei", ""], ["Xu", "Bo", ""], ["Kong", "Xiangjie", ""], ["Tong", "Hanghang", ""], ["King", "Irwin", ""]]}, {"id": "2008.07110", "submitter": "Didong Li", "authors": "Debolina Paul, Saptarshi Chakraborty, Didong Li and David Dunson", "title": "Principal Ellipsoid Analysis (PEA): Efficient non-linear dimension\n  reduction & clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even with the rise in popularity of over-parameterized models, simple\ndimensionality reduction and clustering methods, such as PCA and k-means, are\nstill routinely used in an amazing variety of settings. A primary reason is the\ncombination of simplicity, interpretability and computational efficiency. The\nfocus of this article is on improving upon PCA and k-means, by allowing\nnon-linear relations in the data and more flexible cluster shapes, without\nsacrificing the key advantages. The key contribution is a new framework for\nPrincipal Elliptical Analysis (PEA), defining a simple and computationally\nefficient alternative to PCA that fits the best elliptical approximation\nthrough the data. We provide theoretical guarantees on the proposed PEA\nalgorithm using Vapnik-Chervonenkis (VC) theory to show strong consistency and\nuniform concentration bounds. Toy experiments illustrate the performance of\nPEA, and the ability to adapt to non-linear structure and complex cluster\nshapes. In a rich variety of real data clustering applications, PEA is shown to\ndo as well as k-means for simple datasets, while dramatically improving\nperformance in more complex settings.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 06:25:50 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 03:23:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Paul", "Debolina", ""], ["Chakraborty", "Saptarshi", ""], ["Li", "Didong", ""], ["Dunson", "David", ""]]}, {"id": "2008.07146", "submitter": "Yuta Saito", "authors": "Yuta Saito, Shunsuke Aihara, Megumi Matsutani, Yusuke Narita", "title": "Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible\n  Off-Policy Evaluation", "comments": "Please follow the updates of the whole project at\n  https://groups.google.com/g/open-bandit-project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) aims to estimate the performance of hypothetical\npolicies using data generated by a different policy. Because of its huge\npotential impact, there has been growing research interest in OPE. There is,\nhowever, no real-world public dataset that enables the evaluation of OPE,\nmaking its experimental studies unrealistic and irreproducible. With the goal\nof enabling realistic and reproducible OPE research, we publicize the Open\nBandit Dataset collected on a large-scale fashion e-commerce platform,\nZOZOTOWN. Our dataset is unique in that it contains a set of multiple logged\nbandit feedback datasets collected by running different policies on the same\nplatform. This enables realistic and reproducible experimental comparisons of\ndifferent OPE estimators for the first time. We also develop Python software\ncalled the Open Bandit Pipeline to streamline and standardize the\nimplementations of bandit algorithms and OPE. Our open data and pipeline will\ncontribute to the fair and transparent OPE research and help the community\nidentify fruitful research directions. Finally, we provide extensive benchmark\nexperiments of existing OPE estimators using our data and pipeline. Our\nexperiments open up essential challenges and new avenues for future OPE\nresearch. Our pipeline and example data are available at\nhttps://github.com/st-tech/zr-obp.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:23:50 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 14:39:36 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 18:11:53 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Saito", "Yuta", ""], ["Aihara", "Shunsuke", ""], ["Matsutani", "Megumi", ""], ["Narita", "Yusuke", ""]]}, {"id": "2008.07180", "submitter": "Antonious Girgis Mamdouh", "authors": "Antonious M. Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and\n  Ananda Theertha Suresh", "title": "Shuffled Model of Federated Learning: Privacy, Communication and\n  Accuracy Trade-offs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed empirical risk minimization (ERM) optimization\nproblem with communication efficiency and privacy requirements, motivated by\nthe federated learning (FL) framework. Unique challenges to the traditional ERM\nproblem in the context of FL include (i) need to provide privacy guarantees on\nclients' data, (ii) compress the communication between clients and the server,\nsince clients might have low-bandwidth links, (iii) work with a dynamic client\npopulation at each round of communication between the server and the clients,\nas a small fraction of clients are sampled at each round. To address these\nchallenges we develop (optimal) communication-efficient schemes for private\nmean estimation for several $\\ell_p$ spaces, enabling efficient gradient\naggregation for each iteration of the optimization solution of the ERM. We also\nprovide lower and upper bounds for mean estimation with privacy and\ncommunication constraints for arbitrary $\\ell_p$ spaces. To get the overall\ncommunication, privacy, and optimization performance operation point, we\ncombine this with privacy amplification opportunities inherent to this setup.\nOur solution takes advantage of the inherent privacy amplification provided by\nclient sampling and data sampling at each client (through Stochastic Gradient\nDescent) as well as the recently developed privacy framework using\nanonymization, which effectively presents to the server responses that are\nrandomly shuffled with respect to the clients. Putting these together, we\ndemonstrate that one can get the same privacy, optimization-performance\noperating point developed in recent methods that use full-precision\ncommunication, but at a much lower communication cost, i.e., effectively\ngetting communication efficiency for \"free\".\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 09:41:04 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 16:54:50 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Girgis", "Antonious M.", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""], ["Kairouz", "Peter", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2008.07192", "submitter": "Antonio Ferrara", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Antonio Ferrara,\n  Fedelucio Narducci", "title": "How to Put Users in Control of their Data in Federated Top-N\n  Recommendation with Learning to Rank", "comments": "Accepted at the 36th ACM/SIGAPP Symposium on Applied Computing (SAC\n  '21)", "journal-ref": null, "doi": "10.1145/3412841.3442010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommendation services are extensively adopted in several user-centered\napplications as a tool to alleviate the information overload problem and help\nusers in orienteering in a vast space of possible choices. In such scenarios,\ndata ownership is a crucial concern since users may not be willing to share\ntheir sensitive preferences (e.g., visited locations) with a central server.\nUnfortunately, data harvesting and collection is at the basis of modern,\nstate-of-the-art approaches to recommendation. To address this issue, we\npresent FPL, an architecture in which users collaborate in training a central\nfactorization model while controlling the amount of sensitive data leaving\ntheir devices. The proposed approach implements pair-wise learning-to-rank\noptimization by following the Federated Learning principles, originally\nconceived to mitigate the privacy risks of traditional machine learning. The\npublic implementation is available at https://split.to/sisinflab-fpl.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:13:15 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 15:45:41 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 20:24:20 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 10:14:40 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Ferrara", "Antonio", ""], ["Narducci", "Fedelucio", ""]]}, {"id": "2008.07244", "submitter": "Piotr Masztalski", "authors": "Micha{\\l} Romaniuk, Piotr Masztalski, Karol Piaskowski, Mateusz\n  Matuszewski", "title": "Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming\n  Networks", "comments": "Accepted for INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Mobile Audio Streaming Networks (MASnet) for efficient low-latency\nspeech enhancement, which is particularly suitable for mobile devices and other\napplications where computational capacity is a limitation. MASnet processes\nlinear-scale spectrograms, transforming successive noisy frames into\ncomplex-valued ratio masks which are then applied to the respective noisy\nframes. MASnet can operate in a low-latency incremental inference mode which\nmatches the complexity of layer-by-layer batch mode. Compared to a similar\nfully-convolutional architecture, MASnet incorporates depthwise and pointwise\nconvolutions for a large reduction in fused multiply-accumulate operations per\nsecond (FMA/s), at the cost of some reduction in SNR.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:18:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Romaniuk", "Micha\u0142", ""], ["Masztalski", "Piotr", ""], ["Piaskowski", "Karol", ""], ["Matuszewski", "Mateusz", ""]]}, {"id": "2008.07249", "submitter": "Reza Malekian Ph.D.", "authors": "Jessica Quach, Reza Malekian", "title": "Exploring the weather impact on bike sharing usage through a clustering\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike sharing systems (BSS) have been a popular traveling service for years\nand are used worldwide. It is attractive for cities and users who wants to\npromote healthier lifestyles; to reduce air pollution and greenhouse gas\nemission as well as improve traffic. One major challenge to docked bike sharing\nsystem is redistributing bikes and balancing dock stations. Some studies\npropose models that can help forecasting bike usage; strategies for rebalancing\nbike distribution; establish patterns or how to identify patterns. Other\nstudies propose to extend the approach by including weather data. This study\naims to extend upon these proposals and opportunities to explore how and in\nwhat magnitude weather impacts bike usage. Bike usage data and weather data are\ngathered for the city of Washington D.C. and are analyzed using k-means\nclustering algorithm. K-means managed to identify three clusters that\ncorrespond to bike usage depending on weather conditions. The results show that\nthe weather impact on bike usage was noticeable between clusters. It showed\nthat temperature followed by precipitation weighted the most, out of five\nweather variables.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:24:37 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Quach", "Jessica", ""], ["Malekian", "Reza", ""]]}, {"id": "2008.07257", "submitter": "Yuan Liang", "authors": "Yuan Liang, Yange Guo, Yanxia Gong, Chunjie Luo, Jianfeng Zhan, Yunyou\n  Huang", "title": "FLBench: A Benchmark Suite for Federated Learning", "comments": "12 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a new machine learning paradigm. The goal is to build a\nmachine learning model from the data sets distributed on multiple devices\nso-called an isolated data island, while keeping their data secure and private.\nMost existing federated learning benchmarks work manually splits commonly used\npublic datasets into partitions to simulate real world isolated data island\nscenarios. Still, this simulation fails to capture real world isolated data\nisland intrinsic characteristics. This paper presents a federated learning (FL)\nbenchmark suite named FLBench. FLBench contains three domains: medical,\nfinancial, and AIoT. By configuring various domains, FLBench is qualified to\nevaluate federated learning systems and algorithms essential aspects, like\ncommunication, scenario transformation, privacy-preserving, data distribution\nheterogeneity, and cooperation strategy. Hence, it becomes a promising platform\nfor developing novel federated learning algorithms. Currently, FLBench is open\nsourced and in fast evolution. We package it as an automated deployment tool.\nThe benchmark suite is available from\nhttps://www.benchcouncil.org/flbench.html.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:41:46 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 11:08:56 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 02:22:31 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Liang", "Yuan", ""], ["Guo", "Yange", ""], ["Gong", "Yanxia", ""], ["Luo", "Chunjie", ""], ["Zhan", "Jianfeng", ""], ["Huang", "Yunyou", ""]]}, {"id": "2008.07275", "submitter": "Damian Borth", "authors": "L\\'ea Steinacker, Miriam Meckel, Genia Kostka, Damian Borth", "title": "Facial Recognition: A cross-national Survey on Public Acceptance,\n  Privacy, and Discrimination", "comments": "ICML 2020 - Law and Machine Learning Workshop, Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid advances in machine learning (ML), more of this technology is\nbeing deployed into the real world interacting with us and our environment. One\nof the most widely applied application of ML is facial recognition as it is\nrunning on millions of devices. While being useful for some people, others\nperceive it as a threat when used by public authorities. This discrepancy and\nthe lack of policy increases the uncertainty in the ML community about the\nfuture direction of facial recognition research and development. In this paper\nwe present results from a cross-national survey about public acceptance,\nprivacy, and discrimination of the use of facial recognition technology (FRT)\nin the public. This study provides insights about the opinion towards FRT from\nChina, Germany, the United Kingdom (UK), and the United States (US), which can\nserve as input for policy makers and legal regulators.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:17:21 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Steinacker", "L\u00e9a", ""], ["Meckel", "Miriam", ""], ["Kostka", "Genia", ""], ["Borth", "Damian", ""]]}, {"id": "2008.07281", "submitter": "Jun Qi", "authors": "Jun Qi, Jun Du, Sabato Marco Siniscalchi, Xiaoli Ma, Chin-Hui Lee", "title": "On Mean Absolute Error for Deep Neural Network Based Vector-to-Vector\n  Regression", "comments": null, "journal-ref": "IEEE Signal Processing Letters, 2020", "doi": "10.1109/LSP.2020.3016837", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we exploit the properties of mean absolute error (MAE) as a\nloss function for the deep neural network (DNN) based vector-to-vector\nregression. The goal of this work is two-fold: (i) presenting performance\nbounds of MAE, and (ii) demonstrating new properties of MAE that make it more\nappropriate than mean squared error (MSE) as a loss function for DNN based\nvector-to-vector regression. First, we show that a generalized upper-bound for\nDNN-based vector- to-vector regression can be ensured by leveraging the known\nLipschitz continuity property of MAE. Next, we derive a new generalized upper\nbound in the presence of additive noise. Finally, in contrast to conventional\nMSE commonly adopted to approximate Gaussian errors for regression, we show\nthat MAE can be interpreted as an error modeled by Laplacian distribution.\nSpeech enhancement experiments are conducted to corroborate our proposed\ntheorems and validate the performance advantages of MAE over MSE for DNN based\nregression.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:41:26 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Qi", "Jun", ""], ["Du", "Jun", ""], ["Siniscalchi", "Sabato Marco", ""], ["Ma", "Xiaoli", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2008.07283", "submitter": "Sergio Garrido", "authors": "Sergio Garrido, Stanislav S. Borysov, Jeppe Rich, Francisco C. Pereira", "title": "Estimating Causal Effects with the Neural Autoregressive Density\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of causal effects is fundamental in situations were the underlying\nsystem will be subject to active interventions. Part of building a causal\ninference engine is defining how variables relate to each other, that is,\ndefining the functional relationship between variables given conditional\ndependencies. In this paper, we deviate from the common assumption of linear\nrelationships in causal models by making use of neural autoregressive density\nestimators and use them to estimate causal effects within the Pearl's\ndo-calculus framework. Using synthetic data, we show that the approach can\nretrieve causal effects from non-linear systems without explicitly modeling the\ninteractions between the variables.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:12:38 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 13:03:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Garrido", "Sergio", ""], ["Borysov", "Stanislav S.", ""], ["Rich", "Jeppe", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2008.07291", "submitter": "Michael Sejr Schlichtkrull", "authors": "Michael Sejr Schlichtkrull, Weiwei Cheng", "title": "Evaluating for Diversity in Question Generation over Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating diverse and relevant questions over text is a task with widespread\napplications. We argue that commonly-used evaluation metrics such as BLEU and\nMETEOR are not suitable for this task due to the inherent diversity of\nreference questions, and propose a scheme for extending conventional metrics to\nreflect diversity. We furthermore propose a variational encoder-decoder model\nfor this task. We show through automatic and human evaluation that our\nvariational model improves diversity without loss of quality, and demonstrate\nhow our evaluation scheme reflects this improvement.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:16:12 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Schlichtkrull", "Michael Sejr", ""], ["Cheng", "Weiwei", ""]]}, {"id": "2008.07298", "submitter": "Buse Gul Atli Tekgul", "authors": "Buse Gul Atli, Yuxi Xia, Samuel Marchal, N. Asokan", "title": "WAFFLE: Watermarking in Federated Learning", "comments": "Will appear in the proceedings of SRDS 2021; 14 pages, 11 figures, 10\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a distributed learning technique where machine learning\nmodels are trained on client devices in which the local training data resides.\nThe training is coordinated via a central server which is, typically,\ncontrolled by the intended owner of the resulting model. By avoiding the need\nto transport the training data to the central server, federated learning\nimproves privacy and efficiency. But it raises the risk of model theft by\nclients because the resulting model is available on every client device. Even\nif the application software used for local training may attempt to prevent\ndirect access to the model, a malicious client may bypass any such restrictions\nby reverse engineering the application software. Watermarking is a well-known\ndeterrence method against model theft by providing the means for model owners\nto demonstrate ownership of their models. Several recent deep neural network\n(DNN) watermarking techniques use backdooring: training the models with\nadditional mislabeled data. Backdooring requires full access to the training\ndata and control of the training process. This is feasible when a single party\ntrains the model in a centralized manner, but not in a federated learning\nsetting where the training process and training data are distributed among\nseveral client devices. In this paper, we present WAFFLE, the first approach to\nwatermark DNN models trained using federated learning. It introduces a\nretraining step at the server after each aggregation of local models into the\nglobal model. We show that WAFFLE efficiently embeds a resilient watermark into\nmodels incurring only negligible degradation in test accuracy (-0.17%), and\ndoes not require access to training data. We also introduce a novel technique\nto generate the backdoor used as a watermark. It outperforms prior techniques,\nimposing no communication, and low computational (+3.2%) overhead.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:27:45 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 13:33:02 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 10:04:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Atli", "Buse Gul", ""], ["Xia", "Yuxi", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "2008.07303", "submitter": "Philipp Geiger", "authors": "Philipp Geiger, Christoph-Nikolas Straehle", "title": "Learning game-theoretic models of multiagent trajectories using implicit\n  layers", "comments": "Accepted at AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For prediction of interacting agents' trajectories, we propose an end-to-end\ntrainable architecture that hybridizes neural nets with game-theoretic\nreasoning, has interpretable intermediate representations, and transfers to\ndownstream decision making. It uses a net that reveals preferences from the\nagents' past joint trajectory, and a differentiable implicit layer that maps\nthese preferences to local Nash equilibria, forming the modes of the predicted\nfuture trajectory. Additionally, it learns an equilibrium refinement concept.\nFor tractability, we introduce a new class of continuous potential games and an\nequilibrium-separating partition of the action space. We provide theoretical\nresults for explicit gradients and soundness. In experiments, we evaluate our\napproach on two real-world data sets, where we predict highway driver merging\ntrajectories, and on a simple decision-making transfer task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:34:12 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 15:09:02 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 14:43:04 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 21:07:22 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 14:16:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Geiger", "Philipp", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "2008.07318", "submitter": "Suining He", "authors": "Xi Yang and Suining He", "title": "Towards Dynamic Urban Bike Usage Prediction for Station Network\n  Reconfiguration", "comments": "9 pages, UrbComp 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bike sharing has become one of the major choices of transportation for\nresidents in metropolitan cities worldwide. A station-based bike sharing system\nis usually operated in the way that a user picks up a bike from one station,\nand drops it off at another. Bike stations are, however, not static, as the\nbike stations are often reconfigured to accommodate changing demands or city\nurbanization over time. One of the key operations is to evaluate candidate\nlocations and install new stations to expand the bike sharing station network.\nConventional practices have been studied to predict existing station usage,\nwhile evaluating new stations is highly challenging due to the lack of the\nhistorical bike usage.\n  To fill this gap, in this work we propose a novel and efficient bike\nstation-level prediction algorithm called AtCoR, which can predict the bike\nusage at both existing and new stations (candidate locations during\nreconfiguration). In order to address the lack of historical data issues,\nvirtual historical usage of new stations is generated according to their\ncorrelations with the surrounding existing stations, for AtCoR model\ninitialization. We have designed novel station-centered heatmaps which\ncharacterize for each target station centered at the heatmap the trend that\nriders travel between it and the station's neighboring regions, enabling the\nmodel to capture the learnable features of the bike station network. The\ncaptured features are further applied to the prediction of bike usage for new\nstations. Our extensive experiment study on more than 23 million trips from\nthree major bike sharing systems in US, including New York City, Chicago and\nLos Angeles, shows that AtCoR outperforms baselines and state-of-art models in\nprediction of both existing and future stations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 23:41:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yang", "Xi", ""], ["He", "Suining", ""]]}, {"id": "2008.07320", "submitter": "Charlie Kirkwood", "authors": "Charlie Kirkwood, Theo Economou, Nicolas Pugeault", "title": "Bayesian deep learning for mapping via auxiliary information: a new era\n  for geostatistics?", "comments": "10 pages, 5 figures, version submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For geospatial modelling and mapping tasks, variants of kriging - the spatial\ninterpolation technique developed by South African mining engineer Danie Krige\n- have long been regarded as the established geostatistical methods. However,\nkriging and its variants (such as regression kriging, in which auxiliary\nvariables or derivatives of these are included as covariates) are relatively\nrestrictive models and lack capabilities that have been afforded to us in the\nlast decade by deep neural networks. Principal among these is feature learning\n- the ability to learn filters to recognise task-specific patterns in gridded\ndata such as images. Here we demonstrate the power of feature learning in a\ngeostatistical context, by showing how deep neural networks can automatically\nlearn the complex relationships between point-sampled target variables and\ngridded auxiliary variables (such as those provided by remote sensing), and in\ndoing so produce detailed maps of chosen target variables. At the same time, in\norder to cater for the needs of decision makers who require well-calibrated\nprobabilities, we obtain uncertainty estimates via a Bayesian approximation\nknown as Monte Carlo dropout. In our example, we produce a national-scale\nprobabilistic geochemical map from point-sampled assay data, with auxiliary\ninformation provided by a terrain elevation grid. Unlike traditional\ngeostatistical approaches, auxiliary variable grids are fed into our deep\nneural network raw. There is no need to provide terrain derivatives (e.g. slope\nangles, roughness, etc) because the deep neural network is capable of learning\nthese and arbitrarily more complex derivatives as necessary to maximise\npredictive performance. We hope our results will raise awareness of the\nsuitability of Bayesian deep learning - and its feature learning capabilities -\nfor large-scale geostatistical applications where uncertainty matters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:56:43 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 12:11:59 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 20:22:04 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Kirkwood", "Charlie", ""], ["Economou", "Theo", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "2008.07330", "submitter": "Puja Sahu", "authors": "Puja Sahu and Nandyala Hemachandra", "title": "Optimal Posteriors for Chi-squared Divergence based PAC-Bayesian Bounds\n  and Comparison with KL-divergence based Optimal Posteriors and\n  Cross-Validation Procedure", "comments": "arXiv admin note: text overlap with arXiv:1912.06803", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate optimal posteriors for recently introduced \\cite{begin2016pac}\nchi-squared divergence based PAC-Bayesian bounds in terms of nature of their\ndistribution, scalability of computations, and test set performance. For a\nfinite classifier set, we deduce bounds for three distance functions:\nKL-divergence, linear and squared distances. Optimal posterior weights are\nproportional to deviations of empirical risks, usually with subset support. For\nuniform prior, it is sufficient to search among posteriors on classifier\nsubsets ordered by these risks. We show the bound minimization for linear\ndistance as a convex program and obtain a closed-form expression for its\noptimal posterior. Whereas that for squared distance is a quasi-convex program\nunder a specific condition, and the one for KL-divergence is non-convex\noptimization (a difference of convex functions). To compute such optimal\nposteriors, we derive fast converging fixed point (FP) equations. We apply\nthese approaches to a finite set of SVM regularization parameter values to\nyield stochastic SVMs with tight bounds. We perform a comprehensive performance\ncomparison between our optimal posteriors and known KL-divergence based\nposteriors on a variety of UCI datasets with varying ranges and variances in\nrisk values, etc. Chi-squared divergence based posteriors have weaker bounds\nand worse test errors, hinting at an underlying regularization by KL-divergence\nbased posteriors. Our study highlights the impact of divergence function on the\nperformance of PAC-Bayesian classifiers. We compare our stochastic classifiers\nwith cross-validation based deterministic classifier. The latter has better\ntest errors, but ours is more sample robust, has quantifiable generalization\nguarantees, and is computationally much faster.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 03:15:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sahu", "Puja", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "2008.07331", "submitter": "Shuby Deshpande", "authors": "Shuby Deshpande, Benjamin Eysenbach, Jeff Schneider", "title": "Interactive Visualization for Debugging RL", "comments": "Builds on preliminary work presented at ICML 2020 (WHI)\n  arXiv:2007.05577. An interactive demo of the system can be at\n  https://tinyurl.com/y5gv5t4m", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualization tools for supervised learning allow users to interpret,\nintrospect, and gain an intuition for the successes and failures of their\nmodels. While reinforcement learning practitioners ask many of the same\nquestions, existing tools are not applicable to the RL setting as these tools\naddress challenges typically found in the supervised learning regime. In this\nwork, we design and implement an interactive visualization tool for debugging\nand interpreting RL algorithms. Our system addresses many features missing from\nprevious tools such as (1) tools for supervised learning often are not\ninteractive; (2) while debugging RL policies researchers use state\nrepresentations that are different from those seen by the agent; (3) a\nframework designed to make the debugging RL policies more conducive. We provide\nan example workflow of how this system could be used, along with ideas for\nfuture extensions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:28:18 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 22:27:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Deshpande", "Shuby", ""], ["Eysenbach", "Benjamin", ""], ["Schneider", "Jeff", ""]]}, {"id": "2008.07349", "submitter": "Matthew Dirks", "authors": "Matthew Dirks, David Poole", "title": "Binarised Regression with Instance-Varying Costs: Evaluation using\n  Impact Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many evaluation methods exist, each for a particular prediction task, and\nthere are a number of prediction tasks commonly performed including\nclassification and regression. In binarised regression, binary decisions are\ngenerated from a learned regression model (or real-valued dependent variable),\nwhich is useful when the division between instances that should be predicted\npositive or negative depends on the utility. For example, in mining, the\nboundary between a valuable rock and a waste rock depends on the market price\nof various metals, which varies with time. This paper proposes impact curves to\nevaluate binarised regression with instance-varying costs, where some instances\nare much worse to be classified as positive (or negative) than other instances;\ne.g., it is much worse to throw away a high-grade gold rock than a medium-grade\ncopper-ore rock, even if the mine wishes to keep both because both are\nprofitable. We show how to construct an impact curve for a variety of domains,\nincluding examples from healthcare, mining, and entertainment. Impact curves\noptimize binary decisions across all utilities of the chosen utility function,\nidentify the conditions where one model may be favoured over another, and\nquantitatively assess improvement between competing models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 04:16:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dirks", "Matthew", ""], ["Poole", "David", ""]]}, {"id": "2008.07353", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Zheng Wen, Xi Chen", "title": "On the Sample Complexity of Reinforcement Learning with Policy Space\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimal sample complexity in large-scale Reinforcement Learning\n(RL) problems with policy space generalization, i.e. the agent has a prior\nknowledge that the optimal policy lies in a known policy space. Existing\nresults show that without a generalization model, the sample complexity of an\nRL algorithm will inevitably depend on the cardinalities of state space and\naction space, which are intractably large in many practical problems.\n  To avoid such undesirable dependence on the state and action space sizes,\nthis paper proposes a new notion of eluder dimension for the policy space,\nwhich characterizes the intrinsic complexity of policy learning in an arbitrary\nMarkov Decision Process (MDP). Using a simulator oracle, we prove a\nnear-optimal sample complexity upper bound that only depends linearly on the\neluder dimension. We further prove a similar regret bound in deterministic\nsystems without the simulator.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:26:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mou", "Wenlong", ""], ["Wen", "Zheng", ""], ["Chen", "Xi", ""]]}, {"id": "2008.07361", "submitter": "Luis John", "authors": "Luis H. John, Jan A. Kors, Jenna M. Reps, Patrick B. Ryan, Peter R.\n  Rijnbeek", "title": "How little data do we need for patient-level prediction?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Provide guidance on sample size considerations for developing\npredictive models by empirically establishing the adequate sample size, which\nbalances the competing objectives of improving model performance and reducing\nmodel complexity as well as computational requirements.\n  Materials and Methods: We empirically assess the effect of sample size on\nprediction performance and model complexity by generating learning curves for\n81 prediction problems in three large observational health databases, requiring\ntraining of 17,248 prediction models. The adequate sample size was defined as\nthe sample size for which the performance of a model equalled the maximum model\nperformance minus a small threshold value.\n  Results: The adequate sample size achieves a median reduction of the number\nof observations between 9.5% and 78.5% for threshold values between 0.001 and\n0.02. The median reduction of the number of predictors in the models at the\nadequate sample size varied between 8.6% and 68.3%, respectively.\n  Discussion: Based on our results a conservative, yet significant, reduction\nin sample size and model complexity can be estimated for future prediction\nwork. Though, if a researcher is willing to generate a learning curve a much\nlarger reduction of the model complexity may be possible as suggested by a\nlarge outcome-dependent variability.\n  Conclusion: Our results suggest that in most cases only a fraction of the\navailable data was sufficient to produce a model close to the performance of\none developed on the full data set, but with a substantially reduced model\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:00:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["John", "Luis H.", ""], ["Kors", "Jan A.", ""], ["Reps", "Jenna M.", ""], ["Ryan", "Patrick B.", ""], ["Rijnbeek", "Peter R.", ""]]}, {"id": "2008.07364", "submitter": "Teng Ye", "authors": "Teng Ye, Wei Ai, Lingyu Zhang, Ning Luo, Lulu Zhang, Jieping Ye,\n  Qiaozhu Mei", "title": "Predicting Individual Treatment Effects of Large-scale Team Competitions\n  in a Ride-sharing Economy", "comments": "Accepted to KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of drivers worldwide have enjoyed financial benefits and work\nschedule flexibility through a ride-sharing economy, but meanwhile they have\nsuffered from the lack of a sense of identity and career achievement. Equipped\nwith social identity and contest theories, financially incentivized team\ncompetitions have been an effective instrument to increase drivers'\nproductivity, job satisfaction, and retention, and to improve revenue over cost\nfor ride-sharing platforms. While these competitions are overall effective, the\ndecisive factors behind the treatment effects and how they affect the outcomes\nof individual drivers have been largely mysterious. In this study, we analyze\ndata collected from more than 500 large-scale team competitions organized by a\nleading ride-sharing platform, building machine learning models to predict\nindividual treatment effects. Through a careful investigation of features and\npredictors, we are able to reduce out-sample prediction error by more than 24%.\nThrough interpreting the best-performing models, we discover many novel and\nactionable insights regarding how to optimize the design and the execution of\nteam competitions on ride-sharing platforms. A simulated analysis demonstrates\nthat by simply changing a few contest design options, the average treatment\neffect of a real competition is expected to increase by as much as 26%. Our\nprocedure and findings shed light on how to analyze and optimize large-scale\nonline field experiments in general.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:01:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ye", "Teng", ""], ["Ai", "Wei", ""], ["Zhang", "Lingyu", ""], ["Luo", "Ning", ""], ["Zhang", "Lulu", ""], ["Ye", "Jieping", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2008.07365", "submitter": "Remi Leluc", "authors": "Hamid Jalalzai and R\\'emi Leluc", "title": "Feature Clustering for Support Identification in Extreme Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the complex structure of multivariate extremes is a major\nchallenge in various fields from portfolio monitoring and environmental risk\nmanagement to insurance. In the framework of multivariate Extreme Value Theory,\na common characterization of extremes' dependence structure is the angular\nmeasure. It is a suitable measure to work in extreme regions as it provides\nmeaningful insights concerning the subregions where extremes tend to\nconcentrate their mass. The present paper develops a novel optimization-based\napproach to assess the dependence structure of extremes. This support\nidentification scheme rewrites as estimating clusters of features which best\ncapture the support of extremes. The dimension reduction technique we provide\nis applied to statistical learning tasks such as feature clustering and anomaly\ndetection. Numerical experiments provide strong empirical evidence of the\nrelevance of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:51:53 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 15:54:38 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Jalalzai", "Hamid", ""], ["Leluc", "R\u00e9mi", ""]]}, {"id": "2008.07386", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro, Audun J{\\o}sang", "title": "Using Subjective Logic to Estimate Uncertainty in Multi-Armed Bandit\n  Problems", "comments": "Published at ECML/PKDD 2020 Workshop on Uncertainty in Machine\n  Learning, 12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit problem is a classical decision-making problem where\nan agent has to learn an optimal action balancing exploration and exploitation.\nProperly managing this trade-off requires a correct assessment of uncertainty;\nin multi-armed bandits, as in other machine learning applications, it is\nimportant to distinguish between stochasticity that is inherent to the system\n(aleatoric uncertainty) and stochasticity that derives from the limited\nknowledge of the agent (epistemic uncertainty). In this paper we consider the\nformalism of subjective logic, a concise and expressive framework to express\nDirichlet-multinomial models as subjective opinions, and we apply it to the\nproblem of multi-armed bandits. We propose new algorithms grounded in\nsubjective logic to tackle the multi-armed bandit problem, we compare them\nagainst classical algorithms from the literature, and we analyze the insights\nthey provide in evaluating the dynamics of uncertainty. Our preliminary results\nsuggest that subjective logic quantities enable useful assessment of\nuncertainty that may be exploited by more refined agents.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:53:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["J\u00f8sang", "Audun", ""]]}, {"id": "2008.07426", "submitter": "Matias Valdenegro-Toro", "authors": "Maryam Matin and Matias Valdenegro-Toro", "title": "Hey Human, If your Facial Emotions are Uncertain, You Should Use\n  Bayesian Neural Networks!", "comments": "10 pages, 7 figures, Women in Computer Vision @ ECCV 2020 camera\n  ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial emotion recognition is the task to classify human emotions in face\nimages. It is a difficult task due to high aleatoric uncertainty and visual\nambiguity. A large part of the literature aims to show progress by increasing\naccuracy on this task, but this ignores the inherent uncertainty and ambiguity\nin the task. In this paper we show that Bayesian Neural Networks, as\napproximated using MC-Dropout, MC-DropConnect, or an Ensemble, are able to\nmodel the aleatoric uncertainty in facial emotion recognition, and produce\noutput probabilities that are closer to what a human expects. We also show that\ncalibration metrics show strange behaviors for this task, due to the multiple\nclasses that can be considered correct, which motivates future work. We believe\nour work will motivate other researchers to move away from Classical and into\nBayesian Neural Networks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:50:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Matin", "Maryam", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "2008.07428", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "Fast decentralized non-convex finite-sum optimization with recursive\n  variance reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers decentralized minimization of $N:=nm$ smooth non-convex\ncost functions equally divided over a directed network of $n$ nodes.\nSpecifically, we describe a stochastic first-order gradient method, called\nGT-SARAH, that employs a SARAH-type variance reduction technique and gradient\ntracking (GT) to address the stochastic and decentralized nature of the\nproblem. We show that GT-SARAH, with appropriate algorithmic parameters, finds\nan $\\epsilon$-accurate first-order stationary point with\n$O\\big(\\max\\big\\{N^{\\frac{1}{2}},n(1-\\lambda)^{-2},n^{\\frac{2}{3}}m^{\\frac{1}{3}}(1-\\lambda)^{-1}\\big\\}L\\epsilon^{-2}\\big)$\ngradient complexity, where ${(1-\\lambda)\\in(0,1]}$ is the spectral gap of the\nnetwork weight matrix and $L$ is the smoothness parameter of the cost\nfunctions. This gradient complexity outperforms that of the existing\ndecentralized stochastic gradient methods. In particular, in a big-data regime\nsuch that ${n = O(N^{\\frac{1}{2}}(1-\\lambda)^{3})}$, this gradient complexity\nfurthers reduces to ${O(N^{\\frac{1}{2}}L\\epsilon^{-2})}$, independent of the\nnetwork topology, and matches that of the centralized near-optimal\nvariance-reduced methods. Moreover, in this regime GT-SARAH achieves a\nnon-asymptotic linear speedup, in that, the total number of gradient\ncomputations at each node is reduced by a factor of $1/n$ compared to the\ncentralized near-optimal algorithms that perform all gradient computations at a\nsingle node. To the best of our knowledge, GT-SARAH is the first algorithm that\nachieves this property. In addition, we show that appropriate choices of local\nminibatch size balance the trade-offs between the gradient and communication\ncomplexity of GT-SARAH. Over infinite time horizon, we establish that all nodes\nin GT-SARAH asymptotically achieve consensus and converge to a first-order\nstationary point in the almost sure and mean-squared sense.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:51:32 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:07:13 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 01:54:21 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 16:19:01 GMT"}, {"version": "v5", "created": "Tue, 15 Jun 2021 03:10:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.07459", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Yuanhao Wang", "title": "On the Suboptimality of Negative Momentum for Minimax Optimization", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth game optimization has recently attracted great interest in machine\nlearning as it generalizes the single-objective optimization paradigm. However,\ngame dynamics is more complex due to the interaction between different players\nand is therefore fundamentally different from minimization, posing new\nchallenges for algorithm design. Notably, it has been shown that negative\nmomentum is preferred due to its ability to reduce oscillation in game\ndynamics. Nevertheless, the convergence rate of negative momentum was only\nestablished in simple bilinear games. In this paper, we extend the analysis to\nsmooth and strongly-convex strongly-concave minimax games by taking the\nvariational inequality formulation. By connecting momentum method with\nChebyshev polynomials, we show that negative momentum accelerates convergence\nof game dynamics locally, though with a suboptimal rate. To the best of our\nknowledge, this is the \\emph{first work} that provides an explicit convergence\nrate for negative momentum in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:34:53 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:32:29 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:15:47 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 17:26:55 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zhang", "Guodong", ""], ["Wang", "Yuanhao", ""]]}, {"id": "2008.07473", "submitter": "Xiaojie Mao", "authors": "Nathan Kallus and Xiaojie Mao", "title": "Stochastic Optimization Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual stochastic optimization problems, where we leverage rich\nauxiliary observations (e.g., product characteristics) to improve decision\nmaking with uncertain variables (e.g., demand). We show how to train forest\ndecision policies for this problem by growing trees that choose splits to\ndirectly optimize the downstream decision quality, rather than splitting to\nimprove prediction accuracy as in the standard random forest algorithm. We\nrealize this seemingly computationally intractable problem by developing\napproximate splitting criteria that utilize optimization perturbation analysis\nto eschew burdensome re-optimization for every candidate split, so that our\nmethod scales to large-scale problems. We prove that our splitting criteria\nconsistently approximate the true risk and that our method achieves asymptotic\noptimality. We extensively validate our method empirically, demonstrating the\nvalue of optimization-aware construction of forests and the success of our\nefficient approximations. We show that our approximate splitting criteria can\nreduce running time hundredfold, while achieving performance close to forest\nalgorithms that exactly re-optimize for every candidate split.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:56:06 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 00:17:52 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 14:13:33 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 10:12:16 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 00:46:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "2008.07496", "submitter": "Mert Sabuncu", "authors": "Mert R. Sabuncu", "title": "Intelligence plays dice: Stochasticity is essential for machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fields view stochasticity as a way to gain computational efficiency,\nwhile often having to trade off accuracy. In this perspective article, we argue\nthat stochasticity plays a fundamentally different role in machine learning\n(ML) and is likely a critical ingredient of intelligent systems. As we review\nthe ML literature, we notice that stochasticity features in many ML methods,\naffording them robustness, generalizability, and calibration. We also note that\nrandomness seems to be prominent in biological intelligence, from the spiking\npatterns of individual neurons to the complex behavior of animals. We conclude\nwith a discussion of how we believe stochasticity might shape the future of ML.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:40:38 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sabuncu", "Mert R.", ""]]}, {"id": "2008.07513", "submitter": "Shiliang Zuo `", "authors": "Shiliang Zuo", "title": "A Realistic Example in 2 Dimension that Gradient Descent Takes\n  Exponential Time to Escape Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent is a popular algorithm in optimization, and its performance\nin convex settings is mostly well understood. In non-convex settings, it has\nbeen shown that gradient descent is able to escape saddle points asymptotically\nand converge to local minimizers [Lee et. al. 2016]. Recent studies also show a\nperturbed version of gradient descent is enough to escape saddle points\nefficiently [Jin et. al. 2015, Ge et. al. 2017]. In this paper we show a\nnegative result: gradient descent may take exponential time to escape saddle\npoints, with non-pathological two dimensional functions. While our focus is\ntheoretical, we also conduct experiments verifying our theoretical result.\nThrough our analysis we demonstrate that stochasticity is essential to escape\nsaddle points efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:57:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zuo", "Shiliang", ""]]}, {"id": "2008.07524", "submitter": "Owen Lockwood", "authors": "Owen Lockwood and Mei Si", "title": "Reinforcement Learning with Quantum Variational Circuits", "comments": "Accepted to AIIDE 2020 Updated to better reflect AAAI formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of quantum computational techniques has advanced greatly in\nrecent years, parallel to the advancements in techniques for deep reinforcement\nlearning. This work explores the potential for quantum computing to facilitate\nreinforcement learning problems. Quantum computing approaches offer important\npotential improvements in time and space complexity over traditional algorithms\nbecause of its ability to exploit the quantum phenomena of superposition and\nentanglement. Specifically, we investigate the use of quantum variational\ncircuits, a form of quantum machine learning. We present our techniques for\nencoding classical data for a quantum variational circuit, we further explore\npure and hybrid quantum algorithms for DQN and Double DQN. Our results indicate\nboth hybrid and pure quantum variational circuit have the ability to solve\nreinforcement learning tasks with a smaller parameter space. These comparison\nare conducted with two OpenAI Gym environments: CartPole and Blackjack, The\nsuccess of this work is indicative of a strong future relationship between\nquantum machine learning and deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 00:13:01 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 23:53:32 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 06:54:21 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lockwood", "Owen", ""], ["Si", "Mei", ""]]}, {"id": "2008.07545", "submitter": "Neha Wadia", "authors": "Neha S. Wadia, Daniel Duckworth, Samuel S. Schoenholz, Ethan Dyer and\n  Jascha Sohl-Dickstein", "title": "Whitening and second order optimization both make information in the\n  dataset unusable during training, and can reduce or prevent generalization", "comments": "13+10 pages, 10 figures; minor textual changes and some\n  reorganization, one new figure and a new proof of main theorem added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is predicated on the concept of generalization: a model\nachieving low error on a sufficiently large training set should also perform\nwell on novel samples from the same distribution. We show that both data\nwhitening and second order optimization can harm or entirely prevent\ngeneralization. In general, model training harnesses information contained in\nthe sample-sample second moment matrix of a dataset. For a general class of\nmodels, namely models with a fully connected first layer, we prove that the\ninformation contained in this matrix is the only information which can be used\nto generalize. Models trained using whitened data, or with certain second order\noptimization schemes, have less access to this information, resulting in\nreduced or nonexistent generalization ability. We experimentally verify these\npredictions for several architectures, and further demonstrate that\ngeneralization continues to be harmed even when theoretical requirements are\nrelaxed. However, we also show experimentally that regularized second order\noptimization can provide a practical tradeoff, where training is accelerated\nbut less information is lost, and generalization can in some circumstances even\nimprove.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:00:05 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 17:42:29 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 06:29:08 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 07:00:41 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wadia", "Neha S.", ""], ["Duckworth", "Daniel", ""], ["Schoenholz", "Samuel S.", ""], ["Dyer", "Ethan", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2008.07577", "submitter": "Bahare Askari", "authors": "Bahare Askari, Jaroslaw Szlichta, Amirali Salehi-Abari", "title": "Joint Variational Autoencoders for Recommendation with Implicit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) have recently shown promising performance in\ncollaborative filtering with implicit feedback. These existing recommendation\nmodels learn user representations to reconstruct or predict user preferences.\nWe introduce joint variational autoencoders (JoVA), an ensemble of two VAEs, in\nwhich VAEs jointly learn both user and item representations and collectively\nreconstruct and predict user preferences. This design allows JoVA to capture\nuser-user and item-item correlations simultaneously. By extending the objective\nfunction of JoVA with a hinge-based pairwise loss function (JoVA-Hinge), we\nfurther specialize it for top-k recommendation with implicit feedback. Our\nextensive experiments on several real-world datasets show that JoVA-Hinge\noutperforms a broad set of state-of-the-art collaborative filtering methods,\nunder a variety of commonly-used metrics. Our empirical results also confirm\nthe outperformance of JoVA-Hinge over existing methods for cold-start users\nwith a limited number of training data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 19:06:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Askari", "Bahare", ""], ["Szlichta", "Jaroslaw", ""], ["Salehi-Abari", "Amirali", ""]]}, {"id": "2008.07587", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Stochastic Bayesian Neural Networks", "comments": "There is an error in modelling stochastic process. Hence the results\n  are not correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks perform variational inference over the weights\nhowever calculation of the posterior distribution remains a challenge. Our work\nbuilds on variational inference techniques for bayesian neural networks using\nthe original Evidence Lower Bound. In this paper, we present a stochastic\nbayesian neural network in which we maximize Evidence Lower Bound using a new\nobjective function which we name as Stochastic Evidence Lower Bound. We\nevaluate our network on 5 publicly available UCI datasets using test RMSE and\nlog likelihood as the evaluation metrics. We demonstrate that our work not only\nbeats the previous state of the art algorithms but is also scalable to larger\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:48:34 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 12:17:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 18:12:29 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2008.07588", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Uncertainty Quantification using Variational Inference for Biomedical\n  Image Segmentation", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning motivated by convolutional neural networks has been highly\nsuccessful in a range of medical imaging problems like image classification,\nimage segmentation, image synthesis etc. However for validation and\ninterpretability, not only do we need the predictions made by the model but\nalso how confident it is while making those predictions. This is important in\nsafety critical applications for the people to accept it. In this work, we used\nan encoder decoder architecture based on variational inference techniques for\nsegmenting brain tumour images. We compare different backbones architectures\nlike U-Net, V-Net and FCN as sampling data from the conditional distribution\nfor the encoder. We evaluate our work on the publicly available BRATS dataset\nusing Dice Similarity Coefficient (DSC) and Intersection Over Union (IOU) as\nthe evaluation metrics. Our model outperforms previous state of the art results\nwhile making use of uncertainty quantification in a principled bayesian manner.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:08:04 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2008.07599", "submitter": "Steve Li", "authors": "Steven Cheng-Xian Li, Benjamin M. Marlin", "title": "Learning from Irregularly-Sampled Time Series: A Missing Data\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregularly-sampled time series occur in many domains including healthcare.\nThey can be challenging to model because they do not naturally yield a\nfixed-dimensional representation as required by many standard machine learning\nmodels. In this paper, we consider irregular sampling from the perspective of\nmissing data. We model observed irregularly-sampled time series data as a\nsequence of index-value pairs sampled from a continuous but unobserved\nfunction. We introduce an encoder-decoder framework for learning from such\ngeneric indexed sequences. We propose learning methods for this framework based\non variational autoencoders and generative adversarial networks. For continuous\nirregularly-sampled time series, we introduce continuous convolutional layers\nthat can efficiently interface with existing neural network architectures.\nExperiments show that our models are able to achieve competitive or better\nclassification results on irregularly-sampled multivariate time series compared\nto recent RNN models while offering significantly faster training times.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:01:55 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Li", "Steven Cheng-Xian", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2008.07606", "submitter": "Shubhada Agrawal", "authors": "Shubhada Agrawal, Wouter M. Koolen, Sandeep Juneja", "title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures", "comments": "55 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular\ntail-risk measures in finance and insurance industries as well as in highly\nreliable, safety-critical uncertain environments where often the underlying\nprobability distributions are heavy-tailed. We use the multi-armed bandit\nbest-arm identification framework and consider the problem of identifying the\narm from amongst finitely many that has the smallest CVaR, VaR, or weighted sum\nof CVaR and mean. The latter captures the risk-return trade-off common in\nfinance. Our main contribution is an optimal $\\delta$-correct algorithm that\nacts on general arms, including heavy-tailed distributions, and matches the\nlower bound on the expected number of samples needed, asymptotically (as\n$\\delta$ approaches $0$). The algorithm requires solving a non-convex\noptimization problem in the space of probability measures, that requires\ndelicate analysis. En-route, we develop new non-asymptotic empirical\nlikelihood-based concentration inequalities for tail-risk measures which are\ntighter than those for popular truncation-based empirical estimators.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:23:24 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 12:23:16 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 00:58:34 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Agrawal", "Shubhada", ""], ["Koolen", "Wouter M.", ""], ["Juneja", "Sandeep", ""]]}, {"id": "2008.07609", "submitter": "Shreekanth Prabhu", "authors": "Shreekanth M. Prabhu and Natarajan Subramaniam", "title": "Surveillance of COVID-19 Pandemic using Hidden Markov Model", "comments": "29 pages, 9 figures, submitted to Elsevier Information Sciences\n  Journal on 13 August 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic has brought the whole world to a stand-still over the last\nfew months. In particular the pace at which pandemic has spread has taken\neverybody off-guard. The Governments across the world have responded by\nimposing lock-downs, stopping/restricting travel and mandating social\ndistancing. On the positive side there is wide availability of information on\nactive cases, recoveries and deaths collected daily across regions. However,\nwhat has been particularly challenging is to track the spread of the disease by\nasymptomatic carriers termed as super-spreaders. In this paper we look at\napplying Hidden Markov Model to get a better assessment of extent of spread.\nThe outcome of such analysis can be useful to Governments to design the\nrequired interventions/responses in a calibrated manner. The data we have\nchosen to analyze pertains to Indian scenario.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 05:45:34 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Prabhu", "Shreekanth M.", ""], ["Subramaniam", "Natarajan", ""]]}, {"id": "2008.07648", "submitter": "Zhunxuan Wang", "authors": "Zhunxuan Wang, Linyun He, Chunchuan Lyu and Shay B. Cohen", "title": "Nonparametric Learning of Two-Layer ReLU Residual Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm that learns two-layer residual units with rectified\nlinear unit (ReLU) activation: suppose the input $\\mathbf{x}$ is from a\ndistribution with support space $\\mathbb{R}^d$ and the ground-truth generative\nmodel is such a residual unit, given by \\[\\mathbf{y}=\n\\boldsymbol{B}^\\ast\\left[\\left(\\boldsymbol{A}^\\ast\\mathbf{x}\\right)^+ +\n\\mathbf{x}\\right]\\text{,}\\] where ground-truth network parameters\n$\\boldsymbol{A}^\\ast \\in \\mathbb{R}^{d\\times d}$ is a nonnegative full-rank\nmatrix and $\\boldsymbol{B}^\\ast \\in \\mathbb{R}^{m\\times d}$ is full-rank with\n$m \\geq d$ and for $\\mathbf{c} \\in \\mathbb{R}^d$, $[\\mathbf{c}^{+}]_i =\n\\max\\{0, c_i\\}$. We design layer-wise objectives as functionals whose analytic\nminimizers express the exact ground-truth network in terms of its parameters\nand nonlinearities. Following this objective landscape, learning residual units\nfrom finite samples can be formulated using convex optimization of a\nnonparametric function: for each layer, we first formulate the corresponding\nempirical risk minimization (ERM) as a positive semi-definite quadratic program\n(QP), then we show the solution space of the QP can be equivalently determined\nby a set of linear inequalities, which can then be efficiently solved by linear\nprogramming (LP). We further prove the statistical strong consistency of our\nalgorithm, and demonstrate the robustness and sample efficiency of our\nalgorithm by experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:11:26 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 17:03:23 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wang", "Zhunxuan", ""], ["He", "Linyun", ""], ["Lyu", "Chunchuan", ""], ["Cohen", "Shay B.", ""]]}, {"id": "2008.07653", "submitter": "David Huberman", "authors": "David B. Huberman, Brian J. Reich, and Howard D. Bondell", "title": "Nonparametric Conditional Density Estimation In A Deep Learning\n  Framework For Short-Term Forecasting", "comments": "44 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term forecasting is an important tool in understanding environmental\nprocesses. In this paper, we incorporate machine learning algorithms into a\nconditional distribution estimator for the purposes of forecasting tropical\ncyclone intensity. Many machine learning techniques give a single-point\nprediction of the conditional distribution of the target variable, which does\nnot give a full accounting of the prediction variability. Conditional\ndistribution estimation can provide extra insight on predicted response\nbehavior, which could influence decision-making and policy. We propose a\ntechnique that simultaneously estimates the entire conditional distribution and\nflexibly allows for machine learning techniques to be incorporated. A smooth\nmodel is fit over both the target variable and covariates, and a logistic\ntransformation is applied on the model output layer to produce an expression of\nthe conditional density function. We provide two examples of machine learning\nmodels that can be used, polynomial regression and deep learning models. To\nachieve computational efficiency we propose a case-control sampling\napproximation to the conditional distribution. A simulation study for four\ndifferent data distributions highlights the effectiveness of our method\ncompared to other machine learning-based conditional distribution estimation\ntechniques. We then demonstrate the utility of our approach for forecasting\npurposes using tropical cyclone data from the Atlantic Seaboard. This paper\ngives a proof of concept for the promise of our method, further computational\ndevelopments can fully unlock its insights in more complex forecasting and\nother applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:31:19 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Huberman", "David B.", ""], ["Reich", "Brian J.", ""], ["Bondell", "Howard D.", ""]]}, {"id": "2008.07665", "submitter": "Azade Farshad", "authors": "Yousef Yeganeh, Azade Farshad, Nassir Navab, Shadi Albarqouni", "title": "Inverse Distance Aggregation for Federated Learning with Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has been a promising approach in the field of medical\nimaging in recent years. A critical problem in FL, specifically in medical\nscenarios is to have a more accurate shared model which is robust to noisy and\nout-of distribution clients. In this work, we tackle the problem of statistical\nheterogeneity in data for FL which is highly plausible in medical data where\nfor example the data comes from different sites with different scanner\nsettings. We propose IDA (Inverse Distance Aggregation), a novel adaptive\nweighting approach for clients based on meta-information which handles\nunbalanced and non-iid data. We extensively analyze and evaluate our method\nagainst the well-known FL approach, Federated Averaging as a baseline.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:20:01 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Yeganeh", "Yousef", ""], ["Farshad", "Azade", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "2008.07669", "submitter": "Albert Gu", "authors": "Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, Christopher Re", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in learning from sequential data is representing cumulative\nhistory in an incremental fashion as more data is processed. We introduce a\ngeneral framework (HiPPO) for the online compression of continuous signals and\ndiscrete time series by projection onto polynomial bases. Given a measure that\nspecifies the importance of each time step in the past, HiPPO produces an\noptimal solution to a natural online function approximation problem. As special\ncases, our framework yields a short derivation of the recent Legendre Memory\nUnit (LMU) from first principles, and generalizes the ubiquitous gating\nmechanism of recurrent neural networks such as GRUs. This formal framework\nyields a new memory update mechanism (HiPPO-LegS) that scales through time to\nremember all history, avoiding priors on the timescale. HiPPO-LegS enjoys the\ntheoretical benefits of timescale robustness, fast updates, and bounded\ngradients. By incorporating the memory dynamics into recurrent neural networks,\nHiPPO RNNs can empirically capture complex temporal dependencies. On the\nbenchmark permuted MNIST dataset, HiPPO-LegS sets a new state-of-the-art\naccuracy of 98.3%. Finally, on a novel trajectory classification task testing\nrobustness to out-of-distribution timescales and missing data, HiPPO-LegS\noutperforms RNN and neural ODE baselines by 25-40% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:39:33 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 02:48:03 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gu", "Albert", ""], ["Dao", "Tri", ""], ["Ermon", "Stefano", ""], ["Rudra", "Atri", ""], ["Re", "Christopher", ""]]}, {"id": "2008.07672", "submitter": "Jia Chen", "authors": "Jia Chen and Evangelos E. Papalexakis", "title": "Ensemble Node Embeddings using Tensor Decomposition: A Case-Study on\n  DeepWalk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node embeddings have been attracting increasing attention during the past\nyears. In this context, we propose a new ensemble node embedding approach,\ncalled TenSemble2Vec, by first generating multiple embeddings using the\nexisting techniques and taking them as multiview data input of the state-of-art\ntensor decomposition model namely PARAFAC2 to learn the shared\nlower-dimensional representations of the nodes. Contrary to other embedding\nmethods, our TenSemble2Vec takes advantage of the complementary information\nfrom different methods or the same method with different hyper-parameters,\nwhich bypasses the challenge of choosing models. Extensive tests using\nreal-world data validates the efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:56:06 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chen", "Jia", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2008.07687", "submitter": "Liangyuan Hu", "authors": "Liangyuan Hu, Chenyang Gu", "title": "Estimation of causal effects of multiple treatments in healthcare\n  database studies with rare outcomes", "comments": "15 pages, 3 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preponderance of large-scale healthcare databases provide abundant\nopportunities for comparative effectiveness research. Evidence necessary to\nmaking informed treatment decisions often relies on comparing effectiveness of\nmultiple treatment options on outcomes of interest observed in a small number\nof individuals. Causal inference with multiple treatments and rare outcomes is\na subject that has been treated sparingly in the literature. This paper designs\nthree sets of simulations, representative of the structure of our healthcare\ndatabase study, and propose causal analysis strategies for such settings. We\ninvestigate and compare the operating characteristics of three types of methods\nand their variants: Bayesian Additive Regression Trees (BART), regression\nadjustment on multivariate spline of generalized propensity scores (RAMS) and\ninverse probability of treatment weighting (IPTW) with multinomial logistic\nregression or generalized boosted models. Our results suggest that BART and\nRAMS provide lower bias and mean squared error, and the widely used IPTW\nmethods deliver unfavorable operating characteristics. We illustrate the\nmethods using a case study evaluating the comparative effectiveness of\nrobotic-assisted surgery, video-assisted thoracoscopic surgery and open\nthoracotomy for treating non-small cell lung cancer.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 01:26:36 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 03:25:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hu", "Liangyuan", ""], ["Gu", "Chenyang", ""]]}, {"id": "2008.07688", "submitter": "Vaibhav Kumar", "authors": "Vaibhav Kumar and Vikas Raunak and Jamie Callan", "title": "Ranking Clarification Questions via Natural Language Inference", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412137", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given a natural language query, teaching machines to ask clarifying questions\nis of immense utility in practical natural language processing systems. Such\ninteractions could help in filling information gaps for better machine\ncomprehension of the query. For the task of ranking clarification questions, we\nhypothesize that determining whether a clarification question pertains to a\nmissing entry in a given post (on QA forums such as StackExchange) could be\nconsidered as a special case of Natural Language Inference (NLI), where both\nthe post and the most relevant clarification question point to a shared latent\npiece of information or context. We validate this hypothesis by incorporating\nrepresentations from a Siamese BERT model fine-tuned on NLI and Multi-NLI\ndatasets into our models and demonstrate that our best performing model obtains\na relative performance improvement of 40 percent and 60 percent respectively\n(on the key metric of Precision@1), over the state-of-the-art baseline(s) on\nthe two evaluation sets of the StackExchange dataset, thereby, significantly\nsurpassing the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 01:32:29 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Raunak", "Vikas", ""], ["Callan", "Jamie", ""]]}, {"id": "2008.07707", "submitter": "Zhiwen Xiao", "authors": "Zhiwen Xiao, Xin Xu, Huanlai Xing and Juan Chen", "title": "RTFN: Robust Temporal Feature Network", "comments": "10pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series analysis plays a vital role in various applications, for\ninstance, healthcare, weather prediction, disaster forecast, etc. However, to\nobtain sufficient shapelets by a feature network is still challenging. To this\nend, we propose a novel robust temporal feature network (RTFN) that contains\ntemporal feature networks and attentional LSTM networks. The temporal feature\nnetworks are built to extract basic features from input data while the\nattentional LSTM networks are devised to capture complicated shapelets and\nrelationships to enrich features. In experiments, we embed RTFN into supervised\nstructure as a feature extraction network and into unsupervised clustering as\nan encoder, respectively. The results show that the RTFN-based supervised\nstructure is a winner of 40 out of 85 datasets and the RTFN-based unsupervised\nclustering performs the best on 4 out of 11 datasets in the UCR2018 archive.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:43:30 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:03:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xiao", "Zhiwen", ""], ["Xu", "Xin", ""], ["Xing", "Huanlai", ""], ["Chen", "Juan", ""]]}, {"id": "2008.07709", "submitter": "Shusuke Kobayashi", "authors": "Shusuke Kobayashi, Susumu Shirayama", "title": "Selecting Data Adaptive Learner from Multiple Deep Learners using\n  Bayesian Networks", "comments": "14 pages, 12 tables and 4 figures, Submitted to Neural Computing and\n  Applications", "journal-ref": null, "doi": "10.1007/s00521-020-05234-6", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to predict time-series using multiple deep learners and a Bayesian\nnetwork is proposed. In this study, the input explanatory variables are\nBayesian network nodes that are associated with learners. Training data are\ndivided using K-means clustering, and multiple deep learners are trained\ndepending on the cluster. A Bayesian network is used to determine which deep\nlearner is in charge of predicting a time-series. We determine a threshold\nvalue and select learners with a posterior probability equal to or greater than\nthe threshold value, which could facilitate more robust prediction. The\nproposed method is applied to financial time-series data, and the predicted\nresults for the Nikkei 225 index are demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:48:43 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kobayashi", "Shusuke", ""], ["Shirayama", "Susumu", ""]]}, {"id": "2008.07719", "submitter": "Kai Ma", "authors": "Kai Ma, Biao Jie, Daoqiang Zhang", "title": "Ordinal Pattern Kernel for Brain Connectivity Network Classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain connectivity networks, which characterize the functional or structural\ninteraction of brain regions, has been widely used for brain disease\nclassification. Kernel-based method, such as graph kernel (i.e., kernel defined\non graphs), has been proposed for measuring the similarity of brain networks,\nand yields the promising classification performance. However, most of graph\nkernels are built on unweighted graph (i.e., network) with edge present or not,\nand neglecting the valuable weight information of edges in brain connectivity\nnetwork, with edge weights conveying the strengths of temporal correlation or\nfiber connection between brain regions. Accordingly, in this paper, we present\nan ordinal pattern kernel for brain connectivity network classification.\nDifferent with existing graph kernels that measures the topological similarity\nof unweighted graphs, the proposed ordinal pattern kernels calculate the\nsimilarity of weighted networks by comparing ordinal patterns from weighted\nnetworks.\n  To evaluate the effectiveness of the proposed ordinal kernel, we further\ndevelop a depth-first-based ordinal pattern kernel, and perform extensive\nexperiments in a real dataset of brain disease from ADNI database. The results\ndemonstrate that our proposed ordinal pattern kernel can achieve better\nclassification performance compared with state-of-the-art graph kernels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:16:40 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 04:07:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ma", "Kai", ""], ["Jie", "Biao", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2008.07720", "submitter": "Hung Pham Thuc", "authors": "Pham Thuc Hung, Kenji Yamanishi", "title": "Word2vec Skip-gram Dimensionality Selection via Sequential Normalized\n  Maximum Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel information criteria-based approach to\nselect the dimensionality of the word2vec Skip-gram (SG). From the perspective\nof the probability theory, SG is considered as an implicit probability\ndistribution estimation under the assumption that there exists a true\ncontextual distribution among words. Therefore, we apply information criteria\nwith the aim of selecting the best dimensionality so that the corresponding\nmodel can be as close as possible to the true distribution. We examine the\nfollowing information criteria for the dimensionality selection problem: the\nAkaike Information Criterion, Bayesian Information Criterion, and Sequential\nNormalized Maximum Likelihood (SNML) criterion. SNML is the total codelength\nrequired for the sequential encoding of a data sequence on the basis of the\nminimum description length. The proposed approach is applied to both the\noriginal SG model and the SG Negative Sampling model to clarify the idea of\nusing information criteria. Additionally, as the original SNML suffers from\ncomputational disadvantages, we introduce novel heuristics for its efficient\ncomputation. Moreover, we empirically demonstrate that SNML outperforms both\nBIC and AIC. In comparison with other evaluation methods for word embedding,\nthe dimensionality selected by SNML is significantly closer to the optimal\ndimensionality obtained by word analogy or word similarity tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:24:21 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 04:55:56 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 01:08:24 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hung", "Pham Thuc", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "2008.07730", "submitter": "Ziheng Duan", "authors": "Yifu Zhou, Ziheng Duan, Haoyan Xu, Jie Feng, Anni Ren, Yueyang Wang,\n  Xiaoqian Wang", "title": "Parallel Extraction of Long-term Trends and Short-term Fluctuation\n  Framework for Multivariate Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is widely used in various fields.\nReasonable prediction results can assist people in planning and\ndecision-making, generate benefits and avoid risks. Normally, there are two\ncharacteristics of time series, that is, long-term trend and short-term\nfluctuation. For example, stock prices will have a long-term upward trend with\nthe market, but there may be a small decline in the short term. These two\ncharacteristics are often relatively independent of each other. However, the\nexisting prediction methods often do not distinguish between them, which\nreduces the accuracy of the prediction model. In this paper, a MTS forecasting\nframework that can capture the long-term trends and short-term fluctuations of\ntime series in parallel is proposed. This method uses the original time series\nand its first difference to characterize long-term trends and short-term\nfluctuations. Three prediction sub-networks are constructed to predict\nlong-term trends, short-term fluctuations and the final value to be predicted.\nIn the overall optimization goal, the idea of multi-task learning is used for\nreference, which is to make the prediction results of long-term trends and\nshort-term fluctuations as close to the real values as possible while requiring\nto approximate the values to be predicted. In this way, the proposed method\nuses more supervision information and can more accurately capture the changing\ntrend of the time series, thereby improving the forecasting performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:55:29 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:30:45 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 16:02:57 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Zhou", "Yifu", ""], ["Duan", "Ziheng", ""], ["Xu", "Haoyan", ""], ["Feng", "Jie", ""], ["Ren", "Anni", ""], ["Wang", "Yueyang", ""], ["Wang", "Xiaoqian", ""]]}, {"id": "2008.07737", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Alessandro Lazaric, Mykel J. Kochenderfer, Emma\n  Brunskill", "title": "Provably Efficient Reward-Agnostic Navigation with Linear Value\n  Iteration", "comments": "Minor update; appears in NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing progress on theoretical analyses for provably\nefficient learning in MDPs with linear function approximation, but much of the\nexisting work has made strong assumptions to enable exploration by conventional\nexploration frameworks. Typically these assumptions are stronger than what is\nneeded to find good solutions in the batch setting. In this work, we show how\nunder a more standard notion of low inherent Bellman error, typically employed\nin least-square value iteration-style algorithms, we can provide strong PAC\nguarantees on learning a near optimal value function provided that the linear\nspace is sufficiently \"explorable\". We present a computationally tractable\nalgorithm for the reward-free setting and show how it can be used to learn a\nnear optimal policy for any (linear) reward function, which is revealed only\nonce learning has completed. If this reward function is also estimated from the\nsamples gathered during pure exploration, our results also provide same-order\nPAC guarantees on the performance of the resulting policy for this setting.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:34:21 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 02:30:08 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zanette", "Andrea", ""], ["Lazaric", "Alessandro", ""], ["Kochenderfer", "Mykel J.", ""], ["Brunskill", "Emma", ""]]}, {"id": "2008.07739", "submitter": "Lifeng Gu", "authors": "Lifeng Gu", "title": "Positive semidefinite support vector regression metric learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing metric learning methods focus on learning a similarity or\ndistance measure relying on similar and dissimilar relations between sample\npairs. However, pairs of samples cannot be simply identified as similar or\ndissimilar in many real-world applications, e.g., multi-label learning, label\ndistribution learning. To this end, relation alignment metric learning (RAML)\nframework is proposed to handle the metric learning problem in those scenarios.\nBut RAML framework uses SVR solvers for optimization. It can't learn positive\nsemidefinite distance metric which is necessary in metric learning. In this\npaper, we propose two methds to overcame the weakness. Further, We carry out\nseveral experiments on the single-label classification, multi-label\nclassification, label distribution learning to demonstrate the new methods\nachieves favorable performance against RAML framework.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:45:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gu", "Lifeng", ""]]}, {"id": "2008.07740", "submitter": "Minhui Huang", "authors": "Minhui Huang, Shiqian Ma, Lifeng Lai", "title": "Robust Low-rank Matrix Completion via an Alternating Manifold Proximal\n  Gradient Continuation Method", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3073544", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust low-rank matrix completion (RMC), or robust principal component\nanalysis with partially observed data, has been studied extensively for\ncomputer vision, signal processing and machine learning applications. This\nproblem aims to decompose a partially observed matrix into the superposition of\na low-rank matrix and a sparse matrix, where the sparse matrix captures the\ngrossly corrupted entries of the matrix. A widely used approach to tackle RMC\nis to consider a convex formulation, which minimizes the nuclear norm of the\nlow-rank matrix (to promote low-rankness) and the l1 norm of the sparse matrix\n(to promote sparsity). In this paper, motivated by some recent works on\nlow-rank matrix completion and Riemannian optimization, we formulate this\nproblem as a nonsmooth Riemannian optimization problem over Grassmann manifold.\nThis new formulation is scalable because the low-rank matrix is factorized to\nthe multiplication of two much smaller matrices. We then propose an alternating\nmanifold proximal gradient continuation (AManPGC) method to solve the proposed\nnew formulation. The convergence rate of the proposed algorithm is rigorously\nanalyzed. Numerical results on both synthetic data and real data on background\nextraction from surveillance videos are reported to demonstrate the advantages\nof the proposed new formulation and algorithm over several popular existing\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:46:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Huang", "Minhui", ""], ["Ma", "Shiqian", ""], ["Lai", "Lifeng", ""]]}, {"id": "2008.07758", "submitter": "Fei Zheng", "authors": "Fei Zheng", "title": "Efficient Private Machine Learning by Differentiable Random\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demands for privacy protection, many privacy-preserving\nmachine learning systems were proposed in recent years. However, most of them\ncannot be put into production due to their slow training and inference speed\ncaused by the heavy cost of homomorphic encryption and secure multiparty\ncomputation(MPC) methods. To circumvent this, I proposed a privacy definition\nwhich is suitable for large amount of data in machine learning tasks. Based on\nthat, I showed that random transformations like linear transformation and\nrandom permutation can well protect privacy. Merging random transformations and\narithmetic sharing together, I designed a framework for private machine\nlearning with high efficiency and low computation cost.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 06:17:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zheng", "Fei", ""]]}, {"id": "2008.07759", "submitter": "Senci Ying", "authors": "Senci Ying", "title": "Shared MF: A privacy-preserving recommendation system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is one of the most commonly used technologies in\nrecommendation system. With the promotion of recommendation system in\ne-commerce shopping, online video and other aspects, distributed recommendation\nsystem has been widely promoted, and the privacy problem of multi-source data\nbecomes more and more important. Based on Federated learning technology, this\npaper proposes a shared matrix factorization scheme called SharedMF. Firstly, a\ndistributed recommendation system is built, and then secret sharing technology\nis used to protect the privacy of local data. Experimental results show that\ncompared with the existing homomorphic encryption methods, our method can have\nfaster execution speed without privacy disclosure, and can better adapt to\nrecommendation scenarios with large amount of data.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 06:19:38 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ying", "Senci", ""]]}, {"id": "2008.07779", "submitter": "Devendra Swami", "authors": "Devendra Swami, Alay Dilipbhai Shah, Subhrajeet K B Ray", "title": "Predicting Future Sales of Retail Products using Machine Learning", "comments": "6 pages, 4 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for making future predictions based upon the present and past\ndata, has always been an area with direct application to various real life\nproblems. We are discussing a similar problem in this paper. The problem\nstatement is provided by Kaggle, which also serves as an ongoing competition on\nthe Kaggle platform. In this project, we worked with a challenging time-series\ndataset consisting of daily sales data, kindly provided by one of the largest\nRussian software firms - 1C Company. The objective is to predict the total\nsales for every product and store in the next month given the past data.\n  In order to perform forecasting for next month, we have deployed eXtreme\nGradient Boosting (XGBoost) and Long Short Term Memory (LSTM) based network\narchitecture to perform learning task. Root mean squared error (RMSE) between\nthe actual and predicted target values is used to evaluate the performance, and\nmake comparisons between the deployed algorithms. It has been found that\nXGBoost fared better than LSTM over this dataset which can be attributed to its\nrelatively higher sparsity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:36:14 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Swami", "Devendra", ""], ["Shah", "Alay Dilipbhai", ""], ["Ray", "Subhrajeet K B", ""]]}, {"id": "2008.07815", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau and Olga Fink", "title": "Unsupervised Transfer Learning for Anomaly Detection: Application to\n  Complementary Operating Condition Transfer", "comments": "14 pages, 7 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.knosys.2021.106816", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly Detectors are trained on healthy operating condition data and raise\nan alarm when the measured samples deviate from the training data distribution.\nThis means that the samples used to train the model should be sufficient in\nquantity and representative of the healthy operating conditions. But for\nindustrial systems subject to changing operating conditions, acquiring such\ncomprehensive sets of samples requires a long collection period and delay the\npoint at which the anomaly detector can be trained and put in operation.\n  A solution to this problem is to perform unsupervised transfer learning\n(UTL), to transfer complementary data between different units. In the\nliterature however, UTL aims at finding common structure between the datasets,\nto perform clustering or dimensionality reduction. Yet, the task of\ntransferring and combining complementary training data has not been studied.\n  Our proposed framework is designed to transfer complementary operating\nconditions between different units in a completely unsupervised way to train\nmore robust anomaly detectors. It differs, thereby, from other unsupervised\ntransfer learning works as it focuses on a one-class classification problem.\nThe proposed methodology enables to detect anomalies in operating conditions\nonly experienced by other units. The proposed end-to-end framework uses\nadversarial deep learning to ensure alignment of the different units'\ndistributions. The framework introduces a new loss, inspired by a\ndimensionality reduction tool, to enforce the conservation of the inherent\nvariability of each dataset, and uses state-of-the art once-class approach to\ndetect anomalies. We demonstrate the benefit of the proposed framework using\nthree open source datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 09:23:39 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 10:32:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2008.07838", "submitter": "Lina Wang", "authors": "Lina Wang, Rui Tang, Yawei Yue, Xingshu Chen, Wei Wang, Yi Zhu, and\n  Xuemei Zeng", "title": "Improving adversarial robustness of deep neural networks by using\n  semantic information", "comments": "13 pages, 9 figures", "journal-ref": "[J]. Knowledge-Based Systems, 2021: 107141", "doi": "10.1016/j.knosys.2021.107141", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks (DNNs) to adversarial attack, which\nis an attack that can mislead state-of-the-art classifiers into making an\nincorrect classification with high confidence by deliberately perturbing the\noriginal inputs, raises concerns about the robustness of DNNs to such attacks.\nAdversarial training, which is the main heuristic method for improving\nadversarial robustness and the first line of defense against adversarial\nattacks, requires many sample-by-sample calculations to increase training size\nand is usually insufficiently strong for an entire network. This paper provides\na new perspective on the issue of adversarial robustness, one that shifts the\nfocus from the network as a whole to the critical part of the region close to\nthe decision boundary corresponding to a given class. From this perspective, we\npropose a method to generate a single but image-agnostic adversarial\nperturbation that carries the semantic information implying the directions to\nthe fragile parts on the decision boundary and causes inputs to be\nmisclassified as a specified target. We call the adversarial training based on\nsuch perturbations \"region adversarial training\" (RAT), which resembles\nclassical adversarial training but is distinguished in that it reinforces the\nsemantic information missing in the relevant regions. Experimental results on\nthe MNIST and CIFAR-10 datasets show that this approach greatly improves\nadversarial robustness even using a very small dataset from the training data;\nmoreover, it can defend against FGSM adversarial attacks that have a completely\ndifferent pattern from the model seen during retraining.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:23:57 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 02:24:45 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Lina", ""], ["Tang", "Rui", ""], ["Yue", "Yawei", ""], ["Chen", "Xingshu", ""], ["Wang", "Wei", ""], ["Zhu", "Yi", ""], ["Zeng", "Xuemei", ""]]}, {"id": "2008.07839", "submitter": "Raghav Bali", "authors": "Kartik Chaudhary and Raghav Bali", "title": "EASTER: Efficient and Scalable Text Recognizer", "comments": "9 pages, fixed typos and minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent progress in deep learning has led to the development of Optical\nCharacter Recognition (OCR) systems which perform remarkably well. Most\nresearch has been around recurrent networks as well as complex gated layers\nwhich make the overall solution complex and difficult to scale. In this paper,\nwe present an Efficient And Scalable TExt Recognizer (EASTER) to perform\noptical character recognition on both machine printed and handwritten text. Our\nmodel utilises 1-D convolutional layers without any recurrence which enables\nparallel training with considerably less volume of data. We experimented with\nmultiple variations of our architecture and one of the smallest variant (depth\nand number of parameter wise) performs comparably to RNN based complex choices.\nOur 20-layered deepest variant outperforms RNN architectures with a good margin\non benchmarking datasets like IIIT-5k and SVT. We also showcase improvements\nover the current best results on offline handwritten text recognition task. We\nalso present data generation pipelines with augmentation setup to generate\nsynthetic datasets for both handwritten and machine printed text.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:26:03 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 14:02:50 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Chaudhary", "Kartik", ""], ["Bali", "Raghav", ""]]}, {"id": "2008.07841", "submitter": "Hoi-To Wai", "authors": "Hoi-To Wai", "title": "On the Convergence of Consensus Algorithms with Markovian Noise and\n  Gradient Bias", "comments": "Accepted to IEEE CDC 2020. 16 pages. FIxed a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a finite time convergence analysis for a decentralized\nstochastic approximation (SA) scheme. The scheme generalizes several algorithms\nfor decentralized machine learning and multi-agent reinforcement learning. Our\nproof technique involves separating the iterates into their respective\nconsensual parts and consensus error. The consensus error is bounded in terms\nof the stationarity of the consensual part, while the updates of the consensual\npart can be analyzed as a perturbed SA scheme. Under the Markovian noise and\ntime varying communication graph assumptions, the decentralized SA scheme has\nan expected convergence rate of ${\\cal O}(\\log T/ \\sqrt{T} )$, where $T$ is the\niteration number, in terms of squared norms of gradient for nonlinear SA with\nsmooth but non-convex cost function. This rate is comparable to the best known\nperformances of SA in a centralized setting with a non-convex potential\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:29:33 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 15:42:01 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 14:46:56 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Wai", "Hoi-To", ""]]}, {"id": "2008.07865", "submitter": "Maximilian Toller", "authors": "Maximilian Toller, Bernhard C. Geiger, Roman Kern", "title": "A Formally Robust Time Series Distance Metric", "comments": "MileTS Workshop at KDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance-based classification is among the most competitive classification\nmethods for time series data. The most critical component of distance-based\nclassification is the selected distance function. Past research has proposed\nvarious different distance metrics or measures dedicated to particular aspects\nof real-world time series data, yet there is an important aspect that has not\nbeen considered so far: Robustness against arbitrary data contamination. In\nthis work, we propose a novel distance metric that is robust against\narbitrarily \"bad\" contamination and has a worst-case computational complexity\nof $\\mathcal{O}(n\\log n)$. We formally argue why our proposed metric is robust,\nand demonstrate in an empirical evaluation that the metric yields competitive\nclassification accuracy when applied in k-Nearest Neighbor time series\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:28:50 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Toller", "Maximilian", ""], ["Geiger", "Bernhard C.", ""], ["Kern", "Roman", ""]]}, {"id": "2008.07870", "submitter": "Sandro Hauri", "authors": "Sandro Hauri, Nemanja Djuric, Vladan Radosavljevic, Slobodan Vucetic", "title": "Multi-Modal Trajectory Prediction of NBA Players", "comments": "Accepted Paper at WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  National Basketball Association (NBA) players are highly motivated and\nskilled experts that solve complex decision making problems at every time point\nduring a game. As a step towards understanding how players make their\ndecisions, we focus on their movement trajectories during games. We propose a\nmethod that captures the multi-modal behavior of players, where they might\nconsider multiple trajectories and select the most advantageous one. The method\nis built on an LSTM-based architecture predicting multiple trajectories and\ntheir probabilities, trained by a multi-modal loss function that updates the\nbest trajectories. Experiments on large, fine-grained NBA tracking data show\nthat the proposed method outperforms the state-of-the-art. In addition, the\nresults indicate that the approach generates more realistic trajectories and\nthat it can learn individual playing styles of specific players.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:35:44 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Hauri", "Sandro", ""], ["Djuric", "Nemanja", ""], ["Radosavljevic", "Vladan", ""], ["Vucetic", "Slobodan", ""]]}, {"id": "2008.07875", "submitter": "Jorge Pe\\~na Queralta", "authors": "Wenshuai Zhao, Jorge Pe\\~na Queralta, Li Qingqing, Tomi Westerlund", "title": "Towards Closing the Sim-to-Real Gap in Collaborative Multi-Robot Deep\n  Reinforcement Learning", "comments": "Accepted to the 5th International Conference on Robotics and\n  Automation Engineering, IEEE, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research directions in deep reinforcement learning include bridging\nthe simulation-reality gap, improving sample efficiency of experiences in\ndistributed multi-agent reinforcement learning, together with the development\nof robust methods against adversarial agents in distributed learning, among\nmany others. In this work, we are particularly interested in analyzing how\nmulti-agent reinforcement learning can bridge the gap to reality in distributed\nmulti-robot systems where the operation of the different robots is not\nnecessarily homogeneous. These variations can happen due to sensing mismatches,\ninherent errors in terms of calibration of the mechanical joints, or simple\ndifferences in accuracy. While our results are simulation-based, we introduce\nthe effect of sensing, calibration, and accuracy mismatches in distributed\nreinforcement learning with proximal policy optimization (PPO). We discuss on\nhow both the different types of perturbances and how the number of agents\nexperiencing those perturbances affect the collaborative learning effort. The\nsimulations are carried out using a Kuka arm model in the Bullet physics\nengine. This is, to the best of our knowledge, the first work exploring the\nlimitations of PPO in multi-robot systems when considering that different\nrobots might be exposed to different environments where their sensors or\nactuators have induced errors. With the conclusions of this work, we set the\ninitial point for future work on designing and developing methods to achieve\nrobust reinforcement learning on the presence of real-world perturbances that\nmight differ within a multi-robot system.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:57:33 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Queralta", "Jorge Pe\u00f1a", ""], ["Qingqing", "Li", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2008.07902", "submitter": "Guoli Wu", "authors": "Guoli Wu and Hefeng Dong and Junqiang Song and Jingya Zhang", "title": "Bayesian geoacoustic inversion using mixture density network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian geoacoustic inversion problems are conventionally solved by Markov\nchain Monte Carlo methods or its variants, which are computationally expensive.\nThis paper extends the classic Bayesian geoacoustic inversion framework by\nderiving important geoacoustic statistics of Bayesian geoacoustic inversion\nfrom the multidimensional posterior probability density (PPD) using the mixture\ndensity network (MDN) theory. These statistics make it convenient to train the\nnetwork directly on the whole parameter space and get the multidimensional PPD\nof model parameters. The present approach provides a much more efficient way to\nsolve geoacoustic inversion problems in Bayesian inference framework. The\nnetwork is trained on a simulated dataset of surface-wave dispersion curves\nwith shear-wave velocities as labels and tested on both synthetic and real data\ncases. The results show that the network gives reliable predictions and has\ngood generalization performance on unseen data. Once trained, the network can\nrapidly (within seconds) give a fully probabilistic solution which is\ncomparable to Monte Carlo methods. It provides an promising approach for\nreal-time inversion.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:02:40 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 08:00:52 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 02:52:35 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wu", "Guoli", ""], ["Dong", "Hefeng", ""], ["Song", "Junqiang", ""], ["Zhang", "Jingya", ""]]}, {"id": "2008.07922", "submitter": "Matthew Painter", "authors": "Matthew Painter, Jonathon Hare and Adam Prugel-Bennett", "title": "Linear Disentangled Representations and Unsupervised Action Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled representation learning has seen a surge in interest over recent\ntimes, generally focusing on new models which optimise one of many disparate\ndisentanglement metrics. Symmetry Based Disentangled Representation learning\nintroduced a robust mathematical framework that defined precisely what is meant\nby a \"linear disentangled representation\". This framework determined that such\nrepresentations would depend on a particular decomposition of the symmetry\ngroup acting on the data, showing that actions would manifest through\nirreducible group representations acting on independent representational\nsubspaces. Caselles-Dupre et al [2019] subsequently proposed the first model to\ninduce and demonstrate a linear disentangled representation in a VAE model. In\nthis work we empirically show that linear disentangled representations are not\ngenerally present in standard VAE models and that they instead require altering\nthe loss landscape to induce them. We proceed to show that such representations\nare a desirable property with regard to classical disentanglement metrics.\nFinally we propose a method to induce irreducible representations which forgoes\nthe need for labelled action sequences, as was required by prior work. We\nexplore a number of properties of this method, including the ability to learn\nfrom action sequences without knowledge of intermediate states and robustness\nunder visual noise. We also demonstrate that it can successfully learn 4\nindependent symmetries directly from pixels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:23:57 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 14:41:48 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Painter", "Matthew", ""], ["Hare", "Jonathon", ""], ["Prugel-Bennett", "Adam", ""]]}, {"id": "2008.07948", "submitter": "Ryo Yonetani", "authors": "Jiaxin Ma and Ryo Yonetani and Zahid Iqbal", "title": "Adaptive Distillation for Decentralized Learning from Heterogeneous\n  Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of decentralized learning to achieve a\nhigh-performance global model by asking a group of clients to share local\nmodels pre-trained with their own data resources. We are particularly\ninterested in a specific case where both the client model architectures and\ndata distributions are diverse, which makes it nontrivial to adopt conventional\napproaches such as Federated Learning and network co-distillation. To this end,\nwe propose a new decentralized learning method called Decentralized Learning\nvia Adaptive Distillation (DLAD). Given a collection of client models and a\nlarge number of unlabeled distillation samples, the proposed DLAD 1) aggregates\nthe outputs of the client models while adaptively emphasizing those with higher\nconfidence in given distillation samples and 2) trains the global model to\nimitate the aggregated outputs. Our extensive experimental evaluation on\nmultiple public datasets (MNIST, CIFAR-10, and CINIC-10) demonstrates the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:25:22 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ma", "Jiaxin", ""], ["Yonetani", "Ryo", ""], ["Iqbal", "Zahid", ""]]}, {"id": "2008.07956", "submitter": "Farhan Khawar", "authors": "Farhan Khawar, Leonard Kin Man Poon, Nevin Lianwen Zhang", "title": "Learning the Structure of Auto-Encoding Recommenders", "comments": "Proceedings of The Web Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380135", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder recommenders have recently shown state-of-the-art performance in\nthe recommendation task due to their ability to model non-linear item\nrelationships effectively. However, existing autoencoder recommenders use\nfully-connected neural network layers and do not employ structure learning.\nThis can lead to inefficient training, especially when the data is sparse as\ncommonly found in collaborative filtering. The aforementioned results in lower\ngeneralization ability and reduced performance. In this paper, we introduce\nstructure learning for autoencoder recommenders by taking advantage of the\ninherent item groups present in the collaborative filtering domain. Due to the\nnature of items in general, we know that certain items are more related to each\nother than to other items. Based on this, we propose a method that first learns\ngroups of related items and then uses this information to determine the\nconnectivity structure of an auto-encoding neural network. This results in a\nnetwork that is sparsely connected. This sparse structure can be viewed as a\nprior that guides the network training. Empirically we demonstrate that the\nproposed structure learning enables the autoencoder to converge to a local\noptimum with a much smaller spectral norm and generalization error bound than\nthe fully-connected network. The resultant sparse network considerably\noutperforms the state-of-the-art methods like \\textsc{Mult-vae/Mult-dae} on\nmultiple benchmarked datasets even when the same number of parameters and flops\nare used. It also has a better cold-start performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:37:40 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Khawar", "Farhan", ""], ["Poon", "Leonard Kin Man", ""], ["Zhang", "Nevin Lianwen", ""]]}, {"id": "2008.07970", "submitter": "Divya Gaur", "authors": "Divya Gaur, Joachim Folz, and Andreas Dengel", "title": "Training Deep Neural Networks Without Batch Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks is an optimization problem, and finding a decent set\nof parameters through gradient descent can be a difficult task. A host of\ntechniques has been developed to aid this process before and during the\ntraining phase. One of the most important and widely used class of method is\nnormalization. It is generally favorable for neurons to receive inputs that are\ndistributed with zero mean and unit variance, so we use statistics about\ndataset to normalize them before the first layer. However, this property cannot\nbe guaranteed for the intermediate activations inside the network. A widely\nused method to enforce this property inside the network is batch normalization.\nIt was developed to combat covariate shift inside networks. Empirically it is\nknown to work, but there is a lack of theoretical understanding about its\neffectiveness and potential drawbacks it might have when used in practice. This\nwork studies batch normalization in detail, while comparing it with other\nmethods such as weight normalization, gradient clipping and dropout. The main\npurpose of this work is to determine if it is possible to train networks\neffectively when batch normalization is removed through adaption of the\ntraining process.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:04:40 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gaur", "Divya", ""], ["Folz", "Joachim", ""], ["Dengel", "Andreas", ""]]}, {"id": "2008.07972", "submitter": "Ming Yan", "authors": "Ningyu Sha and Lei Shi and Ming Yan", "title": "Fast algorithms for robust principal component analysis with an upper\n  bound on the rank", "comments": "Accepted by Inverse Problems and Imaging", "journal-ref": "Inverse Problems and Imaging, 15 (2021), 109-128", "doi": "10.3934/ipi.2020067", "report-no": null, "categories": "math.NA cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust principal component analysis (RPCA) decomposes a data matrix into\na low-rank part and a sparse part. There are mainly two types of algorithms for\nRPCA. The first type of algorithm applies regularization terms on the singular\nvalues of a matrix to obtain a low-rank matrix. However, calculating singular\nvalues can be very expensive for large matrices. The second type of algorithm\nreplaces the low-rank matrix as the multiplication of two small matrices. They\nare faster than the first type because no singular value decomposition (SVD) is\nrequired. However, the rank of the low-rank matrix is required, and an accurate\nrank estimation is needed to obtain a reasonable solution. In this paper, we\npropose algorithms that combine both types. Our proposed algorithms require an\nupper bound of the rank and SVD on small matrices. First, they are faster than\nthe first type because the cost of SVD on small matrices is negligible. Second,\nthey are more robust than the second type because an upper bound of the rank\ninstead of the exact rank is required. Furthermore, we apply the Gauss-Newton\nmethod to increase the speed of our algorithms. Numerical experiments show the\nbetter performance of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:07:57 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 18:04:29 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sha", "Ningyu", ""], ["Shi", "Lei", ""], ["Yan", "Ming", ""]]}, {"id": "2008.07978", "submitter": "Chen Chen", "authors": "Chen Chen, Jaewoo Lee", "title": "Stochastic Adaptive Line Search for Differentially Private Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of private gradient-based optimization algorithms is highly\ndependent on the choice of step size (or learning rate) which often requires\nnon-trivial amount of tuning. In this paper, we introduce a stochastic variant\nof classic backtracking line search algorithm that satisfies R\\'enyi\ndifferential privacy. Specifically, the proposed algorithm adaptively chooses\nthe step size satsisfying the the Armijo condition (with high probability)\nusing noisy gradients and function estimates. Furthermore, to improve the\nprobability with which the chosen step size satisfies the condition, it adjusts\nper-iteration privacy budget during runtime according to the reliability of\nnoisy gradient. A naive implementation of the backtracking search algorithm may\nend up using unacceptably large privacy budget as the ability of adaptive step\nsize selection comes at the cost of extra function evaluations. The proposed\nalgorithm avoids this problem by using the sparse vector technique combined\nwith the recent privacy amplification lemma. We also introduce a privacy budget\nadaptation strategy in which the algorithm adaptively increases the budget when\nit detects that directions pointed by consecutive gradients are drastically\ndifferent. Extensive experiments on both convex and non-convex problems show\nthat the adaptively chosen step sizes allow the proposed algorithm to\nefficiently use the privacy budget and show competitive performance against\nexisting private optimizers.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:18:47 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 05:49:54 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chen", "Chen", ""], ["Lee", "Jaewoo", ""]]}, {"id": "2008.07997", "submitter": "Hyeji Kim", "authors": "Hyeji Kim, Yihan Jiang, Sreeram Kannan, Sewoong Oh, Pramod Viswanath", "title": "Deepcode and Modulo-SK are Designed for Different Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We respond to [1] which claimed that \"Modulo-SK scheme outperforms Deepcode\n[2]\". We demonstrate that this statement is not true: the two schemes are\ndesigned and evaluated for entirely different settings. DeepCode is designed\nand evaluated for the AWGN channel with (potentially delayed) uncoded output\nfeedback. Modulo-SK is evaluated on the AWGN channel with coded feedback and\nunit delay. [1] also claimed an implementation of Schalkwijk and Kailath (SK)\n[3] which was numerically stable for any number of information bits and\niterations. However, we observe that while their implementation does marginally\nimprove over ours, it also suffers from a fundamental issue with precision.\nFinally, we show that Deepcode dominates the optimized performance of SK, over\na natural choice of parameterizations when the feedback is noisy.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:52:19 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kim", "Hyeji", ""], ["Jiang", "Yihan", ""], ["Kannan", "Sreeram", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "2008.08007", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "Differentially Private Clustering: Tight Approximation Ratios", "comments": "60 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of differentially private clustering. For several basic\nclustering problems, including Euclidean DensestBall, 1-Cluster, k-means, and\nk-median, we give efficient differentially private algorithms that achieve\nessentially the same approximation ratios as those that can be obtained by any\nnon-private algorithm, while incurring only small additive errors. This\nimproves upon existing efficient algorithms that only achieve some large\nconstant approximation factors.\n  Our results also imply an improved algorithm for the Sample and Aggregate\nprivacy framework. Furthermore, we show that one of the tools used in our\n1-Cluster algorithm can be employed to get a faster quantum algorithm for\nClosestPair in a moderate number of dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:22:06 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2008.08037", "submitter": "Christopher Jung", "authors": "Christopher Jung, Changhwa Lee, Mallesh M. Pai, Aaron Roth, Rakesh\n  Vohra", "title": "Moment Multicalibration for Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to achieve the notion of \"multicalibration\" from H\\'ebert-Johnson\net al. [2018] not just for means, but also for variances and other higher\nmoments. Informally, it means that we can find regression functions which,\ngiven a data point, can make point predictions not just for the expectation of\nits label, but for higher moments of its label distribution as well-and those\npredictions match the true distribution quantities when averaged not just over\nthe population as a whole, but also when averaged over an enormous number of\nfinely defined subgroups. It yields a principled way to estimate the\nuncertainty of predictions on many different subgroups-and to diagnose\npotential sources of unfairness in the predictive power of features across\nsubgroups. As an application, we show that our moment estimates can be used to\nderive marginal prediction intervals that are simultaneously valid as averaged\nover all of the (sufficiently large) subgroups for which moment\nmulticalibration has been obtained.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:08:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Jung", "Christopher", ""], ["Lee", "Changhwa", ""], ["Pai", "Mallesh M.", ""], ["Roth", "Aaron", ""], ["Vohra", "Rakesh", ""]]}, {"id": "2008.08038", "submitter": "Jack McKenzie", "authors": "Jack R. McKenzie, Peter A. Appleby, Thomas House, Neil Walton", "title": "Fast Approximate Bayesian Contextual Cold Start Learning (FAB-COST)", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4418676", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold-start is a notoriously difficult problem which can occur in\nrecommendation systems, and arises when there is insufficient information to\ndraw inferences for users or items. To address this challenge, a contextual\nbandit algorithm -- the Fast Approximate Bayesian Contextual Cold Start\nLearning algorithm (FAB-COST) -- is proposed, which is designed to provide\nimproved accuracy compared to the traditionally used Laplace approximation in\nthe logistic contextual bandit, while controlling both algorithmic complexity\nand computational cost. To this end, FAB-COST uses a combination of two moment\nprojection variational methods: Expectation Propagation (EP), which performs\nwell at the cold start, but becomes slow as the amount of data increases; and\nAssumed Density Filtering (ADF), which has slower growth of computational cost\nwith data size but requires more data to obtain an acceptable level of\naccuracy. By switching from EP to ADF when the dataset becomes large, it is\nable to exploit their complementary strengths. The empirical justification for\nFAB-COST is presented, and systematically compared to other approaches on\nsimulated data. In a benchmark against the Laplace approximation on real data\nconsisting of over $670,000$ impressions from autotrader.co.uk, FAB-COST\ndemonstrates at one point increase of over $16\\%$ in user clicks. On the basis\nof these results, it is argued that FAB-COST is likely to be an attractive\napproach to cold-start recommendation systems in a variety of contexts.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:08:39 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["McKenzie", "Jack R.", ""], ["Appleby", "Peter A.", ""], ["House", "Thomas", ""], ["Walton", "Neil", ""]]}, {"id": "2008.08044", "submitter": "Deborshee Sen", "authors": "Deborshee Sen and Theodore Papamarkou and David Dunson", "title": "Bayesian neural networks and dimensionality reduction", "comments": "29 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conducting non-linear dimensionality reduction and feature learning, it is\ncommon to suppose that the data lie near a lower-dimensional manifold. A class\nof model-based approaches for such problems includes latent variables in an\nunknown non-linear regression function; this includes Gaussian process latent\nvariable models and variational auto-encoders (VAEs) as special cases. VAEs are\nartificial neural networks (ANNs) that employ approximations to make\ncomputation tractable; however, current implementations lack adequate\nuncertainty quantification in estimating the parameters, predictive densities,\nand lower-dimensional subspace, and can be unstable and lack interpretability\nin practice. We attempt to solve these problems by deploying Markov chain Monte\nCarlo sampling algorithms (MCMC) for Bayesian inference in ANN models with\nlatent variables. We address issues of identifiability by imposing constraints\non the ANN parameters as well as by using anchor points. This is demonstrated\non simulated and real data examples. We find that current MCMC sampling schemes\nface fundamental challenges in neural networks involving latent variables,\nmotivating new research directions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:11:07 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 15:47:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sen", "Deborshee", ""], ["Papamarkou", "Theodore", ""], ["Dunson", "David", ""]]}, {"id": "2008.08059", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "When Hardness of Approximation Meets Hardness of Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A supervised learning algorithm has access to a distribution of labeled\nexamples, and needs to return a function (hypothesis) that correctly labels the\nexamples. The hypothesis of the learner is taken from some fixed class of\nfunctions (e.g., linear classifiers, neural networks etc.). A failure of the\nlearning algorithm can occur due to two possible reasons: wrong choice of\nhypothesis class (hardness of approximation), or failure to find the best\nfunction within the hypothesis class (hardness of learning). Although both\napproximation and learnability are important for the success of the algorithm,\nthey are typically studied separately. In this work, we show a single hardness\nproperty that implies both hardness of approximation using linear classes and\nshallow networks, and hardness of learning using correlation queries and\ngradient-descent. This allows us to obtain new results on hardness of\napproximation and learnability of parity functions, DNF formulas and $AC^0$\ncircuits.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:41:28 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 13:46:10 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "2008.08060", "submitter": "Zhenge Jia", "authors": "Zhenge Jia, Zhepeng Wang, Feng Hong, Lichuan Ping, Yiyu Shi, Jingtong\n  Hu", "title": "Personalized Deep Learning for Ventricular Arrhythmias Detection on\n  Medical IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Life-threatening ventricular arrhythmias (VA) are the leading cause of sudden\ncardiac death (SCD), which is the most significant cause of natural death in\nthe US. The implantable cardioverter defibrillator (ICD) is a small device\nimplanted to patients under high risk of SCD as a preventive treatment. The ICD\ncontinuously monitors the intracardiac rhythm and delivers shock when detecting\nthe life-threatening VA. Traditional methods detect VA by setting criteria on\nthe detected rhythm. However, those methods suffer from a high inappropriate\nshock rate and require a regular follow-up to optimize criteria parameters for\neach ICD recipient. To ameliorate the challenges, we propose the personalized\ncomputing framework for deep learning based VA detection on medical IoT\nsystems. The system consists of intracardiac and surface rhythm monitors, and\nthe cloud platform for data uploading, diagnosis, and CNN model\npersonalization. We equip the system with real-time inference on both\nintracardiac and surface rhythm monitors. To improve the detection accuracy, we\nenable the monitors to detect VA collaboratively by proposing the cooperative\ninference. We also introduce the CNN personalization for each patient based on\nthe computing framework to tackle the unlabeled and limited rhythm data\nproblem. When compared with the traditional detection algorithm, the proposed\nmethod achieves comparable accuracy on VA rhythm detection and 6.6% reduction\nin inappropriate shock rate, while the average inference latency is kept at\n71ms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:41:58 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Jia", "Zhenge", ""], ["Wang", "Zhepeng", ""], ["Hong", "Feng", ""], ["Ping", "Lichuan", ""], ["Shi", "Yiyu", ""], ["Hu", "Jingtong", ""]]}, {"id": "2008.08071", "submitter": "Lunjia Hu", "authors": "Lunjia Hu, Omer Reingold", "title": "Robust Mean Estimation on Highly Incomplete Data with Arbitrary Outliers", "comments": "29 pages, 2 figures. Published in AISTATS 2021. More details in the\n  proof of Claim 14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly estimating the mean of a $d$-dimensional\ndistribution given $N$ examples, where most coordinates of every example may be\nmissing and $\\varepsilon N$ examples may be arbitrarily corrupted. Assuming\neach coordinate appears in a constant factor more than $\\varepsilon N$\nexamples, we show algorithms that estimate the mean of the distribution with\ninformation-theoretically optimal dimension-independent error guarantees in\nnearly-linear time $\\widetilde O(Nd)$. Our results extend recent work on\ncomputationally-efficient robust estimation to a more widely applicable\nincomplete-data setting.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:53:34 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 07:50:25 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 01:13:12 GMT"}, {"version": "v4", "created": "Sat, 6 Mar 2021 19:39:54 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 04:25:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hu", "Lunjia", ""], ["Reingold", "Omer", ""]]}, {"id": "2008.08080", "submitter": "Raphael Sonabend", "authors": "Raphael Sonabend, Franz J. Kir\\'aly, Andreas Bender, Bernd Bischl,\n  Michel Lang", "title": "mlr3proba: An R Package for Machine Learning in Survival Analysis", "comments": "Submitted to Bioinformatics", "journal-ref": null, "doi": "10.1093/bioinformatics/btab039", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning has become increasingly popular over the last few\ndecades, so too has the number of machine learning interfaces for implementing\nthese models. Whilst many R libraries exist for machine learning, very few\noffer extended support for survival analysis. This is problematic considering\nits importance in fields like medicine, bioinformatics, economics, engineering,\nand more. mlr3proba provides a comprehensive machine learning interface for\nsurvival analysis and connects with mlr3's general model tuning and\nbenchmarking facilities to provide a systematic infrastructure for survival\nmodeling and evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:21:24 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 11:41:25 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Sonabend", "Raphael", ""], ["Kir\u00e1ly", "Franz J.", ""], ["Bender", "Andreas", ""], ["Bischl", "Bernd", ""], ["Lang", "Michel", ""]]}, {"id": "2008.08134", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller and Anders Bourgeat and Jana Schmurr", "title": "Differentially Private Sketches for Jaccard Similarity Estimation", "comments": "Accepted at SISAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes two locally-differential private algorithms for\nreleasing user vectors such that the Jaccard similarity between these vectors\ncan be efficiently estimated. The basic building block is the well known\nMinHash method. To achieve a privacy-utility trade-off, MinHash is extended in\ntwo ways using variants of Generalized Randomized Response and the Laplace\nMechanism. A theoretical analysis provides bounds on the absolute error and\nexperiments show the utility-privacy trade-off on synthetic and real-world\ndata. The paper ends with a critical discussion of related work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 19:42:46 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Bourgeat", "Anders", ""], ["Schmurr", "Jana", ""]]}, {"id": "2008.08177", "submitter": "Aryan Deshwal", "authors": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa", "title": "Scalable Combinatorial Bayesian Optimization with Tractable Statistical\n  models", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing expensive blackbox functions over\ncombinatorial spaces (e.g., sets, sequences, trees, and graphs). BOCS (Baptista\nand Poloczek, 2018) is a state-of-the-art Bayesian optimization method for\ntractable statistical models, which performs semi-definite programming based\nacquisition function optimization (AFO) to select the next structure for\nevaluation. Unfortunately, BOCS scales poorly for large number of binary and/or\ncategorical variables. Based on recent advances in submodular relaxation (Ito\nand Fujimaki, 2016) for solving Binary Quadratic Programs, we study an approach\nreferred as Parametrized Submodular Relaxation (PSR) towards the goal of\nimproving the scalability and accuracy of solving AFO problems for BOCS model.\nPSR approach relies on two key ideas. First, reformulation of AFO problem as\nsubmodular relaxation with some unknown parameters, which can be solved\nefficiently using minimum graph cut algorithms. Second, construction of an\noptimization problem to estimate the unknown parameters with close\napproximation to the true objective. Experiments on diverse benchmark problems\nshow significant improvements with PSR for BOCS model. The source code is\navailable at https://github.com/aryandeshwal/Submodular_Relaxation_BOCS .\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 22:56:46 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Deshwal", "Aryan", ""], ["Belakaria", "Syrine", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2008.08186", "submitter": "Xiaoyan Han", "authors": "Vardan Papyan, X.Y. Han, David L. Donoho", "title": "Prevalence of Neural Collapse during the terminal phase of deep learning\n  training", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.2015509117", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern practice for training classification deepnets involves a Terminal\nPhase of Training (TPT), which begins at the epoch where training error first\nvanishes; During TPT, the training error stays effectively zero while training\nloss is pushed towards zero. Direct measurements of TPT, for three prototypical\ndeepnet architectures and across seven canonical classification datasets,\nexpose a pervasive inductive bias we call Neural Collapse, involving four\ndeeply interconnected phenomena: (NC1) Cross-example within-class variability\nof last-layer training activations collapses to zero, as the individual\nactivations themselves collapse to their class-means; (NC2) The class-means\ncollapse to the vertices of a Simplex Equiangular Tight Frame (ETF); (NC3) Up\nto rescaling, the last-layer classifiers collapse to the class-means, or in\nother words to the Simplex ETF, i.e. to a self-dual configuration; (NC4) For a\ngiven activation, the classifier's decision collapses to simply choosing\nwhichever class has the closest train class-mean, i.e. the Nearest Class Center\n(NCC) decision rule. The symmetric and very simple geometry induced by the TPT\nconfers important benefits, including better generalization performance, better\nrobustness, and better interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:12:54 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:15:50 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Papyan", "Vardan", ""], ["Han", "X. Y.", ""], ["Donoho", "David L.", ""]]}, {"id": "2008.08191", "submitter": "James Brofos", "authors": "James A. Brofos and Roy R. Lederman", "title": "Non-Canonical Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo is typically based on the assumption of an underlying\ncanonical symplectic structure. Numerical integrators designed for the\ncanonical structure are incompatible with motion generated by non-canonical\ndynamics. These non-canonical dynamics, motivated by examples in physics and\nsymplectic geometry, correspond to techniques such as preconditioning which are\nroutinely used to improve algorithmic performance. Indeed, recently, a special\ncase of non-canonical structure, magnetic Hamiltonian Monte Carlo, was\ndemonstrated to provide advantageous sampling properties. We present a\nframework for Hamiltonian Monte Carlo using non-canonical symplectic\nstructures. Our experimental results demonstrate sampling advantages associated\nto Hamiltonian Monte Carlo with non-canonical structure. To summarize our\ncontributions: (i) we develop non-canonical HMC from foundations in symplectic\ngeomtry; (ii) we construct an HMC procedure using implicit integration that\nsatisfies the detailed balance; (iii) we propose to accelerate the sampling\nusing an {\\em approximate} explicit methodology; (iv) we study two novel,\nrandomly-generated non-canonical structures: magnetic momentum and the coupled\nmagnet structure, with implicit and explicit integration.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:25:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Brofos", "James A.", ""], ["Lederman", "Roy R.", ""]]}, {"id": "2008.08221", "submitter": "Zhaoyi Xu", "authors": "Zhaoyi Xu, Joseph Homer Saleh", "title": "Machine Learning for Reliability Engineering and Safety Applications:\n  Review of Current Status and Future Opportunities", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) pervades an increasing number of academic disciplines\nand industries. Its impact is profound, and several fields have been\nfundamentally altered by it, autonomy and computer vision for example;\nreliability engineering and safety will undoubtedly follow suit. There is\nalready a large but fragmented literature on ML for reliability and safety\napplications, and it can be overwhelming to navigate and integrate into a\ncoherent whole. In this work, we facilitate this task by providing a synthesis\nof, and a roadmap to this ever-expanding analytical landscape and highlighting\nits major landmarks and pathways. We first provide an overview of the different\nML categories and sub-categories or tasks, and we note several of the\ncorresponding models and algorithms. We then look back and review the use of ML\nin reliability and safety applications. We examine several publications in each\ncategory/sub-category, and we include a short discussion on the use of Deep\nLearning to highlight its growing popularity and distinctive advantages.\nFinally, we look ahead and outline several promising future opportunities for\nleveraging ML in service of advancing reliability and safety considerations.\nOverall, we argue that ML is capable of providing novel insights and\nopportunities to solve important challenges in reliability and safety\napplications. It is also capable of teasing out more accurate insights from\naccident datasets than with traditional analysis tools, and this in turn can\nlead to better informed decision-making and more effective accident prevention.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:08:56 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Xu", "Zhaoyi", ""], ["Saleh", "Joseph Homer", ""]]}, {"id": "2008.08244", "submitter": "Yihong Wu", "authors": "Yury Polyanskiy and Yihong Wu", "title": "Self-regularizing Property of Nonparametric Maximum Likelihood Estimator\n  in Mixture Models", "comments": "Refer conjecture of [DYPS20] in Sec 5.4 to the arxiv version\n  arXiv:1901.03264v4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduced by Kiefer and Wolfowitz \\cite{KW56}, the nonparametric maximum\nlikelihood estimator (NPMLE) is a widely used methodology for learning mixture\nodels and empirical Bayes estimation. Sidestepping the non-convexity in mixture\nlikelihood, the NPMLE estimates the mixing distribution by maximizing the total\nlikelihood over the space of probability measures, which can be viewed as an\nextreme form of overparameterization.\n  In this paper we discover a surprising property of the NPMLE solution.\nConsider, for example, a Gaussian mixture model on the real line with a\nsubgaussian mixing distribution. Leveraging complex-analytic techniques, we\nshow that with high probability the NPMLE based on a sample of size $n$ has\n$O(\\log n)$ atoms (mass points), significantly improving the deterministic\nupper bound of $n$ due to Lindsay \\cite{lindsay1983geometry1}. Notably, any\nsuch Gaussian mixture is statistically indistinguishable from a finite one with\n$O(\\log n)$ components (and this is tight for certain mixtures). Thus, absent\nany explicit form of model selection, NPMLE automatically chooses the right\nmodel complexity, a property we term \\emph{self-regularization}. Extensions to\nother exponential families are given. As a statistical application, we show\nthat this structural property can be harnessed to bootstrap existing Hellinger\nrisk bound of the (parametric) MLE for finite Gaussian mixtures to the NPMLE\nfor general Gaussian mixtures, recovering a result of Zhang\n\\cite{zhang2009generalized}.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:39:13 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 01:10:12 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Polyanskiy", "Yury", ""], ["Wu", "Yihong", ""]]}, {"id": "2008.08273", "submitter": "Sung Min Cho", "authors": "Sung Min Cho, Eunhyeok Park, Sungjoo Yoo", "title": "MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings\n  for Sequential Recommendation", "comments": "Accepted at RecSys 2020", "journal-ref": null, "doi": "10.1145/3383313.3412216", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, self-attention based models have achieved state-of-the-art\nperformance in sequential recommendation task. Following the custom from\nlanguage processing, most of these models rely on a simple positional embedding\nto exploit the sequential nature of the user's history. However, there are some\nlimitations regarding the current approaches. First, sequential recommendation\nis different from language processing in that timestamp information is\navailable. Previous models have not made good use of it to extract additional\ncontextual information. Second, using a simple embedding scheme can lead to\ninformation bottleneck since the same embedding has to represent all possible\ncontextual biases. Third, since previous models use the same positional\nembedding in each attention head, they can wastefully learn overlapping\npatterns. To address these limitations, we propose MEANTIME (MixturE of\nAtteNTIon mechanisms with Multi-temporal Embeddings) which employs multiple\ntypes of temporal embeddings designed to capture various patterns from the\nuser's behavior sequence, and an attention structure that fully leverages such\ndiversity. Experiments on real-world data show that our proposed method\noutperforms current state-of-the-art sequential recommendation methods, and we\nprovide an extensive ablation study to analyze how the model gains from the\ndiverse positional information.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:32:14 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 07:18:14 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Cho", "Sung Min", ""], ["Park", "Eunhyeok", ""], ["Yoo", "Sungjoo", ""]]}, {"id": "2008.08289", "submitter": "Afshin Abdi", "authors": "Afshin Abdi, Saeed Rashidi, Faramarz Fekri, Tushar Krishna", "title": "Restructuring, Pruning, and Adjustment of Deep Models for Parallel\n  Distributed Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using multiple nodes and parallel computing algorithms has become a principal\ntool to improve training and execution times of deep neural networks as well as\neffective collective intelligence in sensor networks. In this paper, we\nconsider the parallel implementation of an already-trained deep model on\nmultiple processing nodes (a.k.a. workers) where the deep model is divided into\nseveral parallel sub-models, each of which is executed by a worker. Since\nlatency due to synchronization and data transfer among workers negatively\nimpacts the performance of the parallel implementation, it is desirable to have\nminimum interdependency among parallel sub-models. To achieve this goal, we\npropose to rearrange the neurons in the neural network and partition them\n(without changing the general topology of the neural network), such that the\ninterdependency among sub-models is minimized under the computations and\ncommunications constraints of the workers. We propose RePurpose, a layer-wise\nmodel restructuring and pruning technique that guarantees the performance of\nthe overall parallelized model. To efficiently apply RePurpose, we propose an\napproach based on $\\ell_0$ optimization and the Munkres assignment algorithm.\nWe show that, compared to the existing methods, RePurpose significantly\nimproves the efficiency of the distributed inference via parallel\nimplementation, both in terms of communication and computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:44:41 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Abdi", "Afshin", ""], ["Rashidi", "Saeed", ""], ["Fekri", "Faramarz", ""], ["Krishna", "Tushar", ""]]}, {"id": "2008.08316", "submitter": "Margarita Osadchy", "authors": "Ben Mussay, Daniel Feldman, Samson Zhou, Vladimir Braverman, Margarita\n  Osadchy", "title": "Data-Independent Structured Pruning of Neural Networks via Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is crucial for deployment of neural networks on devices\nwith limited computational and memory resources. Many different methods show\ncomparable accuracy of the compressed model and similar compression rates.\nHowever, the majority of the compression methods are based on heuristics and\noffer no worst-case guarantees on the trade-off between the compression rate\nand the approximation error for an arbitrarily new sample. We propose the first\nefficient structured pruning algorithm with a provable trade-off between its\ncompression rate and the approximation error for any future test sample. Our\nmethod is based on the coreset framework and it approximates the output of a\nlayer of neurons/filters by a coreset of neurons/filters in the previous layer\nand discards the rest. We apply this framework in a layer-by-layer fashion from\nthe bottom to the top. Unlike previous works, our coreset is data independent,\nmeaning that it provably guarantees the accuracy of the function for any input\n$x\\in \\mathbb{R}^d$, including an adversarial one.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:03:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mussay", "Ben", ""], ["Feldman", "Daniel", ""], ["Zhou", "Samson", ""], ["Braverman", "Vladimir", ""], ["Osadchy", "Margarita", ""]]}, {"id": "2008.08345", "submitter": "Dominik Engel", "authors": "Dominik Engel, Timo Ropinski", "title": "Deep Volumetric Ambient Occlusion", "comments": "IEEE VIS SciVis 2020", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030344", "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning based technique for volumetric ambient\nocclusion in the context of direct volume rendering. Our proposed Deep\nVolumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient\nocclusion in volumetric data sets, while considering global information\nprovided through the transfer function. The proposed neural network only needs\nto be executed upon change of this global information, and thus supports\nreal-time volume interaction. Accordingly, we demonstrate DVAOs ability to\npredict volumetric ambient occlusion, such that it can be applied interactively\nwithin direct volume rendering. To achieve the best possible results, we\npropose and analyze a variety of transfer function representations and\ninjection strategies for deep neural networks. Based on the obtained results we\nalso give recommendations applicable in similar volume learning scenarios.\nLastly, we show that DVAO generalizes to a variety of modalities, despite being\ntrained on computed tomography data only.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:19:08 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 06:13:14 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Engel", "Dominik", ""], ["Ropinski", "Timo", ""]]}, {"id": "2008.08353", "submitter": "Furui Cheng", "authors": "Furui Cheng, Yao Ming, Huamin Qu", "title": "DECE: Decision Explorer with Counterfactual Explanations for Machine\n  Learning Models", "comments": "10 pages, 7 figures. The paper will be published on IEEE Transactions\n  on Visualization and Computer Graphics (TVCG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With machine learning models being increasingly applied to various\ndecision-making scenarios, people have spent growing efforts to make machine\nlearning models more transparent and explainable. Among various explanation\ntechniques, counterfactual explanations have the advantages of being\nhuman-friendly and actionable -- a counterfactual explanation tells the user\nhow to gain the desired prediction with minimal changes to the input. Besides,\ncounterfactual explanations can also serve as efficient probes to the models'\ndecisions. In this work, we exploit the potential of counterfactual\nexplanations to understand and explore the behavior of machine learning models.\nWe design DECE, an interactive visualization system that helps understand and\nexplore a model's decisions on individual instances and data subsets,\nsupporting users ranging from decision-subjects to model developers. DECE\nsupports exploratory analysis of model decisions by combining the strengths of\ncounterfactual explanations at instance- and subgroup-levels. We also introduce\na set of interactions that enable users to customize the generation of\ncounterfactual explanations to find more actionable ones that can suit their\nneeds. Through three use cases and an expert interview, we demonstrate the\neffectiveness of DECE in supporting decision exploration tasks and instance\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:44:47 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Cheng", "Furui", ""], ["Ming", "Yao", ""], ["Qu", "Huamin", ""]]}, {"id": "2008.08384", "submitter": "Alfred Laugros", "authors": "Alfred Laugros, Alice Caplier, Matthieu Ospici", "title": "Addressing Neural Network Robustness with Mixup and Targeted Labeling\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their performance, Artificial Neural Networks are not reliable enough\nfor most of industrial applications. They are sensitive to noises, rotations,\nblurs and adversarial examples. There is a need to build defenses that protect\nagainst a wide range of perturbations, covering the most traditional common\ncorruptions and adversarial examples. We propose a new data augmentation\nstrategy called M-TLAT and designed to address robustness in a broad sense. Our\napproach combines the Mixup augmentation and a new adversarial training\nalgorithm called Targeted Labeling Adversarial Training (TLAT). The idea of\nTLAT is to interpolate the target labels of adversarial examples with the\nground-truth labels. We show that M-TLAT can increase the robustness of image\nclassifiers towards nineteen common corruptions and five adversarial attacks,\nwithout reducing the accuracy on clean samples.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 11:34:11 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Laugros", "Alfred", ""], ["Caplier", "Alice", ""], ["Ospici", "Matthieu", ""]]}, {"id": "2008.08386", "submitter": "Steffen Goebbels", "authors": "Steffen Goebbels", "title": "ReLU activated Multi-Layer Neural Networks trained with Mixed Integer\n  Linear Programs", "comments": "published paper. Technical Report 2021-01, Niederrhein University of\n  Applied Sciences, Faculty of Electrical Engineering and Computer Science,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, it is demonstrated through a case study that multilayer\nfeedforward neural networks activated by ReLU functions can in principle be\ntrained iteratively with Mixed Integer Linear Programs (MILPs) as follows.\nWeights are determined with batch learning. Multiple iterations are used per\nbatch of training data. In each iteration, the algorithm starts at the output\nlayer and propagates information back to the first hidden layer to adjust the\nweights using MILPs or Linear Programs. For each layer, the goal is to minimize\nthe difference between its output and the corresponding target output. The\ntarget output of the last (output) layer is equal to the ground truth. The\ntarget output of a previous layer is defined as the adjusted input of the\nfollowing layer. For a given layer, weights are computed by solving a MILP.\nThen, except for the first hidden layer, the input values are also modified\nwith a MILP to better match the layer outputs to their corresponding target\noutputs. The method was tested and compared with Tensorflow/Keras (Adam\noptimizer) using two simple networks on the MNIST dataset containing\nhandwritten digits. Accuracies of the same magnitude as with Tensorflow/Keras\nwere achieved.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 11:42:34 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:19:29 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 07:19:27 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Goebbels", "Steffen", ""]]}, {"id": "2008.08397", "submitter": "Nicolas Rivera", "authors": "Tamara Fernandez, Nicolas Rivera, Wenkai Xu and Arthur Gretton", "title": "Kernelized Stein Discrepancy Tests of Goodness-of-fit for Time-to-Event\n  Data", "comments": "Proceedings of the International Conference on Machine Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival Analysis and Reliability Theory are concerned with the analysis of\ntime-to-event data, in which observations correspond to waiting times until an\nevent of interest such as death from a particular disease or failure of a\ncomponent in a mechanical system. This type of data is unique due to the\npresence of censoring, a type of missing data that occurs when we do not\nobserve the actual time of the event of interest but, instead, we have access\nto an approximation for it given by random interval in which the observation is\nknown to belong. Most traditional methods are not designed to deal with\ncensoring, and thus we need to adapt them to censored time-to-event data. In\nthis paper, we focus on non-parametric goodness-of-fit testing procedures based\non combining the Stein's method and kernelized discrepancies. While for\nuncensored data, there is a natural way of implementing a kernelized Stein\ndiscrepancy test, for censored data there are several options, each of them\nwith different advantages and disadvantages. In this paper, we propose a\ncollection of kernelized Stein discrepancy tests for time-to-event data, and we\nstudy each of them theoretically and empirically; our experimental results show\nthat our proposed methods perform better than existing tests, including\nprevious tests based on a kernelized maximum mean discrepancy.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:27:43 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 18:13:45 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Fernandez", "Tamara", ""], ["Rivera", "Nicolas", ""], ["Xu", "Wenkai", ""], ["Gretton", "Arthur", ""]]}, {"id": "2008.08400", "submitter": "Alexander Immer", "authors": "Alexander Immer, Maciej Korzepa, Matthias Bauer", "title": "Improving predictions of Bayesian neural nets via local linearization", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized Gauss-Newton (GGN) approximation is often used to make\npractical Bayesian deep learning approaches scalable by replacing a second\norder derivative with a product of first order derivatives. In this paper we\nargue that the GGN approximation should be understood as a local linearization\nof the underlying Bayesian neural network (BNN), which turns the BNN into a\ngeneralized linear model (GLM). Because we use this linearized model for\nposterior inference, we should also predict using this modified model instead\nof the original one. We refer to this modified predictive as \"GLM predictive\"\nand show that it effectively resolves common underfitting problems of the\nLaplace approximation. It extends previous results in this vein to general\nlikelihoods and has an equivalent Gaussian process formulation, which enables\nalternative inference schemes for BNNs in function space. We demonstrate the\neffectiveness of our approach on several standard classification datasets as\nwell as on out-of-distribution detection. We provide an implementation at\nhttps://github.com/AlexImmer/BNN-predictions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:35:55 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:45:01 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 17:59:47 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Immer", "Alexander", ""], ["Korzepa", "Maciej", ""], ["Bauer", "Matthias", ""]]}, {"id": "2008.08424", "submitter": "Harkirat Behl", "authors": "Harkirat Singh Behl, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Ran Gal, Philip\n  H.S. Torr, Vibhav Vineet", "title": "AutoSimulate: (Quickly) Learning Synthetic Data Generation", "comments": "ECCV 2020", "journal-ref": "European Conference on Computer Vision (ECCV) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is increasingly being used for generating large labelled datasets\nin many machine learning problems. Recent methods have focused on adjusting\nsimulator parameters with the goal of maximising accuracy on a validation task,\nusually relying on REINFORCE-like gradient estimators. However these approaches\nare very expensive as they treat the entire data generation, model training,\nand validation pipeline as a black-box and require multiple costly objective\nevaluations at each iteration. We propose an efficient alternative for optimal\nsynthetic data generation, based on a novel differentiable approximation of the\nobjective. This allows us to optimize the simulator, which may be\nnon-differentiable, requiring only one objective evaluation at each iteration\nwith a little overhead. We demonstrate on a state-of-the-art photorealistic\nrenderer that the proposed method finds the optimal data distribution faster\n(up to $50\\times$), with significantly reduced training data generation (up to\n$30\\times$) and better accuracy ($+8.7\\%$) on real-world test datasets than\nprevious methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:36:11 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Behl", "Harkirat Singh", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Gal", "Ran", ""], ["Torr", "Philip H. S.", ""], ["Vineet", "Vibhav", ""]]}, {"id": "2008.08427", "submitter": "Sho Sonoda Dr", "authors": "Sho Sonoda, Ming Li, Feilong Cao, Changqin Huang, Yu Guang Wang", "title": "On the Approximation Lower Bound for Neural Nets with Random Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random net is a shallow neural network where the hidden layer is frozen\nwith random assignment and the output layer is trained by convex optimization.\nUsing random weights for a hidden layer is an effective method to avoid the\ninevitable non-convexity in standard gradient descent learning. It has recently\nbeen adopted in the study of deep learning theory. Here, we investigate the\nexpressive power of random nets. We show that, despite the well-known fact that\na shallow neural network is a universal approximator, a random net cannot\nachieve zero approximation error even for smooth functions. In particular, we\nprove that for a class of smooth functions, if the proposal distribution is\ncompactly supported, then a lower bound is positive. Based on the ridgelet\nanalysis and harmonic analysis for neural networks, the proof uses the\nPlancherel theorem and an estimate for the truncated tail of the parameter\ndistribution. We corroborate our theoretical results with various simulation\nstudies, and generally two main take-home messages are offered: (i) Not any\ndistribution for selecting random weights is feasible to build a universal\napproximator; (ii) A suitable assignment of random weights exists but to some\ndegree is associated with the complexity of the target function.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:26:12 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sonoda", "Sho", ""], ["Li", "Ming", ""], ["Cao", "Feilong", ""], ["Huang", "Changqin", ""], ["Wang", "Yu Guang", ""]]}, {"id": "2008.08433", "submitter": "Qingjie Meng", "authors": "Qingjie Meng and Daniel Rueckert and Bernhard Kainz", "title": "Unsupervised Cross-domain Image Classification by Distance Metric Guided\n  Feature Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning deep neural networks that are generalizable across different domains\nremains a challenge due to the problem of domain shift. Unsupervised domain\nadaptation is a promising avenue which transfers knowledge from a source domain\nto a target domain without using any labels in the target domain. Contemporary\ntechniques focus on extracting domain-invariant features using domain\nadversarial training. However, these techniques neglect to learn discriminative\nclass boundaries in the latent representation space on a target domain and\nyield limited adaptation performance. To address this problem, we propose\ndistance metric guided feature alignment (MetFA) to extract discriminative as\nwell as domain-invariant features on both source and target domains. The\nproposed MetFA method explicitly and directly learns the latent representation\nwithout using domain adversarial training. Our model integrates class\ndistribution alignment to transfer semantic knowledge from a source domain to a\ntarget domain. We evaluate the proposed method on fetal ultrasound datasets for\ncross-device image classification. Experimental results demonstrate that the\nproposed method outperforms the state-of-the-art and enables model\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:36:57 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Meng", "Qingjie", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2008.08461", "submitter": "Benjamin Miller", "authors": "Benjamin Kurt Miller, Mario Geiger, Tess E. Smidt, Frank No\\'e", "title": "Relevance of Rotationally Equivariant Convolutions for Predicting\n  Molecular Properties", "comments": "Machine Learning for Molecules Workshop at NeurIPS 2020, NeurIPS\n  workshop on Interpretable Inductive Biases and Physically Structured Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivariant neural networks (ENNs) are graph neural networks embedded in\n$\\mathbb{R}^3$ and are well suited for predicting molecular properties. The ENN\nlibrary e3nn has customizable convolutions, which can be designed to depend\nonly on distances between points, or also on angular features, making them\nrotationally invariant, or equivariant, respectively. This paper studies the\npractical value of including angular dependencies for molecular property\nprediction directly via an ablation study with \\texttt{e3nn} and the QM9 data\nset. We find that, for fixed network depth and parameter count, adding angular\nfeatures decreased test error by an average of 23%. Meanwhile, increasing\nnetwork depth decreased test error by only 4% on average, implying that\nrotationally equivariant layers are comparatively parameter efficient. We\npresent an explanation of the accuracy improvement on the dipole moment, the\ntarget which benefited most from the introduction of angular features.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:07:36 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 10:26:07 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 18:57:27 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 09:27:37 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Miller", "Benjamin Kurt", ""], ["Geiger", "Mario", ""], ["Smidt", "Tess E.", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2008.08476", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Andrea Massa, Vojtech Mrazek, Beatrice Bussolino,\n  Maurizio Martina, Muhammad Shafique", "title": "NASCaps: A Framework for Neural Architecture Search to Optimize the\n  Accuracy and Hardware Efficiency of Convolutional Capsule Networks", "comments": "To appear at the IEEE/ACM International Conference on Computer-Aided\n  Design (ICCAD '20), November 2-5, 2020, Virtual Event, USA", "journal-ref": null, "doi": "10.1145/3400302.3415731", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have made significant improvements to reach the\ndesired accuracy to be employed in a wide variety of Machine Learning (ML)\napplications. Recently the Google Brain's team demonstrated the ability of\nCapsule Networks (CapsNets) to encode and learn spatial correlations between\ndifferent input features, thereby obtaining superior learning capabilities\ncompared to traditional (i.e., non-capsule based) DNNs. However, designing\nCapsNets using conventional methods is a tedious job and incurs significant\ntraining effort. Recent studies have shown that powerful methods to\nautomatically select the best/optimal DNN model configuration for a given set\nof applications and a training dataset are based on the Neural Architecture\nSearch (NAS) algorithms. Moreover, due to their extreme computational and\nmemory requirements, DNNs are employed using the specialized hardware\naccelerators in IoT-Edge/CPS devices. In this paper, we propose NASCaps, an\nautomated framework for the hardware-aware NAS of different types of DNNs,\ncovering both traditional convolutional DNNs and CapsNets. We study the\nefficacy of deploying a multi-objective Genetic Algorithm (e.g., based on the\nNSGA-II algorithm). The proposed framework can jointly optimize the network\naccuracy and the corresponding hardware efficiency, expressed in terms of\nenergy, memory, and latency of a given hardware accelerator executing the DNN\ninference. Besides supporting the traditional DNN layers, our framework is the\nfirst to model and supports the specialized capsule layers and dynamic routing\nin the NAS-flow. We evaluate our framework on different datasets, generating\ndifferent network configurations, and demonstrate the tradeoffs between the\ndifferent output metrics. We will open-source the complete framework and\nconfigurations of the Pareto-optimal architectures at\nhttps://github.com/ehw-fit/nascaps.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:29:36 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marchisio", "Alberto", ""], ["Massa", "Andrea", ""], ["Mrazek", "Vojtech", ""], ["Bussolino", "Beatrice", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2008.08501", "submitter": "Lorenzo Federici Mr.", "authors": "Alessandro Zavoli and Lorenzo Federici", "title": "Reinforcement Learning for Low-Thrust Trajectory Design of\n  Interplanetary Missions", "comments": "2020 AAS/AIAA Astrodynamics Specialist Virtual Lake Tahoe Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of Reinforcement Learning for the robust\ndesign of low-thrust interplanetary trajectories in presence of severe\ndisturbances, modeled alternatively as Gaussian additive process noise,\nobservation noise, control actuation errors on thrust magnitude and direction,\nand possibly multiple missed thrust events. The optimal control problem is\nrecast as a time-discrete Markov Decision Process to comply with the standard\nformulation of reinforcement learning. An open-source implementation of the\nstate-of-the-art algorithm Proximal Policy Optimization is adopted to carry out\nthe training process of a deep neural network, used to map the spacecraft\n(observed) states to the optimal control policy. The resulting Guidance and\nControl Network provides both a robust nominal trajectory and the associated\nclosed-loop guidance law. Numerical results are presented for a typical\nEarth-Mars mission. First, in order to validate the proposed approach, the\nsolution found in a (deterministic) unperturbed scenario is compared with the\noptimal one provided by an indirect technique. Then, the robustness and\noptimality of the obtained closed-loop guidance laws is assessed by means of\nMonte Carlo campaigns performed in the considered uncertain scenarios. These\npreliminary results open up new horizons for the use of reinforcement learning\nin the robust design of interplanetary missions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:22:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zavoli", "Alessandro", ""], ["Federici", "Lorenzo", ""]]}, {"id": "2008.08516", "submitter": "Hugo Jair  Escalante", "authors": "Hugo Jair Escalante", "title": "Automated Machine Learning -- a brief review at the end of the early\n  years", "comments": "Preprint submitted to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) is the sub-field of machine learning that\naims at automating, to some extend, all stages of the design of a machine\nlearning system. In the context of supervised learning, AutoML is concerned\nwith feature extraction, pre processing, model design and post processing.\nMajor contributions and achievements in AutoML have been taking place during\nthe recent decade. We are therefore in perfect timing to look back and realize\nwhat we have learned. This chapter aims to summarize the main findings in the\nearly years of AutoML. More specifically, in this chapter an introduction to\nAutoML for supervised learning is provided and an historical review of progress\nin this field is presented. Likewise, the main paradigms of AutoML are\ndescribed and research opportunities are outlined.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:48:49 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:23:41 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 14:45:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Escalante", "Hugo Jair", ""]]}, {"id": "2008.08522", "submitter": "Marta Golabek", "authors": "Marta Go{\\l}\\k{a}bek, Robin Senge, and Rainer Neumann", "title": "Demand Forecasting using Long Short-Term Memory Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate to what extent long short-term memory neural\nnetworks (LSTMs) are suitable for demand forecasting in the e-grocery retail\nsector. For this purpose, univariate as well as multivariate LSTM-based models\nwere developed and tested for 100 fast-moving consumer goods in the context of\na master's thesis. On average, the developed models showed better results for\nfood products than the comparative models from both statistical and machine\nlearning families. Solely in the area of beverages random forest and linear\nregression achieved slightly better results. This outcome suggests that LSTMs\ncan be used for demand forecasting at product level. The performance of the\nmodels presented here goes beyond the current state of research, as can be seen\nfrom the evaluations based on a data set that unfortunately has not been\npublicly available to date.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:01:23 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Go\u0142\u0105bek", "Marta", ""], ["Senge", "Robin", ""], ["Neumann", "Rainer", ""]]}, {"id": "2008.08601", "submitter": "James Halverson", "authors": "James Halverson, Anindita Maiti, and Keegan Stoner", "title": "Neural Networks and Quantum Field Theory", "comments": "v2: published in Machine Learning: Science and Technology. Additions\n  include study of N-scaling, a correction for examples, and new experimental\n  tests. 53 pages, 7 figures, and appendices", "journal-ref": null, "doi": "10.1088/2632-2153/abeca3", "report-no": null, "categories": "cs.LG cond-mat.dis-nn hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a theoretical understanding of neural networks in terms of\nWilsonian effective field theory. The correspondence relies on the fact that\nmany asymptotic neural networks are drawn from Gaussian processes, the analog\nof non-interacting field theories. Moving away from the asymptotic limit yields\na non-Gaussian process and corresponds to turning on particle interactions,\nallowing for the computation of correlation functions of neural network outputs\nwith Feynman diagrams. Minimal non-Gaussian process likelihoods are determined\nby the most relevant non-Gaussian terms, according to the flow in their\ncoefficients induced by the Wilsonian renormalization group. This yields a\ndirect connection between overparameterization and simplicity of neural network\nlikelihoods. Whether the coefficients are constants or functions may be\nunderstood in terms of GP limit symmetries, as expected from 't Hooft's\ntechnical naturalness. General theoretical calculations are matched to neural\nnetwork experiments in the simplest class of models allowing the\ncorrespondence. Our formalism is valid for any of the many architectures that\nbecomes a GP in an asymptotic limit, a property preserved under certain types\nof training.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:00:06 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:52:31 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Halverson", "James", ""], ["Maiti", "Anindita", ""], ["Stoner", "Keegan", ""]]}, {"id": "2008.08604", "submitter": "Nathaniel Craig", "authors": "Tianji Cai, Junyi Cheng, Katy Craig, Nathaniel Craig", "title": "Linearized Optimal Transport for Collider Events", "comments": "16 pages, 5 figures", "journal-ref": "Phys. Rev. D 102, 116019 (2020)", "doi": "10.1103/PhysRevD.102.116019", "report-no": null, "categories": "hep-ph hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient framework for computing the distance between\ncollider events using the tools of Linearized Optimal Transport (LOT). This\npreserves many of the advantages of the recently-introduced Energy Mover's\nDistance, which quantifies the \"work\" required to rearrange one event into\nanother, while significantly reducing the computational cost. It also furnishes\na Euclidean embedding amenable to simple machine learning algorithms and\nvisualization techniques, which we demonstrate in a variety of jet tagging\nexamples. The LOT approximation lowers the threshold for diverse applications\nof the theory of optimal transport to collider physics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:00:09 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Cai", "Tianji", ""], ["Cheng", "Junyi", ""], ["Craig", "Katy", ""], ["Craig", "Nathaniel", ""]]}, {"id": "2008.08605", "submitter": "Maria Schuld", "authors": "Maria Schuld, Ryan Sweke, Johannes Jakob Meyer", "title": "The effect of data encoding on the expressive power of variational\n  quantum machine learning models", "comments": "Minor corrections, including credits to a closely related paper.\n  Source code available at\n  https://github.com/XanaduAI/expressive_power_of_quantum_models", "journal-ref": "Phys. Rev. A 103, 032430 (2021)", "doi": "10.1103/PhysRevA.103.032430", "report-no": null, "categories": "quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum computers can be used for supervised learning by treating\nparametrised quantum circuits as models that map data inputs to predictions.\nWhile a lot of work has been done to investigate practical implications of this\napproach, many important theoretical properties of these models remain unknown.\nHere we investigate how the strategy with which data is encoded into the model\ninfluences the expressive power of parametrised quantum circuits as function\napproximators. We show that one can naturally write a quantum model as a\npartial Fourier series in the data, where the accessible frequencies are\ndetermined by the nature of the data encoding gates in the circuit. By\nrepeating simple data encoding gates multiple times, quantum models can access\nincreasingly rich frequency spectra. We show that there exist quantum models\nwhich can realise all possible sets of Fourier coefficients, and therefore, if\nthe accessible frequency spectrum is asymptotically rich enough, such models\nare universal function approximators.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:00:11 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 09:18:49 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Schuld", "Maria", ""], ["Sweke", "Ryan", ""], ["Meyer", "Johannes Jakob", ""]]}, {"id": "2008.08617", "submitter": "Ziheng Duan", "authors": "Yueyang Wang, Ziheng Duan, Yida Huang, Haoyan Xu, Jie Feng, Anni Ren", "title": "MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate\n  Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting, which analyzes historical time series\nto predict future trends, can effectively help decision-making. Complex\nrelations among variables in MTS, including static, dynamic, predictable, and\nlatent relations, have made it possible to mining more features of MTS.\nModeling complex relations are not only essential in characterizing latent\ndependency as well as modeling temporal dependence, but also brings great\nchallenges in the MTS forecasting task. However, existing methods mainly focus\non modeling certain relations among MTS variables. In this paper, we propose a\nnovel end-to-end deep learning model, termed Multivariate Time Series\nForecasting via Heterogeneous Graph Neural Networks (MTHetGNN). To characterize\ncomplex relations among variables, a relation embedding module is designed in\nMTHetGNN, where each variable is regarded as a graph node, and each type of\nedge represents a specific static or dynamic relationship. Meanwhile, a\ntemporal embedding module is introduced for time series features extraction,\nwhere involving convolutional neural network (CNN) filters with different\nperception scales. Finally, a heterogeneous graph embedding module is adopted\nto handle the complex structural information generated by the two modules.\nThree benchmark datasets from the real world are used to evaluate the proposed\nMTHetGNN. The comprehensive experiments show that MTHetGNN achieves\nstate-of-the-art results in the MTS forecasting task.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:21:22 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:30:54 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 14:50:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Yueyang", ""], ["Duan", "Ziheng", ""], ["Huang", "Yida", ""], ["Xu", "Haoyan", ""], ["Feng", "Jie", ""], ["Ren", "Anni", ""]]}, {"id": "2008.08624", "submitter": "Akwarandu Nwachuku", "authors": "Mary Akinyemi, Chika Yinka-Banjo, Ogban-Asuquo Ugot, Akwarandu Ugo\n  Nwachuku", "title": "Estimating the time-lapse between medical insurance reimbursement with\n  non-parametric regression models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-parametric supervised learning algorithms represent a succinct class of\nsupervised learning algorithms where the learning parameters are highly\nflexible and whose values are directly dependent on the size of the training\ndata. In this paper, we comparatively study the properties of four\nnonparametric algorithms, K-Nearest Neighbours (KNNs), Support Vector Machines\n(SVMs), Decision trees and Random forests. The supervised learning task is a\nregression estimate of the time-lapse in medical insurance reimbursement. Our\nstudy is concerned precisely with how well each of the nonparametric regression\nmodels fits the training data. We quantify the goodness of fit using the\nR-squared metric. The results are presented with a focus on the effect of the\nsize of the training data, the feature space dimension and hyperparameter\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:39:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Akinyemi", "Mary", ""], ["Yinka-Banjo", "Chika", ""], ["Ugot", "Ogban-Asuquo", ""], ["Nwachuku", "Akwarandu Ugo", ""]]}, {"id": "2008.08637", "submitter": "Weijing Tang", "authors": "Weijing Tang, Jiaqi Ma, Qiaozhu Mei, Ji Zhu", "title": "SODEN: A Scalable Continuous-Time Survival Model through Ordinary\n  Differential Equation Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a flexible model for survival analysis using neural\nnetworks along with scalable optimization algorithms. One key technical\nchallenge for directly applying maximum likelihood estimation (MLE) to censored\ndata is that evaluating the objective function and its gradients with respect\nto model parameters requires the calculation of integrals. To address this\nchallenge, we recognize that the MLE for censored data can be viewed as a\ndifferential-equation constrained optimization problem, a novel perspective.\nFollowing this connection, we model the distribution of event time through an\nordinary differential equation and utilize efficient ODE solvers and adjoint\nsensitivity analysis to numerically evaluate the likelihood and the gradients.\nUsing this approach, we are able to 1) provide a broad family of\ncontinuous-time survival distributions without strong structural assumptions,\n2) obtain powerful feature representations using neural networks, and 3) allow\nefficient estimation of the model in large-scale applications using stochastic\ngradient descent. Through both simulation studies and real-world data examples,\nwe demonstrate the effectiveness of the proposed method in comparison to\nexisting state-of-the-art deep learning survival analysis models.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:11:25 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tang", "Weijing", ""], ["Ma", "Jiaqi", ""], ["Mei", "Qiaozhu", ""], ["Zhu", "Ji", ""]]}, {"id": "2008.08642", "submitter": "Shervin Rahimzadeh Arashloo", "authors": "Shervin Rahimzadeh Arashloo", "title": "$\\ell_p$-Norm Multiple Kernel One-Class Fisher Null-Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the multiple kernel learning (MKL) problem for one-class\nclassification (OCC). For this purpose, based on the Fisher null-space\none-class classification method, we present a multiple kernel learning\nalgorithm where a general $\\ell_p$-norm constraint ($p\\geq1$) on kernel weights\nis considered. The proposed approach is then extended to learn several related\none-class MKL problems jointly by constraining them to share common kernel\nweights. We pose the one-class MKL task as a min-max saddle point Lagrangian\noptimisation problem and propose an efficient alternating optimisation method\nto solve it.\n  An extensive assessment of the proposed method on ten data sets from\ndifferent application domains in one-class classification confirms its merits\nagainst the baseline and several other one-class multiple kernel learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:25:55 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Arashloo", "Shervin Rahimzadeh", ""]]}, {"id": "2008.08653", "submitter": "Julia Steinberg", "authors": "Julia Steinberg, Madhu Advani, Haim Sompolinsky", "title": "A new role for circuit expansion for learning in neural networks", "comments": "13+10 pages, 13 figures", "journal-ref": "Phys. Rev. E 103, 022404 (2021)", "doi": "10.1103/PhysRevE.103.022404", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sensory pathways in the brain rely on sparsely active populations of\nneurons downstream from the input stimuli. The biological reason for the\noccurrence of expanded structure in the brain is unclear, but may be because\nexpansion can increase the expressive power of a neural network. In this work,\nwe show that expanding a neural network can improve its generalization\nperformance even in cases in which the expanded structure is pruned after the\nlearning period. To study this setting we use a teacher-student framework where\na perceptron teacher network generates labels which are corrupted with small\namounts of noise. We then train a student network that is structurally matched\nto the teacher and can achieve optimal accuracy if given the teacher's synaptic\nweights. We find that sparse expansion of the input of a student perceptron\nnetwork both increases its capacity and improves the generalization performance\nof the network when learning a noisy rule from a teacher perceptron when these\nexpansions are pruned after learning. We find similar behavior when the\nexpanded units are stochastic and uncorrelated with the input and analyze this\nnetwork in the mean field limit. We show by solving the mean field equations\nthat the generalization error of the stochastic expanded student network\ncontinues to drop as the size of the network increases. The improvement in\ngeneralization performance occurs despite the increased complexity of the\nstudent network relative to the teacher it is trying to learn. We show that\nthis effect is closely related to the addition of slack variables in artificial\nneural networks and suggest possible implications for artificial and biological\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:00:44 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 21:34:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Steinberg", "Julia", ""], ["Advani", "Madhu", ""], ["Sompolinsky", "Haim", ""]]}, {"id": "2008.08662", "submitter": "Musadig Aliyev", "authors": "Musadig Aliyev, Elvin Ahmadov, Habil Gadirli, Arzu Mammadova and Emin\n  Alasgarov", "title": "Segmenting Bank Customers via RFM Model and Unsupervised Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, one of the major challenges for financial institutions is\nthe retention of their customers using new methodologies of reliable and\nprofitable segmentation. In the field of banking, the approach of offering all\nof the services to all the existing customers at the same time does not always\nwork. However, being aware of what to sell, when to sell and whom to sell makes\na huge difference in the conversion rate of the customers responding to new\nservices and buying new products. In this paper, we used RFM technique and\nvarious clustering algorithms applied to the real customer data of one of the\nlargest private banks of Azerbaijan.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:41:18 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Aliyev", "Musadig", ""], ["Ahmadov", "Elvin", ""], ["Gadirli", "Habil", ""], ["Mammadova", "Arzu", ""], ["Alasgarov", "Emin", ""]]}, {"id": "2008.08675", "submitter": "Anders Johan Andreassen", "authors": "Anders Andreassen, Ethan Dyer", "title": "Asymptotics of Wide Convolutional Neural Networks", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide neural networks have proven to be a rich class of architectures for both\ntheory and practice. Motivated by the observation that finite width\nconvolutional networks appear to outperform infinite width networks, we study\nscaling laws for wide CNNs and networks with skip connections. Following the\napproach of (Dyer & Gur-Ari, 2019), we present a simple diagrammatic recipe to\nderive the asymptotic width dependence for many quantities of interest. These\nscaling relationships provide a solvable description for the training dynamics\nof wide convolutional networks. We test these relations across a broad range of\narchitectures. In particular, we find that the difference in performance\nbetween finite and infinite width models vanishes at a definite rate with\nrespect to model width. Nonetheless, this relation is consistent with finite\nwidth models generalizing either better or worse than their infinite width\ncounterparts, and we provide examples where the relative performance depends on\nthe optimization details.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:22:19 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Andreassen", "Anders", ""], ["Dyer", "Ethan", ""]]}, {"id": "2008.08685", "submitter": "Parikshit Ram", "authors": "Kaushik Sinha and Parikshit Ram", "title": "Neural Neighborhood Encoding for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Inspired by the fruit-fly olfactory circuit, the Fly Bloom Filter [Dasgupta\net al., 2018] is able to efficiently summarize the data with a single pass and\nhas been used for novelty detection. We propose a new classifier (for binary\nand multi-class classification) that effectively encodes the different local\nneighborhoods for each class with a per-class Fly Bloom Filter. The inference\non test data requires an efficient {\\tt FlyHash} [Dasgupta, et al., 2017]\noperation followed by a high-dimensional, but {\\em sparse}, dot product with\nthe per-class Bloom Filters. The learning is trivially parallelizable. On the\ntheoretical side, we establish conditions under which the prediction of our\nproposed classifier on any test example agrees with the prediction of the\nnearest neighbor classifier with high probability. We extensively evaluate our\nproposed scheme with over $50$ data sets of varied data dimensionality to\ndemonstrate that the predictive performance of our proposed neuroscience\ninspired classifier is competitive the the nearest-neighbor classifiers and\nother single-pass classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:01:27 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Sinha", "Kaushik", ""], ["Ram", "Parikshit", ""]]}, {"id": "2008.08710", "submitter": "Baihong Jin", "authors": "Baihong Jin, Yingshui Tan, Albert Liu, Xiangyu Yue, Yuxin Chen,\n  Alberto Sangiovanni Vincentelli", "title": "Using Ensemble Classifiers to Detect Incipient Anomalies", "comments": "Submitted to Transactions on Cyber-Physical Systems for Special Issue\n  on AI and Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incipient anomalies present milder symptoms compared to severe ones, and are\nmore difficult to detect and diagnose due to their close resemblance to normal\noperating conditions. The lack of incipient anomaly examples in the training\ndata can pose severe risks to anomaly detection methods that are built upon\nMachine Learning (ML) techniques, because these anomalies can be easily\nmistaken as normal operating conditions. To address this challenge, we propose\nto utilize the uncertainty information available from ensemble learning to\nidentify potential misclassified incipient anomalies. We show in this paper\nthat ensemble learning methods can give improved performance on incipient\nanomalies and identify common pitfalls in these models through extensive\nexperiments on two real-world datasets. Then, we discuss how to design more\neffective ensemble models for detecting incipient anomalies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 00:00:39 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jin", "Baihong", ""], ["Tan", "Yingshui", ""], ["Liu", "Albert", ""], ["Yue", "Xiangyu", ""], ["Chen", "Yuxin", ""], ["Vincentelli", "Alberto Sangiovanni", ""]]}, {"id": "2008.08713", "submitter": "Baihong Jin", "authors": "Yingshui Tan, Baihong Jin, Qiushi Cui, Xiangyu Yue, Alberto\n  Sangiovanni Vincentelli", "title": "Generalizing Fault Detection Against Domain Shifts Using\n  Stratification-Aware Cross-Validation", "comments": "Submitted to Transactions on Cyber-Physical Systems for Special Issue\n  on AI and Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incipient anomalies present milder symptoms compared to severe ones, and are\nmore difficult to detect and diagnose due to their close resemblance to normal\noperating conditions. The lack of incipient anomaly examples in the training\ndata can pose severe risks to anomaly detection methods that are built upon\nMachine Learning (ML) techniques, because these anomalies can be easily\nmistaken as normal operating conditions. To address this challenge, we propose\nto utilize the uncertainty information available from ensemble learning to\nidentify potential misclassified incipient anomalies. We show in this paper\nthat ensemble learning methods can give improved performance on incipient\nanomalies and identify common pitfalls in these models through extensive\nexperiments on two real-world datasets. Then, we discuss how to design more\neffective ensemble models for detecting incipient anomalies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 00:03:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tan", "Yingshui", ""], ["Jin", "Baihong", ""], ["Cui", "Qiushi", ""], ["Yue", "Xiangyu", ""], ["Vincentelli", "Alberto Sangiovanni", ""]]}, {"id": "2008.08718", "submitter": "Yaroslav Averyanov", "authors": "Yaroslav Averyanov and Alain Celisse", "title": "Minimum discrepancy principle strategy for choosing $k$ in $k$-NN\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel data-driven strategy to choose the hyperparameter $k$ in\nthe $k$-NN regression estimator. We treat the problem of choosing the\nhyperparameter as an iterative procedure (over $k$) and propose using an easily\nimplemented in practice strategy based on the idea of early stopping and the\nminimum discrepancy principle. This model selection strategy is proven to be\nminimax-optimal, under the fixed-design assumption on covariates, over some\nsmoothness function classes, for instance, the Lipschitz functions class on a\nbounded domain. The novel method often improves statistical performance on\nartificial and real-world data sets in comparison to other model selection\nstrategies, such as the Hold-out method and 5-fold cross-validation. The\nnovelty of the strategy comes from reducing the computational time of the model\nselection procedure while preserving the statistical (minimax) optimality of\nthe resulting estimator. More precisely, given a sample of size $n$, assuming\nthat the nearest neighbors are already precomputed, if one should choose $k$\namong $\\left\\{ 1, \\ldots, n \\right\\}$, the strategy reduces the computational\ntime of the generalized cross-validation or Akaike's AIC criteria from\n$\\mathcal{O}\\left( n^3 \\right)$ to $\\mathcal{O}\\left( n^2 (n - k) \\right)$,\nwhere $k$ is the proposed (minimum discrepancy principle) value of the nearest\nneighbors. Code for the simulations is provided at\nhttps://github.com/YaroslavAveryanov/Minimum-discrepancy-principle-for-choosing-k.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 00:13:19 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 15:11:35 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 11:53:33 GMT"}, {"version": "v4", "created": "Wed, 5 May 2021 11:33:16 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Averyanov", "Yaroslav", ""], ["Celisse", "Alain", ""]]}, {"id": "2008.08734", "submitter": "Jing Lai", "authors": "Jing Lai, Junlin Xiong, Zhan Shu", "title": "Model-free optimal control of discrete-time systems with additive and\n  multiplicative noises", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the optimal control problem for a class of\ndiscrete-time stochastic systems subject to additive and multiplicative noises.\nA stochastic Lyapunov equation and a stochastic algebra Riccati equation are\nestablished for the existence of the optimal admissible control policy. A\nmodel-free reinforcement learning algorithm is proposed to learn the optimal\nadmissible control policy using the data of the system states and inputs\nwithout requiring any knowledge of the system matrices. It is proven that the\nlearning algorithm converges to the optimal admissible control policy. The\nimplementation of the model-free algorithm is based on batch least squares and\nnumerical average. The proposed algorithm is illustrated through a numerical\nexample, which shows our algorithm outperforms other policy iteration\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:18:00 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Lai", "Jing", ""], ["Xiong", "Junlin", ""], ["Shu", "Zhan", ""]]}, {"id": "2008.08750", "submitter": "Sayed Kamaledin Ghiasi-Shirazi", "authors": "Ramin Zarei Sabzevar, Kamaledin Ghiasi-Shirazi, Ahad Harati", "title": "Prototype-based interpretation of the functionality of neurons in\n  winner-take-all neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototype-based learning (PbL) using a winner-take-all (WTA) network based on\nminimum Euclidean distance (ED-WTA) is an intuitive approach to multiclass\nclassification. By constructing meaningful class centers, PbL provides higher\ninterpretability and generalization than hyperplane-based learning (HbL)\nmethods based on maximum Inner Product (IP-WTA) and can efficiently detect and\nreject samples that do not belong to any classes. In this paper, we first prove\nthe equivalence of IP-WTA and ED-WTA from a representational point of view.\nThen, we show that naively using this equivalence leads to unintuitive ED-WTA\nnetworks in which the centers have high distances to data that they represent.\nWe propose $\\pm$ED-WTA which models each neuron with two prototypes: one\npositive prototype representing samples that are modeled by this neuron and a\nnegative prototype representing the samples that are erroneously won by that\nneuron during training. We propose a novel training algorithm for the\n$\\pm$ED-WTA network, which cleverly switches between updating the positive and\nnegative prototypes and is essential to the emergence of interpretable\nprototypes. Unexpectedly, we observed that the negative prototype of each\nneuron is indistinguishably similar to the positive one. The rationale behind\nthis observation is that the training data that are mistaken with a prototype\nare indeed similar to it. The main finding of this paper is this interpretation\nof the functionality of neurons as computing the difference between the\ndistances to a positive and a negative prototype, which is in agreement with\nthe BCM theory. In our experiments, we show that the proposed $\\pm$ED-WTA\nmethod constructs highly interpretable prototypes that can be successfully used\nfor detecting outlier and adversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:15:37 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Sabzevar", "Ramin Zarei", ""], ["Ghiasi-Shirazi", "Kamaledin", ""], ["Harati", "Ahad", ""]]}, {"id": "2008.08755", "submitter": "Yihan Wang", "authors": "Yihan Wang, Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh", "title": "On $\\ell_p$-norm Robustness of Ensemble Stumps and Trees", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers have demonstrated that ensemble stumps and trees could be\nvulnerable to small input perturbations, so robustness verification and defense\nfor those models have become an important research problem. However, due to the\nstructure of decision trees, where each node makes decision purely based on one\nfeature value, all the previous works only consider the $\\ell_\\infty$ norm\nperturbation. To study robustness with respect to a general $\\ell_p$ norm\nperturbation, one has to consider the correlation between perturbations on\ndifferent features, which has not been handled by previous algorithms. In this\npaper, we study the problem of robustness verification and certified defense\nwith respect to general $\\ell_p$ norm perturbations for ensemble decision\nstumps and trees. For robustness verification of ensemble stumps, we prove that\ncomplete verification is NP-complete for $p\\in(0, \\infty)$ while polynomial\ntime algorithms exist for $p=0$ or $\\infty$. For $p\\in(0, \\infty)$ we develop\nan efficient dynamic programming based algorithm for sound verification of\nensemble stumps. For ensemble trees, we generalize the previous multi-level\nrobustness verification algorithm to $\\ell_p$ norm. We demonstrate the first\ncertified defense method for training ensemble stumps and trees with respect to\n$\\ell_p$ norm perturbations, and verify its effectiveness empirically on real\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:42:40 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 06:13:02 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Yihan", ""], ["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2008.08757", "submitter": "Jonathan Scarlett", "authors": "Xu Cai and Jonathan Scarlett", "title": "On Lower Bounds for Standard and Robust Gaussian Process Bandit\n  Optimization", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider algorithm-independent lower bounds for the problem\nof black-box optimization of functions having a bounded norm is some\nReproducing Kernel Hilbert Space (RKHS), which can be viewed as a non-Bayesian\nGaussian process bandit problem. In the standard noisy setting, we provide a\nnovel proof technique for deriving lower bounds on the regret, with benefits\nincluding simplicity, versatility, and an improved dependence on the error\nprobability. In a robust setting in which every sampled point may be perturbed\nby a suitably-constrained adversary, we provide a novel lower bound for\ndeterministic strategies, demonstrating an inevitable joint dependence of the\ncumulative regret on the corruption level and the time horizon, in contrast\nwith existing lower bounds that only characterize the individual dependencies.\nFurthermore, in a distinct robust setting in which the final point is perturbed\nby an adversary, we strengthen an existing lower bound that only holds for\ntarget success probabilities very close to one, by allowing for arbitrary\nsuccess probabilities above $\\frac{2}{3}$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:48:14 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 08:52:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cai", "Xu", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2008.08818", "submitter": "DuongNguyen Nguyen", "authors": "Duong-Nguyen Nguyen, Tien-Lam Pham, Viet-Cuong Nguyen, Hiori Kino,\n  Takashi Miyake, Hieu-Chi Dam", "title": "Ensemble learning reveals dissimilarity between rare-earth transition\n  metal binary alloys with respect to the Curie temperature", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven method to extract dissimilarity between materials,\nwith respect to a given target physical property. The technique is based on an\nensemble method with Kernel ridge regression as the predicting model; multiple\nrandom subset sampling of the materials is done to generate prediction models\nand the corresponding contributions of the reference training materials in\ndetail. The distribution of the predicted values for each material can be\napproximated by a Gaussian mixture model. The reference training materials\ncontributed to the prediction model that accurately predicts the physical\nproperty value of a specific material, are considered to be similar to that\nmaterial, or vice versa. Evaluations using synthesized data demonstrate that\nthe proposed method can effectively measure the dissimilarity between data\ninstances. An application of the analysis method on the data of Curie\ntemperature (TC) of binary 3d transition metal 4f rare earth binary alloys also\nreveals meaningful results on the relations between the materials. The proposed\nmethod can be considered as a potential tool for obtaining a deeper\nunderstanding of the structure of data, with respect to a target property, in\nparticular.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:46:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Nguyen", "Duong-Nguyen", ""], ["Pham", "Tien-Lam", ""], ["Nguyen", "Viet-Cuong", ""], ["Kino", "Hiori", ""], ["Miyake", "Takashi", ""], ["Dam", "Hieu-Chi", ""]]}, {"id": "2008.08838", "submitter": "Sitao Luan", "authors": "Sitao Luan, Mingde Zhao, Xiao-Wen Chang, Doina Precup", "title": "Training Matters: Unlocking Potentials of Deeper Graph Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance limit of Graph Convolutional Networks (GCNs) and the fact\nthat we cannot stack more of them to increase the performance, which we usually\ndo for other deep learning paradigms, are pervasively thought to be caused by\nthe limitations of the GCN layers, including insufficient expressive power,\netc. However, if so, for a fixed architecture, it would be unlikely to lower\nthe training difficulty and to improve performance by changing only the\ntraining procedure, which we show in this paper not only possible but possible\nin several ways. This paper first identify the training difficulty of GCNs from\nthe perspective of graph signal energy loss. More specifically, we find that\nthe loss of energy in the backward pass during training nullifies the learning\nof the layers closer to the input. Then, we propose several methodologies to\nmitigate the training problem by slightly modifying the GCN operator, from the\nenergy perspective. After empirical validation, we confirm that these changes\nof operator lead to significant decrease in the training difficulties and\nnotable performance boost, without changing the composition of parameters. With\nthese, we conclude that the root cause of the problem is more likely the\ntraining difficulty than the others.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 08:36:27 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Luan", "Sitao", ""], ["Zhao", "Mingde", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "2008.08844", "submitter": "Sitao Luan", "authors": "Sitao Luan, Mingde Zhao, Chenqing Hua, Xiao-Wen Chang, Doina Precup", "title": "Complete the Missing Half: Augmenting Aggregation Filtering with\n  Diversification for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core operation of current Graph Neural Networks (GNNs) is the aggregation\nenabled by the graph Laplacian or message passing, which filters the\nneighborhood node information. Though effective for various tasks, in this\npaper, we show that they are potentially a problematic factor underlying all\nGNN methods for learning on certain datasets, as they force the node\nrepresentations similar, making the nodes gradually lose their identity and\nbecome indistinguishable. Hence, we augment the aggregation operations with\ntheir dual, i.e. diversification operators that make the node more distinct and\npreserve the identity. Such augmentation replaces the aggregation with a\ntwo-channel filtering process that, in theory, is beneficial for enriching the\nnode representations. In practice, the proposed two-channel filters can be\neasily patched on existing GNN methods with diverse training strategies,\nincluding spectral and spatial (message passing) methods. In the experiments,\nwe observe desired characteristics of the models and significant performance\nboost upon the baselines on 9 node classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 08:45:16 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 23:21:11 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 20:25:09 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Luan", "Sitao", ""], ["Zhao", "Mingde", ""], ["Hua", "Chenqing", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "2008.08878", "submitter": "Satheesh Kumar Perepu", "authors": "Satheesh K. Perepu, Bala Shyamala Balaji, Hemanth Kumar Tanneru,\n  Sudhakar Kathari, Vivek Shankar Pinnamaraju", "title": "Reinforcement Learning based dynamic weighing of Ensemble Models for\n  Time Series Forecasting", "comments": "6 pages, 4 figures, In review for conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble models are powerful model building tools that are developed with a\nfocus to improve the accuracy of model predictions. They find applications in\ntime series forecasting in varied scenarios including but not limited to\nprocess industries, health care, and economics where a single model might not\nprovide optimal performance. It is known that if models selected for data\nmodelling are distinct (linear/non-linear, static/dynamic) and independent\n(minimally correlated models), the accuracy of the predictions is improved.\nVarious approaches suggested in the literature to weigh the ensemble models use\na static set of weights. Due to this limitation, approaches using a static set\nof weights for weighing ensemble models cannot capture the dynamic changes or\nlocal features of the data effectively. To address this issue, a Reinforcement\nLearning (RL) approach to dynamically assign and update weights of each of the\nmodels at different time instants depending on the nature of data and the\nindividual model predictions is proposed in this work. The RL method\nimplemented online, essentially learns to update the weights and reduce the\nerrors as the time progresses. Simulation studies on time series data showed\nthat the dynamic weighted approach using RL learns the weight better than\nexisting approaches. The accuracy of the proposed method is compared with an\nexisting approach of online Neural Network tuning quantitatively through\nnormalized mean square error(NMSE) values.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:40:42 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Perepu", "Satheesh K.", ""], ["Balaji", "Bala Shyamala", ""], ["Tanneru", "Hemanth Kumar", ""], ["Kathari", "Sudhakar", ""], ["Pinnamaraju", "Vivek Shankar", ""]]}, {"id": "2008.08882", "submitter": "Jaehoon Oh", "authors": "Jaehoon Oh, Hyungjun Yoo, ChangHwan Kim, Se-Young Yun", "title": "BOIL: Towards Representation Change for Few-shot Learning", "comments": "24 pages, 26 figures, 19 tables, ICLR 2021 published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model Agnostic Meta-Learning (MAML) is one of the most representative of\ngradient-based meta-learning algorithms. MAML learns new tasks with a few data\nsamples using inner updates from a meta-initialization point and learns the\nmeta-initialization parameters with outer updates. It has recently been\nhypothesized that representation reuse, which makes little change in efficient\nrepresentations, is the dominant factor in the performance of the\nmeta-initialized model through MAML in contrast to representation change, which\ncauses a significant change in representations. In this study, we investigate\nthe necessity of representation change for the ultimate goal of few-shot\nlearning, which is solving domain-agnostic tasks. To this aim, we propose a\nnovel meta-learning algorithm, called BOIL (Body Only update in Inner Loop),\nwhich updates only the body (extractor) of the model and freezes the head\n(classifier) during inner loop updates. BOIL leverages representation change\nrather than representation reuse. This is because feature vectors\n(representations) have to move quickly to their corresponding frozen head\nvectors. We visualize this property using cosine similarity, CKA, and empirical\nresults without the head. BOIL empirically shows significant performance\nimprovement over MAML, particularly on cross-domain tasks. The results imply\nthat representation change in gradient-based meta-learning approaches is a\ncritical component.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:52:23 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 05:16:52 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Oh", "Jaehoon", ""], ["Yoo", "Hyungjun", ""], ["Kim", "ChangHwan", ""], ["Yun", "Se-Young", ""]]}, {"id": "2008.08885", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "No-regret Algorithms for Multi-task Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-objective optimization (MOO) of an unknown vector-valued\nfunction in the non-parametric Bayesian optimization (BO) setting, with the aim\nbeing to learn points on the Pareto front of the objectives. Most existing BO\nalgorithms do not model the fact that the multiple objectives, or equivalently,\ntasks can share similarities, and even the few that do lack rigorous,\nfinite-time regret guarantees that capture explicitly inter-task structure. In\nthis work, we address this problem by modelling inter-task dependencies using a\nmulti-task kernel and develop two novel BO algorithms based on random\nscalarizations of the objectives. Our algorithms employ vector-valued kernel\nregression as a stepping stone and belong to the upper confidence bound class\nof algorithms. Under a smoothness assumption that the unknown vector-valued\nfunction is an element of the reproducing kernel Hilbert space associated with\nthe multi-task kernel, we derive worst-case regret bounds for our algorithms\nthat explicitly capture the similarities between tasks. We numerically\nbenchmark our algorithms on both synthetic and real-life MOO problems, and show\nthe advantages offered by learning with multi-task kernels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:55:20 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2008.08894", "submitter": "Tsuyoshi Kato", "authors": "Kenya Tajima, Yoshihiro Hirohashi, Esmeraldo Ronnie Rey Zara, Tsuyoshi\n  Kato", "title": "Frank-Wolfe algorithm for learning SVM-type multi-category classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-category support vector machine (MC-SVM) is one of the most popular\nmachine learning algorithms. There are lots of variants of MC-SVM, although\ndifferent optimization algorithms were developed for different learning\nmachines. In this study, we developed a new optimization algorithm that can be\napplied to many of MC-SVM variants. The algorithm is based on the Frank-Wolfe\nframework that requires two subproblems, direction finding and line search, in\neach iteration. The contribution of this study is the discovery that both\nsubproblems have a closed form solution if the Frank-Wolfe framework is applied\nto the dual problem. Additionally, the closed form solutions on both for the\ndirection finding and for the line search exist even for the Moreau envelopes\nof the loss functions. We use several large datasets to demonstrate that the\nproposed optimization algorithm converges rapidly and thereby improves the\npattern recognition performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:19:07 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tajima", "Kenya", ""], ["Hirohashi", "Yoshihiro", ""], ["Zara", "Esmeraldo Ronnie Rey", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "2008.08912", "submitter": "Hrithwik Shalu", "authors": "Hrithwik Shalu, Harikrishnan P, Akash Das, Megdut Mandal,\n  Harshavardhan M Sali, Juned Kadiwala", "title": "A Data-Efficient Deep Learning Based Smartphone Application For\n  Detection Of Pulmonary Diseases Using Chest X-rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a paradigm of smartphone application based disease\ndiagnostics that may completely revolutionise the way healthcare services are\nbeing provided. Although primarily aimed to assist the problems in rendering\nthe healthcare services during the coronavirus pandemic, the model can also be\nextended to identify the exact disease that the patient is caught with from a\nbroad spectrum of pulmonary diseases. The app inputs Chest X-Ray images\ncaptured from the mobile camera which is then relayed to the AI architecture in\na cloud platform, and diagnoses the disease with state of the art accuracy.\nDoctors with a smartphone can leverage the application to save the considerable\ntime that standard COVID-19 tests take for preliminary diagnosis. The scarcity\nof training data and class imbalance issues were effectively tackled in our\napproach by the use of Data Augmentation Generative Adversarial Network (DAGAN)\nand model architecture based as a Convolutional Siamese Network with attention\nmechanism. The backend model was tested for robustness us-ing publicly\navailable datasets under two different classification\nscenarios(Binary/Multiclass) with minimal and noisy data. The model achieved\npinnacle testing accuracy of 99.30% and 98.40% on the two respective scenarios,\nmaking it completely reliable for its users. On top of that a semi-live\ntraining scenario was introduced, which helps improve the app performance over\ntime as data accumulates. Overall, the problems of generalisability of complex\nmodels and data inefficiency is tackled through the model architecture. The app\nbased setting with semi live training helps in ease of access to reliable\nhealthcare in the society, as well as help ineffective research of rare\ndiseases in a minimal data setting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 04:28:17 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Shalu", "Hrithwik", ""], ["P", "Harikrishnan", ""], ["Das", "Akash", ""], ["Mandal", "Megdut", ""], ["Sali", "Harshavardhan M", ""], ["Kadiwala", "Juned", ""]]}, {"id": "2008.08915", "submitter": "Yikai Wang", "authors": "Yikai Wang and Ying Guo", "title": "LOCUS: A Novel Decomposition Method for Brain Network Connectivity\n  Matrices using Low-rank Structure with Uniform Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network-oriented research has been increasingly popular in many scientific\nareas. In neuroscience research, imaging-based network connectivity measures\nhave become the key for understanding brain organizations, potentially serving\nas individual neural fingerprints. There are major challenges in analyzing\nconnectivity matrices including the high dimensionality of brain networks,\nunknown latent sources underlying the observed connectivity, and the large\nnumber of brain connections leading to spurious findings. In this paper, we\npropose a novel blind source separation method with low-rank structure and\nuniform sparsity (LOCUS) as a fully data-driven decomposition method for\nnetwork measures. Compared with the existing method that vectorizes\nconnectivity matrices ignoring brain network topology, LOCUS achieves more\nefficient and accurate source separation for connectivity matrices using\nlow-rank structure. We propose a novel angle-based uniform sparsity\nregularization that demonstrates better performance than the existing sparsity\ncontrols for low-rank tensor methods. We propose a highly efficient iterative\nNode-Rotation algorithm that exploits the block multi-convexity of the\nobjective function to solve the non-convex optimization problem for learning\nLOCUS. We illustrate the advantage of LOCUS through extensive simulation\nstudies. Application of LOCUS to Philadelphia Neurodevelopmental Cohort\nneuroimaging study reveals biologically insightful connectivity traits which\nare not found using the existing method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:47:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Wang", "Yikai", ""], ["Guo", "Ying", ""]]}, {"id": "2008.08931", "submitter": "Liyi Guo", "authors": "Liyi Guo, Rui Lu, Haoqi Zhang, Junqi Jin, Zhenzhe Zheng, Fan Wu, Jin\n  Li, Haiyang Xu, Han Li, Wenkai Lu, Jian Xu, Kun Gai", "title": "A Deep Prediction Network for Understanding Advertiser Intent and\n  Satisfaction", "comments": null, "journal-ref": "CIKM 2020, Virtual Event, Ireland", "doi": "10.1145/3340531.3412681", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For e-commerce platforms such as Taobao and Amazon, advertisers play an\nimportant role in the entire digital ecosystem: their behaviors explicitly\ninfluence users' browsing and shopping experience; more importantly,\nadvertiser's expenditure on advertising constitutes a primary source of\nplatform revenue. Therefore, providing better services for advertisers is\nessential for the long-term prosperity for e-commerce platforms. To achieve\nthis goal, the ad platform needs to have an in-depth understanding of\nadvertisers in terms of both their marketing intents and satisfaction over the\nadvertising performance, based on which further optimization could be carried\nout to service the advertisers in the correct direction. In this paper, we\npropose a novel Deep Satisfaction Prediction Network (DSPN), which models\nadvertiser intent and satisfaction simultaneously. It employs a two-stage\nnetwork structure where advertiser intent vector and satisfaction are jointly\nlearned by considering the features of advertiser's action information and\nadvertising performance indicators. Experiments on an Alibaba advertisement\ndataset and online evaluations show that our proposed DSPN outperforms\nstate-of-the-art baselines and has stable performance in terms of AUC in the\nonline environment. Further analyses show that DSPN not only predicts\nadvertisers' satisfaction accurately but also learns an explainable advertiser\nintent, revealing the opportunities to optimize the advertising performance\nfurther.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:08:50 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Guo", "Liyi", ""], ["Lu", "Rui", ""], ["Zhang", "Haoqi", ""], ["Jin", "Junqi", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Li", "Jin", ""], ["Xu", "Haiyang", ""], ["Li", "Han", ""], ["Lu", "Wenkai", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "2008.08937", "submitter": "Christopher Frantz", "authors": "Christopher K. Frantz and Saba N. Siddiki", "title": "Institutional Grammar 2.0 Codebook", "comments": "120 pages, 16 figures, 14 tables", "journal-ref": null, "doi": "10.1111/padm.12719", "report-no": "IG-001", "categories": "cs.MA cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Grammar of Institutions, or Institutional Grammar, is an established\napproach to encode policy information in terms of institutional statements\nbased on a set of pre-defined syntactic components. This codebook provides\ncoding guidelines for a revised version of the Institutional Grammar, the\nInstitutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at\nfacilitating the encoding of policy to meet varying analytical objectives. To\nthis end, it revises the grammar with respect to comprehensiveness,\nflexibility, and specificity by offering multiple levels of expressiveness (IG\nCore, IG Extended, IG Logico). In addition to the encoding of regulative\nstatements, it further introduces the encoding of constitutive institutional\nstatements, as well as statements that exhibit both constitutive and regulative\ncharacteristics. Introducing those aspects, the codebook initially covers\nfundamental concepts of IG 2.0, before providing an overview of pre-coding\nsteps relevant for document preparation. Detailed coding guidelines are\nprovided for both regulative and constitutive statements across all levels of\nexpressiveness, along with the encoding guidelines for statements of mixed form\n-- hybrid and polymorphic institutional statements. The document further\nprovides an overview of taxonomies used in the encoding process and referred to\nthroughout the codebook. The codebook concludes with a summary and discussion\nof relevant considerations to facilitate the coding process. An initial\nReader's Guide helps the reader tailor the content to her interest.\n  Note that this codebook specifically focuses on operational aspects of IG 2.0\nin the context of policy coding. Links to additional resources such as the\nunderlying scientific literature (that offers a comprehensive treatment of the\nunderlying theoretical concepts) are referred to in the concluding section of\nthe codebook.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 12:38:55 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 21:15:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 13:12:00 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Frantz", "Christopher K.", ""], ["Siddiki", "Saba N.", ""]]}, {"id": "2008.08951", "submitter": "Rahim Mammadli", "authors": "Rahim Mammadli, Ali Jannesari and Felix Wolf", "title": "Static Neural Compiler Optimization via Deep Reinforcement Learning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase-ordering problem of modern compilers has received a lot of\nattention from the research community over the years, yet remains largely\nunsolved. Various optimization sequences exposed to the user are manually\ndesigned by compiler developers. In designing such a sequence developers have\nto choose the set of optimization passes, their parameters and ordering within\na sequence. Resulting sequences usually fall short of achieving optimal runtime\nfor a given source code and may sometimes even degrade the performance when\ncompared to unoptimized version. In this paper, we employ a deep reinforcement\nlearning approach to the phase-ordering problem. Provided with sub-sequences\nconstituting LLVM's O3 sequence, our agent learns to outperform the O3 sequence\non the set of source codes used for training and achieves competitive\nperformance on the validation set, gaining up to 1.32x speedup on\npreviously-unseen programs. Notably, our approach differs from autotuning\nmethods by not depending on one or more test runs of the program for making\nsuccessful optimization decisions. It has no dependence on any dynamic feature,\nbut only on the statically-attainable intermediate representation of the source\ncode. We believe that the models trained using our approach can be integrated\ninto modern compilers as neural optimization agents, at first to complement,\nand eventually replace the hand-crafted optimization sequences.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:16:29 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:10:48 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 11:31:38 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mammadli", "Rahim", ""], ["Jannesari", "Ali", ""], ["Wolf", "Felix", ""]]}, {"id": "2008.08956", "submitter": "Manikandan Ravikiran", "authors": "Siddharth Vohra, Manikandan Ravikiran", "title": "Investigating the Effect of Intraclass Variability in Temporal\n  Ensembling", "comments": "Preliminary Results; More Experiments to be added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Ensembling is a semi-supervised approach that allows training deep\nneural network models with a small number of labeled images. In this paper, we\npresent our preliminary study on the effect of intraclass variability on\ntemporal ensembling, with a focus on seed size and seed type, respectively.\nThrough our experiments we find that (a) there is a significant drop in\naccuracy with datasets that offer high intraclass variability, (b) more seed\nimages offer consistently higher accuracy across the datasets, and (c) seed\ntype indeed has an impact on the overall efficiency, where it produces a\nspectrum of accuracy both lower and higher. Additionally, based on our\nexperiments, we also find KMNIST to be a competitive baseline for temporal\nensembling.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:24:51 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 09:12:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Vohra", "Siddharth", ""], ["Ravikiran", "Manikandan", ""]]}, {"id": "2008.08970", "submitter": "Monika Csikos", "authors": "M\\'onika Csik\\'os and Nabil H. Mustafa", "title": "Optimal Approximations Made Easy", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental result of Li, Long, and Srinivasan on approximations of set\nsystems has become a key tool across several communities such as learning\ntheory, algorithms, computational geometry, combinatorics and data analysis.\n  The goal of this paper is to give a modular, self-contained, intuitive proof\nof this result for finite set systems. The only ingredient we assume is the\nstandard Chernoff's concentration bound. This makes the proof accessible to a\nwider audience, readers not familiar with techniques from statistical learning\ntheory, and makes it possible to be covered in a single self-contained lecture\nin a geometry, algorithms or combinatorics course.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:58:14 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 16:16:31 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Csik\u00f3s", "M\u00f3nika", ""], ["Mustafa", "Nabil H.", ""]]}, {"id": "2008.09010", "submitter": "Marco Maggipinto", "authors": "Marco Maggipinto and Matteo Terzi and Gian Antonio Susto", "title": "$\\beta$-Variational Classifiers Under Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural networks have gained lots of attention in recent years thanks to\nthe breakthroughs obtained in the field of Computer Vision. However, despite\ntheir popularity, it has been shown that they provide limited robustness in\ntheir predictions. In particular, it is possible to synthesise small\nadversarial perturbations that imperceptibly modify a correctly classified\ninput data, making the network confidently misclassify it. This has led to a\nplethora of different methods to try to improve robustness or detect the\npresence of these perturbations. In this paper, we perform an analysis of\n$\\beta$-Variational Classifiers, a particular class of methods that not only\nsolve a specific classification task, but also provide a generative component\nthat is able to generate new samples from the input distribution. More in\ndetails, we study their robustness and detection capabilities, together with\nsome novel insights on the generative part of the model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:57:22 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Maggipinto", "Marco", ""], ["Terzi", "Matteo", ""], ["Susto", "Gian Antonio", ""]]}, {"id": "2008.09020", "submitter": "Md. Khaledur Rahman", "authors": "Md. Khaledur Rahman", "title": "Training Sensitivity in Graph Isomorphism Network", "comments": "Accepted for publication in CIKM 2020", "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph neural network (GNN) is a popular tool to learn the lower-dimensional\nrepresentation of a graph. It facilitates the applicability of machine learning\ntasks on graphs by incorporating domain-specific features. There are various\noptions for underlying procedures (such as optimization functions, activation\nfunctions, etc.) that can be considered in the implementation of GNN. However,\nmost of the existing tools are confined to one approach without any analysis.\nThus, this emerging field lacks a robust implementation ignoring the highly\nirregular structure of the real-world graphs. In this paper, we attempt to fill\nthis gap by studying various alternative functions for a respective module\nusing a diverse set of benchmark datasets. Our empirical results suggest that\nthe generally used underlying techniques do not always perform well to capture\nthe overall structure from a set of graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:50:28 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Rahman", "Md. Khaledur", ""]]}, {"id": "2008.09055", "submitter": "Quoc Tran-Dinh", "authors": "Deyi Liu, Lam M. Nguyen, and Quoc Tran-Dinh", "title": "An Optimal Hybrid Variance-Reduced Algorithm for Stochastic Composite\n  Nonconvex Optimization", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": "STOR-UNC-08-20-P4", "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we propose a new variant of the hybrid variance-reduced proximal\ngradient method in [7] to solve a common stochastic composite nonconvex\noptimization problem under standard assumptions. We simply replace the\nindependent unbiased estimator in our hybrid- SARAH estimator introduced in [7]\nby the stochastic gradient evaluated at the same sample, leading to the\nidentical momentum-SARAH estimator introduced in [2]. This allows us to save\none stochastic gradient per iteration compared to [7], and only requires two\nsamples per iteration. Our algorithm is very simple and achieves optimal\nstochastic oracle complexity bound in terms of stochastic gradient evaluations\n(up to a constant factor). Our analysis is essentially inspired by [7], but we\ndo not use two different step-sizes.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:15:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Liu", "Deyi", ""], ["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""]]}, {"id": "2008.09083", "submitter": "Soumendu Sundar Mukherjee", "authors": "Shyamal K. De and Soumendu Sundar Mukherjee", "title": "Exact Tests for Offline Changepoint Detection in Multichannel Binary and\n  Count Data with Application to Networks", "comments": "31 pages, 9 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider offline detection of a single changepoint in binary and count\ntime-series. We compare exact tests based on the cumulative sum (CUSUM) and the\nlikelihood ratio (LR) statistics, and a new proposal that combines exact\ntwo-sample conditional tests with multiplicity correction, against standard\nasymptotic tests based on the Brownian bridge approximation to the CUSUM\nstatistic. We see empirically that the exact tests are much more powerful in\nsituations where normal approximations driving asymptotic tests are not\ntrustworthy: (i) small sample settings; (ii) sparse parametric settings; (iii)\ntime-series with changepoint near the boundary.\n  We also consider a multichannel version of the problem, where channels can\nhave different changepoints. Controlling the False Discovery Rate (FDR), we\nsimultaneously detect changes in multiple channels. This \"local\" approach is\nshown to be more advantageous than multivariate global testing approaches when\nthe number of channels with changepoints is much smaller than the total number\nof channels.\n  As a natural application, we consider network-valued time-series and use our\napproach with (a) edges as binary channels and (b) node-degrees or other local\nsubgraph statistics as count channels. The local testing approach is seen to be\nmuch more informative than global network changepoint algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:16:05 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["De", "Shyamal K.", ""], ["Mukherjee", "Soumendu Sundar", ""]]}, {"id": "2008.09148", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Usman Roshan", "title": "Towards adversarial robustness with 01 loss neural networks", "comments": "arXiv admin note: text overlap with arXiv:2006.07800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the general robustness properties of the 01 loss we propose a\nsingle hidden layer 01 loss neural network trained with stochastic coordinate\ndescent as a defense against adversarial attacks in machine learning. One\nmeasure of a model's robustness is the minimum distortion required to make the\ninput adversarial. This can be approximated with the Boundary Attack (Brendel\net. al. 2018) and HopSkipJump (Chen et. al. 2019) methods. We compare the\nminimum distortion of the 01 loss network to the binarized neural network and\nthe standard sigmoid activation network with cross-entropy loss all trained\nwith and without Gaussian noise on the CIFAR10 benchmark binary classification\nbetween classes 0 and 1. Both with and without noise training we find our 01\nloss network to have the largest adversarial distortion of the three models by\nnon-trivial margins. To further validate these results we subject all models to\nsubstitute model black box attacks under different distortion thresholds and\nfind that the 01 loss network is the hardest to attack across all distortions.\nAt a distortion of 0.125 both sigmoid activated cross-entropy loss and\nbinarized networks have almost 0% accuracy on adversarial examples whereas the\n01 loss network is at 40%. Even though both 01 loss and the binarized network\nuse sign activations their training algorithms are different which in turn give\ndifferent solutions for robustness. Finally we compare our network to simple\nconvolutional models under substitute model black box attacks and find their\naccuracies to be comparable. Our work shows that the 01 loss network has the\npotential to defend against black box adversarial attacks better than convex\nloss and binarized networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:18:49 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Roshan", "Usman", ""]]}, {"id": "2008.09149", "submitter": "Yoni Choukroun", "authors": "Yoni Choukroun, Michael Zibulevsky, Pavel Kisilev", "title": "Primal-Dual Sequential Subspace Optimization for Saddle-point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new sequential subspace optimization method for large-scale\nsaddle-point problems. It solves iteratively a sequence of auxiliary\nsaddle-point problems in low-dimensional subspaces, spanned by directions\nderived from first-order information over the primal \\emph{and} dual variables.\nProximal regularization is further deployed to stabilize the optimization\nprocess. Experimental results demonstrate significantly better convergence\nrelative to popular first-order methods. We analyze the influence of the\nsubspace on the convergence of the algorithm, and assess its performance in\nvarious deterministic optimization scenarios, such as bi-linear games,\nADMM-based constrained optimization and generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:19:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Choukroun", "Yoni", ""], ["Zibulevsky", "Michael", ""], ["Kisilev", "Pavel", ""]]}, {"id": "2008.09161", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Abhishek Singh, Otkrist Gupta, Ramesh Raskar", "title": "NoPeek: Information leakage reduction to share activations in\n  distributed deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distributed machine learning with sensitive data, we demonstrate how\nminimizing distance correlation between raw data and intermediary\nrepresentations reduces leakage of sensitive raw data patterns across client\ncommunications while maintaining model accuracy. Leakage (measured using\ndistance correlation between input and intermediate representations) is the\nrisk associated with the invertibility of raw data from intermediary\nrepresentations. This can prevent client entities that hold sensitive data from\nusing distributed deep learning services. We demonstrate that our method is\nresilient to such reconstruction attacks and is based on reduction of distance\ncorrelation between raw data and learned representations during training and\ninference with image datasets. We prevent such reconstruction of raw data while\nmaintaining information required to sustain good classification accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:03:17 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Singh", "Abhishek", ""], ["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2008.09165", "submitter": "Caroline Moosm\\\"uller", "authors": "Caroline Moosm\\\"uller and Alexander Cloninger", "title": "Linear Optimal Transport Embedding: Provable Wasserstein classification\n  for certain rigid transformations and perturbations", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating between distributions is an important problem in a number of\nscientific fields. This motivated the introduction of Linear Optimal\nTransportation (LOT), which embeds the space of distributions into an\n$L^2$-space. The transform is defined by computing the optimal transport of\neach distribution to a fixed reference distribution, and has a number of\nbenefits when it comes to speed of computation and to determining\nclassification boundaries. In this paper, we characterize a number of settings\nin which LOT embeds families of distributions into a space in which they are\nlinearly separable. This is true in arbitrary dimension, and for families of\ndistributions generated through perturbations of shifts and scalings of a fixed\ndistribution.We also prove conditions under which the $L^2$ distance of the LOT\nembedding between two distributions in arbitrary dimension is nearly isometric\nto Wasserstein-2 distance between those distributions. This is of significant\ncomputational benefit, as one must only compute $N$ optimal transport maps to\ndefine the $N^2$ pairwise distances between $N$ distributions. We demonstrate\nthe benefits of LOT on a number of distribution classification problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:09:33 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 03:17:30 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 03:48:35 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Moosm\u00fcller", "Caroline", ""], ["Cloninger", "Alexander", ""]]}, {"id": "2008.09167", "submitter": "Georgios Papagiannis", "authors": "Georgios Papagiannis and Yunpeng Li", "title": "Imitation Learning with Sinkhorn Distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms have been interpreted as variants of divergence\nminimization problems. The ability to compare occupancy measures between\nexperts and learners is crucial in their effectiveness in learning from\ndemonstrations. In this paper, we present tractable solutions by formulating\nimitation learning as minimization of the Sinkhorn distance between occupancy\nmeasures. The formulation combines the valuable properties of optimal transport\nmetrics in comparing non-overlapping distributions with a cosine distance cost\ndefined in an adversarially learned feature space. This leads to a highly\ndiscriminative critic network and optimal transport plan that subsequently\nguide imitation learning. We evaluate the proposed approach using both the\nreward metric and the Sinkhorn distance metric on a number of MuJoCo\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:13:21 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Papagiannis", "Georgios", ""], ["Li", "Yunpeng", ""]]}, {"id": "2008.09239", "submitter": "Jing Liu", "authors": "Jing Liu, Aditya Deshmukh, Venugopal V. Veeravalli", "title": "Robust Mean Estimation in High Dimensions via $\\ell_0$ Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robust mean estimation problem in high dimensions, where $\\alpha\n<0.5$ fraction of the data points can be arbitrarily corrupted. Motivated by\ncompressive sensing, we formulate the robust mean estimation problem as the\nminimization of the $\\ell_0$-`norm' of the outlier indicator vector, under\nsecond moment constraints on the inlier data points. We prove that the global\nminimum of this objective is order optimal for the robust mean estimation\nproblem, and we propose a general framework for minimizing the objective. We\nfurther leverage the $\\ell_1$ and $\\ell_p$ $(0<p<1)$, minimization techniques\nin compressive sensing to provide computationally tractable solutions to the\n$\\ell_0$ minimization problem. Both synthetic and real data experiments\ndemonstrate that the proposed algorithms significantly outperform\nstate-of-the-art robust mean estimation methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:19:48 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Liu", "Jing", ""], ["Deshmukh", "Aditya", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "2008.09246", "submitter": "Jie Xu", "authors": "Jie Xu, Wei Zhang, Fei Wang", "title": "A(DP)$^2$SGD: Asynchronous Decentralized Parallel Stochastic Gradient\n  Descent with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning models are usually massive and complex, distributed learning\nis essential for increasing training efficiency. Moreover, in many real-world\napplication scenarios like healthcare, distributed learning can also keep the\ndata local and protect privacy. A popular distributed learning strategy is\nfederated learning, where there is a central server storing the global model\nand a set of local computing nodes updating the model parameters with their\ncorresponding data. The updated model parameters will be processed and\ntransmitted to the central server, which leads to heavy communication costs.\nRecently, asynchronous decentralized distributed learning has been proposed and\ndemonstrated to be a more efficient and practical strategy where there is no\ncentral server, so that each computing node only communicates with its\nneighbors. Although no raw data will be transmitted across different local\nnodes, there is still a risk of information leak during the communication\nprocess for malicious participants to make attacks. In this paper, we present a\ndifferentially private version of asynchronous decentralized parallel SGD\n(ADPSGD) framework, or A(DP)$^2$SGD for short, which maintains communication\nefficiency of ADPSGD and prevents the inference from malicious participants.\nSpecifically, R{\\'e}nyi differential privacy is used to provide tighter privacy\nanalysis for our composite Gaussian mechanisms while the convergence rate is\nconsistent with the non-private version. Theoretical analysis shows\nA(DP)$^2$SGD also converges at the optimal $\\mathcal{O}(1/\\sqrt{T})$ rate as\nSGD. Empirically, A(DP)$^2$SGD achieves comparable model accuracy as the\ndifferentially private version of Synchronous SGD (SSGD) but runs much faster\nthan SSGD in heterogeneous computing environments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:56:22 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xu", "Jie", ""], ["Zhang", "Wei", ""], ["Wang", "Fei", ""]]}, {"id": "2008.09251", "submitter": "Yuanhao Wang", "authors": "Yuanhao Wang and Kefan Dong", "title": "Refined Analysis of FPL for Adversarial Markov Decision Processes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the adversarial Markov Decision Process (MDP) problem, where the\nrewards for the MDP can be adversarially chosen, and the transition function\ncan be either known or unknown. In both settings, Follow-the-PerturbedLeader\n(FPL) based algorithms have been proposed in previous literature. However, the\nestablished regret bounds for FPL based algorithms are worse than algorithms\nbased on mirrordescent. We improve the analysis of FPL based algorithms in both\nsettings, matching the current best regret bounds using faster and simpler\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 01:12:10 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Wang", "Yuanhao", ""], ["Dong", "Kefan", ""]]}, {"id": "2008.09279", "submitter": "Sandamal Weerasinghe", "authors": "Sandamal Weerasinghe, Sarah M. Erfani, Tansu Alpcan, Christopher\n  Leckie, Justin Kopacz", "title": "Defending Regression Learners Against Poisoning Attacks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression models, which are widely used from engineering applications to\nfinancial forecasting, are vulnerable to targeted malicious attacks such as\ntraining data poisoning, through which adversaries can manipulate their\npredictions. Previous works that attempt to address this problem rely on\nassumptions about the nature of the attack/attacker or overestimate the\nknowledge of the learner, making them impractical. We introduce a novel Local\nIntrinsic Dimensionality (LID) based measure called N-LID that measures the\nlocal deviation of a given data point's LID with respect to its neighbors. We\nthen show that N-LID can distinguish poisoned samples from normal samples and\npropose an N-LID based defense approach that makes no assumptions of the\nattacker. Through extensive numerical experiments with benchmark datasets, we\nshow that the proposed defense mechanism outperforms the state of the art\ndefenses in terms of prediction accuracy (up to 76% lower MSE compared to an\nundefended ridge model) and running time.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:02:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Weerasinghe", "Sandamal", ""], ["Erfani", "Sarah M.", ""], ["Alpcan", "Tansu", ""], ["Leckie", "Christopher", ""], ["Kopacz", "Justin", ""]]}, {"id": "2008.09284", "submitter": "Sandamal Weerasinghe", "authors": "Sandamal Weerasinghe, Tansu Alpcan, Sarah M. Erfani, Christopher\n  Leckie", "title": "Defending Distributed Classifiers Against Data Poisoning Attacks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines (SVMs) are vulnerable to targeted training data\nmanipulations such as poisoning attacks and label flips. By carefully\nmanipulating a subset of training samples, the attacker forces the learner to\ncompute an incorrect decision boundary, thereby cause misclassifications.\nConsidering the increased importance of SVMs in engineering and life-critical\napplications, we develop a novel defense algorithm that improves resistance\nagainst such attacks. Local Intrinsic Dimensionality (LID) is a promising\nmetric that characterizes the outlierness of data samples. In this work, we\nintroduce a new approximation of LID called K-LID that uses kernel distance in\nthe LID calculation, which allows LID to be calculated in high dimensional\ntransformed spaces. We introduce a weighted SVM against such attacks using\nK-LID as a distinguishing characteristic that de-emphasizes the effect of\nsuspicious data samples on the SVM decision boundary. Each sample is weighted\non how likely its K-LID value is from the benign K-LID distribution rather than\nthe attacked K-LID distribution. We then demonstrate how the proposed defense\ncan be applied to a distributed SVM framework through a case study on an\nSDR-based surveillance system. Experiments with benchmark data sets show that\nthe proposed defense reduces classification error rates substantially (10% on\naverage).\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:11:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Weerasinghe", "Sandamal", ""], ["Alpcan", "Tansu", ""], ["Erfani", "Sarah M.", ""], ["Leckie", "Christopher", ""]]}, {"id": "2008.09289", "submitter": "Nathaniel Bloomfield", "authors": "Nathaniel J. Bloomfield and Susan Wei and Bartholomew Woodham and\n  Peter Wilkinson and Andrew Robinson", "title": "Automating the assessment of biofouling in images using expert agreement\n  as a gold standard", "comments": "12 pages", "journal-ref": "Sci Rep 11, 2739 (2021)", "doi": "10.1038/s41598-021-81011-2", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biofouling is the accumulation of organisms on surfaces immersed in water. It\nis of particular concern to the international shipping industry because it\nincreases fuel costs and presents a biosecurity risk by providing a pathway for\nnon-indigenous marine species to establish in new areas. There is growing\ninterest within jurisdictions to strengthen biofouling risk-management\nregulations, but it is expensive to conduct in-water inspections and assess the\ncollected data to determine the biofouling state of vessel hulls. Machine\nlearning is well suited to tackle the latter challenge, and here we apply deep\nlearning to automate the classification of images from in-water inspections to\nidentify the presence and severity of fouling. We combined several datasets to\nobtain over 10,000 images collected from in-water surveys which were annotated\nby a group biofouling experts. We compared the annotations from three experts\non a 120-sample subset of these images, and found that they showed 89%\nagreement (95% CI: 87-92%). Subsequent labelling of the whole dataset by one of\nthese experts achieved similar levels of agreement with this group of experts,\nwhich we defined as performing at most 5% worse (p=0.009-0.054). Using these\nexpert labels, we were able to train a deep learning model that also agreed\nsimilarly with the group of experts (p=0.001-0.014), demonstrating that\nautomated analysis of biofouling in images is feasible and effective using this\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:30:45 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 03:59:09 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bloomfield", "Nathaniel J.", ""], ["Wei", "Susan", ""], ["Woodham", "Bartholomew", ""], ["Wilkinson", "Peter", ""], ["Robinson", "Andrew", ""]]}, {"id": "2008.09293", "submitter": "Kishor Jothimurugan", "authors": "Kishor Jothimurugan, Rajeev Alur and Osbert Bastani", "title": "A Composable Specification Language for Reinforcement Learning Tasks", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems, pp.\n  13041-13051. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach for learning control policies\nfor robot tasks. However, specifying complex tasks (e.g., with multiple\nobjectives and safety constraints) can be challenging, since the user must\ndesign a reward function that encodes the entire task. Furthermore, the user\noften needs to manually shape the reward to ensure convergence of the learning\nalgorithm. We propose a language for specifying complex control tasks, along\nwith an algorithm that compiles specifications in our language into a reward\nfunction and automatically performs reward shaping. We implement our approach\nin a tool called SPECTRL, and show that it outperforms several state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:40:57 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:02:43 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Jothimurugan", "Kishor", ""], ["Alur", "Rajeev", ""], ["Bastani", "Osbert", ""]]}, {"id": "2008.09301", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Jane. X. Wang, Jovana Mitrovic, Martin Szummer,\n  Danilo J. Rezende", "title": "Amortized learning of neural causal representations", "comments": "ICLR 2020 causal learning for decision making workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal models can compactly and efficiently encode the data-generating\nprocess under all interventions and hence may generalize better under changes\nin distribution. These models are often represented as Bayesian networks and\nlearning them scales poorly with the number of variables. Moreover, these\napproaches cannot leverage previously learned knowledge to help with learning\nnew causal models. In order to tackle these challenges, we represent a novel\nalgorithm called \\textit{causal relational networks} (CRN) for learning causal\nmodels using neural networks. The CRN represent causal models using continuous\nrepresentations and hence could scale much better with the number of variables.\nThese models also take in previously learned information to facilitate learning\nof new causal models. Finally, we propose a decoding-based metric to evaluate\ncausal models with continuous representations. We test our method on synthetic\ndata achieving high accuracy and quick adaptation to previously unseen causal\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 04:35:06 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Wang", "Jane. X.", ""], ["Mitrovic", "Jovana", ""], ["Szummer", "Martin", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "2008.09312", "submitter": "Shiliang Zuo", "authors": "Shiliang Zuo", "title": "Near Optimal Adversarial Attack on UCB Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic multi-arm bandit problem where rewards are subject\nto adversarial corruption. We propose a novel attack strategy that manipulates\na UCB principle into pulling some non-optimal target arm $T - o(T)$ times with\na cumulative cost that scales as $\\sqrt{\\log T}$, where $T$ is the number of\nrounds. We also prove the first lower bound on the cumulative attack cost. Our\nlower bound matches our upper bound up to $\\log \\log T$ factors, showing our\nattack to be near optimal.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:23:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zuo", "Shiliang", ""]]}, {"id": "2008.09316", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Yong Ge, Li Li, Xia Hu, Rui Chen, Soo-Hyun Choi", "title": "Explainable Recommender Systems via Resolving Learning Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play a fundamental role in web applications in filtering\nmassive information and matching user interests. While many efforts have been\ndevoted to developing more effective models in various scenarios, the\nexploration on the explainability of recommender systems is running behind.\nExplanations could help improve user experience and discover system defects. In\nthis paper, after formally introducing the elements that are related to model\nexplainability, we propose a novel explainable recommendation model through\nimproving the transparency of the representation learning process.\nSpecifically, to overcome the representation entangling problem in traditional\nmodels, we revise traditional graph convolution to discriminate information\nfrom different layers. Also, each representation vector is factorized into\nseveral segments, where each segment relates to one semantic aspect in data.\nDifferent from previous work, in our model, factor discovery and representation\nlearning are simultaneously conducted, and we are able to handle extra\nattribute information and knowledge. In this way, the proposed model can learn\ninterpretable and meaningful representations for users and items. Unlike\ntraditional methods that need to make a trade-off between explainability and\neffectiveness, the performance of our proposed explainable model is not\nnegatively affected after considering explainability. Finally, comprehensive\nexperiments are conducted to validate the performance of our model as well as\nexplanation faithfulness.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:30:48 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Liu", "Ninghao", ""], ["Ge", "Yong", ""], ["Li", "Li", ""], ["Hu", "Xia", ""], ["Chen", "Rui", ""], ["Choi", "Soo-Hyun", ""]]}, {"id": "2008.09323", "submitter": "Frank Lin", "authors": "Frank Po-Chen Lin, Christopher G. Brinton, Nicol\\`o Michelusi", "title": "Federated Learning with Communication Delay in Edge Networks", "comments": "Accepted for publication at IEEE Global Communications Conference\n  (Globecom 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has received significant attention as a potential solution\nfor distributing machine learning (ML) model training through edge networks.\nThis work addresses an important consideration of federated learning at the\nnetwork edge: communication delays between the edge nodes and the aggregator. A\ntechnique called FedDelAvg (federated delayed averaging) is developed, which\ngeneralizes the standard federated averaging algorithm to incorporate a\nweighting between the current local model and the delayed global model received\nat each device during the synchronization step. Through theoretical analysis,\nan upper bound is derived on the global model loss achieved by FedDelAvg, which\nreveals a strong dependency of learning performance on the values of the\nweighting and learning rate. Experimental results on a popular ML task indicate\nsignificant improvements in terms of convergence speed when optimizing the\nweighting scheme to account for delays.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 06:21:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Lin", "Frank Po-Chen", ""], ["Brinton", "Christopher G.", ""], ["Michelusi", "Nicol\u00f2", ""]]}, {"id": "2008.09340", "submitter": "Sasho Nedelkoski", "authors": "Sasho Nedelkoski, Jasmin Bogatinovski, Alexander Acker, Jorge Cardoso,\n  Odej Kao", "title": "Self-Attentive Classification-Based Anomaly Detection in Unstructured\n  Logs", "comments": "11 pages, 8 figures, Accepted at ICDM 2020: 20th IEEE International\n  Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of anomalies is essential mining task for the security and\nreliability in computer systems. Logs are a common and major data source for\nanomaly detection methods in almost every computer system. They collect a range\nof significant events describing the runtime system status. Recent studies have\nfocused predominantly on one-class deep learning methods on predefined\nnon-learnable numerical log representations. The main limitation is that these\nmodels are not able to learn log representations describing the semantic\ndifferences between normal and anomaly logs, leading to a poor generalization\nof unseen logs. We propose Logsy, a classification-based method to learn log\nrepresentations in a way to distinguish between normal data from the system of\ninterest and anomaly samples from auxiliary log datasets, easily accessible via\nthe internet. The idea behind such an approach to anomaly detection is that the\nauxiliary dataset is sufficiently informative to enhance the representation of\nthe normal data, yet diverse to regularize against overfitting and improve\ngeneralization. We propose an attention-based encoder model with a new\nhyperspherical loss function. This enables learning compact log representations\ncapturing the intrinsic differences between normal and anomaly logs.\nEmpirically, we show an average improvement of 0.25 in the F1 score, compared\nto the previous methods. To investigate the properties of Logsy, we perform\nadditional experiments including evaluation of the effect of the auxiliary data\nsize, the influence of expert knowledge, and the quality of the learned log\nrepresentations. The results show that the learned representation boost the\nperformance of the previous methods such as PCA with a relative improvement of\n28.2%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:26:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Nedelkoski", "Sasho", ""], ["Bogatinovski", "Jasmin", ""], ["Acker", "Alexander", ""], ["Cardoso", "Jorge", ""], ["Kao", "Odej", ""]]}, {"id": "2008.09377", "submitter": "Binyamin Manela", "authors": "Binyamin Manela, Armin Biess", "title": "Curriculum Learning with Hindsight Experience Replay for Sequential\n  Object Manipulation Tasks", "comments": "arXiv admin note: text overlap with arXiv:2001.03877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning complex tasks from scratch is challenging and often impossible for\nhumans as well as for artificial agents. A curriculum can be used instead,\nwhich decomposes a complex task (target task) into a sequence of source tasks\n(the curriculum). Each source task is a simplified version of the next source\ntask with increasing complexity. Learning then occurs gradually by training on\neach source task while using knowledge from the curriculum's prior source\ntasks. In this study, we present a new algorithm that combines curriculum\nlearning with Hindsight Experience Replay (HER), to learn sequential object\nmanipulation tasks for multiple goals and sparse feedback. The algorithm\nexploits the recurrent structure inherent in many object manipulation tasks and\nimplements the entire learning process in the original simulation without\nadjusting it to each source task. We have tested our algorithm on three\nchallenging throwing tasks and show vast improvements compared to vanilla-HER.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:59:28 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Manela", "Binyamin", ""], ["Biess", "Armin", ""]]}, {"id": "2008.09381", "submitter": "Julia Lust", "authors": "Julia Lust and Alexandru Paul Condurache", "title": "A Survey on Assessing the Generalization Envelope of Deep Neural\n  Networks at Inference Time for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) achieve state-of-the-art performance on numerous\napplications. However, it is difficult to tell beforehand if a DNN receiving an\ninput will deliver the correct output since their decision criteria are usually\nnontransparent. A DNN delivers the correct output if the input is within the\narea enclosed by its generalization envelope. In this case, the information\ncontained in the input sample is processed reasonably by the network. It is of\nlarge practical importance to assess at inference time if a DNN generalizes\ncorrectly. Currently, the approaches to achieve this goal are investigated in\ndifferent problem set-ups rather independently from one another, leading to\nthree main research and literature fields: predictive uncertainty,\nout-of-distribution detection and adversarial example detection. This survey\nconnects the three fields within the larger framework of investigating the\ngeneralization performance of machine learning methods and in particular DNNs.\nWe underline the common ground, point at the most promising approaches and give\na structured overview of the methods that provide at inference time means to\nestablish if the current input is within the generalization envelope of a DNN.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:12:52 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 19:54:19 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lust", "Julia", ""], ["Condurache", "Alexandru Paul", ""]]}, {"id": "2008.09384", "submitter": "Florian Schaefer", "authors": "Florian Schaefer, Jan-Hendrik Menke, Martin Braun", "title": "Evaluating Machine Learning Models for the Fast Identification of\n  Contingency Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast approximations of power flow results are beneficial in power system\nplanning and live operation. In planning, millions of power flow calculations\nare necessary if multiple years, different control strategies or contingency\npolicies are to be considered. In live operation, grid operators must assess if\ngrid states comply with contingency requirements in a short time. In this\npaper, we compare regression and classification methods to either predict\nmulti-variable results, e.g. bus voltage magnitudes and line loadings, or\nbinary classifications of time steps to identify critical loading situations.\nWe test the methods on three realistic power systems based on time series in 15\nmin and 5 min resolution of one year. We compare different machine learning\nmodels, such as multilayer perceptrons (MLPs), decision trees, k-nearest\nneighbours, gradient boosting, and evaluate the required training time and\nprediction times as well as the prediction errors. We additionally determine\nthe amount of training data needed for each method and show results, including\nthe approximation of untrained curtailment of generation. Regarding the\ncompared methods, we identified the MLPs as most suitable for the task. The\nMLP-based models can predict critical situations with an accuracy of 97-98 %\nand a very low number of false negative predictions of 0.0-0.64 %.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:24:57 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Schaefer", "Florian", ""], ["Menke", "Jan-Hendrik", ""], ["Braun", "Martin", ""]]}, {"id": "2008.09396", "submitter": "Uri Shaham", "authors": "Uri Shaham and Omer Levy", "title": "Neural Machine Translation without Embeddings", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP models operate over sequences of subword tokens produced by\nhand-crafted tokenization rules and heuristic subword induction algorithms. A\nsimple universal alternative is to represent every computerized text as a\nsequence of bytes via UTF-8, obviating the need for an embedding layer since\nthere are fewer token types (256) than dimensions. Surprisingly, replacing the\nubiquitous embedding layer with one-hot representations of each byte does not\nhurt performance; experiments on byte-to-byte machine translation from English\nto 10 different languages show a consistent improvement in BLEU, rivaling\ncharacter-level and even standard subword-level models. A deeper investigation\nreveals that the combination of embeddingless models with decoder-input dropout\namounts to token dropout, which benefits byte-to-byte models in particular.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:54:11 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 13:33:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Shaham", "Uri", ""], ["Levy", "Omer", ""]]}, {"id": "2008.09413", "submitter": "Yiming Li", "authors": "Yiming Li, Jiawang Bai, Jiawei Li, Xue Yang, Yong Jiang, Shu-Tao Xia", "title": "Rectified Decision Trees: Exploring the Landscape of Interpretable and\n  Effective Machine Learning", "comments": "9 pages. The first two authors contribute equally to this work. arXiv\n  admin note: text overlap with arXiv:1903.05965", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and effectiveness are two essential and indispensable\nrequirements for adopting machine learning methods in reality. In this paper,\nwe propose a knowledge distillation based decision trees extension, dubbed\nrectified decision trees (ReDT), to explore the possibility of fulfilling those\nrequirements simultaneously. Specifically, we extend the splitting criteria and\nthe ending condition of the standard decision trees, which allows training with\nsoft labels while preserving the deterministic splitting paths. We then train\nthe ReDT based on the soft label distilled from a well-trained teacher model\nthrough a novel jackknife-based method. Accordingly, ReDT preserves the\nexcellent interpretable nature of the decision trees while having a relatively\ngood performance. The effectiveness of adopting soft labels instead of hard\nones is also analyzed empirically and theoretically. Surprisingly, experiments\nindicate that the introduction of soft labels also reduces the model size\ncompared with the standard decision trees from the aspect of the total nodes\nand rules, which is an unexpected gift from the `dark knowledge' distilled from\nthe teacher model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:45:25 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Li", "Yiming", ""], ["Bai", "Jiawang", ""], ["Li", "Jiawei", ""], ["Yang", "Xue", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2008.09416", "submitter": "Alexander Neergaard Olesen", "authors": "Alexander Neergaard Olesen, Poul Jennum, Emmanuel Mignot, Helge B D\n  Sorensen", "title": "Automatic sleep stage classification with deep residual networks in a\n  mixed-cohort setting", "comments": "Author's original version. This article has been accepted for\n  publication in SLEEP published by Oxford University Press", "journal-ref": null, "doi": "10.1093/sleep/zsaa161", "report-no": null, "categories": "cs.CV eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Study Objectives: Sleep stage scoring is performed manually by sleep experts\nand is prone to subjective interpretation of scoring rules with low intra- and\ninterscorer reliability. Many automatic systems rely on few small-scale\ndatabases for developing models, and generalizability to new datasets is thus\nunknown. We investigated a novel deep neural network to assess the\ngeneralizability of several large-scale cohorts.\n  Methods: A deep neural network model was developed using 15684\npolysomnography studies from five different cohorts. We applied four different\nscenarios: 1) impact of varying time-scales in the model; 2) performance of a\nsingle cohort on other cohorts of smaller, greater or equal size relative to\nthe performance of other cohorts on a single cohort; 3) varying the fraction of\nmixed-cohort training data compared to using single-origin data; and 4)\ncomparing models trained on combinations of data from 2, 3, and 4 cohorts.\n  Results: Overall classification accuracy improved with increasing fractions\nof training data (0.25$\\%$: 0.782 $\\pm$ 0.097, 95$\\%$ CI [0.777-0.787];\n100$\\%$: 0.869 $\\pm$ 0.064, 95$\\%$ CI [0.864-0.872]), and with increasing\nnumber of data sources (2: 0.788 $\\pm$ 0.102, 95$\\%$ CI [0.787-0.790]; 3: 0.808\n$\\pm$ 0.092, 95$\\%$ CI [0.807-0.810]; 4: 0.821 $\\pm$ 0.085, 95$\\%$ CI\n[0.819-0.823]). Different cohorts show varying levels of generalization to\nother cohorts.\n  Conclusions: Automatic sleep stage scoring systems based on deep learning\nalgorithms should consider as much data as possible from as many sources\navailable to ensure proper generalization. Public datasets for benchmarking\nshould be made available for future research.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:48:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Olesen", "Alexander Neergaard", ""], ["Jennum", "Poul", ""], ["Mignot", "Emmanuel", ""], ["Sorensen", "Helge B D", ""]]}, {"id": "2008.09450", "submitter": "MyungJae Shin", "authors": "MyungJae Shin, Joongheon Kim", "title": "Adversarial Imitation Learning via Random Search", "comments": "Accepted at IJCNN 2019. arXiv admin note: text overlap with\n  arXiv:1905.05637", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852307", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing agents that can perform challenging complex tasks is the goal of\nreinforcement learning. The model-free reinforcement learning has been\nconsidered as a feasible solution. However, the state of the art research has\nbeen to develop increasingly complicated techniques. This increasing complexity\nmakes the reconstruction difficult. Furthermore, the problem of reward\ndependency is still exists. As a result, research on imitation learning, which\nlearns policy from a demonstration of experts, has begun to attract attention.\nImitation learning directly learns policy based on data on the behavior of the\nexperts without the explicit reward signal provided by the environment.\nHowever, imitation learning tries to optimize policies based on deep\nreinforcement learning such as trust region policy optimization. As a result,\ndeep reinforcement learning based imitation learning also poses a crisis of\nreproducibility. The issue of complex model-free model has received\nconsiderable critical attention. A derivative-free optimization based\nreinforcement learning and the simplification on policies obtain competitive\nperformance on the dynamic complex tasks. The simplified policies and\nderivative free methods make algorithm be simple. The reconfiguration of\nresearch demo becomes easy. In this paper, we propose an imitation learning\nmethod that takes advantage of the derivative-free optimization with simple\nlinear policies. The proposed method performs simple random search in the\nparameter space of policies and shows computational efficiency. Experiments in\nthis paper show that the proposed model, without a direct reward signal from\nthe environment, obtains competitive performance on the MuJoCo locomotion\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:40:03 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shin", "MyungJae", ""], ["Kim", "Joongheon", ""]]}, {"id": "2008.09466", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Prathosh A.P", "title": "RespVAD: Voice Activity Detection via Video-Extracted Respiration\n  Patterns", "comments": "Accepted in IEEE Sensor Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Activity Detection (VAD) refers to the task of identification of\nregions of human speech in digital signals such as audio and video. While VAD\nis a necessary first step in many speech processing systems, it poses\nchallenges when there are high levels of ambient noise during the audio\nrecording. To improve the performance of VAD in such conditions, several\nmethods utilizing the visual information extracted from the region surrounding\nthe mouth/lip region of the speakers' video recording have been proposed. Even\nthough these provide advantages over audio-only methods, they depend on\nfaithful extraction of lip/mouth regions. Motivated by these, a new paradigm\nfor VAD based on the fact that respiration forms the primary source of energy\nfor speech production is proposed. Specifically, an audio-independent VAD\ntechnique using the respiration pattern extracted from the speakers' video is\ndeveloped. The Respiration Pattern is first extracted from the video focusing\non the abdominal-thoracic region of a speaker using an optical flow based\nmethod. Subsequently, voice activity is detected from the respiration pattern\nsignal using neural sequence-to-sequence prediction models. The efficacy of the\nproposed method is demonstrated through experiments on a challenging dataset\nrecorded in real acoustic environments and compared with four previous methods\nbased on audio and visual cues.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:26:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["P", "Prathosh A.", ""]]}, {"id": "2008.09469", "submitter": "Qi Wang", "authors": "Qi Wang, Herke van Hoof", "title": "Doubly Stochastic Variational Inference for Neural Processes with\n  Hierarchical Latent Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural processes (NPs) constitute a family of variational approximate models\nfor stochastic processes with promising properties in computational efficiency\nand uncertainty quantification. These processes use neural networks with latent\nvariable inputs to induce predictive distributions. However, the expressiveness\nof vanilla NPs is limited as they only use a global latent variable, while\ntarget specific local variation may be crucial sometimes. To address this\nchallenge, we investigate NPs systematically and present a new variant of NP\nmodel that we call Doubly Stochastic Variational Neural Process (DSVNP). This\nmodel combines the global latent variable and local latent variables for\nprediction. We evaluate this model in several experiments, and our results\ndemonstrate competitive prediction performance in multi-output regression and\nuncertainty estimation in classification.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:32:12 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 23:05:15 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qi", ""], ["van Hoof", "Herke", ""]]}, {"id": "2008.09470", "submitter": "Dimo Angelov", "authors": "Dimo Angelov", "title": "Top2Vec: Distributed Representations of Topics", "comments": "Implementation available at https://github.com/ddangelov/Top2Vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling is used for discovering latent semantic structure, usually\nreferred to as topics, in a large collection of documents. The most widely used\nmethods are Latent Dirichlet Allocation and Probabilistic Latent Semantic\nAnalysis. Despite their popularity they have several weaknesses. In order to\nachieve optimal results they often require the number of topics to be known,\ncustom stop-word lists, stemming, and lemmatization. Additionally these methods\nrely on bag-of-words representation of documents which ignore the ordering and\nsemantics of words. Distributed representations of documents and words have\ngained popularity due to their ability to capture semantics of words and\ndocuments. We present $\\texttt{top2vec}$, which leverages joint document and\nword semantic embedding to find $\\textit{topic vectors}$. This model does not\nrequire stop-word lists, stemming or lemmatization, and it automatically finds\nthe number of topics. The resulting topic vectors are jointly embedded with the\ndocument and word vectors with distance between them representing semantic\nsimilarity. Our experiments demonstrate that $\\texttt{top2vec}$ finds topics\nwhich are significantly more informative and representative of the corpus\ntrained on than probabilistic generative models.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:58:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Angelov", "Dimo", ""]]}, {"id": "2008.09477", "submitter": "Pietro Barbiero", "authors": "Pietro Barbiero, Gabriele Ciravegna, Vincenzo Randazzo, Giansalvo\n  Cirrincione", "title": "Topological Gradient-based Competitive Learning", "comments": "12 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological learning is a wide research area aiming at uncovering the mutual\nspatial relationships between the elements of a set. Some of the most common\nand oldest approaches involve the use of unsupervised competitive neural\nnetworks. However, these methods are not based on gradient optimization which\nhas been proven to provide striking results in feature extraction also in\nunsupervised learning. Unfortunately, by focusing mostly on algorithmic\nefficiency and accuracy, deep clustering techniques are composed of overly\ncomplex feature extractors, while using trivial algorithms in their top layer.\nThe aim of this work is to present a novel comprehensive theory aspiring at\nbridging competitive learning with gradient-based learning, thus allowing the\nuse of extremely powerful deep neural networks for feature extraction and\nprojection combined with the remarkable flexibility and expressiveness of\ncompetitive learning. In this paper we fully demonstrate the theoretical\nequivalence of two novel gradient-based competitive layers. Preliminary\nexperiments show how the dual approach, trained on the transpose of the input\nmatrix i.e. $X^T$, lead to faster convergence rate and higher training accuracy\nboth in low and high-dimensional scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:44:38 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Barbiero", "Pietro", ""], ["Ciravegna", "Gabriele", ""], ["Randazzo", "Vincenzo", ""], ["Cirrincione", "Giansalvo", ""]]}, {"id": "2008.09488", "submitter": "Hao Luo", "authors": "Hao Luo and Li Liu", "title": "Counterfactual-based minority oversampling for imbalanced classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge of oversampling in imbalanced classification is that the\ngeneration of new minority samples often neglects the usage of majority\nclasses, resulting in most new minority sampling spreading the whole minority\nspace. In view of this, we present a new oversampling framework based on the\ncounterfactual theory. Our framework introduces a counterfactual objective by\nleveraging the rich inherent information of majority classes and explicitly\nperturbing majority samples to generate new samples in the territory of\nminority space. It can be analytically shown that the new minority samples\nsatisfy the minimum inversion, and therefore most of them locate near the\ndecision boundary. Empirical evaluations on benchmark datasets suggest that our\napproach significantly outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:13:15 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 13:16:47 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Luo", "Hao", ""], ["Liu", "Li", ""]]}, {"id": "2008.09490", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Corinna Cortes, Yishay Mansour, Mehryar Mohri", "title": "Beyond Individual and Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new data-driven model of fairness that, unlike existing static\ndefinitions of individual or group fairness is guided by the unfairness\ncomplaints received by the system. Our model supports multiple fairness\ncriteria and takes into account their potential incompatibilities. We consider\nboth a stochastic and an adversarial setting of our model. In the stochastic\nsetting, we show that our framework can be naturally cast as a Markov Decision\nProcess with stochastic losses, for which we give efficient vanishing regret\nalgorithmic solutions. In the adversarial setting, we design efficient\nalgorithms with competitive ratio guarantees. We also report the results of\nexperiments with our algorithms and the stochastic framework on artificial\ndatasets, to demonstrate their effectiveness empirically.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:14:44 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Cortes", "Corinna", ""], ["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""]]}, {"id": "2008.09498", "submitter": "Alexis Derumigny", "authors": "Alexis Derumigny, Jean-David Fermanian and Aleksey Min", "title": "Testing for equality between conditional copulas given discretized\n  conditioning events", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several procedures have been recently proposed to test the simplifying\nassumption for conditional copulas. Instead of considering pointwise\nconditioning events, we study the constancy of the conditional dependence\nstructure when some covariates belong to general borelian conditioning subsets.\nSeveral test statistics based on the equality of conditional Kendall's tau are\nintroduced, and we derive their asymptotic distributions under the null. When\nsuch conditioning events are not fixed ex ante, we propose a data-driven\nprocedure to recursively build such relevant subsets. It is based on decision\ntrees that maximize the differences between the conditional Kendall's taus\ncorresponding to the leaves of the trees. The performances of such tests are\nillustrated in a simulation experiment. Moreover, a study of the conditional\ndependence between financial stock returns is managed, given some clustering of\ntheir past values. The last application deals with the conditional dependence\nbetween coverage amounts in an insurance dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:26:05 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Derumigny", "Alexis", ""], ["Fermanian", "Jean-David", ""], ["Min", "Aleksey", ""]]}, {"id": "2008.09514", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Weizhi Ma, Jiaxin Mao, Min Zhang, Yongfeng\n  Zhang", "title": "Neural Logic Reasoning", "comments": "Accepted to ACM CIKM 2020. arXiv admin note: substantial text overlap\n  with arXiv:1910.08629", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of cognitive reasoning. However, the concrete ability of\nreasoning is critical to many theoretical and practical problems. On the other\nhand, traditional symbolic reasoning methods do well in making logical\ninference, but they are mostly hard rule-based reasoning, which limits their\ngeneralization ability to different tasks since difference tasks may require\ndifferent rules. Both reasoning and generalization ability are important for\nprediction tasks such as recommender systems, where reasoning provides strong\nconnection between user history and target items for accurate prediction, and\ngeneralization helps the model to draw a robust user portrait over noisy\ninputs.\n  In this paper, we propose Logic-Integrated Neural Network (LINN) to integrate\nthe power of deep learning and logic reasoning. LINN is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations such as AND, OR, NOT as neural\nmodules, and conducts propositional logical reasoning through the network for\ninference. Experiments on theoretical task show that LINN achieves significant\nperformance on solving logical equations and variables. Furthermore, we test\nour approach on the practical task of recommendation by formulating the task\ninto a logical inference problem. Experiments show that LINN significantly\noutperforms state-of-the-art recommendation models in Top-K recommendation,\nwhich verifies the potential of LINN in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:53:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Ma", "Weizhi", ""], ["Mao", "Jiaxin", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2008.09524", "submitter": "Tim De Ryck", "authors": "Tim De Ryck, Maarten De Vos, Alexander Bertrand", "title": "Change Point Detection in Time Series Data using Autoencoders with a\n  Time-Invariant Representation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3087031", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change point detection (CPD) aims to locate abrupt property changes in time\nseries data. Recent CPD methods demonstrated the potential of using deep\nlearning techniques, but often lack the ability to identify more subtle changes\nin the autocorrelation statistics of the signal and suffer from a high false\nalarm rate. To address these issues, we employ an autoencoder-based methodology\nwith a novel loss function, through which the used autoencoders learn a\npartially time-invariant representation that is tailored for CPD. The result is\na flexible method that allows the user to indicate whether change points should\nbe sought in the time domain, frequency domain or both. Detectable change\npoints include abrupt changes in the slope, mean, variance, autocorrelation\nfunction and frequency spectrum. We demonstrate that our proposed method is\nconsistently highly competitive or superior to baseline methods on diverse\nsimulated and real-life benchmark data sets. Finally, we mitigate the issue of\nfalse detection alarms through the use of a postprocessing procedure that\ncombines a matched filter and a newly proposed change point score. We show that\nthis combination drastically improves the performance of our method as well as\nall baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:03:21 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 11:25:07 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["De Ryck", "Tim", ""], ["De Vos", "Maarten", ""], ["Bertrand", "Alexander", ""]]}, {"id": "2008.09566", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth and Franz Pernkopf", "title": "Differentiable TAN Structure Learning for Bayesian Network Classifiers", "comments": "Accepted at PGM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of Bayesian networks is a difficult combinatorial\noptimization problem. In this paper, we consider learning of tree-augmented\nnaive Bayes (TAN) structures for Bayesian network classifiers with discrete\ninput features. Instead of performing a combinatorial optimization over the\nspace of possible graph structures, the proposed method learns a distribution\nover graph structures. After training, we select the most probable structure of\nthis distribution. This allows for a joint training of the Bayesian network\nparameters along with its TAN structure using gradient-based optimization. The\nproposed method is agnostic to the specific loss and only requires that it is\ndifferentiable. We perform extensive experiments using a hybrid\ngenerative-discriminative loss based on the discriminative probabilistic\nmargin. Our method consistently outperforms random TAN structures and Chow-Liu\nTAN structures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:22:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Roth", "Wolfgang", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2008.09567", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak", "title": "TAnoGAN: Time Series Anomaly Detection with Generative Adversarial\n  Networks", "comments": "Made some minor changes. This is the accepted version of the paper at\n  AusDM'20", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI47803.2020.9308512", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in time series data is a significant problem faced in many\napplication areas such as manufacturing, medical imaging and cyber-security.\nRecently, Generative Adversarial Networks (GAN) have gained attention for\ngeneration and anomaly detection in image domain. In this paper, we propose a\nnovel GAN-based unsupervised method called TAnoGan for detecting anomalies in\ntime series when a small number of data points are available. We evaluate\nTAnoGan with 46 real-world time series datasets that cover a variety of\ndomains. Extensive experimental results show that TAnoGan performs better than\ntraditional and neural network models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:24:51 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 01:50:33 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.09570", "submitter": "Punit Rathore", "authors": "Punit Rathore, James C. Bezdek, Paolo Santi, Carlo Ratti", "title": "ConiVAT: Cluster Tendency Assessment and Clustering with Partial\n  Background Knowledge", "comments": "Submitted to IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VAT method is a visual technique for determining the potential cluster\nstructure and the possible number of clusters in numerical data. Its improved\nversion, iVAT, uses a path-based distance transform to improve the\neffectiveness of VAT for \"tough\" cases. Both VAT and iVAT have also been used\nin conjunction with a single-linkage(SL) hierarchical clustering algorithm.\nHowever, they are sensitive to noise and bridge points between clusters in the\ndataset, and consequently, the corresponding VAT/iVAT images are often\nin-conclusive for such cases. In this paper, we propose a constraint-based\nversion of iVAT, which we call ConiVAT, that makes use of background knowledge\nin the form of constraints, to improve VAT/iVAT for challenging and complex\ndatasets. ConiVAT uses the input constraints to learn the underlying similarity\nmetric and builds a minimum transitive dissimilarity matrix, before applying\nVAT to it. We demonstrate ConiVAT approach to visual assessment and single\nlinkage clustering on nine datasets to show that, it improves the quality of\niVAT images for complex datasets, and it also overcomes the limitation of SL\nclustering with VAT/iVAT due to \"noisy\" bridges between clusters. Extensive\nexperiment results on nine datasets suggest that ConiVAT outperforms the other\nthree semi-supervised clustering algorithms in terms of improved clustering\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:30:31 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 17:21:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rathore", "Punit", ""], ["Bezdek", "James C.", ""], ["Santi", "Paolo", ""], ["Ratti", "Carlo", ""]]}, {"id": "2008.09579", "submitter": "Alden Bradford", "authors": "Alden Bradford, Tarun Yellamraju, and Mireille Boutin", "title": "Clustering small datasets in high-dimension by random projection", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets in high-dimension do not typically form clusters in their original\nspace; the issue is worse when the number of points in the dataset is small. We\npropose a low-computation method to find statistically significant clustering\nstructures in a small dataset. The method proceeds by projecting the data on a\nrandom line and seeking binary clusterings in the resulting one-dimensional\ndata. Non-linear separations are obtained by extending the feature space using\nmonomials of higher degrees in the original features. The statistical validity\nof the clustering structures obtained is tested in the projected\none-dimensional space, thus bypassing the challenge of statistical validation\nin high-dimension. Projecting on a random line is an extreme dimension\nreduction technique that has previously been used successfully as part of a\nhierarchical clustering method for high-dimensional data. Our experiments show\nthat with this simplified framework, statistically significant clustering\nstructures can be found with as few as 100-200 points, depending on the\ndataset. The different structures uncovered are found to persist as more points\nare added to the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:49:37 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Bradford", "Alden", ""], ["Yellamraju", "Tarun", ""], ["Boutin", "Mireille", ""]]}, {"id": "2008.09589", "submitter": "Amir Shahmoradi", "authors": "Amir Shahmoradi, Fatemeh Bagheri", "title": "ParaDRAM: A Cross-Language Toolbox for Parallel High-Performance\n  Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE astro-ph.IM physics.data-an stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ParaDRAM, a high-performance Parallel Delayed-Rejection Adaptive\nMetropolis Markov Chain Monte Carlo software for optimization, sampling, and\nintegration of mathematical objective functions encountered in scientific\ninference. ParaDRAM is currently accessible from several popular programming\nlanguages including C/C++, Fortran, MATLAB, Python and is part of the ParaMonte\nopen-source project with the following principal design goals: 1. full\nautomation of Monte Carlo simulations, 2. interoperability of the core library\nwith as many programming languages as possible, thus, providing a unified\nApplication Programming Interface and Monte Carlo simulation environment across\nall programming languages, 3. high-performance 4. parallelizability and\nscalability of simulations from personal laptops to supercomputers, 5.\nvirtually zero-dependence on external libraries, 6. fully-deterministic\nreproducibility of simulations, 7. automatic comprehensive reporting and\npost-processing of the simulation results. We present and discuss several novel\ntechniques implemented in ParaDRAM to automatically and dynamically ensure the\ngood-mixing and the diminishing-adaptation of the resulting pseudo-Markov\nchains from ParaDRAM. We also discuss the implementation of an efficient data\nstorage method used in ParaDRAM that reduces the average memory and storage\nrequirements of the algorithm by, a factor of 4 for simple simulation problems,\nto an order of magnitude and more for sampling complex high-dimensional\nmathematical objective functions. Finally, we discuss how the design goals of\nParaDRAM can help users readily and efficiently solve a variety of machine\nlearning and scientific inference problems on a wide range of computing\nplatforms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:29:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shahmoradi", "Amir", ""], ["Bagheri", "Fatemeh", ""]]}, {"id": "2008.09623", "submitter": "Zhengdao Chen", "authors": "Zhengdao Chen, Grant M. Rotskoff, Joan Bruna, Eric Vanden-Eijnden", "title": "A Dynamical Central Limit Theorem for Shallow Neural Networks", "comments": "To appear in Advances in Neural Information Processing Systems 33\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical works have characterized the dynamics of wide shallow\nneural networks trained via gradient descent in an asymptotic mean-field limit\nwhen the width tends towards infinity. At initialization, the random sampling\nof the parameters leads to deviations from the mean-field limit dictated by the\nclassical Central Limit Theorem (CLT). However, since gradient descent induces\ncorrelations among the parameters, it is of interest to analyze how these\nfluctuations evolve. Here, we use a dynamical CLT to prove that the asymptotic\nfluctuations around the mean limit remain bounded in mean square throughout\ntraining. The upper bound is given by a Monte-Carlo resampling error, with a\nvariance that that depends on the 2-norm of the underlying measure, which also\ncontrols the generalization error. This motivates the use of this 2-norm as a\nregularization term during training. Furthermore, if the mean-field dynamics\nconverges to a measure that interpolates the training data, we prove that the\nasymptotic deviation eventually vanishes in the CLT scaling. We also complement\nthese results with numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:00:50 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 16:22:30 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chen", "Zhengdao", ""], ["Rotskoff", "Grant M.", ""], ["Bruna", "Joan", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2008.09624", "submitter": "Mohammad Rasool Izadi", "authors": "Mohammad Rasool Izadi, Yihao Fang, Robert Stevenson, Lizhen Lin", "title": "Optimization of Graph Neural Networks with Natural Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to employ information-geometric tools to optimize a\ngraph neural network architecture such as the graph convolutional networks.\nMore specifically, we develop optimization algorithms for the graph-based\nsemi-supervised learning by employing the natural gradient information in the\noptimization process. This allows us to efficiently exploit the geometry of the\nunderlying statistical model or parameter space for optimization and inference.\nTo the best of our knowledge, this is the first work that has utilized the\nnatural gradient for the optimization of graph neural networks that can be\nextended to other semi-supervised problems. Efficient computations algorithms\nare developed and extensive numerical studies are conducted to demonstrate the\nsuperior performance of our algorithms over existing algorithms such as ADAM\nand SGD.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:00:53 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Izadi", "Mohammad Rasool", ""], ["Fang", "Yihao", ""], ["Stevenson", "Robert", ""], ["Lin", "Lizhen", ""]]}, {"id": "2008.09643", "submitter": "Rachel Luo", "authors": "Rachel Luo, Shengjia Zhao, Jiaming Song, Jonathan Kuck, Stefano Ermon,\n  Silvio Savarese", "title": "Privacy Preserving Recalibration under Domain Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers deployed in high-stakes real-world applications must output\ncalibrated confidence scores, i.e. their predicted probabilities should reflect\nempirical frequencies. Recalibration algorithms can greatly improve a model's\nprobability estimates; however, existing algorithms are not applicable in\nreal-world situations where the test data follows a different distribution from\nthe training data, and privacy preservation is paramount (e.g. protecting\npatient records). We introduce a framework that abstracts out the properties of\nrecalibration problems under differential privacy constraints. This framework\nallows us to adapt existing recalibration algorithms to satisfy differential\nprivacy while remaining effective for domain-shift situations. Guided by our\nframework, we also design a novel recalibration algorithm, accuracy temperature\nscaling, that outperforms prior work on private datasets. In an extensive\nempirical study, we find that our algorithm improves calibration on\ndomain-shift benchmarks under the constraints of differential privacy. On the\n15 highest severity perturbations of the ImageNet-C dataset, our method\nachieves a median ECE of 0.029, over 2x better than the next best recalibration\nmethod and almost 5x better than without recalibration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:43:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Luo", "Rachel", ""], ["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Kuck", "Jonathan", ""], ["Ermon", "Stefano", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.09657", "submitter": "Arnab Bhattacharya", "authors": "Sunil Nishad and Shubhangi Agarwal and Arnab Bhattacharya and Sayan\n  Ranu", "title": "GraphReach: Position-Aware Graph Neural Network using Reachability\n  Estimations", "comments": null, "journal-ref": "IJCAI 2021", "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the existing graph neural networks (GNN) learn node embeddings\nthat encode their local neighborhoods but not their positions. Consequently,\ntwo nodes that are vastly distant but located in similar local neighborhoods\nmap to similar embeddings in those networks. This limitation prevents accurate\nperformance in predictive tasks that rely on position information. In this\npaper,we develop GraphReach, a position-aware inductive GNN that captures the\nglobal positions of nodes through reachability estimations with respect to a\nset of anchor nodes. The anchors are strategically selected so that\nreachability estimations across all the nodes are maximized. We show that this\ncombinatorial anchor selection problem is NP-hard and, consequently, develop a\ngreedy (1-1/e) approximation heuristic. Empirical evaluation against\nstate-of-the-art GNN architectures reveal that GraphReach provides up to 40%\nrelative improvement in accuracy. In addition, it is more robust to adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:30:03 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 11:51:31 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 10:00:36 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Nishad", "Sunil", ""], ["Agarwal", "Shubhangi", ""], ["Bhattacharya", "Arnab", ""], ["Ranu", "Sayan", ""]]}, {"id": "2008.09667", "submitter": "Xiao Li", "authors": "Xiao Li and Weili Wu", "title": "A Blockchain Transaction Graph based Machine Learning Method for Bitcoin\n  Price Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin, as one of the most popular cryptocurrency, is recently attracting\nmuch attention of investors. Bitcoin price prediction task is consequently a\nrising academic topic for providing valuable insights and suggestions. Existing\nbitcoin prediction works mostly base on trivial feature engineering, that\nmanually designs features or factors from multiple areas, including Bticoin\nBlockchain information, finance and social media sentiments. The feature\nengineering not only requires much human effort, but the effectiveness of the\nintuitively designed features can not be guaranteed. In this paper, we aim to\nmining the abundant patterns encoded in bitcoin transactions, and propose\nk-order transaction graph to reveal patterns under different scope. We propose\nthe transaction graph based feature to automatically encode the patterns. A\nnovel prediction method is proposed to accept the features and make price\nprediction, which can take advantage from particular patterns from different\nhistory period. The results of comparison experiments demonstrate that the\nproposed method outperforms the most recent state-of-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:08:17 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Xiao", ""], ["Wu", "Weili", ""]]}, {"id": "2008.09695", "submitter": "Huiqi Deng", "authors": "Huiqi Deng, Na Zou, Mengnan Du, Weifu Chen, Guocan Feng, and Xia Hu", "title": "A Unified Taylor Framework for Revisiting Attribution Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods have been developed to understand the decision-making\nprocess of machine learning models, especially deep neural networks, by\nassigning importance scores to individual features. Existing attribution\nmethods often built upon empirical intuitions and heuristics. There still lacks\na general and theoretical framework that not only can unify these attribution\nmethods, but also theoretically reveal their rationales, fidelity, and\nlimitations. To bridge the gap, in this paper, we propose a Taylor attribution\nframework and reformulate seven mainstream attribution methods into the\nframework. Based on reformulations, we analyze the attribution methods in terms\nof rationale, fidelity, and limitation. Moreover, We establish three principles\nfor a good attribution in the Taylor attribution framework, i.e., low\napproximation error, correct contribution assignment, and unbiased baseline\nselection. Finally, we empirically validate the Taylor reformulations and\nreveal a positive correlation between the attribution performance and the\nnumber of principles followed by the attribution method via benchmarking on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:07:06 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 11:38:08 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 09:00:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Deng", "Huiqi", ""], ["Zou", "Na", ""], ["Du", "Mengnan", ""], ["Chen", "Weifu", ""], ["Feng", "Guocan", ""], ["Hu", "Xia", ""]]}, {"id": "2008.09727", "submitter": "Thien Q. Tran", "authors": "Thien Q. Tran, Jun Sakuma", "title": "Seasonal-adjustment Based Feature Selection Method for Large-scale\n  Search Engine Logs", "comments": "The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD '19)", "journal-ref": null, "doi": "10.1145/3292500.3330766", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engine logs have a great potential in tracking and predicting\noutbreaks of infectious disease. More precisely, one can use the search volume\nof some search terms to predict the infection rate of an infectious disease in\nnearly real-time. However, conducting accurate and stable prediction of\noutbreaks using search engine logs is a challenging task due to the following\ntwo-way instability characteristics of the search logs. First, the search\nvolume of a search term may change irregularly in the short-term, for example,\ndue to environmental factors such as the amount of media or news. Second, the\nsearch volume may also change in the long-term due to the demographic change of\nthe search engine. That is to say, if a model is trained with such search logs\nwith ignoring such characteristic, the resulting prediction would contain\nserious mispredictions when these changes occur.\n  In this work, we proposed a novel feature selection method to overcome this\ninstability problem. In particular, we employ a seasonal-adjustment method that\ndecomposes each time series into three components: seasonal, trend and\nirregular component and build prediction models for each component\nindividually. We also carefully design a feature selection method to select\nproper search terms to predict each component. We conducted comprehensive\nexperiments on ten different kinds of infectious diseases. The experimental\nresults show that the proposed method outperforms all comparative methods in\nprediction accuracy for seven of ten diseases, in both now-casting and\nforecasting setting. Also, the proposed method is more successful in selecting\nsearch terms that are semantically related to target diseases.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 01:35:25 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tran", "Thien Q.", ""], ["Sakuma", "Jun", ""]]}, {"id": "2008.09733", "submitter": "Junyu Cao", "authors": "Junyu Cao, Wei Sun, Zuo-Jun (Max) Shen, Markus Ettl", "title": "Fatigue-aware Bandits for Dependent Click Models", "comments": null, "journal-ref": "AAAI. 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As recommender systems send a massive amount of content to keep users\nengaged, users may experience fatigue which is contributed by 1) an\noverexposure to irrelevant content, 2) boredom from seeing too many similar\nrecommendations. To address this problem, we consider an online learning\nsetting where a platform learns a policy to recommend content that takes user\nfatigue into account. We propose an extension of the Dependent Click Model\n(DCM) to describe users' behavior. We stipulate that for each piece of content,\nits attractiveness to a user depends on its intrinsic relevance and a discount\nfactor which measures how many similar contents have been shown. Users view the\nrecommended content sequentially and click on the ones that they find\nattractive. Users may leave the platform at any time, and the probability of\nexiting is higher when they do not like the content. Based on user's feedback,\nthe platform learns the relevance of the underlying content as well as the\ndiscounting effect due to content fatigue. We refer to this learning task as\n\"fatigue-aware DCM Bandit\" problem. We consider two learning scenarios\ndepending on whether the discounting effect is known. For each scenario, we\npropose a learning algorithm which simultaneously explores and exploits, and\ncharacterize its regret bound.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 02:18:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Cao", "Junyu", "", "Max"], ["Sun", "Wei", "", "Max"], ["Zuo-Jun", "", "", "Max"], ["Shen", "", ""], ["Ettl", "Markus", ""]]}, {"id": "2008.09763", "submitter": "Jiaqing Xie", "authors": "Hongyuan Dong, Jiaqing Xie, Zhi Jing, Dexin Ren", "title": "Variational Autoencoder for Anti-Cancer Drug Response Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is a primary cause of human death, but discovering drugs and tailoring\ncancer therapies are expensive and time-consuming. We seek to facilitate the\ndiscovery of new drugs and treatment strategies for cancer using variational\nautoencoders (VAEs) and multi-layer perceptrons (MLPs) to predict anti-cancer\ndrug responses. Our model takes as input gene expression data of cancer cell\nlines and anti-cancer drug molecular data and encodes these data with our {\\sc\n{GeneVae}} model, which is an ordinary VAE model, and a rectified junction tree\nvariational autoencoder ({\\sc JTVae}) model, respectively. A multi-layer\nperceptron processes these encoded features to produce a final prediction. Our\ntests show our system attains a high average coefficient of determination\n($R^{2} = 0.83$) in predicting drug responses for breast cancer cell lines and\nan average $R^{2} = 0.845$ for pan-cancer cell lines. Additionally, we show\nthat our model can generates effective drug compounds not previously used for\nspecific cancer cell lines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 06:03:22 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 15:00:42 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 12:32:32 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 13:10:25 GMT"}, {"version": "v5", "created": "Sat, 7 Nov 2020 02:10:01 GMT"}, {"version": "v6", "created": "Wed, 25 Nov 2020 04:36:14 GMT"}, {"version": "v7", "created": "Thu, 15 Apr 2021 09:08:43 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Dong", "Hongyuan", ""], ["Xie", "Jiaqing", ""], ["Jing", "Zhi", ""], ["Ren", "Dexin", ""]]}, {"id": "2008.09775", "submitter": "Qiang Liu", "authors": "Zhaocheng Liu and Qiang Liu and Haoli Zhang and Yuntian Chen", "title": "DNN2LR: Interpretation-inspired Feature Crossing for Real-world Tabular\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sake of reliability, it is necessary for models in real-world\napplications to be both powerful and globally interpretable. Simple\nclassifiers, e.g., Logistic Regression (LR), are globally interpretable, but\nnot powerful enough to model complex nonlinear interactions among features in\ntabular data. Meanwhile, Deep Neural Networks (DNNs) have shown great\neffectiveness for modeling tabular data, but is not globally interpretable. In\nthis work, we find local piece-wise interpretations in DNN of a specific\nfeature are usually inconsistent in different samples, which is caused by\nfeature interactions in the hidden layers. Accordingly, we can design an\nautomatic feature crossing method to find feature interactions in DNN, and use\nthem as cross features in LR. We give definition of the interpretation\ninconsistency in DNN, based on which a novel feature crossing method called\nDNN2LR is proposed. Extensive experiments have been conducted on four public\ndatasets and two real-world datasets. The final model, i.e., a LR model\nempowered with cross features, generated by DNN2LR can outperform the complex\nDNN model, as well as several state-of-the-art feature crossing methods. The\nexperimental results strongly verify the effectiveness and efficiency of\nDNN2LR, especially on real-world datasets with large numbers of feature fields.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 08:03:15 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 08:28:48 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 04:55:49 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 10:30:34 GMT"}, {"version": "v5", "created": "Tue, 19 Jan 2021 06:54:36 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Liu", "Zhaocheng", ""], ["Liu", "Qiang", ""], ["Zhang", "Haoli", ""], ["Chen", "Yuntian", ""]]}, {"id": "2008.09848", "submitter": "Vladimir Joukov", "authors": "Vladimir Joukov and Dana Kuli\\'c", "title": "Fast Approximate Multi-output Gaussian Processes", "comments": "10 pages, 9 figures, 3 tables, will be submitted to IEEE Transactions\n  on Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes regression models are an appealing machine learning method\nas they learn expressive non-linear models from exemplar data with minimal\nparameter tuning and estimate both the mean and covariance of unseen points.\nHowever, exponential computational complexity growth with the number of\ntraining samples has been a long standing challenge. During training, one has\nto compute and invert an $N \\times N$ kernel matrix at every iteration.\nRegression requires computation of an $m \\times N$ kernel where $N$ and $m$ are\nthe number of training and test points respectively. In this work we show how\napproximating the covariance kernel using eigenvalues and functions leads to an\napproximate Gaussian process with significant reduction in training and\nregression complexity. Training with the proposed approach requires computing\nonly a $N \\times n$ eigenfunction matrix and a $n \\times n$ inverse where $n$\nis a selected number of eigenvalues. Furthermore, regression now only requires\nan $m \\times n$ matrix. Finally, in a special case the hyperparameter\noptimization is completely independent form the number of training samples. The\nproposed method can regress over multiple outputs, estimate the derivative of\nthe regressor of any order, and learn the correlations between them. The\ncomputational complexity reduction, regression capabilities, and multioutput\ncorrelation learning are demonstrated in simulation examples.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 14:34:45 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Joukov", "Vladimir", ""], ["Kuli\u0107", "Dana", ""]]}, {"id": "2008.09864", "submitter": "Wenbing Huang", "authors": "Wenbing Huang, Yu Rong, Tingyang Xu, Fuchun Sun, Junzhou Huang", "title": "Tackling Over-Smoothing for General Graph Convolutional Networks", "comments": "Submitted to TPAMI, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the depth of GCN, which is expected to permit more expressivity,\nis shown to incur performance detriment especially on node classification. The\nmain cause of this lies in over-smoothing. The over-smoothing issue drives the\noutput of GCN towards a space that contains limited distinguished information\namong nodes, leading to poor expressivity. Several works on refining the\narchitecture of deep GCN have been proposed, but it is still unknown in theory\nwhether or not these refinements are able to relieve over-smoothing. In this\npaper, we first theoretically analyze how general GCNs act with the increase in\ndepth, including generic GCN, GCN with bias, ResGCN, and APPNP. We find that\nall these models are characterized by a universal process: all nodes converging\nto a cuboid. Upon this theorem, we propose DropEdge to alleviate over-smoothing\nby randomly removing a certain number of edges at each training epoch.\nTheoretically, DropEdge either reduces the convergence speed of over-smoothing\nor relieves the information loss caused by dimension collapse. Experimental\nevaluations on simulated dataset have visualized the difference in\nover-smoothing between different GCNs. Moreover, extensive experiments on\nseveral real benchmarks support that DropEdge consistently improves the\nperformance on a variety of both shallow and deep GCNs.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:14:01 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 08:36:13 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 09:19:11 GMT"}, {"version": "v4", "created": "Mon, 29 Mar 2021 07:02:59 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Huang", "Wenbing", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Sun", "Fuchun", ""], ["Huang", "Junzhou", ""]]}, {"id": "2008.09874", "submitter": "Jongwon Kim", "authors": "Jongwon Kim, Sungho Shin, Yeonguk Yu, Junseok Lee, Kyoobin Lee", "title": "Multiple Classification with Split Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy issues were raised in the process of training deep learning in\nmedical, mobility, and other fields. To solve this problem, we present\nprivacy-preserving distributed deep learning method that allow clients to learn\na variety of data without direct exposure. We divided a single deep learning\narchitecture into a common extractor, a cloud model and a local classifier for\nthe distributed learning. First, the common extractor, which is used by local\nclients, extracts secure features from the input data. The secure features also\ntake the role that the cloud model can employ various task and diverse types of\ndata. The feature contain the most important information that helps to proceed\nvarious task. Second, the cloud model including most parts of the whole\ntraining model gets the embedded features from the massive local clients, and\nperforms most of deep learning operations which takes severe computing cost.\nAfter the operations in cloud model finished, outputs of the cloud model send\nback to local clients. Finally, the local classifier determined classification\nresults and delivers the results to local clients. When clients train models,\nour model does not directly expose sensitive information to exterior network.\nDuring the test, the average performance improvement was 2.63% over the\nexisting local training model. However, in a distributed environment, there is\na possibility of inversion attack due to exposed features. For this reason, we\nexperimented with the common extractor to prevent data restoration. The quality\nof restoration of the original image was tested by adjusting the depth of the\ncommon extractor. As a result, we found that the deeper the common extractor,\nthe restoration score decreased to 89.74.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:54:42 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 02:59:45 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 05:18:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Kim", "Jongwon", ""], ["Shin", "Sungho", ""], ["Yu", "Yeonguk", ""], ["Lee", "Junseok", ""], ["Lee", "Kyoobin", ""]]}, {"id": "2008.09878", "submitter": "Gurpreet Singh", "authors": "Gurpreet Singh, Soumyajit Gupta, Clint N. Dawson", "title": "Prevention is Better than Cure: Handling Basis Collapse and Transparency\n  in Dense Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense nets are an integral part of any classification and regression problem.\nRecently, these networks have found a new application as solvers for known\nrepresentations in various domains. However, one crucial issue with dense nets\nis it's feature interpretation and lack of reproducibility over multiple\ntraining runs. In this work, we identify a basis collapse issue as a primary\ncause and propose a modified loss function that circumvents this problem. We\nalso provide a few general guidelines relating the choice of activations to\nloss surface roughness and appropriate scaling for designing low-weight dense\nnets. We demonstrate through carefully chosen numerical experiments that the\nbasis collapse issue leads to the design of massively redundant networks. Our\napproach results in substantially concise nets, having $100 \\times$ fewer\nparameters, while achieving a much lower $(10\\times)$ MSE loss at scale than\nreported in prior works. Further, we show that the width of a dense net is\nacutely dependent on the feature complexity. This is in contrast to the\ndimension dependent width choice reported in prior theoretical works. To the\nbest of our knowledge, this is the first time these issues and contradictions\nhave been reported and experimentally verified. With our design guidelines we\nrender transparency in terms of a low-weight network design. We share our codes\nfor full reproducibility available at\nhttps://github.com/smjtgupta/Dense_Net_Regress.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:09:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Singh", "Gurpreet", ""], ["Gupta", "Soumyajit", ""], ["Dawson", "Clint N.", ""]]}, {"id": "2008.09879", "submitter": "Vasilis Margonis", "authors": "Vasilis Margonis, Athanasios Davvetas, Iraklis A. Klampanos", "title": "WeLa-VAE: Learning Alternative Disentangled Representations Using Weak\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning disentangled representations without supervision or inductive\nbiases, often leads to non-interpretable or undesirable representations. On the\nother hand, strict supervision requires detailed knowledge of the true\ngenerative factors, which is not always possible. In this paper, we consider\nweak supervision by means of high-level labels that are not assumed to be\nexplicitly related to the ground truth factors. Such labels, while being easier\nto acquire, can also be used as inductive biases for algorithms to learn more\ninterpretable or alternative disentangled representations. To this end, we\npropose WeLa-VAE, a variational inference framework where observations and\nlabels share the same latent variables, which involves the maximization of a\nmodified variational lower bound and total correlation regularization. Our\nmethod is a generalization of TCVAE, adding only one extra hyperparameter. We\nexperiment on a dataset generated by Cartesian coordinates and we show that,\nwhile a TCVAE learns a factorized Cartesian representation, given weak labels\nof distance and angle, WeLa-VAE is able to learn and disentangle a polar\nrepresentation. This is achieved without the need of refined labels or having\nto adjust the number of layers, the optimization parameters, or the total\ncorrelation hyperparameter.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:13:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Margonis", "Vasilis", ""], ["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "2008.09887", "submitter": "Ayush Maheshwari", "authors": "Ayush Maheshwari, Oishik Chatterjee, KrishnaTeja Killamsetty, Ganesh\n  Ramakrishnan, Rishabh Iyer", "title": "Semi-Supervised Data Programming with Subset Selection", "comments": "Findings of ACL, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of data programming, which uses weak supervision in the form of\nrules/labelling functions, and semi-supervised learning, which augments small\namounts of labelled data with a large unlabelled dataset, have shown great\npromise in several text classification scenarios. In this work, we argue that\nby not using any labelled data, data programming based approaches can yield\nsub-optimal performances, particularly when the labelling functions are noisy.\nThe first contribution of this work is an introduction of a framework, \\model\nwhich is a semi-supervised data programming paradigm that learns a \\emph{joint\nmodel} that effectively uses the rules/labelling functions along with\nsemi-supervised loss functions on the feature space. Next, we also study\n\\modelss which additionally does subset selection on top of the joint\nsemi-supervised data programming objective and \\emph{selects} a set of examples\nthat can be used as the labelled set by \\model. The goal of \\modelss is to\nensure that the labelled data can \\emph{complement} the labelling functions,\nthereby benefiting from both data-programming as well as appropriately selected\ndata for human labelling. We demonstrate that by effectively combining\nsemi-supervision, data-programming, and subset selection paradigms, we\nsignificantly outperform the current state-of-the-art on seven publicly\navailable datasets. \\footnote{The source code is available at\n\\url{https://github.com/ayushbits/Semi-Supervised-LFs-Subset-Selection}}\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:53:16 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 09:32:57 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 17:01:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Maheshwari", "Ayush", ""], ["Chatterjee", "Oishik", ""], ["Killamsetty", "KrishnaTeja", ""], ["Ramakrishnan", "Ganesh", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2008.09903", "submitter": "Leonardo Enzo Brito Da Silva", "authors": "Leonardo Enzo Brito da Silva and Nagasharath Rayapati and Donald C.\n  Wunsch II", "title": "iCVI-ARTMAP: Accelerating and improving clustering using adaptive\n  resonance theory predictive mapping and incremental cluster validity indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive resonance theory predictive mapping (ARTMAP)\nmodel which uses incremental cluster validity indices (iCVIs) to perform\nunsupervised learning, namely iCVI-ARTMAP. Incorporating iCVIs to the\ndecision-making and many-to-one mapping capabilities of ARTMAP can improve the\nchoices of clusters to which samples are incrementally assigned. These\nimprovements are accomplished by intelligently performing the operations of\nswapping sample assignments between clusters, splitting and merging clusters,\nand caching the values of variables when iCVI values need to be recomputed.\nUsing recursive formulations enables iCVI-ARTMAP to considerably reduce the\ncomputational burden associated with cluster validity index (CVI)-based offline\nclustering. Depending on the iCVI and the data set, it can achieve running\ntimes up to two orders of magnitude shorter than when using batch CVI\ncomputations. In this work, the incremental versions of Calinski-Harabasz,\nWB-index, Xie-Beni, Davies-Bouldin, Pakhira-Bandyopadhyay-Maulik, and\nnegentropy increment were integrated into fuzzy ARTMAP. Experimental results\nshow that, with proper choice of iCVI, iCVI-ARTMAP outperformed fuzzy adaptive\nresonance theory (ART), dual vigilance fuzzy ART, kmeans, spectral clustering,\nGaussian mixture models and hierarchical agglomerative clustering algorithms in\nmost of the synthetic benchmark data sets. It also performed competitively on\nreal world image benchmark data sets when clustering on projections and on\nlatent spaces generated by a deep clustering model. Naturally, the performance\nof iCVI-ARTMAP is subject to the selected iCVI and its suitability to the data\nat hand; fortunately, it is a general model wherein other iCVIs can be easily\nembedded.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 19:37:01 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["da Silva", "Leonardo Enzo Brito", ""], ["Rayapati", "Nagasharath", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "2008.09915", "submitter": "Sai Ravela", "authors": "Margaret Trautner and Gabriel Margolis and Sai Ravela", "title": "Informative Neural Ensemble Kalman Learning", "comments": "ten pages; accepted for presentation in DDDAS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic systems, informative approaches select key measurement or\ndecision variables that maximize information gain to enhance the efficacy of\nmodel-related inferences. Neural Learning also embodies stochastic dynamics,\nbut informative Learning is less developed. Here, we propose Informative\nEnsemble Kalman Learning, which replaces backpropagation with an adaptive\nEnsemble Kalman Filter to quantify uncertainty and enables maximizing\ninformation gain during Learning. After demonstrating Ensemble Kalman\nLearning's competitive performance on standard datasets, we apply the\ninformative approach to neural structure learning. In particular, we show that\nwhen trained from the Lorenz-63 system's simulations, the efficaciously learned\nstructure recovers the dynamical equations. To the best of our knowledge,\nInformative Ensemble Kalman Learning is new. Results suggest that this approach\nto optimized Learning is promising.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 21:30:41 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Trautner", "Margaret", ""], ["Margolis", "Gabriel", ""], ["Ravela", "Sai", ""]]}, {"id": "2008.09951", "submitter": "Junjie Zhang", "authors": "Junjie Zhang, Cong Zhang, Neal N. Xiong", "title": "DSP: A Differential Spatial Prediction Scheme for Comprehensive real\n  industrial datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse Distance Weighted models (IDW) have been widely used for predicting\nand modeling multidimensional space in multimodal industrial processes.\nHowever, the more complex the structure of multidimensional space, the lower\nthe performance of IDW models, and real industrial datasets tend to have more\ncomplex spatial structure. To solve this problem, a new framework for spatial\nprediction and modeling based on deep reinforcement learning network is\nproposed. In the proposed framework, the internal relationship between state\nand action is enhanced by reusing the state values in the Q network, and the\nconvergence rate and stability of the deep reinforcement learning network are\nimproved. The improved deep reinforcement learning network is then used to\nsearch for and learn the hyperparameters of each sample point in the inverse\ndistance weighted model. These hyperparameters can reflect the spatial\nstructure of the current industrial dataset to some extent. Then a spatial\ndistribution of hyperparameters is constructed based on the learned\nhyperparameters. Each interpolation point obtains corresponding hyperparameters\nfrom the hyperparametric spatial distribution and brings them into the\nclassical IDW models for prediction, thus achieving differential spatial\nprediction and modeling. The simulation results show that the proposed\nframework is suitable for real industrial datasets with complex spatial\nstructure characteristics and is more accurate than current IDW models in\nspatial prediction.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 03:30:07 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Junjie", ""], ["Zhang", "Cong", ""], ["Xiong", "Neal N.", ""]]}, {"id": "2008.09983", "submitter": "Sahaana Suri", "authors": "Sahaana Suri, Raghuveer Chanda, Neslihan Bulut, Pradyumna Narayana,\n  Yemao Zeng, Peter Bailis, Sugato Basu, Girija Narlikar, Christopher Re, and\n  Abishek Sethi", "title": "Leveraging Organizational Resources to Adapt Models to New Data\n  Modalities", "comments": null, "journal-ref": "PVLDB,13(12): 3396-3410, 2020", "doi": "10.14778/3415478.3415559", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As applications in large organizations evolve, the machine learning (ML)\nmodels that power them must adapt the same predictive tasks to newly arising\ndata modalities (e.g., a new video content launch in a social media application\nrequires existing text or image models to extend to video). To solve this\nproblem, organizations typically create ML pipelines from scratch. However,\nthis fails to utilize the domain expertise and data they have cultivated from\ndeveloping tasks for existing modalities. We demonstrate how organizational\nresources, in the form of aggregate statistics, knowledge bases, and existing\nservices that operate over related tasks, enable teams to construct a common\nfeature space that connects new and existing data modalities. This allows teams\nto apply methods for training data curation (e.g., weak supervision and label\npropagation) and model training (e.g., forms of multi-modal learning) across\nthese different data modalities. We study how this use of organizational\nresources composes at production scale in over 5 classification tasks at\nGoogle, and demonstrate how it reduces the time needed to develop models for\nnew modalities from months to weeks to days.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 07:29:00 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Suri", "Sahaana", ""], ["Chanda", "Raghuveer", ""], ["Bulut", "Neslihan", ""], ["Narayana", "Pradyumna", ""], ["Zeng", "Yemao", ""], ["Bailis", "Peter", ""], ["Basu", "Sugato", ""], ["Narlikar", "Girija", ""], ["Re", "Christopher", ""], ["Sethi", "Abishek", ""]]}, {"id": "2008.09990", "submitter": "Yukai Shi", "authors": "Junpeng Tan, Yukai Shi, Zhijing Yang, Caizhen Wen, Liang Lin", "title": "Unsupervised Multi-view Clustering by Squeezing Hybrid Knowledge from\n  Cross View and Each View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-view clustering methods have been a focus in recent years because of\ntheir superiority in clustering performance. However, typical traditional\nmulti-view clustering algorithms still have shortcomings in some aspects, such\nas removal of redundant information, utilization of various views and fusion of\nmulti-view features. In view of these problems, this paper proposes a new\nmulti-view clustering method, low-rank subspace multi-view clustering based on\nadaptive graph regularization. We construct two new data matrix decomposition\nmodels into a unified optimization model. In this framework, we address the\nsignificance of the common knowledge shared by the cross view and the unique\nknowledge of each view by presenting new low-rank and sparse constraints on the\nsparse subspace matrix. To ensure that we achieve effective sparse\nrepresentation and clustering performance on the original data matrix, adaptive\ngraph regularization and unsupervised clustering constraints are also\nincorporated in the proposed model to preserve the internal structural features\nof the data. Finally, the proposed method is compared with several\nstate-of-the-art algorithms. Experimental results for five widely used\nmulti-view benchmarks show that our proposed algorithm surpasses other\nstate-of-the-art methods by a clear margin.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 08:25:06 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tan", "Junpeng", ""], ["Shi", "Yukai", ""], ["Yang", "Zhijing", ""], ["Wen", "Caizhen", ""], ["Lin", "Liang", ""]]}, {"id": "2008.10020", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and George Yin", "title": "Multi-kernel Passive Stochastic Gradient Algorithms and Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel passive stochastic gradient algorithm. In passive\nstochastic approximation, the stochastic gradient algorithm does not have\ncontrol over the location where noisy gradients of the cost function are\nevaluated. Classical passive stochastic gradient algorithms use a kernel that\napproximates a Dirac delta to weigh the gradients based on how far they are\nevaluated from the desired point. In this paper we construct a multi-kernel\npassive stochastic gradient algorithm. The algorithm performs substantially\nbetter in high dimensional problems and incorporates variance reduction. We\nanalyze the weak convergence of the multi-kernel algorithm and its rate of\nconvergence. In numerical examples, we study the multi-kernel version of the\npassive least mean squares (LMS) algorithm for transfer learning to compare the\nperformance with the classical passive version.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 11:55:19 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 03:34:03 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Yin", "George", ""]]}, {"id": "2008.10021", "submitter": "Jinsong Li", "authors": "Jinsong Li, Jianhua Peng, Shuxin Liu, Lintianran Weng, Cong Li", "title": "TSAM: Temporal Link Prediction in Directed Networks based on\n  Self-Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of graph neural networks (GCN) makes it possible to learn\nstructural features from evolving complex networks. Even though a wide range of\nrealistic networks are directed ones, few existing works investigated the\nproperties of directed and temporal networks. In this paper, we address the\nproblem of temporal link prediction in directed networks and propose a deep\nlearning model based on GCN and self-attention mechanism, namely TSAM. The\nproposed model adopts an autoencoder architecture, which utilizes graph\nattentional layers to capture the structural feature of neighborhood nodes, as\nwell as a set of graph convolutional layers to capture motif features. A graph\nrecurrent unit layer with self-attention is utilized to learn temporal\nvariations in the snapshot sequence. We run comparative experiments on four\nrealistic networks to validate the effectiveness of TSAM. Experimental results\nshow that TSAM outperforms most benchmarks under two evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 11:56:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Jinsong", ""], ["Peng", "Jianhua", ""], ["Liu", "Shuxin", ""], ["Weng", "Lintianran", ""], ["Li", "Cong", ""]]}, {"id": "2008.10030", "submitter": "You-Wei Luo", "authors": "You-Wei Luo, Chuan-Xian Ren, Dao-Qing Dai and Hong Yan", "title": "Unsupervised Domain Adaptation via Discriminative Manifold Propagation", "comments": "To be published in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3014218", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is effective in leveraging rich information\nfrom a labeled source domain to an unlabeled target domain. Though deep\nlearning and adversarial strategy made a significant breakthrough in the\nadaptability of features, there are two issues to be further studied. First,\nhard-assigned pseudo labels on the target domain are arbitrary and error-prone,\nand direct application of them may destroy the intrinsic data structure.\nSecond, batch-wise training of deep learning limits the characterization of the\nglobal structure. In this paper, a Riemannian manifold learning framework is\nproposed to achieve transferability and discriminability simultaneously. For\nthe first issue, this framework establishes a probabilistic discriminant\ncriterion on the target domain via soft labels. Based on pre-built prototypes,\nthis criterion is extended to a global approximation scheme for the second\nissue. Manifold metric alignment is adopted to be compatible with the embedding\nspace. The theoretical error bounds of different alignment metrics are derived\nfor constructive guidance. The proposed method can be used to tackle a series\nof variants of domain adaptation problems, including both vanilla and partial\nsettings. Extensive experiments have been conducted to investigate the method\nand a comparative study shows the superiority of the discriminative manifold\nlearning framework.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 12:31:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Luo", "You-Wei", ""], ["Ren", "Chuan-Xian", ""], ["Dai", "Dao-Qing", ""], ["Yan", "Hong", ""]]}, {"id": "2008.10053", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Andrea Iannelli, Bernhard Sch\\\"olkopf", "title": "Learning Dynamical Systems using Local Stability Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A coupled computational approach to simultaneously learn a vector field and\nthe region of attraction of an equilibrium point from generated trajectories of\nthe system is proposed. The nonlinear identification leverages the local\nstability information as a prior on the system, effectively endowing the\nestimate with this important structural property. In addition, the knowledge of\nthe region of attraction plays an experiment design role by informing the\nselection of initial conditions from which trajectories are generated and by\nenabling the use of a Lyapunov function of the system as a regularization term.\nNumerical results show that the proposed method allows efficient sampling and\nprovides an accurate estimate of the dynamics in an inner approximation of its\nregion of attraction.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 14:51:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mehrjou", "Arash", ""], ["Iannelli", "Andrea", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2008.10065", "submitter": "Xingyue Pu", "authors": "Xingyue Pu, Siu Lun Chau, Xiaowen Dong and Dino Sejdinovic", "title": "Kernel-based Graph Learning from Smooth Signals: A Functional Viewpoint", "comments": "13 pages, with extra 3-page appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of graph learning concerns the construction of an explicit\ntopological structure revealing the relationship between nodes representing\ndata entities, which plays an increasingly important role in the success of\nmany graph-based representations and algorithms in the field of machine\nlearning and graph signal processing. In this paper, we propose a novel graph\nlearning framework that incorporates the node-side and observation-side\ninformation, and in particular the covariates that help to explain the\ndependency structures in graph signals. To this end, we consider graph signals\nas functions in the reproducing kernel Hilbert space associated with a\nKronecker product kernel, and integrate functional learning with\nsmoothness-promoting graph learning to learn a graph representing the\nrelationship between nodes. The functional learning increases the robustness of\ngraph learning against missing and incomplete information in the graph signals.\nIn addition, we develop a novel graph-based regularisation method which, when\ncombined with the Kronecker product kernel, enables our model to capture both\nthe dependency explained by the graph and the dependency due to graph signals\nobserved under different but related circumstances, e.g. different points in\ntime. The latter means the graph signals are free from the i.i.d. assumptions\nrequired by the classical graph learning models. Experiments on both synthetic\nand real-world data show that our methods outperform the state-of-the-art\nmodels in learning a meaningful graph topology from graph signals, in\nparticular under heavy noise, missing values, and multiple dependency.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 16:04:23 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pu", "Xingyue", ""], ["Chau", "Siu Lun", ""], ["Dong", "Xiaowen", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2008.10087", "submitter": "Li Wenliang", "authors": "Li K. Wenliang", "title": "Blindness of score-based methods to isolated components and mixing\n  proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A large family of score-based methods are developed recently to solve\nunsupervised learning problems including density estimation, statistical\ntesting and variational inference. These methods are attractive because they\nexploit the derivative of the log density, which is independent of the\nnormaliser, and are thus suitable for tasks involving unnormalised densities.\nDespite the theoretical guarantees on the performance, here we illustrate a\ncommon practical issue suffered by these methods when the unnormalised\ndistribution of interest has isolated components. In particular, we study the\nbehaviour of some popular score-based methods on tasks involving 1-D mixture of\nGaussian. These methods fail to identify appropriate mixing proportions when\nthe unnormalised distribution is multimodal. Finally, some directions for\nfinding a remedy are discussed in light of recent successes in specific tasks.\nWe hope to bring the attention of theoreticians and practitioners to this issue\nwhen developing new algorithms and applications.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 18:24:42 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wenliang", "Li K.", ""]]}, {"id": "2008.10097", "submitter": "Sophie H. Yu", "authors": "Yihong Wu, Jiaming Xu, Sophie H. Yu", "title": "Testing correlation of unlabeled random graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO math.PR stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of detecting the edge correlation between two random\ngraphs with $n$ unlabeled nodes. This is formalized as a hypothesis testing\nproblem, where under the null hypothesis, the two graphs are independently\ngenerated; under the alternative, the two graphs are edge-correlated under some\nlatent node correspondence, but have the same marginal distributions as the\nnull. For both Gaussian-weighted complete graphs and dense Erd\\H{o}s-R\\'enyi\ngraphs (with edge probability $n^{-o(1)}$), we determine the sharp threshold at\nwhich the optimal testing error probability exhibits a phase transition from\nzero to one as $n\\to \\infty$. For sparse Erd\\H{o}s-R\\'enyi graphs with edge\nprobability $n^{-\\Omega(1)}$, we determine the threshold within a constant\nfactor.\n  The proof of the impossibility results is an application of the conditional\nsecond-moment method, where we bound the truncated second moment of the\nlikelihood ratio by carefully conditioning on the typical behavior of the\nintersection graph (consisting of edges in both observed graphs) and taking\ninto account the cycle structure of the induced random permutation on the\nedges. Notably, in the sparse regime, this is accomplished by leveraging the\npseudoforest structure of subcritical Erd\\H{o}s-R\\'enyi graphs and a careful\nenumeration of subpseudoforests that can be assembled from short orbits of the\nedge permutation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 19:19:45 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 01:57:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wu", "Yihong", ""], ["Xu", "Jiaming", ""], ["Yu", "Sophie H.", ""]]}, {"id": "2008.10103", "submitter": "Shuang Qiu", "authors": "Shuang Qiu, Zhuoran Yang, Xiaohan Wei, Jieping Ye, Zhaoran Wang", "title": "Single-Timescale Stochastic Nonconvex-Concave Optimization for Smooth\n  Nonlinear TD Learning", "comments": "45 pages; initial draft submitted in Feb, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-Difference (TD) learning with nonlinear smooth function\napproximation for policy evaluation has achieved great success in modern\nreinforcement learning. It is shown that such a problem can be reformulated as\na stochastic nonconvex-strongly-concave optimization problem, which is\nchallenging as naive stochastic gradient descent-ascent algorithm suffers from\nslow convergence. Existing approaches for this problem are based on\ntwo-timescale or double-loop stochastic gradient algorithms, which may also\nrequire sampling large-batch data. However, in practice, a single-timescale\nsingle-loop stochastic algorithm is preferred due to its simplicity and also\nbecause its step-size is easier to tune. In this paper, we propose two\nsingle-timescale single-loop algorithms which require only one data point each\nstep. Our first algorithm implements momentum updates on both primal and dual\nvariables achieving an $O(\\varepsilon^{-4})$ sample complexity, which shows the\nimportant role of momentum in obtaining a single-timescale algorithm. Our\nsecond algorithm improves upon the first one by applying variance reduction on\ntop of momentum, which matches the best known $O(\\varepsilon^{-3})$ sample\ncomplexity in existing works. Furthermore, our variance-reduction algorithm\ndoes not require a large-batch checkpoint. Moreover, our theoretical results\nfor both algorithms are expressed in a tighter form of simultaneous primal and\ndual side convergence.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 20:36:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qiu", "Shuang", ""], ["Yang", "Zhuoran", ""], ["Wei", "Xiaohan", ""], ["Ye", "Jieping", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2008.10117", "submitter": "Robin M. Schmidt", "authors": "Robin M. Schmidt, Moritz Hahn", "title": "Collaborative Filtering under Model Uncertainty", "comments": "v2: small display fix in affiliation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their work, Dean, Rich, and Recht create a model to research recourse and\navailability of items in a recommender system. We used the definition of\npredictive multiplicity by Marx, Pin Calmon, and Ustun to examine different\nvariations of this model, using different values for two model parameters.\nPairwise comparison of their models show, that most of these models produce\nvery similar results in terms of discrepancy and ambiguity for the availability\nand only in some cases the availability sets differ significantly.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 22:09:31 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 02:10:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Schmidt", "Robin M.", ""], ["Hahn", "Moritz", ""]]}, {"id": "2008.10138", "submitter": "Sayedmasoud Hashemi Amroabadi", "authors": "Masoud Hashemi, Ali Fathi", "title": "PermuteAttack: Counterfactual Explanation of Machine Learning Credit\n  Scorecards", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a note on new directions and methodologies for validation and\nexplanation of Machine Learning (ML) models employed for retail credit scoring\nin finance. Our proposed framework draws motivation from the field of\nArtificial Intelligence (AI) security and adversarial ML where the need for\ncertifying the performance of the ML algorithms in the face of their\noverwhelming complexity poses a need for rethinking the traditional notions of\nmodel architecture selection, sensitivity analysis and stress testing. Our\npoint of view is that the phenomenon of adversarial perturbations when detached\nfrom the AI security domain, has purely algorithmic roots and fall within the\nscope of model risk assessment. We propose a model criticism and explanation\nframework based on adversarially generated counterfactual examples for tabular\ndata. A counterfactual example to a given instance in this context is defined\nas a synthetically generated data point sampled from the estimated data\ndistribution which is treated differently by a model. The counterfactual\nexamples can be used to provide a black-box instance-level explanation of the\nmodel behaviour as well as studying the regions in the input space where the\nmodel performance deteriorates. Adversarial example generating algorithms are\nextensively studied in the image and natural language processing (NLP) domains.\nHowever, most financial data come in tabular format and naive application of\nthe existing techniques on this class of datasets generates unrealistic\nsamples. In this paper, we propose a counterfactual example generation method\ncapable of handling tabular data including discrete and categorical variables.\nOur proposed algorithm uses a gradient-free optimization based on genetic\nalgorithms and therefore is applicable to any classification model.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 00:05:13 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:06:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hashemi", "Masoud", ""], ["Fathi", "Ali", ""]]}, {"id": "2008.10150", "submitter": "Daniel Hsu", "authors": "Christopher Tosh, Akshay Krishnamurthy, Daniel Hsu", "title": "Contrastive learning, multi-view redundancy, and linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning is an empirically successful approach to\nunsupervised learning based on creating artificial supervised learning\nproblems. A popular self-supervised approach to representation learning is\ncontrastive learning, which leverages naturally occurring pairs of similar and\ndissimilar data points, or multiple views of the same data. This work provides\na theoretical analysis of contrastive learning in the multi-view setting, where\ntwo views of each datum are available. The main result is that linear functions\nof the learned representations are nearly optimal on downstream prediction\ntasks whenever the two views provide redundant information about the label.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 01:31:47 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 19:19:55 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Tosh", "Christopher", ""], ["Krishnamurthy", "Akshay", ""], ["Hsu", "Daniel", ""]]}, {"id": "2008.10159", "submitter": "Dongxiao Zhang", "authors": "Miao Rong, Dongxiao Zhang, Nanzhe Wang", "title": "A Lagrangian Dual-based Theory-guided Deep Neural Network", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory-guided neural network (TgNN) is a kind of method which improves\nthe effectiveness and efficiency of neural network architectures by\nincorporating scientific knowledge or physical information. Despite its great\nsuccess, the theory-guided (deep) neural network possesses certain limits when\nmaintaining a tradeoff between training data and domain knowledge during the\ntraining process. In this paper, the Lagrangian dual-based TgNN (TgNN-LD) is\nproposed to improve the effectiveness of TgNN. We convert the original loss\nfunction into a constrained form with fewer items, in which partial\ndifferential equations (PDEs), engineering controls (ECs), and expert knowledge\n(EK) are regarded as constraints, with one Lagrangian variable per constraint.\nThese Lagrangian variables are incorporated to achieve an equitable tradeoff\nbetween observation data and corresponding constraints, in order to improve\nprediction accuracy, and conserve time and computational resources adjusted by\nan ad-hoc procedure. To investigate the performance of the proposed method, the\noriginal TgNN model with a set of optimized weight values adjusted by ad-hoc\nprocedures is compared on a subsurface flow problem, with their L2 error, R\nsquare (R2), and computational time being analyzed. Experimental results\ndemonstrate the superiority of the Lagrangian dual-based TgNN.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 02:06:19 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Rong", "Miao", ""], ["Zhang", "Dongxiao", ""], ["Wang", "Nanzhe", ""]]}, {"id": "2008.10183", "submitter": "Skyler Seto", "authors": "Skyler Seto, Martin T. Wells, Wenyu Zhang", "title": "HALO: Learning to Prune Neural Networks with Shrinkage", "comments": "Accepted at SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve state-of-the-art performance in a variety of\ntasks by extracting a rich set of features from unstructured data, however this\nperformance is closely tied to model size. Modern techniques for inducing\nsparsity and reducing model size are (1) network pruning, (2) training with a\nsparsity inducing penalty, and (3) training a binary mask jointly with the\nweights of the network. We study different sparsity inducing penalties from the\nperspective of Bayesian hierarchical models and present a novel penalty called\nHierarchical Adaptive Lasso (HALO) which learns to adaptively sparsify weights\nof a given network via trainable parameters. When used to train\nover-parametrized networks, our penalty yields small subnetworks with high\naccuracy without fine-tuning. Empirically, on image recognition tasks, we find\nthat HALO is able to learn highly sparse network (only 5% of the parameters)\nwith significant gains in performance over state-of-the-art magnitude pruning\nmethods at the same level of sparsity. Code is available at\nhttps://github.com/skyler120/sparsity-halo.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 04:08:48 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 01:47:29 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 04:26:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Seto", "Skyler", ""], ["Wells", "Martin T.", ""], ["Zhang", "Wenyu", ""]]}, {"id": "2008.10208", "submitter": "Youwei Liang", "authors": "Youwei Liang, Dong Huang, Chang-Dong Wang, and Philip S. Yu", "title": "Multi-view Graph Learning by Joint Modeling of Consistency and\n  Inconsistency", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph learning has emerged as a promising technique for multi-view clustering\nwith its ability to learn a unified and robust graph from multiple views.\nHowever, existing graph learning methods mostly focus on the multi-view\nconsistency issue, yet often neglect the inconsistency across multiple views,\nwhich makes them vulnerable to possibly low-quality or noisy datasets. To\novercome this limitation, we propose a new multi-view graph learning framework,\nwhich for the first time simultaneously and explicitly models multi-view\nconsistency and multi-view inconsistency in a unified objective function,\nthrough which the consistent and inconsistent parts of each single-view graph\nas well as the unified graph that fuses the consistent parts can be iteratively\nlearned. Though optimizing the objective function is NP-hard, we design a\nhighly efficient optimization algorithm which is able to obtain an approximate\nsolution with linear time complexity in the number of edges in the unified\ngraph. Furthermore, our multi-view graph learning approach can be applied to\nboth similarity graphs and dissimilarity graphs, which lead to two graph\nfusion-based variants in our framework. Experiments on twelve multi-view\ndatasets have demonstrated the robustness and efficiency of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 06:11:29 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 10:02:51 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liang", "Youwei", ""], ["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.10249", "submitter": "Xiugang Wu", "authors": "Yikun Bai, Xiugang Wu, Ayfer Ozgur", "title": "Information Constrained Optimal Transport: From Talagrand, to Marton, to\n  Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.FA math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal transport problem studies how to transport one measure to another\nin the most cost-effective way and has wide range of applications from\neconomics to machine learning. In this paper, we introduce and study an\ninformation constrained variation of this problem. Our study yields a\nstrengthening and generalization of Talagrand's celebrated transportation cost\ninequality. Following Marton's approach, we show that the new transportation\ncost inequality can be used to recover old and new concentration of measure\nresults. Finally, we provide an application of this new inequality to network\ninformation theory. We show that it can be used to recover almost immediately a\nrecent solution to a long-standing open problem posed by Cover regarding the\ncapacity of the relay channel.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 08:23:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bai", "Yikun", ""], ["Wu", "Xiugang", ""], ["Ozgur", "Ayfer", ""]]}, {"id": "2008.10277", "submitter": "Abhay Shukla", "authors": "Abhay Shukla, Jairaj Sathyanarayana, Dipyaman Banerjee", "title": "Sample-Rank: Weak Multi-Objective Recommendations Using Rejection\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online food ordering marketplaces are multi-stakeholder systems where\nrecommendations impact the experience and growth of each participant in the\nsystem. A recommender system in this setting has to encapsulate the objectives\nand constraints of different stakeholders in order to find utility of an item\nfor recommendation. Constrained-optimization based approaches to this problem\ntypically involve complex formulations and have high computational complexity\nin production settings involving millions of entities. Simplifications and\nrelaxation techniques (for example, scalarization) help but introduce\nsub-optimality and can be time-consuming due to the amount of tuning needed. In\nthis paper, we introduce a method involving multi-goal sampling followed by\nranking for user-relevance (Sample-Rank), to nudge recommendations towards\nmulti-objective (MO) goals of the marketplace. The proposed method's novelty is\nthat it reduces the MO recommendation problem to sampling from a desired\nmulti-goal distribution then using it to build a production-friendly\nlearning-to-rank (LTR) model. In offline experiments we show that we are able\nto bias recommendations towards MO criteria with acceptable trade-offs in\nmetrics like AUC and NDCG. We also show results from a large-scale online A/B\nexperiment where this approach gave a statistically significant lift of 2.64%\nin average revenue per order (RPO) (objective #1) with no drop in conversion\nrate (CR) (objective #2) while holding the average last-mile traversed flat\n(objective #3), vs. the baseline ranking method. This method also significantly\nreduces time to model development and deployment in MO settings and allows for\ntrivial extensions to more objectives and other types of LTR models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:17:18 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Shukla", "Abhay", ""], ["Sathyanarayana", "Jairaj", ""], ["Banerjee", "Dipyaman", ""]]}, {"id": "2008.10293", "submitter": "Dimitrios Bariamis", "authors": "Armin Runge (1) and Thomas Wenzel (2) and Dimitrios Bariamis (2) and\n  Benedikt Sebastian Staffler (3) and Lucas Rego Drumond (2) and Michael\n  Pfeiffer (3) ((1) Department of Advanced Digital Technologies, Bosch\n  Corporate Research, Renningen, Germany, (2) Computer Vision Lab, Bosch\n  Corporate Research, Hildesheim, Germany, (3) Bosch Center for Artificial\n  Intelligence, Renningen, Germany)", "title": "Bosch Deep Learning Hardware Benchmark", "comments": "Presented in MLBench: Workshop on Benchmarking Machine Learning\n  Workloads (https://sites.google.com/g.harvard.edu/mlbench/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of Deep Learning (DL) applications in science and industry\nhas created a large demand for efficient inference systems. This has resulted\nin a rapid increase of available Hardware Accelerators (HWAs) making comparison\nchallenging and laborious. To address this, several DL hardware benchmarks have\nbeen proposed aiming at a comprehensive comparison for many models, tasks, and\nhardware platforms. Here, we present our DL hardware benchmark which has been\nspecifically developed for inference on embedded HWAs and tasks required for\nautonomous driving. In addition to previous benchmarks, we propose a new\ngranularity level to evaluate common submodules of DL models, a twofold\nbenchmark procedure that accounts for hardware and model optimizations done by\nHWA manufacturers, and an extended set of performance indicators that can help\nto identify a mismatch between a HWA and the DL models used in our benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:50:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Runge", "Armin", ""], ["Wenzel", "Thomas", ""], ["Bariamis", "Dimitrios", ""], ["Staffler", "Benedikt Sebastian", ""], ["Drumond", "Lucas Rego", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "2008.10320", "submitter": "Fanhua Shang", "authors": "Hongying Liu, Zhubo Ruan, Chaowei Fang, Peng Zhao, Fanhua Shang,\n  Yuanyuan Liu, Lijun Wang", "title": "A Single Frame and Multi-Frame Joint Network for 360-degree Panorama\n  Video Super-Resolution", "comments": "10 pages, 5 figures, submitted to an international peer-review\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical videos, also known as \\ang{360} (panorama) videos, can be viewed\nwith various virtual reality devices such as computers and head-mounted\ndisplays. They attract large amount of interest since awesome immersion can be\nexperienced when watching spherical videos. However, capturing, storing and\ntransmitting high-resolution spherical videos are extremely expensive. In this\npaper, we propose a novel single frame and multi-frame joint network (SMFN) for\nrecovering high-resolution spherical videos from low-resolution inputs. To take\nadvantage of pixel-level inter-frame consistency, deformable convolutions are\nused to eliminate the motion difference between feature maps of the target\nframe and its neighboring frames. A mixed attention mechanism is devised to\nenhance the feature representation capability. The dual learning strategy is\nexerted to constrain the space of solution so that a better solution can be\nfound. A novel loss function based on the weighted mean square error is\nproposed to emphasize on the super-resolution of the equatorial regions. This\nis the first attempt to settle the super-resolution of spherical videos, and we\ncollect a novel dataset from the Internet, MiG Panorama Video, which includes\n204 videos. Experimental results on 4 representative video clips demonstrate\nthe efficacy of the proposed method. The dataset and code are available at\nhttps://github.com/lovepiano/SMFN_For_360VSR.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:09:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Hongying", ""], ["Ruan", "Zhubo", ""], ["Fang", "Chaowei", ""], ["Zhao", "Peng", ""], ["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Wang", "Lijun", ""]]}, {"id": "2008.10351", "submitter": "Lucas Hu", "authors": "Lucas Hu, Caleb Robinson, Bistra Dilkina", "title": "Model Generalization in Deep Learning Applications for Land Cover\n  Mapping", "comments": "9 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep learning models can be used to classify\nland-use data from geospatial satellite imagery. We show that when these deep\nlearning models are trained on data from specific continents/seasons, there is\na high degree of variability in model performance on out-of-sample\ncontinents/seasons. This suggests that just because a model accurately predicts\nland-use classes in one continent or season does not mean that the model will\naccurately predict land-use classes in a different continent or season. We then\nuse clustering techniques on satellite imagery from different continents to\nvisualize the differences in landscapes that make geospatial generalization\nparticularly difficult, and summarize our takeaways for future satellite\nimagery-related applications.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 01:50:52 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 02:04:42 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 19:04:16 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Hu", "Lucas", ""], ["Robinson", "Caleb", ""], ["Dilkina", "Bistra", ""]]}, {"id": "2008.10365", "submitter": "Ravi Vadlamani", "authors": "Sarveswararao Vangala, Ravi Vadlamani", "title": "ATM Cash demand forecasting in an Indian Bank with chaos and deep\n  learning", "comments": "20 pages; 6 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes to model chaos in the ATM cash withdrawal time series of\na big Indian bank and forecast the withdrawals using deep learning methods. It\nalso considers the importance of day-of-the-week and includes it as a dummy\nexogenous variable. We first modelled the chaos present in the withdrawal time\nseries by reconstructing the state space of each series using the lag, and\nembedding dimension found using an auto-correlation function and Cao's method.\nThis process converts the uni-variate time series into multi variate time\nseries. The \"day-of-the-week\" is converted into seven features with the help of\none-hot encoding. Then these seven features are augmented to the multivariate\ntime series. For forecasting the future cash withdrawals, using algorithms\nnamely ARIMA, random forest (RF), support vector regressor (SVR), multi-layer\nperceptron (MLP), group method of data handling (GMDH), general regression\nneural network (GRNN), long short term memory neural network and 1-dimensional\nconvolutional neural network. We considered a daily cash withdrawals data set\nfrom an Indian commercial bank. After modelling chaos and adding exogenous\nfeatures to the data set, we observed improvements in the forecasting for all\nmodels. Even though the random forest (RF) yielded better Symmetric Mean\nAbsolute Percentage Error (SMAPE) value, deep learning algorithms, namely LSTM\nand 1D CNN, showed similar performance compared to RF, based on t-test.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:23:07 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Vangala", "Sarveswararao", ""], ["Vadlamani", "Ravi", ""]]}, {"id": "2008.10376", "submitter": "Ulrik Brandes", "authors": "Katharina B\\\"orsig, Ulrik Brandes and Barna Pasztor", "title": "Stochastic Gradient Descent Works Really Well for Stress Minimization", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress minimization is among the best studied force-directed graph layout\nmethods because it reliably yields high-quality layouts. It thus comes as a\nsurprise that a novel approach based on stochastic gradient descent (Zheng,\nPawar and Goodman, TVCG 2019) is claimed to improve on state-of-the-art\napproaches based on majorization. We present experimental evidence that the new\napproach does not actually yield better layouts, but that it is still to be\npreferred because it is simpler and robust against poor initialization.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:37:00 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["B\u00f6rsig", "Katharina", ""], ["Brandes", "Ulrik", ""], ["Pasztor", "Barna", ""]]}, {"id": "2008.10380", "submitter": "Gang Mei", "authors": "Gang Mei, Jingzhi Tu, Lei Xiao, Francesco Piccialli", "title": "KCoreMotif: An Efficient Graph Clustering Algorithm for Large Networks\n  by Exploiting k-core Decomposition and Motifs", "comments": "33 pages; 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering analysis has been widely used in trust evaluation on various\ncomplex networks such as wireless sensors networks and online social networks.\nSpectral clustering is one of the most commonly used algorithms for\ngraph-structured data (networks). However, the conventional spectral clustering\nis inherently difficult to work with large-scale networks due to the fact that\nit needs computationally expensive matrix manipulations. To deal with large\nnetworks, in this paper, we propose an efficient graph clustering algorithm,\nKCoreMotif, specifically for large networks by exploiting k-core decomposition\nand motifs. The essential idea behind the proposed clustering algorithm is to\nperform the efficient motif-based spectral clustering algorithm on k-core\nsubgraphs, rather than on the entire graph. More specifically, (1) we first\nconduct the k-core decomposition of the large input network; (2) we then\nperform the motif-based spectral clustering for the top k-core subgraphs; (3)\nwe group the remaining vertices in the rest (k-1)-core subgraphs into\npreviously found clusters; and finally obtain the desired clusters of the large\ninput network. To evaluate the performance of the proposed graph clustering\nalgorithm KCoreMotif, we use both the conventional and the motif-based spectral\nclustering algorithms as the baselines and compare our algorithm with them for\n18 groups of real-world datasets. Comparative results demonstrate that the\nproposed graph clustering algorithm is accurate yet efficient for large\nnetworks, which also means that it can be further used to evaluate the\nintra-cluster and inter-cluster trusts on large networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:21:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mei", "Gang", ""], ["Tu", "Jingzhi", ""], ["Xiao", "Lei", ""], ["Piccialli", "Francesco", ""]]}, {"id": "2008.10419", "submitter": "Amine Dadoun", "authors": "Amine Dadoun (1 and 2), Ismail Harrando (1), Pasquale Lisena (1),\n  Alison Reboud (1), Raphael Troncy (1) ((1) Eurecom, (2) Amadeus SAS)", "title": "Two Stages Approach for Tweet Engagement Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the approach proposed by the D2KLab team for the 2020\nRecSys Challenge on the task of predicting user engagement facing tweets. This\napproach relies on two distinct stages. First, relevant features are learned\nfrom the challenge dataset. These features are heterogeneous and are the\nresults of different learning modules such as handcrafted features, knowledge\ngraph embeddings, sentiment analysis features and BERT word embeddings. Second,\nthese features are provided in input to an ensemble system based on XGBoost.\nThis approach, only trained on a subset of the entire challenge dataset, ranked\n22 in the final leaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:18:10 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Dadoun", "Amine", "", "1 and 2"], ["Harrando", "Ismail", "", "Eurecom"], ["Lisena", "Pasquale", "", "Eurecom"], ["Reboud", "Alison", "", "Eurecom"], ["Troncy", "Raphael", "", "Eurecom"]]}, {"id": "2008.10425", "submitter": "Ajay Patrikar", "authors": "Ajay M. Patrikar", "title": "Efficient Design of Neural Networks with Random Weights", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single layer feedforward networks with random weights are known for their\nnon-iterative and fast training algorithms and are successful in a variety of\nclassification and regression problems. A major drawback of these networks is\nthat they require a large number of hidden units. In this paper, we propose a\ntechnique to reduce the number of hidden units substantially without affecting\nthe accuracy of the networks significantly. We introduce the concept of primary\nand secondary hidden units. The weights for the primary hidden units are chosen\nrandomly while the secondary hidden units are derived using pairwise\ncombinations of the primary hidden units. Using this technique, we show that\nthe number of hidden units can be reduced by at least one order of magnitude.\nWe experimentally show that this technique leads to significant drop in\ncomputations at inference time and has only a minor impact on network accuracy.\nA huge reduction in computations is possible if slightly lower accuracy is\nacceptable.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:24:25 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Patrikar", "Ajay M.", ""]]}, {"id": "2008.10433", "submitter": "Pantelis Vlachas", "authors": "Francesco Varoli, Guido Novati, Pantelis R. Vlachas, Petros\n  Koumoutsakos", "title": "Improved Memories Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Improved Memories Learning (IMeL), a novel algorithm that turns\nreinforcement learning (RL) into a supervised learning (SL) problem and\ndelimits the role of neural networks (NN) to interpolation. IMeL consists of\ntwo components. The first is a reservoir of experiences. Each experience is\nupdated based on a non-parametric procedural improvement of the policy,\ncomputed as a bounded one-sample Monte Carlo estimate. The second is a NN\nregressor, which receives as input improved experiences from the reservoir\n(context points) and computes the policy by interpolation. The NN learns to\nmeasure the similarity between states in order to compute long-term forecasts\nby averaging experiences, rather than by encoding the problem structure in the\nNN parameters. We present preliminary results and propose IMeL as a baseline\nmethod for assessing the merits of more complex models and inductive biases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:37:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Varoli", "Francesco", ""], ["Novati", "Guido", ""], ["Vlachas", "Pantelis R.", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "2008.10435", "submitter": "Hongchang Gao", "authors": "Hongchang Gao, Heng Huang", "title": "Periodic Stochastic Gradient Descent with Momentum for Decentralized\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized training has been actively studied in recent years. Although a\nwide variety of methods have been proposed, yet the decentralized momentum SGD\nmethod is still underexplored. In this paper, we propose a novel periodic\ndecentralized momentum SGD method, which employs the momentum schema and\nperiodic communication for decentralized training. With these two strategies,\nas well as the topology of the decentralized training system, the theoretical\nconvergence analysis of our proposed method is difficult. We address this\nchallenging problem and provide the condition under which our proposed method\ncan achieve the linear speedup regarding the number of workers. Furthermore, we\nalso introduce a communication-efficient variant to reduce the communication\ncost in each communication round. The condition for achieving the linear\nspeedup is also provided for this variant. To the best of our knowledge, these\ntwo methods are all the first ones achieving these theoretical results in their\ncorresponding domain. We conduct extensive experiments to verify the\nperformance of our proposed two methods, and both of them have shown superior\nperformance over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:38:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gao", "Hongchang", ""], ["Huang", "Heng", ""]]}, {"id": "2008.10466", "submitter": "Yitian Qian", "authors": "Ting Tao, Shaohua Pan and Yitian Qian", "title": "Column $\\ell_{2,0}$-norm regularized factorization model of low-rank\n  matrix recovery and its computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the column $\\ell_{2,0}$-regularized\nfactorization model of low-rank matrix recovery problems and its computation.\nThe column $\\ell_{2,0}$-norm of factor matrices is introduced to promote column\nsparsity of factors and lower rank solutions. For this nonconvex nonsmooth and\nnon-Lipschitz problem, we develop an alternating majorization-minimization\n(AMM) method with extrapolation, and a hybrid AMM in which a majorized\nalternating proximal method is proposed to seek an initial factor pair with\nless nonzero columns and the AMM with extrapolation is then employed to\nminimize of a smooth nonconvex loss. We provide the global convergence analysis\nfor the proposed AMM methods and apply them to the matrix completion problem\nwith non-uniform sampling schemes. Numerical experiments are conducted with\nsynthetic and real data examples, and comparison results with the nuclear-norm\nregularized factorization model and the max-norm regularized convex model show\nthat the column $\\ell_{2,0}$-regularized factorization model has an advantage\nin offering solutions of lower error and rank within less time.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:15:36 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 08:35:14 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tao", "Ting", ""], ["Pan", "Shaohua", ""], ["Qian", "Yitian", ""]]}, {"id": "2008.10498", "submitter": "Yuzuru Sato", "authors": "Yuzuru Sato, Daiji Tsutsui, and Akio Fujiwara", "title": "Noise-induced degeneration in online learning", "comments": "16 pages, 5 figures, submitted to Physica D", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to elucidate the plateau phenomena caused by vanishing gradient, we\nherein analyse stability of stochastic gradient descent near degenerated\nsubspaces in a multi-layer perceptron. In stochastic gradient descent for\nFukumizu-Amari model, which is the minimal multi-layer perceptron showing\nnon-trivial plateau phenomena, we show that (1) attracting regions exist in\nmultiply degenerated subspaces, (2) a strong plateau phenomenon emerges as a\nnoise-induced synchronisation, which is not observed in deterministic gradient\ndescent, (3) an optimal fluctuation exists to minimise the escape time from the\ndegenerated subspace. The noise-induced degeneration observed herein is\nexpected to be found in a broad class of machine learning via neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:03:58 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 16:33:57 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 04:06:18 GMT"}, {"version": "v4", "created": "Sat, 21 Nov 2020 03:20:47 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sato", "Yuzuru", ""], ["Tsutsui", "Daiji", ""], ["Fujiwara", "Akio", ""]]}, {"id": "2008.10519", "submitter": "Emil Bols", "authors": "Emil Bols, Jan Kieseler, Mauro Verzetti, Markus Stoye, Anna Stakia", "title": "Jet Flavour Classification Using DeepJet", "comments": "14 pages, 9 figures, accepted for publication in JINST", "journal-ref": "JINST 15 (2020) P12012", "doi": "10.1088/1748-0221/15/12/P12012", "report-no": null, "categories": "hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jet flavour classification is of paramount importance for a broad range of\napplications in modern-day high-energy-physics experiments, particularly at the\nLHC. In this paper we propose a novel architecture for this task that exploits\nmodern deep learning techniques. This new model, called DeepJet, overcomes the\nlimitations in input size that affected previous approaches. As a result, the\nheavy flavour classification performance improves, and the model is extended to\nalso perform quark-gluon tagging.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:42:36 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 21:39:30 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bols", "Emil", ""], ["Kieseler", "Jan", ""], ["Verzetti", "Mauro", ""], ["Stoye", "Markus", ""], ["Stakia", "Anna", ""]]}, {"id": "2008.10526", "submitter": "Saeed Ghadimi", "authors": "Krishnakumar Balasubramanian, Saeed Ghadimi, Anthony Nguyen", "title": "Stochastic Multi-level Composition Optimization Algorithms with\n  Level-Independent Convergence Rates", "comments": "Refined the convergence analysis in Section 3 under weaker\n  assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study smooth stochastic multi-level composition\noptimization problems, where the objective function is a nested composition of\n$T$ functions. We assume access to noisy evaluations of the functions and their\ngradients, through a stochastic first-order oracle. For solving this class of\nproblems, we propose two algorithms using moving-average stochastic estimates,\nand analyze their convergence to an $\\epsilon$-stationary point of the problem.\nWe show that the first algorithm, which is a generalization of\n\\cite{GhaRuswan20} to the $T$ level case, can achieve a sample complexity of\n$\\mathcal{O}(1/\\epsilon^6)$ by using mini-batches of samples in each iteration.\nBy modifying this algorithm using linearized stochastic estimates of the\nfunction values, we improve the sample complexity to\n$\\mathcal{O}(1/\\epsilon^4)$. {\\color{black}This modification not only removes\nthe requirement of having a mini-batch of samples in each iteration, but also\nmakes the algorithm parameter-free and easy to implement}. To the best of our\nknowledge, this is the first time that such an online algorithm designed for\nthe (un)constrained multi-level setting, obtains the same sample complexity of\nthe smooth single-level setting, under standard assumptions (unbiasedness and\nboundedness of the second moments) on the stochastic first-order oracle.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:57:50 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:59:02 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 04:36:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Nguyen", "Anthony", ""]]}, {"id": "2008.10532", "submitter": "Claire Heaney", "authors": "Toby Phillips, Claire E. Heaney, Paul N. Smith, Christopher C. Pain", "title": "An autoencoder-based reduced-order model for eigenvalue problems with\n  application to neutron diffusion", "comments": "35 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using an autoencoder for dimensionality reduction, this paper presents a\nnovel projection-based reduced-order model for eigenvalue problems.\nReduced-order modelling relies on finding suitable basis functions which define\na low-dimensional space in which a high-dimensional system is approximated.\nProper orthogonal decomposition (POD) and singular value decomposition (SVD)\nare often used for this purpose and yield an optimal linear subspace.\nAutoencoders provide a nonlinear alternative to POD/SVD, that may capture, more\nefficiently, features or patterns in the high-fidelity model results.\n  Reduced-order models based on an autoencoder and a novel hybrid\nSVD-autoencoder are developed. These methods are compared with the standard\nPOD-Galerkin approach and are applied to two test cases taken from the field of\nnuclear reactor physics.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 16:52:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Phillips", "Toby", ""], ["Heaney", "Claire E.", ""], ["Smith", "Paul N.", ""], ["Pain", "Christopher C.", ""]]}, {"id": "2008.10546", "submitter": "Lingkai Kong", "authors": "Lingkai Kong, Jimeng Sun and Chao Zhang", "title": "SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates", "comments": "ICML2020. Code is available through\n  https://github.com/Lingkai-Kong/SDE-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification is a fundamental yet unsolved problem for deep\nlearning. The Bayesian framework provides a principled way of uncertainty\nestimation but is often not scalable to modern deep neural nets (DNNs) that\nhave a large number of parameters. Non-Bayesian methods are simple to implement\nbut often conflate different sources of uncertainties and require huge\ncomputing resources. We propose a new method for quantifying uncertainties of\nDNNs from a dynamical system perspective. The core of our method is to view DNN\ntransformations as state evolution of a stochastic dynamical system and\nintroduce a Brownian motion term for capturing epistemic uncertainty. Based on\nthis perspective, we propose a neural stochastic differential equation model\n(SDE-Net) which consists of (1) a drift net that controls the system to fit the\npredictive function; and (2) a diffusion net that captures epistemic\nuncertainty. We theoretically analyze the existence and uniqueness of the\nsolution to SDE-Net. Our experiments demonstrate that the SDE-Net model can\noutperform existing uncertainty estimation methods across a series of tasks\nwhere uncertainty plays a fundamental role.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:33:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kong", "Lingkai", ""], ["Sun", "Jimeng", ""], ["Zhang", "Chao", ""]]}, {"id": "2008.10547", "submitter": "William Stephenson", "authors": "William T. Stephenson, Madeleine Udell, Tamara Broderick", "title": "Approximate Cross-Validation with Low-Rank Data in High Dimensions", "comments": "19 pages, 6 figures", "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in machine learning are driven by a challenging\ntrifecta: large data size $N$; high dimensions; and expensive algorithms. In\nthis setting, cross-validation (CV) serves as an important tool for model\nassessment. Recent advances in approximate cross validation (ACV) provide\naccurate approximations to CV with only a single model fit, avoiding\ntraditional CV's requirement for repeated runs of expensive algorithms.\nUnfortunately, these ACV methods can lose both speed and accuracy in high\ndimensions -- unless sparsity structure is present in the data. Fortunately,\nthere is an alternative type of simplifying structure that is present in most\ndata: approximate low rank (ALR). Guided by this observation, we develop a new\nalgorithm for ACV that is fast and accurate in the presence of ALR data. Our\nfirst key insight is that the Hessian matrix -- whose inverse forms the\ncomputational bottleneck of existing ACV methods -- is ALR. We show that,\ndespite our use of the \\emph{inverse} Hessian, a low-rank approximation using\nthe largest (rather than the smallest) matrix eigenvalues enables fast,\nreliable ACV. Our second key insight is that, in the presence of ALR data,\nerror in existing ACV methods roughly grows with the (approximate, low) rank\nrather than with the (full, high) dimension. These insights allow us to prove\ntheoretical guarantees on the quality of our proposed algorithm -- along with\nfast-to-compute upper bounds on its error. We demonstrate the speed and\naccuracy of our method, as well as the usefulness of our bounds, on a range of\nreal and simulated data sets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:34:05 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Stephenson", "William T.", ""], ["Udell", "Madeleine", ""], ["Broderick", "Tamara", ""]]}, {"id": "2008.10549", "submitter": "Alireza Heidari", "authors": "Alireza Heidari, Shrinu Kushagra, Ihab F. Ilyas", "title": "On sampling from data with duplicate records", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data deduplication is the task of detecting records in a database that\ncorrespond to the same real-world entity. Our goal is to develop a procedure\nthat samples uniformly from the set of entities present in the database in the\npresence of duplicates. We accomplish this by a two-stage process. In the first\nstep, we estimate the frequencies of all the entities in the database. In the\nsecond step, we use rejection sampling to obtain a (approximately) uniform\nsample from the set of entities. However, efficiently estimating the frequency\nof all the entities is a non-trivial task and not attainable in the general\ncase. Hence, we consider various natural properties of the data under which\nsuch frequency estimation (and consequently uniform sampling) is possible.\nUnder each of those assumptions, we provide sampling algorithms and give proofs\nof the complexity (both statistical and computational) of our approach. We\ncomplement our study by conducting extensive experiments on both real and\nsynthetic datasets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:41:47 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Heidari", "Alireza", ""], ["Kushagra", "Shrinu", ""], ["Ilyas", "Ihab F.", ""]]}, {"id": "2008.10581", "submitter": "Aman Sinha", "authors": "Aman Sinha, Matthew O'Kelly, Russ Tedrake, John Duchi", "title": "Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based methodologies increasingly find applications in\nsafety-critical domains like autonomous driving and medical robotics. Due to\nthe rare nature of dangerous events, real-world testing is prohibitively\nexpensive and unscalable. In this work, we employ a probabilistic approach to\nsafety evaluation in simulation, where we are concerned with computing the\nprobability of dangerous events. We develop a novel rare-event simulation\nmethod that combines exploration, exploitation, and optimization techniques to\nfind failure modes and estimate their rate of occurrence. We provide rigorous\nguarantees for the performance of our method in terms of both statistical and\ncomputational efficiency. Finally, we demonstrate the efficacy of our approach\non a variety of scenarios, illustrating its usefulness as a tool for rapid\nsensitivity analysis and model comparison that are essential to developing and\ntesting safety-critical autonomous systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:46:27 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 19:53:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sinha", "Aman", ""], ["O'Kelly", "Matthew", ""], ["Tedrake", "Russ", ""], ["Duchi", "John", ""]]}, {"id": "2008.10587", "submitter": "Siddhesh Khandelwal", "authors": "Siddhesh Khandelwal, William Qi, Jagjeet Singh, Andrew Hartnett, Deva\n  Ramanan", "title": "What-If Motion Prediction for Autonomous Driving", "comments": "16 pages, 6 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the long-term future motion of road actors is a core challenge to\nthe deployment of safe autonomous vehicles (AVs). Viable solutions must account\nfor both the static geometric context, such as road lanes, and dynamic social\ninteractions arising from multiple actors. While recent deep architectures have\nachieved state-of-the-art performance on distance-based forecasting metrics,\nthese approaches produce forecasts that are predicted without regard to the\nAV's intended motion plan. In contrast, we propose a recurrent graph-based\nattentional approach with interpretable geometric (actor-lane) and social\n(actor-actor) relationships that supports the injection of counterfactual\ngeometric goals and social contexts. Our model can produce diverse predictions\nconditioned on hypothetical or \"what-if\" road lanes and multi-actor\ninteractions. We show that such an approach could be used in the planning loop\nto reason about unobserved causes or unlikely futures that are directly\nrelevant to the AV's intended route.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:49:30 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Khandelwal", "Siddhesh", ""], ["Qi", "William", ""], ["Singh", "Jagjeet", ""], ["Hartnett", "Andrew", ""], ["Ramanan", "Deva", ""]]}, {"id": "2008.10653", "submitter": "Liu Yang", "authors": "Xiaoli Chen, Liu Yang, Jinqiao Duan, George Em Karniadakis", "title": "Solving Inverse Stochastic Problems from Discrete Particle Observations\n  Using the Fokker-Planck Equation and Physics-informed Neural Networks", "comments": "The first two authors contributed equally to this paper.\n  Corresponding author: George Em Karniadakis", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fokker-Planck (FP) equation governing the evolution of the probability\ndensity function (PDF) is applicable to many disciplines but it requires\nspecification of the coefficients for each case, which can be functions of\nspace-time and not just constants, hence requiring the development of a\ndata-driven modeling approach. When the data available is directly on the PDF,\nthen there exist methods for inverse problems that can be employed to infer the\ncoefficients and thus determine the FP equation and subsequently obtain its\nsolution. Herein, we address a more realistic scenario, where only sparse data\nare given on the particles' positions at a few time instants, which are not\nsufficient to accurately construct directly the PDF even at those times from\nexisting methods, e.g., kernel estimation algorithms. To this end, we develop a\ngeneral framework based on physics-informed neural networks (PINNs) that\nintroduces a new loss function using the Kullback-Leibler divergence to connect\nthe stochastic samples with the FP equation, to simultaneously learn the\nequation and infer the multi-dimensional PDF at all times. In particular, we\nconsider two types of inverse problems, type I where the FP equation is known\nbut the initial PDF is unknown, and type II in which, in addition to unknown\ninitial PDF, the drift and diffusion terms are also unknown. In both cases, we\ninvestigate problems with either Brownian or Levy noise or a combination of\nboth. We demonstrate the new PINN framework in detail in the one-dimensional\ncase (1D) but we also provide results for up to 5D demonstrating that we can\ninfer both the FP equation and} dynamics simultaneously at all times with high\naccuracy using only very few discrete observations of the particles.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 18:51:56 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Chen", "Xiaoli", ""], ["Yang", "Liu", ""], ["Duan", "Jinqiao", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2008.10766", "submitter": "Dong Lao", "authors": "Dong Lao, Peihao Zhu, Peter Wonka, Ganesh Sundaramoorthi", "title": "Channel-Directed Gradients for Optimization of Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce optimization methods for convolutional neural networks that can\nbe used to improve existing gradient-based optimization in terms of\ngeneralization error. The method requires only simple processing of existing\nstochastic gradients, can be used in conjunction with any optimizer, and has\nonly a linear overhead (in the number of parameters) compared to computation of\nthe stochastic gradient. The method works by computing the gradient of the loss\nfunction with respect to output-channel directed re-weighted L2 or Sobolev\nmetrics, which has the effect of smoothing components of the gradient across a\ncertain direction of the parameter tensor. We show that defining the gradients\nalong the output channel direction leads to a performance boost, while other\ndirections can be detrimental. We present the continuum theory of such\ngradients, its discretization, and application to deep networks. Experiments on\nbenchmark datasets, several networks and baseline optimizers show that\noptimizers can be improved in generalization error by simply computing the\nstochastic gradient with respect to output-channel directed metrics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 00:44:09 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lao", "Dong", ""], ["Zhu", "Peihao", ""], ["Wonka", "Peter", ""], ["Sundaramoorthi", "Ganesh", ""]]}, {"id": "2008.10769", "submitter": "Chiwoo Park", "authors": "Chiwoo Park, David J. Borth, Nicholas S. Wilson and Chad N. Hunter", "title": "Variable selection for Gaussian process regression through a sparse\n  projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new variable selection approach integrated with\nGaussian process (GP) regression. We consider a sparse projection of input\nvariables and a general stationary covariance model that depends on the\nEuclidean distance between the projected features. The sparse projection matrix\nis considered as an unknown parameter. We propose a forward stagewise approach\nwith embedded gradient descent steps to co-optimize the parameter with other\ncovariance parameters based on the maximization of a non-convex marginal\nlikelihood function with a concave sparsity penalty, and some convergence\nproperties of the algorithm are provided. The proposed model covers a broader\nclass of stationary covariance functions than the existing automatic relevance\ndetermination approaches, and the solution approach is more computationally\nfeasible than the existing MCMC sampling procedures for the automatic relevance\nparameter estimation with a sparsity prior. The approach is evaluated for a\nlarge number of simulated scenarios. The choice of tuning parameters and the\naccuracy of the parameter estimation are evaluated with the simulation study.\nIn the comparison to some chosen benchmark approaches, the proposed approach\nhas provided a better accuracy in the variable selection. It is applied to an\nimportant problem of identifying environmental factors that affect an\natmospheric corrosion of metal alloys.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:06:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Park", "Chiwoo", ""], ["Borth", "David J.", ""], ["Wilson", "Nicholas S.", ""], ["Hunter", "Chad N.", ""]]}, {"id": "2008.10781", "submitter": "Burak Aksar", "authors": "Emre Ates, Burak Aksar, Vitus J. Leung, Ayse K. Coskun", "title": "Counterfactual Explanations for Machine Learning on Multivariate Time\n  Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying machine learning (ML) on multivariate time series data has growing\npopularity in many application domains, including in computer system\nmanagement. For example, recent high performance computing (HPC) research\nproposes a variety of ML frameworks that use system telemetry data in the form\nof multivariate time series so as to detect performance variations, perform\nintelligent scheduling or node allocation, and improve system security. Common\nbarriers for adoption for these ML frameworks include the lack of user trust\nand the difficulty of debugging. These barriers need to be overcome to enable\nthe widespread adoption of ML frameworks in production systems. To address this\nchallenge, this paper proposes a novel explainability technique for providing\ncounterfactual explanations for supervised ML frameworks that use multivariate\ntime series data. The proposed method outperforms state-of-the-art\nexplainability methods on several different ML frameworks and data sets in\nmetrics such as faithfulness and robustness. The paper also demonstrates how\nthe proposed method can be used to debug ML frameworks and gain a better\nunderstanding of HPC system telemetry data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:04:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ates", "Emre", ""], ["Aksar", "Burak", ""], ["Leung", "Vitus J.", ""], ["Coskun", "Ayse K.", ""]]}, {"id": "2008.10797", "submitter": "Susan Wei", "authors": "Susan Wei, Marc Niethammer", "title": "The Fairness-Accuracy Pareto Front", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating bias in machine learning is a challenging task, due in large part\nto the presence of competing objectives. Namely, a fair algorithm often comes\nat the cost of lower predictive accuracy, and vice versa, a highly predictive\nalgorithm may be one that incurs high bias. This work presents a methodology\nfor estimating the fairness-accuracy Pareto front of a fully-connected\nfeedforward neural network, for any accuracy measure and any fairness measure.\nOur experiments firstly reveal that for training data already exhibiting\ndisparities, a newly introduced causal notion of fairness may be capable of\ntraversing a greater part of the fairness-accuracy space, relative to more\nstandard measures such as demographic parity and conditional parity. The\nexperiments also reveal that tools from multi-objective optimisation are\ncrucial in efficiently estimating the Pareto front (i.e., by finding more\nnon-dominated points), relative to other sensible but ad-hoc approaches.\nFinally, the work serves to highlight possible synergy between deep learning\nand multi-objective optimisation. Given that deep learning is increasingly\ndeployed in real-world decision making, the Pareto front can provide a formal\nway to reason about inherent conflicts.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 03:32:15 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wei", "Susan", ""], ["Niethammer", "Marc", ""]]}, {"id": "2008.10805", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Wei Chen, Radu Marculescu", "title": "New Directions in Distributed Deep Learning: Bringing the Network at\n  Forefront of IoT Design", "comments": "This preprint is for personal use only. The official article will\n  appear in proceedings of Design Automation Conference (DAC), 2020. This work\n  was presented at the DAC 2020 special session on Edge-to-Cloud Neural\n  Networks for Machine Learning Applications in Future IoT Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first highlight three major challenges to large-scale\nadoption of deep learning at the edge: (i) Hardware-constrained IoT devices,\n(ii) Data security and privacy in the IoT era, and (iii) Lack of network-aware\ndeep learning algorithms for distributed inference across multiple IoT devices.\nWe then provide a unified view targeting three research directions that\nnaturally emerge from the above challenges: (1) Federated learning for training\ndeep networks, (2) Data-independent deployment of learning algorithms, and (3)\nCommunication-aware distributed inference. We believe that the above research\ndirections need a network-centric approach to enable the edge intelligence and,\ntherefore, fully exploit the true potential of IoT.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:08:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Chen", "Wei", ""], ["Marculescu", "Radu", ""]]}, {"id": "2008.10806", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu and Takamitsu Matsubara", "title": "Ensuring Monotonic Policy Improvement in Entropy-regularized Value-based\n  Reinforcement Learning", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to establish an entropy-regularized value-based reinforcement\nlearning method that can ensure the monotonic improvement of policies at each\npolicy update. Unlike previously proposed lower-bounds on policy improvement in\ngeneral infinite-horizon MDPs, we derive an entropy-regularization aware lower\nbound. Since our bound only requires the expected policy advantage function to\nbe estimated, it is scalable to large-scale (continuous) state-space problems.\nWe propose a novel reinforcement learning algorithm that exploits this\nlower-bound as a criterion for adjusting the degree of a policy update for\nalleviating policy oscillation. We demonstrate the effectiveness of our\napproach in both discrete-state maze and continuous-state inverted pendulum\ntasks using a linear function approximator for value estimation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:09:18 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhu", "Lingwei", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2008.10838", "submitter": "Yan Kang", "authors": "Yan Kang, Yang Liu, Tianjian Chen", "title": "FedMVT: Semi-supervised Vertical Federated Learning with MultiView\n  Training", "comments": "International Workshop on Federated Learning for User Privacy and\n  Data Confidentiality in Conjunction with IJCAI 2020 (FL-IJCAI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows many parties to collaboratively build a model\nwithout exposing data. Particularly, vertical federated learning (VFL) enables\nparties to build a robust shared machine learning model based upon distributed\nfeatures about the same samples. However, VFL requires all parties to share a\nsufficient amount of overlapping samples. In reality, the set of overlapping\nsamples may be small, leaving the majority of the non-overlapping data\nunutilized. In this paper, we propose Federated Multi-View Training (FedMVT), a\nsemi-supervised learning approach that improves the performance of VFL with\nlimited overlapping samples. FedMVT estimates representations for missing\nfeatures and predicts pseudo-labels for unlabeled samples to expand training\nset, and trains three classifiers jointly based upon different views of the\ninput to improve model's representation learning. FedMVT does not require\nparties to share their original data and model parameters, thus preserving data\nprivacy. We conduct experiments on the NUS-WIDE and the CIFAR10. The\nexperimental results demonstrate that FedMVT significantly outperforms vanilla\nVFL that only utilizes overlapping samples, and improves the performance of the\nlocal model in the party that owns labels.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:20:31 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kang", "Yan", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""]]}, {"id": "2008.10845", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "CnGAN: Generative Adversarial Networks for Cross-network user preference\n  generation for non-overlapped users", "comments": null, "journal-ref": "The World Wide Web Conference, 2019 (WWW'19)", "doi": "10.1145/3308558.3313733", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major drawback of cross-network recommender solutions is that they can only\nbe applied to users that are overlapped across networks. Thus, the\nnon-overlapped users, which form the majority of users are ignored. As a\nsolution, we propose CnGAN, a novel multi-task learning based,\nencoder-GAN-recommender architecture. The proposed model synthetically\ngenerates source network user preferences for non-overlapped users by learning\nthe mapping from target to source network preference manifolds. The resultant\nuser preferences are used in a Siamese network based neural recommender\narchitecture. Furthermore, we propose a novel user based pairwise loss function\nfor recommendations using implicit interactions to better guide the generation\nprocess in the multi-task learning environment.We illustrate our solution by\ngenerating user preferences on the Twitter source network for recommendations\non the YouTube target network. Extensive experiments show that the generated\npreferences can be used to improve recommendations for non-overlapped users.\nThe resultant recommendations achieve superior performance compared to the\nstate-of-the-art cross-network recommender solutions in terms of accuracy,\nnovelty and diversity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:47:44 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10849", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "LSTM Networks for Online Cross-Network Recommendations", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence, 2018\n  (IJCAI-18)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-network recommender systems use auxiliary information from multiple\nsource networks to create holistic user profiles and improve recommendations in\na target network. However, we find two major limitations in existing\ncross-network solutions that reduce overall recommender performance. Existing\nmodels (1) fail to capture complex non-linear relationships in user\ninteractions, and (2) are designed for offline settings hence, not updated\nonline with incoming interactions to capture the dynamics in the recommender\nenvironment. We propose a novel multi-layered Long Short-Term Memory (LSTM)\nnetwork based online solution to mitigate these issues. The proposed model\ncontains three main extensions to the standard LSTM: First, an attention gated\nmechanism to capture long-term user preference changes. Second, a higher order\ninteraction layer to alleviate data sparsity. Third, time aware LSTM cell gates\nto capture irregular time intervals between user interactions. We illustrate\nour solution using auxiliary information from Twitter and Google Plus to\nimprove recommendations on YouTube. Extensive experiments show that the\nproposed model consistently outperforms state-of-the-art in terms of accuracy,\ndiversity and novelty.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:10:24 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 09:34:10 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10857", "submitter": "Carlo Ciliberto", "authors": "Giulia Denevi, Massimiliano Pontil, Carlo Ciliberto", "title": "The Advantage of Conditional Meta-Learning for Biased Regularization and\n  Fine-Tuning", "comments": "34 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biased regularization and fine-tuning are two recent meta-learning\napproaches. They have been shown to be effective to tackle distributions of\ntasks, in which the tasks' target vectors are all close to a common\nmeta-parameter vector. However, these methods may perform poorly on\nheterogeneous environments of tasks, where the complexity of the tasks'\ndistribution cannot be captured by a single meta-parameter vector. We address\nthis limitation by conditional meta-learning, inferring a conditioning function\nmapping task's side information into a meta-parameter vector that is\nappropriate for that task at hand. We characterize properties of the\nenvironment under which the conditional approach brings a substantial advantage\nover standard meta-learning and we highlight examples of environments, such as\nthose with multiple clusters, satisfying these properties. We then propose a\nconvex meta-algorithm providing a comparable advantage also in practice.\nNumerical experiments confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:32:16 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Denevi", "Giulia", ""], ["Pontil", "Massimiliano", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2008.10858", "submitter": "Saadullah Amin", "authors": "Saadullah Amin, Stalin Varanasi, Katherine Ann Dunfield, G\\\"unter\n  Neumann", "title": "LowFER: Low-rank Bilinear Pooling for Link Prediction", "comments": "Accepted by ICML'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are incomplete by nature, with only a limited number of\nobserved facts from the world knowledge being represented as structured\nrelations between entities. To partly address this issue, an important task in\nstatistical relational learning is that of link prediction or knowledge graph\ncompletion. Both linear and non-linear models have been proposed to solve the\nproblem. Bilinear models, while expressive, are prone to overfitting and lead\nto quadratic growth of parameters in number of relations. Simpler models have\nbecome more standard, with certain constraints on bilinear map as relation\nparameters. In this work, we propose a factorized bilinear pooling model,\ncommonly used in multi-modal learning, for better fusion of entities and\nrelations, leading to an efficient and constraint-free model. We prove that our\nmodel is fully expressive, providing bounds on the embedding dimensionality and\nfactorization rank. Our model naturally generalizes Tucker decomposition based\nTuckER model, which has been shown to generalize other models, as efficient\nlow-rank approximation without substantially compromising the performance. Due\nto low-rank approximation, the model complexity can be controlled by the\nfactorization rank, avoiding the possible cubic growth of TuckER. Empirically,\nwe evaluate on real-world datasets, reaching on par or state-of-the-art\nperformance. At extreme low-ranks, model preserves the performance while\nstaying parameter efficient.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:33:52 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Amin", "Saadullah", ""], ["Varanasi", "Stalin", ""], ["Dunfield", "Katherine Ann", ""], ["Neumann", "G\u00fcnter", ""]]}, {"id": "2008.10861", "submitter": "Taisuke Kobayashi", "authors": "Taisuke Kobayashi and Wendyam Eric Lionel Ilboudo", "title": "t-Soft Update of Target Network for Deep Reinforcement Learning", "comments": "11 pages, 7 figures", "journal-ref": "Neural Networks, 2021", "doi": "10.1016/j.neunet.2020.12.023", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new robust update rule of target network for deep\nreinforcement learning (DRL), to replace the conventional update rule, given as\nan exponential moving average. The target network is for smoothly generating\nthe reference signals for a main network in DRL, thereby reducing learning\nvariance. The problem with its conventional update rule is the fact that all\nthe parameters are smoothly copied with the same speed from the main network,\neven when some of them are trying to update toward the wrong directions. This\nbehavior increases the risk of generating the wrong reference signals. Although\nslowing down the overall update speed is a naive way to mitigate wrong updates,\nit would decrease learning speed. To robustly update the parameters while\nkeeping learning speed, a t-soft update method, which is inspired by student-t\ndistribution, is derived with reference to the analogy between the exponential\nmoving average and the normal distribution. Through the analysis of the derived\nt-soft update, we show that it takes over the properties of the student-t\ndistribution. Specifically, with a heavy-tailed property of the student-t\ndistribution, the t-soft update automatically excludes extreme updates that\ndiffer from past experiences. In addition, when the updates are similar to the\npast experiences, it can mitigate the learning delay by increasing the amount\nof updates. In PyBullet robotics simulations for DRL, an online actor-critic\nalgorithm with the t-soft update outperformed the conventional methods in terms\nof the obtained return and/or its variance. From the training process by the\nt-soft update, we found that the t-soft update is globally consistent with the\nstandard soft update, and the update rates are locally adjusted for\nacceleration or suppression.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:41:47 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 01:56:12 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Kobayashi", "Taisuke", ""], ["Ilboudo", "Wendyam Eric Lionel", ""]]}, {"id": "2008.10863", "submitter": "Jan Neerbek", "authors": "Jan Neerbek", "title": "Sensitive Information Detection: Recursive Neural Networks for Encoding\n  Context", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of data for processing and categorization grows at an ever\nincreasing rate. At the same time the demand for collaboration and transparency\nin organizations, government and businesses, drives the release of data from\ninternal repositories to the public or 3rd party domain. This in turn increase\nthe potential of sharing sensitive information. The leak of sensitive\ninformation can potentially be very costly, both financially for organizations,\nbut also for individuals. In this work we address the important problem of\nsensitive information detection. Specially we focus on detection in\nunstructured text documents.\n  We show that simplistic, brittle rule sets for detecting sensitive\ninformation only find a small fraction of the actual sensitive information.\nFurthermore we show that previous state-of-the-art approaches have been\nimplicitly tailored to such simplistic scenarios and thus fail to detect actual\nsensitive content. We develop a novel family of sensitive information detection\napproaches which only assumes access to labeled examples, rather than\nunrealistic assumptions such as access to a set of generating rules or\ndescriptive topical seed words. Our approaches are inspired by the current\nstate-of-the-art for paraphrase detection and we adapt deep learning approaches\nover recursive neural networks to the problem of sensitive information\ndetection. We show that our context-based approaches significantly outperforms\nthe family of previous state-of-the-art approaches for sensitive information\ndetection, so-called keyword-based approaches, on real-world data and with\nhuman labeled examples of sensitive and non-sensitive documents.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:49:46 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Neerbek", "Jan", ""]]}, {"id": "2008.10866", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "Exploring the use of Time-Dependent Cross-Network Information for\n  Personalized Recommendations", "comments": null, "journal-ref": "ACM Multimedia 2017, (MM'17)", "doi": "10.1145/3123266.3123447", "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overwhelming volume and complexity of information in online applications\nmake recommendation essential for users to find information of interest.\nHowever, two major limitations that coexist in real world applications (1)\nincomplete user profiles, and (2) the dynamic nature of user preferences\ncontinue to degrade recommender quality in aspects such as timeliness,\naccuracy, diversity and novelty. To address both the above limitations in a\nsingle solution, we propose a novel cross-network time aware recommender\nsolution. The solution first learns historical user models in the target\nnetwork by aggregating user preferences from multiple source networks. Second,\nuser level time aware latent factors are learnt to develop current user models\nfrom the historical models and conduct timely recommendations. We illustrate\nour solution by using auxiliary information from the Twitter source network to\nimprove recommendations for the YouTube target network. Experiments conducted\nusing multiple time aware and cross-network baselines under different time\ngranularities show that the proposed solution achieves superior performance in\nterms of accuracy, novelty and diversity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:52:47 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10870", "submitter": "Arunselvan Ramaswamy Dr.", "authors": "Arunselvan Ramaswamy, Eyke H\\\"ullermeier", "title": "Deep Q-Learning: Theoretical Insights from an Asymptotic Analysis", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning is an important reinforcement learning algorithm, which\ninvolves training a deep neural network, called Deep Q-Network (DQN), to\napproximate the well-known Q-function. Although wildly successful under\nlaboratory conditions, serious gaps between theory and practice as well as a\nlack of formal guarantees prevent its use in the real world. Adopting a\ndynamical systems perspective, we provide a theoretical analysis of a popular\nversion of Deep Q-Learning under realistic and verifiable assumptions. More\nspecifically, we prove an important result on the convergence of the algorithm,\ncharacterizing the asymptotic behavior of the learning process. Our result\nsheds light on hitherto unexplained properties of the algorithm and helps\nunderstand empirical observations, such as performance inconsistencies even\nafter training. Unlike previous theories, our analysis accommodates state\nMarkov processes with multiple stationary distributions. In spite of the focus\non Deep Q-Learning, we believe that our theory may be applied to understand\nother deep learning algorithms\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:59:20 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 08:53:38 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ramaswamy", "Arunselvan", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2008.10880", "submitter": "Rik Helwegen MSc", "authors": "Rik Helwegen, Christos Louizos and Patrick Forr\\'e", "title": "Improving Fair Predictions Using Variational Inference In Causal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of algorithmic fairness grows with the increasing impact\nmachine learning has on people's lives. Recent work on fairness metrics shows\nthe need for causal reasoning in fairness constraints. In this work, a\npractical method named FairTrade is proposed for creating flexible prediction\nmodels which integrate fairness constraints on sensitive causal paths. The\nmethod uses recent advances in variational inference in order to account for\nunobserved confounders. Further, a method outline is proposed which uses the\ncausal mechanism estimates to audit black box models. Experiments are conducted\non simulated data and on a real dataset in the context of detecting unlawful\nsocial welfare. This research aims to contribute to machine learning techniques\nwhich honour our ethical and legal boundaries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:27:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Helwegen", "Rik", ""], ["Louizos", "Christos", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2008.10898", "submitter": "Zhize Li", "authors": "Zhize Li, Hongyan Bao, Xiangliang Zhang, Peter Richt\\'arik", "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for\n  Nonconvex Optimization", "comments": "25 pages; accepted by ICML 2021 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel stochastic gradient estimator --\nProbAbilistic Gradient Estimator (PAGE) -- for nonconvex optimization. PAGE is\neasy to implement as it is designed via a small adjustment to vanilla SGD: in\neach iteration, PAGE uses the vanilla minibatch SGD update with probability\n$p_t$ or reuses the previous gradient with a small adjustment, at a much lower\ncomputational cost, with probability $1-p_t$. We give a simple formula for the\noptimal choice of $p_t$. Moreover, we prove the first tight lower bound\n$\\Omega(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ for nonconvex finite-sum problems,\nwhich also leads to a tight lower bound $\\Omega(b+\\frac{\\sqrt{b}}{\\epsilon^2})$\nfor nonconvex online problems, where $b:= \\min\\{\\frac{\\sigma^2}{\\epsilon^2},\nn\\}$. Then, we show that PAGE obtains the optimal convergence results\n$O(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ (finite-sum) and\n$O(b+\\frac{\\sqrt{b}}{\\epsilon^2})$ (online) matching our lower bounds for both\nnonconvex finite-sum and online problems. Besides, we also show that for\nnonconvex functions satisfying the Polyak-\\L{}ojasiewicz (PL) condition, PAGE\ncan automatically switch to a faster linear convergence rate $O(\\cdot\\log\n\\frac{1}{\\epsilon})$. Finally, we conduct several deep learning experiments\n(e.g., LeNet, VGG, ResNet) on real datasets in PyTorch showing that PAGE not\nonly converges much faster than SGD in training but also achieves the higher\ntest accuracy, validating the optimal theoretical results and confirming the\npractical superiority of PAGE.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:11:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 18:25:41 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 21:37:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Zhize", ""], ["Bao", "Hongyan", ""], ["Zhang", "Xiangliang", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2008.10936", "submitter": "Tom Beer", "authors": "Tom Beer, Bar Eini-Porat, Sebastian Goodfellow, Danny Eytan and Uri\n  Shalit", "title": "Using Deep Networks for Scientific Discovery in Physiological Signals", "comments": "2020 Machine Learning for Healthcare Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have shown remarkable success in the\nclassification of physiological signals. In this study we propose a method for\nexamining to what extent does a DNN's performance rely on rediscovering\nexisting features of the signals, as opposed to discovering genuinely new\nfeatures. Moreover, we offer a novel method of \"removing\" a hand-engineered\nfeature from the network's hypothesis space, thus forcing it to try and learn\nrepresentations which are different from known ones, as a method of scientific\nexploration. We then build on existing work in the field of interpretability,\nspecifically class activation maps, to try and infer what new features the\nnetwork has learned. We demonstrate this approach using ECG and EEG signals.\nWith respect to ECG signals we show that for the specific task of classifying\natrial fibrillation, DNNs are likely rediscovering known features. We also show\nhow our method could be used to discover new features, by selectively removing\nsome ECG features and \"rediscovering\" them. We further examine how could our\nmethod be used as a tool for examining scientific hypotheses. We simulate this\nscenario by looking into the importance of eye movements in classifying sleep\nfrom EEG. We show that our tool can successfully focus a researcher's attention\nby bringing to light patterns in the data that would be hidden otherwise.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 10:55:25 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Beer", "Tom", ""], ["Eini-Porat", "Bar", ""], ["Goodfellow", "Sebastian", ""], ["Eytan", "Danny", ""], ["Shalit", "Uri", ""]]}, {"id": "2008.10982", "submitter": "Esa Ollila", "authors": "Esa Ollila and Ammar Mian", "title": "Block-wise Minimization-Majorization algorithm for Huber's criterion:\n  sparse learning and applications", "comments": "To appear in International Workshop on Machine Learning for Signal\n  Processing (MLSP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huber's criterion can be used for robust joint estimation of regression and\nscale parameters in the linear model. Huber's (Huber, 1981) motivation for\nintroducing the criterion stemmed from non-convexity of the joint maximum\nlikelihood objective function as well as non-robustness (unbounded influence\nfunction) of the associated ML-estimate of scale. In this paper, we illustrate\nhow the original algorithm proposed by Huber can be set within the block-wise\nminimization majorization framework. In addition, we propose novel\ndata-adaptive step sizes for both the location and scale, which are further\nimproving the convergence. We then illustrate how Huber's criterion can be used\nfor sparse learning of underdetermined linear model using the iterative hard\nthresholding approach. We illustrate the usefulness of the algorithms in an\nimage denoising application and simulation studies.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:18:07 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ollila", "Esa", ""], ["Mian", "Ammar", ""]]}, {"id": "2008.11036", "submitter": "Ananda Theertha Suresh", "authors": "Corinna Cortes and Mehryar Mohri and Ananda Theertha Suresh and\n  Ningshan Zhang", "title": "A Discriminative Technique for Multiple-Source Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new discriminative technique for the multiple-source adaptation,\nMSA, problem. Unlike previous work, which relies on density estimation for each\nsource domain, our solution only requires conditional probabilities that can\neasily be accurately estimated from unlabeled data from the source domains. We\ngive a detailed analysis of our new technique, including general guarantees\nbased on R\\'enyi divergences, and learning bounds when conditional Maxent is\nused for estimating conditional probabilities for a point to belong to a source\ndomain. We show that these guarantees compare favorably to those that can be\nderived for the generative solution, using kernel density estimation. Our\nexperiments with real-world applications further demonstrate that our new\ndiscriminative MSA algorithm outperforms the previous generative solution as\nwell as other domain adaptation baselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:06:15 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:39:58 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Suresh", "Ananda Theertha", ""], ["Zhang", "Ningshan", ""]]}, {"id": "2008.11037", "submitter": "Jiawei Ren", "authors": "Jiawei Ren, Cunjun Yu, Zhongang Cai, Haiyu Zhao", "title": "Balanced Activation for Long-tailed Visual Recognition", "comments": "LVIS Challenge Workshop at ECCV 2020 Spotlight. arXiv admin note:\n  substantial text overlap with arXiv:2007.10740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep classifiers have achieved great success in visual recognition. However,\nreal-world data is long-tailed by nature, leading to the mismatch between\ntraining and testing distributions. In this report, we introduce Balanced\nActivation (Balanced Softmax and Balanced Sigmoid), an elegant unbiased, and\nsimple extension of Sigmoid and Softmax activation function, to accommodate the\nlabel distribution shift between training and testing in object detection. We\nderive the generalization bound for multiclass Softmax regression and show our\nloss minimizes the bound. In our experiments, we demonstrate that Balanced\nActivation generally provides ~3% gain in terms of mAP on LVIS-1.0 and\noutperforms the current state-of-the-art methods without introducing any extra\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:36:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ren", "Jiawei", ""], ["Yu", "Cunjun", ""], ["Cai", "Zhongang", ""], ["Zhao", "Haiyu", ""]]}, {"id": "2008.11062", "submitter": "Haotao Wang", "authors": "Haotao Wang, Shupeng Gui, Haichuan Yang, Ji Liu, Zhangyang Wang", "title": "GAN Slimming: All-in-One GAN Compression by A Unified Optimization\n  Framework", "comments": "ECCV 2020 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have gained increasing popularity in\nvarious computer vision applications, and recently start to be deployed to\nresource-constrained mobile devices. Similar to other deep models,\nstate-of-the-art GANs suffer from high parameter complexities. That has\nrecently motivated the exploration of compressing GANs (usually generators).\nCompared to the vast literature and prevailing success in compressing deep\nclassifiers, the study of GAN compression remains in its infancy, so far\nleveraging individual compression techniques instead of more sophisticated\ncombinations. We observe that due to the notorious instability of training\nGANs, heuristically stacking different compression techniques will result in\nunsatisfactory results. To this end, we propose the first unified optimization\nframework combining multiple compression means for GAN compression, dubbed GAN\nSlimming (GS). GS seamlessly integrates three mainstream compression\ntechniques: model distillation, channel pruning and quantization, together with\nthe GAN minimax objective, into one unified optimization form, that can be\nefficiently optimized from end to end. Without bells and whistles, GS largely\noutperforms existing options in compressing image-to-image translation GANs.\nSpecifically, we apply GS to compress CartoonGAN, a state-of-the-art style\ntransfer network, by up to 47 times, with minimal visual quality degradation.\nCodes and pre-trained models can be found at\nhttps://github.com/TAMU-VITA/GAN-Slimming.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:39:42 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Haotao", ""], ["Gui", "Shupeng", ""], ["Yang", "Haichuan", ""], ["Liu", "Ji", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2008.11087", "submitter": "Chuheng Zhang", "authors": "Wei Shen, Xiaonan He, Chuheng Zhang, Qiang Ni, Wanchun Dou, Yan Wang", "title": "Auxiliary-task Based Deep Reinforcement Learning for Participant\n  Selection Problem in Mobile Crowdsourcing", "comments": "Accepted by CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411913", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile crowdsourcing (MCS), the platform selects participants to complete\nlocation-aware tasks from the recruiters aiming to achieve multiple goals\n(e.g., profit maximization, energy efficiency, and fairness). However,\ndifferent MCS systems have different goals and there are possibly conflicting\ngoals even in one MCS system. Therefore, it is crucial to design a participant\nselection algorithm that applies to different MCS systems to achieve multiple\ngoals. To deal with this issue, we formulate the participant selection problem\nas a reinforcement learning problem and propose to solve it with a novel\nmethod, which we call auxiliary-task based deep reinforcement learning (ADRL).\nWe use transformers to extract representations from the context of the MCS\nsystem and a pointer network to deal with the combinatorial optimization\nproblem. To improve the sample efficiency, we adopt an auxiliary-task training\nprocess that trains the network to predict the imminent tasks from the\nrecruiters, which facilitates the embedding learning of the deep learning\nmodel. Additionally, we release a simulated environment on a specific MCS task,\nthe ride-sharing task, and conduct extensive performance evaluations in this\nenvironment. The experimental results demonstrate that ADRL outperforms and\nimproves sample efficiency over other well-recognized baselines in various\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:02:54 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 00:55:05 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shen", "Wei", ""], ["He", "Xiaonan", ""], ["Zhang", "Chuheng", ""], ["Ni", "Qiang", ""], ["Dou", "Wanchun", ""], ["Wang", "Yan", ""]]}, {"id": "2008.11089", "submitter": "Yinghua Zhang", "authors": "Yinghua Zhang, Yangqiu Song, Jian Liang, Kun Bai, Qiang Yang", "title": "Two Sides of the Same Coin: White-box and Black-box Attacks for Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403349", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has become a common practice for training deep learning\nmodels with limited labeled data in a target domain. On the other hand, deep\nmodels are vulnerable to adversarial attacks. Though transfer learning has been\nwidely applied, its effect on model robustness is unclear. To figure out this\nproblem, we conduct extensive empirical evaluations to show that fine-tuning\neffectively enhances model robustness under white-box FGSM attacks. We also\npropose a black-box attack method for transfer learning models which attacks\nthe target model with the adversarial examples produced by its source model. To\nsystematically measure the effect of both white-box and black-box attacks, we\npropose a new metric to evaluate how transferable are the adversarial examples\nproduced by a source model to a target model. Empirical results show that the\nadversarial examples are more transferable when fine-tuning is used than they\nare when the two networks are trained independently.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:04:32 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Yinghua", ""], ["Song", "Yangqiu", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Yang", "Qiang", ""]]}, {"id": "2008.11091", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Unconstrained optimisation on Riemannian manifolds", "comments": "29 pages. Some experimental results (on singular cost functions on\n  Euclidean spaces, and on minimum on the closed unit ball in the Euclidean\n  spaces) are given. References updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give explicit descriptions of versions of (Local-)\nBacktracking Gradient Descent and New Q-Newton's method to the Riemannian\nsetting.Here are some easy to state consequences of results in this paper,\nwhere X is a general Riemannian manifold of finite dimension and\n$f:X\\rightarrow \\mathbb{R}$ a $C^2$ function which is Morse (that is, all its\ncritical points are non-degenerate).\n  {\\bf Theorem.} For random choices of the hyperparameters in the Riemanian\nLocal Backtracking Gradient Descent algorithm and for random choices of the\ninitial point $x_0$, the sequence $\\{x_n\\}$ constructed by the algorithm either\n(i) converges to a local minimum of $f$ or (ii) eventually leaves every compact\nsubsets of $X$ (in other words, diverges to infinity on $X$). If $f$ has\ncompact sublevels, then only the former alternative happens. The convergence\nrate is the same as in the classical paper by Armijo.\n  {\\bf Theorem.} Assume that $f$ is $C^3$. For random choices of the\nhyperparametes in the Riemannian New Q-Newton's method, if the sequence\nconstructed by the algorithm converges, then the limit is a critical point of\n$f$. We have a local Stable-Center manifold theorem, near saddle points of $f$,\nfor the dynamical system associated to the algorithm. If the limit point is a\nnon-degenerate minimum point, then the rate of convergence is quadratic. If\nmoreover $X$ is an open subset of a Lie group and the initial point $x_0$ is\nchosen randomly, then we can globally avoid saddle points.\n  As an application, we propose a general method using Riemannian Backtracking\nGD to find minimum of a function on a bounded ball in a Euclidean space, and do\nexplicit calculations for calculating the smallest eigenvalue of a symmetric\nsquare matrix.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:10:21 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 11:00:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2008.11092", "submitter": "Damien Garreau", "authors": "Damien Garreau, Ulrike von Luxburg", "title": "Looking Deeper into Tabular LIME", "comments": "63 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning algorithms is an urgent need. Numerous\nmethods appeared in recent years, but do their explanations make sense? In this\npaper, we present a thorough theoretical analysis of one of these methods,\nLIME, in the case of tabular data. We prove that in the large sample limit, the\ninterpretable coefficients provided by Tabular LIME can be computed in an\nexplicit way as a function of the algorithm parameters and some expectation\ncomputations related to the black-box model. When the function to explain has\nsome nice algebraic structure (linear, multiplicative, or sparsely depending on\na subset of the coordinates), our analysis provides interesting insights into\nthe explanations provided by LIME. These can be applied to a range of machine\nlearning models including Gaussian kernels or CART random forests. As an\nexample, for linear functions we show that LIME has the desirable property to\nprovide explanations that are proportional to the coefficients of the function\nto explain and to ignore coordinates that are not used by the function to\nexplain. For partition-based regressors, on the other side, we show that LIME\nproduces undesired artifacts that may provide misleading explanations.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:10:57 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 09:35:15 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Garreau", "Damien", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "2008.11095", "submitter": "George Wynne", "authors": "George Wynne, Andrew B. Duncan", "title": "A Kernel Two-Sample Test for Functional Data", "comments": "Added to numerics section", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric two-sample test procedure based on Maximum Mean\nDiscrepancy (MMD) for testing the hypothesis that two samples of functions have\nthe same underlying distribution, using kernels defined on function spaces.\nThis construction is motivated by a scaling analysis of the efficiency of\nMMD-based tests for datasets of increasing dimension. Theoretical properties of\nkernels on function spaces and their associated MMD are established and\nemployed to ascertain the efficacy of the newly proposed test, as well as to\nassess the effects of using functional reconstructions based on discretised\nfunction samples. The theoretical results are demonstrated over a range of\nsynthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:19:02 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 12:02:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wynne", "George", ""], ["Duncan", "Andrew B.", ""]]}, {"id": "2008.11117", "submitter": "Jonathan Ashbrock", "authors": "Jonathan Ashbrock, Alexander M. Powell", "title": "Stochastic Markov Gradient Descent and Training Low-Bit Neural Networks", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive size of modern neural networks has motivated substantial recent\ninterest in neural network quantization. We introduce Stochastic Markov\nGradient Descent (SMGD), a discrete optimization method applicable to training\nquantized neural networks. The SMGD algorithm is designed for settings where\nmemory is highly constrained during training. We provide theoretical guarantees\nof algorithm performance as well as encouraging numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:48:15 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 15:48:20 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ashbrock", "Jonathan", ""], ["Powell", "Alexander M.", ""]]}, {"id": "2008.11136", "submitter": "Amine Dadoun", "authors": "Amine Dadoun (1 and 2), Raphael Troncy (1) ((1) Eurecom, (2) Amadeus\n  SAS)", "title": "Many-to-one Recurrent Neural Network for Session-based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the D2KLab team's approach to the RecSys Challenge 2019\nwhich focuses on the task of recommending accommodations based on user\nsessions. What is the feeling of a person who says \"Rooms of the hotel are\nenormous, staff are friendly and efficient\"? It is positive. Similarly to the\nsequence of words in a sentence where one can affirm what the feeling is,\nanalysing a sequence of actions performed by a user in a website can lead to\npredict what will be the item the user will add to his basket at the end of the\nshopping session. We propose to use a many-to-one recurrent neural network that\nlearns the probability that a user will click on an accommodation based on the\nsequence of actions he has performed during his browsing session. More\nspecifically, we combine a rule-based algorithm with a Gated Recurrent Unit RNN\nin order to sort the list of accommodations that is shown to the user. We\noptimized the RNN on a validation set, tuning the hyper-parameters such as the\nlearning rate, the batch-size and the accommodation embedding size. This\nanalogy with the sentiment analysis task gives promising results. However, it\nis computationally demanding in the training phase and it needs to be further\ntuned.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:07:23 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Dadoun", "Amine", "", "1 and 2"], ["Troncy", "Raphael", ""]]}, {"id": "2008.11141", "submitter": "Mohammad Mohammadi Amiri Dr.", "authors": "Mohammad Mohammadi Amiri, Deniz Gunduz, Sanjeev R. Kulkarni, H.\n  Vincent Poor", "title": "Convergence of Federated Learning over a Noisy Downlink", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study federated learning (FL), where power-limited wireless devices\nutilize their local datasets to collaboratively train a global model with the\nhelp of a remote parameter server (PS). The PS has access to the global model\nand shares it with the devices for local training, and the devices return the\nresult of their local updates to the PS to update the global model. This\nframework requires downlink transmission from the PS to the devices and uplink\ntransmission from the devices to the PS. The goal of this study is to\ninvestigate the impact of the bandwidth-limited shared wireless medium in both\nthe downlink and uplink on the performance of FL with a focus on the downlink.\nTo this end, the downlink and uplink channels are modeled as fading broadcast\nand multiple access channels, respectively, both with limited bandwidth. For\ndownlink transmission, we first introduce a digital approach, where a\nquantization technique is employed at the PS to broadcast the global model\nupdate at a common rate such that all the devices can decode it. Next, we\npropose analog downlink transmission, where the global model is broadcast by\nthe PS in an uncoded manner. We consider analog transmission over the uplink in\nboth cases. We further analyze the convergence behavior of the proposed analog\napproach assuming that the uplink transmission is error-free. Numerical\nexperiments show that the analog downlink approach provides significant\nimprovement over the digital one, despite a significantly lower transmit power\nat the PS. The experimental results corroborate the convergence results, and\nshow that a smaller number of local iterations should be used when the data\ndistribution is more biased, and also when the devices have a better estimate\nof the global model in the analog downlink approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:15:05 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Gunduz", "Deniz", ""], ["Kulkarni", "Sanjeev R.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2008.11174", "submitter": "Robin Strudel", "authors": "Robin Strudel, Ricardo Garcia, Justin Carpentier, Jean-Paul Laumond,\n  Ivan Laptev, Cordelia Schmid", "title": "Learning Obstacle Representations for Neural Motion Planning", "comments": "CoRL 2020. See the project webpage at\n  https://www.di.ens.fr/willow/research/nmp_repr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motion planning and obstacle avoidance is a key challenge in robotics\napplications. While previous work succeeds to provide excellent solutions for\nknown environments, sensor-based motion planning in new and dynamic\nenvironments remains difficult. In this work we address sensor-based motion\nplanning from a learning perspective. Motivated by recent advances in visual\nrecognition, we argue the importance of learning appropriate representations\nfor motion planning. We propose a new obstacle representation based on the\nPointNet architecture and train it jointly with policies for obstacle\navoidance. We experimentally evaluate our approach for rigid body motion\nplanning in challenging environments and demonstrate significant improvements\nof the state of the art in terms of accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:12:32 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 16:51:26 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 15:58:40 GMT"}, {"version": "v4", "created": "Sat, 7 Nov 2020 11:30:09 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Strudel", "Robin", ""], ["Garcia", "Ricardo", ""], ["Carpentier", "Justin", ""], ["Laumond", "Jean-Paul", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2008.11193", "submitter": "Tijana Zrnic", "authors": "Vitaly Feldman and Tijana Zrnic", "title": "Individual Privacy Accounting via a Renyi Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential setting in which a single dataset of individuals is\nused to perform adaptively-chosen analyses, while ensuring that the\ndifferential privacy loss of each participant does not exceed a pre-specified\nprivacy budget. The standard approach to this problem relies on bounding a\nworst-case estimate of the privacy loss over all individuals and all possible\nvalues of their data, for every single analysis. Yet, in many scenarios this\napproach is overly conservative, especially for \"typical\" data points which\nincur little privacy loss by participation in most of the analyses. In this\nwork, we give a method for tighter privacy loss accounting based on the value\nof a personalized privacy loss estimate for each individual in each analysis.\nTo implement the accounting method we design a filter for R\\'enyi differential\nprivacy. A filter is a tool that ensures that the privacy parameter of a\ncomposed sequence of algorithms with adaptively-chosen privacy parameters does\nnot exceed a pre-specified budget. Our filter is simpler and tighter than the\nknown filter for $(\\epsilon,\\delta)$-differential privacy by Rogers et al. We\napply our results to the analysis of noisy gradient descent and show that\npersonalized accounting can be practical, easy to implement, and can only make\nthe privacy-utility tradeoff tighter.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:49:48 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 15:02:45 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 15:34:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Feldman", "Vitaly", ""], ["Zrnic", "Tijana", ""]]}, {"id": "2008.11245", "submitter": "Sam Buchanan", "authors": "Sam Buchanan, Dar Gilboa, John Wright", "title": "Deep Networks and the Multiple Manifold Problem", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multiple manifold problem, a binary classification task modeled\non applications in machine vision, in which a deep fully-connected neural\nnetwork is trained to separate two low-dimensional submanifolds of the unit\nsphere. We provide an analysis of the one-dimensional case, proving for a\nsimple manifold configuration that when the network depth $L$ is large relative\nto certain geometric and statistical properties of the data, the network width\n$n$ grows as a sufficiently large polynomial in $L$, and the number of i.i.d.\nsamples from the manifolds is polynomial in $L$, randomly-initialized gradient\ndescent rapidly learns to classify the two manifolds perfectly with high\nprobability. Our analysis demonstrates concrete benefits of depth and width in\nthe context of a practically-motivated model problem: the depth acts as a\nfitting resource, with larger depths corresponding to smoother networks that\ncan more readily separate the class manifolds, and the width acts as a\nstatistical resource, enabling concentration of the randomly-initialized\nnetwork and its gradients. The argument centers around the neural tangent\nkernel and its role in the nonasymptotic analysis of training overparameterized\nneural networks; to this literature, we contribute essentially optimal rates of\nconcentration for the neural tangent kernel of deep fully-connected networks,\nrequiring width $n \\gtrsim L\\,\\mathrm{poly}(d_0)$ to achieve uniform\nconcentration of the initial kernel over a $d_0$-dimensional submanifold of the\nunit sphere $\\mathbb{S}^{n_0-1}$, and a nonasymptotic framework for\nestablishing generalization of networks trained in the NTK regime with\nstructured data. The proof makes heavy use of martingale concentration to\noptimally treat statistical dependencies across layers of the initial random\nnetwork. This approach should be of use in establishing similar results for\nother network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 19:20:00 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 06:55:39 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Buchanan", "Sam", ""], ["Gilboa", "Dar", ""], ["Wright", "John", ""]]}, {"id": "2008.11249", "submitter": "Elena Khusainova", "authors": "Elena Khusainova, Emily Dodwell, Ritwik Mitra", "title": "SOAR: Simultaneous Or of And Rules for Classification of Positive &\n  Negative Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic decision making has proliferated and now impacts our daily lives\nin both mundane and consequential ways. Machine learning practitioners make use\nof a myriad of algorithms for predictive models in applications as diverse as\nmovie recommendations, medical diagnoses, and parole recommendations without\ndelving into the reasons driving specific predictive decisions. Machine\nlearning algorithms in such applications are often chosen for their superior\nperformance, however popular choices such as random forest and deep neural\nnetworks fail to provide an interpretable understanding of the predictive\nmodel. In recent years, rule-based algorithms have been used to address this\nissue. Wang et al. (2017) presented an or-of-and (disjunctive normal form)\nbased classification technique that allows for classification rule mining of a\nsingle class in a binary classification; this method is also shown to perform\ncomparably to other modern algorithms. In this work, we extend this idea to\nprovide classification rules for both classes simultaneously. That is, we\nprovide a distinct set of rules for both positive and negative classes. In\ndescribing this approach, we also present a novel and complete taxonomy of\nclassifications that clearly capture and quantify the inherent ambiguity in\nnoisy binary classifications in the real world. We show that this approach\nleads to a more granular formulation of the likelihood model and a\nsimulated-annealing based optimization achieves classification performance\ncompetitive with comparable techniques. We apply our method to synthetic as\nwell as real world data sets to compare with other related methods that\ndemonstrate the utility of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:00:27 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 00:24:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Khusainova", "Elena", ""], ["Dodwell", "Emily", ""], ["Mitra", "Ritwik", ""]]}, {"id": "2008.11251", "submitter": "Sangwon Hyun", "authors": "Sangwon Hyun, Mattias Rolf Cape, Francois Ribalet, Jacob Bien", "title": "Modeling Cell Populations Measured By Flow Cytometry With Covariates\n  Using Sparse Mixture of Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ocean is filled with microscopic microalgae called phytoplankton, which\ntogether are responsible for as much photosynthesis as all plants on land\ncombined. Our ability to predict their response to the warming ocean relies on\nunderstanding how the dynamics of phytoplankton populations is influenced by\nchanges in environmental conditions. One powerful technique to study the\ndynamics of phytoplankton is flow cytometry, which measures the optical\nproperties of thousands of individual cells per second. Today, oceanographers\nare able to collect flow cytometry data in real-time onboard a moving ship,\nproviding them with fine-scale resolution of the distribution of phytoplankton\nacross thousands of kilometers. One of the current challenges is to understand\nhow these small and large scale variations relate to environmental conditions,\nsuch as nutrient availability, temperature, light and ocean currents. In this\npaper, we propose a novel sparse mixture of multivariate regressions model to\nestimate the time-varying phytoplankton subpopulations while simultaneously\nidentifying the specific environmental covariates that are predictive of the\nobserved changes to these subpopulations. We demonstrate the usefulness and\ninterpretability of the approach using both synthetic data and real\nobservations collected on an oceanographic cruise conducted in the north-east\nPacific in the spring of 2017.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:03:24 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hyun", "Sangwon", ""], ["Cape", "Mattias Rolf", ""], ["Ribalet", "Francois", ""], ["Bien", "Jacob", ""]]}, {"id": "2008.11273", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "Independent Vector Analysis with Deep Neural Network Source Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the density priors for independent vector analysis (IVA)\nwith convolutive speech mixture separation as the exemplary application. Most\nexisting source priors for IVA are too simplified to capture the fine\nstructures of speeches. Here, we first time show that it is possible to\nefficiently estimate the derivative of speech density with universal\napproximators like deep neural networks (DNN) by optimizing certain proxy\nseparation related performance indices. Experimental results suggest that the\nresultant neural network density priors consistently outperform previous ones\nin convergence speed for online implementation and signal-to-interference ratio\n(SIR) for batch implementation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:13:55 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:43:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "2008.11281", "submitter": "Dimitris Stripelis", "authors": "Dimitris Stripelis and Jose Luis Ambite", "title": "Accelerating Federated Learning in Heterogeneous Data and Computational\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are situations where data relevant to a machine learning problem are\ndistributed among multiple locations that cannot share the data due to\nregulatory, competitiveness, or privacy reasons. For example, data present in\nusers' cellphones, manufacturing data of companies in a given industrial\nsector, or medical records located at different hospitals. Moreover,\nparticipating sites often have different data distributions and computational\ncapabilities. Federated Learning provides an approach to learn a joint model\nover all the available data in these environments. In this paper, we introduce\na novel distributed validation weighting scheme (DVW), which evaluates the\nperformance of a learner in the federation against a distributed validation\nset. Each learner reserves a small portion (e.g., 5%) of its local training\nexamples as a validation dataset and allows other learners models to be\nevaluated against it. We empirically show that DVW results in better\nperformance compared to established methods, such as FedAvg, both under\nsynchronous and asynchronous communication protocols in data and\ncomputationally heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:28:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Stripelis", "Dimitris", ""], ["Ambite", "Jose Luis", ""]]}, {"id": "2008.11297", "submitter": "Malik Boudiaf", "authors": "Malik Boudiaf, Ziko Imtiaz Masud, J\\'er\\^ome Rony, Jos\\'e Dolz, Pablo\n  Piantanida, Ismail Ben Ayed", "title": "Transductive Information Maximization For Few-Shot Learning", "comments": "NeurIPS 2020. Code available at https://github.com/mboudiaf/TIM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Transductive Infomation Maximization (TIM) for few-shot\nlearning. Our method maximizes the mutual information between the query\nfeatures and their label predictions for a given few-shot task, in conjunction\nwith a supervision loss based on the support set. Furthermore, we propose a new\nalternating-direction solver for our mutual-information loss, which\nsubstantially speeds up transductive-inference convergence over gradient-based\noptimization, while yielding similar accuracy. TIM inference is modular: it can\nbe used on top of any base-training feature extractor. Following standard\ntransductive few-shot settings, our comprehensive experiments demonstrate that\nTIM outperforms state-of-the-art methods significantly across various datasets\nand networks, while used on top of a fixed feature extractor trained with\nsimple cross-entropy on the base classes, without resorting to complex\nmeta-learning schemes. It consistently brings between 2% and 5% improvement in\naccuracy over the best performing method, not only on all the well-established\nfew-shot benchmarks but also on more challenging scenarios,with domain shifts\nand larger numbers of classes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:38:41 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 02:43:51 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 17:36:19 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Boudiaf", "Malik", ""], ["Masud", "Ziko Imtiaz", ""], ["Rony", "J\u00e9r\u00f4me", ""], ["Dolz", "Jos\u00e9", ""], ["Piantanida", "Pablo", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "2008.11332", "submitter": "Izumi Karino", "authors": "Izumi Karino, Yoshiyuki Ohmura, Yasuo Kuniyoshi", "title": "Identifying Critical States by the Action-Based Variance of Expected\n  Return", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": "10.1007/978-3-030-61609-0_29", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The balance of exploration and exploitation plays a crucial role in\naccelerating reinforcement learning (RL). To deploy an RL agent in human\nsociety, its explainability is also essential. However, basic RL approaches\nhave difficulties in deciding when to choose exploitation as well as in\nextracting useful points for a brief explanation of its operation. One reason\nfor the difficulties is that these approaches treat all states the same way.\nHere, we show that identifying critical states and treating them specially is\ncommonly beneficial to both problems. These critical states are the states at\nwhich the action selection changes the potential of success and failure\nsubstantially. We propose to identify the critical states using the variance in\nthe Q-function for the actions and to perform exploitation with high\nprobability on the identified states. These simple methods accelerate RL in a\ngrid world with cliffs and two baseline tasks of deep RL. Our results also\ndemonstrate that the identified critical states are intuitively interpretable\nregarding the crucial nature of the action selection. Furthermore, our analysis\nof the relationship between the timing of the identification of especially\ncritical states and the rapid progress of learning suggests there are a few\nespecially critical states that have important information for accelerating RL\nrapidly.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 01:38:58 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 10:54:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Karino", "Izumi", ""], ["Ohmura", "Yoshiyuki", ""], ["Kuniyoshi", "Yasuo", ""]]}, {"id": "2008.11343", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Shaoduo Gan, Samyam Rajbhandari, Xiangru Lian, Ji Liu,\n  Yuxiong He, Ce Zhang", "title": "APMSqueeze: A Communication Efficient Adam-Preconditioned Momentum SGD\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is the important optimization algorithm to guarantee efficiency and\naccuracy for training many important tasks such as BERT and ImageNet. However,\nAdam is generally not compatible with information (gradient) compression\ntechnology. Therefore, the communication usually becomes the bottleneck for\nparallelizing Adam. In this paper, we propose a communication efficient {\\bf\nA}DAM {\\bf p}reconditioned {\\bf M}omentum SGD algorithm-- named APMSqueeze--\nthrough an error compensated method compressing gradients. The proposed\nalgorithm achieves a similar convergence efficiency to Adam in term of epochs,\nbut significantly reduces the running time per epoch. In terms of end-to-end\nperformance (including the full-precision pre-condition step), APMSqueeze is\nable to provide {sometimes by up to $2-10\\times$ speed-up depending on network\nbandwidth.} We also conduct theoretical analysis on the convergence and\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:20:23 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 03:59:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tang", "Hanlin", ""], ["Gan", "Shaoduo", ""], ["Rajbhandari", "Samyam", ""], ["Lian", "Xiangru", ""], ["Liu", "Ji", ""], ["He", "Yuxiong", ""], ["Zhang", "Ce", ""]]}, {"id": "2008.11364", "submitter": "Yaoqing Yang", "authors": "Zhengming Zhang, Yaoqing Yang, Zhewei Yao, Yujun Yan, Joseph E.\n  Gonzalez, Michael W. Mahoney", "title": "Improving Semi-supervised Federated Learning by Reducing the Gradient\n  Diversity of Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising way to use the computing power of\nmobile devices while maintaining the privacy of users. Current work in FL,\nhowever, makes the unrealistic assumption that the users have ground-truth\nlabels on their devices, while also assuming that the server has neither data\nnor labels. In this work, we consider the more realistic scenario where the\nusers have only unlabeled data, while the server has some labeled data, and\nwhere the amount of labeled data is smaller than the amount of unlabeled data.\nWe call this learning problem semi-supervised federated learning (SSFL). For\nSSFL, we demonstrate that a critical issue that affects the test accuracy is\nthe large gradient diversity of the models from different users. Based on this,\nwe investigate several design choices. First, we find that the so-called\nconsistency regularization loss (CRL), which is widely used in semi-supervised\nlearning, performs reasonably well but has large gradient diversity. Second, we\nfind that Batch Normalization (BN) increases gradient diversity. Replacing BN\nwith the recently-proposed Group Normalization (GN) can reduce gradient\ndiversity and improve test accuracy. Third, we show that CRL combined with GN\nstill has a large gradient diversity when the number of users is large. Based\non these results, we propose a novel grouping-based model averaging method to\nreplace the FedAvg averaging method. Overall, our grouping-based averaging,\ncombined with GN and CRL, achieves better test accuracy than not just a\ncontemporary paper on SSFL in the same settings (>10\\%), but also four\nsupervised FL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:36:07 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 04:03:44 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zhang", "Zhengming", ""], ["Yang", "Yaoqing", ""], ["Yao", "Zhewei", ""], ["Yan", "Yujun", ""], ["Gonzalez", "Joseph E.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2008.11370", "submitter": "Bogdan Petrenko V.", "authors": "Chad Kelterborn, Marcin Mazur, and Bogdan V. Petrenko", "title": "Gravilon: Applications of a New Gradient Descent Method to Machine\n  Learning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent algorithms have been used in countless applications since\nthe inception of Newton's method. The explosion in the number of applications\nof neural networks has re-energized efforts in recent years to improve the\nstandard gradient descent method in both efficiency and accuracy. These methods\nmodify the effect of the gradient in updating the values of the parameters.\nThese modifications often incorporate hyperparameters: additional variables\nwhose values must be specified at the outset of the program. We provide, below,\na novel gradient descent algorithm, called Gravilon, that uses the geometry of\nthe hypersurface to modify the length of the step in the direction of the\ngradient. Using neural networks, we provide promising experimental results\ncomparing the accuracy and efficiency of the Gravilon method against commonly\nused gradient descent algorithms on MNIST digit classification.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 04:02:02 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 19:15:31 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kelterborn", "Chad", ""], ["Mazur", "Marcin", ""], ["Petrenko", "Bogdan V.", ""]]}, {"id": "2008.11376", "submitter": "Raha Moraffah", "authors": "Raha Moraffah, Bahman Moraffah, Mansooreh Karami, Adrienne Raglin,\n  Huan Liu", "title": "Causal Adversarial Network for Learning Conditional and Interventional\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative Causal Adversarial Network (CAN) for learning and\nsampling from conditional and interventional distributions. In contrast to the\nexisting CausalGAN which requires the causal graph to be given, our proposed\nframework learns the causal relations from the data and generates samples\naccordingly. The proposed CAN comprises a two-fold process namely Label\nGeneration Network (LGN) and Conditional Image Generation Network (CIGN). The\nLGN is a GAN-based architecture which learns and samples from the causal model\nover labels. The sampled labels are then fed to CIGN, a conditional GAN\narchitecture, which learns the relationships amongst labels and pixels and\npixels themselves and generates samples based on them. This framework is\nequipped with an intervention mechanism which enables. the model to generate\nsamples from interventional distributions. We quantitatively and qualitatively\nassess the performance of CAN and empirically show that our model is able to\ngenerate both interventional and conditional samples without having access to\nthe causal graph for the application of face generation on CelebA data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 05:08:38 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 19:14:03 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Moraffah", "Raha", ""], ["Moraffah", "Bahman", ""], ["Karami", "Mansooreh", ""], ["Raglin", "Adrienne", ""], ["Liu", "Huan", ""]]}, {"id": "2008.11384", "submitter": "Yiliang Zhang", "authors": "Li Zeng, Zhaolong Yu, Yiliang Zhang, Hongyu Zhao", "title": "A general kernel boosting framework integrating pathways for predictive\n  modeling based on genomic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modeling based on genomic data has gained popularity in biomedical\nresearch and clinical practice by allowing researchers and clinicians to\nidentify biomarkers and tailor treatment decisions more efficiently. Analysis\nincorporating pathway information can boost discovery power and better connect\nnew findings with biological mechanisms. In this article, we propose a general\nframework, Pathway-based Kernel Boosting (PKB), which incorporates clinical\ninformation and prior knowledge about pathways for prediction of binary,\ncontinuous and survival outcomes. We introduce appropriate loss functions and\noptimization procedures for different outcome types. Our prediction algorithm\nincorporates pathway knowledge by constructing kernel function spaces from the\npathways and use them as base learners in the boosting procedure. Through\nextensive simulations and case studies in drug response and cancer survival\ndatasets, we demonstrate that PKB can substantially outperform other competing\nmethods, better identify biological pathways related to drug response and\npatient survival, and provide novel insights into cancer pathogenesis and\ntreatment response.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 05:54:23 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 22:56:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zeng", "Li", ""], ["Yu", "Zhaolong", ""], ["Zhang", "Yiliang", ""], ["Zhao", "Hongyu", ""]]}, {"id": "2008.11406", "submitter": "Darius Afchar", "authors": "Darius Afchar and Romain Hennequin", "title": "Making Neural Networks Interpretable with Attribution: Application to\n  Implicit Signals Prediction", "comments": "14th ACM Conference on Recommender Systems (RecSys '20)", "journal-ref": null, "doi": "10.1145/3383313.3412253", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining recommendations enables users to understand whether recommended\nitems are relevant to their needs and has been shown to increase their trust in\nthe system. More generally, if designing explainable machine learning models is\nkey to check the sanity and robustness of a decision process and improve their\nefficiency, it however remains a challenge for complex architectures,\nespecially deep neural networks that are often deemed \"black-box\". In this\npaper, we propose a novel formulation of interpretable deep neural networks for\nthe attribution task. Differently to popular post-hoc methods, our approach is\ninterpretable by design. Using masked weights, hidden features can be deeply\nattributed, split into several input-restricted sub-networks and trained as a\nboosted mixture of experts. Experimental results on synthetic data and\nreal-world recommendation tasks demonstrate that our method enables to build\nmodels achieving close predictive performances to their non-interpretable\ncounterparts, while providing informative attribution interpretations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 06:46:49 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Afchar", "Darius", ""], ["Hennequin", "Romain", ""]]}, {"id": "2008.11416", "submitter": "Xu Chen", "authors": "Xu Chen and Ya Zhang and Ivor Tsang and Yuangang Pan", "title": "Learning Robust Node Representations on Graphs", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN), as a popular methodology for node representation\nlearning on graphs, currently mainly focus on preserving the smoothness and\nidentifiability of node representations. A robust node representation on graphs\nshould further hold the stability property which means a node representation is\nresistant to slight perturbations on the input. In this paper, we introduce the\nstability of node representations in addition to the smoothness and\nidentifiability, and develop a novel method called contrastive graph neural\nnetworks (CGNN) that learns robust node representations in an unsupervised\nmanner. Specifically, CGNN maintains the stability and identifiability by a\ncontrastive learning objective, while preserving the smoothness with existing\nGNN models. Furthermore, the proposed method is a generic framework that can be\nequipped with many other backbone models (e.g. GCN, GraphSage and GAT).\nExtensive experiments on four benchmarks under both transductive and inductive\nlearning setups demonstrate the effectiveness of our method in comparison with\nrecent supervised and unsupervised models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 07:11:01 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 03:04:42 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Xu", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor", ""], ["Pan", "Yuangang", ""]]}, {"id": "2008.11426", "submitter": "Ozan Ozdenizci", "authors": "Mo Han, Ozan Ozdenizci, Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Disentangled Adversarial Autoencoder for Subject-Invariant Physiological\n  Feature Extraction", "comments": "Accepted for publication by IEEE Signal Processing Letters", "journal-ref": "IEEE Signal Processing Letters, 2020", "doi": "10.1109/LSP.2020.3020215", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in biosignal processing have enabled users to exploit\ntheir physiological status for manipulating devices in a reliable and safe\nmanner. One major challenge of physiological sensing lies in the variability of\nbiosignals across different users and tasks. To address this issue, we propose\nan adversarial feature extractor for transfer learning to exploit disentangled\nuniversal representations. We consider the trade-off between task-relevant\nfeatures and user-discriminative information by introducing additional\nadversary and nuisance networks in order to manipulate the latent\nrepresentations such that the learned feature extractor is applicable to\nunknown users and various tasks. Results on cross-subject transfer evaluations\nexhibit the benefits of the proposed framework, with up to 8.8% improvement in\naverage accuracy of classification, and demonstrate adaptability to a broader\nrange of subjects.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 07:45:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Han", "Mo", ""], ["Ozdenizci", "Ozan", ""], ["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2008.11433", "submitter": "Ajitabh Kumar", "authors": "Ajitabh Kumar", "title": "Uncertainty-Aware Surrogate Model For Oilfield Reservoir Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have gained increased attention in machine learning, but\nthey are limited by the fact that many such regression and classification\nmodels do not capture prediction uncertainty. Though this might be acceptable\nfor certain non-critical applications, it is not so for oil and gas industry\napplications where business and economic consequences of wrong or even\nsub-optimal decision is quite high. In this work I discuss the application of\ndeep neural networks as a framework for approximate Bayesian inference in\noilfield reservoir simulation study. Surrogate models with different neural\nnetwork architecture are proposed to speed up compute- and labor-intensive\nsimulation workflow. Regularization tools such as dropout and batch\nnormalization, variational autoencoder for regression, and probabilistic\ndistribution layers are used to quantify prediction uncertainty. Monte-Carlo\ndropout approach is further applied to estimate uncertainty given by standard\ndeviation values for the predictions. Probabilistic distribution layers are\nused to compare its efficacy in capturing the model prediction uncertainty with\nrespect to deterministic neural layers. Deep ensemble approach is also used to\ntrain multiple surrogates which capture uncertainty. Among different models\ntested, VAE based regression model with multivariate-normal latent features\nworks best for prediction uncertainty assessment. Compute time required by\nsurrogate model for prediction is a small fraction of that for full-physics\nreservoir simulator. Prediction uncertainty information can be used in various\nsimulation workflows to decide when to use surrogate model and when to further\nexplore the solution space using reservoir simulator, thus reducing total\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 08:03:03 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kumar", "Ajitabh", ""]]}, {"id": "2008.11450", "submitter": "Jason Armitage", "authors": "Jason Armitage, Shramana Thakur, Rishi Tripathi, Jens Lehmann, and\n  Maria Maleshkova", "title": "Training Multimodal Systems for Classification with Multiple Objectives", "comments": null, "journal-ref": "Proceedings of the 1st International Workshop on Cross-lingual\n  Event-centric Open Analytics co-located with the 17th Extended Semantic Web\n  Conference (ESWC 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We learn about the world from a diverse range of sensory information.\nAutomated systems lack this ability as investigation has centred on processing\ninformation presented in a single form. Adapting architectures to learn from\nmultiple modalities creates the potential to learn rich representations of the\nworld - but current multimodal systems only deliver marginal improvements on\nunimodal approaches. Neural networks learn sampling noise during training with\nthe result that performance on unseen data is degraded. This research\nintroduces a second objective over the multimodal fusion process learned with\nvariational inference. Regularisation methods are implemented in the inner\ntraining loop to control variance and the modular structure stabilises\nperformance as additional neurons are added to layers. This framework is\nevaluated on a multilabel classification task with textual and visual inputs to\ndemonstrate the potential for multiple objectives and probabilistic methods to\nlower variance and improve generalisation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:05:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Armitage", "Jason", ""], ["Thakur", "Shramana", ""], ["Tripathi", "Rishi", ""], ["Lehmann", "Jens", ""], ["Maleshkova", "Maria", ""]]}, {"id": "2008.11573", "submitter": "Selim F{\\i}rat Y{\\i}lmaz", "authors": "Selim F. Yilmaz, E. Batuhan Kaynak, Aykut Ko\\c{c}, Hamdi\n  Dibeklio\\u{g}lu and Suleyman S. Kozat", "title": "Multi-Label Sentiment Analysis on 100 Languages with Dynamic Weighting\n  for Label Imbalance", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate cross-lingual sentiment analysis, which has attracted\nsignificant attention due to its applications in various areas including market\nresearch, politics and social sciences. In particular, we introduce a sentiment\nanalysis framework in multi-label setting as it obeys Plutchik wheel of\nemotions. We introduce a novel dynamic weighting method that balances the\ncontribution from each class during training, unlike previous static weighting\nmethods that assign non-changing weights based on their class frequency.\nMoreover, we adapt the focal loss that favors harder instances from\nsingle-label object recognition literature to our multi-label setting.\nFurthermore, we derive a method to choose optimal class-specific thresholds\nthat maximize the macro-f1 score in linear time complexity. Through an\nextensive set of experiments, we show that our method obtains the\nstate-of-the-art performance in 7 of 9 metrics in 3 different languages using a\nsingle model compared to the common baselines and the best-performing methods\nin the SemEval competition. We publicly share our code for our model, which can\nperform sentiment analysis in 100 languages, to facilitate further research.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:16:02 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kaynak", "E. Batuhan", ""], ["Ko\u00e7", "Aykut", ""], ["Dibeklio\u011flu", "Hamdi", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2008.11618", "submitter": "Mohammad Esmaeilpour", "authors": "Raymel Alfonso Sallo, Mohammad Esmaeilpour, Patrick Cardinal", "title": "Adversarially Training for Audio Classifiers", "comments": "Paper accepted to International Conference on Pattern Recognition\n  (ICPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the potential effect of the adversarially\ntraining on the robustness of six advanced deep neural networks against a\nvariety of targeted and non-targeted adversarial attacks. We firstly show that,\nthe ResNet-56 model trained on the 2D representation of the discrete wavelet\ntransform appended with the tonnetz chromagram outperforms other models in\nterms of recognition accuracy. Then we demonstrate the positive impact of\nadversarially training on this model as well as other deep architectures\nagainst six types of attack algorithms (white and black-box) with the cost of\nthe reduced recognition accuracy and limited adversarial perturbation. We run\nour experiments on two benchmarking environmental sound datasets and show that\nwithout any imposed limitations on the budget allocations for the adversary,\nthe fooling rate of the adversarially trained models can exceed 90\\%. In other\nwords, adversarial attacks exist in any scales, but they might require higher\nadversarial perturbations compared to non-adversarially trained models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:15:32 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 17:43:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sallo", "Raymel Alfonso", ""], ["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""]]}, {"id": "2008.11643", "submitter": "Sam Verboven", "authors": "Sam Verboven, Muhammad Hafeez Chaudhary, Jeroen Berrevoets, Wouter\n  Verbeke", "title": "HydaLearn: Highly Dynamic Task Weighting for Multi-task Learning with\n  Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) can improve performance on a task by sharing\nrepresentations with one or more related auxiliary-tasks. Usually, MTL-networks\nare trained on a composite loss function formed by a constant weighted\ncombination of the separate task losses. In practice, constant loss weights\nlead to poor results for two reasons: (i) the relevance of the auxiliary tasks\ncan gradually drift throughout the learning process; (ii) for mini-batch based\noptimisation, the optimal task weights vary significantly from one update to\nthe next depending on mini-batch sample composition. We introduce HydaLearn, an\nintelligent weighting algorithm that connects main-task gain to the individual\ntask gradients, in order to inform dynamic loss weighting at the mini-batch\nlevel, addressing i and ii. Using HydaLearn, we report performance increases on\nsynthetic data, as well as on two supervised learning domains.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:04:02 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Verboven", "Sam", ""], ["Chaudhary", "Muhammad Hafeez", ""], ["Berrevoets", "Jeroen", ""], ["Verbeke", "Wouter", ""]]}, {"id": "2008.11652", "submitter": "Huan Zhao Dr.", "authors": "Huan Zhao and Lanning Wei and Quanming Yao", "title": "Simplifying Architecture Search for Graph Neural Network", "comments": "CIKM 2020 Workshop: 1st Workshop Combining Symbolic and Subsymbolic\n  Methods and their Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the popularity of Graph Neural Networks (GNN) in\nvarious scenarios. To obtain optimal data-specific GNN architectures,\nresearchers turn to neural architecture search (NAS) methods, which have made\nimpressive progress in discovering effective architectures in convolutional\nneural networks. Two preliminary works, GraphNAS and Auto-GNN, have made first\nattempt to apply NAS methods to GNN. Despite the promising results, there are\nseveral drawbacks in expressive capability and search efficiency of GraphNAS\nand Auto-GNN due to the designed search space. To overcome these drawbacks, we\npropose the SNAG framework (Simplified Neural Architecture search for Graph\nneural networks), consisting of a novel search space and a reinforcement\nlearning based search algorithm. Extensive experiments on real-world datasets\ndemonstrate the effectiveness of the SNAG framework compared to human-designed\nGNNs and NAS methods, including GraphNAS and Auto-GNN.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:24:03 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 12:06:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhao", "Huan", ""], ["Wei", "Lanning", ""], ["Yao", "Quanming", ""]]}, {"id": "2008.11655", "submitter": "Jacques Wainer", "authors": "Jacques Wainer and Pablo Fonseca", "title": "How to tune the RBF SVM hyperparameters?: An empirical evaluation of 18\n  search algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SVM with an RBF kernel is usually one of the best classification algorithms\nfor most data sets, but it is important to tune the two hyperparameters $C$ and\n$\\gamma$ to the data itself. In general, the selection of the hyperparameters\nis a non-convex optimization problem and thus many algorithms have been\nproposed to solve it, among them: grid search, random search, Bayesian\noptimization, simulated annealing, particle swarm optimization, Nelder Mead,\nand others. There have also been proposals to decouple the selection of\n$\\gamma$ and $C$. We empirically compare 18 of these proposed search algorithms\n(with different parameterizations for a total of 47 combinations) on 115\nreal-life binary data sets. We find (among other things) that trees of Parzen\nestimators and particle swarm optimization select better hyperparameters with\nonly a slight increase in computation time with respect to a grid search with\nthe same number of evaluations. We also find that spending too much\ncomputational effort searching the hyperparameters will not likely result in\nbetter performance for future data and that there are no significant\ndifferences among the different procedures to select the best set of\nhyperparameters when more than one is found by the search algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:28:48 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Wainer", "Jacques", ""], ["Fonseca", "Pablo", ""]]}, {"id": "2008.11664", "submitter": "Richard Berk", "authors": "Richard A. Berk and Arun Kumar Kuchibhotla", "title": "Improving Fairness in Criminal Justice Algorithmic Risk Assessments\n  Using Conformal Prediction Sets", "comments": "We found an interpretive error in the method. We are trying now to\n  develop a better approach", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk assessment algorithms have been correctly criticized for potential\nunfairness, and there is an active cottage industry trying to make repairs. In\nthis paper, we adopt a framework from conformal prediction sets to remove\nunfairness from risk algorithms themselves and the covariates used for\nforecasting. From a sample of 300,000 offenders at their arraignments, we\nconstruct a confusion table and its derived measures of fairness that are\neffectively free any meaningful differences between Black and White offenders.\nWe also produce fair forecasts for individual offenders coupled with valid\nprobability guarantees that the forecasted outcome is the true outcome. We see\nour work as a demonstration of concept for application in a wide variety of\ncriminal justice decisions. The procedures provided can be routinely\nimplemented in jurisdictions with the usual criminal justice datasets used by\nadministrators. The requisite procedures can be found in the scripting software\nR. However, whether stakeholders will accept our approach as a means to achieve\nrisk assessment fairness is unknown. There also are legal issues that would\nneed to be resolved although we offer a Pareto improvement.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:47:02 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 17:23:37 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 17:35:18 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Berk", "Richard A.", ""], ["Kuchibhotla", "Arun Kumar", ""]]}, {"id": "2008.11687", "submitter": "Hanie Sedghi", "authors": "Behnam Neyshabur and Hanie Sedghi and Chiyuan Zhang", "title": "What is being transferred in transfer learning?", "comments": "Equal contribution, authors ordered randomly", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One desired capability for machines is the ability to transfer their\nknowledge of one domain to another where data is (usually) scarce. Despite\nample adaptation of transfer learning in various deep learning applications, we\nyet do not understand what enables a successful transfer and which part of the\nnetwork is responsible for that. In this paper, we provide new tools and\nanalyses to address these fundamental questions. Through a series of analyses\non transferring to block-shuffled images, we separate the effect of feature\nreuse from learning low-level statistics of data and show that some benefit of\ntransfer learning comes from the latter. We present that when training from\npre-trained weights, the model stays in the same basin in the loss landscape\nand different instances of such model are similar in feature space and close in\nparameter space.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:23:40 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 20:32:39 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Sedghi", "Hanie", ""], ["Zhang", "Chiyuan", ""]]}, {"id": "2008.11707", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Zhiwei Steven Wu, Rayid Ghani, Fei Fang", "title": "Bandit Data-driven Optimization: AI for Social Good and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning (ML) systems in real-world applications entails\nmore than just a prediction algorithm. AI for social good applications, and\nmany real-world ML tasks in general, feature an iterative process which joins\nprediction, optimization, and data acquisition happen in a loop. We introduce\nbandit data-driven optimization, the first iterative prediction-prescription\nframework to formally analyze this practical routine. Bandit data-driven\noptimization combines the advantages of online bandit learning and offline\npredictive analytics in an integrated framework. It offers a flexible setup to\nreason about unmodeled policy objectives and unforeseen consequences. We\npropose PROOF, the first algorithm for this framework and show that it achieves\nno-regret. Using numerical simulations, we show that PROOF achieves superior\nperformance over existing baseline.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:50:49 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Wu", "Zhiwei Steven", ""], ["Ghani", "Rayid", ""], ["Fang", "Fei", ""]]}, {"id": "2008.11721", "submitter": "Hua Shen", "authors": "Hua Shen and Ting-Hao Kenneth Huang", "title": "How Useful Are the Machine-Generated Interpretations to General Users? A\n  Human Evaluation on Guessing the Incorrectly Predicted Labels", "comments": "Accepted by The 8th AAAI Conference on Human Computation and\n  Crowdsourcing (HCOMP 2020) https://github.com/huashen218/GuessWrongLabel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining to users why automated systems make certain mistakes is important\nand challenging. Researchers have proposed ways to automatically produce\ninterpretations for deep neural network models. However, it is unclear how\nuseful these interpretations are in helping users figure out why they are\ngetting an error. If an interpretation effectively explains to users how the\nunderlying deep neural network model works, people who were presented with the\ninterpretation should be better at predicting the model's outputs than those\nwho were not. This paper presents an investigation on whether or not showing\nmachine-generated visual interpretations helps users understand the incorrectly\npredicted labels produced by image classifiers. We showed the images and the\ncorrect labels to 150 online crowd workers and asked them to select the\nincorrectly predicted labels with or without showing them the machine-generated\nvisual interpretations. The results demonstrated that displaying the visual\ninterpretations did not increase, but rather decreased, the average guessing\naccuracy by roughly 10%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:02:05 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 02:42:23 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Shen", "Hua", ""], ["Huang", "Ting-Hao Kenneth", ""]]}, {"id": "2008.11752", "submitter": "Shounak Datta", "authors": "Sankha Subhra Mullick and Shounak Datta and Sourish Gunesh Dhekane and\n  Swagatam Das", "title": "Appropriateness of Performance Indices for Imbalanced Data\n  Classification: An Analysis", "comments": "Published in Pattern Recognition (Elsevier)", "journal-ref": "Pattern Recognition, 102, p.107197 (2020)", "doi": "10.1016/j.patcog.2020.107197", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indices quantifying the performance of classifiers under class-imbalance,\noften suffer from distortions depending on the constitution of the test set or\nthe class-specific classification accuracy, creating difficulties in assessing\nthe merit of the classifier. We identify two fundamental conditions that a\nperformance index must satisfy to be respectively resilient to altering number\nof testing instances from each class and the number of classes in the test set.\nIn light of these conditions, under the effect of class imbalance, we\ntheoretically analyze four indices commonly used for evaluating binary\nclassifiers and five popular indices for multi-class classifiers. For indices\nviolating any of the conditions, we also suggest remedial modification and\nnormalization. We further investigate the capability of the indices to retain\ninformation about the classification performance over all the classes, even\nwhen the classifier exhibits extreme performance on some classes. Simulation\nstudies are performed on high dimensional deep representations of subset of the\nImageNet dataset using four state-of-the-art classifiers tailored for handling\nclass imbalance. Finally, based on our theoretical findings and empirical\nevidence, we recommend the appropriate indices that should be used to evaluate\nthe performance of classifiers in presence of class-imbalance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 18:23:36 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Mullick", "Sankha Subhra", ""], ["Datta", "Shounak", ""], ["Dhekane", "Sourish Gunesh", ""], ["Das", "Swagatam", ""]]}, {"id": "2008.11790", "submitter": "Daniel Berman", "authors": "Daniel S. Berman (1), Craig Howser (1), Thomas Mehoke (1), Jared D.\n  Evans (1) ((1) Johns Hopkins Applied Physics Laboratory, Laurel, United\n  States)", "title": "MutaGAN: A Seq2seq GAN Framework to Predict Mutations of Evolving\n  Protein Populations", "comments": "28 pages, 9 figures, 2 tables, Daniel S. Berman and Craig Howser\n  contributed equally to this work. This paper was submitted to Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to predict the evolution of a pathogen would significantly\nimprove the ability to control, prevent, and treat disease. Despite significant\nprogress in other problem spaces, deep learning has yet to contribute to the\nissue of predicting mutations of evolving populations. To address this gap, we\ndeveloped a novel machine learning framework using generative adversarial\nnetworks (GANs) with recurrent neural networks (RNNs) to accurately predict\ngenetic mutations and evolution of future biological populations. Using a\ngeneralized time-reversible phylogenetic model of protein evolution with\nbootstrapped maximum likelihood tree estimation, we trained a\nsequence-to-sequence generator within an adversarial framework, named MutaGAN,\nto generate complete protein sequences augmented with possible mutations of\nfuture virus populations. Influenza virus sequences were identified as an ideal\ntest case for this deep learning framework because it is a significant human\npathogen with new strains emerging annually and global surveillance efforts\nhave generated a large amount of publicly available data from the National\nCenter for Biotechnology Information's (NCBI) Influenza Virus Resource (IVR).\nMutaGAN generated \"child\" sequences from a given \"parent\" protein sequence with\na median Levenshtein distance of 2.00 amino acids. Additionally, the generator\nwas able to augment the majority of parent proteins with at least one mutation\nidentified within the global influenza virus population. These results\ndemonstrate the power of the MutaGAN framework to aid in pathogen forecasting\nwith implications for broad utility in evolutionary prediction for any protein\npopulation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:20:30 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Berman", "Daniel S.", ""], ["Howser", "Craig", ""], ["Mehoke", "Thomas", ""], ["Evans", "Jared D.", ""]]}, {"id": "2008.11809", "submitter": "Ruiyi Yang", "authors": "Daniel Sanz-Alonso and Ruiyi Yang", "title": "Unlabeled Data Help in Graph-Based Semi-Supervised Learning: A Bayesian\n  Nonparametrics Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the graph-based approach to semi-supervised learning\nunder a manifold assumption. We adopt a Bayesian perspective and demonstrate\nthat, for a suitable choice of prior constructed with sufficiently many\nunlabeled data, the posterior contracts around the truth at a rate that is\nminimax optimal up to a logarithmic factor. Our theory covers both regression\nand classification.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:51:30 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 22:51:53 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 03:01:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sanz-Alonso", "Daniel", ""], ["Yang", "Ruiyi", ""]]}, {"id": "2008.11811", "submitter": "Harsh Satija", "authors": "Harsh Satija, Philip Amortila, Joelle Pineau", "title": "Constrained Markov Decision Processes via Backward Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Reinforcement Learning (RL) algorithms have found tremendous success\nin simulated domains, they often cannot directly be applied to physical\nsystems, especially in cases where there are hard constraints to satisfy (e.g.\non safety or resources). In standard RL, the agent is incentivized to explore\nany behavior as long as it maximizes rewards, but in the real world, undesired\nbehavior can damage either the system or the agent in a way that breaks the\nlearning process itself. In this work, we model the problem of learning with\nconstraints as a Constrained Markov Decision Process and provide a new\non-policy formulation for solving it. A key contribution of our approach is to\ntranslate cumulative cost constraints into state-based constraints. Through\nthis, we define a safe policy improvement method which maximizes returns while\nensuring that the constraints are satisfied at every step. We provide\ntheoretical guarantees under which the agent converges while ensuring safety\nover the course of training. We also highlight the computational advantages of\nthis approach. The effectiveness of our approach is demonstrated on safe\nnavigation tasks and in safety-constrained versions of MuJoCo environments,\nwith deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:56:16 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Satija", "Harsh", ""], ["Amortila", "Philip", ""], ["Pineau", "Joelle", ""]]}, {"id": "2008.11828", "submitter": "Dilip K. Prasad", "authors": "Rohit Agarwal and Arif Ahmed Sekh and Krishna Agarwal and Dilip K.\n  Prasad", "title": "Auxiliary Network: Scalable and agile online learning for dynamic system\n  with inconsistently available inputs", "comments": "under review at NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming classification methods assume the number of input features is fixed\nand always received. But in many real-world scenarios demand is some input\nfeatures are reliable while others are unreliable or inconsistent. In this\npaper, we propose a novel deep learning-based model called Auxiliary Network\n(Aux-Net), which is scalable and agile. It employs a weighted ensemble of\nclassifiers to give a final outcome. The Aux-Net model is based on the hedging\nalgorithm and online gradient descent. It employs a model of varying depth in\nan online setting using single pass learning. Aux-Net is a foundational work\ntowards scalable neural network model for a dynamic complex environment\nrequiring ad hoc or inconsistent input data. The efficacy of Aux-Net is shown\non public dataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:37:24 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Agarwal", "Rohit", ""], ["Sekh", "Arif Ahmed", ""], ["Agarwal", "Krishna", ""], ["Prasad", "Dilip K.", ""]]}, {"id": "2008.11832", "submitter": "Wenqian Dong", "authors": "Wenqian Dong, Jie Liu, Zhen Xie and Dong Li", "title": "Adaptive Neural Network-Based Approximation to Accelerate Eulerian Fluid\n  Simulation", "comments": null, "journal-ref": null, "doi": "10.1145/3295500.3356147", "report-no": null, "categories": "cs.LG cs.DC physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Eulerian fluid simulation is an important HPC application. The neural\nnetwork has been applied to accelerate it. The current methods that accelerate\nthe fluid simulation with neural networks lack flexibility and generalization.\nIn this paper, we tackle the above limitation and aim to enhance the\napplicability of neural networks in the Eulerian fluid simulation. We introduce\nSmartfluidnet, a framework that automates model generation and application.\nGiven an existing neural network as input, Smartfluidnet generates multiple\nneural networks before the simulation to meet the execution time and simulation\nquality requirement. During the simulation, Smartfluidnet dynamically switches\nthe neural networks to make the best efforts to reach the user requirement on\nsimulation quality. Evaluating with 20,480 input problems, we show that\nSmartfluidnet achieves 1.46x and 590x speedup comparing with a state-of-the-art\nneural network model and the original fluid simulation respectively on an\nNVIDIA Titan X Pascal GPU, while providing better simulation quality than the\nstate-of-the-art model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:44:44 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Dong", "Wenqian", ""], ["Liu", "Jie", ""], ["Xie", "Zhen", ""], ["Li", "Dong", ""]]}, {"id": "2008.11835", "submitter": "Rylan Perumal", "authors": "Rylan Perumal and Terence L van Zyl", "title": "Surrogate Assisted Methods for the Parameterisation of Agent-Based\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter calibration is a major challenge in agent-based modelling and\nsimulation (ABMS). As the complexity of agent-based models (ABMs) increase, the\nnumber of parameters required to be calibrated grows. This leads to the ABMS\nequivalent of the \\say{curse of dimensionality}. We propose an ABMS framework\nwhich facilitates the effective integration of different sampling methods and\nsurrogate models (SMs) in order to evaluate how these strategies affect\nparameter calibration and exploration. We show that surrogate assisted methods\nperform better than the standard sampling methods. In addition, we show that\nthe XGBoost and Decision Tree SMs are most optimal overall with regards to our\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:47:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Perumal", "Rylan", ""], ["van Zyl", "Terence L", ""]]}, {"id": "2008.11840", "submitter": "Pierre C. Bellec", "authors": "Pierre C Bellec", "title": "Out-of-sample error estimate for robust M-estimators with convex penalty", "comments": "This version adds simulations for the nuclear norm penalty", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generic out-of-sample error estimate is proposed for robust $M$-estimators\nregularized with a convex penalty in high-dimensional linear regression where\n$(X,y)$ is observed and $p,n$ are of the same order. If $\\psi$ is the\nderivative of the robust data-fitting loss $\\rho$, the estimate depends on the\nobserved data only through the quantities $\\hat\\psi = \\psi(y-X\\hat\\beta)$,\n$X^\\top \\hat\\psi$ and the derivatives $(\\partial/\\partial y) \\hat\\psi$ and\n$(\\partial/\\partial y) X\\hat\\beta$ for fixed $X$.\n  The out-of-sample error estimate enjoys a relative error of order $n^{-1/2}$\nin a linear model with Gaussian covariates and independent noise, either\nnon-asymptotically when $p/n\\le \\gamma$ or asymptotically in the\nhigh-dimensional asymptotic regime $p/n\\to\\gamma'\\in(0,\\infty)$. General\ndifferentiable loss functions $\\rho$ are allowed provided that $\\psi=\\rho'$ is\n1-Lipschitz. The validity of the out-of-sample error estimate holds either\nunder a strong convexity assumption, or for the $\\ell_1$-penalized Huber\nM-estimator if the number of corrupted observations and sparsity of the true\n$\\beta$ are bounded from above by $s_*n$ for some small enough constant\n$s_*\\in(0,1)$ independent of $n,p$.\n  For the square loss and in the absence of corruption in the response, the\nresults additionally yield $n^{-1/2}$-consistent estimates of the noise\nvariance and of the generalization error. This generalizes, to arbitrary convex\npenalty, estimates that were previously known for the Lasso.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:50:41 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 23:23:24 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 14:48:21 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 20:17:13 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Bellec", "Pierre C", ""]]}, {"id": "2008.11846", "submitter": "Habib Asseiss Neto", "authors": "Habib Asseiss Neto and Ronnie C. O. Alves and Sergio V. A. Campos", "title": "NASirt: AutoML based learning with instance-level complexity information", "comments": "to be published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing adequate and precise neural architectures is a challenging task,\noften done by highly specialized personnel. AutoML is a machine learning field\nthat aims to generate good performing models in an automated way. Spectral data\nsuch as those obtained from biological analysis have generally a lot of\nimportant information, and these data are specifically well suited to\nConvolutional Neural Networks (CNN) due to their image-like shape. In this work\nwe present NASirt, an AutoML methodology based on Neural Architecture Search\n(NAS) that finds high accuracy CNN architectures for spectral datasets. The\nproposed methodology relies on the Item Response Theory (IRT) for obtaining\ncharacteristics from an instance level, such as discrimination and difficulty,\nand it is able to define a rank of top performing submodels. Several\nexperiments are performed in order to demonstrate the methodology's performance\nwith different spectral datasets. Accuracy results are compared to other\nbenchmarks methods, such as a high performing, manually crafted CNN and the\nAuto-Keras AutoML tool. The results show that our method performs, in most\ncases, better than the benchmarks, achieving average accuracy as high as\n97.40%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:21:44 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 18:17:52 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Neto", "Habib Asseiss", ""], ["Alves", "Ronnie C. O.", ""], ["Campos", "Sergio V. A.", ""]]}, {"id": "2008.11849", "submitter": "Ziheng Wang", "authors": "Ziheng Wang", "title": "SparseRT: Accelerating Unstructured Sparsity on GPUs for Deep Learning\n  Inference", "comments": "Accepted for publication at PACT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a flurry of research in deep neural network\npruning and compression. Early approaches prune weights individually. However,\nit is difficult to take advantage of the resulting unstructured sparsity\npatterns on modern hardware like GPUs. As a result, pruning strategies which\nimpose sparsity structures in the weights have become more popular.\nHowever,these structured pruning approaches typically lead to higher losses in\naccuracy than unstructured pruning. In this paper, we present SparseRT, a code\ngenerator that leverage unstructured sparsity to accelerate sparse linear\nalgebra operations in deep learning inference on GPUs. For 1x1 convolutions and\nfully connected layers, we demonstrate geometric mean of speedups of 3.4x over\nthe equivalent dense computation at 90% sparsity and 5.4x at 95% sparsity when\nevaluated on hundreds of test cases in deep learning. For sparse 3x3\nconvolutions, we show speedups of over 5x on use cases in ResNet-50.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:36:12 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Wang", "Ziheng", ""]]}, {"id": "2008.11856", "submitter": "Mohammad Jafar Mashhadi Ebrahim", "authors": "Mohammad Jafar Mashhadi and Hadi Hemmati", "title": "Hybrid Deep Neural Networks to Infer State Models of Black-Box Systems", "comments": "11 Pages, ASE '20 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Inferring behavior model of a running software system is quite useful for\nseveral automated software engineering tasks, such as program comprehension,\nanomaly detection, and testing. Most existing dynamic model inference\ntechniques are white-box, i.e., they require source code to be instrumented to\nget run-time traces. However, in many systems, instrumenting the entire source\ncode is not possible (e.g., when using black-box third-party libraries) or\nmight be very costly. Unfortunately, most black-box techniques that detect\nstates over time are either univariate, or make assumptions on the data\ndistribution, or have limited power for learning over a long period of past\nbehavior. To overcome the above issues, in this paper, we propose a hybrid deep\nneural network that accepts as input a set of time series, one per input/output\nsignal of the system, and applies a set of convolutional and recurrent layers\nto learn the non-linear correlations between signals and the patterns, over\ntime. We have applied our approach on a real UAV auto-pilot solution from our\nindustry partner with half a million lines of C code. We ran 888 random recent\nsystem-level test cases and inferred states, over time. Our comparison with\nseveral traditional time series change point detection techniques showed that\nour approach improves their performance by up to 102%, in terms of finding\nstate change points, measured by F1 score. We also showed that our state\nclassification algorithm provides on average 90.45% F1 score, which improves\ntraditional classification algorithms by up to 17%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 23:24:34 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mashhadi", "Mohammad Jafar", ""], ["Hemmati", "Hadi", ""]]}, {"id": "2008.11865", "submitter": "Vardan Papyan", "authors": "Vardan Papyan", "title": "Traces of Class/Cross-Class Structure Pervade Deep Learning Spectra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous researchers recently applied empirical spectral analysis to the\nstudy of modern deep learning classifiers. We identify and discuss an important\nformal class/cross-class structure and show how it lies at the origin of the\nmany visually striking features observed in deepnet spectra, some of which were\nreported in recent articles, others are unveiled here for the first time. These\ninclude spectral outliers, \"spikes\", and small but distinct continuous\ndistributions, \"bumps\", often seen beyond the edge of a \"main bulk\".\n  The significance of the cross-class structure is illustrated in three ways:\n(i) we prove the ratio of outliers to bulk in the spectrum of the Fisher\ninformation matrix is predictive of misclassification, in the context of\nmultinomial logistic regression; (ii) we demonstrate how, gradually with depth,\na network is able to separate class-distinctive information from class\nvariability, all while orthogonalizing the class-distinctive information; and\n(iii) we propose a correction to KFAC, a well-known second-order optimization\nalgorithm for training deepnets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 00:08:49 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Papyan", "Vardan", ""]]}, {"id": "2008.11880", "submitter": "Martin Khannouz", "authors": "Martin Khannouz and Tristan Glatard", "title": "A benchmark of data stream classification for human activity recognition\n  on connected objects", "comments": "8 pages, 9 figures, for a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper evaluates data stream classifiers from the perspective of\nconnected devices, focusing on the use case of HAR. We measure both\nclassification performance and resource consumption (runtime, memory, and\npower) of five usual stream classification algorithms, implemented in a\nconsistent library, and applied to two real human activity datasets and to\nthree synthetic datasets. Regarding classification performance, results show an\noverall superiority of the HT, the MF, and the NB classifiers over the FNN and\nthe Micro Cluster Nearest Neighbor (MCNN) classifiers on 4 datasets out of 6,\nincluding the real ones. In addition, the HT, and to some extent MCNN, are the\nonly classifiers that can recover from a concept drift. Overall, the three\nleading classifiers still perform substantially lower than an offline\nclassifier on the real datasets. Regarding resource consumption, the HT and the\nMF are the most memory intensive and have the longest runtime, however, no\ndifference in power consumption is found between classifiers. We conclude that\nstream learning for HAR on connected objects is challenged by two factors which\ncould lead to interesting future work: a high memory consumption and low F1\nscores overall.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 01:42:07 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Khannouz", "Martin", ""], ["Glatard", "Tristan", ""]]}, {"id": "2008.11918", "submitter": "Zhimei Ren", "authors": "Zhimei Ren and Zhengyuan Zhou", "title": "Dynamic Batch Learning in High-Dimensional Sparse Linear Contextual\n  Bandits", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of dynamic batch learning in high-dimensional sparse\nlinear contextual bandits, where a decision maker can only adapt decisions at a\nbatch level. In particular, the decision maker, only observing rewards at the\nend of each batch, dynamically decides how many individuals to include in the\nnext batch (at the current batch's end) and what personalized action-selection\nscheme to adopt within the batch. Such batch constraints are ubiquitous in a\nvariety of practical contexts, including personalized product offerings in\nmarketing and medical treatment selection in clinical trials. We characterize\nthe fundamental learning limit in this problem via a novel lower bound analysis\nand provide a simple, exploration-free algorithm that uses the LASSO estimator,\nwhich achieves the minimax optimal performance characterized by the lower bound\n(up to log factors). To our best knowledge, our work provides the first inroad\ninto a rigorous understanding of dynamic batch learning with high-dimensional\ncovariates. We also demonstrate the efficacy of our algorithm on both synthetic\ndata and the Warfarin medical dosing data. The empirical results show that with\nthree batches (hence only two opportunities to adapt), our algorithm already\nperforms comparably (in terms of statistical performance) to the\nstate-of-the-art fully online high-dimensional linear contextual bandits\nalgorithm. As an added bonus, since our algorithm operates in batches, it is\norders of magnitudes faster than fully online learning algorithms. As such, our\nalgorithm provides a desirable candidate for practical data-driven personalized\ndecision making problems, where limited adaptivity is often a hard constraint.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 05:34:34 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 01:03:55 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 19:40:59 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ren", "Zhimei", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2008.11922", "submitter": "Maxim Naumov", "authors": "Tigran Ishkhanov, Maxim Naumov, Xianjie Chen, Yan Zhu, Yuan Zhong,\n  Alisson Gusatti Azzolini, Chonglin Sun, Frank Jiang, Andrey Malevich and\n  Liang Xiong", "title": "Time-based Sequence Model for Personalization and Recommendation Systems", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel recommendation model that explicitly\nincorporates time information. The model relies on an embedding layer and TSL\nattention-like mechanism with inner products in different vector spaces, that\ncan be thought of as a modification of multi-headed attention. This mechanism\nallows the model to efficiently treat sequences of user behavior of different\nlength. We study the properties of our state-of-the-art model on statistically\ndesigned data set. Also, we show that it outperforms more complex models with\nlonger sequence length on the Taobao User Behavior dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 05:46:47 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Ishkhanov", "Tigran", ""], ["Naumov", "Maxim", ""], ["Chen", "Xianjie", ""], ["Zhu", "Yan", ""], ["Zhong", "Yuan", ""], ["Azzolini", "Alisson Gusatti", ""], ["Sun", "Chonglin", ""], ["Jiang", "Frank", ""], ["Malevich", "Andrey", ""], ["Xiong", "Liang", ""]]}, {"id": "2008.11979", "submitter": "Ayoub Bagheri Dr.", "authors": "Ayoub Bagheri, T. Katrien J. Groenhof, Wouter B. Veldhuis, Pim A. de\n  Jong, Folkert W. Asselbergs, Daniel L. Oberski", "title": "Multimodal Learning for Cardiovascular Risk Prediction using EHR Data", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) contain structured and unstructured data of\nsignificant clinical and research value. Various machine learning approaches\nhave been developed to employ information in EHRs for risk prediction. The\nmajority of these attempts, however, focus on structured EHR fields and lose\nthe vast amount of information in the unstructured texts. To exploit the\npotential information captured in EHRs, in this study we propose a multimodal\nrecurrent neural network model for cardiovascular risk prediction that\nintegrates both medical texts and structured clinical information. The proposed\nmultimodal bidirectional long short-term memory (BiLSTM) model concatenates\nword embeddings to classical clinical predictors before applying them to a\nfinal fully connected neural network. In the experiments, we compare\nperformance of different deep neural network (DNN) architectures including\nconvolutional neural network and long short-term memory in scenarios of using\nclinical variables and chest X-ray radiology reports. Evaluated on a data set\nof real world patients with manifest vascular disease or at high-risk for\ncardiovascular disease, the proposed BiLSTM model demonstrates state-of-the-art\nperformance and outperforms other DNN baseline architectures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:09:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bagheri", "Ayoub", ""], ["Groenhof", "T. Katrien J.", ""], ["Veldhuis", "Wouter B.", ""], ["de Jong", "Pim A.", ""], ["Asselbergs", "Folkert W.", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2008.11990", "submitter": "Yatin Nandwani", "authors": "Yatin Nandwani, Deepanshu Jindal, Mausam and Parag Singla", "title": "Neural Learning of One-of-Many Solutions for Combinatorial Problems in\n  Structured Output Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has proposed neural architectures for solving combinatorial\nproblems in structured output spaces. In many such problems, there may exist\nmultiple solutions for a given input, e.g. a partially filled Sudoku puzzle may\nhave many completions satisfying all constraints. Further, we are often\ninterested in finding any one of the possible solutions, without any preference\nbetween them. Existing approaches completely ignore this solution multiplicity.\nIn this paper, we argue that being oblivious to the presence of multiple\nsolutions can severely hamper their training ability. Our contribution is two\nfold. First, we formally define the task of learning one-of-many solutions for\ncombinatorial problems in structured output spaces, which is applicable for\nsolving several problems of interest such as N-Queens, and Sudoku. Second, we\npresent a generic learning framework that adapts an existing prediction network\nfor a combinatorial problem to handle solution multiplicity. Our framework uses\na selection module, whose goal is to dynamically determine, for every input,\nthe solution that is most effective for training the network parameters in any\ngiven learning iteration. We propose an RL based approach to jointly train the\nselection module with the prediction network. Experiments on three different\ndomains, and using two different prediction networks, demonstrate that our\nframework significantly improves the accuracy in our setting, obtaining up to\n21 pt gain over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:37:01 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 15:36:05 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Nandwani", "Yatin", ""], ["Jindal", "Deepanshu", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "2008.12001", "submitter": "Wei Fan", "authors": "Wei Fan, Kunpeng Liu, Hao Liu, Pengyang Wang, Yong Ge and Yanjie Fu", "title": "AutoFS: Automated Feature Selection via Diversity-aware Interactive\n  Reinforcement Learning", "comments": "Accepted by ICDM 2020. In this version, we revised some typos or\n  mistakes for camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of balancing effectiveness and efficiency\nin automated feature selection. Feature selection is a fundamental intelligence\nfor machine learning and predictive analysis. After exploring many feature\nselection methods, we observe a computational dilemma: 1) traditional feature\nselection methods (e.g., mRMR) are mostly efficient, but difficult to identify\nthe best subset; 2) the emerging reinforced feature selection methods\nautomatically navigate feature space to explore the best subset, but are\nusually inefficient. Are automation and efficiency always apart from each\nother? Can we bridge the gap between effectiveness and efficiency under\nautomation? Motivated by such a computational dilemma, this study is to develop\na novel feature space navigation method. To that end, we propose an Interactive\nReinforced Feature Selection (IRFS) framework that guides agents by not just\nself-exploration experience, but also diverse external skilled trainers to\naccelerate learning for feature exploration. Specifically, we formulate the\nfeature selection problem into an interactive reinforcement learning framework.\nIn this framework, we first model two trainers skilled at different searching\nstrategies: (1) KBest based trainer; (2) Decision Tree based trainer. We then\ndevelop two strategies: (1) to identify assertive and hesitant agents to\ndiversify agent training, and (2) to enable the two trainers to take the\nteaching role in different stages to fuse the experiences of the trainers and\ndiversify teaching process. Such a hybrid teaching strategy can help agents to\nlearn broader knowledge, and, thereafter, be more effective. Finally, we\npresent extensive experiments on real-world datasets to demonstrate the\nimproved performances of our method: more efficient than existing reinforced\nselection and more effective than classic selection.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:11:30 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 05:15:32 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 08:12:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fan", "Wei", ""], ["Liu", "Kunpeng", ""], ["Liu", "Hao", ""], ["Wang", "Pengyang", ""], ["Ge", "Yong", ""], ["Fu", "Yanjie", ""]]}, {"id": "2008.12003", "submitter": "Nikolaos Tziortziotis", "authors": "Yang Qiu, Nikolaos Tziortziotis, Martial Hue, Michalis Vazirgiannis", "title": "Predicting conversions in display advertising based on URL embeddings", "comments": "Accepted at AdKDD 2020 workshop at KDD'20 conference, San Diego, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online display advertising is growing rapidly in recent years thanks to the\nautomation of the ad buying process. Real-time bidding (RTB) allows the\nautomated trading of ad impressions between advertisers and publishers through\nreal-time auctions. In order to increase the effectiveness of their campaigns,\nadvertisers should deliver ads to the users who are highly likely to be\nconverted (i.e., purchase, registration, website visit, etc.) in the near\nfuture. In this study, we introduce and examine different models for estimating\nthe probability of a user converting, given their history of visited URLs.\nInspired by natural language processing, we introduce three URL embedding\nmodels to compute semantically meaningful URL representations. To demonstrate\nthe effectiveness of the different proposed representation and conversion\nprediction models, we have conducted experiments on real logged events\ncollected from an advertising platform.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:14:28 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 09:09:26 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Qiu", "Yang", ""], ["Tziortziotis", "Nikolaos", ""], ["Hue", "Martial", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2008.12005", "submitter": "Raoul Heese", "authors": "Raoul Heese, Michael Bortz", "title": "Adaptive Sampling of Pareto Frontiers with Binary Constraints Using\n  Regression and Classification", "comments": "10 pages, 7 figures, 2 tables; International Conference on Pattern\n  Recognition (ICPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel adaptive optimization algorithm for black-box\nmulti-objective optimization problems with binary constraints on the foundation\nof Bayes optimization. Our method is based on probabilistic regression and\nclassification models, which act as a surrogate for the optimization goals and\nallow us to suggest multiple design points at once in each iteration. The\nproposed acquisition function is intuitively understandable and can be tuned to\nthe demands of the problems at hand. We also present a novel ellipsoid\ntruncation method to speed up the expected hypervolume calculation in a\nstraightforward way for regression models with a normal probability density. We\nbenchmark our approach with an evolutionary algorithm on multiple test\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:15:02 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 10:10:49 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Heese", "Raoul", ""], ["Bortz", "Michael", ""]]}, {"id": "2008.12025", "submitter": "\\'Alvar Arnaiz-Gonz\\'alez", "authors": "Ludmila I. Kuncheva, Clare E. Matthews, \\'Alvar Arnaiz-Gonz\\'alez,\n  Juan J. Rodr\\'iguez", "title": "Feature Selection from High-Dimensional Data with Very Low Sample Size:\n  A Cautionary Tale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification problems, the purpose of feature selection is to identify a\nsmall, highly discriminative subset of the original feature set. In many\napplications, the dataset may have thousands of features and only a few dozens\nof samples (sometimes termed `wide'). This study is a cautionary tale\ndemonstrating why feature selection in such cases may lead to undesirable\nresults. In view to highlight the sample size issue, we derive the required\nsample size for declaring two features different. Using an example, we\nillustrate the heavy dependency between feature set and classifier, which poses\na question to classifier-agnostic feature selection methods. However, the\nchoice of a good selector-classifier pair is hampered by the low correlation\nbetween estimated and true error rate, as illustrated by another example. While\nprevious studies raising similar issues validate their message with mostly\nsynthetic data, here we carried out an experiment with 20 real datasets. We\ncreated an exaggerated scenario whereby we cut a very small portion of the data\n(10 instances per class) for feature selection and used the rest of the data\nfor testing. The results reinforce the caution and suggest that it may be\nbetter to refrain from feature selection from very wide datasets rather than\nreturn misleading output to the user.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:00:58 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kuncheva", "Ludmila I.", ""], ["Matthews", "Clare E.", ""], ["Arnaiz-Gonz\u00e1lez", "\u00c1lvar", ""], ["Rodr\u00edguez", "Juan J.", ""]]}, {"id": "2008.12037", "submitter": "Ekaterina Iakovleva", "authors": "Ekaterina Iakovleva, Jakob Verbeek, Karteek Alahari", "title": "Meta-Learning with Shared Amortized Variational Inference", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel amortized variational inference scheme for an empirical\nBayes meta-learning model, where model parameters are treated as latent\nvariables. We learn the prior distribution over model parameters conditioned on\nlimited training data using a variational autoencoder approach. Our framework\nproposes sharing the same amortized inference network between the conditional\nprior and variational posterior distributions over the model parameters. While\nthe posterior leverages both the labeled support and query data, the\nconditional prior is based only on the labeled support data. We show that in\nearlier work, relying on Monte-Carlo approximation, the conditional prior\ncollapses to a Dirac delta function. In contrast, our variational approach\nprevents this collapse and preserves uncertainty over the model parameters. We\nevaluate our approach on the miniImageNet, CIFAR-FS and FC100 datasets, and\npresent results demonstrating its advantages over previous work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:28:13 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Iakovleva", "Ekaterina", ""], ["Verbeek", "Jakob", ""], ["Alahari", "Karteek", ""]]}, {"id": "2008.12063", "submitter": "Wolfgang Garn", "authors": "Wolfgang Garn", "title": "Balanced dynamic multiple travelling salesmen: algorithms and continuous\n  approximations", "comments": "15 pages, 10 figures, 7 tables, 2 heuristics, 3 CAM models", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic routing occurs when customers are not known in advance, e.g. for\nreal-time routing. Two heuristics are proposed that solve the balanced dynamic\nmultiple travelling salesmen problem (BD-mTSP). These heuristics represent\noperational (tactical) tools for dynamic (online, real-time) routing. Several\ntypes and scopes of dynamics are proposed. Particular attention is given to\nsequential dynamics. The balanced dynamic closest vehicle heuristic (BD-CVH)\nand the balanced dynamic assignment vehicle heuristic (BD-AVH) are applied to\nthis type of dynamics. The algorithms are tested for instances in the Euclidean\nplane. Continuous approximation models for the BD-mTSP's are derived and serve\nas strategic tools for dynamic routing. The models express route lengths using\nvehicles, customers and dynamic scopes without the need of running an\nalgorithm. A machine learning approach was used to obtain regression models.\nThe mean-average-percentage error of two of these models is below 3%.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 11:41:20 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Garn", "Wolfgang", ""]]}, {"id": "2008.12065", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Astin-Walmsley Kieren, Heath Kerina, Richi Nayak", "title": "Propensity-to-Pay: Machine Learning for Estimating Prediction\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting a customer's propensity-to-pay at an early point in the revenue\ncycle can provide organisations many opportunities to improve the customer\nexperience, reduce hardship and reduce the risk of impaired cash flow and\noccurrence of bad debt. With the advancements in data science; machine learning\ntechniques can be used to build models to accurately predict a customer's\npropensity-to-pay. Creating effective machine learning models without access to\nlarge and detailed datasets presents some significant challenges. This paper\npresents a case-study, conducted on a dataset from an energy organisation, to\nexplore the uncertainty around the creation of machine learning models that are\nable to predict residential customers entering financial hardship which then\nreduces their ability to pay energy bills. Incorrect predictions can result in\ninefficient resource allocation and vulnerable customers not being proactively\nidentified. This study investigates machine learning models' ability to\nconsider different contexts and estimate the uncertainty in the prediction.\nSeven models from four families of machine learning algorithms are investigated\nfor their novel utilisation. A novel concept of utilising a Baysian Neural\nNetwork to the binary classification problem of propensity-to-pay energy bills\nis proposed and explored for deployment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 11:49:25 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bashar", "Md Abul", ""], ["Kieren", "Astin-Walmsley", ""], ["Kerina", "Heath", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.12070", "submitter": "Tim Sullivan", "authors": "Ilja Klebanov and Bj\\\"orn Sprungk and T. J. Sullivan", "title": "The linear conditional expectation in Hilbert space", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear conditional expectation (LCE) provides a best linear (or rather,\naffine) estimate of the conditional expectation and hence plays an important\nr\\^ole in approximate Bayesian inference, especially the Bayes linear approach.\nThis article establishes the analytical properties of the LCE in an\ninfinite-dimensional Hilbert space context. In addition, working in the space\nof affine Hilbert--Schmidt operators, we establish a regularisation procedure\nfor this LCE. As an important application, we obtain a simple alternative\nderivation and intuitive justification of the conditional mean embedding\nformula, a concept widely used in machine learning to perform the conditioning\nof random variables by embedding them into reproducing kernel Hilbert spaces.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 11:56:51 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 14:35:32 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Klebanov", "Ilja", ""], ["Sprungk", "Bj\u00f6rn", ""], ["Sullivan", "T. J.", ""]]}, {"id": "2008.12122", "submitter": "Michele Ceriotti", "authors": "Andrea Grisafi and Jigyasa Nigam and Michele Ceriotti", "title": "Multi-scale approach for the prediction of atomic scale properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic nearsightedness is one of the fundamental principles governing the\nbehavior of condensed matter and supporting its description in terms of local\nentities such as chemical bonds. Locality also underlies the tremendous success\nof machine-learning schemes that predict quantum mechanical observables -- such\nas the cohesive energy, the electron density, or a variety of response\nproperties -- as a sum of atom-centred contributions, based on a short-range\nrepresentation of atomic environments. One of the main shortcomings of these\napproaches is their inability to capture physical effects, ranging from\nelectrostatic interactions to quantum delocalization, which have a long-range\nnature. Here we show how to build a multi-scale scheme that combines in the\nsame framework local and non-local information, overcoming such limitations. We\nshow that the simplest version of such features can be put in formal\ncorrespondence with a multipole expansion of permanent electrostatics. The\ndata-driven nature of the model construction, however, makes this simple form\nsuitable to tackle also different types of delocalized and collective effects.\nWe present several examples that range from molecular physics, to surface\nscience and biophysics, demonstrating the ability of this multi-scale approach\nto model interactions driven by electrostatics, polarization and dispersion, as\nwell as the cooperative behavior of dielectric response functions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:01:00 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 09:35:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Grisafi", "Andrea", ""], ["Nigam", "Jigyasa", ""], ["Ceriotti", "Michele", ""]]}, {"id": "2008.12138", "submitter": "Galit Shmueli", "authors": "Galit Shmueli", "title": "\"Improving\" prediction of human behavior using behavior modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of statistics and machine learning design algorithms, models, and\napproaches to improve prediction. Larger and richer behavioral data increase\npredictive power, as evident from recent advances in behavioral prediction\ntechnology. Large internet platforms that collect behavioral big data predict\nuser behavior for internal purposes and for third parties (advertisers,\ninsurers, security forces, political consulting firms) who utilize the\npredictions for personalization, targeting and other decision-making. While\nstandard data collection and modeling efforts are directed at improving\npredicted values, internet platforms can minimize prediction error by \"pushing\"\nusers' actions towards their predicted values using behavior modification\ntechniques. The better the platform can make users conform to their predicted\noutcomes, the more it can boast its predictive accuracy and ability to induce\nbehavior change. Hence, platforms are strongly incentivized to \"make\npredictions true\". This strategy is absent from the ML and statistics\nliterature. Investigating its properties requires incorporating causal notation\ninto the correlation-based predictive environment---an integration currently\nmissing. To tackle this void, we integrate Pearl's causal do(.) operator into\nthe predictive framework. We then decompose the expected prediction error given\nbehavior modification, and identify the components impacting predictive power.\nOur derivation elucidates the implications of such behavior modification to\ndata scientists, platforms, their clients, and the humans whose behavior is\nmanipulated. Behavior modification can make users' behavior more predictable\nand even more homogeneous; yet this apparent predictability might not\ngeneralize when clients use predictions in practice. Outcomes pushed towards\ntheir predictions can be at odds with clients' intentions, and harmful to\nmanipulated users.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 12:39:35 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Shmueli", "Galit", ""]]}, {"id": "2008.12145", "submitter": "William Cheung", "authors": "William Cheung and Sudip Vhaduri", "title": "Context-Dependent Implicit Authentication for Wearable Device User", "comments": "7 pages, 5 figures, accepted at IEEE International Symposium on\n  Personal, Indoor and Mobile Radio Communications (PIMRC). arXiv admin note:\n  substantial text overlap with arXiv:2008.10779", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As market wearables are becoming popular with a range of services, including\nmaking financial transactions, accessing cars, etc. that they provide based on\nvarious private information of a user, security of this information is becoming\nvery important. However, users are often flooded with PINs and passwords in\nthis internet of things (IoT) world. Additionally, hard-biometric, such as\nfacial or finger recognition, based authentications are not adaptable for\nmarket wearables due to their limited sensing and computation capabilities.\nTherefore, it is a time demand to develop a burden-free implicit authentication\nmechanism for wearables using the less-informative soft-biometric data that are\neasily obtainable from the market wearables. In this work, we present a\ncontext-dependent soft-biometric-based wearable authentication system utilizing\nthe heart rate, gait, and breathing audio signals. From our detailed analysis,\nwe find that a binary support vector machine (SVM) with radial basis function\n(RBF) kernel can achieve an average accuracy of $0.94 \\pm 0.07$, $F_1$ score of\n$0.93 \\pm 0.08$, an equal error rate (EER) of about $0.06$ at a lower\nconfidence threshold of 0.52, which shows the promise of this work.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:34:19 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Cheung", "William", ""], ["Vhaduri", "Sudip", ""]]}, {"id": "2008.12152", "submitter": "Rodrigo Rivera-Castro", "authors": "Aiusha Sangadiev, Rodrigo Rivera-Castro, Kirill Stepanov, Andrey\n  Poddubny, Kirill Bubenchikov, Nikita Bekezin, Polina Pilyugina and Evgeny\n  Burnaev", "title": "DeepFolio: Convolutional Neural Networks for Portfolios with Limit Order\n  Book Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.TR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes DeepFolio, a new model for deep portfolio management based\non data from limit order books (LOB). DeepFolio solves problems found in the\nstate-of-the-art for LOB data to predict price movements. Our evaluation\nconsists of two scenarios using a large dataset of millions of time series. The\nimprovements deliver superior results both in cases of abundant as well as\nscarce data. The experiments show that DeepFolio outperforms the\nstate-of-the-art on the benchmark FI-2010 LOB. Further, we use DeepFolio for\noptimal portfolio allocation of crypto-assets with rebalancing. For this\npurpose, we use two loss-functions - Sharpe ratio loss and minimum volatility\nrisk. We show that DeepFolio outperforms widely used portfolio allocation\ntechniques in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:28:18 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Sangadiev", "Aiusha", ""], ["Rivera-Castro", "Rodrigo", ""], ["Stepanov", "Kirill", ""], ["Poddubny", "Andrey", ""], ["Bubenchikov", "Kirill", ""], ["Bekezin", "Nikita", ""], ["Pilyugina", "Polina", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2008.12161", "submitter": "Xinyi Xu Mr", "authors": "Lingjuan Lyu, Xinyi Xu, and Qian Wang", "title": "Collaborative Fairness in Federated Learning", "comments": "accepted to FL-IJCAI'20 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current deep learning paradigms, local training or the Standalone\nframework tends to result in overfitting and thus poor generalizability. This\nproblem can be addressed by Distributed or Federated Learning (FL) that\nleverages a parameter server to aggregate model updates from individual\nparticipants. However, most existing Distributed or FL frameworks have\noverlooked an important aspect of participation: collaborative fairness. In\nparticular, all participants can receive the same or similar models, regardless\nof their contributions. To address this issue, we investigate the collaborative\nfairness in FL, and propose a novel Collaborative Fair Federated Learning\n(CFFL) framework which utilizes reputation to enforce participants to converge\nto different models, thus achieving fairness without compromising the\npredictive performance. Extensive experiments on benchmark datasets demonstrate\nthat CFFL achieves high fairness, delivers comparable accuracy to the\nDistributed framework, and outperforms the Standalone framework.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:39:09 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 01:06:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Xu", "Xinyi", ""], ["Wang", "Qian", ""]]}, {"id": "2008.12172", "submitter": "Anna Kruspe", "authors": "Anna Kruspe and Matthias H\\\"aberle and Iona Kuhn and Xiao Xiang Zhu", "title": "Cross-language sentiment analysis of European Twitter messages duringthe\n  COVID-19 pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media data can be a very salient source of information during crises.\nUser-generated messages provide a window into people's minds during such times,\nallowing us insights about their moods and opinions. Due to the vast amounts of\nsuch messages, a large-scale analysis of population-wide developments becomes\npossible. In this paper, we analyze Twitter messages (tweets) collected during\nthe first months of the COVID-19 pandemic in Europe with regard to their\nsentiment. This is implemented with a neural network for sentiment analysis\nusing multilingual sentence embeddings. We separate the results by country of\norigin, and correlate their temporal development with events in those\ncountries. This allows us to study the effect of the situation on people's\nmoods. We see, for example, that lockdown announcements correlate with a\ndeterioration of mood in almost all surveyed countries, which recovers within a\nshort time span.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:00:36 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kruspe", "Anna", ""], ["H\u00e4berle", "Matthias", ""], ["Kuhn", "Iona", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2008.12187", "submitter": "Shengli Jiang", "authors": "Shengli Jiang, Prasanna Balaprakash", "title": "Graph Neural Network Architecture Search for Molecular Property\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the properties of a molecule from its structure is a challenging\ntask. Recently, deep learning methods have improved the state of the art for\nthis task because of their ability to learn useful features from the given\ndata. By treating molecule structure as graphs, where atoms and bonds are\nmodeled as nodes and edges, graph neural networks (GNNs) have been widely used\nto predict molecular properties. However, the design and development of GNNs\nfor a given data set rely on labor-intensive design and tuning of the network\narchitectures. Neural architecture search (NAS) is a promising approach to\ndiscover high-performing neural network architectures automatically. To that\nend, we develop an NAS approach to automate the design and development of GNNs\nfor molecular property prediction. Specifically, we focus on automated\ndevelopment of message-passing neural networks (MPNNs) to predict the molecular\nproperties of small molecules in quantum mechanics and physical chemistry data\nsets from the MoleculeNet benchmark. We demonstrate the superiority of the\nautomatically discovered MPNNs by comparing them with manually designed GNNs\nfrom the MoleculeNet benchmark. We study the relative importance of the choices\nin the MPNN search space, demonstrating that customizing the architecture is\ncritical to enhancing performance in molecular property prediction and that the\nproposed approach can perform customization automatically with minimal manual\neffort.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:30:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jiang", "Shengli", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.12224", "submitter": "Ping Li", "authors": "Jerry Chee and Ping Li", "title": "Understanding and Detecting Convergence for Stochastic Gradient Descent\n  with Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence detection of iterative stochastic optimization methods is of\ngreat practical interest. This paper considers stochastic gradient descent\n(SGD) with a constant learning rate and momentum. We show that there exists a\ntransient phase in which iterates move towards a region of interest, and a\nstationary phase in which iterates remain bounded in that region around a\nminimum point. We construct a statistical diagnostic test for convergence to\nthe stationary phase using the inner product between successive gradients and\ndemonstrate that the proposed diagnostic works well. We theoretically and\nempirically characterize how momentum can affect the test statistic of the\ndiagnostic, and how the test statistic captures a relatively sparse signal\nwithin the gradients in convergence. Finally, we demonstrate an application to\nautomatically tune the learning rate by reducing it each time stationarity is\ndetected, and show the procedure is robust to mis-specified initial rates.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:24:18 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chee", "Jerry", ""], ["Li", "Ping", ""]]}, {"id": "2008.12228", "submitter": "Tim Hertweck", "authors": "Roland Hafner, Tim Hertweck, Philipp Kl\\\"oppner, Michael Bloesch,\n  Michael Neunert, Markus Wulfmeier, Saran Tunyasuvunakool, Nicolas Heess,\n  Martin Riedmiller", "title": "Towards General and Autonomous Learning of Core Skills: A Case Study in\n  Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Reinforcement Learning (RL) algorithms promise to solve difficult\nmotor control problems directly from raw sensory inputs. Their attraction is\ndue in part to the fact that they can represent a general class of methods that\nallow to learn a solution with a reasonably set reward and minimal prior\nknowledge, even in situations where it is difficult or expensive for a human\nexpert. For RL to truly make good on this promise, however, we need algorithms\nand learning setups that can work across a broad range of problems with minimal\nproblem specific adjustments or engineering. In this paper, we study this idea\nof generality in the locomotion domain. We develop a learning framework that\ncan learn sophisticated locomotion behavior for a wide spectrum of legged\nrobots, such as bipeds, tripeds, quadrupeds and hexapods, including wheeled\nvariants. Our learning framework relies on a data-efficient, off-policy\nmulti-task RL algorithm and a small set of reward functions that are\nsemantically identical across robots. To underline the general applicability of\nthe method, we keep the hyper-parameter settings and reward definitions\nconstant across experiments and rely exclusively on on-board sensing. For nine\ndifferent types of robots, including a real-world quadruped robot, we\ndemonstrate that the same algorithm can rapidly learn diverse and reusable\nlocomotion skills without any platform specific adjustments or additional\ninstrumentation of the learning setup.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:23:55 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Hafner", "Roland", ""], ["Hertweck", "Tim", ""], ["Kl\u00f6ppner", "Philipp", ""], ["Bloesch", "Michael", ""], ["Neunert", "Michael", ""], ["Wulfmeier", "Markus", ""], ["Tunyasuvunakool", "Saran", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2008.12248", "submitter": "Yunhao Yang", "authors": "Yunhao Yang, Andrew Whinston", "title": "A Survey on Reinforcement Learning for Combinatorial Optimization", "comments": "manuscript submitted to Management Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a detailed review of reinforcement learning in combinatorial\noptimization, introduces the history of combinatorial optimization starting in\nthe 1960s, and compares it with the reinforcement learning algorithms in recent\nyears. We explicitly look at a famous combinatorial problem known as the\nTraveling Salesperson Problem (TSP). We compare the approach of the modern\nreinforcement learning algorithms on TSP with an approach published in 1970.\nThen, we discuss the similarities between these algorithms and how the approach\nof reinforcement learning changes due to the evolution of machine learning\ntechniques and computing power. We also mention the deep learning approach on\nthe TSP, which is named Deep Reinforcement Learning. We argue that deep\nlearning is a generic approach that can be integrated with traditional\nreinforcement learning algorithms and optimize the outcomes of the TSP.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:08:55 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 18:52:22 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Yang", "Yunhao", ""], ["Whinston", "Andrew", ""]]}, {"id": "2008.12282", "submitter": "Saskia Nu\\~nez von Voigt", "authors": "Saskia Nu\\~nez von Voigt, Mira Pauli, Johanna Reichert, Florian\n  Tschorsch", "title": "Every Query Counts: Analyzing the Privacy Loss of Exploratory Data\n  Analyses", "comments": "Accepted Paper for DPM 2020 co-located ESORICS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-66172-4_17", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exploratory data analysis is an essential step for every data analyst to\ngain insights, evaluate data quality and (if required) select a machine\nlearning model for further processing. While privacy-preserving machine\nlearning is on the rise, more often than not this initial analysis is not\ncounted towards the privacy budget. In this paper, we quantify the privacy loss\nfor basic statistical functions and highlight the importance of taking it into\naccount when calculating the privacy-loss budget of a machine learning\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:40:29 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["von Voigt", "Saskia Nu\u00f1ez", ""], ["Pauli", "Mira", ""], ["Reichert", "Johanna", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2008.12284", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M. R. Arnold, Praateek Mahajan, Debajyoti Datta, Ian\n  Bunner, Konstantinos Saitas Zarkias", "title": "learn2learn: A Library for Meta-Learning Research", "comments": "Software available at: https://github.com/learnables/learn2learn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning researchers face two fundamental issues in their empirical\nwork: prototyping and reproducibility. Researchers are prone to make mistakes\nwhen prototyping new algorithms and tasks because modern meta-learning methods\nrely on unconventional functionalities of machine learning frameworks. In turn,\nreproducing existing results becomes a tedious endeavour -- a situation\nexacerbated by the lack of standardized implementations and benchmarks. As a\nresult, researchers spend inordinate amounts of time on implementing software\nrather than understanding and developing new ideas.\n  This manuscript introduces learn2learn, a library for meta-learning research\nfocused on solving those prototyping and reproducibility issues. learn2learn\nprovides low-level routines common across a wide-range of meta-learning\ntechniques (e.g. meta-descent, meta-reinforcement learning, few-shot learning),\nand builds standardized interfaces to algorithms and benchmarks on top of them.\nIn releasing learn2learn under a free and open source license, we hope to\nfoster a community around standardized software for meta-learning research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:41:34 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 03:48:50 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Mahajan", "Praateek", ""], ["Datta", "Debajyoti", ""], ["Bunner", "Ian", ""], ["Zarkias", "Konstantinos Saitas", ""]]}, {"id": "2008.12315", "submitter": "Magda Amiridi", "authors": "Magda Amiridi, Nikos Kargas, Nicholas D. Sidiropoulos", "title": "Low-rank Characteristic Tensor Density Estimation Part I: Foundations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective non-parametric density estimation is a key challenge in\nhigh-dimensional multivariate data analysis. In this paper,we propose a novel\napproach that builds upon tensor factorization tools. Any multivariate density\ncan be represented by its characteristic function, via the Fourier transform.\nIf the sought density is compactly supported, then its characteristic function\ncan be approximated, within controllable error, by a finite tensor of leading\nFourier coefficients, whose size de-pends on the smoothness of the underlying\ndensity. This tensor can be naturally estimated from observed realizations of\nthe random vector of interest, via sample averaging. In order to circumvent the\ncurse of dimensionality, we introduce a low-rank model of this characteristic\ntensor, which significantly improves the density estimate especially for\nhigh-dimensional data and/or in the sample-starved regime. By virtue of\nuniqueness of low-rank tensor decomposition, under certain conditions, our\nmethod enables learning the true data-generating distribution. We demonstrate\nthe very promising performance of the proposed method using several measured\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:06:19 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 03:06:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Amiridi", "Magda", ""], ["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2008.12319", "submitter": "Joshua Hanson", "authors": "Joshua Hanson, Pavel Bochev, Biliana Paskaleva", "title": "Learning Compact Physics-Aware Delayed Photocurrent Models Using Dynamic\n  Mode Decomposition", "comments": "18 pages, 17 figures, submitted to SADM CoDA 2020 special issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiation-induced photocurrent in semiconductor devices can be simulated\nusing complex physics-based models, which are accurate, but computationally\nexpensive. This presents a challenge for implementing device characteristics in\nhigh-level circuit simulations where it is computationally infeasible to\nevaluate detailed models for multiple individual circuit elements. In this work\nwe demonstrate a procedure for learning compact delayed photocurrent models\nthat are efficient enough to implement in large-scale circuit simulations, but\nremain faithful to the underlying physics. Our approach utilizes Dynamic Mode\nDecomposition (DMD), a system identification technique for learning reduced\norder discrete-time dynamical systems from time series data based on singular\nvalue decomposition. To obtain physics-aware device models, we simulate the\nexcess carrier density induced by radiation pulses by solving numerically the\nAmbipolar Diffusion Equation, then use the simulated internal state as training\ndata for the DMD algorithm. Our results show that the significantly reduced\norder delayed photocurrent models obtained via this method accurately\napproximate the dynamics of the internal excess carrier density -- which can be\nused to calculate the induced current at the device boundaries -- while\nremaining compact enough to incorporate into larger circuit simulations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:21:46 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Hanson", "Joshua", ""], ["Bochev", "Pavel", ""], ["Paskaleva", "Biliana", ""]]}, {"id": "2008.12330", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "The Impact of Discretization Method on the Detection of Six Types of\n  Anomalies in Datasets", "comments": "16 pages, 5 figures, 2 tables. Presented at the 30th Benelux\n  Conference on Artificial Intelligence (BNAIC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is the process of identifying cases, or groups of cases,\nthat are in some way unusual and do not fit the general patterns present in the\ndataset. Numerous algorithms use discretization of numerical data in their\ndetection processes. This study investigates the effect of the discretization\nmethod on the unsupervised detection of each of the six anomaly types\nacknowledged in a recent typology of data anomalies. To this end, experiments\nare conducted with various datasets and SECODA, a general-purpose algorithm for\nunsupervised non-parametric anomaly detection in datasets with numerical and\ncategorical attributes. This algorithm employs discretization of continuous\nattributes, exponentially increasing weights and discretization cut points, and\na pruning heuristic to detect anomalies with an optimal number of iterations.\nThe results demonstrate that standard SECODA can detect all six types, but that\ndifferent discretization methods favor the discovery of certain anomaly types.\nThe main findings also hold for other detection techniques using\ndiscretization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:43:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2008.12332", "submitter": "Sarah Dean", "authors": "Sarah Dean and Benjamin Recht", "title": "Certainty Equivalent Perception-Based Control", "comments": "to appear at L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to certify performance and safety, feedback control requires precise\ncharacterization of sensor errors. In this paper, we provide guarantees on such\nfeedback systems when sensors are characterized by solving a supervised\nlearning problem. We show a uniform error bound on nonparametric kernel\nregression under a dynamically-achievable dense sampling scheme. This allows\nfor a finite-time convergence rate on the sub-optimality of using the regressor\nin closed-loop for waypoint tracking. We demonstrate our results in simulation\nwith simplified unmanned aerial vehicle and autonomous driving examples.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:45:40 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 19:45:35 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Dean", "Sarah", ""], ["Recht", "Benjamin", ""]]}, {"id": "2008.12333", "submitter": "Marcus Badgeley", "authors": "Gabe Schamberg, Marcus Badgeley, and Emery N. Brown", "title": "Controlling Level of Unconsciousness by Titrating Propofol with Deep\n  Reinforcement Learning", "comments": "International Conference on Artificial Intelligence in Medicine 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) can be used to fit a mapping from patient state\nto a medication regimen. Prior studies have used deterministic and value-based\ntabular learning to learn a propofol dose from an observed anesthetic state.\nDeep RL replaces the table with a deep neural network and has been used to\nlearn medication regimens from registry databases. Here we perform the first\napplication of deep RL to closed-loop control of anesthetic dosing in a\nsimulated environment. We use the cross-entropy method to train a deep neural\nnetwork to map an observed anesthetic state to a probability of infusing a\nfixed propofol dosage. During testing, we implement a deterministic policy that\ntransforms the probability of infusion to a continuous infusion rate. The model\nis trained and tested on simulated pharmacokinetic/pharmacodynamic models with\nrandomized parameters to ensure robustness to patient variability. The deep RL\nagent significantly outperformed a proportional-integral-derivative controller\n(median absolute performance error 1.7% +/- 0.6 and 3.4% +/- 1.2). Modeling\ncontinuous input variables instead of a table affords more robust pattern\nrecognition and utilizes our prior domain knowledge. Deep RL learned a smooth\npolicy with a natural interpretation to data scientists and anesthesia care\nproviders alike.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:47:08 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:24:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Schamberg", "Gabe", ""], ["Badgeley", "Marcus", ""], ["Brown", "Emery N.", ""]]}, {"id": "2008.12335", "submitter": "Vahid Noroozi", "authors": "Vahid Noroozi, Yang Zhang, Evelina Bakhturina, Tomasz Kornuta", "title": "A Fast and Robust BERT-based Dialogue State Tracker for Schema-Guided\n  Dialogue Dataset", "comments": "Accepted to the Workshop on Conversational Systems Towards Mainstream\n  Adoption at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog State Tracking (DST) is one of the most crucial modules for\ngoal-oriented dialogue systems. In this paper, we introduce FastSGT (Fast\nSchema Guided Tracker), a fast and robust BERT-based model for state tracking\nin goal-oriented dialogue systems. The proposed model is designed for the\nSchema-Guided Dialogue (SGD) dataset which contains natural language\ndescriptions for all the entities including user intents, services, and slots.\nThe model incorporates two carry-over procedures for handling the extraction of\nthe values not explicitly mentioned in the current user utterance. It also uses\nmulti-head attention projections in some of the decoders to have a better\nmodelling of the encoder outputs. In the conducted experiments we compared\nFastSGT to the baseline model for the SGD dataset. Our model keeps the\nefficiency in terms of computational and memory consumption while improving the\naccuracy significantly. Additionally, we present ablation studies measuring the\nimpact of different parts of the model on its performance. We also show the\neffectiveness of data augmentation for improving the accuracy without\nincreasing the amount of computational resources.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:51:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Noroozi", "Vahid", ""], ["Zhang", "Yang", ""], ["Bakhturina", "Evelina", ""], ["Kornuta", "Tomasz", ""]]}, {"id": "2008.12338", "submitter": "Gauri Jagatap", "authors": "Gauri Jagatap, Ameya Joshi, Animesh Basak Chowdhury, Siddharth Garg,\n  Chinmay Hegde", "title": "Adversarially Robust Learning via Entropic Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new family of algorithms, ATENT, for training\nadversarially robust deep neural networks. We formulate a new loss function\nthat is equipped with an additional entropic regularization. Our loss function\nconsiders the contribution of adversarial samples that are drawn from a\nspecially designed distribution in the data space that assigns high probability\nto points with high loss and in the immediate neighborhood of training samples.\nOur proposed algorithms optimize this loss to seek adversarially robust valleys\nof the loss landscape. Our approach achieves competitive (or better)\nperformance in terms of robust classification accuracy as compared to several\nstate-of-the-art robust learning approaches on benchmark datasets such as MNIST\nand CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:54:43 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 15:39:02 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jagatap", "Gauri", ""], ["Joshi", "Ameya", ""], ["Chowdhury", "Animesh Basak", ""], ["Garg", "Siddharth", ""], ["Hegde", "Chinmay", ""]]}, {"id": "2008.12340", "submitter": "Tianyang Xie", "authors": "Tianyang Xie, Jie Ding", "title": "Forecasting with Multiple Seasonality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging number of modern applications involve forecasting time series\ndata that exhibit both short-time dynamics and long-time seasonality.\nSpecifically, time series with multiple seasonality is a difficult task with\ncomparatively fewer discussions. In this paper, we propose a two-stage method\nfor time series with multiple seasonality, which does not require\npre-determined seasonality periods. In the first stage, we generalize the\nclassical seasonal autoregressive moving average (ARMA) model in multiple\nseasonality regime. In the second stage, we utilize an appropriate criterion\nfor lag order selection. Simulation and empirical studies show the excellent\npredictive performance of our method, especially compared to a recently popular\n`Facebook Prophet' model for time series.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:08:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Xie", "Tianyang", ""], ["Ding", "Jie", ""]]}, {"id": "2008.12410", "submitter": "Niharika Shimona D'Souza", "authors": "Niharika Shimona D'Souza, Mary Beth Nebel, Deana Crocetti, Nicholas\n  Wymbs, Joshua Robinson, Stewart H. Mostofsky, Archana Venkataraman", "title": "Deep sr-DDL: Deep Structurally Regularized Dynamic Dictionary Learning\n  to Integrate Multimodal and Dynamic Functional Connectomics data for\n  Multidimensional Clinical Characterizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel integrated framework that jointly models complementary\ninformation from resting-state functional MRI (rs-fMRI) connectivity and\ndiffusion tensor imaging (DTI) tractography to extract biomarkers of brain\nconnectivity predictive of behavior. Our framework couples a generative model\nof the connectomics data with a deep network that predicts behavioral scores.\nThe generative component is a structurally-regularized Dynamic Dictionary\nLearning (sr-DDL) model that decomposes the dynamic rs-fMRI correlation\nmatrices into a collection of shared basis networks and time varying\nsubject-specific loadings. We use the DTI tractography to regularize this\nmatrix factorization and learn anatomically informed functional connectivity\nprofiles. The deep component of our framework is an LSTM-ANN block, which uses\nthe temporal evolution of the subject-specific sr-DDL loadings to predict\nmultidimensional clinical characterizations. Our joint optimization strategy\ncollectively estimates the basis networks, the subject-specific time-varying\nloadings, and the neural network weights. We validate our framework on a\ndataset of neurotypical individuals from the Human Connectome Project (HCP)\ndatabase to map to cognition and on a separate multi-score prediction task on\nindividuals diagnosed with Autism Spectrum Disorder (ASD) in a five-fold cross\nvalidation setting. Our hybrid model outperforms several state-of-the-art\napproaches at clinical outcome prediction and learns interpretable multimodal\nneural signatures of brain organization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:43:56 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["D'Souza", "Niharika Shimona", ""], ["Nebel", "Mary Beth", ""], ["Crocetti", "Deana", ""], ["Wymbs", "Nicholas", ""], ["Robinson", "Joshua", ""], ["Mostofsky", "Stewart H.", ""], ["Venkataraman", "Archana", ""]]}, {"id": "2008.12438", "submitter": "Weijun Xie", "authors": "Yongchun Li and Weijun Xie", "title": "Exact and Approximation Algorithms for Sparse PCA", "comments": "49 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse PCA (SPCA) is a fundamental model in machine learning and data\nanalytics, which has witnessed a variety of application areas such as finance,\nmanufacturing, biology, healthcare. To select a prespecified-size principal\nsubmatrix from a covariance matrix to maximize its largest eigenvalue for the\nbetter interpretability purpose, SPCA advances the conventional PCA with both\nfeature selection and dimensionality reduction. This paper proposes two exact\nmixed-integer SDPs (MISDPs) by exploiting the spectral decomposition of the\ncovariance matrix and the properties of the largest eigenvalues. We then\nanalyze the theoretical optimality gaps of their continuous relaxation values\nand prove that they are stronger than that of the state-of-art one. We further\nshow that the continuous relaxations of two MISDPs can be recast as saddle\npoint problems without involving semi-definite cones, and thus can be\neffectively solved by first-order methods such as the subgradient method. Since\noff-the-shelf solvers, in general, have difficulty in solving MISDPs, we\napproximate SPCA with arbitrary accuracy by a mixed-integer linear program\n(MILP) of a similar size as MISDPs. To be more scalable, we also analyze greedy\nand local search algorithms, prove their first-known approximation ratios, and\nshow that the approximation ratios are tight. Our numerical study demonstrates\nthat the continuous relaxation values of the proposed MISDPs are quite close to\noptimality, the proposed MILP model can solve small and medium-size instances\nto optimality, and the approximation algorithms work very well for all the\ninstances. Finally, we extend the analyses to Rank-one Sparse SVD (R1-SSVD)\nwith non-symmetric matrices and Sparse Fair PCA (SFPCA) when there are multiple\ncovariance matrices, each corresponding to a protected group.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:07:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Li", "Yongchun", ""], ["Xie", "Weijun", ""]]}, {"id": "2008.12442", "submitter": "Zhe Jiang", "authors": "Wenchong He and Zhe Jiang", "title": "Semi-supervised Learning with the EM Algorithm: A Comparative Study\n  between Unstructured and Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning aims to learn prediction models from both labeled\nand unlabeled samples. There has been extensive research in this area. Among\nexisting work, generative mixture models with Expectation-Maximization (EM) is\na popular method due to clear statistical properties. However, existing\nliterature on EM-based semi-supervised learning largely focuses on unstructured\nprediction, assuming that samples are independent and identically distributed.\nStudies on EM-based semi-supervised approach in structured prediction is\nlimited. This paper aims to fill the gap through a comparative study between\nunstructured and structured methods in EM-based semi-supervised learning.\nSpecifically, we compare their theoretical properties and find that both\nmethods can be considered as a generalization of self-training with soft class\nassignment of unlabeled samples, but the structured method additionally\nconsiders structural constraint in soft class assignment. We conducted a case\nstudy on real-world flood mapping datasets to compare the two methods. Results\nshow that structured EM is more robust to class confusion caused by noise and\nobstacles in features in the context of the flood mapping application.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:20:05 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["He", "Wenchong", ""], ["Jiang", "Zhe", ""]]}, {"id": "2008.12450", "submitter": "Xu Chen", "authors": "Xu Chen and Jiangchao Yao and Maosen Li and Ya zhang and Yanfeng Wang", "title": "Decoupled Variational Embedding for Signed Directed Networks", "comments": "This paper is accepted by ACM Transactions on the WEB, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node representation learning for signed directed networks has received\nconsiderable attention in many real-world applications such as link sign\nprediction, node classification and node recommendation. The challenge lies in\nhow to adequately encode the complex topological information of the networks.\nRecent studies mainly focus on preserving the first-order network topology\nwhich indicates the closeness relationships of nodes. However, these methods\ngenerally fail to capture the high-order topology which indicates the local\nstructures of nodes and serves as an essential characteristic of the network\ntopology. In addition, for the first-order topology, the additional value of\nnon-existent links is largely ignored. In this paper, we propose to learn more\nrepresentative node embeddings by simultaneously capturing the first-order and\nhigh-order topology in signed directed networks. In particular, we reformulate\nthe representation learning problem on signed directed networks from a\nvariational auto-encoding perspective and further develop a decoupled\nvariational embedding (DVE) method. DVE leverages a specially designed\nauto-encoder structure to capture both the first-order and high-order topology\nof signed directed networks, and thus learns more representative node\nembedding. Extensive experiments are conducted on three widely used real-world\ndatasets. Comprehensive results on both link sign prediction and node\nrecommendation task demonstrate the effectiveness of DVE. Qualitative results\nand analysis are also given to provide a better understanding of DVE.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:48:15 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Xu", ""], ["Yao", "Jiangchao", ""], ["Li", "Maosen", ""], ["zhang", "Ya", ""], ["Wang", "Yanfeng", ""]]}, {"id": "2008.12454", "submitter": "Robert Bassett", "authors": "Robert Bassett, Mitchell Graves, Patrick Reilly", "title": "Color and Edge-Aware Adversarial Image Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial perturbation of images, in which a source image is deliberately\nmodified with the intent of causing a classifier to misclassify the image,\nprovides important insight into the robustness of image classifiers. In this\nwork we develop two new methods for constructing adversarial perturbations,\nboth of which are motivated by minimizing human ability to detect changes\nbetween the perturbed and source image. The first of these, the Edge-Aware\nmethod, reduces the magnitude of perturbations permitted in smooth regions of\nan image where changes are more easily detected. Our second method, the\nColor-Aware method, performs the perturbation in a color space which accurately\ncaptures human ability to distinguish differences in colors, thus reducing the\nperceived change. The Color-Aware and Edge-Aware methods can also be\nimplemented simultaneously, resulting in image perturbations which account for\nboth human color perception and sensitivity to changes in homogeneous regions.\nBecause Edge-Aware and Color-Aware modifications exist for many image\nperturbations techniques, we also focus on computation to demonstrate their\npotential for use within more complex perturbation schemes. We empirically\ndemonstrate that the Color-Aware and Edge-Aware perturbations we consider\neffectively cause misclassification, are less distinguishable to human\nperception, and are as easy to compute as the most efficient image perturbation\ntechniques. Code and demo available at\nhttps://github.com/rbassett3/Color-and-Edge-Aware-Perturbations\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 03:02:20 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 19:25:48 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Bassett", "Robert", ""], ["Graves", "Mitchell", ""], ["Reilly", "Patrick", ""]]}, {"id": "2008.12466", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Deconvoluting Kernel Density Estimation and Regression for Locally\n  Differentially Private Data", "comments": "updated reference list, deeper numerical analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy has become the gold-standard of privacy literature\nfor gathering or releasing sensitive individual data points in a\nprivacy-preserving manner. However, locally differential data can twist the\nprobability density of the data because of the additive noise used to ensure\nprivacy. In fact, the density of privacy-preserving data (no matter how many\nsamples we gather) is always flatter in comparison with the density function of\nthe original data points due to convolution with privacy-preserving noise\ndensity function. The effect is especially more pronounced when using\nslow-decaying privacy-preserving noises, such as the Laplace noise. This can\nresult in under/over-estimation of the heavy-hitters. This is an important\nchallenge facing social scientists due to the use of differential privacy in\nthe 2020 Census in the United States. In this paper, we develop density\nestimation methods using smoothing kernels. We use the framework of\ndeconvoluting kernel density estimators to remove the effect of\nprivacy-preserving noise. This approach also allows us to adapt the results\nfrom non-parameteric regression with errors-in-variables to develop regression\nmodels based on locally differentially private data. We demonstrate the\nperformance of the developed methods on financial and demographic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 03:39:17 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 03:32:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2008.12477", "submitter": "Philippe Goulet Coulombe", "authors": "Philippe Goulet Coulombe, Maxime Leroux, Dalibor Stevanovic,\n  St\\'ephane Surprenant", "title": "How is Machine Learning Useful for Macroeconomic Forecasting?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We move beyond \"Is Machine Learning Useful for Macroeconomic Forecasting?\" by\nadding the \"how\". The current forecasting literature has focused on matching\nspecific variables and horizons with a particularly successful algorithm. In\ncontrast, we study the usefulness of the underlying features driving ML gains\nover standard macroeconometric methods. We distinguish four so-called features\n(nonlinearities, regularization, cross-validation and alternative loss\nfunction) and study their behavior in both the data-rich and data-poor\nenvironments. To do so, we design experiments that allow to identify the\n\"treatment\" effects of interest. We conclude that (i) nonlinearity is the true\ngame changer for macroeconomic prediction, (ii) the standard factor model\nremains the best regularization, (iii) K-fold cross-validation is the best\npractice and (iv) the $L_2$ is preferred to the $\\bar \\epsilon$-insensitive\nin-sample loss. The forecasting gains of nonlinear techniques are associated\nwith high macroeconomic uncertainty, financial stress and housing bubble\nbursts. This suggests that Machine Learning is useful for macroeconomic\nforecasting by mostly capturing important nonlinearities that arise in the\ncontext of uncertainty and financial frictions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:23:52 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Coulombe", "Philippe Goulet", ""], ["Leroux", "Maxime", ""], ["Stevanovic", "Dalibor", ""], ["Surprenant", "St\u00e9phane", ""]]}, {"id": "2008.12478", "submitter": "Alessandro Achille", "authors": "Luca Zancato, Alessandro Achille, Avinash Ravichandran, Rahul Bhotika,\n  Stefano Soatto", "title": "Predicting Training Time Without Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of predicting the number of optimization steps that a\npre-trained deep network needs to converge to a given value of the loss\nfunction. To do so, we leverage the fact that the training dynamics of a deep\nnetwork during fine-tuning are well approximated by those of a linearized\nmodel. This allows us to approximate the training loss and accuracy at any\npoint during training by solving a low-dimensional Stochastic Differential\nEquation (SDE) in function space. Using this result, we are able to predict the\ntime it takes for Stochastic Gradient Descent (SGD) to fine-tune a model to a\ngiven loss without having to perform any training. In our experiments, we are\nable to predict training time of a ResNet within a 20% error margin on a\nvariety of datasets and hyper-parameters, at a 30 to 45-fold reduction in cost\ncompared to actual training. We also discuss how to further reduce the\ncomputational and memory cost of our method, and in particular we show that by\nexploiting the spectral properties of the gradients' matrix it is possible\npredict training time on a large dataset while processing only a subset of the\nsamples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:29:54 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Zancato", "Luca", ""], ["Achille", "Alessandro", ""], ["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2008.12504", "submitter": "Rohde David", "authors": "Otmane Sakhi, Stephen Bonner, David Rohde, Flavian Vasile", "title": "BLOB : A Probabilistic Model for Recommendation that Combines Organic\n  and Bandit Signals", "comments": "26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,\n  Aug 2020, San Diego, United States", "journal-ref": null, "doi": "10.1145/3394486.3403121", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common task for recommender systems is to build a pro le of the interests\nof a user from items in their browsing history and later to recommend items to\nthe user from the same catalog. The users' behavior consists of two parts: the\nsequence of items that they viewed without intervention (the organic part) and\nthe sequences of items recommended to them and their outcome (the bandit part).\nIn this paper, we propose Bayesian Latent Organic Bandit model (BLOB), a\nprobabilistic approach to combine the 'or-ganic' and 'bandit' signals in order\nto improve the estimation of recommendation quality. The bandit signal is\nvaluable as it gives direct feedback of recommendation performance, but the\nsignal quality is very uneven, as it is highly concentrated on the\nrecommendations deemed optimal by the past version of the recom-mender system.\nIn contrast, the organic signal is typically strong and covers most items, but\nis not always relevant to the recommendation task. In order to leverage the\norganic signal to e ciently learn the bandit signal in a Bayesian model we\nidentify three fundamental types of distances, namely action-history,\naction-action and history-history distances. We implement a scalable\napproximation of the full model using variational auto-encoders and the local\nre-paramerization trick. We show using extensive simulation studies that our\nmethod out-performs or matches the value of both state-of-the-art organic-based\nrecommendation algorithms, and of bandit-based methods (both value and\npolicy-based) both in organic and bandit-rich environments.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 06:57:10 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Sakhi", "Otmane", ""], ["Bonner", "Stephen", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""]]}, {"id": "2008.12522", "submitter": "Genggeng Liu", "authors": "Genggeng Liu, Canyang Guo, Lin Xie, Wenxi Liu, Naixue Xiong and\n  Guolong Chen", "title": "An Intelligent CNN-VAE Text Representation Technology Based on Text\n  Semantics for Comprehensive Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, a large number of text data generated by the Internet\nhas given birth to a variety of text representation methods. In natural\nlanguage processing (NLP), text representation transforms text into vectors\nthat can be processed by computer without losing the original semantic\ninformation. However, these methods are difficult to effectively extract the\nsemantic features among words and distinguish polysemy in language. Therefore,\na text feature representation model based on convolutional neural network (CNN)\nand variational autoencoder (VAE) is proposed to extract the text features and\napply the obtained text feature representation on the text classification\ntasks. CNN is used to extract the features of text vector to get the semantics\namong words and VAE is introduced to make the text feature space more\nconsistent with Gaussian distribution. In addition, the output of the improved\nword2vec model is employed as the input of the proposed model to distinguish\ndifferent meanings of the same word in different contexts. The experimental\nresults show that the proposed model outperforms in k-nearest neighbor (KNN),\nrandom forest (RF) and support vector machine (SVM) classification algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 07:39:45 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Liu", "Genggeng", ""], ["Guo", "Canyang", ""], ["Xie", "Lin", ""], ["Liu", "Wenxi", ""], ["Xiong", "Naixue", ""], ["Chen", "Guolong", ""]]}, {"id": "2008.12534", "submitter": "Lingxiao Li", "authors": "Lingxiao Li, Aude Genevay, Mikhail Yurochkin, Justin Solomon", "title": "Continuous Regularized Wasserstein Barycenters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein barycenters provide a geometrically meaningful way to aggregate\nprobability distributions, built on the theory of optimal transport. They are\ndifficult to compute in practice, however, leading previous work to restrict\ntheir supports to finite sets of points. Leveraging a new dual formulation for\nthe regularized Wasserstein barycenter problem, we introduce a stochastic\nalgorithm that constructs a continuous approximation of the barycenter. We\nestablish strong duality and use the corresponding primal-dual relationship to\nparametrize the barycenter implicitly using the dual potentials of regularized\ntransport problems. The resulting problem can be solved with stochastic\ngradient descent, which yields an efficient online algorithm to approximate the\nbarycenter of continuous distributions given sample access. We demonstrate the\neffectiveness of our approach and compare against previous work on synthetic\nexamples and real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 08:28:06 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 01:09:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Lingxiao", ""], ["Genevay", "Aude", ""], ["Yurochkin", "Mikhail", ""], ["Solomon", "Justin", ""]]}, {"id": "2008.12537", "submitter": "Paraskevi Chasani", "authors": "Paraskevi Chasani and Aristidis Likas", "title": "The UU-test for Statistical Modeling of Unimodal Data", "comments": "19 pages, 15 figures, 5 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding on the unimodality of a dataset is an important problem in data\nanalysis and statistical modeling. It allows to obtain knowledge about the\nstructure of the dataset, ie. whether data points have been generated by a\nprobability distribution with a single or more than one peaks. Such knowledge\nis very useful for several data analysis problems, such as for deciding on the\nnumber of clusters and determining unimodal projections. We propose a technique\ncalled UU-test (Unimodal Uniform test) to decide on the unimodality of a\none-dimensional dataset. The method operates on the empirical cumulative\ndensity function (ecdf) of the dataset. It attempts to build a piecewise linear\napproximation of the ecdf that is unimodal and models the data sufficiently in\nthe sense that the data corresponding to each linear segment follows the\nuniform distribution. A unique feature of this approach is that in the case of\nunimodality, it also provides a statistical model of the data in the form of a\nUniform Mixture Model. We present experimental results in order to assess the\nability of the method to decide on unimodality and perform comparisons with the\nwell-known dip-test approach. In addition, in the case of unimodal datasets we\nevaluate the Uniform Mixture Models provided by the proposed method using the\ntest set log-likelihood and the two-sample Kolmogorov-Smirnov (KS) test.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 08:34:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chasani", "Paraskevi", ""], ["Likas", "Aristidis", ""]]}, {"id": "2008.12559", "submitter": "Yong-Chan Park", "authors": "Yong-chan Park, Jun-Gi Jang, U Kang", "title": "Fast Partial Fourier Transform", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a time series vector, how can we efficiently compute a specified part\nof Fourier coefficients? Fast Fourier transform (FFT) is a widely used\nalgorithm that computes the discrete Fourier transform in many machine learning\napplications. Despite its pervasive use, all known FFT algorithms do not\nprovide a fine-tuning option for the user to specify one's demand, that is, the\noutput size (the number of Fourier coefficients to be computed) is\nalgorithmically determined by the input size. This matters because not every\napplication using FFT requires the whole spectrum of the frequency domain,\nresulting in an inefficiency due to extra computation. In this paper, we\npropose a fast Partial Fourier Transform (PFT), a careful modification of the\nCooley-Tukey algorithm that enables one to specify an arbitrary consecutive\nrange where the coefficients should be computed. We derive the asymptotic time\ncomplexity of PFT with respect to input and output sizes, as well as its\nnumerical accuracy. Experimental results show that our algorithm outperforms\nthe state-of-the-art FFT algorithms, with an order of magnitude of speedup for\nsufficiently small output sizes without sacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:01:49 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Park", "Yong-chan", ""], ["Jang", "Jun-Gi", ""], ["Kang", "U", ""]]}, {"id": "2008.12578", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Duc Minh Nguyen, Giannis Bekoulis, Adrian Munteanu, Nikos\n  Deligiannis", "title": "Graph Convolutional Neural Networks with Node Transition\n  Probability-based Message Passing and DropNode Regularization", "comments": "Expert Systems with Applications, graph-based deep learning, graph\n  neural networks, document classification", "journal-ref": "Expert Systems with Applications, 174 (2021), Elsevier", "doi": "10.1016/j.eswa.2021.114711", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNNs) have received much attention\nrecently, owing to their capability in handling graph-structured data. Among\nthe existing GCNNs, many methods can be viewed as instances of a neural message\npassing motif; features of nodes are passed around their neighbors, aggregated\nand transformed to produce better nodes' representations. Nevertheless, these\nmethods seldom use node transition probabilities, a measure that has been found\nuseful in exploring graphs. Furthermore, when the transition probabilities are\nused, their transition direction is often improperly considered in the feature\naggregation step, resulting in an inefficient weighting scheme. In addition,\nalthough a great number of GCNN models with increasing level of complexity have\nbeen introduced, the GCNNs often suffer from over-fitting when being trained on\nsmall graphs. Another issue of the GCNNs is over-smoothing, which tends to make\nnodes' representations indistinguishable. This work presents a new method to\nimprove the message passing process based on node transition probabilities by\nproperly considering the transition direction, leading to a better weighting\nscheme in nodes' features aggregation compared to the existing counterpart.\nMoreover, we propose a novel regularization method termed DropNode to address\nthe over-fitting and over-smoothing issues simultaneously. DropNode randomly\ndiscards part of a graph, thus it creates multiple deformed versions of the\ngraph, leading to data augmentation regularization effect. Additionally,\nDropNode lessens the connectivity of the graph, mitigating the effect of\nover-smoothing in deep GCNNs. Extensive experiments on eight benchmark datasets\nfor node and graph classification tasks demonstrate the effectiveness of the\nproposed methods in comparison with the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:51:03 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 13:48:49 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Do", "Tien Huu", ""], ["Nguyen", "Duc Minh", ""], ["Bekoulis", "Giannis", ""], ["Munteanu", "Adrian", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2008.12595", "submitter": "Xavier Alameda-Pineda", "authors": "Laurent Girin and Simon Leglaive and Xiaoyu Bie and Julien Diard and\n  Thomas Hueber and Xavier Alameda-Pineda", "title": "Dynamical Variational Autoencoders: A Comprehensive Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) is a powerful deep generative model that is\nnow extensively used to represent high-dimensional complex data via a\nlow-dimensional latent space learned in an unsupervised manner. In the original\nVAE model, input data vectors are processed independently. In recent years, a\nseries of papers have presented different extensions of the VAE to process\nsequential data, that not only model the latent space, but also model the\ntemporal dependencies within a sequence of data vectors and corresponding\nlatent vectors, relying on recurrent neural networks or state space models. In\nthis paper we perform an extensive literature review of these models.\nImportantly, we introduce and discuss a general class of models called\nDynamical Variational Autoencoders (DVAEs) that encompasses a large subset of\nthese temporal VAE extensions. Then we present in detail seven different\ninstances of DVAE that were recently proposed in the literature, with an effort\nto homogenize the notations and presentation lines, as well as to relate these\nmodels with existing classical temporal models. We reimplemented those seven\nDVAE models and we present the results of an experimental benchmark conducted\non the speech analysis-resynthesis task (the PyTorch code is made publicly\navailable). The paper is concluded with an extensive discussion on important\nissues concerning the DVAE class of models and future research guidelines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 11:49:33 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 16:17:22 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Girin", "Laurent", ""], ["Leglaive", "Simon", ""], ["Bie", "Xiaoyu", ""], ["Diard", "Julien", ""], ["Hueber", "Thomas", ""], ["Alameda-Pineda", "Xavier", ""]]}, {"id": "2008.12604", "submitter": "Hirokazu Kameoka", "authors": "Hirokazu Kameoka, Takuhiro Kaneko, Kou Tanaka, Nobukatsu Hojo", "title": "Nonparallel Voice Conversion with Augmented Classifier Star Generative\n  Adversarial Networks", "comments": "Submitted to IEEE/ACM Trans. ASLP. This paper is an extended\n  full-paper version of arXiv:1806.02169", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We previously proposed a method that allows for nonparallel voice conversion\n(VC) by using a variant of generative adversarial networks (GANs) called\nStarGAN. The main features of our method, called StarGAN-VC, are as follows:\nFirst, it requires no parallel utterances, transcriptions, or time alignment\nprocedures for speech generator training. Second, it can simultaneously learn\nmappings across multiple domains using a single generator network and thus\nfully exploit available training data collected from multiple domains to\ncapture latent features that are common to all the domains. Third, it can\ngenerate converted speech signals quickly enough to allow real-time\nimplementations and requires only several minutes of training examples to\ngenerate reasonably realistic-sounding speech. In this paper, we describe three\nformulations of StarGAN, including a newly introduced novel StarGAN variant\ncalled \"Augmented classifier StarGAN (A-StarGAN)\", and compare them in a\nnonparallel VC task. We also compare them with several baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:30:05 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 09:25:50 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 03:36:27 GMT"}, {"version": "v4", "created": "Wed, 2 Sep 2020 16:43:30 GMT"}, {"version": "v5", "created": "Fri, 11 Sep 2020 03:55:28 GMT"}, {"version": "v6", "created": "Thu, 8 Oct 2020 15:46:20 GMT"}, {"version": "v7", "created": "Tue, 10 Nov 2020 09:57:32 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Kameoka", "Hirokazu", ""], ["Kaneko", "Takuhiro", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "2008.12623", "submitter": "Smitha Milli", "authors": "Smitha Milli, Luca Belli, Moritz Hardt", "title": "From Optimizing Engagement to Measuring Value", "comments": "Published at FAccT'21", "journal-ref": null, "doi": "10.1145/3442188.3445933", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most recommendation engines today are based on predicting user engagement,\ne.g. predicting whether a user will click on an item or not. However, there is\npotentially a large gap between engagement signals and a desired notion of\n\"value\" that is worth optimizing for. We use the framework of measurement\ntheory to (a) confront the designer with a normative question about what the\ndesigner values, (b) provide a general latent variable model approach that can\nbe used to operationalize the target construct and directly optimize for it,\nand (c) guide the designer in evaluating and revising their operationalization.\nWe implement our approach on the Twitter platform on millions of users. In line\nwith established approaches to assessing the validity of measurements, we\nperform a qualitative evaluation of how well our model captures a desired\nnotion of \"value\".\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:10:45 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 16:32:49 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Milli", "Smitha", ""], ["Belli", "Luca", ""], ["Hardt", "Moritz", ""]]}, {"id": "2008.12625", "submitter": "Berent {\\AA}nund Str{\\o}mnes Lunde", "authors": "Berent {\\AA}nund Str{\\o}mnes Lunde, Tore Selland Kleppe", "title": "agtboost: Adaptive and Automatic Gradient Tree Boosting Computations", "comments": "16 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  agtboost is an R package implementing fast gradient tree boosting\ncomputations in a manner similar to other established frameworks such as\nxgboost and LightGBM, but with significant decreases in computation time and\nrequired mathematical and technical knowledge. The package automatically takes\ncare of split/no-split decisions and selects the number of trees in the\ngradient tree boosting ensemble, i.e., agtboost adapts the complexity of the\nensemble automatically to the information in the data. All of this is done\nduring a single training run, which is made possible by utilizing developments\nin information theory for tree algorithms {\\tt arXiv:2008.05926v1 [stat.ME]}.\nagtboost also comes with a feature importance function that eliminates the\ncommon practice of inserting noise features. Further, a useful model validation\nfunction performs the Kolmogorov-Smirnov test on the learned distribution.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:42:19 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lunde", "Berent \u00c5nund Str\u00f8mnes", ""], ["Kleppe", "Tore Selland", ""]]}, {"id": "2008.12646", "submitter": "Yun Peng", "authors": "Yun Peng, Byron Choi, Jianliang Xu", "title": "Graph Learning for Combinatorial Optimization: A Survey of\n  State-of-the-Art", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have been widely used to represent complex data in many applications.\nEfficient and effective analysis of graphs is important for graph-based\napplications. However, most graph analysis tasks are combinatorial optimization\n(CO) problems, which are NP-hard. Recent studies have focused a lot on the\npotential of using machine learning (ML) to solve graph-based CO problems. Most\nrecent methods follow the two-stage framework. The first stage is graph\nrepresentation learning, which embeds the graphs into low-dimension vectors.\nThe second stage uses ML to solve the CO problems using the embeddings of the\ngraphs learned in the first stage. The works for the first stage can be\nclassified into two categories, graph embedding (GE) methods and end-to-end\n(E2E) learning methods. For GE methods, learning graph embedding has its own\nobjective, which may not rely on the CO problems to be solved. The CO problems\nare solved by independent downstream tasks. For E2E learning methods, the\nlearning of graph embeddings does not have its own objective and is an\nintermediate step of the learning procedure of solving the CO problems. The\nworks for the second stage can also be classified into two categories,\nnon-autoregressive methods and autoregressive methods. Non-autoregressive\nmethods predict a solution for a CO problem in one shot. A non-autoregressive\nmethod predicts a matrix that denotes the probability of each node/edge being a\npart of a solution of the CO problem. The solution can be computed from the\nmatrix. Autoregressive methods iteratively extend a partial solution step by\nstep. At each step, an autoregressive method predicts a node/edge conditioned\nto current partial solution, which is used to its extension. In this survey, we\nprovide a thorough overview of recent studies of the graph learning-based CO\nmethods. The survey ends with several remarks on future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:56:30 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 08:47:03 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 02:07:09 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Peng", "Yun", ""], ["Choi", "Byron", ""], ["Xu", "Jianliang", ""]]}, {"id": "2008.12686", "submitter": "Yang Chen Dr.", "authors": "Yang Chen, Nami Ashizawa, Seanglidet Yean, Chai Kiat Yeo, Naoto Yanai", "title": "Self-Organizing Map assisted Deep Autoencoding Gaussian Mixture Model\n  for Intrusion Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the information age, a secure and stable network environment is essential\nand hence intrusion detection is critical for any networks. In this paper, we\npropose a self-organizing map assisted deep autoencoding Gaussian mixture model\n(SOMDAGMM) supplemented with well-preserved input space topology for more\naccurate network intrusion detection. The deep autoencoding Gaussian mixture\nmodel comprises a compression network and an estimation network which is able\nto perform unsupervised joint training. However, the code generated by the\nautoencoder is inept at preserving the topology of the input space, which is\nrooted in the bottleneck of the adopted deep structure. A self-organizing map\nhas been introduced to construct SOMDAGMM for addressing this issue. The\nsuperiority of the proposed SOM-DAGMM is empirically demonstrated with\nextensive experiments conducted upon two datasets. Experimental results show\nthat SOM-DAGMM outperforms state-of-the-art DAGMM on all tests, and achieves up\nto 15.58% improvement in F1 score and with better stability.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:41:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Yang", ""], ["Ashizawa", "Nami", ""], ["Yean", "Seanglidet", ""], ["Yeo", "Chai Kiat", ""], ["Yanai", "Naoto", ""]]}, {"id": "2008.12690", "submitter": "Junchi Li", "authors": "Chris Junchi Li, Wenlong Mou, Martin J. Wainwright, Michael I. Jordan", "title": "ROOT-SGD: Sharp Nonasymptotics and Asymptotic Efficiency in a Single\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory and practice of stochastic optimization has focused on stochastic\ngradient descent (SGD) in recent years, retaining the basic first-order\nstochastic nature of SGD while aiming to improve it via mechanisms such as\naveraging, momentum, and variance reduction. Improvement can be measured along\nvarious dimensions, however, and it has proved difficult to achieve\nimprovements both in terms of nonasymptotic measures of convergence rate and\nasymptotic measures of distributional tightness. In this work, we consider\nfirst-order stochastic optimization from a general statistical point of view,\nmotivating a specific form of recursive averaging of past stochastic gradients.\nThe resulting algorithm, which we refer to as \\emph{Recursive One-Over-T SGD}\n(ROOT-SGD), matches the state-of-the-art convergence rate among online\nvariance-reduced stochastic approximation methods. Moreover, under slightly\nstronger distributional assumptions, the rescaled last-iterate of ROOT-SGD\nconverges to a zero-mean Gaussian distribution that achieves near-optimal\ncovariance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:46:56 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Li", "Chris Junchi", ""], ["Mou", "Wenlong", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2008.12693", "submitter": "Trevor McInroe", "authors": "Trevor A. McInroe", "title": "Sample Efficiency in Sparse Reinforcement Learning: Or Your Money Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse rewards present a difficult problem in reinforcement learning and may\nbe inevitable in certain domains with complex dynamics such as real-world\nrobotics. Hindsight Experience Replay (HER) is a recent replay memory\ndevelopment that allows agents to learn in sparse settings by altering memories\nto show them as successful even though they may not be. While, empirically, HER\nhas shown some success, it does not provide guarantees around the makeup of\nsamples drawn from an agent's replay memory. This may result in minibatches\nthat contain only memories with zero-valued rewards or agents learning an\nundesirable policy that completes HER-adjusted goals instead of the actual\ngoal.\n  In this paper, we introduce Or Your Money Back (OYMB), a replay memory\nsampler designed to work with HER. OYMB improves training efficiency in sparse\nsettings by providing a direct interface to the agent's replay memory that\nallows for control over minibatch makeup, as well as a preferential lookup\nscheme that prioritizes real-goal memories before HER-adjusted memories. We\ntest our approach on five tasks across three unique environments. Our results\nshow that using HER in combination with OYMB outperforms using HER alone and\nleads to agents that learn to complete the real goal more quickly.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:48:48 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["McInroe", "Trevor A.", ""]]}, {"id": "2008.12706", "submitter": "Michael Pfarrhofer", "authors": "Florian Huber, Gary Koop, Luca Onorante, Michael Pfarrhofer, Josef\n  Schreiner", "title": "Nowcasting in a Pandemic using Non-Parametric Mixed Frequency VARs", "comments": "JEL: C11, C32, C53, E37; Keywords: Regression tree models, Bayesian,\n  macroeconomic forecasting, vector autoregressions", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops Bayesian econometric methods for posterior inference in\nnon-parametric mixed frequency VARs using additive regression trees. We argue\nthat regression tree models are ideally suited for macroeconomic nowcasting in\nthe face of extreme observations, for instance those produced by the COVID-19\npandemic of 2020. This is due to their flexibility and ability to model\noutliers. In an application involving four major euro area countries, we find\nsubstantial improvements in nowcasting performance relative to a linear mixed\nfrequency VAR.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:35:54 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:45:24 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 10:28:04 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Huber", "Florian", ""], ["Koop", "Gary", ""], ["Onorante", "Luca", ""], ["Pfarrhofer", "Michael", ""], ["Schreiner", "Josef", ""]]}, {"id": "2008.12736", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, Jaideep Srivastava", "title": "RKT : Relation-Aware Self-Attention for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3411994", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has transitioned into a new phase of online learning in response to\nthe recent Covid19 pandemic. Now more than ever, it has become paramount to\npush the limits of online learning in every manner to keep flourishing the\neducation system. One crucial component of online learning is Knowledge Tracing\n(KT). The aim of KT is to model student's knowledge level based on their\nanswers to a sequence of exercises referred as interactions. Students acquire\ntheir skills while solving exercises and each such interaction has a distinct\nimpact on student ability to solve a future exercise. This \\textit{impact} is\ncharacterized by 1) the relation between exercises involved in the interactions\nand 2) student forget behavior. Traditional studies on knowledge tracing do not\nexplicitly model both the components jointly to estimate the impact of these\ninteractions. In this paper, we propose a novel Relation-aware self-attention\nmodel for Knowledge Tracing (RKT). We introduce a relation-aware self-attention\nlayer that incorporates the contextual information. This contextual information\nintegrates both the exercise relation information through their textual content\nas well as student performance data and the forget behavior information through\nmodeling an exponentially decaying kernel function. Extensive experiments on\nthree real-world datasets, among which two new collections are released to the\npublic, show that our model outperforms state-of-the-art knowledge tracing\nmethods. Furthermore, the interpretable attention weights help visualize the\nrelation between interactions and temporal patterns in the human learning\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:47:03 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Pandey", "Shalini", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "2008.12767", "submitter": "Bashir Mohammed", "authors": "Tanwi Mallick, Mariam Kiran, Bashir Mohammed, Prasanna Balaprakash", "title": "Dynamic Graph Neural Network for Traffic Forecasting in Wide Area\n  Networks", "comments": "10 Pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wide area networking infrastructures (WANs), particularly science and\nresearch WANs, are the backbone for moving large volumes of scientific data\nbetween experimental facilities and data centers. With demands growing at\nexponential rates, these networks are struggling to cope with large data\nvolumes, real-time responses, and overall network performance. Network\noperators are increasingly looking for innovative ways to manage the limited\nunderlying network resources. Forecasting network traffic is a critical\ncapability for proactive resource management, congestion mitigation, and\ndedicated transfer provisioning. To this end, we propose a nonautoregressive\ngraph-based neural network for multistep network traffic forecasting.\nSpecifically, we develop a dynamic variant of diffusion convolutional recurrent\nneural networks to forecast traffic in research WANs. We evaluate the efficacy\nof our approach on real traffic from ESnet, the U.S. Department of Energy's\ndedicated science network. Our results show that compared to classical\nforecasting methods, our approach explicitly learns the dynamic nature of\nspatiotemporal traffic patterns, showing significant improvements in\nforecasting accuracy. Our technique can surpass existing statistical and deep\nlearning approaches by achieving approximately 20% mean absolute percentage\nerror for multiple hours of forecasts despite dynamic network traffic settings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:47:11 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mallick", "Tanwi", ""], ["Kiran", "Mariam", ""], ["Mohammed", "Bashir", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.12775", "submitter": "Brandon Amos", "authors": "Brandon Amos, Samuel Stanton, Denis Yarats, Andrew Gordon Wilson", "title": "On the model-based stochastic value gradient for continuous\n  reinforcement learning", "comments": "L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade, model-based reinforcement learning has been seen as a way\nto leverage control-based domain knowledge to improve the sample-efficiency of\nreinforcement learning agents. While model-based agents are conceptually\nappealing, their policies tend to lag behind those of model-free agents in\nterms of final reward, especially in non-trivial environments. In response,\nresearchers have proposed model-based agents with increasingly complex\ncomponents, from ensembles of probabilistic dynamics models, to heuristics for\nmitigating model error. In a reversal of this trend, we show that simple\nmodel-based agents can be derived from existing ideas that not only match, but\noutperform state-of-the-art model-free agents in terms of both\nsample-efficiency and final reward. We find that a model-free soft value\nestimate for policy evaluation and a model-based stochastic value gradient for\npolicy improvement is an effective combination, achieving state-of-the-art\nresults on a high-dimensional humanoid control task, which most model-based\nagents are unable to solve. Our findings suggest that model-based policy\nevaluation deserves closer attention.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:58:29 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:28:25 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 17:59:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Amos", "Brandon", ""], ["Stanton", "Samuel", ""], ["Yarats", "Denis", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2008.12776", "submitter": "Yujia Jin", "authors": "Yujia Jin and Aaron Sidford", "title": "Efficiently Solving MDPs with Stochastic Mirror Descent", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework based on primal-dual stochastic mirror descent\nfor approximately solving infinite-horizon Markov decision processes (MDPs)\ngiven a generative model. When applied to an average-reward MDP with $A_{tot}$\ntotal state-action pairs and mixing time bound $t_{mix}$ our method computes an\n$\\epsilon$-optimal policy with an expected $\\widetilde{O}(t_{mix}^2 A_{tot}\n\\epsilon^{-2})$ samples from the state-transition matrix, removing the\nergodicity dependence of prior art. When applied to a $\\gamma$-discounted MDP\nwith $A_{tot}$ total state-action pairs our method computes an\n$\\epsilon$-optimal policy with an expected $\\widetilde{O}((1-\\gamma)^{-4}\nA_{tot} \\epsilon^{-2})$ samples, matching the previous state-of-the-art up to a\n$(1-\\gamma)^{-1}$ factor. Both methods are model-free, update state values and\npolicies simultaneously, and run in time linear in the number of samples taken.\nWe achieve these results through a more general stochastic mirror descent\nframework for solving bilinear saddle-point problems with simplex and box\ndomains and we demonstrate the flexibility of this framework by providing\nfurther applications to constrained MDPs.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:58:40 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "2008.12802", "submitter": "Hao Chen Dr.", "authors": "Hao Chen, Minguang Zhang, Lanshan Han, Alvin Lim", "title": "Hierarchical Marketing Mix Models with Sign Constraints", "comments": null, "journal-ref": "Journal of Applied Statistics (2021)", "doi": "10.1080/02664763.2021.1946020", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marketing mix models (MMMs) are statistical models for measuring the\neffectiveness of various marketing activities such as promotion, media\nadvertisement, etc. In this research, we propose a comprehensive marketing mix\nmodel that captures the hierarchical structure and the carryover, shape and\nscale effects of certain marketing activities, as well as sign restrictions on\ncertain coefficients that are consistent with common business sense. In\ncontrast to commonly adopted approaches in practice, which estimate parameters\nin a multi-stage process, the proposed approach estimates all the unknown\nparameters/coefficients simultaneously using a constrained maximum likelihood\napproach and solved with the Hamiltonian Monte Carlo algorithm. We present\nresults on real datasets to illustrate the use of the proposed solution\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:16:21 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Chen", "Hao", ""], ["Zhang", "Minguang", ""], ["Han", "Lanshan", ""], ["Lim", "Alvin", ""]]}, {"id": "2008.12828", "submitter": "Mike Merrill", "authors": "Ge Zhang, Mike A. Merrill, Yang Liu, Jeffrey Heer, Tim Althoff", "title": "CORAL: COde RepresentAtion Learning with Weakly-Supervised Transformers\n  for Analyzing Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale analysis of source code, and in particular scientific source\ncode, holds the promise of better understanding the data science process,\nidentifying analytical best practices, and providing insights to the builders\nof scientific toolkits. However, large corpora have remained unanalyzed in\ndepth, as descriptive labels are absent and require expert domain knowledge to\ngenerate. We propose a novel weakly supervised transformer-based architecture\nfor computing joint representations of code from both abstract syntax trees and\nsurrounding natural language comments. We then evaluate the model on a new\nclassification task for labeling computational notebook cells as stages in the\ndata analysis process from data import to wrangling, exploration, modeling, and\nevaluation. We show that our model, leveraging only easily-available weak\nsupervision, achieves a 38% increase in accuracy over expert-supplied\nheuristics and outperforms a suite of baselines. Our model enables us to\nexamine a set of 118,000 Jupyter Notebooks to uncover common data analysis\npatterns. Focusing on notebooks with relationships to academic articles, we\nconduct the largest ever study of scientific code and find that notebook\ncomposition correlates with the citation count of corresponding papers.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:57:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhang", "Ge", ""], ["Merrill", "Mike A.", ""], ["Liu", "Yang", ""], ["Heer", "Jeffrey", ""], ["Althoff", "Tim", ""]]}, {"id": "2008.12829", "submitter": "Ryan Urbanowicz", "authors": "Ryan J. Urbanowicz and Pranshu Suri and Yuhan Cui and Jason H. Moore\n  and Karen Ruth and Rachael Stolzenberg-Solomon and Shannon M. Lynch", "title": "A Rigorous Machine Learning Analysis Pipeline for Biomedical Binary\n  Classification: Application in Pancreatic Cancer Nested Case-control Studies\n  with Implications for Bias Assessments", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) offers a collection of powerful approaches for\ndetecting and modeling associations, often applied to data having a large\nnumber of features and/or complex associations. Currently, there are many tools\nto facilitate implementing custom ML analyses (e.g. scikit-learn). Interest is\nalso increasing in automated ML packages, which can make it easier for\nnon-experts to apply ML and have the potential to improve model performance. ML\npermeates most subfields of biomedical research with varying levels of rigor\nand correct usage. Tremendous opportunities offered by ML are frequently offset\nby the challenge of assembling comprehensive analysis pipelines, and the ease\nof ML misuse. In this work we have laid out and assembled a complete, rigorous\nML analysis pipeline focused on binary classification (i.e. case/control\nprediction), and applied this pipeline to both simulated and real world data.\nAt a high level, this 'automated' but customizable pipeline includes a)\nexploratory analysis, b) data cleaning and transformation, c) feature\nselection, d) model training with 9 established ML algorithms, each with\nhyperparameter optimization, and e) thorough evaluation, including appropriate\nmetrics, statistical analyses, and novel visualizations. This pipeline\norganizes the many subtle complexities of ML pipeline assembly to illustrate\nbest practices to avoid bias and ensure reproducibility. Additionally, this\npipeline is the first to compare established ML algorithms to 'ExSTraCS', a\nrule-based ML algorithm with the unique capability of interpretably modeling\nheterogeneous patterns of association. While designed to be widely applicable\nwe apply this pipeline to an epidemiological investigation of established and\nnewly identified risk factors for pancreatic cancer to evaluate how different\nsources of bias might be handled by ML algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:58:05 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 20:31:35 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Urbanowicz", "Ryan J.", ""], ["Suri", "Pranshu", ""], ["Cui", "Yuhan", ""], ["Moore", "Jason H.", ""], ["Ruth", "Karen", ""], ["Stolzenberg-Solomon", "Rachael", ""], ["Lynch", "Shannon M.", ""]]}, {"id": "2008.12833", "submitter": "Gabriel Spadon", "authors": "Gabriel Spadon, Shenda Hong, Bruno Brandoli, Stan Matwin, Jose F.\n  Rodrigues-Jr, and Jimeng Sun", "title": "Pay Attention to Evolution: Time Series Forecasting with Deep\n  Graph-Evolution Learning", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3076155", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is one of the most active research topics in\nartificial intelligence. Applications in real-world time series should consider\ntwo factors for achieving reliable predictions: modeling dynamic dependencies\namong multiple variables and adjusting the model's intrinsic hyperparameters. A\nstill open gap in that literature is that statistical and ensemble learning\napproaches systematically present lower predictive performance than deep\nlearning methods. They generally disregard the data sequence aspect entangled\nwith multivariate data represented in more than one time series. Conversely,\nthis work presents a novel neural network architecture for time-series\nforecasting that combines the power of graph evolution with deep recurrent\nlearning on distinct data distributions; we named our method Recurrent Graph\nEvolution Neural Network (ReGENN). The idea is to infer multiple multivariate\nrelationships between co-occurring time-series by assuming that the temporal\ndata depends not only on inner variables and intra-temporal relationships\n(i.e., observations from itself) but also on outer variables and inter-temporal\nrelationships (i.e., observations from other-selves). An extensive set of\nexperiments was conducted comparing ReGENN with dozens of ensemble methods and\nclassical statistical ones, showing sound improvement of up to 64.87% over the\ncompeting algorithms. Furthermore, we present an analysis of the intermediate\nweights arising from ReGENN, showing that by looking at inter and\nintra-temporal relationships simultaneously, time-series forecasting is majorly\nimproved if paying attention to how multiple multivariate data synchronously\nevolve.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 20:10:07 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 11:10:35 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 15:46:00 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 19:58:48 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Spadon", "Gabriel", ""], ["Hong", "Shenda", ""], ["Brandoli", "Bruno", ""], ["Matwin", "Stan", ""], ["Rodrigues-Jr", "Jose F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2008.12842", "submitter": "Rahul Ragesh", "authors": "Rahul Ragesh, Sundararajan Sellamanickam, Arun Iyer, Ram Bairi, Vijay\n  Lingam", "title": "HeteGCN: Heterogeneous Graph Convolutional Networks for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning efficient and inductive graph\nconvolutional networks for text classification with a large number of examples\nand features. Existing state-of-the-art graph embedding based methods such as\npredictive text embedding (PTE) and TextGCN have shortcomings in terms of\npredictive performance, scalability and inductive capability. To address these\nlimitations, we propose a heterogeneous graph convolutional network (HeteGCN)\nmodeling approach that unites the best aspects of PTE and TextGCN together. The\nmain idea is to learn feature embeddings and derive document embeddings using a\nHeteGCN architecture with different graphs used across layers. We simplify\nTextGCN by dissecting into several HeteGCN models which (a) helps to study the\nusefulness of individual models and (b) offers flexibility in fusing learned\nembeddings from different models. In effect, the number of model parameters is\nreduced significantly, enabling faster training and improving performance in\nsmall labeled training set scenario. Our detailed experimental studies\ndemonstrate the efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:24:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ragesh", "Rahul", ""], ["Sellamanickam", "Sundararajan", ""], ["Iyer", "Arun", ""], ["Bairi", "Ram", ""], ["Lingam", "Vijay", ""]]}, {"id": "2008.12857", "submitter": "Austin Cole", "authors": "D. Austin Cole, Ryan Christianson, Robert B. Gramacy", "title": "Locally induced Gaussian processes for large-scale simulation\n  experiments", "comments": "34 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) serve as flexible surrogates for complex surfaces,\nbut buckle under the cubic cost of matrix decompositions with big training data\nsizes. Geospatial and machine learning communities suggest pseudo-inputs, or\ninducing points, as one strategy to obtain an approximation easing that\ncomputational burden. However, we show how placement of inducing points and\ntheir multitude can be thwarted by pathologies, especially in large-scale\ndynamic response surface modeling tasks. As remedy, we suggest porting the\ninducing point idea, which is usually applied globally, over to a more local\ncontext where selection is both easier and faster. In this way, our proposed\nmethodology hybridizes global inducing point and data subset-based local GP\napproximation. A cascade of strategies for planning the selection of local\ninducing points is provided, and comparisons are drawn to related methodology\nwith emphasis on computer surrogate modeling applications. We show that local\ninducing points extend their global and data-subset component parts on the\naccuracy--computational efficiency frontier. Illustrative examples are provided\non benchmark data and a large-scale real-simulation satellite drag\ninterpolation problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:37:46 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 20:57:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Cole", "D. Austin", ""], ["Christianson", "Ryan", ""], ["Gramacy", "Robert B.", ""]]}, {"id": "2008.12882", "submitter": "Bhaswar Bhattacharya", "authors": "Somabha Mukherjee, Jaesung Son, and Bhaswar B. Bhattacharya", "title": "Estimation in Tensor Ising Models", "comments": "34 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $p$-tensor Ising model is a one-parameter discrete exponential family for\nmodeling dependent binary data, where the sufficient statistic is a\nmulti-linear form of degree $p \\geq 2$. This is a natural generalization of the\nmatrix Ising model, that provides a convenient mathematical framework for\ncapturing higher-order dependencies in complex relational data. In this paper,\nwe consider the problem of estimating the natural parameter of the $p$-tensor\nIsing model given a single sample from the distribution on $N$ nodes. Our\nestimate is based on the maximum pseudo-likelihood (MPL) method, which provides\na computationally efficient algorithm for estimating the parameter that avoids\ncomputing the intractable partition function. We derive general conditions\nunder which the MPL estimate is $\\sqrt N$-consistent, that is, it converges to\nthe true parameter at rate $1/\\sqrt N$. In particular, we show the $\\sqrt\nN$-consistency of the MPL estimate in the $p$-spin Sherrington-Kirkpatrick (SK)\nmodel, spin systems on general $p$-uniform hypergraphs, and Ising models on the\nhypergraph stochastic block model (HSBM). In fact, for the HSBM we pin down the\nexact location of the phase transition threshold, which is determined by the\npositivity of a certain mean-field variational problem, such that above this\nthreshold the MPL estimate is $\\sqrt N$-consistent, while below the threshold\nno estimator is consistent. Finally, we derive the precise fluctuations of the\nMPL estimate in the special case of the $p$-tensor Curie-Weiss model. An\ninteresting consequence of our results is that the MPL estimate in the\nCurie-Weiss model saturates the Cramer-Rao lower bound at all points above the\nestimation threshold, that is, the MPL estimate incurs no loss in asymptotic\nefficiency, even though it is obtained by minimizing only an approximation of\nthe true likelihood function for computational tractability.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 00:06:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mukherjee", "Somabha", ""], ["Son", "Jaesung", ""], ["Bhattacharya", "Bhaswar B.", ""]]}, {"id": "2008.12886", "submitter": "James P. Crutchfield", "authors": "Alexandra M. Jurgens and James P. Crutchfield", "title": "Shannon Entropy Rate of Hidden Markov Processes", "comments": "11 pages, 4 figures; supplementary material 10 pages, 7 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/serhmp.htm", "journal-ref": null, "doi": "10.1007/s10955-021-02769-3", "report-no": null, "categories": "nlin.CD cond-mat.stat-mech cs.IT math.DS math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov chains are widely applied statistical models of stochastic\nprocesses, from fundamental physics and chemistry to finance, health, and\nartificial intelligence. The hidden Markov processes they generate are\nnotoriously complicated, however, even if the chain is finite state: no finite\nexpression for their Shannon entropy rate exists, as the set of their\npredictive features is generically infinite. As such, to date one cannot make\ngeneral statements about how random they are nor how structured. Here, we\naddress the first part of this challenge by showing how to efficiently and\naccurately calculate their entropy rates. We also show how this method gives\nthe minimal set of infinite predictive features. A sequel addresses the\nchallenge's second part on structure.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 00:48:17 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Jurgens", "Alexandra M.", ""], ["Crutchfield", "James P.", ""]]}, {"id": "2008.12916", "submitter": "Athanasios N. Nikolakopoulos", "authors": "Athanasios N. Nikolakopoulos", "title": "Random Surfing Revisited: Generalizing PageRank's Teleportation Model", "comments": "34 pages, 11 figures; Preliminary versions of (part of) this work\n  have been presented as an ACM WSDM conference paper\n  (https://dl.acm.org/doi/10.1145/2433396.2433415), as well as in\n  arXiv:1506.00092 (This article supersedes arXiv:1506.00092) v2: corrected\n  numerical example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We revisit the Random Surfer model, focusing on its--often\noverlooked--Teleportation component, and we introduce NCDawareRank; a novel\nranking framework designed to exploit network meta-information as well as\naspects of its higher-order structural organization in a way that preserves the\nmathematical structure and the attractive computational characteristics of\nPageRank. A rigorous theoretical exploration of the proposed model reveals a\nwealth of mathematical properties that entail tangible benefits in terms of\nrobustness, computability, as well as modeling flexibility and expressiveness.\nA set of experiments on real-work networks verify the theoretically predicted\nproperties of NCDawareRank, and showcase its effectiveness as a network\ncentrality measure.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 05:45:05 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 03:06:05 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Nikolakopoulos", "Athanasios N.", ""]]}, {"id": "2008.12922", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Xiaomo Jiang, Xiaofang Wang", "title": "Modulating Scalable Gaussian Processes for Expressive Statistical\n  Learning", "comments": "31 pages, 9 figures, 4 tables, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a learning task, Gaussian process (GP) is interested in learning the\nstatistical relationship between inputs and outputs, since it offers not only\nthe prediction mean but also the associated variability. The vanilla GP however\nstruggles to learn complicated distribution with the property of, e.g.,\nheteroscedastic noise, multi-modality and non-stationarity, from massive data\ndue to the Gaussian marginal and the cubic complexity. To this end, this\narticle studies new scalable GP paradigms including the non-stationary\nheteroscedastic GP, the mixture of GPs and the latent GP, which introduce\nadditional latent variables to modulate the outputs or inputs in order to learn\nricher, non-Gaussian statistical representation. We further resort to different\nvariational inference strategies to arrive at analytical or tighter evidence\nlower bounds (ELBOs) of the marginal likelihood for efficient and effective\nmodel training. Extensive numerical experiments against state-of-the-art GP and\nneural network (NN) counterparts on various tasks verify the superiority of\nthese scalable modulated GPs, especially the scalable latent GP, for learning\ndiverse data distributions.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 06:41:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Jiang", "Xiaomo", ""], ["Wang", "Xiaofang", ""]]}, {"id": "2008.12925", "submitter": "Seok-Ju Hahn", "authors": "Seok-Ju Hahn, Junghye Lee", "title": "GRAFFL: Gradient-free Federated Learning of a Bayesian Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning platforms are gaining popularity. One of the major\nbenefits is to mitigate the privacy risks as the learning of algorithms can be\nachieved without collecting or sharing data. While federated learning (i.e.,\nmany based on stochastic gradient algorithms) has shown great promise, there\nare still many challenging problems in protecting privacy, especially during\nthe process of gradients update and exchange. This paper presents the first\ngradient-free federated learning framework called GRAFFL for learning a\nBayesian generative model based on approximate Bayesian computation. Unlike\nconventional federated learning algorithms based on gradients, our framework\ndoes not require to disassemble a model (i.e., to linear components) or to\nperturb data (or encryption of data for aggregation) to preserve privacy.\nInstead, this framework uses implicit information derived from each\nparticipating institution to learn posterior distributions of parameters. The\nimplicit information is summary statistics derived from SuffiAE that is a\nneural network developed in this study to create compressed and linearly\nseparable representations thereby protecting sensitive information from\nleakage. As a sufficient dimensionality reduction technique, this is proved to\nprovide sufficient summary statistics. We propose the GRAFFL-based Bayesian\nGaussian mixture model to serve as a proof-of-concept of the framework. Using\nseveral datasets, we demonstrated the feasibility and usefulness of our model\nin terms of privacy protection and prediction performance (i.e., close to an\nideal setting). The trained model as a quasi-global model can generate\ninformative samples involving information from other institutions and enhances\ndata analysis of each institution.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 07:19:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hahn", "Seok-Ju", ""], ["Lee", "Junghye", ""]]}, {"id": "2008.12952", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Johannes Klicpera, Stephan G\\\"unnemann", "title": "Efficient Robustness Certificates for Discrete Data: Sparsity-Aware\n  Randomized Smoothing for Graphs, Images and More", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques for certifying the robustness of models for discrete data\neither work only for a small class of models or are general at the expense of\nefficiency or tightness. Moreover, they do not account for sparsity in the\ninput which, as our findings show, is often essential for obtaining non-trivial\nguarantees. We propose a model-agnostic certificate based on the randomized\nsmoothing framework which subsumes earlier work and is tight, efficient, and\nsparsity-aware. Its computational complexity does not depend on the number of\ndiscrete categories or the dimension of the input (e.g. the graph size), making\nit highly scalable. We show the effectiveness of our approach on a wide variety\nof models, datasets, and tasks -- specifically highlighting its use for Graph\nNeural Networks. So far, obtaining provable guarantees for GNNs has been\ndifficult due to the discrete and non-i.i.d. nature of graph data. Our method\ncan certify any GNN and handles perturbations to both the graph structure and\nthe node attributes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 10:09:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["Klicpera", "Johannes", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2008.12967", "submitter": "Jong Chul Ye", "authors": "Gyutaek Oh, Byeongsu Sim, Hyungjin Chung, Leonard Sunwoo, and Jong\n  Chul Ye", "title": "Unpaired Deep Learning for Accelerated MRI using Optimal Transport\n  Driven CycleGAN", "comments": "Accepted for IEEE Transactions on Computational Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning approaches for accelerated MRI have been extensively\nstudied thanks to their high performance reconstruction in spite of\nsignificantly reduced runtime complexity. These neural networks are usually\ntrained in a supervised manner, so matched pairs of subsampled and fully\nsampled k-space data are required. Unfortunately, it is often difficult to\nacquire matched fully sampled k-space data, since the acquisition of fully\nsampled k-space data requires long scan time and often leads to the change of\nthe acquisition protocol. Therefore, unpaired deep learning without matched\nlabel data has become a very important research topic. In this paper, we\npropose an unpaired deep learning approach using a optimal transport driven\ncycle-consistent generative adversarial network (OT-cycleGAN) that employs a\nsingle pair of generator and discriminator. The proposed OT-cycleGAN\narchitecture is rigorously derived from a dual formulation of the optimal\ntransport formulation using a specially designed penalized least squares cost.\nThe experimental results show that our method can reconstruct high resolution\nMR images from accelerated k- space data from both single and multiple coil\nacquisition, without requiring matched reference data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 12:02:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Oh", "Gyutaek", ""], ["Sim", "Byeongsu", ""], ["Chung", "Hyungjin", ""], ["Sunwoo", "Leonard", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.12987", "submitter": "Mohammadhossein Ghahramani", "authors": "Mohammadhossein Ghahramani, Yan Qiao, MengChu Zhou, Adrian OHagan, and\n  James Sweeney", "title": "AI-based Modeling and Data-driven Evaluation for Smart Manufacturing\n  Processes", "comments": "13 pages, 7 figures. To appear in IEEE/CAA JAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart Manufacturing refers to optimization techniques that are implemented in\nproduction operations by utilizing advanced analytics approaches. With the\nwidespread increase in deploying Industrial Internet of Things (IIoT) sensors\nin manufacturing processes, there is a progressive need for optimal and\neffective approaches to data management. Embracing Machine Learning and\nArtificial Intelligence to take advantage of manufacturing data can lead to\nefficient and intelligent automation. In this paper, we conduct a comprehensive\nanalysis based on Evolutionary Computing and Deep Learning algorithms toward\nmaking semiconductor manufacturing smart. We propose a dynamic algorithm for\ngaining useful insights about semiconductor manufacturing processes and to\naddress various challenges. We elaborate on the utilization of a Genetic\nAlgorithm and Neural Network to propose an intelligent feature selection\nalgorithm. Our objective is to provide an advanced solution for controlling\nmanufacturing processes and to gain perspective on various dimensions that\nenable manufacturers to access effective predictive technologies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 14:57:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ghahramani", "Mohammadhossein", ""], ["Qiao", "Yan", ""], ["Zhou", "MengChu", ""], ["OHagan", "Adrian", ""], ["Sweeney", "James", ""]]}, {"id": "2008.12997", "submitter": "Pengfei Xia", "authors": "Pengfei Xia and Bin Li", "title": "Improving Resistance to Adversarial Deformations by Regularizing\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the resistance of deep neural networks against adversarial attacks\nis important for deploying models to realistic applications. However, most\ndefense methods are designed to defend against intensity perturbations and\nignore location perturbations, which should be equally important for deep model\nsecurity. In this paper, we focus on adversarial deformations, a typical class\nof location perturbations, and propose a flow gradient regularization to\nimprove the resistance of models. Theoretically, we prove that, compared with\ninput gradient regularization, regularizing flow gradients is able to get a\ntighter bound. Over multiple datasets, architectures, and adversarial\ndeformations, our empirical results indicate that models trained with flow\ngradients can acquire a better resistance than trained with input gradients\nwith a large margin, and also better than adversarial training. Moreover,\ncompared with directly training with adversarial deformations, our method can\nachieve better results in unseen attacks, and combining these two methods can\nimprove the resistance further.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 15:28:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 05:58:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Xia", "Pengfei", ""], ["Li", "Bin", ""]]}, {"id": "2008.13038", "submitter": "F. Trevor Rogers", "authors": "F. Trevor Rogers", "title": "Loss convergence in a causal Bayesian neural network of retail firm\n  performance", "comments": "7 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the empirical results from the structural equation model (SEM)\npublished in the paper Assortment Planning for Retail Buying, Retail Store\nOperations, and Firm Performance [1] by implementing the directed acyclic graph\nas a causal Bayesian neural network. Neural network convergence is shown to\nimprove with the removal of the node with the weakest SEM path when variational\ninference is provided by perturbing weights with Flipout layers, while results\nfrom perturbing weights at the output with the Vadam optimizer are\ninconclusive.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 19:16:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Rogers", "F. Trevor", ""]]}, {"id": "2008.13044", "submitter": "Stephen Chung", "authors": "Stephen Chung, Robert Kozma", "title": "Reinforcement Learning with Feedback-modulated TD-STDP", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neuron networks have been used successfully to solve simple\nreinforcement learning tasks with continuous action set applying learning rules\nbased on spike-timing-dependent plasticity (STDP). However, most of these\nmodels cannot be applied to reinforcement learning tasks with discrete action\nset since they assume that the selected action is a deterministic function of\nfiring rate of neurons, which is continuous. In this paper, we propose a new\nSTDP-based learning rule for spiking neuron networks which contains feedback\nmodulation. We show that the STDP-based learning rule can be used to solve\nreinforcement learning tasks with discrete action set at a speed similar to\nstandard reinforcement learning algorithms when applied to the CartPole and\nLunarLander tasks. Moreover, we demonstrate that the agent is unable to solve\nthese tasks if feedback modulation is omitted from the learning rule. We\nconclude that feedback modulation allows better credit assignment when only the\nunits contributing to the executed action and TD error participate in learning.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 20:08:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chung", "Stephen", ""], ["Kozma", "Robert", ""]]}, {"id": "2008.13064", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Arjun Mukherjee, Omprakash Gnawali, Mohammad\n  Amin Alipour", "title": "Towards Demystifying Dimensions of Source Code Embeddings", "comments": "1st ACM SIGSOFT International Workshop on Representation Learning for\n  Software Engineering and Program Languages, Co-located with ESEC/FSE\n  (RL+SE&PL'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code representations are key in applying machine learning techniques\nfor processing and analyzing programs. A popular approach in representing\nsource code is neural source code embeddings that represents programs with\nhigh-dimensional vectors computed by training deep neural networks on a large\nvolume of programs. Although successful, there is little known about the\ncontents of these vectors and their characteristics. In this paper, we present\nour preliminary results towards better understanding the contents of code2vec\nneural source code embeddings. In particular, in a small case study, we use the\ncode2vec embeddings to create binary SVM classifiers and compare their\nperformance with the handcrafted features. Our results suggest that the\nhandcrafted features can perform very close to the highly-dimensional code2vec\nembeddings, and the information gains are more evenly distributed in the\ncode2vec embeddings compared to the handcrafted features. We also find that the\ncode2vec embeddings are more resilient to the removal of dimensions with low\ninformation gains than the handcrafted features. We hope our results serve a\nstepping stone toward principled analysis and evaluation of these code\nrepresentations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 21:59:11 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 03:53:21 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 00:19:28 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Mukherjee", "Arjun", ""], ["Gnawali", "Omprakash", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "2008.13065", "submitter": "Elizabeth Cole", "authors": "Elizabeth K. Cole, John M. Pauly, Shreyas S. Vasanawala, Frank Ong", "title": "Unsupervised MRI Reconstruction with Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based image reconstruction methods have achieved promising\nresults across multiple MRI applications. However, most approaches require\nlarge-scale fully-sampled ground truth data for supervised training. Acquiring\nfully-sampled data is often either difficult or impossible, particularly for\ndynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a\ndeep learning framework for MRI reconstruction without any fully-sampled data\nusing generative adversarial networks. We test the proposed method in two\nscenarios: retrospectively undersampled fast spin echo knee exams and\nprospectively undersampled abdominal DCE. The method recovers more anatomical\nstructure compared to conventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 22:00:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cole", "Elizabeth K.", ""], ["Pauly", "John M.", ""], ["Vasanawala", "Shreyas S.", ""], ["Ong", "Frank", ""]]}, {"id": "2008.13066", "submitter": "Won Chang", "authors": "Saumya Bhatnagar, Won Chang, Seonjin Kim Jiali Wang", "title": "Computer Model Calibration with Time Series Data using Deep Learning and\n  Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer models play a key role in many scientific and engineering problems.\nOne major source of uncertainty in computer model experiment is input parameter\nuncertainty. Computer model calibration is a formal statistical procedure to\ninfer input parameters by combining information from model runs and\nobservational data. The existing standard calibration framework suffers from\ninferential issues when the model output and observational data are\nhigh-dimensional dependent data such as large time series due to the difficulty\nin building an emulator and the non-identifiability between effects from input\nparameters and data-model discrepancy. To overcome these challenges we propose\na new calibration framework based on a deep neural network (DNN) with\nlong-short term memory layers that directly emulates the inverse relationship\nbetween the model output and input parameters. Adopting the 'learning with\nnoise' idea we train our DNN model to filter out the effects from data model\ndiscrepancy on input parameter inference. We also formulate a new way to\nconstruct interval predictions for DNN using quantile regression to quantify\nthe uncertainty in input parameter estimates. Through a simulation study and\nreal data application with WRF-hydro model we show that our approach can yield\naccurate point estimates and well calibrated interval estimates for input\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 22:18:41 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 06:10:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bhatnagar", "Saumya", ""], ["Chang", "Won", ""], ["Wang", "Seonjin Kim Jiali", ""]]}, {"id": "2008.13072", "submitter": "Kaiyang Li", "authors": "Kaiyang Li, Guangchun Luo, Yang Ye, Wei Li, Shihao Ji, Zhipeng Cai", "title": "Adversarial Privacy Preserving Graph Embedding against Inference Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the surge in popularity of Internet of Things (IoT), mobile\ndevices, social media, etc. has opened up a large source for graph data. Graph\nembedding has been proved extremely useful to learn low-dimensional feature\nrepresentations from graph structured data. These feature representations can\nbe used for a variety of prediction tasks from node classification to link\nprediction. However, existing graph embedding methods do not consider users'\nprivacy to prevent inference attacks. That is, adversaries can infer users'\nsensitive information by analyzing node representations learned from graph\nembedding algorithms. In this paper, we propose Adversarial Privacy Graph\nEmbedding (APGE), a graph adversarial training framework that integrates the\ndisentangling and purging mechanisms to remove users' private information from\nlearned node representations. The proposed method preserves the structural\ninformation and utility attributes of a graph while concealing users' private\nattributes from inference attacks. Extensive experiments on real-world graph\ndatasets demonstrate the superior performance of APGE compared to the\nstate-of-the-arts. Our source code can be found at\nhttps://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 00:06:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Kaiyang", ""], ["Luo", "Guangchun", ""], ["Ye", "Yang", ""], ["Li", "Wei", ""], ["Ji", "Shihao", ""], ["Cai", "Zhipeng", ""]]}, {"id": "2008.13099", "submitter": "Qingyun Sun", "authors": "Qingyun Sun, Hao Peng, Jianxin Li, Senzhang Wang, Xiangyu Dong,\n  Liangxuan Zhao, Philip S. Yu and Lifang He", "title": "Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous\n  Academic Networks", "comments": "accepted by ICDM 2020 as regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name disambiguation aims to identify unique authors with the same name.\nExisting name disambiguation methods always exploit author attributes to\nenhance disambiguation results. However, some discriminative author attributes\n(e.g., email and affiliation) may change because of graduation or job-hopping,\nwhich will result in the separation of the same author's papers in digital\nlibraries. Although these attributes may change, an author's co-authors and\nresearch topics do not change frequently with time, which means that papers\nwithin a period have similar text and relation information in the academic\nnetwork. Inspired by this idea, we introduce Multi-view Attention-based\nPairwise Recurrent Neural Network (MA-PairRNN) to solve the name disambiguation\nproblem. We divided papers into small blocks based on discriminative author\nattributes and blocks of the same author will be merged according to pairwise\nclassification results of MA-PairRNN. MA-PairRNN combines heterogeneous graph\nembedding learning and pairwise similarity learning into a framework. In\naddition to attribute and structure information, MA-PairRNN also exploits\nsemantic information by meta-path and generates node representation in an\ninductive way, which is scalable to large graphs. Furthermore, a semantic-level\nattention mechanism is adopted to fuse multiple meta-path based\nrepresentations. A Pseudo-Siamese network consisting of two RNNs takes two\npaper sequences in publication time order as input and outputs their\nsimilarity. Results on two real-world datasets demonstrate that our framework\nhas a significant and consistent improvement of performance on the name\ndisambiguation task. It was also demonstrated that MA-PairRNN can perform well\nwith a small amount of training data and have better generalization ability\nacross different research areas.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 06:08:20 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 03:50:21 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 14:22:45 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 12:31:45 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Sun", "Qingyun", ""], ["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Wang", "Senzhang", ""], ["Dong", "Xiangyu", ""], ["Zhao", "Liangxuan", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2008.13114", "submitter": "Ali Nawaz", "authors": "Ali Nawaz, Attique Ur Rehman, Muhammad Abbas", "title": "A Novel Multiple Ensemble Learning Models Based on Different Datasets\n  for Software Defect Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software testing is one of the important ways to ensure the quality of\nsoftware. It is found that testing cost more than 50% of overall project cost.\nEffective and efficient software testing utilizes the minimum resources of\nsoftware. Therefore, it is important to construct the procedure which is not\nonly able to perform the efficient testing but also minimizes the utilization\nof project resources. The goal of software testing is to find maximum defects\nin the software system. More the defects found in the software ensure more\nefficiency is the software testing Different techniques have been proposed to\ndetect the defects in software and to utilize the resources and achieve good\nresults. As world is continuously moving toward data driven approach for making\nimportant decision. Therefore, in this research paper we performed the machine\nlearning analysis on the publicly available datasets and tried to achieve the\nmaximum accuracy. The major focus of the paper is to apply different machine\nlearning techniques on the datasets and find out which technique produce\nefficient result. Particularly, we proposed an ensemble learning models and\nperform comparative analysis among KNN, Decision tree, SVM and Na\\\"ive Bayes on\ndifferent datasets and it is demonstrated that performance of Ensemble method\nis more than other methods in term of accuracy, precision, recall and F1-score.\nThe classification accuracy of ensemble model trained on CM1 is 98.56%,\nclassification accuracy of ensemble model trained on KM2 is 98.18% similarly,\nthe classification accuracy of ensemble learning model trained on PC1 is\n99.27%. This reveals that Ensemble is more efficient method for making the\ndefect prediction as compared other techniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:01:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Nawaz", "Ali", ""], ["Rehman", "Attique Ur", ""], ["Abbas", "Muhammad", ""]]}, {"id": "2008.13122", "submitter": "Vincent Grari", "authors": "Vincent Grari, Sylvain Lamprier, Marcin Detyniecki", "title": "Adversarial Learning for Counterfactual Fairness", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, fairness has become an important topic in the machine\nlearning research community. In particular, counterfactual fairness aims at\nbuilding prediction models which ensure fairness at the most individual level.\nRather than globally considering equity over the entire population, the idea is\nto imagine what any individual would look like with a variation of a given\nattribute of interest, such as a different gender or race for instance.\nExisting approaches rely on Variational Auto-encoding of individuals, using\nMaximum Mean Discrepancy (MMD) penalization to limit the statistical dependence\nof inferred representations with their corresponding sensitive attributes. This\nenables the simulation of counterfactual samples used for training the target\nfair model, the goal being to produce similar outcomes for every alternate\nversion of any individual. In this work, we propose to rely on an adversarial\nneural learning approach, that enables more powerful inference than with MMD\npenalties, and is particularly better fitted for the continuous setting, where\nvalues of sensitive attributes cannot be exhaustively enumerated. Experiments\nshow significant improvements in term of counterfactual fairness for both the\ndiscrete and the continuous settings.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 09:06:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Grari", "Vincent", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2008.13128", "submitter": "Dachao Lin", "authors": "Dachao Lin, Peiqin Sun, Guangzeng Xie, Shuchang Zhou, Zhihua Zhang", "title": "Optimal Quantization for Batch Normalization in Neural Network\n  Deployments and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantized Neural Networks (QNNs) use low bit-width fixed-point numbers for\nrepresenting weight parameters and activations, and are often used in\nreal-world applications due to their saving of computation resources and\nreproducibility of results.\n  Batch Normalization (BN) poses a challenge for QNNs for requiring floating\npoints in reciprocal operations, and previous QNNs either require computing BN\nat high precision or revise BN to some variants in heuristic ways.\n  In this work, we propose a novel method to quantize BN by converting an\naffine transformation of two floating points to a fixed-point operation with\nshared quantized scale, which is friendly for hardware acceleration and model\ndeployment.\n  We confirm that our method maintains same outputs through rigorous\ntheoretical analysis and numerical analysis. Accuracy and efficiency of our\nquantization method are verified by experiments at layer level on CIFAR and\nImageNet datasets.\n  We also believe that our method is potentially useful in other problems\ninvolving quantization.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 09:33:29 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lin", "Dachao", ""], ["Sun", "Peiqin", ""], ["Xie", "Guangzeng", ""], ["Zhou", "Shuchang", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2008.13162", "submitter": "Przemyslaw Biecek", "authors": "Wojciech Kretowicz, Przemys{\\l}aw Biecek", "title": "MementoML: Performance of selected machine learning algorithm\n  configurations on OpenML100 datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding optimal hyperparameters for the machine learning algorithm can often\nsignificantly improve its performance. But how to choose them in a\ntime-efficient way? In this paper we present the protocol of generating\nbenchmark data describing the performance of different ML algorithms with\ndifferent hyperparameter configurations. Data collected in this way is used to\nstudy the factors influencing the algorithm's performance.\n  This collection was prepared for the purposes of the study presented in the\nEPP study. We tested algorithms performance on dense grid of hyperparameters.\nTested datasets and hyperparameters were chosen before any algorithm has run\nand were not changed. This is a different approach than the one usually used in\nhyperparameter tuning, where the selection of candidate hyperparameters depends\non the results obtained previously. However, such selection allows for\nsystematic analysis of performance sensitivity from individual hyperparameters.\n  This resulted in a comprehensive dataset of such benchmarks that we would\nlike to share. We hope, that computed and collected result may be helpful for\nother researchers. This paper describes the way data was collected. Here you\ncan find benchmarks of 7 popular machine learning algorithms on 39 OpenML\ndatasets.\n  The detailed data forming this benchmark are available at:\nhttps://www.kaggle.com/mi2datalab/mementoml.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:13:52 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kretowicz", "Wojciech", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2008.13210", "submitter": "Dimosthenis Pasadakis", "authors": "Dimosthenis Pasadakis, Christie Louis Alappat, Olaf Schenk, Gerhard\n  Wellein", "title": "$K$-way $p$-spectral clustering on Grassmann manifolds", "comments": "36 pages, 12 figures, 4 Tables. Submitted to the \"Journal of Machine\n  Learning Research\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods have gained a lot of recent attention due to the simplicity\nof their implementation and their solid mathematical background. We revisit\nspectral graph clustering, and reformulate in the $p$-norm the continuous\nproblem of minimizing the graph Laplacian Rayleigh quotient. The value of $p\n\\in (1,2]$ is reduced, promoting sparser solution vectors that correspond to\noptimal clusters as $p$ approaches one. The computation of multiple\n$p$-eigenvectors of the graph $p$-Laplacian, a nonlinear generalization of the\nstandard graph Laplacian, is achieved by the minimization of our objective\nfunction on the Grassmann manifold, hence ensuring the enforcement of the\northogonality constraint between them. Our approach attempts to bridge the\nfields of graph clustering and nonlinear numerical optimization, and employs a\nrobust algorithm to obtain clusters of high quality. The benefits of the\nsuggested method are demonstrated in a plethora of artificial and real-world\ngraphs. Our results are compared against standard spectral clustering methods\nand the current state-of-the-art algorithm for clustering using the graph\n$p$-Laplacian variant.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 16:25:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pasadakis", "Dimosthenis", ""], ["Alappat", "Christie Louis", ""], ["Schenk", "Olaf", ""], ["Wellein", "Gerhard", ""]]}, {"id": "2008.13221", "submitter": "Vinicius G. Goecks", "authors": "Vinicius G. Goecks", "title": "Human-in-the-Loop Methods for Data-Driven and Reinforcement Learning\n  Systems", "comments": "PhD thesis, Aerospace Engineering, Texas A&M (2020). For more\n  information, see https://vggoecks.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes combine reinforcement learning algorithms and deep neural\nnetworks, despite reinforcement learning not being widely applied to robotics\nand real world scenarios. This can be attributed to the fact that current\nstate-of-the-art, end-to-end reinforcement learning approaches still require\nthousands or millions of data samples to converge to a satisfactory policy and\nare subject to catastrophic failures during training. Conversely, in real world\nscenarios and after just a few data samples, humans are able to either provide\ndemonstrations of the task, intervene to prevent catastrophic actions, or\nsimply evaluate if the policy is performing correctly. This research\ninvestigates how to integrate these human interaction modalities to the\nreinforcement learning loop, increasing sample efficiency and enabling\nreal-time reinforcement learning in robotics and real world scenarios. This\nnovel theoretical foundation is called Cycle-of-Learning, a reference to how\ndifferent human interaction modalities, namely, task demonstration,\nintervention, and evaluation, are cycled and combined to reinforcement learning\nalgorithms. Results presented in this work show that the reward signal that is\nlearned based upon human interaction accelerates the rate of learning of\nreinforcement learning algorithms and that learning from a combination of human\ndemonstrations and interventions is faster and more sample efficient when\ncompared to traditional supervised learning algorithms. Finally,\nCycle-of-Learning develops an effective transition between policies learned\nusing human demonstrations and interventions to reinforcement learning. The\ntheoretical foundation developed by this research opens new research paths to\nhuman-agent teaming scenarios where autonomous agents are able to learn from\nhuman teammates and adapt to mission performance metrics in real-time and in\nreal world scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:28:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Goecks", "Vinicius G.", ""]]}, {"id": "2008.13225", "submitter": "Tharun Kumar Reddy Medini", "authors": "Tharun Medini, Beidi Chen, Anshumali Shrivastava", "title": "SOLAR: Sparse Orthogonal Learned and Random Embeddings", "comments": "Under review at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense embedding models are commonly deployed in commercial search engines,\nwherein all the document vectors are pre-computed, and near-neighbor search\n(NNS) is performed with the query vector to find relevant documents. However,\nthe bottleneck of indexing a large number of dense vectors and performing an\nNNS hurts the query time and accuracy of these models. In this paper, we argue\nthat high-dimensional and ultra-sparse embedding is a significantly superior\nalternative to dense low-dimensional embedding for both query efficiency and\naccuracy. Extreme sparsity eliminates the need for NNS by replacing them with\nsimple lookups, while its high dimensionality ensures that the embeddings are\ninformative even when sparse. However, learning extremely high dimensional\nembeddings leads to blow up in the model size. To make the training feasible,\nwe propose a partitioning algorithm that learns such high dimensional\nembeddings across multiple GPUs without any communication. This is facilitated\nby our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random\n(SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal\nby design, while the query vectors are learned and sparse. We theoretically\nprove that our way of one-sided learning is equivalent to learning both query\nand label embeddings. With these unique properties, we can successfully train\n500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books\nand multi-label classification on the three largest public datasets. We achieve\nsuperior precision and recall compared to the respective state-of-the-art\nbaselines for each of the tasks with up to 10 times faster speed.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:35:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Medini", "Tharun", ""], ["Chen", "Beidi", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2008.13235", "submitter": "Yuyan Wang", "authors": "Benjamin Moseley, Yuyan Wang", "title": "An Objective for Hierarchical Clustering in Euclidean Space and its\n  Connection to Bisecting K-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores hierarchical clustering in the case where pairs of points\nhave dissimilarity scores (e.g. distances) as a part of the input. The recently\nintroduced objective for points with dissimilarity scores results in every tree\nbeing a 1/2 approximation if the distances form a metric. This shows the\nobjective does not make a significant distinction between a good and poor\nhierarchical clustering in metric spaces. Motivated by this, the paper develops\na new global objective for hierarchical clustering in Euclidean space. The\nobjective captures the criterion that has motivated the use of divisive\nclustering algorithms: that when a split happens, points in the same cluster\nshould be more similar than points in different clusters. Moreover, this\nobjective gives reasonable results on ground-truth inputs for hierarchical\nclustering. The paper builds a theoretical connection between this objective\nand the bisecting k-means algorithm. This paper proves that the optimal 2-means\nsolution results in a constant approximation for the objective. This is the\nfirst paper to show the bisecting k-means algorithm optimizes a natural global\nobjective over the entire tree.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 18:17:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Moseley", "Benjamin", ""], ["Wang", "Yuyan", ""]]}, {"id": "2008.13261", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed", "title": "Benchmarking adversarial attacks and defenses for time-series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The adversarial vulnerability of deep networks has spurred the interest of\nresearchers worldwide. Unsurprisingly, like images, adversarial examples also\ntranslate to time-series data as they are an inherent weakness of the model\nitself rather than the modality. Several attempts have been made to defend\nagainst these adversarial attacks, particularly for the visual modality. In\nthis paper, we perform detailed benchmarking of well-proven adversarial defense\nmethodologies on time-series data. We restrict ourselves to the $L_{\\infty}$\nthreat model. We also explore the trade-off between smoothness and clean\naccuracy for regularization-based defenses to better understand the trade-offs\nthat they offer. Our analysis shows that the explored adversarial defenses\noffer robustness against both strong white-box as well as black-box attacks.\nThis paves the way for future research in the direction of adversarial attacks\nand defenses, particularly for time-series data.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:03:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2008.13265", "submitter": "Deepan Muthirayan", "authors": "Deepan Muthirayan and Pramod Khargonekar", "title": "A Meta-Learning Control Algorithm with Provable Finite-Time Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide provable regret guarantees for an online\nmeta-learning control algorithm in an iterative control setting, where in each\niteration the system to be controlled is a linear deterministic system that is\ndifferent and unknown, the cost for the controller in an iteration is a general\nadditive cost function and the control input is required to be constrained,\nwhich if violated incurs an additional cost. We prove (i) that the algorithm\nachieves a regret for the controller cost and constraint violation that are\n$O(T^{3/4})$ for an episode of duration $T$ with respect to the best policy\nthat satisfies the control input control constraints and (ii) that the average\nof the regret for the controller cost and constraint violation with respect to\nthe same policy vary as $O((1+\\log(N)/N)T^{3/4})$ with the number of iterations\n$N$, showing that the worst regret for the learning within an iteration\ncontinuously improves with experience of more iterations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:30:40 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 21:04:18 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 01:32:32 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 22:18:33 GMT"}, {"version": "v5", "created": "Thu, 8 Oct 2020 20:47:57 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Muthirayan", "Deepan", ""], ["Khargonekar", "Pramod", ""]]}, {"id": "2008.13293", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani", "title": "Sharp finite-sample concentration of independent variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an extension of Sanov's theorem on large deviations, controlling the\ntail probabilities of i.i.d. random variables with matching concentration and\nanti-concentration bounds. This result has a general scope, applies to samples\nof any size, and has a short information-theoretic proof using elementary\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 23:05:55 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 07:22:14 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 02:17:20 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 23:29:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Balsubramani", "Akshay", ""]]}, {"id": "2008.13306", "submitter": "Subhashis Hazarika", "authors": "Subhashis Hazarika, Ayan Biswas, Phillip J. Wolfram, Earl Lawrence,\n  Nathan Urban", "title": "Relationship-aware Multivariate Sampling Strategy for Scientific\n  Simulation Data", "comments": "To appear as IEEE Vis 2020 Shortpaper", "journal-ref": null, "doi": "10.1109/VIS47514.2020.00015", "report-no": "2020 IEEE Visualization Conference (VIS)", "categories": "cs.LG cs.GR cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing computational power of current supercomputers, the size\nof data produced by scientific simulations is rapidly growing. To reduce the\nstorage footprint and facilitate scalable post-hoc analyses of such scientific\ndata sets, various data reduction/summarization methods have been proposed over\nthe years. Different flavors of sampling algorithms exist to sample the\nhigh-resolution scientific data, while preserving important data properties\nrequired for subsequent analyses. However, most of these sampling algorithms\nare designed for univariate data and cater to post-hoc analyses of single\nvariables. In this work, we propose a multivariate sampling strategy which\npreserves the original variable relationships and enables different\nmultivariate analyses directly on the sampled data. Our proposed strategy\nutilizes principal component analysis to capture the variance of multivariate\ndata and can be built on top of any existing state-of-the-art sampling\nalgorithms for single variables. In addition, we also propose variants of\ndifferent data partitioning schemes (regular and irregular) to efficiently\nmodel the local multivariate relationships. Using two real-world multivariate\ndata sets, we demonstrate the efficacy of our proposed multivariate sampling\nstrategy with respect to its data reduction capabilities as well as the ease of\nperforming efficient post-hoc multivariate analyses.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 00:52:17 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hazarika", "Subhashis", ""], ["Biswas", "Ayan", ""], ["Wolfram", "Phillip J.", ""], ["Lawrence", "Earl", ""], ["Urban", "Nathan", ""]]}, {"id": "2008.13319", "submitter": "Xiaoyu Chen", "authors": "Xiaoyu Chen, Jiachen Hu, Lihong Li, Liwei Wang", "title": "Efficient Reinforcement Learning in Factored MDPs with Application to\n  Constrained RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in episodic, factored Markov decision processes\n(FMDPs) is studied. We propose an algorithm called FMDP-BF, which leverages the\nfactorization structure of FMDP. The regret of FMDP-BF is shown to be\nexponentially smaller than that of optimal algorithms designed for non-factored\nMDPs, and improves on the best previous result for FMDPs~\\citep{osband2014near}\nby a factored of $\\sqrt{H|\\mathcal{S}_i|}$, where $|\\mathcal{S}_i|$ is the\ncardinality of the factored state subspace and $H$ is the planning horizon. To\nshow the optimality of our bounds, we also provide a lower bound for FMDP,\nwhich indicates that our algorithm is near-optimal w.r.t. timestep $T$, horizon\n$H$ and factored state-action subspace cardinality. Finally, as an application,\nwe study a new formulation of constrained RL, known as RL with knapsack\nconstraints (RLwK), and provides the first sample-efficient algorithm based on\nFMDP-BF.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 02:20:41 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 07:09:43 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:58:03 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chen", "Xiaoyu", ""], ["Hu", "Jiachen", ""], ["Li", "Lihong", ""], ["Wang", "Liwei", ""]]}, {"id": "2008.13351", "submitter": "Yang Yang", "authors": "Yang Yang, Zhen-Qiang Sun, HengShu Zhu, Yanjie Fu, Hui Xiong, Jian\n  Yang", "title": "Learning Adaptive Embedding Considering Incremental Class", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-Incremental Learning (CIL) aims to train a reliable model with the\nstreaming data, which emerges unknown classes sequentially. Different from\ntraditional closed set learning, CIL has two main challenges: 1) Novel class\ndetection. The initial training data only contains incomplete classes, and\nstreaming test data will accept unknown classes. Therefore, the model needs to\nnot only accurately classify known classes, but also effectively detect unknown\nclasses; 2) Model expansion. After the novel classes are detected, the model\nneeds to be updated without re-training using entire previous data. However,\ntraditional CIL methods have not fully considered these two challenges, first,\nthey are always restricted to single novel class detection each phase and\nembedding confusion caused by unknown classes. Besides, they also ignore the\ncatastrophic forgetting of known categories in model update. To this end, we\npropose a Class-Incremental Learning without Forgetting (CILF) framework, which\naims to learn adaptive embedding for processing novel class detection and model\nupdate in a unified framework. In detail, CILF designs to regularize\nclassification with decoupled prototype based loss, which can improve the\nintra-class and inter-class structure significantly, and acquire a compact\nembedding representation for novel class detection in result. Then, CILF\nemploys a learnable curriculum clustering operator to estimate the number of\nsemantic clusters via fine-tuning the learned network, in which curriculum\noperator can adaptively learn the embedding in self-taught form. Therefore,\nCILF can detect multiple novel classes and mitigate the embedding confusion\nproblem. Last, with the labeled streaming test data, CILF can update the\nnetwork with robust regularization to mitigate the catastrophic forgetting.\nConsequently, CILF is able to iteratively perform novel class detection and\nmodel update.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:11:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Yang", "Yang", ""], ["Sun", "Zhen-Qiang", ""], ["Zhu", "HengShu", ""], ["Fu", "Yanjie", ""], ["Xiong", "Hui", ""], ["Yang", "Jian", ""]]}, {"id": "2008.13361", "submitter": "Zhiwei Wang", "authors": "Zhiwei Wang, Zhengzhang Chen, Jingchao Ni, Hui Liu, Haifeng Chen,\n  Jiliang Tang", "title": "Multi-Scale One-Class Recurrent Neural Networks for Discrete Event\n  Sequence Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete event sequences are ubiquitous, such as an ordered event series of\nprocess interactions in Information and Communication Technology systems.\nRecent years have witnessed increasing efforts in detecting anomalies with\ndiscrete-event sequences. However, it still remains an extremely difficult task\ndue to several intrinsic challenges including data imbalance issues, the\ndiscrete property of the events, and sequential nature of the data. To address\nthese challenges, in this paper, we propose OC4Seq, a multi-scale one-class\nrecurrent neural network for detecting anomalies in discrete event sequences.\nSpecifically, OC4Seq integrates the anomaly detection objective with recurrent\nneural networks (RNNs) to embed the discrete event sequences into latent\nspaces, where anomalies can be easily detected. In addition, given that an\nanomalous sequence could be caused by either individual events, subsequences of\nevents, or the whole sequence, we design a multi-scale RNN framework to capture\ndifferent levels of sequential patterns simultaneously. Experimental results on\nthree benchmark datasets show that OC4Seq consistently outperforms various\nrepresentative baselines by a large margin. Moreover, through both quantitative\nand qualitative analysis, the importance of capturing multi-scale sequential\npatterns for event anomaly detection is verified.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:48:22 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Zhiwei", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Liu", "Hui", ""], ["Chen", "Haifeng", ""], ["Tang", "Jiliang", ""]]}, {"id": "2008.13363", "submitter": "Harsh Mehta", "authors": "Harsh Mehta, Ashok Cutkosky, Behnam Neyshabur", "title": "Extreme Memorization via Scale of Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an experimental setup in which changing the scale of\ninitialization strongly impacts the implicit regularization induced by SGD,\ninterpolating from good generalization performance to completely memorizing the\ntraining set while making little progress on the test set. Moreover, we find\nthat the extent and manner in which generalization ability is affected depends\non the activation and loss function used, with $\\sin$ activation demonstrating\nextreme memorization. In the case of the homogeneous ReLU activation, we show\nthat this behavior can be attributed to the loss function. Our empirical\ninvestigation reveals that increasing the scale of initialization correlates\nwith misalignment of representations and gradients across examples in the same\nclass. This insight allows us to devise an alignment measure over gradients and\nrepresentations which can capture this phenomenon. We demonstrate that our\nalignment measure correlates with generalization of deep models trained on\nimage classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:53:11 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 22:09:15 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Mehta", "Harsh", ""], ["Cutkosky", "Ashok", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "2008.13374", "submitter": "Neha Gupta", "authors": "Arturs Backurs, Avrim Blum, Neha Gupta", "title": "Active Local Learning", "comments": "Published at COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider active local learning: given a query point $x$, and\nactive access to an unlabeled training set $S$, output the prediction $h(x)$ of\na near-optimal $h \\in H$ using significantly fewer labels than would be needed\nto actually learn $h$ fully. In particular, the number of label queries should\nbe independent of the complexity of $H$, and the function $h$ should be\nwell-defined, independent of $x$. This immediately also implies an algorithm\nfor distance estimation: estimating the value $opt(H)$ from many fewer labels\nthan needed to actually learn a near-optimal $h \\in H$, by running local\nlearning on a few random query points and computing the average error.\n  For the hypothesis class consisting of functions supported on the interval\n$[0,1]$ with Lipschitz constant bounded by $L$, we present an algorithm that\nmakes $O(({1 / \\epsilon^6}) \\log(1/\\epsilon))$ label queries from an unlabeled\npool of $O(({L / \\epsilon^4})\\log(1/\\epsilon))$ samples. It estimates the\ndistance to the best hypothesis in the class to an additive error of $\\epsilon$\nfor an arbitrary underlying distribution. We further generalize our algorithm\nto more than one dimensions. We emphasize that the number of labels used is\nindependent of the complexity of the hypothesis class which depends on $L$.\nFurthermore, we give an algorithm to locally estimate the values of a\nnear-optimal function at a few query points of interest with number of labels\nindependent of $L$.\n  We also consider the related problem of approximating the minimum error that\ncan be achieved by the Nadaraya-Watson estimator under a linear diagonal\ntransformation with eigenvalues coming from a small range. For a\n$d$-dimensional pointset of size $N$, our algorithm achieves an additive\napproximation of $\\epsilon$, makes $\\tilde{O}({d}/{\\epsilon^2})$ queries and\nruns in $\\tilde{O}({d^2}/{\\epsilon^{d+4}}+{dN}/{\\epsilon^2})$ time.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 05:39:35 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 02:58:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Backurs", "Arturs", ""], ["Blum", "Avrim", ""], ["Gupta", "Neha", ""]]}, {"id": "2008.13429", "submitter": "Zhao Kang", "authors": "Zhao Kang and Chong Peng and Qiang Cheng and Xinwang Liu and Xi Peng\n  and Zenglin Xu and Ling Tian", "title": "Structured Graph Learning for Clustering and Semi-supervised\n  Classification", "comments": "Appear in Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have become increasingly popular in modeling structures and\ninteractions in a wide variety of problems during the last decade. Graph-based\nclustering and semi-supervised classification techniques have shown impressive\nperformance. This paper proposes a graph learning framework to preserve both\nthe local and global structure of data. Specifically, our method uses the\nself-expressiveness of samples to capture the global structure and adaptive\nneighbor approach to respect the local structure. Furthermore, most existing\ngraph-based methods conduct clustering and semi-supervised classification on\nthe graph learned from the original data matrix, which doesn't have explicit\ncluster structure, thus they might not achieve the optimal performance. By\nconsidering rank constraint, the achieved graph will have exactly $c$ connected\ncomponents if there are $c$ clusters or classes. As a byproduct of this, graph\nlearning and label inference are jointly and iteratively implemented in a\nprincipled way. Theoretically, we show that our model is equivalent to a\ncombination of kernel k-means and k-means methods under certain condition.\nExtensive experiments on clustering and semi-supervised classification\ndemonstrate that the proposed method outperforms other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:41:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""], ["Liu", "Xinwang", ""], ["Peng", "Xi", ""], ["Xu", "Zenglin", ""], ["Tian", "Ling", ""]]}, {"id": "2008.13443", "submitter": "Inon Peled", "authors": "Inon Peled, Kelvin Lee, Yu Jiang, Justin Dauwels, Francisco C. Pereira", "title": "Curb Your Normality: On the Quality Requirements of Demand Prediction\n  for Dynamic Public Transport", "comments": "10 pages, 9 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Public Transport (PT) becomes more dynamic and demand-responsive, it\nincreasingly depends on predictions of transport demand. But how accurate need\nsuch predictions be for effective PT operation? We address this question\nthrough an experimental case study of PT trips in Metropolitan Copenhagen,\nDenmark, which we conduct independently of any specific prediction models.\nFirst, we simulate errors in demand prediction through unbiased noise\ndistributions that vary considerably in shape. Using the noisy predictions, we\nthen simulate and optimize demand-responsive PT fleets via a commonly used\nlinear programming formulation and measure their performance. Our results\nsuggest that the optimized performance is mainly affected by the skew of the\nnoise distribution and the presence of infrequently large prediction errors. In\nparticular, the optimized performance can improve under non-Gaussian vs.\nGaussian noise. We also obtain that dynamic routing can reduce trip time by at\nleast 23% vs. static routing. This reduction is estimated at 809,000 EUR per\nyear in terms of Value of Travel Time Savings for the case study.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 09:05:05 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:16:06 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Peled", "Inon", ""], ["Lee", "Kelvin", ""], ["Jiang", "Yu", ""], ["Dauwels", "Justin", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2008.13454", "submitter": "Maximilian M\\\"unch", "authors": "Maximilian M\\\"unch and Michiel Straat and Michael Biehl and\n  Frank-Michael Schleif", "title": "Complex-valued embeddings of generic proximity data", "comments": "Proximity learning, embedding, complex values, complex-valued\n  embedding, learning vector quantization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximities are at the heart of almost all machine learning methods. If the\ninput data are given as numerical vectors of equal lengths, euclidean distance,\nor a Hilbertian inner product is frequently used in modeling algorithms. In a\nmore generic view, objects are compared by a (symmetric) similarity or\ndissimilarity measure, which may not obey particular mathematical properties.\nThis renders many machine learning methods invalid, leading to convergence\nproblems and the loss of guarantees, like generalization bounds. In many cases,\nthe preferred dissimilarity measure is not metric, like the earth mover\ndistance, or the similarity measure may not be a simple inner product in a\nHilbert space but in its generalization a Krein space. If the input data are\nnon-vectorial, like text sequences, proximity-based learning is used or ngram\nembedding techniques can be applied. Standard embeddings lead to the desired\nfixed-length vector encoding, but are costly and have substantial limitations\nin preserving the original data's full information. As an information\npreserving alternative, we propose a complex-valued vector embedding of\nproximity data. This allows suitable machine learning algorithms to use these\nfixed-length, complex-valued vectors for further processing. The complex-valued\ndata can serve as an input to complex-valued machine learning algorithms. In\nparticular, we address supervised learning and use extensions of\nprototype-based learning. The proposed approach is evaluated on a variety of\nstandard benchmarks and shows strong performance compared to traditional\ntechniques in processing non-metric or non-psd proximity data.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 09:40:30 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["M\u00fcnch", "Maximilian", ""], ["Straat", "Michiel", ""], ["Biehl", "Michael", ""], ["Schleif", "Frank-Michael", ""]]}, {"id": "2008.13485", "submitter": "Andrea Valenti", "authors": "Andrea Valenti, Michele Barsotti, Raffaello Brondi, Davide Bacciu,\n  Luca Ascari", "title": "ROS-Neuro Integration of Deep Convolutional Autoencoders for EEG Signal\n  Compression in Real-time BCIs", "comments": "Accepted at the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical EEG-based BCI applications require the computation of complex\nfunctions over the noisy EEG channels to be carried out in an efficient way.\nDeep learning algorithms are capable of learning flexible nonlinear functions\ndirectly from data, and their constant processing latency is perfect for their\ndeployment into online BCI systems. However, it is crucial for the jitter of\nthe processing system to be as low as possible, in order to avoid unpredictable\nbehaviour that can ruin the system's overall usability. In this paper, we\npresent a novel encoding method, based on on deep convolutional autoencoders,\nthat is able to perform efficient compression of the raw EEG inputs. We deploy\nour model in a ROS-Neuro node, thus making it suitable for the integration in\nROS-based BCI and robotic systems in real world scenarios. The experimental\nresults show that our system is capable to generate meaningful compressed\nencoding preserving to original information contained in the raw input. They\nalso show that the ROS-Neuro node is able to produce such encodings at a steady\nrate, with minimal jitter. We believe that our system can represent an\nimportant step towards the development of an effective BCI processing pipeline\nfully standardized in ROS-Neuro framework.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 10:58:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Valenti", "Andrea", ""], ["Barsotti", "Michele", ""], ["Brondi", "Raffaello", ""], ["Bacciu", "Davide", ""], ["Ascari", "Luca", ""]]}, {"id": "2008.13516", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "Towards Comprehensive Recommender Systems: Time-Aware\n  UnifiedcRecommendations Based on Listwise Ranking of Implicit Cross-Network\n  Data", "comments": null, "journal-ref": "Association for the Advancement of Artificial Intelligence, 2020\n  (AAAI'20)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of information in web applications make recommendation\nessential for users as well as applications. Despite the effectiveness of\nexisting recommender systems, we find two major limitations that reduce their\noverall performance: (1) inability to provide timely recommendations for both\nnew and existing users by considering the dynamic nature of user preferences,\nand (2) not fully optimized for the ranking task when using implicit feedback.\nTherefore, we propose a novel deep learning based unified cross-network\nsolution to mitigate cold-start and data sparsity issues and provide timely\nrecommendations for new and existing users.Furthermore, we consider the ranking\nproblem under implicit feedback as a classification task, and propose a generic\npersonalized listwise optimization criterion for implicit data to effectively\nrank a list of items. We illustrate our cross-network model using Twitter\nauxiliary information for recommendations on YouTube target network. Extensive\ncomparisons against multiple time aware and cross-network base-lines show that\nthe proposed solution is superior in terms of accuracy, novelty and diversity.\nFurthermore, experiments conducted on the popular MovieLens dataset suggest\nthat the proposed listwise ranking method outperforms existing state-of-the-art\nranking techniques.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:08:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.13517", "submitter": "Yishi Xu", "authors": "Yishi Xu, Yingxue Zhang, Wei Guo, Huifeng Guo, Ruiming Tang, Mark\n  Coates", "title": "GraphSAIL: Graph Structure Aware Incremental Learning for Recommender\n  Systems", "comments": "Accepted by CIKM2020 Applied Research Track", "journal-ref": null, "doi": "10.1145/3340531.3412754", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the convenience of collecting information through online services,\nrecommender systems now consume large scale data and play a more important role\nin improving user experience. With the recent emergence of Graph Neural\nNetworks (GNNs), GNN-based recommender models have shown the advantage of\nmodeling the recommender system as a user-item bipartite graph to learn\nrepresentations of users and items. However, such models are expensive to train\nand difficult to perform frequent updates to provide the most up-to-date\nrecommendations. In this work, we propose to update GNN-based recommender\nmodels incrementally so that the computation time can be greatly reduced and\nmodels can be updated more frequently. We develop a Graph Structure Aware\nIncremental Learning framework, GraphSAIL, to address the commonly experienced\ncatastrophic forgetting problem that occurs when training a model in an\nincremental fashion. Our approach preserves a user's long-term preference (or\nan item's long-term property) during incremental model updating. GraphSAIL\nimplements a graph structure preservation strategy which explicitly preserves\neach node's local structure, global structure, and self-information,\nrespectively. We argue that our incremental training framework is the first\nattempt tailored for GNN based recommender systems and demonstrate its\nimprovement compared to other incremental learning techniques on two public\ndatasets. We further verify the effectiveness of our framework on a large-scale\nindustrial dataset.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:33:59 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 02:56:15 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Xu", "Yishi", ""], ["Zhang", "Yingxue", ""], ["Guo", "Wei", ""], ["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Coates", "Mark", ""]]}, {"id": "2008.13526", "submitter": "Sami Khenissi", "authors": "Sami Khenissi and Mariem Boujelbene and Olfa Nasraoui", "title": "Theoretical Modeling of the Iterative Properties of User Discovery in a\n  Collaborative Filtering Recommender System", "comments": "Accepted in Recsys2020. Code available at:\n  https://github.com/samikhenissi/TheoretUserModeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The closed feedback loop in recommender systems is a common setting that can\nlead to different types of biases. Several studies have dealt with these biases\nby designing methods to mitigate their effect on the recommendations. However,\nmost existing studies do not consider the iterative behavior of the system\nwhere the closed feedback loop plays a crucial role in incorporating different\nbiases into several parts of the recommendation steps.\n  We present a theoretical framework to model the asymptotic evolution of the\ndifferent components of a recommender system operating within a feedback loop\nsetting, and derive theoretical bounds and convergence properties on\nquantifiable measures of the user discovery and blind spots. We also validate\nour theoretical findings empirically using a real-life dataset and empirically\ntest the efficiency of a basic exploration strategy within our theoretical\nframework.\n  Our findings lay the theoretical basis for quantifying the effect of feedback\nloops and for designing Artificial Intelligence and machine learning algorithms\nthat explicitly incorporate the iterative nature of feedback loops in the\nmachine learning and recommendation process.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:30:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Khenissi", "Sami", ""], ["Boujelbene", "Mariem", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2008.13527", "submitter": "Zhimeng Pan", "authors": "Zhimeng Pan, Wenzheng Tao, Qingyao Ai", "title": "Review Regularized Neural Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, text-aware collaborative filtering methods have been\nproposed to address essential challenges in recommendations such as data\nsparsity, cold start problem, and long-tail distribution. However, many of\nthese text-oriented methods rely heavily on the availability of text\ninformation for every user and item, which obviously does not hold in\nreal-world scenarios. Furthermore, specially designed network structures for\ntext processing are highly inefficient for on-line serving and are hard to\nintegrate into current systems. In this paper, we propose a flexible neural\nrecommendation framework, named Review Regularized Recommendation, short as R3.\nIt consists of a neural collaborative filtering part that focuses on prediction\noutput, and a text processing part that serves as a regularizer. This modular\ndesign incorporates text information as richer data sources in the training\nphase while being highly friendly for on-line serving as it needs no on-the-fly\ntext processing in serving time. Our preliminary results show that by using a\nsimple text processing approach, it could achieve better prediction performance\nthan state-of-the-art text-aware methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:54:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pan", "Zhimeng", ""], ["Tao", "Wenzheng", ""], ["Ai", "Qingyao", ""]]}, {"id": "2008.13532", "submitter": "Rohan Anand", "authors": "Rohan Anand and Joeran Beel", "title": "Auto-Surprise: An Automated Recommender-System (AutoRecSys) Library with\n  Tree of Parzens Estimator (TPE) Optimization", "comments": "To be presented at RecSys '20 Fourteenth ACM Conference on\n  Recommender Systems, September 21-26, 2020, Virtual Event", "journal-ref": null, "doi": "10.1145/3383313.3411467", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Auto-Surprise, an Automated Recommender System library.\nAuto-Surprise is an extension of the Surprise recommender system library and\neases the algorithm selection and configuration process. Compared to\nout-of-the-box Surprise library, Auto-Surprise performs better when evaluated\nwith MovieLens, Book Crossing and Jester Datasets. It may also result in the\nselection of an algorithm with significantly lower runtime. Compared to\nSurprise's grid search, Auto-Surprise performs equally well or slightly better\nin terms of RMSE, and is notably faster in finding the optimum hyperparameters.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:29:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Anand", "Rohan", ""], ["Beel", "Joeran", ""]]}, {"id": "2008.13533", "submitter": "Dara Bahri", "authors": "Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, Cliff Brunk, Andrew\n  Tomkins", "title": "Generative Models are Unsupervised Predictors of Page Quality: A\n  Colossal-Scale Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large generative language models such as GPT-2 are well-known for their\nability to generate text as well as their utility in supervised downstream\ntasks via fine-tuning. Our work is twofold: firstly we demonstrate via human\nevaluation that classifiers trained to discriminate between human and\nmachine-generated text emerge as unsupervised predictors of \"page quality\",\nable to detect low quality content without any training. This enables fast\nbootstrapping of quality indicators in a low-resource setting. Secondly,\ncurious to understand the prevalence and nature of low quality pages in the\nwild, we conduct extensive qualitative and quantitative analysis over 500\nmillion web articles, making this the largest-scale study ever conducted on the\ntopic.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:13:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bahri", "Dara", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Metzler", "Donald", ""], ["Brunk", "Cliff", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2008.13535", "submitter": "Ruoxi Wang", "authors": "Ruoxi Wang, Rakesh Shivanna, Derek Z. Cheng, Sagar Jain, Dong Lin,\n  Lichan Hong, Ed H. Chi", "title": "DCN V2: Improved Deep & Cross Network and Practical Lessons for\n  Web-scale Learning to Rank Systems", "comments": null, "journal-ref": "In Proceedings of the Web Conference 2021 (WWW '21)", "doi": "10.1145/3442381.3450078", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning effective feature crosses is the key behind building recommender\nsystems. However, the sparse and large feature space requires exhaustive search\nto identify effective crosses. Deep & Cross Network (DCN) was proposed to\nautomatically and efficiently learn bounded-degree predictive feature\ninteractions. Unfortunately, in models that serve web-scale traffic with\nbillions of training examples, DCN showed limited expressiveness in its cross\nnetwork at learning more predictive feature interactions. Despite significant\nresearch progress made, many deep learning models in production still rely on\ntraditional feed-forward neural networks to learn feature crosses\ninefficiently.\n  In light of the pros/cons of DCN and existing feature interaction learning\napproaches, we propose an improved framework DCN-V2 to make DCN more practical\nin large-scale industrial settings. In a comprehensive experimental study with\nextensive hyper-parameter search and model tuning, we observed that DCN-V2\napproaches outperform all the state-of-the-art algorithms on popular benchmark\ndatasets. The improved DCN-V2 is more expressive yet remains cost efficient at\nfeature interaction learning, especially when coupled with a mixture of\nlow-rank architecture. DCN-V2 is simple, can be easily adopted as building\nblocks, and has delivered significant offline accuracy and online business\nmetrics gains across many web-scale learning to rank systems at Google.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:33:02 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 21:01:21 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wang", "Ruoxi", ""], ["Shivanna", "Rakesh", ""], ["Cheng", "Derek Z.", ""], ["Jain", "Sagar", ""], ["Lin", "Dong", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""]]}, {"id": "2008.13537", "submitter": "He Zhao", "authors": "He Zhao, Dinh Phung, Viet Huynh, Trung Le, Wray Buntine", "title": "Neural Topic Model via Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, Neural Topic Models (NTMs) inspired by variational autoencoders\nhave obtained increasingly research interest due to their promising results on\ntext analysis. However, it is usually hard for existing NTMs to achieve good\ndocument representation and coherent/diverse topics at the same time. Moreover,\nthey often degrade their performance severely on short documents. The\nrequirement of reparameterisation could also comprise their training quality\nand model flexibility. To address these shortcomings, we present a new neural\ntopic model via the theory of optimal transport (OT). Specifically, we propose\nto learn the topic distribution of a document by directly minimising its OT\ndistance to the document's word distributions. Importantly, the cost matrix of\nthe OT distance models the weights between topics and words, which is\nconstructed by the distances between topics and words in an embedding space.\nOur proposed model can be trained efficiently with a differentiable loss.\nExtensive experiments show that our framework significantly outperforms the\nstate-of-the-art NTMs on discovering more coherent and diverse topics and\nderiving better document representations for both regular and short texts.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:37:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 01:49:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhao", "He", ""], ["Phung", "Dinh", ""], ["Huynh", "Viet", ""], ["Le", "Trung", ""], ["Buntine", "Wray", ""]]}, {"id": "2008.13539", "submitter": "Weixuan Liang", "authors": "Weixuan Liang and Sihang Zhou and Jian Xiong and Xinwang Liu and Siwei\n  Wang and En Zhu and Zhiping Cai and Xin Xu", "title": "Multi-View Spectral Clustering with High-Order Optimal Neighborhood\n  Laplacian Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view spectral clustering can effectively reveal the intrinsic cluster\nstructure among data by performing clustering on the learned optimal embedding\nacross views. Though demonstrating promising performance in various\napplications, most of existing methods usually linearly combine a group of\npre-specified first-order Laplacian matrices to construct the optimal Laplacian\nmatrix, which may result in limited representation capability and insufficient\ninformation exploitation. Also, storing and implementing complex operations on\nthe $n\\times n$ Laplacian matrices incurs intensive storage and computation\ncomplexity. To address these issues, this paper first proposes a multi-view\nspectral clustering algorithm that learns a high-order optimal neighborhood\nLaplacian matrix, and then extends it to the late fusion version for accurate\nand efficient multi-view clustering. Specifically, our proposed algorithm\ngenerates the optimal Laplacian matrix by searching the neighborhood of the\nlinear combination of both the first-order and high-order base Laplacian\nmatrices simultaneously. By this way, the representative capacity of the\nlearned optimal Laplacian matrix is enhanced, which is helpful to better\nutilize the hidden high-order connection information among data, leading to\nimproved clustering performance. We design an efficient algorithm with proved\nconvergence to solve the resultant optimization problem. Extensive experimental\nresults on nine datasets demonstrate the superiority of our algorithm against\nstate-of-the-art methods, which verifies the effectiveness and advantages of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 12:28:40 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Liang", "Weixuan", ""], ["Zhou", "Sihang", ""], ["Xiong", "Jian", ""], ["Liu", "Xinwang", ""], ["Wang", "Siwei", ""], ["Zhu", "En", ""], ["Cai", "Zhiping", ""], ["Xu", "Xin", ""]]}, {"id": "2008.13544", "submitter": "Hamada Zahera", "authors": "Hamada M. Zahera, Rricha Jalota, Mohamed A. Sherif, Axel N. Ngomo", "title": "I-AID: Identifying Actionable Information from Disaster-related Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social media plays a significant role in disaster management by providing\nvaluable data about affected people, donations and help requests. Recent\nstudies highlight the need to filter information on social media into\nfine-grained content labels. However, identifying useful information from\nmassive amounts of social media posts during a crisis is a challenging task. In\nthis paper, we propose I-AID, a multimodel approach to automatically categorize\ntweets into multi-label information types and filter critical information from\nthe enormous volume of social media data. I-AID incorporates three main\ncomponents: i) a BERT-based encoder to capture the semantics of a tweet and\nrepresent as a low-dimensional vector, ii) a graph attention network (GAT) to\napprehend correlations between tweets' words/entities and the corresponding\ninformation types, and iii) a Relation Network as a learnable distance metric\nto compute the similarity between tweets and their corresponding information\ntypes in a supervised way. We conducted several experiments on two real\npublicly-available datasets. Our results indicate that I-AID outperforms\nstate-of-the-art approaches in terms of weighted average F1 score by +6% and\n+4% on the TREC-IS dataset and COVID-19 Tweets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:07:50 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 02:32:43 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zahera", "Hamada M.", ""], ["Jalota", "Rricha", ""], ["Sherif", "Mohamed A.", ""], ["Ngomo", "Axel N.", ""]]}, {"id": "2008.13548", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Seth Cooper", "title": "Towards Game Design via Creative Machine Learning (GDCML)", "comments": "6 pages, 4 figures, IEEE Conference on Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning (ML) systems have been increasingly applied\nfor performing creative tasks. Such creative ML approaches have seen wide use\nin the domains of visual art and music for applications such as image and music\ngeneration and style transfer. However, similar creative ML techniques have not\nbeen as widely adopted in the domain of game design despite the emergence of\nML-based methods for generating game content. In this paper, we argue for\nleveraging and repurposing such creative techniques for designing content for\ngames, referring to these as approaches for Game Design via Creative ML\n(GDCML). We highlight existing systems that enable GDCML and illustrate how\ncreative ML can inform new systems via example applications and a proposed\nsystem.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 21:15:55 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2008.13567", "submitter": "Moo K. Chung", "authors": "Moo K. Chung", "title": "Introduction to logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For random field theory based multiple comparison corrections In brain\nimaging, it is often necessary to compute the distribution of the supremum of a\nrandom field. Unfortunately, computing the distribution of the supremum of the\nrandom field is not easy and requires satisfying many distributional\nassumptions that may not be true in real data. Thus, there is a need to come up\nwith a different framework that does not use the traditional statistical\nhypothesis testing paradigm that requires to compute p-values. With this as a\nmotivation, we can use a different approach called the logistic regression that\ndoes not require computing the p-value and still be able to localize the\nregions of brain network differences. Unlike other discriminant and\nclassification techniques that tried to classify preselected feature vectors,\nthe method here does not require any preselected feature vectors and performs\nthe classification at each edge level.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 05:18:55 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:16:47 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chung", "Moo K.", ""]]}, {"id": "2008.13578", "submitter": "Yijue Wang", "authors": "Yijue Wang, Chenghong Wang, Zigeng Wang, Shanglin Zhou, Hang Liu,\n  Jinbo Bi, Caiwen Ding, Sanguthevar Rajasekaran", "title": "Against Membership Inference Attack: Pruning is All You Need", "comments": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine\n  Learning (stat.ML)", "journal-ref": "IJCAI, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large model size, high computational operations, and vulnerability\nagainst membership inference attack (MIA) have impeded deep learning or deep\nneural networks (DNNs) popularity, especially on mobile devices. To address the\nchallenge, we envision that the weight pruning technique will help DNNs against\nMIA while reducing model storage and computational operation. In this work, we\npropose a pruning algorithm, and we show that the proposed algorithm can find a\nsubnetwork that can prevent privacy leakage from MIA and achieves competitive\naccuracy with the original DNNs. We also verify our theoretical insights with\nexperiments. Our experimental results illustrate that the attack accuracy using\nmodel compression is up to 13.6% and 10% lower than that of the baseline and\nMin-Max game, accordingly.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:15:44 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 05:48:54 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 14:50:00 GMT"}, {"version": "v4", "created": "Sun, 4 Jul 2021 13:49:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Yijue", ""], ["Wang", "Chenghong", ""], ["Wang", "Zigeng", ""], ["Zhou", "Shanglin", ""], ["Liu", "Hang", ""], ["Bi", "Jinbo", ""], ["Ding", "Caiwen", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "2008.13600", "submitter": "Dionysis Manousakas", "authors": "Dionysis Manousakas and Cecilia Mascolo", "title": "$\\beta$-Cores: Robust Large-Scale Bayesian Data Summarization in the\n  Presence of Outliers", "comments": "25 pages, 5 figures, Accepted at the 14th ACM International\n  Conference on Web Search and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning applications should be able to address the intrinsic\nchallenges arising over inference on massive real-world datasets, including\nscalability and robustness to outliers. Despite the multiple benefits of\nBayesian methods (such as uncertainty-aware predictions, incorporation of\nexperts knowledge, and hierarchical modeling), the quality of classic Bayesian\ninference depends critically on whether observations conform with the assumed\ndata generating model, which is impossible to guarantee in practice. In this\nwork, we propose a variational inference method that, in a principled way, can\nsimultaneously scale to large datasets, and robustify the inferred posterior\nwith respect to the existence of outliers in the observed data. Reformulating\nBayes theorem via the $\\beta$-divergence, we posit a robustified\npseudo-Bayesian posterior as the target of inference. Moreover, relying on the\nrecent formulations of Riemannian coresets for scalable Bayesian inference, we\npropose a sparse variational approximation of the robustified posterior and an\nefficient stochastic black-box algorithm to construct it. Overall our method\nallows releasing cleansed data summaries that can be applied broadly in\nscenarios including structured data corruption. We illustrate the applicability\nof our approach in diverse simulated and real datasets, and various statistical\nmodels, including Gaussian mean inference, logistic and neural linear\nregression, demonstrating its superiority to existing Bayesian summarization\nmethods in the presence of outliers.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:47:12 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 10:25:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Manousakas", "Dionysis", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2008.13607", "submitter": "Hadrien Pouget", "authors": "Hadrien Pouget, Hana Chockler, Youcheng Sun, Daniel Kroening", "title": "Ranking Policy Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policies trained via Reinforcement Learning (RL) are often needlessly\ncomplex, making them more difficult to analyse and interpret. In a run with $n$\ntime steps, a policy will decide $n$ times on an action to take, even when only\na tiny subset of these decisions deliver value over selecting a simple default\naction. Given a pre-trained policy, we propose a black-box method based on\nstatistical fault localisation that ranks the states of the environment\naccording to the importance of decisions made in those states. We evaluate our\nranking method by creating new, simpler policies by pruning decisions\nidentified as unimportant, and measure the impact on performance. Our\nexperimental results on a diverse set of standard benchmarks (gridworld,\nCartPole, Atari games) show that in some cases less than half of the decisions\nmade contribute to the expected reward. We furthermore show that the decisions\nmade in the most frequently visited states are not the most important for the\nexpected reward.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:54:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pouget", "Hadrien", ""], ["Chockler", "Hana", ""], ["Sun", "Youcheng", ""], ["Kroening", "Daniel", ""]]}, {"id": "2008.13620", "submitter": "Ruoqi Liu", "authors": "Ruoqi Liu, Changchang Yin, Ping Zhang", "title": "Estimating Individual Treatment Effects with Time-Varying Confounders", "comments": "Accepted to ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating the individual treatment effect (ITE) from observational data is\nmeaningful and practical in healthcare. Existing work mainly relies on the\nstrong ignorability assumption that no hidden confounders exist, which may lead\nto bias in estimating causal effects. Some studies consider the hidden\nconfounders are designed for static environment and not easily adaptable to a\ndynamic setting. In fact, most observational data (e.g., electronic medical\nrecords) is naturally dynamic and consists of sequential information. In this\npaper, we propose Deep Sequential Weighting (DSW) for estimating ITE with\ntime-varying confounders. Specifically, DSW infers the hidden confounders by\nincorporating the current treatment assignments and historical information\nusing a deep recurrent weighting neural network. The learned representations of\nhidden confounders combined with current observed data are leveraged for\npotential outcome and treatment predictions. We compute the time-varying\ninverse probabilities of treatment for re-weighting the population. We conduct\ncomprehensive comparison experiments on fully-synthetic, semi-synthetic and\nreal-world datasets to evaluate the performance of our model and baselines.\nResults demonstrate that our model can generate unbiased and accurate treatment\neffect by conditioning both time-varying observed and hidden confounders,\npaving the way for personalized medicine.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 02:21:56 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 16:34:59 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Liu", "Ruoqi", ""], ["Yin", "Changchang", ""], ["Zhang", "Ping", ""]]}, {"id": "2008.13625", "submitter": "Milena \\v{C}uki\\'c Radenkovi\\'c Dr", "authors": "Milena Cukic, Slavoljub Radenkovic, Miodrag Stokic, and Danka Savic", "title": "Transfer entropy applied on EEG in depression reveals aberrated dynamics", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied transfer entropy analysis on samples of electroencephalogram\nrecorded from patients diagnosed with major depressive disorder and matched\nhealthy controls. This is the first graphical representation of aberrated\ndynamics in terms of connectivity and the direction of information between\nstandard centers in MDD.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:07:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cukic", "Milena", ""], ["Radenkovic", "Slavoljub", ""], ["Stokic", "Miodrag", ""], ["Savic", "Danka", ""]]}, {"id": "2008.13629", "submitter": "Anmol Kagrecha", "authors": "Anmol Kagrecha, Jayakrishnan Nair, and Krishna Jagannathan", "title": "Statistically Robust, Risk-Averse Best Arm Identification in Multi-Armed\n  Bandits", "comments": "29 pages. Preliminary version appeared in NeurIPS 2019. arXiv admin\n  note: text overlap with arXiv:1906.00569", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional multi-armed bandit (MAB) formulations usually make certain\nassumptions about the underlying arms' distributions, such as bounds on the\nsupport or their tail behaviour. Moreover, such parametric information is\nusually 'baked' into the algorithms. In this paper, we show that specialized\nalgorithms that exploit such parametric information are prone to inconsistent\nlearning performance when the parameter is misspecified. Our key contributions\nare twofold: (i) We establish fundamental performance limits of statistically\nrobust MAB algorithms under the fixed-budget pure exploration setting, and (ii)\nWe propose two classes of algorithms that are asymptotically near-optimal.\nAdditionally, we consider a risk-aware criterion for best arm identification,\nwhere the objective associated with each arm is a linear combination of the\nmean and the conditional value at risk (CVaR). Throughout, we make a very mild\n'bounded moment' assumption, which lets us work with both light-tailed and\nheavy-tailed distributions within a unified framework.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 13:43:12 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kagrecha", "Anmol", ""], ["Nair", "Jayakrishnan", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "2008.13646", "submitter": "Jong Chul Ye", "authors": "Shujaat Khan, Jaeyoung Huh and Jong Chul Ye", "title": "Switchable Deep Beamformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent proposals of deep beamformers using deep neural networks have\nattracted significant attention as computational efficient alternatives to\nadaptive and compressive beamformers. Moreover, deep beamformers are versatile\nin that image post-processing algorithms can be combined with the beamforming.\nUnfortunately, in the current technology, a separate beamformer should be\ntrained and stored for each application, demanding significant scanner\nresources. To address this problem, here we propose a {\\em switchable} deep\nbeamformer that can produce various types of output such as DAS, speckle\nremoval, deconvolution, etc., using a single network with a simple switch. In\nparticular, the switch is implemented through Adaptive Instance Normalization\n(AdaIN) layers, so that various output can be generated by merely changing the\nAdaIN code. Experimental results using B-mode focused ultrasound confirm the\nflexibility and efficacy of the proposed methods for various applications.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:31:03 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 11:48:41 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.13651", "submitter": "Yingjie Feng", "authors": "Yingjie Feng", "title": "Causal Inference in Possibly Nonlinear Factor Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a general causal inference method for treatment effects\nmodels with noisily measured confounders. The key feature is that a large set\nof noisy measurements are linked with the underlying latent confounders through\nan unknown, possibly nonlinear factor structure. The main building block is a\nlocal principal subspace approximation procedure that combines $K$-nearest\nneighbors matching and principal component analysis. Estimators of many causal\nparameters, including average treatment effects and counterfactual\ndistributions, are constructed based on doubly-robust score functions.\nLarge-sample properties of these estimators are established, which only require\nrelatively mild conditions on the principal subspace approximation. The results\nare illustrated with an empirical application studying the effect of political\nconnections on stock returns of financial firms, and a Monte Carlo experiment.\nThe main technical and methodological results regarding the general local\nprincipal subspace approximation method may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:39:36 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 07:20:38 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Feng", "Yingjie", ""]]}, {"id": "2008.13690", "submitter": "Jussi Tohka", "authors": "Jussi Tohka and Mark van Gils", "title": "Evaluation of machine learning algorithms for Health and Wellness\n  applications: a tutorial", "comments": "To be published in Computers in Biology and Medicine", "journal-ref": null, "doi": "10.1016/j.compbiomed.2021.104324", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Research on decision support applications in healthcare, such as those\nrelated to diagnosis, prediction, treatment planning, etc., have seen\nenormously increased interest recently. This development is thanks to the\nincrease in data availability as well as advances in artificial intelligence\nand machine learning research. Highly promising research examples are published\ndaily. However, at the same time, there are some unrealistic expectations with\nregards to the requirements for reliable development and objective validation\nthat is needed in healthcare settings. These expectations may lead to unmet\nschedules and disappointments (or non-uptake) at the end-user side. It is the\naim of this tutorial to provide practical guidance on how to assess performance\nreliably and efficiently and avoid common traps. Instead of giving a list of\ndo's and don't s, this tutorial tries to build a better understanding behind\nthese do's and don't s and presents both the most relevant performance\nevaluation criteria as well as how to compute them. Along the way, we will\nindicate common mistakes and provide references discussing various topics more\nin-depth.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:50:51 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:40:09 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Tohka", "Jussi", ""], ["van Gils", "Mark", ""]]}, {"id": "2008.13697", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Kyle Istvan", "title": "A Topological Framework for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize classical facts from topology to show that the classification\nproblem in machine learning is always solvable under very mild conditions.\nFurthermore, we show that a softmax classification network acts on an input\ntopological space by a finite sequence of topological moves to achieve the\nclassification task. Moreover, given a training dataset, we show how\ntopological formalism can be used to suggest the appropriate architectural\nchoices for neural networks designed to be trained as classifiers on the data.\nFinally, we show how the architecture of a neural network cannot be chosen\nindependently from the shape of the underlying data. To demonstrate these\nresults, we provide example datasets and show how they are acted upon by neural\nnets from this topological perspective.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:56:42 GMT"}, {"version": "v10", "created": "Wed, 21 Oct 2020 04:56:07 GMT"}, {"version": "v11", "created": "Sat, 26 Dec 2020 21:50:42 GMT"}, {"version": "v12", "created": "Fri, 15 Jan 2021 20:42:06 GMT"}, {"version": "v13", "created": "Mon, 21 Jun 2021 12:24:50 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 02:53:24 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 00:47:36 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 02:40:42 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2020 17:12:02 GMT"}, {"version": "v6", "created": "Mon, 5 Oct 2020 08:31:03 GMT"}, {"version": "v7", "created": "Sun, 11 Oct 2020 23:42:57 GMT"}, {"version": "v8", "created": "Wed, 14 Oct 2020 20:33:22 GMT"}, {"version": "v9", "created": "Sun, 18 Oct 2020 19:27:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Hajij", "Mustafa", ""], ["Istvan", "Kyle", ""]]}, {"id": "2008.13723", "submitter": "Vignesh Srinivasan", "authors": "Vignesh Srinivasan, Klaus-Robert M\\\"uller, Wojciech Samek, Shinichi\n  Nakajima", "title": "Langevin Cooling for Domain Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain translation is the task of finding correspondence between two domains.\nSeveral Deep Neural Network (DNN) models, e.g., CycleGAN and cross-lingual\nlanguage models, have shown remarkable successes on this task under the\nunsupervised setting---the mappings between the domains are learned from two\nindependent sets of training data in both domains (without paired samples).\nHowever, those methods typically do not perform well on a significant\nproportion of test samples. In this paper, we hypothesize that many of such\nunsuccessful samples lie at the fringe---relatively low-density areas---of data\ndistribution, where the DNN was not trained very well, and propose to perform\nLangevin dynamics to bring such fringe samples towards high density areas. We\ndemonstrate qualitatively and quantitatively that our strategy, called Langevin\nCooling (L-Cool), enhances state-of-the-art methods in image translation and\nlanguage translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:43:17 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Srinivasan", "Vignesh", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""], ["Nakajima", "Shinichi", ""]]}, {"id": "2008.13735", "submitter": "Jingqiu Ding", "authors": "Jingqiu Ding, Samuel B.Hopkins, David Steurer", "title": "Estimating Rank-One Spikes from Heavy-Tailed Noise via Self-Avoiding\n  Walks", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study symmetric spiked matrix models with respect to a general class of\nnoise distributions. Given a rank-1 deformation of a random noise matrix, whose\nentries are independently distributed with zero mean and unit variance, the\ngoal is to estimate the rank-1 part. For the case of Gaussian noise, the top\neigenvector of the given matrix is a widely-studied estimator known to achieve\noptimal statistical guarantees, e.g., in the sense of the celebrated BBP phase\ntransition. However, this estimator can fail completely for heavy-tailed noise.\nIn this work, we exhibit an estimator that works for heavy-tailed noise up to\nthe BBP threshold that is optimal even for Gaussian noise. We give a\nnon-asymptotic analysis of our estimator which relies only on the variance of\neach entry remaining constant as the size of the matrix grows: higher moments\nmay grow arbitrarily fast or even fail to exist. Previously, it was only known\nhow to achieve these guarantees if higher-order moments of the noises are\nbounded by a constant independent of the size of the matrix. Our estimator can\nbe evaluated in polynomial time by counting self-avoiding walks via a color\n-coding technique. Moreover, we extend our estimator to spiked tensor models\nand establish analogous results.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:57:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ding", "Jingqiu", ""], ["Hopkins", "Samuel B.", ""], ["Steurer", "David", ""]]}, {"id": "2008.13763", "submitter": "Jan-Philipp Schulze", "authors": "J.-P. Schulze, P. Sperl, K. B\\\"ottinger", "title": "Anomaly Detection by Recombining Gated Unsupervised Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by mixture-of-experts models and the analysis of the hidden\nactivations of neural networks, we introduce a novel unsupervised anomaly\ndetection method called ARGUE. Current anomaly detection methods struggle when\nthe training data does contain multiple notions of normal. We designed ARGUE as\na combination of multiple expert networks, which specialise on parts of the\ninput data. For its final decision, ARGUE fuses the distributed knowledge\nacross the expert systems using a gated mixture-of-experts architecture. ARGUE\nachieves superior detection performance across several domains in a purely\ndata-driven way and is more robust to noisy data sets than other\nstate-of-the-art anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:35:57 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 15:58:25 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 16:58:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Schulze", "J. -P.", ""], ["Sperl", "P.", ""], ["B\u00f6ttinger", "K.", ""]]}, {"id": "2008.13773", "submitter": "Wesley Chung", "authors": "Wesley Chung, Valentin Thomas, Marlos C. Machado, Nicolas Le Roux", "title": "Beyond variance reduction: Understanding the true impact of baselines on\n  policy optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit and reinforcement learning (RL) problems can often be framed as\noptimization problems where the goal is to maximize average performance while\nhaving access only to stochastic estimates of the true gradient. Traditionally,\nstochastic optimization theory predicts that learning dynamics are governed by\nthe curvature of the loss function and the noise of the gradient estimates. In\nthis paper we demonstrate that this is not the case for bandit and RL problems.\nTo allow our analysis to be interpreted in light of multi-step MDPs, we focus\non techniques derived from stochastic optimization principles (e.g., natural\npolicy gradient and EXP3) and we show that some standard assumptions from\noptimization theory are violated in these problems. We present theoretical\nresults showing that, at least for bandit problems, curvature and noise are not\nsufficient to explain the learning dynamics and that seemingly innocuous\nchoices like the baseline can determine whether an algorithm converges. These\ntheoretical findings match our empirical evaluation, which we extend to\nmulti-state MDPs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:52:09 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 18:13:05 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 18:10:59 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Chung", "Wesley", ""], ["Thomas", "Valentin", ""], ["Machado", "Marlos C.", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "2008.13777", "submitter": "Lijun Ding", "authors": "Lijun Ding, Yuqian Zhang, Yudong Chen", "title": "Low-rank matrix recovery with non-quadratic loss: projected gradient\n  method and regularity projection oracle", "comments": "Main text has 13 pages. Reading first seven pages (takes around 10-15\n  minutes) should give a good understanding of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing results for low-rank matrix recovery largely focus on quadratic\nloss, which enjoys favorable properties such as restricted strong\nconvexity/smoothness (RSC/RSM) and well conditioning over all low rank\nmatrices. However, many interesting problems involve non-quadratic loss do not\nsatisfy such properties; examples including one-bit matrix sensing, one-bit\nmatrix completion, and rank aggregation. For these problems, standard nonconvex\napproaches such as projected gradient with rank constraint alone (a.k.a.\niterative hard thresholding) and Burer-Monteiro approach may perform badly in\npractice and have no satisfactory theory in guaranteeing global and efficient\nconvergence.\n  In this paper, we show that the critical component in low-rank recovery with\nnon-quadratic loss is a regularity projection oracle, which restricts iterates\nto low-rank matrix within an appropriate bounded set, over which the loss\nfunction is well behaved and satisfies a set of relaxed RSC/RSM conditions.\nAccordingly, we analyze an (averaged) projected gradient method equipped with\nsuch an oracle, and prove that it converges globally and linearly. Our results\napply to a wide range of non-quadratic problems including rank aggregation, one\nbit matrix sensing/completion, and more broadly generalized linear models with\nrank constraint.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:56:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ding", "Lijun", ""], ["Zhang", "Yuqian", ""], ["Chen", "Yudong", ""]]}, {"id": "2008.13781", "submitter": "Alex Aisen", "authors": "Menashe Benjamin, Guy Engelhard, Alex Aisen, Yinon Aradi, Elad\n  Benjamin", "title": "A Multisite, Report-Based, Centralized Infrastructure for Feedback and\n  Monitoring of Radiology AI/ML Development and Clinical Deployment", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An infrastructure for multisite, geographically-distributed creation and\ncollection of diverse, high-quality, curated and labeled radiology image data\nis crucial for the successful automated development, deployment, monitoring and\ncontinuous improvement of Artificial Intelligence (AI)/Machine Learning (ML)\nsolutions in the real world. An interactive radiology reporting approach that\nintegrates image viewing, dictation, natural language processing (NLP) and\ncreation of hyperlinks between image findings and the report, provides\nlocalized labels during routine interpretation. These images and labels can be\ncaptured and centralized in a cloud-based system. This method provides a\npractical and efficient mechanism with which to monitor algorithm performance.\nIt also supplies feedback for iterative development and quality improvement of\nnew and existing algorithmic models. Both feedback and monitoring are achieved\nwithout burdening the radiologist. The method addresses proposed regulatory\nrequirements for post-marketing surveillance and external data. Comprehensive\nmulti-site data collection assists in reducing bias. Resource requirements are\ngreatly reduced compared to dedicated retrospective expert labeling.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:59:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Benjamin", "Menashe", ""], ["Engelhard", "Guy", ""], ["Aisen", "Alex", ""], ["Aradi", "Yinon", ""], ["Benjamin", "Elad", ""]]}]