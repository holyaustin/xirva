[{"id": "1906.00025", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Maya Gupta", "title": "Minimum-Margin Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new active sampling method we call min-margin which trains\nmultiple learners on bootstrap samples and then chooses the examples to label\nbased on the candidates' minimum margin amongst the bootstrapped models. This\nextends standard margin sampling in a way that increases its diversity in a\nsupervised manner as it arises from the model uncertainty. We focus on the\none-shot batch active learning setting, and show theoretically and through\nextensive experiments on a broad set of problems that min-margin outperforms\nother methods, particularly as batch size grows.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:32:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jiang", "Heinrich", ""], ["Gupta", "Maya", ""]]}, {"id": "1906.00028", "submitter": "Przemys{\\l}aw Spurek", "authors": "Andrzej Bedychaj, Przemys{\\l}aw Spurek, {\\L}ukasz Struskim, Jacek\n  Tabor", "title": "Independent Component Analysis based on multiple data-weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) - one of the basic tools in data\nanalysis - aims to find a coordinate system in which the components of the data\nare independent. In this paper we present Multiple-weighted Independent\nComponent Analysis (MWeICA) algorithm, a new ICA method which is based on\napproximate diagonalization of weighted covariance matrices. Our idea is based\non theoretical result, which says that linear independence of weighted data\n(for gaussian weights) guarantees independence. Experiments show that MWeICA\nachieves better results to most state-of-the-art ICA methods, with similar\ncomputational time.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:39:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bedychaj", "Andrzej", ""], ["Spurek", "Przemys\u0142aw", ""], ["Struskim", "\u0141ukasz", ""], ["Tabor", "Jacek", ""]]}, {"id": "1906.00031", "submitter": "Daniele Bigoni", "authors": "Michael C. Brennan and Daniele Bigoni and Olivier Zahm and Alessio\n  Spantini and Youssef Marzouk", "title": "Greedy inference with structure-exploiting lazy maps", "comments": "21 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for solving high-dimensional Bayesian inference\nproblems using \\emph{structure-exploiting} low-dimensional transport maps or\nflows. These maps are confined to a low-dimensional subspace (hence, lazy), and\nthe subspace is identified by minimizing an upper bound on the\nKullback--Leibler divergence (hence, structured). Our framework provides a\nprincipled way of identifying and exploiting low-dimensional structure in an\ninference problem. It focuses the expressiveness of a transport map along the\ndirections of most significant discrepancy from the posterior, and can be used\nto build deep compositions of lazy maps, where low-dimensional projections of\nthe parameters are iteratively transformed to match the posterior. We prove\nweak convergence of the generated sequence of distributions to the posterior,\nand we demonstrate the benefits of the framework on challenging inference\nproblems in machine learning and differential equations, using inverse\nautoregressive flows and polynomial maps as examples of the underlying density\nestimators.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:52:21 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 06:20:34 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 21:37:44 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Brennan", "Michael C.", ""], ["Bigoni", "Daniele", ""], ["Zahm", "Olivier", ""], ["Spantini", "Alessio", ""], ["Marzouk", "Youssef", ""]]}, {"id": "1906.00066", "submitter": "Dennis Wei", "authors": "Dennis Wei, Karthikeyan Natesan Ramamurthy, Flavio du Pin Calmon", "title": "Optimized Score Transformation for Fair Classification", "comments": "33 pages, 9 figures; additional experimental comparisons and\n  asymptotic optimality result, revised introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers fair probabilistic classification where the outputs of\nprimary interest are predicted probabilities, commonly referred to as scores.\nWe formulate the problem of transforming scores to satisfy fairness constraints\nthat are linear in conditional means of scores while minimizing the loss in\nutility. The formulation can be applied either to post-process classifier\noutputs or to pre-process training data, thus allowing maximum freedom in\nselecting a classification algorithm. We derive a closed-form expression for\nthe optimal transformed scores and a convex optimization problem for the\ntransformation parameters. In the population limit, the transformed score\nfunction is the fairness-constrained minimizer of cross-entropy with respect to\nthe optimal unconstrained scores. In the finite sample setting, we propose to\napproach this solution using a combination of standard probabilistic\nclassifiers and ADMM. The transformation parameters obtained from the\nfinite-sample procedure are shown to be asymptotically optimal. Comprehensive\nexperiments comparing to 10 existing methods show that the proposed\nFairScoreTransformer has advantages for score-based metrics such as Brier score\nand AUC while remaining competitive for binary label-based metrics such as\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:27:55 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 00:43:09 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wei", "Dennis", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Calmon", "Flavio du Pin", ""]]}, {"id": "1906.00088", "submitter": "M. Arjumand Masood", "authors": "Muhammad A. Masood and Finale Doshi-Velez", "title": "Diversity-Inducing Policy Gradient: Using Maximum Mean Discrepancy to\n  Find a Set of Diverse Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard reinforcement learning methods aim to master one way of solving a\ntask whereas there may exist multiple near-optimal policies. Being able to\nidentify this collection of near-optimal policies can allow a domain expert to\nefficiently explore the space of reasonable solutions. Unfortunately, existing\napproaches that quantify uncertainty over policies are not ultimately relevant\nto finding policies with qualitatively distinct behaviors. In this work, we\nformalize the difference between policies as a difference between the\ndistribution of trajectories induced by each policy, which encourages diversity\nwith respect to both state visitation and action choices. We derive a\ngradient-based optimization technique that can be combined with existing policy\ngradient methods to now identify diverse collections of well-performing\npolicies. We demonstrate our approach on benchmarks and a healthcare task.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 21:29:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Masood", "Muhammad A.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1906.00094", "submitter": "Nahil Sobh", "authors": "Diab W. Abueidda, Mohammad Almasri, Rami Ammourah, Umberto Ravaioli,\n  Iwona M. Jasiuk, Nahil A. Sobh", "title": "Prediction and optimization of mechanical properties of composites using\n  convolutional neural networks", "comments": null, "journal-ref": "Composite Structures 2019", "doi": "10.1016/j.compstruct.2019.111264", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a convolutional neural network model to predict the\nmechanical properties of a two-dimensional checkerboard composite\nquantitatively. The checkerboard composite possesses two phases, one phase is\nsoft and ductile while the other is stiff and brittle. The ground-truth data\nused in the training process are obtained from finite element analyses under\nthe assumption of plane stress. Monte Carlo simulations and central limit\ntheorem are used to find the size of the dataset needed. Once the training\nprocess is completed, the developed model is validated using data unseen during\ntraining. The developed neural network model captures the stiffness, strength,\nand toughness of checkerboard composites with high accuracy. Also, we integrate\nthe developed model with a genetic algorithm (GA) optimizer to identify the\noptimal microstructural designs. The genetic algorithm optimizer adopted here\nhas several operators, selection, crossover, mutation, and elitism. The\noptimizer converges to configurations with highly enhanced properties. For the\ncase of the modulus and starting from randomly-initialized generation, the GA\noptimizer converges to the global maximum which involves no soft elements.\nAlso, the GA optimizers, when used to maximize strength and toughness, tend\ntowards having soft elements in the region next to the crack tip.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 21:56:45 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Abueidda", "Diab W.", ""], ["Almasri", "Mohammad", ""], ["Ammourah", "Rami", ""], ["Ravaioli", "Umberto", ""], ["Jasiuk", "Iwona M.", ""], ["Sobh", "Nahil A.", ""]]}, {"id": "1906.00095", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Hao Yang, Jinho D. Choi", "title": "The Pupil Has Become the Master: Teacher-Student Model-Based Word\n  Embedding Distillation with Ensemble Learning", "comments": "7 pages, Proceedings of the 28th International Joint Conference on\n  Artificial Intelligence, 2019 (IJCAI'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have facilitated the demand of neural models\nfor real applications. In practice, these applications often need to be\ndeployed with limited resources while keeping high accuracy. This paper touches\nthe core of neural models in NLP, word embeddings, and presents a new embedding\ndistillation framework that remarkably reduces the dimension of word embeddings\nwithout compromising accuracy. A novel distillation ensemble approach is also\nproposed that trains a high-efficient student model using multiple teacher\nmodels. In our approach, the teacher models play roles only during training\nsuch that the student model operates on its own without getting supports from\nthe teacher models during decoding, which makes it eighty times faster and\nlighter than other typical ensemble methods. All models are evaluated on seven\ndocument classification datasets and show a significant advantage over the\nteacher models for most cases. Our analysis depicts insightful transformation\nof word embeddings from distillation and suggests a future direction to\nensemble approaches using neural models.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 21:58:51 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shin", "Bonggun", ""], ["Yang", "Hao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1906.00097", "submitter": "Elliot Meyerson", "authors": "Elliot Meyerson and Risto Miikkulainen", "title": "Modular Universal Reparameterization: Deep Multi-task Learning Across\n  Diverse Domains", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), 16 pages, including Supplemental Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning applications continue to become more diverse, an interesting\nquestion arises: Can general problem solving arise from jointly learning\nseveral such diverse tasks? To approach this question, deep multi-task learning\nis extended in this paper to the setting where there is no obvious overlap\nbetween task architectures. The idea is that any set of (architecture,task)\npairs can be decomposed into a set of potentially related subproblems, whose\nsharing is optimized by an efficient stochastic algorithm. The approach is\nfirst validated in a classic synthetic multi-task learning benchmark, and then\napplied to sharing across disparate architectures for vision, NLP, and genomics\ntasks. It discovers regularities across these domains, encodes them into\nsharable modules, and combines these modules systematically to improve\nperformance in the individual tasks. The results confirm that sharing learned\nfunctionality across diverse domains and architectures is indeed beneficial,\nthus establishing a key ingredient for general problem solving in the future.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:00:43 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:51:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1906.00098", "submitter": "Hao Wang", "authors": "Hao Wang, Linlin Zong, Bing Liu, Yan Yang and Wei Zhou", "title": "Spectral Perturbation Meets Incomplete Multi-view Data", "comments": "to appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond existing multi-view clustering, this paper studies a more realistic\nclustering scenario, referred to as incomplete multi-view clustering, where a\nnumber of data instances are missing in certain views. To tackle this problem,\nwe explore spectral perturbation theory. In this work, we show a strong link\nbetween perturbation risk bounds and incomplete multi-view clustering. That is,\nas the similarity matrix fed into spectral clustering is a quantity bounded in\nmagnitude O(1), we transfer the missing problem from data to similarity and\ntailor a matrix completion method for incomplete similarity matrix. Moreover,\nwe show that the minimization of perturbation risk bounds among different views\nmaximizes the final fusion result across all views. This provides a solid\nfusion criteria for multi-view data. We motivate and propose a\nPerturbation-oriented Incomplete multi-view Clustering (PIC) method.\nExperimental results demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:05:39 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Hao", ""], ["Zong", "Linlin", ""], ["Liu", "Bing", ""], ["Yang", "Yan", ""], ["Zhou", "Wei", ""]]}, {"id": "1906.00101", "submitter": "Joel LeBlanc", "authors": "Joel W. LeBlanc and Brian J. Thelen and Alfred O. Hero", "title": "Testing that a Local Optimum of the Likelihood is Globally Optimum using\n  Reparameterized Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical imaging problems are posed as non-convex optimization\nproblems. When numerically tractable global optimization procedures are not\navailable, one is often interested in testing ex post facto whether or not a\nlocally convergent algorithm has found the globally optimal solution. When the\nproblem is formulated in terms of maximizing the likelihood function under a\nstatistical model for the measurements, one can construct a statistical test\nthat a local maximum is in fact the global maximum. A one-sided test is\nproposed for the case that the statistical model is a member of the generalized\nlocation family of probability distributions, a condition often satisfied in\nimaging and other inverse problems. We propose a general method for improving\nthe accuracy of the test by reparameterizing the likelihood function to embed\nits domain into a higher dimensional parameter space. We show that the proposed\nglobal maximum testing method results in improved accuracy and reduced\ncomputation for a physically-motivated joint-inverse problem arising in\ncamera-blur estimation.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:11:56 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 20:02:18 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 01:29:51 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 15:07:51 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["LeBlanc", "Joel W.", ""], ["Thelen", "Brian J.", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1906.00108", "submitter": "Gautham Krishna Gudur", "authors": "Gautham Krishna Gudur, Prahalathan Sundaramoorthy and Venkatesh\n  Umaashankar", "title": "ActiveHARNet: Towards On-Device Deep Bayesian Active Learning for Human\n  Activity Recognition", "comments": "6 pages, 5 figures, ACM MobiSys 2019 (3rd International Workshop on\n  Embedded and Mobile Deep Learning - EMDL '19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various health-care applications such as assisted living, fall detection\netc., require modeling of user behavior through Human Activity Recognition\n(HAR). HAR using mobile- and wearable-based deep learning algorithms have been\non the rise owing to the advancements in pervasive computing. However, there\nare two other challenges that need to be addressed: first, the deep learning\nmodel should support on-device incremental training (model updation) from\nreal-time incoming data points to learn user behavior over time, while also\nbeing resource-friendly; second, a suitable ground truthing technique (like\nActive Learning) should help establish labels on-the-fly while also selecting\nonly the most informative data points to query from an oracle. Hence, in this\npaper, we propose ActiveHARNet, a resource-efficient deep ensembled model which\nsupports on-device Incremental Learning and inference, with capabilities to\nrepresent model uncertainties through approximations in Bayesian Neural\nNetworks using dropout. This is combined with suitable acquisition functions\nfor active learning. Empirical results on two publicly available wrist-worn HAR\nand fall detection datasets indicate that ActiveHARNet achieves considerable\nefficiency boost during inference across different users, with a substantially\nlow number of acquired pool points (at least 60% reduction) during incremental\nlearning on both datasets experimented with various acquisition functions, thus\ndemonstrating deployment and Incremental Learning feasibility.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:28:40 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Gudur", "Gautham Krishna", ""], ["Sundaramoorthy", "Prahalathan", ""], ["Umaashankar", "Venkatesh", ""]]}, {"id": "1906.00116", "submitter": "Raif Rustamov", "authors": "Raif M. Rustamov and James T. Klosowski", "title": "Kernel Mean Embedding Based Hypothesis Tests for Comparing Spatial Point\n  Patterns", "comments": "Accepted to Spatial Statistics; updated source code provided", "journal-ref": null, "doi": null, "report-no": "TD:102504/2019-04-04", "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an approach for detecting differences in the\nfirst-order structures of spatial point patterns. The proposed approach\nleverages the kernel mean embedding in a novel way by introducing its\napproximate version tailored to spatial point processes. While the original\nembedding is infinite-dimensional and implicit, our approximate embedding is\nfinite-dimensional and comes with explicit closed-form formulas. With its help\nwe reduce the pattern comparison problem to the comparison of means in the\nEuclidean space. Hypothesis testing is based on conducting t-tests on each\ndimension of the embedding and combining the resulting p-values using one of\nthe recently introduced p-value combination techniques. If desired,\ncorresponding Bayes factors can be computed and averaged over all tests to\nquantify the evidence against the null. The main advantages of the proposed\napproach are that it can be applied to both single and replicated pattern\ncomparisons and that neither bootstrap nor permutation procedures are needed to\nobtain or calibrate the p-values. Our experiments show that the resulting tests\nare powerful and the p-values are well-calibrated; two applications to real\nworld data are presented.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 23:03:49 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 16:16:52 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 18:44:41 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 00:27:55 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Rustamov", "Raif M.", ""], ["Klosowski", "James T.", ""]]}, {"id": "1906.00117", "submitter": "Amit Dhurandhar", "authors": "Amit Dhurandhar, Tejaswini Pedapati, Avinash Balakrishnan, Pin-Yu\n  Chen, Karthikeyan Shanmugam and Ruchir Puri", "title": "Model Agnostic Contrastive Explanations for Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a method [7] was proposed to generate contrastive explanations for\ndifferentiable models such as deep neural networks, where one has complete\naccess to the model. In this work, we propose a method, Model Agnostic\nContrastive Explanations Method (MACEM), to generate contrastive explanations\nfor \\emph{any} classification model where one is able to \\emph{only} query the\nclass probabilities for a desired input. This allows us to generate contrastive\nexplanations for not only neural networks, but models such as random forests,\nboosted trees and even arbitrary ensembles that are still amongst the\nstate-of-the-art when learning on structured data [13]. Moreover, to obtain\nmeaningful explanations we propose a principled approach to handle real and\ncategorical features leading to novel formulations for computing pertinent\npositives and negatives that form the essence of a contrastive explanation. A\ndetailed treatment of the different data types of this nature was not performed\nin the previous work, which assumed all features to be positive real valued\nwith zero being indicative of the least interesting value. We part with this\nstrong implicit assumption and generalize these methods so as to be applicable\nacross a much wider range of problem settings. We quantitatively and\nqualitatively validate our approach over 5 public datasets covering diverse\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 23:06:44 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Pedapati", "Tejaswini", ""], ["Balakrishnan", "Avinash", ""], ["Chen", "Pin-Yu", ""], ["Shanmugam", "Karthikeyan", ""], ["Puri", "Ruchir", ""]]}, {"id": "1906.00120", "submitter": "Zhiqiang Tao", "authors": "Hongfu Liu, Zhiqiang Tao, Zhengming Ding", "title": "Consensus Clustering: An Embedding Perspective, Extension and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus clustering fuses diverse basic partitions (i.e., clustering results\nobtained from conventional clustering methods) into an integrated one, which\nhas attracted increasing attention in both academic and industrial areas due to\nits robust and effective performance. Tremendous research efforts have been\nmade to thrive this domain in terms of algorithms and applications. Although\nthere are some survey papers to summarize the existing literature, they neglect\nto explore the underlying connection among different categories. Differently,\nin this paper we aim to provide an embedding prospective to illustrate the\nconsensus mechanism, which transfers categorical basic partitions to other\nrepresentations (e.g., binary coding, spectral embedding, etc) for the\nclustering purpose. To this end, we not only unify two major categories of\nconsensus clustering, but also build an intuitive connection between consensus\nclustering and graph embedding. Moreover, we elaborate several extensions of\nclassical consensus clustering from different settings and problems. Beyond\nthis, we demonstrate how to leverage consensus clustering to address other\ntasks, such as constrained clustering, domain adaptation, feature selection,\nand outlier detection. Finally, we conclude this survey with future work in\nterms of interpretability, learnability and theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 23:49:34 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liu", "Hongfu", ""], ["Tao", "Zhiqiang", ""], ["Ding", "Zhengming", ""]]}, {"id": "1906.00121", "submitter": "Shirui Pan", "authors": "Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Graph WaveNet for Deep Spatial-Temporal Graph Modeling", "comments": "to be published in IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial-temporal graph modeling is an important task to analyze the spatial\nrelations and temporal trends of components in a system. Existing approaches\nmostly capture the spatial dependency on a fixed graph structure, assuming that\nthe underlying relation between entities is pre-determined. However, the\nexplicit graph structure (relation) does not necessarily reflect the true\ndependency and genuine relation may be missing due to the incomplete\nconnections in the data. Furthermore, existing methods are ineffective to\ncapture the temporal trends as the RNNs or CNNs employed in these methods\ncannot capture long-range temporal sequences. To overcome these limitations, we\npropose in this paper a novel graph neural network architecture, Graph WaveNet,\nfor spatial-temporal graph modeling. By developing a novel adaptive dependency\nmatrix and learn it through node embedding, our model can precisely capture the\nhidden spatial dependency in the data. With a stacked dilated 1D convolution\ncomponent whose receptive field grows exponentially as the number of layers\nincreases, Graph WaveNet is able to handle very long sequences. These two\ncomponents are integrated seamlessly in a unified framework and the whole\nframework is learned in an end-to-end manner. Experimental results on two\npublic traffic network datasets, METR-LA and PEMS-BAY, demonstrate the superior\nperformance of our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 23:53:20 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wu", "Zonghan", ""], ["Pan", "Shirui", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1906.00127", "submitter": "Masayuki Karasuyama", "authors": "Shinya Suzuki, Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, Masayuki\n  Karasuyama", "title": "Multi-objective Bayesian Optimization using Pareto-frontier Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an entropy-based multi-objective Bayesian optimization\n(MBO). The entropy search is successful approach to Bayesian optimization.\nHowever, for MBO, existing entropy-based methods ignore trade-off among\nobjectives or introduce unreliable approximations. We propose a novel\nentropy-based MBO called Pareto-frontier entropy search (PFES) by considering\nthe entropy of Pareto-frontier, which is an essential notion of the optimality\nof the multi-objective problem. Our entropy can incorporate the trade-off\nrelation of the optimal values, and further, we derive an analytical formula\nwithout introducing additional approximations or simplifications to the\nstandard entropy search setting. We also show that our entropy computation is\npractically feasible by using a recursive decomposition technique which has\nbeen known in studies of the Pareto hyper-volume computation. Besides the usual\nMBO setting, in which all the objectives are simultaneously observed, we also\nconsider the \"decoupled\" setting, in which the objective functions can be\nobserved separately. PFES can easily adapt to the decoupled setting by\nconsidering the entropy of the marginal density for each output dimension. This\napproach incorporates dependency among objectives conditioned on\nPareto-frontier, which is ignored by the existing method. Our numerical\nexperiments show effectiveness of PFES through several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 01:52:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 02:14:58 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Suzuki", "Shinya", ""], ["Takeno", "Shion", ""], ["Tamura", "Tomoyuki", ""], ["Shitara", "Kazuki", ""], ["Karasuyama", "Masayuki", ""]]}, {"id": "1906.00128", "submitter": "Boli Fang", "authors": "Boli Fang, Miao Jiang, Jerry Shen", "title": "Achieving Fairness in Determining Medicaid Eligibility through Fairgroup\n  Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective complements to human judgment, artificial intelligence techniques\nhave started to aid human decisions in complicated social problems across the\nworld. In the context of United States for instance, automated ML/DL\nclassification models offer complements to human decisions in determining\nMedicaid eligibility. However, given the limitations in ML/DL model design,\nthese algorithms may fail to leverage various factors for decision making,\nresulting in improper decisions that allocate resources to individuals who may\nnot be in the most need. In view of such an issue, we propose in this paper the\nmethod of \\textit{fairgroup construction}, based on the legal doctrine of\n\\textit{disparate impact}, to improve the fairness of regressive classifiers.\nExperiments on American Community Survey dataset demonstrate that our method\ncould be easily adapted to a variety of regressive classification models to\nboost their fairness in deciding Medicaid Eligibility, while maintaining high\nlevels of classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 01:54:19 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fang", "Boli", ""], ["Jiang", "Miao", ""], ["Shen", "Jerry", ""]]}, {"id": "1906.00137", "submitter": "Bahare Fatemi", "authors": "Bahare Fatemi, Perouz Taslakian, David Vazquez, and David Poole", "title": "Knowledge Hypergraphs: Prediction Beyond Binary Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs store facts using relations between two entities. In this\nwork, we address the question of link prediction in knowledge hypergraphs where\nrelations are defined on any number of entities. While techniques exist (such\nas reification) that convert non-binary relations into binary ones, we show\nthat current embedding-based methods for knowledge graph completion do not work\nwell out of the box for knowledge graphs obtained through these techniques. To\novercome this, we introduce HSimplE and HypE, two embedding-based methods that\nwork directly with knowledge hypergraphs. In both models, the prediction is a\nfunction of the relation embedding, the entity embeddings and their\ncorresponding positions in the relation. We also develop public datasets,\nbenchmarks and baselines for hypergraph prediction and show experimentally that\nthe proposed models are more effective than the baselines.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:03:15 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 20:33:33 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 13:39:31 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Fatemi", "Bahare", ""], ["Taslakian", "Perouz", ""], ["Vazquez", "David", ""], ["Poole", "David", ""]]}, {"id": "1906.00145", "submitter": "Deepak Thukral", "authors": "Deepak Thukral, Adesh Pandey, Rishabh Gupta, Vikram Goyal, Tanmoy\n  Chakraborty", "title": "DiffQue: Estimating Relative Difficulty of Questions in Community\n  Question Answering Services", "comments": "25 pages, 7 figures, ACM Transactions on Intelligent Systems and\n  Technology (TIST) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic estimation of relative difficulty of a pair of questions is an\nimportant and challenging problem in community question answering (CQA)\nservices. There are limited studies which addressed this problem. Past studies\nmostly leveraged expertise of users answering the questions and barely\nconsidered other properties of CQA services such as metadata of users and\nposts, temporal information and textual content. In this paper, we propose\nDiffQue, a novel system that maps this problem to a network-aided edge\ndirectionality prediction problem. DiffQue starts by constructing a novel\nnetwork structure that captures different notions of difficulties among a pair\nof questions. It then measures the relative difficulty of two questions by\npredicting the direction of a (virtual) edge connecting these two questions in\nthe network. It leverages features extracted from the network structure,\nmetadata of users/posts and textual description of questions and answers.\nExperiments on datasets obtained from two CQA sites (further divided into four\ndatasets) with human annotated ground-truth show that DiffQue outperforms four\nstate-of-the-art methods by a significant margin (28.77% higher F1 score and\n28.72% higher AUC than the best baseline). As opposed to the other baselines,\n(i) DiffQue appropriately responds to the training noise, (ii) DiffQue is\ncapable of adapting multiple domains (CQA datasets), and (iii) DiffQue can\nefficiently handle 'cold start' problem which may arise due to the lack of\ninformation for newly posted questions or newly arrived users.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:40:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Thukral", "Deepak", ""], ["Pandey", "Adesh", ""], ["Gupta", "Rishabh", ""], ["Goyal", "Vikram", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1906.00150", "submitter": "Joonyoung Yi", "authors": "Joonyoung Yi, Juhyuk Lee, Kwang Joon Kim, Sung Ju Hwang, Eunho Yang", "title": "Why Not to Use Zero Imputation? Correcting Sparsity Bias in Training\n  Neural Networks", "comments": "27 pages", "journal-ref": "Nucl.Phys.Proc.Suppl. 109 (2002) 3-9 Nucl.Phys.Proc.Suppl. 109\n  (2002) 3-9 Nucl.Phys.Proc.Suppl. 109 (2002) 3-9 Proceedings of International\n  Conference on Learning Representations (ICLR) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling missing data is one of the most fundamental problems in machine\nlearning. Among many approaches, the simplest and most intuitive way is zero\nimputation, which treats the value of a missing entry simply as zero. However,\nmany studies have experimentally confirmed that zero imputation results in\nsuboptimal performances in training neural networks. Yet, none of the existing\nwork has explained what brings such performance degradations. In this paper, we\nintroduce the variable sparsity problem (VSP), which describes a phenomenon\nwhere the output of a predictive model largely varies with respect to the rate\nof missingness in the given input, and show that it adversarially affects the\nmodel performance. We first theoretically analyze this phenomenon and propose a\nsimple yet effective technique to handle missingness, which we refer to as\nSparsity Normalization (SN), that directly targets and resolves the VSP. We\nfurther experimentally validate SN on diverse benchmark datasets, to show that\ndebiasing the effect of input-level sparsity improves the performance and\nstabilizes the training of neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 04:03:53 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 07:55:08 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 09:46:57 GMT"}, {"version": "v4", "created": "Tue, 4 Feb 2020 23:30:25 GMT"}, {"version": "v5", "created": "Thu, 6 Feb 2020 08:43:31 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Yi", "Joonyoung", ""], ["Lee", "Juhyuk", ""], ["Kim", "Kwang Joon", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "1906.00158", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Jerry M. Mendel", "title": "Patch Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been different strategies to improve the performance of a machine\nlearning model, e.g., increasing the depth, width, and/or nonlinearity of the\nmodel, and using ensemble learning to aggregate multiple base/weak learners in\nparallel or in series. This paper proposes a novel strategy called patch\nlearning (PL) for this problem. It consists of three steps: 1) train an initial\nglobal model using all training data; 2) identify from the initial global model\nthe patches which contribute the most to the learning error, and train a\n(local) patch model for each such patch; and, 3) update the global model using\ntraining data that do not fall into any patch. To use a PL model, we first\ndetermine if the input falls into any patch. If yes, then the corresponding\npatch model is used to compute the output. Otherwise, the global model is used.\nWe explain in detail how PL can be implemented using fuzzy systems. Five\nregression problems on 1D/2D/3D curve fitting, nonlinear system identification,\nand chaotic time-series prediction, verified its effectiveness. To our\nknowledge, the PL idea has not appeared in the literature before, and it opens\nup a promising new line of research in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 06:11:06 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wu", "Dongrui", ""], ["Mendel", "Jerry M.", ""]]}, {"id": "1906.00165", "submitter": "Xuehang Zheng", "authors": "Xuehang Zheng, Saiprasad Ravishankar, Yong Long, Marc Louis Klasky,\n  Brendt Wohlberg", "title": "Two-layer Residual Sparsifying Transform Learning for Image\n  Reconstruction", "comments": "Accepted to IEEE ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal models based on sparsity, low-rank and other properties have been\nexploited for image reconstruction from limited and corrupted data in medical\nimaging and other computational imaging applications. In particular,\nsparsifying transform models have shown promise in various applications, and\noffer numerous advantages such as efficiencies in sparse coding and learning.\nThis work investigates pre-learning a two-layer extension of the transform\nmodel for image reconstruction, wherein the transform domain or filtering\nresiduals of the image are further sparsified in the second layer. The proposed\nblock coordinate descent optimization algorithms involve highly efficient\nupdates. Preliminary numerical experiments demonstrate the usefulness of a\ntwo-layer model over the previous related schemes for CT image reconstruction\nfrom low-dose measurements.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 06:47:08 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:40:42 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zheng", "Xuehang", ""], ["Ravishankar", "Saiprasad", ""], ["Long", "Yong", ""], ["Klasky", "Marc Louis", ""], ["Wohlberg", "Brendt", ""]]}, {"id": "1906.00170", "submitter": "Herilalaina Rakotoarison", "authors": "Herilalaina Rakotoarison, Marc Schoenauer, Mich\\`ele Sebag", "title": "Automated Machine Learning with Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AutoML task consists of selecting the proper algorithm in a machine\nlearning portfolio, and its hyperparameter values, in order to deliver the best\nperformance on the dataset at hand. Mosaic, a Monte-Carlo tree search (MCTS)\nbased approach, is presented to handle the AutoML hybrid structural and\nparametric expensive black-box optimization problem. Extensive empirical\nstudies are conducted to independently assess and compare: i) the optimization\nprocesses based on Bayesian optimization or MCTS; ii) its warm-start\ninitialization; iii) the ensembling of the solutions gathered along the search.\nMosaic is assessed on the OpenML 100 benchmark and the Scikit-learn portfolio,\nwith statistically significant gains over Auto-Sklearn, winner of former\ninternational AutoML challenges.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 07:19:18 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 20:42:05 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Rakotoarison", "Herilalaina", ""], ["Schoenauer", "Marc", ""], ["Sebag", "Mich\u00e8le", ""]]}, {"id": "1906.00189", "submitter": "Tongliang Liu", "authors": "Xiaobo Xia and Tongliang Liu and Nannan Wang and Bo Han and Chen Gong\n  and Gang Niu and Masashi Sugiyama", "title": "Are Anchor Points Really Indispensable in Label-Noise Learning?", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In label-noise learning, \\textit{noise transition matrix}, denoting the\nprobabilities that clean labels flip into noisy labels, plays a central role in\nbuilding \\textit{statistically consistent classifiers}. Existing theories have\nshown that the transition matrix can be learned by exploiting \\textit{anchor\npoints} (i.e., data points that belong to a specific class almost surely).\nHowever, when there are no anchor points, the transition matrix will be poorly\nlearned, and those current consistent classifiers will significantly\ndegenerate. In this paper, without employing anchor points, we propose a\n\\textit{transition-revision} ($T$-Revision) method to effectively learn\ntransition matrices, leading to better classifiers. Specifically, to learn a\ntransition matrix, we first initialize it by exploiting data points that are\nsimilar to anchor points, having high \\textit{noisy class posterior\nprobabilities}. Then, we modify the initialized matrix by adding a\n\\textit{slack variable}, which can be learned and validated together with the\nclassifier by using noisy data. Empirical results on benchmark-simulated and\nreal-world label-noise datasets demonstrate that without using exact anchor\npoints, the proposed method is superior to the state-of-the-art label-noise\nlearning methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 09:14:54 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 02:23:29 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Xia", "Xiaobo", ""], ["Liu", "Tongliang", ""], ["Wang", "Nannan", ""], ["Han", "Bo", ""], ["Gong", "Chen", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1906.00190", "submitter": "Shayegan Omidshafiei", "authors": "Daniel Hennes, Dustin Morrill, Shayegan Omidshafiei, Remi Munos,\n  Julien Perolat, Marc Lanctot, Audrunas Gruslys, Jean-Baptiste Lespiau, Paavo\n  Parmas, Edgar Duenez-Guzman, Karl Tuyls", "title": "Neural Replicator Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient and actor-critic algorithms form the basis of many commonly\nused training techniques in deep reinforcement learning. Using these algorithms\nin multiagent environments poses problems such as nonstationarity and\ninstability. In this paper, we first demonstrate that standard softmax-based\npolicy gradient can be prone to poor performance in the presence of even the\nmost benign nonstationarity. By contrast, it is known that the replicator\ndynamics, a well-studied model from evolutionary game theory, eliminates\ndominated strategies and exhibits convergence of the time-averaged trajectories\nto interior Nash equilibria in zero-sum games. Thus, using the replicator\ndynamics as a foundation, we derive an elegant one-line change to policy\ngradient methods that simply bypasses the gradient step through the softmax,\nyielding a new algorithm titled Neural Replicator Dynamics (NeuRD). NeuRD\nreduces to the exponential weights/Hedge algorithm in the single-state\nall-actions case. Additionally, NeuRD has formal equivalence to softmax\ncounterfactual regret minimization, which guarantees convergence in the\nsequential tabular case. Importantly, our algorithm provides a straightforward\nway of extending the replicator dynamics to the function approximation setting.\nEmpirical results show that NeuRD quickly adapts to nonstationarities,\noutperforming policy gradient significantly in both tabular and function\napproximation settings, when evaluated on the standard imperfect information\nbenchmarks of Kuhn Poker, Leduc Poker, and Goofspiel.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 09:18:48 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 13:20:48 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 18:15:16 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 16:51:11 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 13:26:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Hennes", "Daniel", ""], ["Morrill", "Dustin", ""], ["Omidshafiei", "Shayegan", ""], ["Munos", "Remi", ""], ["Perolat", "Julien", ""], ["Lanctot", "Marc", ""], ["Gruslys", "Audrunas", ""], ["Lespiau", "Jean-Baptiste", ""], ["Parmas", "Paavo", ""], ["Duenez-Guzman", "Edgar", ""], ["Tuyls", "Karl", ""]]}, {"id": "1906.00195", "submitter": "Mohammad Pirhooshyaran", "authors": "Mohammad Pirhooshyaran, Lawrence V. Snyder", "title": "Multivariate, Multistep Forecasting, Reconstruction and Feature\n  Selection of Ocean Waves via Recurrent and Sequence-to-Sequence Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article explores the concepts of ocean wave multivariate multistep\nforecasting, reconstruction and feature selection. We introduce recurrent\nneural network frameworks, integrated with Bayesian hyperparameter optimization\nand Elastic Net methods. We consider both short- and long-term forecasts and\nreconstruction, for significant wave height and output power of the ocean\nwaves. Sequence-to-sequence neural networks are being developed for the first\ntime to reconstruct the missing characteristics of ocean waves based on\ninformation from nearby wave sensors. Our results indicate that the Adam and\nAMSGrad optimization algorithms are the most robust ones to optimize the\nsequence-to-sequence network. For the case of significant wave height\nreconstruction, we compare the proposed methods with alternatives on a\nwell-studied dataset. We show the superiority of the proposed methods\nconsidering several error metrics. We design a new case study based on\nmeasurement stations along the east coast of the United States and investigate\nthe feature selection concept. Comparisons substantiate the benefit of\nutilizing Elastic Net. Moreover, case study results indicate that when the\nnumber of features is considerable, having deeper structures improves the\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 09:58:15 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 01:01:57 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Pirhooshyaran", "Mohammad", ""], ["Snyder", "Lawrence V.", ""]]}, {"id": "1906.00199", "submitter": "Kelvin Hsu", "authors": "Kelvin Hsu, Fabio Ramos", "title": "Bayesian Deconditional Kernel Mean Embeddings", "comments": "In the Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019), Long Beach, California, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional kernel mean embeddings form an attractive nonparametric framework\nfor representing conditional means of functions, describing the observation\nprocesses for many complex models. However, the recovery of the original\nunderlying function of interest whose conditional mean was observed is a\nchallenging inference task. We formalize deconditional kernel mean embeddings\nas a solution to this inverse problem, and show that it can be naturally viewed\nas a nonparametric Bayes' rule. Critically, we introduce the notion of task\ntransformed Gaussian processes and establish deconditional kernel means as\ntheir posterior predictive mean. This connection provides Bayesian\ninterpretations and uncertainty estimates for deconditional kernel mean\nembeddings, explains their regularization hyperparameters, and reveals a\nmarginal likelihood for kernel hyperparameter learning. These revelations\nfurther enable practical applications such as likelihood-free inference and\nlearning sparse representations for big data.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 10:38:23 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hsu", "Kelvin", ""], ["Ramos", "Fabio", ""]]}, {"id": "1906.00204", "submitter": "Sid Ahmed Fezza", "authors": "Sid Ahmed Fezza, Yassine Bakhti, Wassim Hamidouche, Olivier D\\'eforges", "title": "Perceptual Evaluation of Adversarial Attacks for CNN-based Image\n  Classification", "comments": "Eleventh International Conference on Quality of Multimedia Experience\n  (QoMEX 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have recently achieved state-of-the-art\nperformance and provide significant progress in many machine learning tasks,\nsuch as image classification, speech processing, natural language processing,\netc. However, recent studies have shown that DNNs are vulnerable to adversarial\nattacks. For instance, in the image classification domain, adding small\nimperceptible perturbations to the input image is sufficient to fool the DNN\nand to cause misclassification. The perturbed image, called \\textit{adversarial\nexample}, should be visually as close as possible to the original image.\nHowever, all the works proposed in the literature for generating adversarial\nexamples have used the $L_{p}$ norms ($L_{0}$, $L_{2}$ and $L_{\\infty}$) as\ndistance metrics to quantify the similarity between the original image and the\nadversarial example. Nonetheless, the $L_{p}$ norms do not correlate with human\njudgment, making them not suitable to reliably assess the perceptual\nsimilarity/fidelity of adversarial examples. In this paper, we present a\ndatabase for visual fidelity assessment of adversarial examples. We describe\nthe creation of the database and evaluate the performance of fifteen\nstate-of-the-art full-reference (FR) image fidelity assessment metrics that\ncould substitute $L_{p}$ norms. The database as well as subjective scores are\npublicly available to help designing new metrics for adversarial examples and\nto facilitate future research works.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 11:26:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fezza", "Sid Ahmed", ""], ["Bakhti", "Yassine", ""], ["Hamidouche", "Wassim", ""], ["D\u00e9forges", "Olivier", ""]]}, {"id": "1906.00214", "submitter": "Tom Jurgenson", "authors": "Tom Jurgenson and Aviv Tamar", "title": "Harnessing Reinforcement Learning for Neural Motion Planning", "comments": "13 pages (all), 8 pages (main sections), 6 figures, 4 tables,\n  accepted to rss2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning is an essential component in most of today's robotic\napplications. In this work, we consider the learning setting, where a set of\nsolved motion planning problems is used to improve the efficiency of motion\nplanning on different, yet similar problems. This setting is important in\napplications with rapidly changing environments such as in e-commerce, among\nothers. We investigate a general deep learning based approach, where a neural\nnetwork is trained to map an image of the domain, the current robot state, and\na goal robot state to the next robot state in the plan. We focus on the\nlearning algorithm, and compare supervised learning methods with reinforcement\nlearning (RL) algorithms. We first establish that supervised learning\napproaches are inferior in their accuracy due to insufficient data on the\nboundary of the obstacles, an issue that RL methods mitigate by actively\nexploring the domain. We then propose a modification of the popular DDPG RL\nalgorithm that is tailored to motion planning domains, by exploiting the known\nmodel in the problem and the set of solved plans in the data. We show that our\nalgorithm, dubbed DDPG-MP, significantly improves the accuracy of the learned\nmotion planning policy. Finally, we show that given enough training data, our\nmethod can plan significantly faster on novel domains than off-the-shelf\nsampling based motion planners. Results of our experiments are shown in\nhttps://youtu.be/wHQ4Y4mBRb8.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 12:19:37 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jurgenson", "Tom", ""], ["Tamar", "Aviv", ""]]}, {"id": "1906.00216", "submitter": "Duc Tam Nguyen", "authors": "Duc Tam Nguyen, Thi-Phuong-Nhung Ngo, Zhongyu Lou, Michael Klar, Laura\n  Beggel, Thomas Brox", "title": "Robust Learning Under Label Noise With Iterative Noise-Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training a model under the presence of label\nnoise. Current approaches identify samples with potentially incorrect labels\nand reduce their influence on the learning process by either assigning lower\nweights to them or completely removing them from the training set. In the first\ncase the model however still learns from noisy labels; in the latter approach,\ngood training data can be lost. In this paper, we propose an iterative\nsemi-supervised mechanism for robust learning which excludes noisy labels but\nis still able to learn from the corresponding samples. To this end, we add an\nunsupervised loss term that also serves as a regularizer against the remaining\nlabel noise. We evaluate our approach on common classification tasks with\ndifferent noise ratios. Our robust models outperform the state-of-the-art\nmethods by a large margin. Especially for very large noise ratios, we achieve\nup to 20 % absolute improvement compared to the previous best model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 12:34:41 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Nguyen", "Duc Tam", ""], ["Ngo", "Thi-Phuong-Nhung", ""], ["Lou", "Zhongyu", ""], ["Klar", "Michael", ""], ["Beggel", "Laura", ""], ["Brox", "Thomas", ""]]}, {"id": "1906.00226", "submitter": "Li-Fang Cheng", "authors": "Li-Fang Cheng, Bianca Dumitrascu, Michael Zhang, Corey Chivers,\n  Michael Draugelis, Kai Li, Barbara E. Engelhardt", "title": "Patient-Specific Effects of Medication Using Latent Force Models with\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output Gaussian processes (GPs) are a flexible Bayesian nonparametric\nframework that has proven useful in jointly modeling the physiological states\nof patients in medical time series data. However, capturing the short-term\neffects of drugs and therapeutic interventions on patient physiological state\nremains challenging. We propose a novel approach that models the effect of\ninterventions as a hybrid Gaussian process composed of a GP capturing patient\nphysiology convolved with a latent force model capturing effects of treatments\non specific physiological features. This convolution of a multi-output GP with\na GP including a causal time-marked kernel leads to a well-characterized model\nof the patients' physiological state responding to interventions. We show that\nour model leads to analytically tractable cross-covariance functions, allowing\nscalable inference. Our hierarchical model includes estimates of\npatient-specific effects but allows sharing of support across patients. Our\napproach achieves competitive predictive performance on challenging hospital\ndata, where we recover patient-specific response to the administration of three\ncommon drugs: one antihypertensive drug and two anticoagulants.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 14:15:30 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cheng", "Li-Fang", ""], ["Dumitrascu", "Bianca", ""], ["Zhang", "Michael", ""], ["Chivers", "Corey", ""], ["Draugelis", "Michael", ""], ["Li", "Kai", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1906.00229", "submitter": "Shiliang Sun", "authors": "Minghao Gu, Shiliang Sun", "title": "Variational Langevin Hamiltonian Monte Carlo for Distant Multi-modal\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hamiltonian Monte Carlo (HMC) sampling algorithm exploits Hamiltonian\ndynamics to construct efficient Markov Chain Monte Carlo (MCMC), which has\nbecome increasingly popular in machine learning and statistics. Since HMC uses\nthe gradient information of the target distribution, it can explore the state\nspace much more efficiently than the random-walk proposals. However,\nprobabilistic inference involving multi-modal distributions is very difficult\nfor standard HMC method, especially when the modes are far away from each\nother. Sampling algorithms are then often incapable of traveling across the\nplaces of low probability. In this paper, we propose a novel MCMC algorithm\nwhich aims to sample from multi-modal distributions effectively. The method\nimproves Hamiltonian dynamics to reduce the autocorrelation of the samples and\nuses a variational distribution to explore the phase space and find new modes.\nA formal proof is provided which shows that the proposed method can converge to\ntarget distributions. Both synthetic and real datasets are used to evaluate its\nproperties and performance. The experimental results verify the theory and show\nsuperior performance in multi-modal sampling.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 14:26:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Gu", "Minghao", ""], ["Sun", "Shiliang", ""]]}, {"id": "1906.00230", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Alexander Camuto, Tom Rainforth, Stephen Roberts,\n  Chris Holmes", "title": "Improving VAEs' Robustness to Adversarial Attack", "comments": "Main paper of 9 pages, followed by appendix", "journal-ref": "International Conference on Learning Representations (ICLR) 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have recently been shown to be vulnerable to\nadversarial attacks, wherein they are fooled into reconstructing a chosen\ntarget image. However, how to defend against such attacks remains an open\nproblem. We make significant advances in addressing this issue by introducing\nmethods for producing adversarially robust VAEs. Namely, we first demonstrate\nthat methods proposed to obtain disentangled latent representations produce\nVAEs that are more robust to these attacks. However, this robustness comes at\nthe cost of reducing the quality of the reconstructions. We ameliorate this by\napplying disentangling methods to hierarchical VAEs. The resulting models\nproduce high-fidelity autoencoders that are also adversarially robust. We\nconfirm their capabilities on several different datasets and with current\nstate-of-the-art VAE adversarial attacks, and also show that they increase the\nrobustness of downstream tasks to attack.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 14:29:01 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 17:25:01 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 15:51:04 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 16:17:46 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 18:25:42 GMT"}, {"version": "v6", "created": "Fri, 29 Jan 2021 18:54:23 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Willetts", "Matthew", ""], ["Camuto", "Alexander", ""], ["Rainforth", "Tom", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1906.00232", "submitter": "Rahul Singh", "authors": "Rahul Singh, Maneesh Sahani, Arthur Gretton", "title": "Kernel Instrumental Variable Regression", "comments": "41 pages, 11 figures. Advances in Neural Information Processing\n  Systems. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.FA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrumental variable (IV) regression is a strategy for learning causal\nrelationships in observational data. If measurements of input X and output Y\nare confounded, the causal relationship can nonetheless be identified if an\ninstrumental variable Z is available that influences X directly, but is\nconditionally independent of Y given X and the unmeasured confounder. The\nclassic two-stage least squares algorithm (2SLS) simplifies the estimation\nproblem by modeling all relationships as linear functions. We propose kernel\ninstrumental variable regression (KIV), a nonparametric generalization of 2SLS,\nmodeling relations among X, Y, and Z as nonlinear functions in reproducing\nkernel Hilbert spaces (RKHSs). We prove the consistency of KIV under mild\nassumptions, and derive conditions under which convergence occurs at the\nminimax optimal rate for unconfounded, single-stage RKHS regression. In doing\nso, we obtain an efficient ratio between training sample sizes used in the\nalgorithm's first and second stages. In experiments, KIV outperforms state of\nthe art alternatives for nonparametric IV regression.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 14:30:03 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 15:51:06 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 13:58:17 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 00:09:43 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 16:59:02 GMT"}, {"version": "v6", "created": "Wed, 15 Jul 2020 18:53:19 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Singh", "Rahul", ""], ["Sahani", "Maneesh", ""], ["Gretton", "Arthur", ""]]}, {"id": "1906.00250", "submitter": "Christina Ilvento", "authors": "Christina Ilvento", "title": "Metric Learning for Individual Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much discussion recently about how fairness should be measured\nor enforced in classification. Individual Fairness [Dwork, Hardt, Pitassi,\nReingold, Zemel, 2012], which requires that similar individuals be treated\nsimilarly, is a highly appealing definition as it gives strong guarantees on\ntreatment of individuals. Unfortunately, the need for a task-specific\nsimilarity metric has prevented its use in practice. In this work, we propose a\nsolution to the problem of approximating a metric for Individual Fairness based\non human judgments. Our model assumes that we have access to a human fairness\narbiter, who can answer a limited set of queries concerning similarity of\nindividuals for a particular task, is free of explicit biases and possesses\nsufficient domain knowledge to evaluate similarity. Our contributions include\ndefinitions for metric approximation relevant for Individual Fairness,\nconstructions for approximations from a limited number of realistic queries to\nthe arbiter on a sample of individuals, and learning procedures to construct\nhypotheses for metric approximations which generalize to unseen samples under\ncertain assumptions of learnability of distance threshold functions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 16:09:23 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 15:18:18 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Ilvento", "Christina", ""]]}, {"id": "1906.00254", "submitter": "Ivan Kiskin", "authors": "Ivan Kiskin, Udeepa Meepegama, Steven Roberts", "title": "Super-resolution of Time-series Labels for Bootstrapped Event Detection", "comments": "Accepted at the Time-series workshop at ICML 2019, Long Beach", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving real-world problems, particularly with deep learning, relies on the\navailability of abundant, quality data. In this paper we develop a novel\nframework that maximises the utility of time-series datasets that contain only\nsmall quantities of expertly-labelled data, larger quantities of weakly (or\ncoarsely) labelled data and a large volume of unlabelled data. This represents\nscenarios commonly encountered in the real world, such as in crowd-sourcing\napplications. In our work, we use a nested loop using a Kernel Density\nEstimator (KDE) to super-resolve the abundant low-quality data labels, thereby\nenabling effective training of a Convolutional Neural Network (CNN). We\ndemonstrate two key results: a) The KDE is able to super-resolve labels more\naccurately, and with better calibrated probabilities, than well-established\nclassifiers acting as baselines; b) Our CNN, trained on super-resolved labels\nfrom the KDE, achieves an improvement in F1 score of 22.1% over the next best\nbaseline system in our candidate problem domain.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 16:29:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kiskin", "Ivan", ""], ["Meepegama", "Udeepa", ""], ["Roberts", "Steven", ""]]}, {"id": "1906.00264", "submitter": "Roi Livni", "authors": "Roi Livni and Yishay Mansour", "title": "Graph-based Discriminators: Sample Complexity and Expressiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic question in learning theory is to identify if two distributions are\nidentical when we have access only to examples sampled from the distributions.\nThis basic task is considered, for example, in the context of Generative\nAdversarial Networks (GANs), where a discriminator is trained to distinguish\nbetween a real-life distribution and a synthetic distribution. % Classically,\nwe use a hypothesis class $H$ and claim that the two distributions are distinct\nif for some $h\\in H$ the expected value on the two distributions is\n(significantly) different. Our starting point is the following fundamental\nproblem: \"is having the hypothesis dependent on more than a single random\nexample beneficial\". To address this challenge we define $k$-ary based\ndiscriminators, which have a family of Boolean $k$-ary functions $\\mathcal{G}$.\nEach function $g\\in \\mathcal{G}$ naturally defines a hyper-graph, indicating\nwhether a given hyper-edge exists. A function $g\\in \\mathcal{G}$ distinguishes\nbetween two distributions, if the expected value of $g$, on a $k$-tuple of\ni.i.d examples, on the two distributions is (significantly) different. We study\nthe expressiveness of families of $k$-ary functions, compared to the classical\nhypothesis class $H$, which is $k=1$. We show a separation in expressiveness of\n$k+1$-ary versus $k$-ary functions. This demonstrate the great benefit of\nhaving $k\\geq 2$ as distinguishers. For $k\\geq 2$ we introduce a notion similar\nto the VC-dimension, and show that it controls the sample complexity. We\nproceed and provide upper and lower bounds as a function of our extended notion\nof VC-dimension.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 18:28:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Livni", "Roi", ""], ["Mansour", "Yishay", ""]]}, {"id": "1906.00271", "submitter": "Harsh Shrivastava", "authors": "Harsh Shrivastava, Xinshi Chen, Binghong Chen, Guanghui Lan, Srinvas\n  Aluru, Han Liu, Le Song", "title": "GLAD: Learning Sparse Graph Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering sparse conditional independence graphs from data is a fundamental\nproblem in machine learning with wide applications. A popular formulation of\nthe problem is an $\\ell_1$ regularized maximum likelihood estimation. Many\nconvex optimization algorithms have been designed to solve this formulation to\nrecover the graph structure. Recently, there is a surge of interest to learn\nalgorithms directly based on data, and in this case, learn to map empirical\ncovariance to the sparse precision matrix. However, it is a challenging task in\nthis case, since the symmetric positive definiteness (SPD) and sparsity of the\nmatrix are not easy to enforce in learned algorithms, and a direct mapping from\ndata to precision matrix may contain many parameters. We propose a deep\nlearning architecture, GLAD, which uses an Alternating Minimization (AM)\nalgorithm as our model inductive bias, and learns the model parameters via\nsupervised learning. We show that GLAD learns a very compact and effective\nmodel for recovering sparse graphs from data.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 18:59:56 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:58:51 GMT"}, {"version": "v3", "created": "Sat, 21 Dec 2019 20:10:47 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Shrivastava", "Harsh", ""], ["Chen", "Xinshi", ""], ["Chen", "Binghong", ""], ["Lan", "Guanghui", ""], ["Aluru", "Srinvas", ""], ["Liu", "Han", ""], ["Song", "Le", ""]]}, {"id": "1906.00273", "submitter": "Erdem Varol", "authors": "Amin Nejatbakhsh, Erdem Varol", "title": "Robust approximate linear regression without correspondence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose methods for estimating correspondence between two point sets under\nthe presence of outliers in both the source and target sets. The proposed\nalgorithms expand upon the theory of the regression without correspondence\nproblem to estimate transformation coefficients using unordered multisets of\ncovariates and responses. Previous theoretical analysis of the problem has been\ndone in a setting where the responses are a complete permutation of the\nregressed covariates. This paper expands the problem setting by analyzing the\ncases where only a subset of the responses is a permutation of the regressed\ncovariates in addition to some covariates being outliers. We term this problem\n\\textit{robust regression without correspondence} and provide several\nalgorithms based on random sample consensus for exact and approximate recovery\nin a noiseless and noisy one-dimensional setting as well as an approximation\nalgorithm for multiple dimensions. The theoretical guarantees of the algorithms\nare verified in simulated data. We demonstrate an important computational\nneuroscience application of the proposed framework by demonstrating its\neffectiveness in a \\textit{Caenorhabditis elegans} neuron matching problem\nwhere the presence of outliers in both the source and target nematodes is a\nnatural tendency.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 19:15:39 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 03:20:56 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 20:41:26 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Nejatbakhsh", "Amin", ""], ["Varol", "Erdem", ""]]}, {"id": "1906.00282", "submitter": "Joel Mathew", "authors": "Joel Mathew, Shobeir Fakhraei, Jos\\'e Luis Ambite", "title": "Biomedical Named Entity Recognition via Reference-Set Augmented\n  Bootstrapping", "comments": "5 pages, 1 Figure, 2 Table, ICML 2019 Workshop on Computational\n  Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a weakly-supervised data augmentation approach to improve Named\nEntity Recognition (NER) in a challenging domain: extracting biomedical\nentities (e.g., proteins) from the scientific literature. First, we train a\nneural NER (NNER) model over a small seed of fully-labeled examples. Second, we\nuse a reference set of entity names (e.g., proteins in UniProt) to identify\nentity mentions with high precision, but low recall, on an unlabeled corpus.\nThird, we use the NNER model to assign weak labels to the corpus. Finally, we\nretrain our NNER model iteratively over the augmented training set, including\nthe seed, the reference-set examples, and the weakly-labeled examples, which\nimproves model performance. We show empirically that this augmented\nbootstrapping process significantly improves NER performance, and discuss the\nfactors impacting the efficacy of the approach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 20:07:11 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Mathew", "Joel", ""], ["Fakhraei", "Shobeir", ""], ["Ambite", "Jos\u00e9 Luis", ""]]}, {"id": "1906.00285", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Xiaojie Mao, Angela Zhou", "title": "Assessing Algorithmic Fairness with Unobserved Protected Class Using\n  Data Combination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing impact of algorithmic decisions on people's lives compels us\nto scrutinize their fairness and, in particular, the disparate impacts that\nostensibly-color-blind algorithms can have on different groups. Examples\ninclude credit decisioning, hiring, advertising, criminal justice, personalized\nmedicine, and targeted policymaking, where in some cases legislative or\nregulatory frameworks for fairness exist and define specific protected classes.\nIn this paper we study a fundamental challenge to assessing disparate impacts\nin practice: protected class membership is often not observed in the data. This\nis particularly a problem in lending and healthcare. We consider the use of an\nauxiliary dataset, such as the US census, to construct models that predict the\nprotected class from proxy variables, such as surname and geolocation. We show\nthat even with such data, a variety of common disparity measures are generally\nunidentifiable, providing a new perspective on the documented biases of popular\nproxy-based methods. We provide exact characterizations of the\ntightest-possible set of all possible true disparities that are consistent with\nthe data (and possibly any assumptions). We further provide optimization-based\nalgorithms for computing and visualizing these sets and statistical tools to\nassess sampling uncertainty. Together, these enable reliable and robust\nassessments of disparities -- an important tool when disparity assessment can\nhave far-reaching policy implications. We demonstrate this in two case studies\nwith real data: mortgage lending and personalized medicine dosing.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 20:32:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 09:56:39 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""], ["Zhou", "Angela", ""]]}, {"id": "1906.00290", "submitter": "Mahdi Jafari Siavoshani", "authors": "Saeed Masoudian, Ali Arabzadeh, Mahdi Jafari Siavoshani, Milad Jalal,\n  Alireza Amouzad", "title": "Adaptive Online Learning for Gradient-Based Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As application demands for online convex optimization accelerate, the need\nfor designing new methods that simultaneously cover a large class of convex\nfunctions and impose the lowest possible regret is highly rising. Known online\noptimization methods usually perform well only in specific settings, and their\nperformance depends highly on the geometry of the decision space and cost\nfunctions. However, in practice, lack of such geometric information leads to\nconfusion in using the appropriate algorithm. To address this issue, some\nadaptive methods have been proposed that focus on adaptively learning\nparameters such as step size, Lipschitz constant, and strong convexity\ncoefficient, or on specific parametric families such as quadratic regularizers.\nIn this work, we generalize these methods and propose a framework that competes\nwith the best algorithm in a family of expert algorithms. Our framework\nincludes many of the well-known adaptive methods including MetaGrad,\nMetaGrad+C, and Ader. We also introduce a second algorithm that computationally\noutperforms our first algorithm with at most a constant factor increase in\nregret. Finally, as a representative application of our proposed algorithm, we\nstudy the problem of learning the best regularizer from a family of\nregularizers for Online Mirror Descent. Empirically, we support our theoretical\nfindings in the problem of learning the best regularizer on the simplex and\n$l_2$-ball in a multiclass learning problem.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:04:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Masoudian", "Saeed", ""], ["Arabzadeh", "Ali", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Jalal", "Milad", ""], ["Amouzad", "Alireza", ""]]}, {"id": "1906.00291", "submitter": "Harsh Shrivastava", "authors": "Harsh Shrivastava, Eugene Bart, Bob Price, Hanjun Dai, Bo Dai,\n  Srinivas Aluru", "title": "Cooperative neural networks (CoNN): Exploiting prior independence\n  structure for improved classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach, called cooperative neural networks (CoNN), which\nuses a set of cooperatively trained neural networks to capture latent\nrepresentations that exploit prior given independence structure. The model is\nmore flexible than traditional graphical models based on exponential family\ndistributions, but incorporates more domain specific prior structure than\ntraditional deep networks or variational autoencoders. The framework is very\ngeneral and can be used to exploit the independence structure of any graphical\nmodel. We illustrate the technique by showing that we can transfer the\nindependence structure of the popular Latent Dirichlet Allocation (LDA) model\nto a cooperative neural network, CoNN-sLDA. Empirical evaluation of CoNN-sLDA\non supervised text classification tasks demonstrates that the theoretical\nadvantages of prior independence structure can be realized in practice -we\ndemonstrate a 23\\% reduction in error on the challenging MultiSent data set\ncompared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:09:28 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shrivastava", "Harsh", ""], ["Bart", "Eugene", ""], ["Price", "Bob", ""], ["Dai", "Hanjun", ""], ["Dai", "Bo", ""], ["Aluru", "Srinivas", ""]]}, {"id": "1906.00294", "submitter": "Robert Busa-Fekete", "authors": "Robert Busa-Fekete, Krzysztof Dembczynski, Alexander Golovnev, Kalina\n  Jasinska, Mikhail Kuznetsov, Maxim Sviridenko and Chao Xu", "title": "On the computational complexity of the probabilistic label tree\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label tree-based algorithms are widely used to tackle multi-class and\nmulti-label problems with a large number of labels. We focus on a particular\nsubclass of these algorithms that use probabilistic classifiers in the tree\nnodes. Examples of such algorithms are hierarchical softmax (HSM), designed for\nmulti-class classification, and probabilistic label trees (PLTs) that\ngeneralize HSM to multi-label problems. If the tree structure is given,\nlearning of PLT can be solved with provable regret guaranties [Wydmuch et.al.\n2018]. However, to find a tree structure that results in a PLT with a low\ntraining and prediction computational costs as well as low statistical error\nseems to be a very challenging problem, not well-understood yet.\n  In this paper, we address the problem of finding a tree structure that has\nlow computational cost. First, we show that finding a tree with optimal\ntraining cost is NP-complete, nevertheless there are some tractable special\ncases with either perfect approximation or exact solution that can be obtained\nin linear time in terms of the number of labels $m$. For the general case, we\nobtain $O(\\log m)$ approximation in linear time too. Moreover, we prove an\nupper bound on the expected prediction cost expressed in terms of the expected\ntraining cost. We also show that under additional assumptions the prediction\ncost of a PLT is $O(\\log m)$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:27:36 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Busa-Fekete", "Robert", ""], ["Dembczynski", "Krzysztof", ""], ["Golovnev", "Alexander", ""], ["Jasinska", "Kalina", ""], ["Kuznetsov", "Mikhail", ""], ["Sviridenko", "Maxim", ""], ["Xu", "Chao", ""]]}, {"id": "1906.00297", "submitter": "Kurtis Evan David", "authors": "Kurtis Evan David, Harrison Keane, Jun Min Noh", "title": "GANchors: Realistic Image Perturbation Distributions for Anchors Using\n  Generative Models", "comments": "Final project for the Fair and Transparent Machine Learning course at\n  UT Austin -- taught by Dr. Joydeep Ghosh", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend and improve the work of Model Agnostic Anchors for explanations on\nimage classification through the use of generative adversarial networks (GANs).\nUsing GANs, we generate samples from a more realistic perturbation\ndistribution, by optimizing under a lower dimensional latent space. This\nincreases the trust in an explanation, as results now come from images that are\nmore likely to be found in the original training set of a classifier, rather\nthan an overlay of random images. A large drawback to our method is the\ncomputational complexity of sampling through optimization; to address this, we\nimplement more efficient algorithms, including a diverse encoder. Lastly, we\nshare results from the MNIST and CelebA datasets, and note that our\nexplanations can lead to smaller and higher precision anchors.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:43:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["David", "Kurtis Evan", ""], ["Keane", "Harrison", ""], ["Noh", "Jun Min", ""]]}, {"id": "1906.00299", "submitter": "Wentao Wu", "authors": "Frances Ann Hubis, Wentao Wu, Ce Zhang", "title": "Quantitative Overfitting Management for Human-in-the-loop ML Application\n  Development with ease.ml/meter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplifying machine learning (ML) application development, including\ndistributed computation, programming interface, resource management, model\nselection, etc, has attracted intensive interests recently. These research\nefforts have significantly improved the efficiency and the degree of automation\nof developing ML models. In this paper, we take a first step in an orthogonal\ndirection towards automated quality management for human-in-the-loop ML\napplication development. We build ease. ml/meter, a system that can\nautomatically detect and measure the degree of overfitting during the whole\nlifecycle of ML application development. ease. ml/meter returns overfitting\nsignals with strong probabilistic guarantees, based on which developers can\ntake appropriate actions. In particular, ease. ml/meter provides principled\nguidelines to simple yet nontrivial questions regarding desired validation and\ntest data sizes, which are among commonest questions raised by developers. The\nfact that ML application development is typically a continuous procedure\nfurther worsens the situation: The validation and test data sets can lose their\nstatistical power quickly due to multiple accesses, especially in the presence\nof adaptive analysis. ease. ml/meter addresses these challenges by leveraging a\ncollection of novel techniques and optimizations, resulting in practically\ntractable data sizes without compromising the probabilistic guarantees. We\npresent the design and implementation details of ease. ml/meter, as well as\ndetailed theoretical analysis and empirical evaluation of its effectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:54:05 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 04:47:26 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 03:58:36 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Hubis", "Frances Ann", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "1906.00302", "submitter": "Yifan Sun", "authors": "Yifan Sun, Yaqi Duan, Hao Gong and Mengdi Wang", "title": "Learning low-dimensional state embeddings and metastable clusters from\n  time series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to find compact state embeddings from high-dimensional\nMarkov state trajectories, where the transition kernel has a small intrinsic\nrank. In the spirit of diffusion map, we propose an efficient method for\nlearning a low-dimensional state embedding and capturing the process's\ndynamics. This idea also leads to a kernel reshaping method for more accurate\nnonparametric estimation of the transition function. State embedding can be\nused to cluster states into metastable sets, thereby identifying the slow\ndynamics. Sharp statistical error bounds and misclassification rate are proved.\nExperiment on a simulated dynamical system shows that the state clustering\nmethod indeed reveals metastable structures. We also experiment with time\nseries generated by layers of a Deep-Q-Network when playing an Atari game. The\nembedding method identifies game states to be similar if they share similar\nfuture events, even though their raw data are far different.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 22:20:59 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 18:03:10 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sun", "Yifan", ""], ["Duan", "Yaqi", ""], ["Gong", "Hao", ""], ["Wang", "Mengdi", ""]]}, {"id": "1906.00303", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Mohammad Ghavamzadeh and Tara Javidi", "title": "Active Learning for Binary Classification with Abstention", "comments": "42 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct and analyze active learning algorithms for the problem of binary\nclassification with abstention. We consider three abstention settings:\n\\emph{fixed-cost} and two variants of \\emph{bounded-rate} abstention, and for\neach of them propose an active learning algorithm. All the proposed algorithms\ncan work in the most commonly used active learning models, i.e.,\n\\emph{membership-query}, \\emph{pool-based}, and \\emph{stream-based} sampling.\nWe obtain upper-bounds on the excess risk of our algorithms in a general\nnon-parametric framework and establish their minimax near-optimality by\nderiving matching lower-bounds. Since our algorithms rely on the knowledge of\nsome smoothness parameters of the regression function, we then describe a new\nstrategy to adapt to these unknown parameters in a data-driven manner. Since\nthe worst case computational complexity of our proposed algorithms increases\nexponentially with the dimension of the input space, we conclude the paper with\na computationally efficient variant of our algorithm whose computational\ncomplexity has a polynomial dependence over a smaller but rich class of\nlearning problems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 22:23:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Ghavamzadeh", "Mohammad", ""], ["Javidi", "Tara", ""]]}, {"id": "1906.00313", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Kristjan Greenewald, Farzaneh Mirzazadeh", "title": "BreGMN: scaled-Bregman Generative Modeling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of f-divergences is ubiquitously applied to generative modeling in\norder to adapt the distribution of the model to that of the data.\nWell-definedness of f-divergences, however, requires the distributions of the\ndata and model to overlap completely in every time step of training. As a\nresult, as soon as the support of distributions of data and model contain\nnon-overlapping portions, gradient based training of the corresponding model\nbecomes hopeless. Recent advances in generative modeling are full of remedies\nfor handling this support mismatch problem: key ideas include either modifying\nthe objective function to integral probability measures (IPMs) that are\nwell-behaved even on disjoint probabilities, or optimizing a well-behaved\nvariational lower bound instead of the true objective. We, on the other hand,\nestablish that a complete change of the objective function is unnecessary, and\ninstead an augmentation of the base measure of the problematic divergence can\nresolve the issue. Based on this observation, we propose a generative model\nwhich leverages the class of Scaled Bregman Divergences and generalizes both\nf-divergences and Bregman divergences. We analyze this class of divergences and\nshow that with the appropriate choice of base measure it can resolve the\nsupport mismatch problem and incorporate geometric information. Finally, we\nstudy the performance of the proposed method and demonstrate promising results\non MNIST, CelebA and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 23:58:41 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Srivastava", "Akash", ""], ["Greenewald", "Kristjan", ""], ["Mirzazadeh", "Farzaneh", ""]]}, {"id": "1906.00325", "submitter": "Andrew Ferguson", "authors": "Wei Chen, Hythem Sidky, and Andrew L. Ferguson", "title": "Capabilities and Limitations of Time-lagged Autoencoders for Slow Mode\n  Discovery in Dynamical Systems", "comments": null, "journal-ref": null, "doi": "10.1063/1.5112048", "report-no": null, "categories": "stat.ML cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-lagged autoencoders (TAEs) have been proposed as a deep learning\nregression-based approach to the discovery of slow modes in dynamical systems.\nHowever, a rigorous analysis of nonlinear TAEs remains lacking. In this work,\nwe discuss the capabilities and limitations of TAEs through both theoretical\nand numerical analyses. Theoretically, we derive bounds for nonlinear TAE\nperformance in slow mode discovery and show that in general TAEs learn a\nmixture of slow and maximum variance modes. Numerically, we illustrate cases\nwhere TAEs can and cannot correctly identify the leading slowest mode in two\nexample systems: a 2D \"Washington beltway\" potential and the alanine dipeptide\nmolecule in explicit water. We also compare the TAE results with those obtained\nusing state-free reversible VAMPnets (SRVs) as a variational-based neural\nnetwork approach for slow modes discovery, and show that SRVs can correctly\ndiscover slow modes where TAEs fail.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 02:15:34 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chen", "Wei", ""], ["Sidky", "Hythem", ""], ["Ferguson", "Andrew L.", ""]]}, {"id": "1906.00331", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Chi Jin, Michael I. Jordan", "title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems", "comments": "Accepted by ICML 2020; Improve the writing and fix some confusing\n  parts in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonconvex-concave minimax problems, $\\min_{\\mathbf{x}}\n\\max_{\\mathbf{y} \\in \\mathcal{Y}} f(\\mathbf{x}, \\mathbf{y})$, where $f$ is\nnonconvex in $\\mathbf{x}$ but concave in $\\mathbf{y}$ and $\\mathcal{Y}$ is a\nconvex and bounded set. One of the most popular algorithms for solving this\nproblem is the celebrated gradient descent ascent (GDA) algorithm, which has\nbeen widely used in machine learning, control theory and economics. Despite the\nextensive convergence results for the convex-concave setting, GDA with equal\nstepsize can converge to limit cycles or even diverge in a general setting. In\nthis paper, we present the complexity results on two-time-scale GDA for solving\nnonconvex-concave minimax problems, showing that the algorithm can find a\nstationary point of the function $\\Phi(\\cdot) := \\max_{\\mathbf{y} \\in\n\\mathcal{Y}} f(\\cdot, \\mathbf{y})$ efficiently. To the best our knowledge, this\nis the first nonasymptotic analysis for two-time-scale GDA in this setting,\nshedding light on its superior practical performance in training generative\nadversarial networks (GANs) and other real applications.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 03:03:45 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 06:25:26 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 16:52:30 GMT"}, {"version": "v4", "created": "Thu, 6 Feb 2020 08:00:58 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 05:23:46 GMT"}, {"version": "v6", "created": "Mon, 15 Jun 2020 22:59:55 GMT"}, {"version": "v7", "created": "Mon, 26 Jul 2021 17:46:41 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Tianyi", ""], ["Jin", "Chi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.00336", "submitter": "Xingyou Song", "authors": "Alex Irpan, Xingyou Song", "title": "The Principle of Unchanged Optimality in Reinforcement Learning\n  Generalization", "comments": "Published at ICML 2019 Workshop \"Understanding and Improving\n  Generalization in Deep Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent papers have examined generalization in reinforcement learning\n(RL), by proposing new environments or ways to add noise to existing\nenvironments, then benchmarking algorithms and model architectures on those\nenvironments. We discuss subtle conceptual properties of RL benchmarks that are\nnot required in supervised learning (SL), and also properties that an RL\nbenchmark should possess. Chief among them is one we call the principle of\nunchanged optimality: there should exist a single $\\pi$ that is optimal across\nall train and test tasks. In this work, we argue why this principle is\nimportant, and ways it can be broken or satisfied due to subtle choices in\nstate representation or model architecture. We conclude by discussing\nchallenges and future lines of research in theoretically analyzing\ngeneralization benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 03:52:28 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Irpan", "Alex", ""], ["Song", "Xingyou", ""]]}, {"id": "1906.00350", "submitter": "Yehong Liu", "authors": "Yehong Liu, Guosheng Yin", "title": "Nonparametric Functional Approximation with Delaunay Triangulation", "comments": "28 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a differentiable nonparametric algorithm, the Delaunay\ntriangulation learner (DTL), to solve the functional approximation problem on\nthe basis of a $p$-dimensional feature space. By conducting the Delaunay\ntriangulation algorithm on the data points, the DTL partitions the feature\nspace into a series of $p$-dimensional simplices in a geometrically optimal\nway, and fits a linear model within each simplex. We study its theoretical\nproperties by exploring the geometric properties of the Delaunay triangulation,\nand compare its performance with other statistical learners in numerical\nstudies.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 05:56:21 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liu", "Yehong", ""], ["Yin", "Guosheng", ""]]}, {"id": "1906.00355", "submitter": "Xiang Ren", "authors": "Yozen Liu, Xiaolin Shi, Lucas Pierce, Xiang Ren", "title": "Characterizing and Forecasting User Engagement with In-app Action Graph:\n  A Case Study of Snapchat", "comments": "9 pages. Accepted to KDD 2019 Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While mobile social apps have become increasingly important in people's daily\nlife, we have limited understanding on what motivates users to engage with\nthese apps. In this paper, we answer the question whether users' in-app\nactivity patterns help inform their future app engagement (e.g., active days in\na future time window)? Previous studies on predicting user app engagement\nmainly focus on various macroscopic features (e.g., time-series of activity\nfrequency), while ignoring fine-grained inter-dependencies between different\nin-app actions at the microscopic level. Here we propose to formalize\nindividual user's in-app action transition patterns as a temporally evolving\naction graph, and analyze its characteristics in terms of informing future user\nengagement. Our analysis suggested that action graphs are able to characterize\nuser behavior patterns and inform future engagement. We derive a number of\nhigh-order graph features to capture in-app usage patterns and construct\ninterpretable models for predicting trends of engagement changes and active\nrates. To further enhance predictive power, we design an end-to-end,\nmulti-channel neural model to encode temporal action graphs, activity\nsequences, and other macroscopic features. Experiments on predicting user\nengagement for 150k Snapchat new users over a 28-day period demonstrate the\neffectiveness of the proposed models. The prediction framework is deployed at\nSnapchat to deliver real world business insights. Our proposed framework is\nalso general and can be applied to other social app platforms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 06:59:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liu", "Yozen", ""], ["Shi", "Xiaolin", ""], ["Pierce", "Lucas", ""], ["Ren", "Xiang", ""]]}, {"id": "1906.00389", "submitter": "Bogdan Kulynych", "authors": "Mohammad Yaghini, Bogdan Kulynych, Giovanni Cherubin, Carmela Troncoso", "title": "Disparate Vulnerability: on the Unfairness of Privacy Attacks Against\n  Machine Learning", "comments": "Mohammad Yaghini and Bogdan Kulynych contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A membership inference attack (MIA) against a machine learning model enables\nan attacker to determine whether a given data record was part of the model's\ntraining data or not. The effectiveness of these attacks is reported using\nmetrics computed across the whole population (e.g., average attack accuracy).\nIn this paper, we show that the attack success varies across different\nsubgroups of the data (e.g., race, gender), i.e., there is \\emph{disparate\nvulnerability}. Even if MIA's success looks no better than random guessing over\nthe whole population, subgroups can still be vulnerable. We study the necessary\nand sufficient conditions for a classifier to exhibit disparate vulnerability,\nand we determine to what extent certain learning techniques (e.g., fairness\nconstraints, differential privacy) can prevent it. Our work provides a\ntheoretical framework for studying MIA attacks from a new perspective.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 11:37:00 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 12:33:38 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Yaghini", "Mohammad", ""], ["Kulynych", "Bogdan", ""], ["Cherubin", "Giovanni", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1906.00391", "submitter": "Zhengxiao Du", "authors": "Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, Jie Tang", "title": "Sequential Scenario-Specific Meta Learner for Online Recommendation", "comments": "Accepted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold-start problems are long-standing challenges for practical\nrecommendations. Most existing recommendation algorithms rely on extensive\nobserved data and are brittle to recommendation scenarios with few\ninteractions. This paper addresses such problems using few-shot learning and\nmeta learning. Our approach is based on the insight that having a good\ngeneralization from a few examples relies on both a generic model\ninitialization and an effective strategy for adapting this model to newly\narising tasks. To accomplish this, we combine the scenario-specific learning\nwith a model-agnostic sequential meta-learning and unify them into an\nintegrated end-to-end framework, namely Scenario-specific Sequential Meta\nlearner (or s^2 meta). By doing so, our meta-learner produces a generic initial\nmodel through aggregating contextual information from a variety of prediction\ntasks while effectively adapting to specific tasks by leveraging\nlearning-to-learn knowledge. Extensive experiments on various real-world\ndatasets demonstrate that our proposed model can achieve significant gains over\nthe state-of-the-arts for cold-start problems in online recommendation.\nDeployment is at the Guess You Like session, the front page of the Mobile\nTaobao.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 11:53:19 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Du", "Zhengxiao", ""], ["Wang", "Xiaowei", ""], ["Yang", "Hongxia", ""], ["Zhou", "Jingren", ""], ["Tang", "Jie", ""]]}, {"id": "1906.00398", "submitter": "Lei Tong", "authors": "Lei Tong, Zhihua Liu, Zheheng Jiang, Feixiang Zhou, Long Chen, Jialin\n  Lyu, Xiangrong Zhang, Qianni Zhang, Abdul Sadka Senior, Yinhai Wang, Ling Li\n  and Huiyu Zhou", "title": "Cost-sensitive Boosting Pruning Trees for depression detection on\n  Twitter", "comments": "12 pages, 7 figures, submitted to IEEE transactions on Affective\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is one of the most common mental health disorders, and a large\nnumber of depressed people commit suicide each year. Potential depression\nsufferers usually do not consult psychological doctors because they feel\nashamed or are unaware of any depression, which may result in severe delay of\ndiagnosis and treatment. In the meantime, evidence shows that social media data\nprovides valuable clues about physical and mental health conditions. In this\npaper, we argue that it is feasible to identify depression at an early stage by\nmining online social behaviours. Our approach, which is innovative to the\npractice of depression detection, does not rely on the extraction of numerous\nor complicated features to achieve accurate depression detection. Instead, we\npropose a novel classifier, namely, Cost-sensitive Boosting Pruning Trees\n(CBPT), which demonstrates a strong classification ability on two publicly\naccessible Twitter depression detection datasets. To comprehensively evaluate\nthe classification capability of the CBPT, we use additional three datasets\nfrom the UCI machine learning repository and the CBPT obtains appealing\nclassification results against several state of the arts boosting algorithms.\nFinally, we comprehensively explore the influence factors of model prediction,\nand the results manifest that our proposed framework is promising for\nidentifying Twitter users with depression.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 13:11:26 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 14:38:29 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tong", "Lei", ""], ["Liu", "Zhihua", ""], ["Jiang", "Zheheng", ""], ["Zhou", "Feixiang", ""], ["Chen", "Long", ""], ["Lyu", "Jialin", ""], ["Zhang", "Xiangrong", ""], ["Zhang", "Qianni", ""], ["Senior", "Abdul Sadka", ""], ["Wang", "Yinhai", ""], ["Li", "Ling", ""], ["Zhou", "Huiyu", ""]]}, {"id": "1906.00410", "submitter": "Melissa Mozifian", "authors": "Melissa Mozifian, Juan Camilo Gamboa Higuera, David Meger, Gregory\n  Dudek", "title": "Learning Domain Randomization Distributions for Training Robust\n  Locomotion Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain randomization (DR) is a successful technique for learning robust\npolicies for robot systems, when the dynamics of the target robot system are\nunknown. The success of policies trained with domain randomization however, is\nhighly dependent on the correct selection of the randomization distribution.\nThe majority of success stories typically use real world data in order to\ncarefully select the DR distribution, or incorporate real world trajectories to\nbetter estimate appropriate randomization distributions. In this paper, we\nconsider the problem of finding good domain randomization parameters for\nsimulation, without prior access to data from the target system. We explore the\nuse of gradient-based search methods to learn a domain randomization with the\nfollowing properties: 1) The trained policy should be successful in\nenvironments sampled from the domain randomization distribution 2) The domain\nrandomization distribution should be wide enough so that the experience similar\nto the target robot system is observed during training, while addressing the\npracticality of training finite capacity models. These two properties aim to\nensure the trajectories encountered in the target system are close to those\nobserved during training, as existing methods in machine learning are better\nsuited for interpolation than extrapolation. We show how adapting the domain\nrandomization distribution while training context-conditioned policies results\nin improvements on jump-start and asymptotic performance when transferring a\nlearned policy to the target environment.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 14:07:23 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 18:33:42 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Mozifian", "Melissa", ""], ["Higuera", "Juan Camilo Gamboa", ""], ["Meger", "David", ""], ["Dudek", "Gregory", ""]]}, {"id": "1906.00422", "submitter": "Abi Komanduru", "authors": "Abi Komanduru, Jean Honorio", "title": "On the Correctness and Sample Complexity of Inverse Reinforcement\n  Learning", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) is the problem of finding a reward\nfunction that generates a given optimal policy for a given Markov Decision\nProcess. This paper looks at an algorithmic-independent geometric analysis of\nthe IRL problem with finite states and actions. A L1-regularized Support Vector\nMachine formulation of the IRL problem motivated by the geometric analysis is\nthen proposed with the basic objective of the inverse reinforcement problem in\nmind: to find a reward function that generates a specified optimal policy. The\npaper further analyzes the proposed formulation of inverse reinforcement\nlearning with $n$ states and $k$ actions, and shows a sample complexity of\n$O(n^2 \\log (nk))$ for recovering a reward function that generates a policy\nthat satisfies Bellman's optimality condition with respect to the true\ntransition probabilities.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:22:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Komanduru", "Abi", ""], ["Honorio", "Jean", ""]]}, {"id": "1906.00423", "submitter": "Zeyu Jia", "authors": "Zeyu Jia, Lin F. Yang, Mengdi Wang", "title": "Feature-Based Q-Learning for Two-Player Stochastic Games", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a two-player zero-sum stochastic game where the transition function\ncan be embedded in a given feature space. We propose a two-player Q-learning\nalgorithm for approximating the Nash equilibrium strategy via sampling. The\nalgorithm is shown to find an $\\epsilon$-optimal strategy using sample size\nlinear to the number of features. To further improve its sample efficiency, we\ndevelop an accelerated algorithm by adopting techniques such as variance\nreduction, monotonicity preservation and two-sided strategy approximation. We\nprove that the algorithm is guaranteed to find an $\\epsilon$-optimal strategy\nusing no more than $\\tilde{\\mathcal{O}}(K/(\\epsilon^{2}(1-\\gamma)^{4}))$\nsamples with high probability, where $K$ is the number of features and $\\gamma$\nis a discount factor. The sample, time and space complexities of the algorithm\nare independent of original dimensions of the game.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:24:19 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jia", "Zeyu", ""], ["Yang", "Lin F.", ""], ["Wang", "Mengdi", ""]]}, {"id": "1906.00425", "submitter": "Ronen Basri", "authors": "Ronen Basri, David Jacobs, Yoni Kasten, Shira Kritchman", "title": "The Convergence Rate of Neural Networks for Learned Functions of\n  Different Frequencies", "comments": null, "journal-ref": "in Advances in Neural Information Processing Systems 32 (NIPS\n  2019)", "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between the frequency of a function and the speed\nat which a neural network learns it. We build on recent results that show that\nthe dynamics of overparameterized neural networks trained with gradient descent\ncan be well approximated by a linear system. When normalized training data is\nuniformly distributed on a hypersphere, the eigenfunctions of this linear\nsystem are spherical harmonic functions. We derive the corresponding\neigenvalues for each frequency after introducing a bias term in the model. This\nbias term had been omitted from the linear network model without significantly\naffecting previous theoretical results. However, we show theoretically and\nexperimentally that a shallow neural network without bias cannot represent or\nlearn simple, low frequency functions with odd frequencies. Our results lead to\nspecific predictions of the time it will take a network to learn functions of\nvarying frequency. These predictions match the empirical behavior of both\nshallow and deep networks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:28:28 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 14:24:32 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 15:28:58 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Basri", "Ronen", ""], ["Jacobs", "David", ""], ["Kasten", "Yoni", ""], ["Kritchman", "Shira", ""]]}, {"id": "1906.00429", "submitter": "Sebastian Tschiatschek", "authors": "Sebastian Tschiatschek, Ahana Ghosh, Luis Haug, Rati Devidze, Adish\n  Singla", "title": "Learner-aware Teaching: Inverse Reinforcement Learning with Preferences\n  and Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) enables an agent to learn complex\nbehavior by observing demonstrations from a (near-)optimal policy. The typical\nassumption is that the learner's goal is to match the teacher's demonstrated\nbehavior. In this paper, we consider the setting where the learner has its own\npreferences that it additionally takes into consideration. These preferences\ncan for example capture behavioral biases, mismatched worldviews, or physical\nconstraints. We study two teaching approaches: learner-agnostic teaching, where\nthe teacher provides demonstrations from an optimal policy ignoring the\nlearner's preferences, and learner-aware teaching, where the teacher accounts\nfor the learner's preferences. We design learner-aware teaching algorithms and\nshow that significant performance improvements can be achieved over\nlearner-agnostic teaching.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:51:35 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:10:09 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Tschiatschek", "Sebastian", ""], ["Ghosh", "Ahana", ""], ["Haug", "Luis", ""], ["Devidze", "Rati", ""], ["Singla", "Adish", ""]]}, {"id": "1906.00431", "submitter": "Xingyou Song", "authors": "Xingyou Song, Yilun Du, Jacob Jackson", "title": "An Empirical Study on Hyperparameters and their Interdependence for RL\n  Generalization", "comments": "Published in ICML 2019 Workshop \"Understanding and Improving\n  Generalization in Deep Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in Reinforcement Learning (RL) have shown that agents with\nlimited training environments are susceptible to a large amount of overfitting\nacross many domains. A key challenge for RL generalization is to quantitatively\nexplain the effects of changing parameters on testing performance. Such\nparameters include architecture, regularization, and RL-dependent variables\nsuch as discount factor and action stochasticity. We provide empirical results\nthat show complex and interdependent relationships between hyperparameters and\ngeneralization. We further show that several empirical metrics such as gradient\ncosine similarity and trajectory-dependent metrics serve to provide intuition\ntowards these results.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:01:17 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Song", "Xingyou", ""], ["Du", "Yilun", ""], ["Jackson", "Jacob", ""]]}, {"id": "1906.00436", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas and Michael I. Jordan", "title": "Generalized Momentum-Based Methods: A Hamiltonian Perspective", "comments": "To appear in SIAM Journal on Optimization. v1 -> v2: minor edits +\n  added funding acknowledgements, v2 -> v3: revised presentation, upon journal\n  revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a Hamiltonian-based perspective to generalize Nesterov's accelerated\ngradient descent and Polyak's heavy ball method to a broad class of momentum\nmethods in the setting of (possibly) constrained minimization in Euclidean and\nnon-Euclidean normed vector spaces. Our perspective leads to a generic and\nunifying nonasymptotic analysis of convergence of these methods in both the\nfunction value (in the setting of convex optimization) and in norm of the\ngradient (in the setting of unconstrained, possibly nonconvex, optimization).\nOur approach relies upon a time-varying Hamiltonian that produces generalized\nmomentum methods as its equations of motion. The convergence analysis for these\nmethods is intuitive and is based on the conserved quantities of the\ntime-dependent Hamiltonian.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:24:08 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 21:06:42 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 20:08:00 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.00442", "submitter": "Yishai Shimoni", "authors": "Yishai Shimoni, Ehud Karavani, Sivan Ravid, Peter Bak, Tan Hung Ng,\n  Sharon Hensley Alford, Denise Meade and Yaara Goldschmidt", "title": "An Evaluation Toolkit to Guide Model Selection and Cohort Definition in\n  Causal Inference", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Real world observational data, together with causal inference, allow the\nestimation of causal effects when randomized controlled trials are not\navailable. To be accepted into practice, such predictive models must be\nvalidated for the dataset at hand, and thus require a comprehensive evaluation\ntoolkit, as introduced here. Since effect estimation cannot be evaluated\ndirectly, we turn to evaluating the various observable properties of causal\ninference, namely the observed outcome and treatment assignment. We developed a\ntoolkit that expands established machine learning evaluation methods and adds\nseveral causal-specific ones. Evaluations can be applied in cross-validation,\nin a train-test scheme, or on the training data. Multiple causal inference\nmethods are implemented within the toolkit in a way that allows modular use of\nthe underlying machine learning models. Thus, the toolkit is agnostic to the\nmachine learning model that is used. We showcase our approach using a\nrheumatoid arthritis cohort (consisting of about 120K patients) extracted from\nthe IBM MarketScan(R) Research Database. We introduce an iterative pipeline of\ndata definition, model definition, and model evaluation. Using this pipeline,\nwe demonstrate how each of the evaluation components helps drive model\nselection and refinement of data extraction criteria in a way that provides\nmore reproducible results and ensures that the causal question is answerable\nwith available data. Furthermore, we show how the evaluation toolkit can be\nused to ensure that performance is maintained when applied to subsets of the\ndata, thus allowing exploration of questions that move towards personalized\nmedicine.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:36:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shimoni", "Yishai", ""], ["Karavani", "Ehud", ""], ["Ravid", "Sivan", ""], ["Bak", "Peter", ""], ["Ng", "Tan Hung", ""], ["Alford", "Sharon Hensley", ""], ["Meade", "Denise", ""], ["Goldschmidt", "Yaara", ""]]}, {"id": "1906.00443", "submitter": "Matthew Farrell", "authors": "Stefano Recanatesi, Matthew Farrell, Madhu Advani, Timothy Moore,\n  Guillaume Lajoie and Eric Shea-Brown", "title": "Dimensionality compression and expansion in Deep Neural Networks", "comments": "Submitted to NeurIPS 2019. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets such as images, text, or movies are embedded in high-dimensional\nspaces. However, in important cases such as images of objects, the statistical\nstructure in the data constrains samples to a manifold of dramatically lower\ndimensionality. Learning to identify and extract task-relevant variables from\nthis embedded manifold is crucial when dealing with high-dimensional problems.\nWe find that neural networks are often very effective at solving this task and\ninvestigate why. To this end, we apply state-of-the-art techniques for\nintrinsic dimensionality estimation to show that neural networks learn\nlow-dimensional manifolds in two phases: first, dimensionality expansion driven\nby feature generation in initial layers, and second, dimensionality compression\ndriven by the selection of task-relevant features in later layers. We model\nnoise generated by Stochastic Gradient Descent and show how this noise balances\nthe dimensionality of neural representations by inducing an effective\nregularization term in the loss. We highlight the important relationship\nbetween low-dimensional compressed representations and generalization\nproperties of the network. Our work contributes by shedding light on the\nsuccess of deep neural networks in disentangling data in high-dimensional space\nwhile achieving good generalization. Furthermore, it invites new learning\nstrategies focused on optimizing measurable geometric properties of learned\nrepresentations, beginning with their intrinsic dimensionality.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:42:20 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 23:38:33 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 15:59:58 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Recanatesi", "Stefano", ""], ["Farrell", "Matthew", ""], ["Advani", "Madhu", ""], ["Moore", "Timothy", ""], ["Lajoie", "Guillaume", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1906.00446", "submitter": "A\\\"aron van den Oord", "authors": "Ali Razavi, Aaron van den Oord, Oriol Vinyals", "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE)\nmodels for large scale image generation. To this end, we scale and enhance the\nautoregressive priors used in VQ-VAE to generate synthetic samples of much\nhigher coherence and fidelity than possible before. We use simple feed-forward\nencoder and decoder networks, making our model an attractive candidate for\napplications where the encoding and/or decoding speed is critical.\nAdditionally, VQ-VAE requires sampling an autoregressive model only in the\ncompressed latent space, which is an order of magnitude faster than sampling in\nthe pixel space, especially for large images. We demonstrate that a multi-scale\nhierarchical organization of VQ-VAE, augmented with powerful priors over the\nlatent codes, is able to generate samples with quality that rivals that of\nstate of the art Generative Adversarial Networks on multifaceted datasets such\nas ImageNet, while not suffering from GAN's known shortcomings such as mode\ncollapse and lack of diversity.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:46:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Razavi", "Ali", ""], ["Oord", "Aaron van den", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1906.00449", "submitter": "Kevin Bello", "authors": "Kevin Bello and Asish Ghoshal and Jean Honorio", "title": "Minimax bounds for structured prediction", "comments": null, "journal-ref": "Artificial Intelligence and Statistics (AISTATS), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction can be considered as a generalization of many standard\nsupervised learning tasks, and is usually thought as a simultaneous prediction\nof multiple labels. One standard approach is to maximize a score function on\nthe space of labels, which decomposes as a sum of unary and pairwise\npotentials, each depending on one or two specific labels, respectively. For\nthis approach, several learning and inference algorithms have been proposed\nover the years, ranging from exact to approximate methods while balancing the\ncomputational complexity. However, in contrast to binary and multiclass\nclassification, results on the necessary number of samples for achieving\nlearning is still limited, even for a specific family of predictors such as\nfactor graphs. In this work, we provide minimax bounds for a class of\nfactor-graph inference models for structured prediction. That is, we\ncharacterize the necessary sample complexity for any conceivable algorithm to\nachieve learning of factor-graph predictors.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:54:25 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Bello", "Kevin", ""], ["Ghoshal", "Asish", ""], ["Honorio", "Jean", ""]]}, {"id": "1906.00451", "submitter": "Kevin Bello", "authors": "Kevin Bello and Jean Honorio", "title": "Exact inference in structured prediction", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction can be thought of as a simultaneous prediction of\nmultiple labels. This is often done by maximizing a score function on the space\nof labels, which decomposes as a sum of pairwise and unary potentials. The\nabove is naturally modeled with a graph, where edges and vertices are related\nto pairwise and unary potentials, respectively. We consider the generative\nprocess proposed by Globerson et al. and apply it to general connected graphs.\nWe analyze the structural conditions of the graph that allow for the exact\nrecovery of the labels. Our results show that exact recovery is possible and\nachievable in polynomial time for a large class of graphs. In particular, we\nshow that graphs that are bad expanders can be exactly recovered by adding\nsmall edge perturbations coming from the Erd\\H{o}s-R\\'enyi model. Finally, as a\nbyproduct of our analysis, we provide an extension of Cheeger's inequality.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 17:03:02 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Bello", "Kevin", ""], ["Honorio", "Jean", ""]]}, {"id": "1906.00452", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski", "title": "Radial-Based Undersampling for Imbalanced Data Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data imbalance remains one of the most widespread problems affecting\ncontemporary machine learning. The negative effect data imbalance can have on\nthe traditional learning algorithms is most severe in combination with other\ndataset difficulty factors, such as small disjuncts, presence of outliers and\ninsufficient number of training observations. Aforementioned difficulty factors\ncan also limit the applicability of some of the methods of dealing with data\nimbalance, in particular the neighborhood-based oversampling algorithms based\non SMOTE. Radial-Based Oversampling (RBO) was previously proposed to mitigate\nsome of the limitations of the neighborhood-based methods. In this paper we\nexamine the possibility of utilizing the concept of mutual class potential,\nused to guide the oversampling process in RBO, in the undersampling procedure.\nConducted computational complexity analysis indicates a significantly reduced\ntime complexity of the proposed Radial-Based Undersampling algorithm, and the\nresults of the performed experimental study indicate its usefulness, especially\non difficult datasets.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 17:06:28 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 13:51:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Koziarski", "Micha\u0142", ""]]}, {"id": "1906.00454", "submitter": "Saeed Khaki", "authors": "Saeed Khaki, Zahra Khalilzadeh and Lizhi Wang", "title": "Classification of Crop Tolerance to Heat and Drought: A Deep\n  Convolutional Neural Networks Approach", "comments": "Won the Best Paper Award of the Second International Workshop on\n  Machine Learning for Cyber-Agricultural Systems (Ames, IA, USA). One of the\n  winning solutions to the 2019 INFORMS Syngenta Crop Challenge. Presented at\n  2019 INFORMS Conference on Business Analytics and Operations Research\n  (Austin, TX, USA). Published in the Agronomy Journal", "journal-ref": "Agronomy 2019, 9, 833", "doi": "10.3390/agronomy9120833", "report-no": null, "categories": "cs.LG q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental stresses such as drought and heat can cause substantial yield\nloss in agriculture. As such, hybrid crops that are tolerant to drought and\nheat stress would produce more consistent yields compared to the hybrids that\nare not tolerant to these stresses. In the 2019 Syngenta Crop Challenge,\nSyngenta released several large datasets that recorded the yield performances\nof 2,452 corn hybrids planted in 1,560 locations between 2008 and 2017 and\nasked participants to classify the corn hybrids as either tolerant or\nsusceptible to drought stress, heat stress, and combined drought and heat\nstress. However, no data was provided that classified any set of hybrids as\ntolerant or susceptible to any type of stress. In this paper, we present an\nunsupervised approach to solving this problem, which was recognized as one of\nthe winners in the 2019 Syngenta Crop Challenge. Our results labeled 121\nhybrids as drought tolerant, 193 as heat tolerant, and 29 as tolerant to both\nstresses.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 17:25:01 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 01:19:44 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 21:17:59 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 19:39:36 GMT"}, {"version": "v5", "created": "Thu, 5 Dec 2019 18:27:29 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Khaki", "Saeed", ""], ["Khalilzadeh", "Zahra", ""], ["Wang", "Lizhi", ""]]}, {"id": "1906.00460", "submitter": "Vladislav Malyshkin", "authors": "Vladislav Gennadievich Malyshkin", "title": "On The Radon-Nikodym Spectral Approach With Optimal Clustering", "comments": "Relation to PCA variation expansion is added. Whereas a regular PCA\n  variation expansion depends on attributes normalizing, the PCA variation\n  expansion in the Lebesgue quadrature arXiv:1807.06007 basis is unique thus\n  does not depend on attributes scale, moreover it is invariant relatively any\n  non-degenerated linear transform of input vector components. Christoffel\n  function solution to vector label", "journal-ref": null, "doi": "10.2139/ssrn.3398755", "report-no": null, "categories": "cs.LG cs.CV cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Problems of interpolation, classification, and clustering are considered. In\nthe tenets of Radon--Nikodym approach $\\langle f(\\mathbf{x})\\psi^2 \\rangle /\n\\langle\\psi^2\\rangle$, where the $\\psi(\\mathbf{x})$ is a linear function on\ninput attributes, all the answers are obtained from a generalized eigenproblem\n$|f|\\psi^{[i]}\\rangle = \\lambda^{[i]} |\\psi^{[i]}\\rangle$. The solution to the\ninterpolation problem is a regular Radon-Nikodym derivative. The solution to\nthe classification problem requires prior and posterior probabilities that are\nobtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian\napproach new observations change only outcome probabilities, in the\nRadon-Nikodym approach not only outcome probabilities but also the probability\nspace $|\\psi^{[i]}\\rangle$ change with new observations. This is a remarkable\nfeature of the approach: both the probabilities and the probability space are\nconstructed from the data. The Lebesgue quadrature technique can be also\napplied to the optimal clustering problem. The problem is solved by\nconstructing a Gaussian quadrature on the Lebesgue measure. A distinguishing\nfeature of the Radon-Nikodym approach is the knowledge of the invariant group:\nall the answers are invariant relatively any non-degenerated linear transform\nof input vector $\\mathbf{x}$ components. A software product implementing the\nalgorithms of interpolation, classification, and optimal clustering is\navailable from the authors.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 17:57:08 GMT"}, {"version": "v10", "created": "Mon, 6 Apr 2020 21:37:36 GMT"}, {"version": "v11", "created": "Tue, 7 Jul 2020 11:50:54 GMT"}, {"version": "v12", "created": "Sun, 18 Oct 2020 12:58:48 GMT"}, {"version": "v13", "created": "Sun, 31 Jan 2021 23:57:44 GMT"}, {"version": "v14", "created": "Sun, 14 Feb 2021 12:44:25 GMT"}, {"version": "v15", "created": "Sun, 9 May 2021 20:39:06 GMT"}, {"version": "v16", "created": "Sun, 13 Jun 2021 22:54:37 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 08:48:17 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 11:29:56 GMT"}, {"version": "v4", "created": "Thu, 27 Jun 2019 15:22:16 GMT"}, {"version": "v5", "created": "Mon, 15 Jul 2019 10:12:08 GMT"}, {"version": "v6", "created": "Wed, 17 Jul 2019 15:26:51 GMT"}, {"version": "v7", "created": "Fri, 30 Aug 2019 13:08:31 GMT"}, {"version": "v8", "created": "Mon, 28 Oct 2019 00:52:34 GMT"}, {"version": "v9", "created": "Mon, 24 Feb 2020 17:11:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Malyshkin", "Vladislav Gennadievich", ""]]}, {"id": "1906.00494", "submitter": "Soumendu Sundar Mukherjee", "authors": "Soumendu Sundar Mukherjee and Sayak Chakrabarti", "title": "Graphon Estimation from Partially Observed Network Data", "comments": "12 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimating the edge-probability matrix of a network generated\nfrom a graphon model when the full network is not observed---only some\noverlapping subgraphs are. We extend the neighbourhood smoothing (NBS)\nalgorithm of Zhang et al. (2017) to this missing-data set-up and show\nexperimentally that, for a wide range of graphons, the extended NBS algorithm\nachieves significantly smaller error rates than standard graphon estimation\nalgorithms such as vanilla neighbourhood smoothing (NBS), universal singular\nvalue thresholding (USVT), blockmodel approximation, matrix completion, etc. We\nalso show that the extended NBS algorithm is much more robust to missing data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 22:18:42 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 17:34:21 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Mukherjee", "Soumendu Sundar", ""], ["Chakrabarti", "Sayak", ""]]}, {"id": "1906.00495", "submitter": "Naiyang Guan", "authors": "Naiyang Guan, Tongliang Liu, Yangmuzi Zhang, Dacheng Tao, Larry S.\n  Davis", "title": "Truncated Cauchy Non-negative Matrix Factorization", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (IEEE T-PAMI), vol. 41, no. 1, pp. 246-259, Jan. 2019", "doi": "10.1109/TPAMI.2017.2777841", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) minimizes the Euclidean distance\nbetween the data matrix and its low rank approximation, and it fails when\napplied to corrupted data because the loss function is sensitive to outliers.\nIn this paper, we propose a Truncated CauchyNMF loss that handle outliers by\ntruncating large errors, and develop a Truncated CauchyNMF to robustly learn\nthe subspace on noisy datasets contaminated by outliers. We theoretically\nanalyze the robustness of Truncated CauchyNMF comparing with the competing\nmodels and theoretically prove that Truncated CauchyNMF has a generalization\nbound which converges at a rate of order $O(\\sqrt{{\\ln n}/{n}})$, where $n$ is\nthe sample size. We evaluate Truncated CauchyNMF by image clustering on both\nsimulated and real datasets. The experimental results on the datasets\ncontaining gross corruptions validate the effectiveness and robustness of\nTruncated CauchyNMF for learning robust subspaces.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 22:21:30 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Guan", "Naiyang", ""], ["Liu", "Tongliang", ""], ["Zhang", "Yangmuzi", ""], ["Tao", "Dacheng", ""], ["Davis", "Larry S.", ""]]}, {"id": "1906.00505", "submitter": "Yotam Hechtlinger", "authors": "Yoav Benjamini, Yotam Hechtlinger and Philip B. Stark", "title": "Confidence Intervals for Selected Parameters", "comments": "36 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Practical or scientific considerations often lead to selecting a subset of\nparameters as ``important.'' Inferences about those parameters often are based\non the same data used to select them in the first place. That can make the\nreported uncertainties deceptively optimistic: confidence intervals that ignore\nselection generally have less than their nominal coverage probability.\nControlling the probability that one or more intervals for selected parameters\ndo not cover---the ``simultaneous over the selected'' (SoS) error rate---is\ncrucial in many scientific problems. Intervals that control the SoS error rate\ncan be constructed in ways that take advantage of knowledge of the selection\nrule. We construct SoS-controlling confidence intervals for parameters deemed\nthe most ``important'' $k$ of $m$ shift parameters because they are estimated\n(by independent estimators) to be the largest. The new intervals improve\nsubstantially over \\v{S}id\\'{a}k intervals when $k$ is small compared to $m$,\nand approach the standard Bonferroni-corrected intervals when $k \\approx m$.\nStandard, unadjusted confidence intervals for location parameters have the\ncorrect coverage probability for $k=1$, $m=2$ if, when the true parameters are\nzero, the estimators are exchangeable and symmetric.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 23:58:17 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Benjamini", "Yoav", ""], ["Hechtlinger", "Yotam", ""], ["Stark", "Philip B.", ""]]}, {"id": "1906.00512", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie, Bert Huang", "title": "Stochastic Generalized Adversarial Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of machine learning models has grown substantially and is spreading\ninto several application domains. A common need in using machine learning\nmodels is collecting the data required to train these models. In some cases,\nlabeling a massive dataset can be a crippling bottleneck, so there is need to\ndevelop models that work when training labels for large amounts of data are not\neasily obtained. A possible solution is weak supervision, which uses noisy\nlabels that are easily obtained from multiple sources. The challenge is how\nbest to combine these noisy labels and train a model to perform well given a\ntask. In this paper, we propose stochastic generalized adversarial label\nlearning (Stoch-GALL), a framework for training machine learning models that\nperform well when noisy and possibly correlated labels are provided. Our\nframework allows users to provide different weak labels and multiple\nconstraints on these labels. Our model then attempts to learn parameters for\nthe data by solving a non-zero sum game optimization. The game is between an\nadversary that chooses labels for the data and a model that minimizes the error\nmade by the adversarial labels. We test our method on three datasets by\ntraining convolutional neural network models that learn to classify image\nobjects with limited access to training labels. Our approach is able to learn\neven in settings where the weak supervision confounds state-of-the-art weakly\nsupervised learning methods. The results of our experiments demonstrate the\napplicability of this approach to general classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 00:39:52 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:15:35 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Arachie", "Chidubem", ""], ["Huang", "Bert", ""]]}, {"id": "1906.00531", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Akshay Krishnamurthy and Haipeng Luo", "title": "Model selection for contextual bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of model selection for contextual bandits, where a\nlearner must adapt to the complexity of the optimal policy while balancing\nexploration and exploitation. Our main result is a new model selection\nguarantee for linear contextual bandits. We work in the stochastic realizable\nsetting with a sequence of nested linear policy classes of dimension $d_1 < d_2\n< \\ldots$, where the $m^\\star$-th class contains the optimal policy, and we\ndesign an algorithm that achieves $\\tilde{O}(T^{2/3}d^{1/3}_{m^\\star})$ regret\nwith no prior knowledge of the optimal dimension $d_{m^\\star}$. The algorithm\nalso achieves regret $\\tilde{O}(T^{3/4} + \\sqrt{Td_{m^\\star}})$, which is\noptimal for $d_{m^{\\star}}\\geq{}\\sqrt{T}$. This is the first model selection\nresult for contextual bandits with non-vacuous regret for all values of\n$d_{m^\\star}$, and to the best of our knowledge is the first positive result of\nthis type for any online learning setting with partial information. The core of\nthe algorithm is a new estimator for the gap in the best loss achievable by two\nlinear policy classes, which we show admits a convergence rate faster than the\nrate required to learn the parameters for either class.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 02:28:45 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 11:05:11 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 06:08:57 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Foster", "Dylan J.", ""], ["Krishnamurthy", "Akshay", ""], ["Luo", "Haipeng", ""]]}, {"id": "1906.00536", "submitter": "Shichen Cao", "authors": "Shichen Cao, Jingjing Li, Kenric P. Nelson, and Mark A. Kon", "title": "Coupled VAE: Improved Accuracy and Robustness of a Variational\n  Autoencoder", "comments": "19 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coupled Variational Auto-Encoder (VAE) method that improves the\naccuracy and robustness of the probabilistic inferences on represented data.\nThe new method models the dependency between input feature vectors (images) and\nweighs the outliers with a higher penalty by generalizing the original loss\nfunction to the coupled entropy function, using the principles of nonlinear\nstatistical coupling. We evaluate the performance of the coupled VAE model\nusing the MNIST dataset. Compared with the traditional VAE algorithm, the\noutput images generated by the coupled VAE method are clearer and less blurry.\nThe visualization of the input images embedded in 2D latent variable space\nprovides a deeper insight into the structure of new model with coupled loss\nfunction: the latent variable has a smaller deviation and a more compact latent\nspace generates the output values. We analyze the histogram of the likelihoods\nof the input images using the generalized mean, which measures the model's\naccuracy as a function of the relative risk. The neutral accuracy, which is the\ngeometric mean and is consistent with a measure of the Shannon cross-entropy,\nis improved. The robust accuracy, measured by the -2/3 generalized mean, is\nalso improved.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 02:42:13 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 11:57:19 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 16:57:31 GMT"}, {"version": "v4", "created": "Mon, 12 Jul 2021 16:36:46 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cao", "Shichen", ""], ["Li", "Jingjing", ""], ["Nelson", "Kenric P.", ""], ["Kon", "Mark A.", ""]]}, {"id": "1906.00541", "submitter": "Jiseob Kim", "authors": "Jiseob Kim, Seungjae Jung, Hyundo Lee, Byoung-Tak Zhang", "title": "Encoder-Powered Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an encoder-powered generative adversarial network (EncGAN) that is\nable to learn both the multi-manifold structure and the abstract features of\ndata. Unlike the conventional decoder-based GANs, EncGAN uses an encoder to\nmodel the manifold structure and invert the encoder to generate data. This\nunique scheme enables the proposed model to exclude discrete features from the\nsmooth structure modeling and learn multi-manifold data without being hindered\nby the disconnections. Also, as EncGAN requires a single latent space to carry\nthe information for all the manifolds, it builds abstract features shared among\nthe manifolds in the latent space. For an efficient computation, we formulate\nEncGAN using a simple regularizer, and mathematically prove its validity. We\nalso experimentally demonstrate that EncGAN successfully learns the\nmulti-manifold structure and the abstract features of MNIST, 3D-chair and\nUT-Zap50k datasets. Our analysis shows that the learned abstract features are\ndisentangled and make a good style-transfer even when the source data is off\nthe trained distribution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:07:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kim", "Jiseob", ""], ["Jung", "Seungjae", ""], ["Lee", "Hyundo", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1906.00547", "submitter": "Sumeet Katariya", "authors": "Sumeet Katariya, Ardhendu Tripathy, Robert Nowak", "title": "MaxGap Bandit: Adaptive Algorithms for Approximate Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of adaptively sampling from K distributions\n(arms) in order to identify the largest gap between any two adjacent means. We\ncall this the MaxGap-bandit problem. This problem arises naturally in\napproximate ranking, noisy sorting, outlier detection, and top-arm\nidentification in bandits. The key novelty of the MaxGap-bandit problem is that\nit aims to adaptively determine the natural partitioning of the distributions\ninto a subset with larger means and a subset with smaller means, where the\nsplit is determined by the largest gap rather than a pre-specified rank or\nthreshold. Estimating an arm's gap requires sampling its neighboring arms in\naddition to itself, and this dependence results in a novel hardness parameter\nthat characterizes the sample complexity of the problem. We propose elimination\nand UCB-style algorithms and show that they are minimax optimal. Our\nexperiments show that the UCB-style algorithms require 6-8x fewer samples than\nnon-adaptive sampling to achieve the same error.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:21:13 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Katariya", "Sumeet", ""], ["Tripathy", "Ardhendu", ""], ["Nowak", "Robert", ""]]}, {"id": "1906.00551", "submitter": "Gengyu Lyu", "authors": "Gengyu Lyu, Songhe Feng, Yi Jin, Guojun Dai, Congyan Lang, Yidong Li", "title": "HERA: Partial Label Learning by Combining Heterogeneous Loss with Sparse\n  and Low-Rank Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Label Learning (PLL) aims to learn from the data where each training\ninstance is associated with a set of candidate labels, among which only one is\ncorrect. Most existing methods deal with such problem by either treating each\ncandidate label equally or identifying the ground-truth label iteratively. In\nthis paper, we propose a novel PLL approach called HERA, which simultaneously\nincorporates the HeterogEneous Loss and the SpaRse and Low-rAnk procedure to\nestimate the labeling confidence for each instance while training the model.\nSpecifically, the heterogeneous loss integrates the strengths of both the\npairwise ranking loss and the pointwise reconstruction loss to provide\ninformative label ranking and reconstruction information for label\nidentification, while the embedded sparse and low-rank scheme constrains the\nsparsity of ground-truth label matrix and the low rank of noise label matrix to\nexplore the global label relevance among the whole training data for improving\nthe learning model. Extensive experiments on both artificial and real-world\ndata sets demonstrate that our method can achieve superior or comparable\nperformance against the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:49:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Lyu", "Gengyu", ""], ["Feng", "Songhe", ""], ["Jin", "Yi", ""], ["Dai", "Guojun", ""], ["Lang", "Congyan", ""], ["Li", "Yidong", ""]]}, {"id": "1906.00554", "submitter": "Zhen Zhang", "authors": "Zhen Zhang, Fan Wu, Wee Sun Lee", "title": "Factor Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the successful deep neural network architectures are structured,\noften consisting of elements like convolutional neural networks and gated\nrecurrent neural networks. Recently, graph neural networks have been\nsuccessfully applied to graph structured data such as point cloud and molecular\ndata. These networks often only consider pairwise dependencies, as they operate\non a graph structure. We generalize the graph neural network into a factor\ngraph neural network (FGNN) in order to capture higher order dependencies. We\nshow that FGNN is able to represent Max-Product Belief Propagation, an\napproximate inference algorithm on probabilistic graphical models; hence it is\nable to do well when Max-Product does well. Promising results on both synthetic\nand real datasets demonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:53:27 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Zhen", ""], ["Wu", "Fan", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1906.00555", "submitter": "Runtian Zhai", "authors": "Runtian Zhai, Tianle Cai, Di He, Chen Dan, Kun He, John Hopcroft,\n  Liwei Wang", "title": "Adversarially Robust Generalization Just Requires More Unlabeled Data", "comments": "16 pages. Submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network robustness has recently been highlighted by the existence of\nadversarial examples. Many previous works show that the learned networks do not\nperform well on perturbed test data, and significantly more labeled data is\nrequired to achieve adversarially robust generalization. In this paper, we\ntheoretically and empirically show that with just more unlabeled data, we can\nlearn a model with better adversarially robust generalization. The key insight\nof our results is based on a risk decomposition theorem, in which the expected\nrobust risk is separated into two parts: the stability part which measures the\nprediction stability in the presence of perturbations, and the accuracy part\nwhich evaluates the standard classification accuracy. As the stability part\ndoes not depend on any label information, we can optimize this part using\nunlabeled data. We further prove that for a specific Gaussian mixture problem,\nadversarially robust generalization can be almost as easy as the standard\ngeneralization in supervised learning if a sufficiently large amount of\nunlabeled data is provided. Inspired by the theoretical findings, we further\nshow that a practical adversarial training algorithm that leverages unlabeled\ndata can improve adversarial robust generalization on MNIST and Cifar-10.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:56:41 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:44:46 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhai", "Runtian", ""], ["Cai", "Tianle", ""], ["He", "Di", ""], ["Dan", "Chen", ""], ["He", "Kun", ""], ["Hopcroft", "John", ""], ["Wang", "Liwei", ""]]}, {"id": "1906.00562", "submitter": "Qianru Sun", "authors": "Xinzhe Li, Qianru Sun, Yaoyao Liu, Shibao Zheng, Qin Zhou, Tat-Seng\n  Chua, and Bernt Schiele", "title": "Learning to Self-Train for Semi-Supervised Few-Shot Classification", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Few-shot classification (FSC) is challenging due to the scarcity of labeled\ntraining data (e.g. only one labeled data point per class). Meta-learning has\nshown to achieve promising results by learning to initialize a classification\nmodel for FSC. In this paper we propose a novel semi-supervised meta-learning\nmethod called learning to self-train (LST) that leverages unlabeled data and\nspecifically meta-learns how to cherry-pick and label such unsupervised data to\nfurther improve performance. To this end, we train the LST model through a\nlarge number of semi-supervised few-shot tasks. On each task, we train a\nfew-shot model to predict pseudo labels for unlabeled data, and then iterate\nthe self-training steps on labeled and pseudo-labeled data with each step\nfollowed by fine-tuning. We additionally learn a soft weighting network (SWN)\nto optimize the self-training weights of pseudo labels so that better ones can\ncontribute more to gradient descent optimization. We evaluate our LST method on\ntwo ImageNet benchmarks for semi-supervised few-shot classification and achieve\nlarge improvements over the state-of-the-art method. Code is at\nhttps://github.com/xinzheli1217/learning-to-self-train.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:09:32 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 04:43:05 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Li", "Xinzhe", ""], ["Sun", "Qianru", ""], ["Liu", "Yaoyao", ""], ["Zheng", "Shibao", ""], ["Zhou", "Qin", ""], ["Chua", "Tat-Seng", ""], ["Schiele", "Bernt", ""]]}, {"id": "1906.00564", "submitter": "Chongyang Bai", "authors": "Chongyang Bai, Tommy White, Linda Xiao, V.S. Subrahmanian and Ziheng\n  Zhou", "title": "C2P2: A Collective Cryptocurrency Up/Down Price Prediction Engine", "comments": "IEEE Blockchain-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of predicting whether the price of the 21 most popular\ncryptocurrencies (according to coinmarketcap.com) will go up or down on day d,\nusing data up to day d-1. Our C2P2 algorithm is the first algorithm to consider\nthe fact that the price of a cryptocurrency c might depend not only on\nhistorical prices, sentiments, global stock indices, but also on the prices and\npredicted prices of other cryptocurrencies. C2P2 therefore does not predict\ncryptocurrency prices one coin at a time --- rather it uses similarity metrics\nin conjunction with collective classification to compare multiple\ncryptocurrency features to jointly predict the cryptocurrency prices for all 21\ncoins considered. We show that our C2P2 algorithm beats out a recent competing\n2017 paper by margins varying from 5.1-83% and another Bitcoin-specific\nprediction paper from 2018 by 16%. In both cases, C2P2 is the winner on all\ncryptocurrencies considered. Moreover, we experimentally show that the use of\nsimilarity metrics within our C2P2 algorithm leads to a direct improvement for\n20 out of 21 cryptocurrencies ranging from 0.4% to 17.8%. Without the\nsimilarity component, C2P2 still beats competitors on 20 out of 21\ncryptocurrencies considered. We show that all these results are statistically\nsignificant via a Student's t-test with p<1e-5. Check our demo at\nhttps://www.cs.dartmouth.edu/dsail/demos/c2p2\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:20:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bai", "Chongyang", ""], ["White", "Tommy", ""], ["Xiao", "Linda", ""], ["Subrahmanian", "V. S.", ""], ["Zhou", "Ziheng", ""]]}, {"id": "1906.00567", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi and Walid Saad", "title": "Generative Adversarial Networks for Distributed Intrusion Detection in\n  the Internet of Things", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reap the benefits of the Internet of Things (IoT), it is imperative to\nsecure the system against cyber attacks in order to enable mission critical and\nreal-time applications. To this end, intrusion detection systems (IDSs) have\nbeen widely used to detect anomalies caused by a cyber attacker in IoT systems.\nHowever, due to the large-scale nature of the IoT, an IDS must operate in a\ndistributed manner with minimum dependence on a central controller. Moreover,\nin many scenarios such as health and financial applications, the datasets are\nprivate and IoTDs may not intend to share such data. To this end, in this\npaper, a distributed generative adversarial network (GAN) is proposed to\nprovide a fully distributed IDS for the IoT so as to detect anomalous behavior\nwithout reliance on any centralized controller. In this architecture, every\nIoTD can monitor its own data as well as neighbor IoTDs to detect internal and\nexternal attacks. In addition, the proposed distributed IDS does not require\nsharing the datasets between the IoTDs, thus, it can be implemented in IoTs\nthat preserve the privacy of user data such as health monitoring systems or\nfinancial applications. It is shown analytically that the proposed distributed\nGAN has higher accuracy of detecting intrusion compared to a standalone IDS\nthat has access to only a single IoTD dataset. Simulation results show that,\nthe proposed distributed GAN-based IDS has up to 20% higher accuracy, 25%\nhigher precision, and 60% lower false positive rate compared to a standalone\nGAN-based IDS.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:32:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "1906.00569", "submitter": "Anmol Kagrecha", "authors": "Anmol Kagrecha (IIT Bombay), Jayakrishnan Nair (IIT Bombay), Krishna\n  Jagannathan (IIT Madras)", "title": "Distribution oblivious, risk-aware algorithms for multi-armed bandits\n  with unbounded rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical multi-armed bandit problems use the expected value of an arm as a\nmetric to evaluate its goodness. However, the expected value is a risk-neutral\nmetric. In many applications like finance, one is interested in balancing the\nexpected return of an arm (or portfolio) with the risk associated with that\nreturn. In this paper, we consider the problem of selecting the arm that\noptimizes a linear combination of the expected reward and the associated\nConditional Value at Risk (CVaR) in a fixed budget best-arm identification\nframework. We allow the reward distributions to be unbounded or even\nheavy-tailed. For this problem, our goal is to devise algorithms that are\nentirely distribution oblivious, i.e., the algorithm is not aware of any\ninformation on the reward distributions, including bounds on the moments/tails,\nor the suboptimality gaps across arms.\n  In this paper, we provide a class of such algorithms with provable upper\nbounds on the probability of incorrect identification. In the process, we\ndevelop a novel estimator for the CVaR of unbounded (including heavy-tailed)\nrandom variables and prove a concentration inequality for the same, which could\nbe of independent interest. We also compare the error bounds for our\ndistribution oblivious algorithms with those corresponding to standard\nnon-oblivious algorithms. Finally, numerical experiments reveal that our\nalgorithms perform competitively when compared with non-oblivious algorithms,\nsuggesting that distribution obliviousness can be realised in practice without\nincurring a significant loss of performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:38:49 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kagrecha", "Anmol", "", "IIT Bombay"], ["Nair", "Jayakrishnan", "", "IIT Bombay"], ["Jagannathan", "Krishna", "", "IIT Madras"]]}, {"id": "1906.00570", "submitter": "Shuai Wang", "authors": "Shuai Wang, Tsung-Hui Chang, Ying Cui, and Jong-Shi Pang", "title": "Clustering by Orthogonal NMF Model and Non-Convex Penalty Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-negative matrix factorization (NMF) model with an additional\northogonality constraint on one of the factor matrices, called the orthogonal\nNMF (ONMF), has been found a promising clustering model and can outperform the\nclassical K-means. However, solving the ONMF model is a challenging\noptimization problem because the coupling of the orthogonality and\nnon-negativity constraints introduces a mixed combinatorial aspect into the\nproblem due to the determination of the correct status of the variables\n(positive or zero). Most of the existing methods directly deal with the\northogonality constraint in its original form via various optimization\ntechniques, but are not scalable for large-scale problems. In this paper, we\npropose a new ONMF based clustering formulation that equivalently transforms\nthe orthogonality constraint into a set of norm-based non-convex equality\nconstraints. We then apply a non-convex penalty (NCP) approach to add them to\nthe objective as penalty terms, leading to a problem that is efficiently\nsolvable. One smooth penalty formulation and one non-smooth penalty formulation\nare respectively studied. We build theoretical conditions for the penalized\nproblems to provide feasible stationary solutions to the ONMF based clustering\nproblem, as well as proposing efficient algorithms for solving the penalized\nproblems of the two NCP methods. Experimental results based on both synthetic\nand real datasets are presented to show that the proposed NCP methods are\ncomputationally time efficient, and either match or outperform the existing\nK-means and ONMF based methods in terms of the clustering performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:40:46 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:05:11 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 09:04:26 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 09:56:28 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 13:04:57 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Shuai", ""], ["Chang", "Tsung-Hui", ""], ["Cui", "Ying", ""], ["Pang", "Jong-Shi", ""]]}, {"id": "1906.00571", "submitter": "Juan Jose Garau Luis", "authors": "Juan Jose Garau Luis, Markus Guerster, Inigo del Portillo, Edward\n  Crawley, Bruce Cameron", "title": "Deep Reinforcement Learning Architecture for Continuous Power Allocation\n  in High Throughput Satellites", "comments": "8 pages, 5 figures, workshop", "journal-ref": null, "doi": "10.13140/RG.2.2.15014.98882", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the coming years, the satellite broadband market will experience\nsignificant increases in the service demand, especially for the mobility\nsector, where demand is burstier. Many of the next generation of satellites\nwill be equipped with numerous degrees of freedom in power and bandwidth\nallocation capabilities, making manual resource allocation impractical and\ninefficient. Therefore, it is desirable to automate the operation of these\nhighly flexible satellites. This paper presents a novel power allocation\napproach based on Deep Reinforcement Learning (DRL) that represents the problem\nas continuous state and action spaces. We make use of the Proximal Policy\nOptimization (PPO) algorithm to optimize the allocation policy for minimum\nUnmet System Demand (USD) and power consumption. The performance of the\nalgorithm is analyzed through simulations of a multibeam satellite system,\nwhich show promising results for DRL to be used as a dynamic resource\nallocation algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:41:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Luis", "Juan Jose Garau", ""], ["Guerster", "Markus", ""], ["del Portillo", "Inigo", ""], ["Crawley", "Edward", ""], ["Cameron", "Bruce", ""]]}, {"id": "1906.00572", "submitter": "Harm van Seijen", "authors": "Harm van Seijen and Mehdi Fatemi and Arash Tavakoli", "title": "Using a Logarithmic Mapping to Enable Lower Discount Factors in\n  Reinforcement Learning", "comments": "NeurIPS 2019, code: https://github.com/microsoft/logrl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to better understand the different ways in which the discount\nfactor affects the optimization process in reinforcement learning, we designed\na set of experiments to study each effect in isolation. Our analysis reveals\nthat the common perception that poor performance of low discount factors is\ncaused by (too) small action-gaps requires revision. We propose an alternative\nhypothesis that identifies the size-difference of the action-gap across the\nstate-space as the primary cause. We then introduce a new method that enables\nmore homogeneous action-gaps by mapping value estimates to a logarithmic space.\nWe prove convergence for this method under standard assumptions and demonstrate\nempirically that it indeed enables lower discount factors for approximate\nreinforcement-learning methods. This in turn allows tackling a class of\nreinforcement-learning problems that are challenging to solve with traditional\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:44:45 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 16:43:25 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["van Seijen", "Harm", ""], ["Fatemi", "Mehdi", ""], ["Tavakoli", "Arash", ""]]}, {"id": "1906.00588", "submitter": "Xin Qiu", "authors": "Xin Qiu, Elliot Meyerson, Risto Miikkulainen", "title": "Quantifying Point-Prediction Uncertainty in Neural Networks via Residual\n  Estimation with an I/O Kernel", "comments": "Fixed technical typos in log marginal likelihood calculation and\n  Lemma A.2 proof", "journal-ref": "Published at ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) have been extensively used for a wide spectrum of\nreal-world regression tasks, where the goal is to predict a numerical outcome\nsuch as revenue, effectiveness, or a quantitative result. In many such tasks,\nthe point prediction is not enough: the uncertainty (i.e. risk or confidence)\nof that prediction must also be estimated. Standard NNs, which are most often\nused in such tasks, do not provide uncertainty information. Existing approaches\naddress this issue by combining Bayesian models with NNs, but these models are\nhard to implement, more expensive to train, and usually do not predict as\naccurately as standard NNs. In this paper, a new framework (RIO) is developed\nthat makes it possible to estimate uncertainty in any pretrained standard NN.\nThe behavior of the NN is captured by modeling its prediction residuals with a\nGaussian Process, whose kernel includes both the NN's input and its output. The\nframework is evaluated in twelve real-world datasets, where it is found to (1)\nprovide reliable estimates of uncertainty, (2) reduce the error of the point\npredictions, and (3) scale well to large datasets. Given that RIO can be\napplied to any standard NN without modifications to model architecture or\ntraining pipeline, it provides an important ingredient for building real-world\nNN applications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 06:08:57 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:05:22 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 02:20:00 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 10:51:17 GMT"}, {"version": "v5", "created": "Thu, 4 Jun 2020 15:26:07 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Qiu", "Xin", ""], ["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1906.00616", "submitter": "Or Yair", "authors": "Or Yair, Felix Dietrich, Ronen Talmon, and Ioannis G. Kevrekidis", "title": "Domain Adaptation with Optimal Transport on the Manifold of SPD matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of Domain Adaptation (DA) using Optimal\nTransport (OT) on Riemannian manifolds. We model the difference between two\ndomains by a diffeomorphism and use the polar factorization theorem to claim\nthat OT is indeed optimal for DA in a well-defined sense, up to a volume\npreserving map. We then focus on the manifold of Symmetric and\nPositive-Definite (SPD) matrices, whose structure provided a useful context in\nrecent applications. We demonstrate the polar factorization theorem on this\nmanifold. Due to the uniqueness of the weighted Riemannian mean, and by\nexploiting existing regularized OT algorithms, we formulate a simple algorithm\nthat maps the source domain to the target domain. We test our algorithm on two\nBrain-Computer Interface (BCI) data sets and observe state of the art\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 07:54:54 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 08:36:16 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 16:41:00 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 16:21:18 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yair", "Or", ""], ["Dietrich", "Felix", ""], ["Talmon", "Ronen", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "1906.00618", "submitter": "Kevin Tian", "authors": "Arun Jambulapati, Aaron Sidford, Kevin Tian", "title": "A Direct $\\tilde{O}(1/\\epsilon)$ Iteration Parallel Algorithm for\n  Optimal Transport", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transportation, or computing the Wasserstein or ``earth mover's''\ndistance between two distributions, is a fundamental primitive which arises in\nmany learning and statistical settings. We give an algorithm which solves this\nproblem to additive $\\epsilon$ with $\\tilde{O}(1/\\epsilon)$ parallel depth, and\n$\\tilde{O}\\left(n^2/\\epsilon\\right)$ work. Barring a breakthrough on a\nlong-standing algorithmic open problem, this is optimal for first-order\nmethods. Blanchet et. al. '18, Quanrud '19 obtained similar runtimes through\nreductions to positive linear programming and matrix scaling. However, these\nreduction-based algorithms use complicated subroutines which may be deemed\nimpractical due to requiring solvers for second-order iterations (matrix\nscaling) or non-parallelizability (positive LP). The fastest practical\nalgorithms run in time $\\tilde{O}(\\min(n^2 / \\epsilon^2, n^{2.5} / \\epsilon))$\n(Dvurechensky et. al. '18, Lin et. al. '19). We bridge this gap by providing a\nparallel, first-order, $\\tilde{O}(1/\\epsilon)$ iteration algorithm without\nworse dependence on dimension, and provide preliminary experimental evidence\nthat our algorithm may enjoy improved practical performance. We obtain this\nruntime via a primal-dual extragradient method, motivated by recent theoretical\nimprovements to maximum flow (Sherman '17).\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 07:58:09 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jambulapati", "Arun", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "1906.00628", "submitter": "Marek Smieja", "authors": "Pawe{\\l} Morawiecki, Przemys{\\l}aw Spurek, Marek \\'Smieja, Jacek Tabor", "title": "Fast and Stable Interval Bounds Propagation for Training Verifiably\n  Robust Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient technique, which allows to train classification\nnetworks which are verifiably robust against norm-bounded adversarial attacks.\nThis framework is built upon the work of Gowal et al., who applies the interval\narithmetic to bound the activations at each layer and keeps the prediction\ninvariant to the input perturbation. While that method is faster than\ncompetitive approaches, it requires careful tuning of hyper-parameters and a\nlarge number of epochs to converge. To speed up and stabilize training, we\nsupply the cost function with an additional term, which encourages the model to\nkeep the interval bounds at hidden layers small. Experimental results\ndemonstrate that we can achieve comparable (or even better) results using a\nsmaller number of training iterations, in a more stable fashion. Moreover, the\nproposed model is not so sensitive to the exact specification of the training\nprocess, which makes it easier to use by practitioners.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:25:47 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 06:28:14 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Morawiecki", "Pawe\u0142", ""], ["Spurek", "Przemys\u0142aw", ""], ["\u015amieja", "Marek", ""], ["Tabor", "Jacek", ""]]}, {"id": "1906.00629", "submitter": "Kosuke Tanizaki", "authors": "Kosuke Tanizaki, Noriaki Hashimoto, Yu Inatsu, Hidekata Hontani and\n  Ichiro Takeuchi", "title": "Computing Valid p-values for Image Segmentation by Selective Inference", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is one of the most fundamental tasks of computer vision.\nIn many practical applications, it is essential to properly evaluate the\nreliability of individual segmentation results. In this study, we propose a\nnovel framework to provide the statistical significance of segmentation results\nin the form of p-values. Specifically, we consider a statistical hypothesis\ntest for determining the difference between the object and the background\nregions. This problem is challenging because the difference can be deceptively\nlarge (called segmentation bias) due to the adaptation of the segmentation\nalgorithm to the data. To overcome this difficulty, we introduce a statistical\napproach called selective inference, and develop a framework to compute valid\np-values in which the segmentation bias is properly accounted for. Although the\nproposed framework is potentially applicable to various segmentation\nalgorithms, we focus in this paper on graph cut-based and threshold-based\nsegmentation algorithms, and develop two specific methods to compute valid\np-values for the segmentation results obtained by these algorithms. We prove\nthe theoretical validity of these two methods and demonstrate their\npracticality by applying them to segmentation problems for medical images.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:27:27 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:23:18 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Tanizaki", "Kosuke", ""], ["Hashimoto", "Noriaki", ""], ["Inatsu", "Yu", ""], ["Hontani", "Hidekata", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1906.00642", "submitter": "Hui Chen", "authors": "Hui Chen, Fangqing Liu, Yin Wang, Liyue Zhao, and Hao Wu", "title": "A Variational Approach for Learning from Positive and Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning binary classifiers only from positive and unlabeled (PU) data is an\nimportant and challenging task in many real-world applications, including web\ntext classification, disease gene identification and fraud detection, where\nnegative samples are difficult to verify experimentally. Most recent PU\nlearning methods are developed based on the conventional misclassification risk\nof the supervised learning type, and they require to solve the intractable risk\nestimation problem by approximating the negative data distribution or the class\nprior. In this paper, we introduce a variational principle for PU learning that\nallows us to quantitatively evaluate the modeling error of the Bayesian\nclassifier directly from given data. This leads to a loss function which can be\nefficiently calculated without any intermediate step or model, and a\nvariational learning method can then be employed to optimize the classifier\nunder general conditions. In addition, the discriminative performance and\nnumerical stability of the variational PU learning method can be further\nimproved by incorporating a margin maximizing loss function. We illustrate the\neffectiveness of the proposed variational method on a number of benchmark\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:57:35 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 10:44:03 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 15:04:13 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2020 01:19:59 GMT"}, {"version": "v5", "created": "Tue, 28 Apr 2020 05:33:08 GMT"}, {"version": "v6", "created": "Sun, 29 Nov 2020 08:53:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chen", "Hui", ""], ["Liu", "Fangqing", ""], ["Wang", "Yin", ""], ["Zhao", "Liyue", ""], ["Wu", "Hao", ""]]}, {"id": "1906.00654", "submitter": "Zhepei Wang", "authors": "Zhepei Wang, Cem Subakan, Efthymios Tzinis, Paris Smaragdis and\n  Laurent Charlin", "title": "Continual Learning of New Sound Classes using Generative Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning consists in incrementally training a model on a sequence\nof datasets and testing on the union of all datasets. In this paper, we examine\ncontinual learning for the problem of sound classification, in which we wish to\nrefine already trained models to learn new sound classes. In practice one does\nnot want to maintain all past training data and retrain from scratch, but\nnaively updating a model with new data(sets) results in a degradation of\nalready learned tasks, which is referred to as \"catastrophic forgetting.\" We\ndevelop a generative replay procedure for generating training audio spectrogram\ndata, in place of keeping older training datasets. We show that by\nincrementally refining a classifier with generative replay a generator that is\n4% of the size of all previous training data matches the performance of\nrefining the classifier keeping 20% of all previous training data. We thus\nconclude that we can extend a trained sound classifier to learn new classes\nwithout having to keep previously used datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:20:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Zhepei", ""], ["Subakan", "Cem", ""], ["Tzinis", "Efthymios", ""], ["Smaragdis", "Paris", ""], ["Charlin", "Laurent", ""]]}, {"id": "1906.00670", "submitter": "Tobias Sommer Thune", "authors": "Tobias Sommer Thune, Nicol\\`o Cesa-Bianchi and Yevgeny Seldin", "title": "Nonstochastic Multiarmed Bandits with Unrestricted Delays", "comments": "9 pages, Neurips camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate multiarmed bandits with delayed feedback, where the delays\nneed neither be identical nor bounded. We first prove that \"delayed\" Exp3\nachieves the $O(\\sqrt{(KT + D)\\ln K} )$ regret bound conjectured by\nCesa-Bianchi et al. [2019] in the case of variable, but bounded delays. Here,\n$K$ is the number of actions and $D$ is the total delay over $T$ rounds. We\nthen introduce a new algorithm that lifts the requirement of bounded delays by\nusing a wrapper that skips rounds with excessively large delays. The new\nalgorithm maintains the same regret bound, but similar to its predecessor\nrequires prior knowledge of $D$ and $T$. For this algorithm we then construct a\nnovel doubling scheme that forgoes the prior knowledge requirement under the\nassumption that the delays are available at action time (rather than at loss\nobservation time). This assumption is satisfied in a broad range of\napplications, including interaction with servers and service providers. The\nresulting oracle regret bound is of order $\\min_\\beta (|S_\\beta|+\\beta \\ln K +\n(KT + D_\\beta)/\\beta)$, where $|S_\\beta|$ is the number of observations with\ndelay exceeding $\\beta$, and $D_\\beta$ is the total delay of observations with\ndelay below $\\beta$. The bound relaxes to $O (\\sqrt{(KT + D)\\ln K} )$, but we\nalso provide examples where $D_\\beta \\ll D$ and the oracle bound has a\npolynomially better dependence on the problem parameters.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:50:51 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 15:55:14 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Thune", "Tobias Sommer", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1906.00684", "submitter": "Yizhou Zhang", "authors": "Yizhou Zhang, Guojie Song, Lun Du, Shuwen Yang, Yilun Jin", "title": "DANE: Domain Adaptive Network Embedding", "comments": "7 pages, 4 figures, accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works reveal that network embedding techniques enable many machine\nlearning models to handle diverse downstream tasks on graph structured data.\nHowever, as previous methods usually focus on learning embeddings for a single\nnetwork, they can not learn representations transferable on multiple networks.\nHence, it is important to design a network embedding algorithm that supports\ndownstream model transferring on different networks, known as domain\nadaptation. In this paper, we propose a novel Domain Adaptive Network Embedding\nframework, which applies graph convolutional network to learn transferable\nembeddings. In DANE, nodes from multiple networks are encoded to vectors via a\nshared set of learnable parameters so that the vectors share an aligned\nembedding space. The distribution of embeddings on different networks are\nfurther aligned by adversarial learning regularization. In addition, DANE's\nadvantage in learning transferable network embedding can be guaranteed\ntheoretically. Extensive experiments reflect that the proposed framework\noutperforms other state-of-the-art network embedding baselines in cross-network\ndomain adaptation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:11:15 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 23:34:19 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Zhang", "Yizhou", ""], ["Song", "Guojie", ""], ["Du", "Lun", ""], ["Yang", "Shuwen", ""], ["Jin", "Yilun", ""]]}, {"id": "1906.00695", "submitter": "Christian Henning", "authors": "Johannes von Oswald and Christian Henning and Jo\\~ao Sacramento and\n  Benjamin F. Grewe", "title": "Continual learning with hypernetworks", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks suffer from catastrophic forgetting when they are\nsequentially trained on multiple tasks. To overcome this problem, we present a\nnovel approach based on task-conditioned hypernetworks, i.e., networks that\ngenerate the weights of a target model based on task identity. Continual\nlearning (CL) is less difficult for this class of models thanks to a simple key\nfeature: instead of recalling the input-output relations of all previously seen\ndata, task-conditioned hypernetworks only require rehearsing task-specific\nweight realizations, which can be maintained in memory using a simple\nregularizer. Besides achieving state-of-the-art performance on standard CL\nbenchmarks, additional experiments on long task sequences reveal that\ntask-conditioned hypernetworks display a very large capacity to retain previous\nmemories. Notably, such long memory lifetimes are achieved in a compressive\nregime, when the number of trainable hypernetwork weights is comparable or\nsmaller than target network size. We provide insight into the structure of\nlow-dimensional task embedding spaces (the input space of the hypernetwork) and\nshow that task-conditioned hypernetworks demonstrate transfer learning.\nFinally, forward information transfer is further supported by empirical results\non a challenging CL benchmark based on the CIFAR-10/100 image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:45:08 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 12:11:32 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 14:56:57 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["von Oswald", "Johannes", ""], ["Henning", "Christian", ""], ["Sacramento", "Jo\u00e3o", ""], ["Grewe", "Benjamin F.", ""]]}, {"id": "1906.00698", "submitter": "Emilio Rafael Balda", "authors": "Emilio Rafael Balda, Arash Behboodi, Niklas Koep, Rudolf Mathar", "title": "Adversarial Risk Bounds for Neural Networks through Sparsity based\n  Compression", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been shown to be vulnerable against minor adversarial\nperturbations of their inputs, especially for high dimensional data under\n$\\ell_\\infty$ attacks. To combat this problem, techniques like adversarial\ntraining have been employed to obtain models which are robust on the training\nset. However, the robustness of such models against adversarial perturbations\nmay not generalize to unseen data. To study how robustness generalizes, recent\nworks assume that the inputs have bounded $\\ell_2$-norm in order to bound the\nadversarial risk for $\\ell_\\infty$ attacks with no explicit dimension\ndependence. In this work we focus on $\\ell_\\infty$ attacks on $\\ell_\\infty$\nbounded inputs and prove margin-based bounds. Specifically, we use a\ncompression based approach that relies on efficiently compressing the set of\ntunable parameters without distorting the adversarial risk. To achieve this, we\napply the concept of effective sparsity and effective joint sparsity on the\nweight matrices of neural networks. This leads to bounds with no explicit\ndependence on the input dimension, neither on the number of classes. Our\nresults show that neural networks with approximately sparse weight matrices not\nonly enjoy enhanced robustness, but also better generalization.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:50:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Balda", "Emilio Rafael", ""], ["Behboodi", "Arash", ""], ["Koep", "Niklas", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1906.00722", "submitter": "Michael Moor", "authors": "Michael Moor and Max Horn and Bastian Rieck and Karsten Borgwardt", "title": "Topological Autoencoders", "comments": "Accepted at the International Conference on Machine Learning (ICML)\n  2020; camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for preserving topological structures of the\ninput space in latent representations of autoencoders. Using persistent\nhomology, a technique from topological data analysis, we calculate topological\nsignatures of both the input and latent space to derive a topological loss\nterm. Under weak theoretical assumptions, we construct this loss in a\ndifferentiable manner, such that the encoding learns to retain multi-scale\nconnectivity information. We show that our approach is theoretically\nwell-founded and that it exhibits favourable latent representations on a\nsynthetic manifold as well as on real-world image data sets, while preserving\nlow reconstruction errors.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 11:41:47 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 12:00:56 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 09:44:54 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 12:01:57 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 15:02:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Moor", "Michael", ""], ["Horn", "Max", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1906.00729", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, Tamer Ba\\c{s}ar", "title": "Policy Optimization Provably Converges to Nash Equilibria in Zero-Sum\n  Linear Quadratic Games", "comments": "Fixed some typos, addressed some comments from NeurIPS reviews", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the global convergence of policy optimization for finding the Nash\nequilibria (NE) in zero-sum linear quadratic (LQ) games. To this end, we first\ninvestigate the landscape of LQ games, viewing it as a nonconvex-nonconcave\nsaddle-point problem in the policy space. Specifically, we show that despite\nits nonconvexity and nonconcavity, zero-sum LQ games have the property that the\nstationary point of the objective function with respect to the linear feedback\ncontrol policies constitutes the NE of the game. Building upon this, we develop\nthree projected nested-gradient methods that are guaranteed to converge to the\nNE of the game. Moreover, we show that all of these algorithms enjoy both\nglobally sublinear and locally linear convergence rates. Simulation results are\nalso provided to illustrate the satisfactory convergence properties of the\nalgorithms. To the best of our knowledge, this work appears to be the first one\nto investigate the optimization landscape of LQ games, and provably show the\nconvergence of policy optimization methods to the Nash equilibria. Our work\nserves as an initial step toward understanding the theoretical aspects of\npolicy-based reinforcement learning algorithms for zero-sum Markov games in\ngeneral.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:28:25 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 11:05:45 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 06:36:33 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 21:30:42 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1906.00735", "submitter": "Nils Strodthoff", "authors": "Jan Laermann, Wojciech Samek and Nils Strodthoff", "title": "Achieving Generalizable Robustness of Deep Neural Networks by Stability\n  Training", "comments": "18 pages, 25 figures; Camera-ready version", "journal-ref": "DAGM GCPR 2019. Lecture Notes in Computer Science, vol. 11824,\n  360-373, 2019", "doi": "10.1007/978-3-030-33676-9_25", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the recently introduced stability training as a general-purpose\nmethod to increase the robustness of deep neural networks against input\nperturbations. In particular, we explore its use as an alternative to data\naugmentation and validate its performance against a number of distortion types\nand transformations including adversarial examples. In our image classification\nexperiments using ImageNet data stability training performs on a par or even\noutperforms data augmentation for specific transformations, while consistently\noffering improved robustness against a broader range of distortion strengths\nand types unseen during training, a considerably smaller hyperparameter\ndependence and less potentially negative side effects compared to data\naugmentation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 12:20:43 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:24:42 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Laermann", "Jan", ""], ["Samek", "Wojciech", ""], ["Strodthoff", "Nils", ""]]}, {"id": "1906.00764", "submitter": "Tomas Pevny", "authors": "Tomas Pevny and Vojtech Kovarik", "title": "Approximation capability of neural networks on spaces of probability\n  measures and tree-structured domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the proof of density of neural networks in the space of\ncontinuous (or even measurable) functions on Euclidean spaces to functions on\ncompact sets of probability measures. By doing so the work parallels a more\nthen a decade old results on mean-map embedding of probability measures in\nreproducing kernel Hilbert spaces. The work has wide practical consequences for\nmulti-instance learning, where it theoretically justifies some recently\nproposed constructions. The result is then extended to Cartesian products,\nyielding universal approximation theorem for tree-structured domains, which\nnaturally occur in data-exchange formats like JSON, XML, YAML, AVRO, and\nProtoBuffer. This has important practical implications, as it enables to\nautomatically create an architecture of neural networks for processing\nstructured data (AutoML paradigms), as demonstrated by an accompanied library\nfor JSON format.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 12:58:59 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Pevny", "Tomas", ""], ["Kovarik", "Vojtech", ""]]}, {"id": "1906.00767", "submitter": "Yue Xu", "authors": "Yue Xu and Wenjun Xu and Zhi Wang and Jiaru Lin and Shuguang Cui", "title": "Load Balancing for Ultra-Dense Networks: A Deep Reinforcement Learning\n  Based Approach", "comments": null, "journal-ref": "IEEE Internet of Things Journal, Volume: 6, Issue: 6, Dec. 2019", "doi": "10.1109/JIOT.2019.2935010", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep reinforcement learning (DRL) based mobility\nload balancing (MLB) algorithm along with a two-layer architecture to solve the\nlarge-scale load balancing problem for ultra-dense networks (UDNs). Our\ncontribution is three-fold. First, this work proposes a two-layer architecture\nto solve the large-scale load balancing problem in a self-organized manner. The\nproposed architecture can alleviate the global traffic variations by\ndynamically grouping small cells into self-organized clusters according to\ntheir historical loads, and further adapt to local traffic variations through\nintra-cluster load balancing afterwards. Second, for the intra-cluster load\nbalancing, this paper proposes an off-policy DRL-based MLB algorithm to\nautonomously learn the optimal MLB policy under an asynchronous parallel\nlearning framework, without any prior knowledge assumed over the underlying UDN\nenvironments. Moreover, the algorithm enables joint exploration with multiple\nbehavior policies, such that the traditional MLB methods can be used to guide\nthe learning process thereby improving the learning efficiency and stability.\nThird, this work proposes an offline-evaluation based safeguard mechanism to\nensure that the online system can always operate with the optimal and\nwell-trained MLB policy, which not only stabilizes the online performance but\nalso enables the exploration beyond current policies to make full use of\nmachine learning in a safe way. Empirical results verify that the proposed\nframework outperforms the existing MLB methods in general UDN environments\nfeatured with irregular network topologies, coupled interferences, and random\nuser movements, in terms of the load balancing performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:02:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 11:37:24 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 04:47:37 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Yue", ""], ["Xu", "Wenjun", ""], ["Wang", "Zhi", ""], ["Lin", "Jiaru", ""], ["Cui", "Shuguang", ""]]}, {"id": "1906.00771", "submitter": "Yaniv Blumenfeld", "authors": "Yaniv Blumenfeld, Dar Gilboa, Daniel Soudry", "title": "A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth\n  Trade-Off", "comments": "NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the precision of weights and activation functions in neural network\ntraining, with minimal impact on performance, is essential for the deployment\nof these models in resource-constrained environments. We apply mean-field\ntechniques to networks with quantized activations in order to evaluate the\ndegree to which quantization degrades signal propagation at initialization. We\nderive initialization schemes which maximize signal propagation in such\nnetworks and suggest why this is helpful for generalization. Building on these\nresults, we obtain a closed form implicit equation for $L_{\\max}$, the maximal\ntrainable depth (and hence model capacity), given $N$, the number of\nquantization levels in the activation function. Solving this equation\nnumerically, we obtain asymptotically: $L_{\\max}\\propto N^{1.82}$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:07:26 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:38:30 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Blumenfeld", "Yaniv", ""], ["Gilboa", "Dar", ""], ["Soudry", "Daniel", ""]]}, {"id": "1906.00794", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, Santiago Pascual, Carlos Segura", "title": "Blow: a single-scale hyperconditioned flow for non-parallel raw-audio\n  voice conversion", "comments": "Includes appendix. Accepted for NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models for raw audio generation are a challenge, specially if they\nhave to work with non-parallel data, which is a desirable setup in many\nsituations. Voice conversion, in which a model has to impersonate a speaker in\na recording, is one of those situations. In this paper, we propose Blow, a\nsingle-scale normalizing flow using hypernetwork conditioning to perform\nmany-to-many voice conversion between raw audio. Blow is trained end-to-end,\nwith non-parallel data, on a frame-by-frame basis using a single speaker\nidentifier. We show that Blow compares favorably to existing flow-based\narchitectures and other competitive baselines, obtaining equal or better\nperformance in both objective and subjective evaluations. We further assess the\nimpact of its main components with an ablation study, and quantify a number of\nproperties such as the necessary amount of training data or the preference for\nsource or target speakers.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:33:36 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 12:20:50 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Pascual", "Santiago", ""], ["Segura", "Carlos", ""]]}, {"id": "1906.00800", "submitter": "Artem Artemov", "authors": "A.Artemov, I.Bolokhov, D.Kem, I.Khasenevich", "title": "Neural Network-based Object Classification by Known and Unknown Features\n  (Based on Text Queries)", "comments": "7 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents a method that improves the quality of classification of\nobjects described by a combination of known and unknown features. The method is\nbased on modernized Informational Neurobayesian Approach with consideration of\nunknown features. The proposed method was developed and trained on 1500 text\nqueries of Promobot users in Russian to classify them into 20 categories\n(classes). As a result, the use of the method allowed to completely solve the\nproblem of misclassification for queries with combining known and unknown\nfeatures of the model. The theoretical substantiation of the method is\npresented by the formulated and proved theorem On the Model with Limited\nKnowledge. It states, that in conditions of limited data, an equal number of\nequally unknown features of an object cannot have different significance for\nthe classification problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:38:20 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Artemov", "A.", ""], ["Bolokhov", "I.", ""], ["Kem", "D.", ""], ["Khasenevich", "I.", ""]]}, {"id": "1906.00816", "submitter": "Manuel Hau{\\ss}mann", "authors": "Manuel Haussmann, Sebastian Gerwinn, Melih Kandemir", "title": "Bayesian Evidential Deep Learning with PAC Regularization", "comments": "Presented at AABI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for closed-form predictive distribution modeling\nwith neural nets. In quantifying prediction uncertainty, we build on Evidential\nDeep Learning, which has been impactful as being both simple to implement and\ngiving closed-form access to predictive uncertainty. We employ it to model\naleatoric uncertainty and extend it to account also for epistemic uncertainty\nby converting it to a Bayesian Neural Net. While extending its uncertainty\nquantification capabilities, we maintain its analytically accessible predictive\ndistribution model by performing progressive moment matching for the first time\nfor approximate weight marginalization. The eventual model introduces a\nprohibitively large number of hyperparameters for stable training. We overcome\nthis drawback by deriving a vacuous PAC bound that comprises the marginal\nlikelihood of the predictor and a complexity penalty. We observe on regression,\nclassification, and out-of-domain detection benchmarks that our method improves\nmodel fit and uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:51:51 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 08:58:43 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 11:03:16 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Haussmann", "Manuel", ""], ["Gerwinn", "Sebastian", ""], ["Kandemir", "Melih", ""]]}, {"id": "1906.00820", "submitter": "Anna Kruspe", "authors": "Anna Kruspe", "title": "One-Way Prototypical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot models have become a popular topic of research in the past years.\nThey offer the possibility to determine class belongings for unseen examples\nusing just a handful of examples for each class. Such models are trained on a\nwide range of classes and their respective examples, learning a decision metric\nin the process. Types of few-shot models include matching networks and\nprototypical networks. We show a new way of training prototypical few-shot\nmodels for just a single class. These models have the ability to predict the\nlikelihood of an unseen query belonging to a group of examples without any\ngiven counterexamples. The difficulty here lies in the fact that no relative\ndistance to other classes can be calculated via softmax. We solve this problem\nby introducing a \"null class\" centered around zero, and enforcing centering\nwith batch normalization. Trained on the commonly used Omniglot data set, we\nobtain a classification accuracy of .98 on the matched test set, and of .8 on\nunmatched MNIST data. On the more complex MiniImageNet data set, test accuracy\nis .8. In addition, we propose a novel Gaussian layer for distance calculation\nin a prototypical network, which takes the support examples' distribution\nrather than just their centroid into account. This extension shows promising\nresults when a higher number of support examples is available.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:00:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kruspe", "Anna", ""]]}, {"id": "1906.00823", "submitter": "Gautier Izacard", "authors": "Gautier Izacard, Sreyas Mohan, Carlos Fernandez-Granda", "title": "Data-driven Estimation of Sinusoid Frequencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency estimation is a fundamental problem in signal processing, with\napplications in radar imaging, underwater acoustics, seismic imaging, and\nspectroscopy. The goal is to estimate the frequency of each component in a\nmultisinusoidal signal from a finite number of noisy samples. A recent\nmachine-learning approach uses a neural network to output a learned\nrepresentation with local maxima at the position of the frequency estimates. In\nthis work, we propose a novel neural-network architecture that produces a\nsignificantly more accurate representation, and combine it with an additional\nneural-network module trained to detect the number of frequencies. This yields\na fast, fully-automatic method for frequency estimation that achieves\nstate-of-the-art results. In particular, it outperforms existing techniques by\na substantial margin at medium-to-high noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:08:08 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 22:59:47 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 10:32:13 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Izacard", "Gautier", ""], ["Mohan", "Sreyas", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "1906.00825", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Verena V. Hafner", "title": "Self-supervised Body Image Acquisition Using a Deep Neural Network for\n  Sensorimotor Prediction", "comments": "6 pages, 7 figures, submitted to ICDL-Epirob 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates how a naive agent can acquire its own body image in a\nself-supervised way, based on the predictability of its sensorimotor\nexperience. Our working hypothesis is that, due to its temporal stability, an\nagent's body produces more consistent sensory experiences than the environment,\nwhich exhibits a greater variability. Given its motor experience, an agent can\nthus reliably predict what appearance its body should have. This intrinsic\npredictability can be used to automatically isolate the body image from the\nrest of the environment. We propose a two-branches deconvolutional neural\nnetwork to predict the visual sensory state associated with an input motor\nstate, as well as the prediction error associated with this input. We train the\nnetwork on a dataset of first-person images collected with a simulated Pepper\nrobot, and show how the network outputs can be used to automatically isolate\nits visible arm from the rest of the environment. Finally, the quality of the\nbody image produced by the network is evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:10:17 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Hafner", "Verena V.", ""]]}, {"id": "1906.00830", "submitter": "Sebastian Szyller", "authors": "Sebastian Szyller, Buse Gul Atli, Samuel Marchal, N. Asokan", "title": "DAWN: Dynamic Adversarial Watermarking of Neural Networks", "comments": "Shorter version of this work to appear in Proceedings of the ACM\n  Multimedia 2021; 16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning (ML) models is expensive in terms of computational\npower, amounts of labeled data and human expertise. Thus, ML models constitute\nintellectual property (IP) and business value for their owners. Embedding\ndigital watermarks during model training allows a model owner to later identify\ntheir models in case of theft or misuse. However, model functionality can also\nbe stolen via model extraction, where an adversary trains a surrogate model\nusing results returned from a prediction API of the original model. Recent work\nhas shown that model extraction is a realistic threat. Existing watermarking\nschemes are ineffective against IP theft via model extraction since it is the\nadversary who trains the surrogate model. In this paper, we introduce DAWN\n(Dynamic Adversarial Watermarking of Neural Networks), the first approach to\nuse watermarking to deter model extraction IP theft. Unlike prior watermarking\nschemes, DAWN does not impose changes to the training process but it operates\nat the prediction API of the protected model, by dynamically changing the\nresponses for a small subset of queries (e.g., <0.5%) from API clients. This\nset is a watermark that will be embedded in case a client uses its queries to\ntrain a surrogate model. We show that DAWN is resilient against two\nstate-of-the-art model extraction attacks, effectively watermarking all\nextracted surrogate models, allowing model owners to reliably demonstrate\nownership (with confidence $>1- 2^{-64}$), incurring negligible loss of\nprediction accuracy (0.03-0.5%).\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:25:30 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:35:09 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 21:15:41 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 08:28:41 GMT"}, {"version": "v5", "created": "Fri, 16 Jul 2021 12:11:57 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Szyller", "Sebastian", ""], ["Atli", "Buse Gul", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "1906.00852", "submitter": "Jaehoon Cha", "authors": "Jaehoon Cha, Kyeong Soo Kim, Sanghyuk Lee", "title": "Hierarchical Auxiliary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional application of convolutional neural networks (CNNs) for image\nclassification and recognition is based on the assumption that all target\nclasses are equal(i.e., no hierarchy) and exclusive of one another (i.e., no\noverlap). CNN-based image classifiers built on this assumption, therefore,\ncannot take into account an innate hierarchy among target classes (e.g., cats\nand dogs in animal image classification) or additional information that can be\neasily derived from the data (e.g.,numbers larger than five in the recognition\nof handwritten digits), thereby resulting in scalability issues when the number\nof target classes is large. Combining two related but slightly different ideas\nof hierarchical classification and logical learning by auxiliary inputs, we\npropose a new learning framework called hierarchical auxiliary learning, which\nnot only address the scalability issues with a large number of classes but also\ncould further reduce the classification/recognition errors with a reasonable\nnumber of classes. In the hierarchical auxiliary learning, target classes are\nsemantically or non-semantically grouped into superclasses, which turns the\noriginal problem of mapping between an image and its target class into a new\nproblem of mapping between a pair of an image and its superclass and the target\nclass. To take the advantage of superclasses, we introduce an auxiliary block\ninto a neural network, which generates auxiliary scores used as additional\ninformation for final classification/recognition; in this paper, we add the\nauxiliary block between the last residual block and the fully-connected output\nlayer of the ResNet. Experimental results demonstrate that the proposed\nhierarchical auxiliary learning can reduce classification errors up to 0.56,\n1.6 and 3.56 percent with MNIST, SVHN and CIFAR-10 datasets, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:01:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cha", "Jaehoon", ""], ["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""]]}, {"id": "1906.00855", "submitter": "Di Chen", "authors": "Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John M. Gregoire,\n  Carla P. Gomes", "title": "Deep Reasoning Networks: Thinking Fast and Slow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Reasoning Networks (DRNets), an end-to-end framework that\ncombines deep learning with reasoning for solving complex tasks, typically in\nan unsupervised or weakly-supervised setting. DRNets exploit problem structure\nand prior knowledge by tightly combining logic and constraint reasoning with\nstochastic-gradient-based neural network optimization. We illustrate the power\nof DRNets on de-mixing overlapping hand-written Sudokus (Multi-MNIST-Sudoku)\nand on a substantially more complex task in scientific discovery that concerns\ninferring crystal structures of materials from X-ray diffraction data under\nthermodynamic rules (Crystal-Structure-Phase-Mapping). At a high level, DRNets\nencode a structured latent space of the input data, which is constrained to\nadhere to prior knowledge by a reasoning module. The structured latent encoding\nis used by a generative decoder to generate the targeted output. Finally, an\noverall objective combines responses from the generative decoder (thinking\nfast) and the reasoning module (thinking slow), which is optimized using\nconstraint-aware stochastic gradient descent. We show how to encode different\ntasks as DRNets and demonstrate DRNets' effectiveness with detailed\nexperiments: DRNets significantly outperform the state of the art and experts'\ncapabilities on Crystal-Structure-Phase-Mapping, recovering more precise and\nphysically meaningful crystal structures. On Multi-MNIST-Sudoku, DRNets\nperfectly recovered the mixed Sudokus' digits, with 100% digit accuracy,\noutperforming the supervised state-of-the-art MNIST de-mixing models. Finally,\nas a proof of concept, we also show how DRNets can solve standard combinatorial\nproblems -- 9-by-9 Sudoku puzzles and Boolean satisfiability problems (SAT),\noutperforming other specialized deep learning models. DRNets are general and\ncan be adapted and expanded to tackle other tasks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:09:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 15:41:03 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chen", "Di", ""], ["Bai", "Yiwei", ""], ["Zhao", "Wenting", ""], ["Ament", "Sebastian", ""], ["Gregoire", "John M.", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1906.00859", "submitter": "Elliot J. Crowley", "authors": "Gavin Gray, Elliot J. Crowley, Amos Storkey", "title": "Separable Layers Enable Structured Efficient Linear Substitutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In response to the development of recent efficient dense layers, this paper\nshows that something as simple as replacing linear components in pointwise\nconvolutions with structured linear decompositions also produces substantial\ngains in the efficiency/accuracy tradeoff. Pointwise convolutions are fully\nconnected layers and are thus prepared for replacement by structured\ntransforms. Networks using such layers are able to learn the same tasks as\nthose using standard convolutions, and provide Pareto-optimal benefits in\nefficiency/accuracy, both in terms of computation (mult-adds) and parameter\ncount (and hence memory). Code is available at\nhttps://github.com/BayesWatch/deficient-efficient.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:12:33 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Gray", "Gavin", ""], ["Crowley", "Elliot J.", ""], ["Storkey", "Amos", ""]]}, {"id": "1906.00904", "submitter": "Boris Hanin", "authors": "Boris Hanin, David Rolnick", "title": "Deep ReLU Networks Have Surprisingly Few Activation Patterns", "comments": "18 page, 7 figures", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep networks has been attributed in part to their\nexpressivity: per parameter, deep networks can approximate a richer class of\nfunctions than shallow networks. In ReLU networks, the number of activation\npatterns is one measure of expressivity; and the maximum number of patterns\ngrows exponentially with the depth. However, recent work has showed that the\npractical expressivity of deep networks - the functions they can learn rather\nthan express - is often far from the theoretical maximum. In this paper, we\nshow that the average number of activation patterns for ReLU networks at\ninitialization is bounded by the total number of neurons raised to the input\ndimension. We show empirically that this bound, which is independent of the\ndepth, is tight both at initialization and during training, even on\nmemorization tasks that should maximize the number of activation patterns. Our\nwork suggests that realizing the full expressivity of deep networks may not be\npossible in practice, at least with current methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:13:15 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 16:26:04 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hanin", "Boris", ""], ["Rolnick", "David", ""]]}, {"id": "1906.00910", "submitter": "Philip Bachman", "authors": "Philip Bachman and R Devon Hjelm and William Buchwalter", "title": "Learning Representations by Maximizing Mutual Information Across Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to self-supervised representation learning based on\nmaximizing mutual information between features extracted from multiple views of\na shared context. For example, one could produce multiple views of a local\nspatio-temporal context by observing it from different locations (e.g., camera\npositions within a scene), and via different modalities (e.g., tactile,\nauditory, or visual). Or, an ImageNet image could provide a context from which\none produces multiple views by repeatedly applying data augmentation.\nMaximizing mutual information between features extracted from these views\nrequires capturing information about high-level factors whose influence spans\nmultiple views -- e.g., presence of certain objects or occurrence of certain\nevents.\n  Following our proposed approach, we develop a model which learns image\nrepresentations that significantly outperform prior methods on the tasks we\nconsider. Most notably, using self-supervised learning, our model learns\nrepresentations which achieve 68.1% accuracy on ImageNet using standard linear\nevaluation. This beats prior results by over 12% and concurrent results by 7%.\nWhen we extend our model to use mixture-based representations, segmentation\nbehaviour emerges as a natural side-effect. Our code is available online:\nhttps://github.com/Philip-Bachman/amdim-public.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:24:57 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 16:41:31 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Bachman", "Philip", ""], ["Hjelm", "R Devon", ""], ["Buchwalter", "William", ""]]}, {"id": "1906.00912", "submitter": "Georg Krempl", "authors": "Georg Krempl and Dominik Lang and Vera Hofer", "title": "Temporal Density Extrapolation using a Dynamic Basis Approach", "comments": "Accepted for publication in Data Mining and Knowledge Discovery,\n  Special issue of the ECML/PKDD 2019 Journal Track, Springer, 2019", "journal-ref": "Data Mining and Knowledge Discovery 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is a versatile technique underlying many data mining tasks\nand techniques,ranging from exploration and presentation of static data, to\nprobabilistic classification, or identifying changes or irregularities in\nstreaming data. With the pervasiveness of embedded systems and digitisation,\nthis latter type of streaming and evolving data becomes more important.\nNevertheless, research in density estimation has so far focused on stationary\ndata, leaving the task of of extrapolating and predicting density at time\npoints outside a training window an open problem. For this task, Temporal\nDensity Extrapolation (TDX) is proposed. This novel method models and predicts\ngradual monotonous changes in a distribution. It is based on the expansion of\nbasis functions, whose weights are modelled as functions of compositional data\nover time by using an isometric log-ratio transformation. Extrapolated density\nestimates are then obtained by extrapolating the weights to the requested time\npoint, and querying the density from the basis functions with back-transformed\nweights. Our approach aims for broad applicability by neither being restricted\nto a specific parametric distribution, nor relying on cluster structure in the\ndata.It requires only two additional extrapolation-specific parameters, for\nwhich reasonable defaults exist. Experimental evaluation on various data\nstreams, synthetic as well as from the real-world domains of credit scoring and\nenvironmental health, shows that the model manages to capture monotonous drift\npatterns accurately and better than existing methods. Thereby, it requires not\nmore than 1.5-times the run time of a corresponding static density estimation\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:29:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Krempl", "Georg", ""], ["Lang", "Dominik", ""], ["Hofer", "Vera", ""]]}, {"id": "1906.00917", "submitter": "Yichang Wang", "authors": "Yichang Wang, R\\'emi Emonet, Elisa Fromont, Simon Malinowski, Etienne\n  Menager, Lo\\\"ic Mosser, Romain Tavenard", "title": "Learning Interpretable Shapelets for Time Series Classification through\n  Adversarial Regularization", "comments": "submitted to CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Times series classification can be successfully tackled by jointly learning a\nshapelet-based representation of the series in the dataset and classifying the\nseries according to this representation. However, although the learned\nshapelets are discriminative, they are not always similar to pieces of a real\nseries in the dataset. This makes it difficult to interpret the decision, i.e.\ndifficult to analyze if there are particular behaviors in a series that\ntriggered the decision. In this paper, we make use of a simple convolutional\nnetwork to tackle the time series classification task and we introduce an\nadversarial regularization to constrain the model to learn more interpretable\nshapelets. Our classification results on all the usual time series benchmarks\nare comparable with the results obtained by similar state-of-the-art algorithms\nbut our adversarially regularized method learns shapelets that are, by design,\ninterpretable.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:38:20 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:44:17 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wang", "Yichang", ""], ["Emonet", "R\u00e9mi", ""], ["Fromont", "Elisa", ""], ["Malinowski", "Simon", ""], ["Menager", "Etienne", ""], ["Mosser", "Lo\u00efc", ""], ["Tavenard", "Romain", ""]]}, {"id": "1906.00923", "submitter": "Michael Fromm", "authors": "Michael Fromm, Evgeniy Faerman, Thomas Seidl", "title": "TACAM: Topic And Context Aware Argument Mining", "comments": null, "journal-ref": null, "doi": "10.1145/3350546.3352506", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the problem of argument search. The purpose of\nargument search is the distillation of pro and contra arguments for requested\ntopics from large text corpora. In previous works, the usual approach is to use\na standard search engine to extract text parts which are relevant to the given\ntopic and subsequently use an argument recognition algorithm to select\narguments from them. The main challenge in the argument recognition task, which\nis also known as argument mining, is that often sentences containing arguments\nare structurally similar to purely informative sentences without any stance\nabout the topic. In fact, they only differ semantically. Most approaches use\ntopic or search term information only for the first search step and therefore\nassume that arguments can be classified independently of a topic. We argue that\ntopic information is crucial for argument mining, since the topic defines the\nsemantic context of an argument. Precisely, we propose different models for the\nclassification of arguments, which take information about a topic of an\nargument into account. Moreover, to enrich the context of a topic and to let\nmodels understand the context of the potential argument better, we integrate\ninformation from different external sources such as Knowledge Graphs or\npre-trained NLP models. Our evaluation shows that considering topic\ninformation, especially in connection with external information, provides a\nsignificant performance boost for the argument mining task.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:06:58 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 12:33:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Fromm", "Michael", ""], ["Faerman", "Evgeniy", ""], ["Seidl", "Thomas", ""]]}, {"id": "1906.00930", "submitter": "Moshe Shenfeld", "authors": "Katrina Ligett and Moshe Shenfeld", "title": "A necessary and sufficient stability notion for adaptive generalization", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems 2019 (pp.\n  11481-11490)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of the stability of computations, which holds under\npost-processing and adaptive composition. We show that the notion is both\nnecessary and sufficient to ensure generalization in the face of adaptivity,\nfor any computations that respond to bounded-sensitivity linear queries while\nproviding accuracy with respect to the data sample set. The stability notion is\nbased on quantifying the effect of observing a computation's outputs on the\nposterior over the data sample elements. We show a separation between this\nstability notion and previously studied notion and observe that all\ndifferentially private algorithms also satisfy this notion.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:07:44 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 17:16:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Ligett", "Katrina", ""], ["Shenfeld", "Moshe", ""]]}, {"id": "1906.00932", "submitter": "Miguel Alonso Jr", "authors": "Miguel Alonso Jr", "title": "Y-GAN: A Generative Adversarial Network for Depthmap Estimation from\n  Multi-camera Stereo Images", "comments": "Accepted for Presentation at the ICML 2019 LatinX in AI Research\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth perception is a key component for autonomous systems that interact in\nthe real world, such as delivery robots, warehouse robots, and self-driving\ncars. Tasks in autonomous robotics such as 3D object recognition, simultaneous\nlocalization and mapping (SLAM), path planning and navigation, require some\nform of 3D spatial information. Depth perception is a long-standing research\nproblem in computer vision and robotics and has had a long history. Many\napproaches using deep learning, ranging from structure from motion,\nshape-from-X, monocular, binocular, and multi-view stereo, have yielded\nacceptable results. However, there are several shortcomings of these methods\nsuch as requiring expensive hardware, needing supervised training data, no\nground truth data for comparison, and disregard for occlusion. In order to\naddress these shortcomings, this work proposes a new deep convolutional\ngenerative adversarial network architecture, called Y-GAN, that uses data from\nthree cameras to estimate a depth map for each frame in a multi-camera video\nstream.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:11:18 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Alonso", "Miguel", "Jr"]]}, {"id": "1906.00938", "submitter": "Feiyu Chen", "authors": "Feiyu Chen, Yuchen Yang, Liwei Xu, Taiping Zhang, Yin Zhang", "title": "Big-Data Clustering: K-Means or K-Indicators?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The K-means algorithm is arguably the most popular data clustering method,\ncommonly applied to processed datasets in some \"feature spaces\", as is in\nspectral clustering. Highly sensitive to initializations, however, K-means\nencounters a scalability bottleneck with respect to the number of clusters K as\nthis number grows in big data applications. In this work, we promote a closely\nrelated model called K-indicators model and construct an efficient,\nsemi-convex-relaxation algorithm that requires no randomized initializations.\nWe present extensive empirical results to show advantages of the new algorithm\nwhen K is large. In particular, using the new algorithm to start the K-means\nalgorithm, without any replication, can significantly outperform the standard\nK-means with a large number of currently state-of-the-art random replications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:30:24 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Feiyu", ""], ["Yang", "Yuchen", ""], ["Xu", "Liwei", ""], ["Zhang", "Taiping", ""], ["Zhang", "Yin", ""]]}, {"id": "1906.00939", "submitter": "Panagiotis Papapetrou", "authors": "Amin Azari, Panagiotis Papapetrou, Stojan Denic, and Gunnar Peters", "title": "Cellular Traffic Prediction and Classification: a comparative evaluation\n  of LSTM and ARIMA", "comments": "arXiv admin note: text overlap with arXiv:1906.00951", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of user traffic in cellular networks has attracted profound\nattention for improving resource utilization. In this paper, we study the\nproblem of network traffic traffic prediction and classification by employing\nstandard machine learning and statistical learning time series prediction\nmethods, including long short-term memory (LSTM) and autoregressive integrated\nmoving average (ARIMA), respectively. We present an extensive experimental\nevaluation of the designed tools over a real network traffic dataset. Within\nthis analysis, we explore the impact of different parameters to the\neffectiveness of the predictions. We further extend our analysis to the problem\nof network traffic classification and prediction of traffic bursts. The\nresults, on the one hand, demonstrate superior performance of LSTM over ARIMA\nin general, especially when the length of the training time series is high\nenough, and it is augmented by a wisely-selected set of features. On the other\nhand, the results shed light on the circumstances in which, ARIMA performs\nclose to the optimal with lower complexity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:31:16 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Azari", "Amin", ""], ["Papapetrou", "Panagiotis", ""], ["Denic", "Stojan", ""], ["Peters", "Gunnar", ""]]}, {"id": "1906.00945", "submitter": "Dimitris Tsipras", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras,\n  Brandon Tran, Aleksander Madry", "title": "Adversarial Robustness as a Prior for Learned Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important goal in deep learning is to learn versatile, high-level feature\nrepresentations of input data. However, standard networks' representations seem\nto possess shortcomings that, as we illustrate, prevent them from fully\nrealizing this goal. In this work, we show that robust optimization can be\nre-cast as a tool for enforcing priors on the features learned by deep neural\nnetworks. It turns out that representations learned by robust models address\nthe aforementioned shortcomings and make significant progress towards learning\na high-level encoding of inputs. In particular, these representations are\napproximately invertible, while allowing for direct visualization and\nmanipulation of salient input features. More broadly, our results indicate\nadversarial robustness as a promising avenue for improving learned\nrepresentations. Our code and models for reproducing these results is available\nat https://git.io/robust-reps .\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:55:20 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 17:39:54 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Tran", "Brandon", ""], ["Madry", "Aleksander", ""]]}, {"id": "1906.00949", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Justin Fu, George Tucker, Sergey Levine", "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction", "comments": "Accepted at NeurIPS 2019; Project Website:\n  https://sites.google.com/view/bear-off-policyrl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning aims to leverage experience collected from\nprior policies for sample-efficient learning. However, in practice, commonly\nused off-policy approximate dynamic programming methods based on Q-learning and\nactor-critic methods are highly sensitive to the data distribution, and can\nmake only limited progress without collecting additional on-policy data. As a\nstep towards more robust off-policy algorithms, we study the setting where the\noff-policy experience is fixed and there is no further interaction with the\nenvironment. We identify bootstrapping error as a key source of instability in\ncurrent methods. Bootstrapping error is due to bootstrapping from actions that\nlie outside of the training data distribution, and it accumulates via the\nBellman backup operator. We theoretically analyze bootstrapping error, and\ndemonstrate how carefully constraining action selection in the backup can\nmitigate it. Based on our analysis, we propose a practical algorithm,\nbootstrapping error accumulation reduction (BEAR). We demonstrate that BEAR is\nable to learn robustly from different off-policy distributions, including\nrandom and suboptimal demonstrations, on a range of continuous control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:59:10 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 18:52:33 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kumar", "Aviral", ""], ["Fu", "Justin", ""], ["Tucker", "George", ""], ["Levine", "Sergey", ""]]}, {"id": "1906.00951", "submitter": "Amin Azari", "authors": "Amin Azari, Panagiotis Papapetrou, Stojan Denic, and Gunnar Peters", "title": "User Traffic Prediction for Proactive Resource Management:\n  Learning-Powered Approaches", "comments": "arXiv admin note: text overlap with arXiv:1906.00939", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic prediction plays a vital role in efficient planning and usage of\nnetwork resources in wireless networks. While traffic prediction in wired\nnetworks is an established field, there is a lack of research on the analysis\nof traffic in cellular networks, especially in a content-blind manner at the\nuser level. Here, we shed light into this problem by designing traffic\nprediction tools that employ either statistical, rule-based, or deep machine\nlearning methods. First, we present an extensive experimental evaluation of the\ndesigned tools over a real traffic dataset. Within this analysis, the impact of\ndifferent parameters, such as length of prediction, feature set used in\nanalyses, and granularity of data, on accuracy of prediction are investigated.\nSecond, regarding the coupling observed between behavior of traffic and its\ngenerating application, we extend our analysis to the blind classification of\napplications generating the traffic based on the statistics of traffic\narrival/departure. The results demonstrate presence of a threshold number of\nprevious observations, beyond which, deep machine learning can outperform\nlinear statistical learning, and before which, statistical learning outperforms\ndeep learning approaches. Further analysis of this threshold value represents a\nstrong coupling between this threshold, the length of future prediction, and\nthe feature set in use. Finally, through a case study, we present how the\nexperienced delay could be decreased by traffic arrival prediction.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:56:51 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Azari", "Amin", ""], ["Papapetrou", "Panagiotis", ""], ["Denic", "Stojan", ""], ["Peters", "Gunnar", ""]]}, {"id": "1906.00957", "submitter": "Niklas Wolf Andreas Gebauer", "authors": "Niklas W. A. Gebauer and Michael Gastegger and Kristof T. Sch\\\"utt", "title": "Symmetry-adapted generation of 3d point sets for the targeted discovery\n  of molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has proven to yield fast and accurate predictions of\nquantum-chemical properties to accelerate the discovery of novel molecules and\nmaterials. As an exhaustive exploration of the vast chemical space is still\ninfeasible, we require generative models that guide our search towards systems\nwith desired properties. While graph-based models have previously been\nproposed, they are restricted by a lack of spatial information such that they\nare unable to recognize spatial isomerism and non-bonded interactions. Here, we\nintroduce a generative neural network for 3d point sets that respects the\nrotational invariance of the targeted structures. We apply it to the generation\nof molecules and demonstrate its ability to approximate the distribution of\nequilibrium structures using spatial metrics as well as established measures\nfrom chemoinformatics. As our model is able to capture the complex relationship\nbetween 3d geometry and electronic properties, we bias the distribution of the\ngenerator towards molecules with a small HOMO-LUMO gap - an important property\nfor the design of organic solar cells.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 11:27:28 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 14:32:05 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 15:36:21 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Gebauer", "Niklas W. A.", ""], ["Gastegger", "Michael", ""], ["Sch\u00fctt", "Kristof T.", ""]]}, {"id": "1906.01004", "submitter": "Yan Zhang", "authors": "Yan Zhang, Krikamol Muandet, Qianli Ma, Heiko Neumann and Siyu Tang", "title": "Frontal Low-rank Random Tensors for Fine-grained Action Segmentation", "comments": "19 pages (4 pages appendix), 3 figures. Revised theories and models,\n  new experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained action segmentation in long untrimmed videos is an important\ntask for many applications such as surveillance, robotics, and human-computer\ninteraction. To understand subtle and precise actions within a long time\nperiod, second-order information (e.g. feature covariance) or higher is\nreported to be effective in the literature. However, extracting such high-order\ninformation is considerably non-trivial. In particular, the dimensionality\nincreases exponentially with the information order, and hence gaining more\nrepresentation power also increases the computational cost and the risk of\noverfitting. In this paper, we propose an approach to representing high-order\ninformation for temporal action segmentation via a simple yet effective\nbilinear form. Specifically, our contributions are: (1) From the multilinear\nperspective, we derive a bilinear form of low complexity, assuming that the\nthree-way tensor has low-rank frontal slices. (2) Rather than learning the\ntensor entries from data, we sample the entries from different underlying\ndistributions, and prove that the underlying distribution influences the\ninformation order. (3) We employed our bilinear form as an intermediate layer\nin state-of-the-art deep neural networks, enabling to represent high-order\ninformation in complex deep models effectively and efficiently. Our\nexperimental results demonstrate that the proposed bilinear form outperforms\nthe previous state-of-the-art methods on the challenging temporal action\nsegmentation task. One can see our project page for data, model and code:\n\\url{https://vlg.inf.ethz.ch/projects/BilinearTCN/}.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:12:26 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:42:57 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Yan", ""], ["Muandet", "Krikamol", ""], ["Ma", "Qianli", ""], ["Neumann", "Heiko", ""], ["Tang", "Siyu", ""]]}, {"id": "1906.01005", "submitter": "Ian Jordan", "authors": "Ian D. Jordan, Piotr Aleksander Sokol, Il Memming Park", "title": "Gated recurrent units viewed through the lens of continuous time\n  dynamical systems", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience, 2021", "doi": "10.3389/fncom.2021.678158", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gated recurrent units (GRUs) are specialized memory elements for building\nrecurrent neural networks. Despite their incredible success on various tasks,\nincluding extracting dynamics underlying neural data, little is understood\nabout the specific dynamics representable in a GRU network. As a result, it is\nboth difficult to know a priori how successful a GRU network will perform on a\ngiven task, and also their capacity to mimic the underlying behavior of their\nbiological counterparts. Using a continuous time analysis, we gain intuition on\nthe inner workings of GRU networks. We restrict our presentation to low\ndimensions, allowing for a comprehensive visualization. We found a surprisingly\nrich repertoire of dynamical features that includes stable limit cycles\n(nonlinear oscillations), multi-stable dynamics with various topologies, and\nhomoclinic bifurcations. At the same time we were unable to train GRU networks\nto produce continuous attractors, which are hypothesized to exist in biological\nneural networks. We contextualize the usefulness of different kinds of observed\ndynamics and support our claims experimentally.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:13:32 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 02:50:50 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jordan", "Ian D.", ""], ["Sokol", "Piotr Aleksander", ""], ["Park", "Il Memming", ""]]}, {"id": "1906.01009", "submitter": "Emmanouil Zampetakis", "authors": "R\\'obert Busa-Fekete and Dimitris Fotakis and Bal\\'azs Sz\\\"or\\'enyi\n  and Manolis Zampetakis", "title": "Optimal Learning of Mallows Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mallows model, introduced in the seminal paper of Mallows 1957, is one of\nthe most fundamental ranking distribution over the symmetric group $S_m$. To\nanalyze more complex ranking data, several studies considered the Generalized\nMallows model defined by Fligner and Verducci 1986. Despite the significant\nresearch interest of ranking distributions, the exact sample complexity of\nestimating the parameters of a Mallows and a Generalized Mallows Model is not\nwell-understood. The main result of the paper is a tight sample complexity\nbound for learning Mallows and Generalized Mallows Model. We approach the\nlearning problem by analyzing a more general model which interpolates between\nthe single parameter Mallows Model and the $m$ parameter Mallows model. We call\nour model Mallows Block Model -- referring to the Block Models that are a\npopular model in theoretical statistics. Our sample complexity analysis gives\ntight bound for learning the Mallows Block Model for any number of blocks. We\nprovide essentially matching lower bounds for our sample complexity results. As\na corollary of our analysis, it turns out that, if the central ranking is\nknown, one single sample from the Mallows Block Model is sufficient to estimate\nthe spread parameters with error that goes to zero as the size of the\npermutations goes to infinity. In addition, we calculate the exact rate of the\nparameter estimation error.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:17:00 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Busa-Fekete", "R\u00f3bert", ""], ["Fotakis", "Dimitris", ""], ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1906.01021", "submitter": "Alexander Cloninger", "authors": "Saeed Vahidian and Baharan Mirzasoleiman and Alexander Cloninger", "title": "Coresets for Estimating Means and Mean Square Error with Limited Greedy\n  Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a number of situations, collecting a function value for every data point\nmay be prohibitively expensive, and random sampling ignores any structure in\nthe underlying data. We introduce a scalable optimization algorithm with no\ncorrection steps (in contrast to Frank-Wolfe and its variants), a variant of\ngradient ascent for coreset selection in graphs, that greedily selects a\nweighted subset of vertices that are deemed most important to sample. Our\nalgorithm estimates the mean of the function by taking a weighted sum only at\nthese vertices, and we provably bound the estimation error in terms of the\nlocation and weights of the selected vertices in the graph. In addition, we\nconsider the case where nodes have different selection costs and provide bounds\non the quality of the low-cost selected coresets. We demonstrate the benefits\nof our algorithm on the semi-supervised node classification of graph\nconvolutional neural network, point clouds and structured graphs, as well as\nsensor placement where the cost of placing sensors depends on the location of\nthe placement. We also elucidate that the empirical convergence of our proposed\nmethod is faster than random selection and various clustering methods while\nstill respecting sensor placement cost. The paper concludes with validation of\nthe developed algorithm on both synthetic and real datasets, demonstrating that\nit outperforms the current state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:46:26 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 17:32:07 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 17:39:40 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Vahidian", "Saeed", ""], ["Mirzasoleiman", "Baharan", ""], ["Cloninger", "Alexander", ""]]}, {"id": "1906.01026", "submitter": "Louis Jensen", "authors": "Louis Jensen, Jacob Harer, Sang Chin", "title": "NodeDrop: A Condition for Reducing Network Size without Effect on Output", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining an appropriate number of features for each layer in a neural\nnetwork is an important and difficult task. This task is especially important\nin applications on systems with limited memory or processing power. Many\ncurrent approaches to reduce network size either utilize iterative procedures,\nwhich can extend training time significantly, or require very careful tuning of\nalgorithm parameters to achieve reasonable results. In this paper we propose\nNodeDrop, a new method for eliminating features in a network. With NodeDrop, we\ndefine a condition to identify and guarantee which nodes carry no information,\nand then use regularization to encourage nodes to meet this condition. We find\nthat NodeDrop drastically reduces the number of features in a network while\nmaintaining high performance, reducing the number of parameters by a factor of\n114x for a VGG like network on CIFAR10 without a drop in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:03:46 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:22:51 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Jensen", "Louis", ""], ["Harer", "Jacob", ""], ["Chin", "Sang", ""]]}, {"id": "1906.01030", "submitter": "Yichen Yang", "authors": "Yichen Yang, Martin Rinard", "title": "Correctness Verification of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first verification that a neural network produces a correct\noutput within a specified tolerance for every input of interest. We define\ncorrectness relative to a specification which identifies 1) a state space\nconsisting of all relevant states of the world and 2) an observation process\nthat produces neural network inputs from the states of the world. Tiling the\nstate and input spaces with a finite number of tiles, obtaining ground truth\nbounds from the state tiles and network output bounds from the input tiles,\nthen comparing the ground truth and network output bounds delivers an upper\nbound on the network output error for any input of interest. Results from a\ncase study highlight the ability of our technique to deliver tight error bounds\nfor all inputs of interest and show how the error bounds vary over the state\nand input spaces.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:13:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 16:03:29 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yang", "Yichen", ""], ["Rinard", "Martin", ""]]}, {"id": "1906.01032", "submitter": "Ben Gelman", "authors": "Ben Gelman, Bryan Hoyle, Jessica Moore, Joshua Saxe, David Slater", "title": "A Language-Agnostic Model for Semantic Source Code Labeling", "comments": "MASES 2018 Publication", "journal-ref": null, "doi": "10.1145/3243127.3243132", "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code search and comprehension have become more difficult in recent years due\nto the rapid expansion of available source code. Current tools lack a way to\nlabel arbitrary code at scale while maintaining up-to-date representations of\nnew programming languages, libraries, and functionalities. Comprehensive\nlabeling of source code enables users to search for documents of interest and\nobtain a high-level understanding of their contents. We use Stack Overflow code\nsnippets and their tags to train a language-agnostic, deep convolutional neural\nnetwork to automatically predict semantic labels for source code documents. On\nStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957\nover a long-tailed list of 4,508 tags. We also manually validate the model\noutputs on a diverse set of unlabeled source code documents retrieved from\nGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates that\nthe model successfully transfers its knowledge from Stack Overflow snippets to\narbitrary source code documents.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:21:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Gelman", "Ben", ""], ["Hoyle", "Bryan", ""], ["Moore", "Jessica", ""], ["Saxe", "Joshua", ""], ["Slater", "David", ""]]}, {"id": "1906.01035", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Klaus Greff, J\\\"urgen Schmidhuber", "title": "A Perspective on Objects and Systematic Generalization in Model-Based RL", "comments": "Accepted to the ICML 2019 workshop on Workshop on Generative Modeling\n  and Model-Based Reasoning for Robotics and AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to meet the diverse challenges in solving many real-world problems,\nan intelligent agent has to be able to dynamically construct a model of its\nenvironment. Objects facilitate the modular reuse of prior knowledge and the\ncombinatorial construction of such models. In this work, we argue that\ndynamically bound features (objects) do not simply emerge in connectionist\nmodels of the world. We identify several requirements that need to be fulfilled\nin overcoming this limitation and highlight corresponding inductive biases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:29:12 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Greff", "Klaus", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1906.01040", "submitter": "Melody Guan", "authors": "Melody Y. Guan, Gregory Valiant", "title": "A Surprising Density of Illusionable Natural Speech", "comments": "CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on adversarial examples has demonstrated that most natural inputs\ncan be perturbed to fool even state-of-the-art machine learning systems. But\ndoes this happen for humans as well? In this work, we investigate: what\nfraction of natural instances of speech can be turned into \"illusions\" which\neither alter humans' perception or result in different people having\nsignificantly different perceptions? We first consider the McGurk effect, the\nphenomenon by which adding a carefully chosen video clip to the audio channel\naffects the viewer's perception of what is said (McGurk and MacDonald, 1976).\nWe obtain empirical estimates that a significant fraction of both words and\nsentences occurring in natural speech have some susceptibility to this effect.\nWe also learn models for predicting McGurk illusionability. Finally we\ndemonstrate that the Yanny or Laurel auditory illusion (Pressnitzer et al.,\n2018) is not an isolated occurrence by generating several very different new\ninstances. We believe that the surprising density of illusionable natural\nspeech warrants further investigation, from the perspectives of both security\nand cognitive science. Supplementary videos are available at:\nhttps://www.youtube.com/playlist?list=PLaX7t1K-e_fF2iaenoKznCatm0RC37B_k.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:33:43 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 00:37:28 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 05:52:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Guan", "Melody Y.", ""], ["Valiant", "Gregory", ""]]}, {"id": "1906.01044", "submitter": "Junxiang Chen", "authors": "Junxiang Chen, Kayhan Batmanghelich", "title": "Weakly Supervised Disentanglement by Pairwise Similarities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researches related to unsupervised disentanglement learning with\ndeep generative models have gained substantial popularity. However, without\nintroducing supervision, there is no guarantee that the factors of interest can\nbe successfully recovered. Motivated by a real-world problem, we propose a\nsetting where the user introduces weak supervision by providing similarities\nbetween instances based on a factor to be disentangled. The similarity is\nprovided as either a binary (yes/no) or a real-valued label describing whether\na pair of instances are similar or not. We propose a new method for weakly\nsupervised disentanglement of latent variables within the framework of\nVariational Autoencoder. Experimental results demonstrate that utilizing weak\nsupervision improves the performance of the disentanglement method\nsubstantially.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:38:14 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 23:20:08 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Chen", "Junxiang", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1906.01076", "submitter": "Dani Yogatama", "authors": "Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, Dani\n  Yogatama", "title": "Episodic Memory in Lifelong Language Learning", "comments": "Proceedings of NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a lifelong language learning setup where a model needs to learn\nfrom a stream of text examples without any dataset identifier. We propose an\nepisodic memory model that performs sparse experience replay and local\nadaptation to mitigate catastrophic forgetting in this setup. Experiments on\ntext classification and question answering demonstrate the complementary\nbenefits of sparse experience replay and local adaptation to allow the model to\ncontinuously learn from new datasets. We also show that the space complexity of\nthe episodic memory module can be reduced significantly (~50-90%) by randomly\nchoosing which examples to store in memory with a minimal decrease in\nperformance. We consider an episodic memory component as a crucial building\nblock of general linguistic intelligence and see our model as a first step in\nthat direction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 20:50:58 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:33:28 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 00:57:40 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["d'Autume", "Cyprien de Masson", ""], ["Ruder", "Sebastian", ""], ["Kong", "Lingpeng", ""], ["Yogatama", "Dani", ""]]}, {"id": "1906.01078", "submitter": "Jyun-Yi Wu", "authors": "Jyun-Yi Wu, Cheng Yu, Szu-Wei Fu, Chih-Ting Liu, Shao-Yi Chien, and Yu\n  Tsao", "title": "Increasing Compactness Of Deep Learning Based Speech Enhancement Models\n  With Parameter Pruning And Quantization Techniques", "comments": "4pages, 6 figures", "journal-ref": null, "doi": "10.1109/LSP.2019.2951950", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent studies on deep learning based speech enhancement (SE) focused on\nimproving denoising performance. However, successful SE applications require\nstriking a desirable balance between denoising performance and computational\ncost in real scenarios. In this study, we propose a novel parameter pruning\n(PP) technique, which removes redundant channels in a neural network. In\naddition, a parameter quantization (PQ) technique was applied to reduce the\nsize of a neural network by representing weights with fewer cluster centroids.\nBecause the techniques are derived based on different concepts, the PP and PQ\ncan be integrated to provide even more compact SE models. The experimental\nresults show that the PP and PQ techniques produce a compacted SE model with a\nsize of only 10.03% compared to that of the original model, resulting in minor\nperformance losses of 1.43% (from 0.70 to 0.69) for STOI and 3.24% (from 1.85\nto 1.79) for PESQ. The promising results suggest that the PP and PQ techniques\ncan be used in a SE system in devices with limited storage and computation\nresources.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 04:07:20 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 18:22:51 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wu", "Jyun-Yi", ""], ["Yu", "Cheng", ""], ["Fu", "Szu-Wei", ""], ["Liu", "Chih-Ting", ""], ["Chien", "Shao-Yi", ""], ["Tsao", "Yu", ""]]}, {"id": "1906.01083", "submitter": "Sean Vasquez", "authors": "Sean Vasquez, Mike Lewis", "title": "MelNet: A Generative Model for Audio in the Frequency Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing high-level structure in audio waveforms is challenging because a\nsingle second of audio spans tens of thousands of timesteps. While long-range\ndependencies are difficult to model directly in the time domain, we show that\nthey can be more tractably modelled in two-dimensional time-frequency\nrepresentations such as spectrograms. By leveraging this representational\nadvantage, in conjunction with a highly expressive probabilistic model and a\nmultiscale generation procedure, we design a model capable of generating\nhigh-fidelity audio samples which capture structure at timescales that\ntime-domain models have yet to achieve. We apply our model to a variety of\naudio generation tasks, including unconditional speech generation, music\ngeneration, and text-to-speech synthesis---showing improvements over previous\napproaches in both density estimates and human judgments.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:58:19 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Vasquez", "Sean", ""], ["Lewis", "Mike", ""]]}, {"id": "1906.01095", "submitter": "Ming Lin", "authors": "Ming Lin, Xiaomin Song, Qi Qian, Hao Li, Liang Sun, Shenghuo Zhu, Rong\n  Jin", "title": "Robust Gaussian Process Regression for Real-Time High Precision GPS\n  Signal Enhancement", "comments": "accepted by SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite-based positioning system such as GPS often suffers from large\namount of noise that degrades the positioning accuracy dramatically especially\nin real-time applications. In this work, we consider a data-mining approach to\nenhance the GPS signal. We build a large-scale high precision GPS receiver grid\nsystem to collect real-time GPS signals for training. The Gaussian Process (GP)\nregression is chosen to model the vertical Total Electron Content (vTEC)\ndistribution of the ionosphere of the Earth. Our experiments show that the\nnoise in the real-time GPS signals often exceeds the breakdown point of the\nconventional robust regression methods resulting in sub-optimal system\nperformance. We propose a three-step approach to address this challenge. In the\nfirst step we perform a set of signal validity tests to separate the signals\ninto clean and dirty groups. In the second step, we train an initial model on\nthe clean signals and then reweigting the dirty signals based on the residual\nerror. A final model is retrained on both the clean signals and the reweighted\ndirty signals. In the theoretical analysis, we prove that the proposed\nthree-step approach is able to tolerate much higher noise level than the\nvanilla robust regression methods if two reweighting rules are followed. We\nvalidate the superiority of the proposed method in our real-time high precision\npositioning system against several popular state-of-the-art robust regression\nmethods. Our method achieves centimeter positioning accuracy in the benchmark\nregion with probability $78.4\\%$ , outperforming the second best baseline\nmethod by a margin of $8.3\\%$. The benchmark takes 6 hours on 20,000 CPU cores\nor 14 years on a single CPU.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 21:57:53 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lin", "Ming", ""], ["Song", "Xiaomin", ""], ["Qian", "Qi", ""], ["Li", "Hao", ""], ["Sun", "Liang", ""], ["Zhu", "Shenghuo", ""], ["Jin", "Rong", ""]]}, {"id": "1906.01101", "submitter": "Binxin Ru", "authors": "Diego Granziol, Binxin Ru, Stefan Zohren, Xiaowen Doing, Michael\n  Osborne and Stephen Roberts", "title": "MEMe: An Accurate Maximum Entropy Method for Efficient Approximations in\n  Large-Scale Machine Learning", "comments": "18 pages, 3 figures, Published at Entropy 2019: Special Issue Entropy\n  Based Inference and Optimization in Machine Learning", "journal-ref": "MEMe: An Accurate Maximum Entropy Method for Efficient\n  Approximations in Large-Scale Machine Learning. Entropy, 21(6), 551 (2019)", "doi": "10.3390/e21060551", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient approximation lies at the heart of large-scale machine learning\nproblems. In this paper, we propose a novel, robust maximum entropy algorithm,\nwhich is capable of dealing with hundreds of moments and allows for\ncomputationally efficient approximations. We showcase the usefulness of the\nproposed method, its equivalence to constrained Bayesian variational inference\nand demonstrate its superiority over existing approaches in two applications,\nnamely, fast log determinant estimation and information-theoretic Bayesian\noptimisation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:10:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Granziol", "Diego", ""], ["Ru", "Binxin", ""], ["Zohren", "Stefan", ""], ["Doing", "Xiaowen", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1906.01102", "submitter": "Mariano Tepper", "authors": "Mariano Tepper", "title": "Do place cells dream of conditional probabilities? Learning Neural\n  Nystr\\\"om representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We posit that hippocampal place cells encode information about future\nlocations under a transition distribution observed as an agent explores a given\n(physical or conceptual) space. The encoding of information about the current\nlocation, usually associated with place cells, then emerges as a necessary step\nto achieve this broader goal. We formally derive a biologically-inspired neural\nnetwork from Nystr\\\"om kernel approximations and empirically demonstrate that\nthe network successfully approximates transition distributions. The proposed\nnetwork yields representations that, just like place cells, soft-tile the input\nspace with highly sparse and localized receptive fields. Additionally, we show\nthat the proposed computational motif can be extended to handle supervised\nproblems, creating class-specific place cells while exhibiting low sample\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:11:10 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 23:35:09 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Tepper", "Mariano", ""]]}, {"id": "1906.01110", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "RL-Based Method for Benchmarking the Adversarial Resilience and\n  Robustness of Deep Reinforcement Learning Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the resilience and robustness of Deep Reinforcement\nLearning (DRL) policies to adversarial perturbations in the state space. We\nfirst present an approach for the disentanglement of vulnerabilities caused by\nrepresentation learning of DRL agents from those that stem from the sensitivity\nof the DRL policies to distributional shifts in state transitions. Building on\nthis approach, we propose two RL-based techniques for quantitative benchmarking\nof adversarial resilience and robustness in DRL policies against perturbations\nof state transitions. We demonstrate the feasibility of our proposals through\nexperimental evaluation of resilience and robustness in DQN, A2C, and PPO2\npolicies trained in the Cartpole environment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:43:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01115", "submitter": "Sarath Pattathil", "authors": "Aryan Mokhtari, Asuman Ozdaglar, Sarath Pattathil", "title": "Convergence Rate of $\\mathcal{O}(1/k)$ for Optimistic Gradient and\n  Extra-gradient Methods in Smooth Convex-Concave Saddle Point Problems", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the iteration complexity of the optimistic gradient descent-ascent\n(OGDA) method and the extra-gradient (EG) method for finding a saddle point of\na convex-concave unconstrained min-max problem. To do so, we first show that\nboth OGDA and EG can be interpreted as approximate variants of the proximal\npoint method. This is similar to the approach taken in [Nemirovski, 2004] which\nanalyzes EG as an approximation of the `conceptual mirror prox'. In this paper,\nwe highlight how gradients used in OGDA and EG try to approximate the gradient\nof the Proximal Point method. We then exploit this interpretation to show that\nboth algorithms produce iterates that remain within a bounded set. We further\nshow that the primal dual gap of the averaged iterates generated by both of\nthese algorithms converge with a rate of $\\mathcal{O}(1/k)$. Our theoretical\nanalysis is of interest as it provides a the first convergence rate estimate\nfor OGDA in the general convex-concave setting. Moreover, it provides a simple\nconvergence analysis for the EG algorithm in terms of function value without\nusing compactness assumption.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:54:41 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 18:24:38 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 17:43:22 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""], ["Pattathil", "Sarath", ""]]}, {"id": "1906.01119", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Analysis and Improvement of Adversarial Training in DQN Agents With\n  Adversarially-Guided Exploration (AGE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effectiveness of adversarial training in\nenhancing the robustness of Deep Q-Network (DQN) policies to state-space\nperturbations. We first present a formal analysis of adversarial training in\nDQN agents and its performance with respect to the proportion of adversarial\nperturbations to nominal observations used for training. Next, we consider the\nsample-inefficiency of current adversarial training techniques, and propose a\nnovel Adversarially-Guided Exploration (AGE) mechanism based on a modified\nhybrid of the $\\epsilon$-greedy algorithm and Boltzmann exploration. We verify\nthe feasibility of this exploration mechanism through experimental evaluation\nof its performance in comparison with the traditional decaying\n$\\epsilon$-greedy and parameter-space noise exploration algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:31:25 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01121", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Adversarial Exploitation of Policy Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a class of attacks targeting the confidentiality\naspect of security in Deep Reinforcement Learning (DRL) policies. Recent\nresearch have established the vulnerability of supervised machine learning\nmodels (e.g., classifiers) to model extraction attacks. Such attacks leverage\nthe loosely-restricted ability of the attacker to iteratively query the model\nfor labels, thereby allowing for the forging of a labeled dataset which can be\nused to train a replica of the original model. In this work, we demonstrate the\nfeasibility of exploiting imitation learning techniques in launching model\nextraction attacks on DRL agents. Furthermore, we develop proof-of-concept\nattacks that leverage such techniques for black-box attacks against the\nintegrity of DRL policies. We also present a discussion on potential solution\nconcepts for mitigation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:38:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01126", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Sequential Triggers for Watermarking of Deep Reinforcement Learning\n  Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel scheme for the watermarking of Deep Reinforcement\nLearning (DRL) policies. This scheme provides a mechanism for the integration\nof a unique identifier within the policy in the form of its response to a\ndesignated sequence of state transitions, while incurring minimal impact on the\nnominal performance of the policy. The applications of this watermarking scheme\ninclude detection of unauthorized replications of proprietary policies, as well\nas enabling the graceful interruption or termination of DRL activities by\nauthorized entities. We demonstrate the feasibility of our proposal via\nexperimental evaluation of watermarking a DQN policy trained in the Cartpole\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:42:44 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01127", "submitter": "Zequn Wang", "authors": "Narendra Patwardhan and Zequn Wang", "title": "Proximal Reliability Optimization for Reinforcement Learning", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the numerous advances, reinforcement learning remains away from\nwidespread acceptance for autonomous controller design as compared to classical\nmethods due to lack of ability to effectively tackle the reality gap. The\nreliance on absolute or deterministic reward as a metric for optimization\nprocess renders reinforcement learning highly susceptible to changes in problem\ndynamics. We introduce a novel framework that effectively quantizes the\nuncertainty of the design space and induces robustness in controllers by\nswitching to a reliability-based optimization routine. The data efficiency of\nthe method is maintained to match reward based optimization methods by\nemploying a model-based approach. We prove the stability of learned\nneuro-controllers in both static and dynamic environments on classical\nreinforcement learning tasks such as Cart Pole balancing and Inverted Pendulum.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:43:16 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Patwardhan", "Narendra", ""], ["Wang", "Zequn", ""]]}, {"id": "1906.01131", "submitter": "Andreas Groll", "authors": "Andreas Groll, Christophe Ley, Gunther Schauberger, Hans Van Eetvelde,\n  Achim Zeileis", "title": "Hybrid Machine Learning Forecasts for the FIFA Women's World Cup 2019", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.03208", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we combine two different ranking methods together with several\nother predictors in a joint random forest approach for the scores of soccer\nmatches. The first ranking method is based on the bookmaker consensus, the\nsecond ranking method estimates adequate ability parameters that reflect the\ncurrent strength of the teams best. The proposed combined approach is then\napplied to the data from the two previous FIFA Women's World Cups 2011 and\n2015. Finally, based on the resulting estimates, the FIFA Women's World Cup\n2019 is simulated repeatedly and winning probabilities are obtained for all\nteams. The model clearly favors the defending champion USA before the host\nFrance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:48:30 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Groll", "Andreas", ""], ["Ley", "Christophe", ""], ["Schauberger", "Gunther", ""], ["Van Eetvelde", "Hans", ""], ["Zeileis", "Achim", ""]]}, {"id": "1906.01139", "submitter": "Daniel Hsu", "authors": "Ji Xu and Daniel Hsu", "title": "On the number of variables to use in principal component regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study least squares linear regression over $N$ uncorrelated Gaussian\nfeatures that are selected in order of decreasing variance. When the number of\nselected features $p$ is at most the sample size $n$, the estimator under\nconsideration coincides with the principal component regression estimator; when\n$p>n$, the estimator is the least $\\ell_2$ norm solution over the selected\nfeatures. We give an average-case analysis of the out-of-sample prediction\nerror as $p,n,N \\to \\infty$ with $p/N \\to \\alpha$ and $n/N \\to \\beta$, for some\nconstants $\\alpha \\in [0,1]$ and $\\beta \\in (0,1)$. In this average-case\nsetting, the prediction error exhibits a \"double descent\" shape as a function\nof $p$. We also establish conditions under which the minimum risk is achieved\nin the interpolating ($p>n$) regime.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 00:22:10 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:10:42 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Xu", "Ji", ""], ["Hsu", "Daniel", ""]]}, {"id": "1906.01148", "submitter": "Besmira Nushi", "authors": "Gagan Bansal, Besmira Nushi, Ece Kamar, Dan Weld, Walter Lasecki, Eric\n  Horvitz", "title": "A Case for Backward Compatibility for Human-AI Teams", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems are being deployed to support human decision making in high-stakes\ndomains. In many cases, the human and AI form a team, in which the human makes\ndecisions after reviewing the AI's inferences. A successful partnership\nrequires that the human develops insights into the performance of the AI\nsystem, including its failures. We study the influence of updates to an AI\nsystem in this setting. While updates can increase the AI's predictive\nperformance, they may also lead to changes that are at odds with the user's\nprior experiences and confidence in the AI's inferences, hurting therefore the\noverall team performance. We introduce the notion of the compatibility of an AI\nupdate with prior user experience and present methods for studying the role of\ncompatibility in human-AI teams. Empirical results on three high-stakes domains\nshow that current machine learning algorithms do not produce compatible\nupdates. We propose a re-training objective to improve the compatibility of an\nupdate by penalizing new errors. The objective offers full leverage of the\nperformance/compatibility tradeoff, enabling more compatible yet accurate\nupdates.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 01:09:14 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Bansal", "Gagan", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Weld", "Dan", ""], ["Lasecki", "Walter", ""], ["Horvitz", "Eric", ""]]}, {"id": "1906.01150", "submitter": "Ikuro Sato", "authors": "Ikuro Sato, Kohta Ishikawa, Guoqing Liu, and Masayuki Tanaka", "title": "Breaking Inter-Layer Co-Adaptation by Classifier Anonymization", "comments": "9 pages. Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study addresses an issue of co-adaptation between a feature extractor\nand a classifier in a neural network. A naive joint optimization of a feature\nextractor and a classifier often brings situations in which an excessively\ncomplex feature distribution adapted to a very specific classifier degrades the\ntest performance. We introduce a method called Feature-extractor Optimization\nthrough Classifier Anonymization (FOCA), which is designed to avoid an explicit\nco-adaptation between a feature extractor and a particular classifier by using\nmany randomly-generated, weak classifiers during optimization. We put forth a\nmathematical proposition that states the FOCA features form a point-like\ndistribution within the same class in a class-separable fashion under special\nconditions. Real-data experiments under more general conditions provide\nsupportive evidences.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 01:33:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sato", "Ikuro", ""], ["Ishikawa", "Kohta", ""], ["Liu", "Guoqing", ""], ["Tanaka", "Masayuki", ""]]}, {"id": "1906.01161", "submitter": "Yury Kashnitsky", "authors": "Matei Ionita, Yury Kashnitsky, Ken Krige, Vladimir Larin, Denis\n  Logvinenko, and Atanas Atanasov", "title": "Resolving Gendered Ambiguous Pronouns with BERT", "comments": "accepted to 1st ACL Workshop on Gender Bias for Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronoun resolution is part of coreference resolution, the task of pairing an\nexpression to its referring entity. This is an important task for natural\nlanguage understanding and a necessary component of machine translation\nsystems, chat bots and assistants. Neural machine learning systems perform far\nfrom ideally in this task, reaching as low as 73% F1 scores on modern benchmark\ndatasets. Moreover, they tend to perform better for masculine pronouns than for\nfeminine ones. Thus, the problem is both challenging and important for NLP\nresearchers and practitioners. In this project, we describe our BERT-based\napproach to solving the problem of gender-balanced pronoun resolution. We are\nable to reach 92% F1 score and a much lower gender bias on the benchmark\ndataset shared by Google AI Language team.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 11:10:10 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 11:26:56 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ionita", "Matei", ""], ["Kashnitsky", "Yury", ""], ["Krige", "Ken", ""], ["Larin", "Vladimir", ""], ["Logvinenko", "Denis", ""], ["Atanasov", "Atanas", ""]]}, {"id": "1906.01164", "submitter": "Julien Mairal", "authors": "Andrei Kulunchakov (Thoth), Julien Mairal (Thoth)", "title": "A Generic Acceleration Framework for Stochastic Composite Optimization", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Dec\n  2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce various mechanisms to obtain accelerated\nfirst-order stochastic optimization algorithms when the objective function is\nconvex or strongly convex. Specifically, we extend the Catalyst approach\noriginally designed for deterministic objectives to the stochastic setting.\nGiven an optimization method with mild convergence guarantees for strongly\nconvex problems, the challenge is to accelerate convergence to a\nnoise-dominated region, and then achieve convergence with an optimal worst-case\ncomplexity depending on the noise variance of the gradients. A side\ncontribution of our work is also a generic analysis that can handle inexact\nproximal operators, providing new insights about the robustness of stochastic\nalgorithms when the proximal operator cannot be exactly computed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 07:33:33 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 12:56:01 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 13:52:11 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kulunchakov", "Andrei", "", "Thoth"], ["Mairal", "Julien", "", "Thoth"]]}, {"id": "1906.01167", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Jiangshan Yu, Karthik Nandakumar, Yitong Li, Xingjun Ma,\n  Jiong Jin, Han Yu, and Kee Siong Ng", "title": "Towards Fair and Privacy-Preserving Federated Deep Models", "comments": "Accepted for publication in TPDS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current standalone deep learning framework tends to result in overfitting\nand low utility. This problem can be addressed by either a centralized\nframework that deploys a central server to train a global model on the joint\ndata from all parties, or a distributed framework that leverages a parameter\nserver to aggregate local model updates. Server-based solutions are prone to\nthe problem of a single-point-of-failure. In this respect, collaborative\nlearning frameworks, such as federated learning (FL), are more robust. Existing\nfederated learning frameworks overlook an important aspect of participation:\nfairness. All parties are given the same final model without regard to their\ncontributions. To address these issues, we propose a decentralized Fair and\nPrivacy-Preserving Deep Learning (FPPDL) framework to incorporate fairness into\nfederated deep learning models. In particular, we design a local credibility\nmutual evaluation mechanism to guarantee fairness, and a three-layer\nonion-style encryption scheme to guarantee both accuracy and privacy. Different\nfrom existing FL paradigm, under FPPDL, each participant receives a different\nversion of the FL model with performance commensurate with his contributions.\nExperiments on benchmark datasets demonstrate that FPPDL balances fairness,\nprivacy and accuracy. It enables federated learning ecosystems to detect and\nisolate low-contribution parties, thereby promoting responsible participation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 02:43:42 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 01:09:35 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 10:43:55 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Jiangshan", ""], ["Nandakumar", "Karthik", ""], ["Li", "Yitong", ""], ["Ma", "Xingjun", ""], ["Jin", "Jiong", ""], ["Yu", "Han", ""], ["Ng", "Kee Siong", ""]]}, {"id": "1906.01171", "submitter": "Ethan Fetaya", "authors": "Ethan Fetaya, J\\\"orn-Henrik Jacobsen, Will Grathwohl and Richard Zemel", "title": "Understanding the Limitations of Conditional Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-conditional generative models hold promise to overcome the shortcomings\nof their discriminative counterparts. They are a natural choice to solve\ndiscriminative tasks in a robust manner as they jointly optimize for predictive\nperformance and accurate modeling of the input distribution. In this work, we\ninvestigate robust classification with likelihood-based generative models from\na theoretical and practical perspective to investigate if they can deliver on\ntheir promises. Our analysis focuses on a spectrum of robustness properties:\n(1) Detection of worst-case outliers in the form of adversarial examples; (2)\nDetection of average-case outliers in the form of ambiguous inputs and (3)\nDetection of incorrectly labeled in-distribution inputs. Our theoretical result\nreveals that it is impossible to guarantee detectability of\nadversarially-perturbed inputs even for near-optimal generative classifiers.\nExperimentally, we find that while we are able to train robust models for\nMNIST, robustness completely breaks down on CIFAR10. We relate this failure to\nvarious undesirable model properties that can be traced to the maximum\nlikelihood training objective. Despite being a common choice in the literature,\nour results indicate that likelihood-based conditional generative models may\nare surprisingly ineffective for robust classification.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 02:56:14 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 12:17:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Fetaya", "Ethan", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Grathwohl", "Will", ""], ["Zemel", "Richard", ""]]}, {"id": "1906.01178", "submitter": "Fangyuan Zhao", "authors": "Fangyuan Zhao, Xuebin Ren, Shusen Yang and Xinyu Yang", "title": "On Privacy Protection of Latent Dirichlet Allocation Model Training", "comments": "8 pages,5 figures,and is published in International Joint Conferences\n  on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for\ndiscovery of hidden semantic architecture of text datasets, and plays a\nfundamental role in many machine learning applications. However, like many\nother machine learning algorithms, the process of training a LDA model may leak\nthe sensitive information of the training datasets and bring significant\nprivacy risks. To mitigate the privacy issues in LDA, we focus on studying\nprivacy-preserving algorithms of LDA model training in this paper. In\nparticular, we first develop a privacy monitoring algorithm to investigate the\nprivacy guarantee obtained from the inherent randomness of the Collapsed Gibbs\nSampling (CGS) process in a typical LDA training algorithm on centralized\ncurated datasets. Then, we further propose a locally private LDA training\nalgorithm on crowdsourced data to provide local differential privacy for\nindividual data contributors. The experimental results on real-world datasets\ndemonstrate the effectiveness of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 03:25:17 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 12:56:11 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhao", "Fangyuan", ""], ["Ren", "Xuebin", ""], ["Yang", "Shusen", ""], ["Yang", "Xinyu", ""]]}, {"id": "1906.01184", "submitter": "Weiran Shen", "authors": "Weiran Shen, S\\'ebastien Lahaie, Renato Paes Leme", "title": "Learning to Clear the Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of market clearing is to set a price for an item such that\nquantity demanded equals quantity supplied. In this work, we cast the problem\nof predicting clearing prices into a learning framework and use the resulting\nmodels to perform revenue optimization in auctions and markets with contextual\ninformation. The economic intuition behind market clearing allows us to obtain\nfine-grained control over the aggressiveness of the resulting pricing policy,\ngrounded in theory. To evaluate our approach, we fit a model of clearing prices\nover a massive dataset of bids in display ad auctions from a major ad exchange.\nThe learned prices outperform other modeling techniques in the literature in\nterms of revenue and efficiency trade-offs. Because of the convex nature of the\nclearing loss function, the convergence rate of our method is as fast as linear\nregression.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 03:34:34 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 07:34:23 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Shen", "Weiran", ""], ["Lahaie", "S\u00e9bastien", ""], ["Leme", "Renato Paes", ""]]}, {"id": "1906.01195", "submitter": "Deepak Nathani", "authors": "Deepak Nathani, Jatin Chauhan, Charu Sharma, Manohar Kaul", "title": "Learning Attention-based Embeddings for Relation Prediction in Knowledge\n  Graphs", "comments": "accepted as long paper in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of knowledge graphs (KGs) coupled with incomplete or\npartial information, in the form of missing relations (links) between entities,\nhas fueled a lot of research on knowledge base completion (also known as\nrelation prediction). Several recent works suggest that convolutional neural\nnetwork (CNN) based models generate richer and more expressive feature\nembeddings and hence also perform well on relation prediction. However, we\nobserve that these KG embeddings treat triples independently and thus fail to\ncover the complex and hidden information that is inherently implicit in the\nlocal neighborhood surrounding a triple. To this effect, our paper proposes a\nnovel attention based feature embedding that captures both entity and relation\nfeatures in any given entity's neighborhood. Additionally, we also encapsulate\nrelation clusters and multihop relations in our model. Our empirical study\noffers insights into the efficacy of our attention based model and we show\nmarked performance gains in comparison to state of the art methods on all\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:59:08 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Nathani", "Deepak", ""], ["Chauhan", "Jatin", ""], ["Sharma", "Charu", ""], ["Kaul", "Manohar", ""]]}, {"id": "1906.01198", "submitter": "Jianjun Wang", "authors": "Feng Zhang, Wendong Wang, Jingyao Hou, Jianjun Wang, Jianwen Huang", "title": "Tensor Restricted Isometry Property Analysis For a Large Class of Random\n  Measurement Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, theoretical analysis based on the tensor Restricted\nIsometry Property (t-RIP) established the robust recovery guarantees of a\nlow-tubal-rank tensor. The obtained sufficient conditions depend strongly on\nthe assumption that the linear measurement maps satisfy the t-RIP. In this\npaper, by exploiting the probabilistic arguments, we prove that such linear\nmeasurement maps exist under suitable conditions on the number of measurements\nin terms of the tubal rank r and the size of third-order tensor n1, n2, n3. And\nthe obtained minimal possible number of linear measurements is nearly optimal\ncompared with the degrees of freedom of a tensor with tubal rank r. Specially,\nwe consider a random sub-Gaussian distribution that includes Gaussian,\nBernoulli and all bounded distributions and construct a large class of linear\nmaps that satisfy a t-RIP with high probability. Moreover, the validity of the\nrequired number of measurements is verified by numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 05:11:22 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 03:20:43 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zhang", "Feng", ""], ["Wang", "Wendong", ""], ["Hou", "Jingyao", ""], ["Wang", "Jianjun", ""], ["Huang", "Jianwen", ""]]}, {"id": "1906.01200", "submitter": "Shengjia Zhao", "authors": "Jun-Ting Hsieh and Shengjia Zhao and Stephan Eismann and Lucia\n  Mirabella and Stefano Ermon", "title": "Learning Neural PDE Solvers with Convergence Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) are widely used across the physical and\ncomputational sciences. Decades of research and engineering went into designing\nfast iterative solution methods. Existing solvers are general purpose, but may\nbe sub-optimal for specific classes of problems. In contrast to existing\nhand-crafted solutions, we propose an approach to learn a fast iterative solver\ntailored to a specific domain. We achieve this goal by learning to modify the\nupdates of an existing solver using a deep neural network. Crucially, our\napproach is proven to preserve strong correctness and convergence guarantees.\nAfter training on a single geometry, our model generalizes to a wide variety of\ngeometries and boundary conditions, and achieves 2-3 times speedup compared to\nstate-of-the-art solvers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 05:28:22 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Hsieh", "Jun-Ting", ""], ["Zhao", "Shengjia", ""], ["Eismann", "Stephan", ""], ["Mirabella", "Lucia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1906.01202", "submitter": "Sumit Kumar", "authors": "Akshat Agarwal, Sumit Kumar and Katia Sycara", "title": "Learning Transferable Cooperative Behavior in Multi-Agent Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While multi-agent interactions can be naturally modeled as a graph, the\nenvironment has traditionally been considered as a black box. We propose to\ncreate a shared agent-entity graph, where agents and environmental entities\nform vertices, and edges exist between the vertices which can communicate with\neach other. Agents learn to cooperate by exchanging messages along the edges of\nthis graph. Our proposed multi-agent reinforcement learning framework is\ninvariant to the number of agents or entities present in the system as well as\npermutation invariance, both of which are desirable properties for any\nmulti-agent system representation. We present state-of-the-art results on\ncoverage, formation and line control tasks for multi-agent teams in a fully\ndecentralized framework and further show that the learned policies quickly\ntransfer to scenarios with different team sizes along with strong zero-shot\ngeneralization performance. This is an important step towards developing\nmulti-agent teams which can be realistically deployed in the real world without\nassuming complete prior knowledge or instantaneous communication at unbounded\ndistances.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 05:36:43 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Agarwal", "Akshat", ""], ["Kumar", "Sumit", ""], ["Sycara", "Katia", ""]]}, {"id": "1906.01210", "submitter": "Qimai Li", "authors": "Xiaotong Zhang, Han Liu, Qimai Li, and Xiao-Ming Wu", "title": "Attributed Graph Clustering via Adaptive Graph Convolution", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributed graph clustering is challenging as it requires joint modelling of\ngraph structures and node attributes. Recent progress on graph convolutional\nnetworks has proved that graph convolution is effective in combining structural\nand content information, and several recent methods based on it have achieved\npromising clustering performance on some real attributed networks. However,\nthere is limited understanding of how graph convolution affects clustering\nperformance and how to properly use it to optimize performance for different\ngraphs. Existing methods essentially use graph convolution of a fixed and low\norder that only takes into account neighbours within a few hops of each node,\nwhich underutilizes node relations and ignores the diversity of graphs. In this\npaper, we propose an adaptive graph convolution method for attributed graph\nclustering that exploits high-order graph convolution to capture global cluster\nstructure and adaptively selects the appropriate order for different graphs. We\nestablish the validity of our method by theoretical analysis and extensive\nexperiments on benchmark datasets. Empirical results show that our method\ncompares favourably with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:01:10 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhang", "Xiaotong", ""], ["Liu", "Han", ""], ["Li", "Qimai", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "1906.01219", "submitter": "Xiaoying Zhang", "authors": "Xiaoying Zhang, Hong Xie, Hang Li, John C.S. Lui", "title": "Conversational Contextual Bandit: Algorithm and Application", "comments": "11 pages; Accepted by WWW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms provide principled online learning solutions to\nbalance the exploitation-exploration trade-off in various applications such as\nrecommender systems. However, the learning speed of the traditional contextual\nbandit algorithms is often slow due to the need for extensive exploration. This\nposes a critical issue in applications like recommender systems, since users\nmay need to provide feedbacks on a lot of uninterested items. To accelerate the\nlearning speed, we generalize contextual bandit to conversational contextual\nbandit. Conversational contextual bandit leverages not only behavioral\nfeedbacks on arms (e.g., articles in news recommendation), but also occasional\nconversational feedbacks on key-terms from the user. Here, a key-term can\nrelate to a subset of arms, for example, a category of articles in news\nrecommendation. We then design the Conversational UCB algorithm (ConUCB) to\naddress two challenges in conversational contextual bandit: (1) which key-terms\nto select to conduct conversation, (2) how to leverage conversational feedbacks\nto accelerate the speed of bandit learning. We theoretically prove that ConUCB\ncan achieve a smaller regret upper bound than the traditional contextual bandit\nalgorithm LinUCB, which implies a faster learning speed. Experiments on\nsynthetic data, as well as real datasets from Yelp and Toutiao, demonstrate the\nefficacy of the ConUCB algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:31:27 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 09:29:09 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhang", "Xiaoying", ""], ["Xie", "Hong", ""], ["Li", "Hang", ""], ["Lui", "John C. S.", ""]]}, {"id": "1906.01227", "submitter": "Chaitanya K. Joshi", "authors": "Chaitanya K. Joshi, Thomas Laurent, Xavier Bresson", "title": "An Efficient Graph Convolutional Network Technique for the Travelling\n  Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new learning-based approach for approximately solving\nthe Travelling Salesman Problem on 2D Euclidean graphs. We use deep Graph\nConvolutional Networks to build efficient TSP graph representations and output\ntours in a non-autoregressive manner via highly parallelized beam search. Our\napproach outperforms all recently proposed autoregressive deep learning\ntechniques in terms of solution quality, inference speed and sample efficiency\nfor problem instances of fixed graph sizes. In particular, we reduce the\naverage optimality gap from 0.52% to 0.01% for 50 nodes, and from 2.26% to\n1.39% for 100 nodes. Finally, despite improving upon other learning-based\napproaches for TSP, our approach falls short of standard Operations Research\nsolvers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:51:45 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 11:31:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Joshi", "Chaitanya K.", ""], ["Laurent", "Thomas", ""], ["Bresson", "Xavier", ""]]}, {"id": "1906.01233", "submitter": "Mengzhuo Guo", "authors": "Mengzhuo Guo, Qingpeng Zhang, Xiuwu Liao, Frank Youhua Chen, Daniel\n  Dajun Zeng", "title": "A hybrid machine learning framework for analyzing human decision making\n  through learning preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has recently been widely adopted to address the managerial\ndecision making problems, in which the decision maker needs to be able to\ninterpret the contributions of individual attributes in an explicit form.\nHowever, there is a trade-off between performance and interpretability. Full\ncomplexity models are non-traceable black-box, whereas classic interpretable\nmodels are usually simplified with lower accuracy. This trade-off limits the\napplication of state-of-the-art machine learning models in management problems,\nwhich requires high prediction performance, as well as the understanding of\nindividual attributes' contributions to the model outcome. Multiple criteria\ndecision aiding (MCDA) is a family of analytic approaches to depicting the\nrationale of human decision. It is also limited by strong assumptions. To meet\nthe decision maker's demand for more interpretable machine learning models, we\npropose a novel hybrid method, namely Neural Network-based Multiple Criteria\nDecision Aiding, which combines an additive value model and a fully-connected\nmultilayer perceptron (MLP) to achieve good performance while capturing the\nexplicit relationships between individual attributes and the prediction.\nNN-MCDA has a linear component to characterize such relationships through\nproviding explicit marginal value functions, and a nonlinear component to\ncapture the implicit high-order interactions between attributes and their\ncomplex nonlinear transformations. We demonstrate the effectiveness of NN-MCDA\nwith extensive simulation studies and three real-world datasets. To the best of\nour knowledge, this research is the first to enhance the interpretability of\nmachine learning models with MCDA techniques. The proposed framework also sheds\nlight on how to use machine learning techniques to free MCDA from strong\nassumptions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:06:50 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 02:58:46 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 13:32:42 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Guo", "Mengzhuo", ""], ["Zhang", "Qingpeng", ""], ["Liao", "Xiuwu", ""], ["Chen", "Frank Youhua", ""], ["Zeng", "Daniel Dajun", ""]]}, {"id": "1906.01235", "submitter": "Trevor Campbell", "authors": "Trevor Campbell and Xinglong Li", "title": "Universal Boosting Variational Inference", "comments": "In Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting variational inference (BVI) approximates an intractable probability\ndensity by iteratively building up a mixture of simple component distributions\none at a time, using techniques from sparse convex optimization to provide both\ncomputational scalability and approximation error guarantees. But the\nguarantees have strong conditions that do not often hold in practice, resulting\nin degenerate component optimization problems; and we show that the ad-hoc\nregularization used to prevent degeneracy in practice can cause BVI to fail in\nunintuitive ways. We thus develop universal boosting variational inference\n(UBVI), a BVI scheme that exploits the simple geometry of probability densities\nunder the Hellinger metric to prevent the degeneracy of other gradient-based\nBVI methods, avoid difficult joint optimizations of both component and weight,\nand simplify fully-corrective weight optimizations. We show that for any target\ndensity and any mixture component family, the output of UBVI converges to the\nbest possible approximation in the mixture family, even when the mixture family\nis misspecified. We develop a scalable implementation based on exponential\nfamily mixture components and standard stochastic optimization techniques.\nFinally, we discuss statistical benefits of the Hellinger distance as a\nvariational objective through bounds on posterior probability, moment, and\nimportance sampling errors. Experiments on multiple datasets and models show\nthat UBVI provides reliable, accurate posterior approximations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:08:50 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 08:24:25 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Campbell", "Trevor", ""], ["Li", "Xinglong", ""]]}, {"id": "1906.01246", "submitter": "Paolo Casari", "authors": "Rafael Garcia Leiva, Antonio Fernandez Anta, Vincenzo Mancuso, Paolo\n  Casari", "title": "A Novel Hyperparameter-free Approach to Decision Tree Construction that\n  Avoids Overfitting by Design", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are an extremely popular machine learning technique.\nUnfortunately, overfitting in decision trees still remains an open issue that\nsometimes prevents achieving good performance. In this work, we present a novel\napproach for the construction of decision trees that avoids the overfitting by\ndesign, without losing accuracy. A distinctive feature of our algorithm is that\nit requires neither the optimization of any hyperparameters, nor the use of\nregularization techniques, thus significantly reducing the decision tree\ntraining time. Moreover, our algorithm produces much smaller and shallower\ntrees than traditional algorithms, facilitating the interpretability of the\nresulting models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:30:32 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Leiva", "Rafael Garcia", ""], ["Anta", "Antonio Fernandez", ""], ["Mancuso", "Vincenzo", ""], ["Casari", "Paolo", ""]]}, {"id": "1906.01251", "submitter": "Michael P. J. Camilleri Mr", "authors": "Michael P. J. Camilleri and Christopher K. I. Williams", "title": "The Extended Dawid-Skene Model: Fusing Information from Multiple Data\n  Schemas", "comments": "Updated with Author-Preprint version following Publication in P.\n  Cellier and K. Driessens (Eds.): ECML PKDD 2019 Workshops, CCIS 1167, pp. 121\n  - 136, 2020", "journal-ref": "in ECML PKDD 2019 Workshops, CCIS 1167, pp. 121 - 136, 2020", "doi": "10.1007/978-3-030-43823-4_11", "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While label fusion from multiple noisy annotations is a well understood\nconcept in data wrangling (tackled for example by the Dawid-Skene (DS) model),\nwe consider the extended problem of carrying out learning when the labels\nthemselves are not consistently annotated with the same schema. We show that\neven if annotators use disparate, albeit related, label-sets, we can still draw\ninferences for the underlying full label-set. We propose the Inter-Schema\nAdapteR (ISAR) to translate the fully-specified label-set to the one used by\neach annotator, enabling learning under such heterogeneous schemas, without the\nneed to re-annotate the data. We apply our method to a mouse behavioural\ndataset, achieving significant gains (compared with DS) in out-of-sample\nlog-likelihood (-3.40 to -2.39) and F1-score (0.785 to 0.864).\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:50:51 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:53:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Camilleri", "Michael P. J.", ""], ["Williams", "Christopher K. I.", ""]]}, {"id": "1906.01277", "submitter": "Matteo Togninalli", "authors": "Matteo Togninalli, Elisabetta Ghisu, Felipe Llinares-L\\'opez, Bastian\n  Rieck, Karsten Borgwardt", "title": "Wasserstein Weisfeiler-Lehman Graph Kernels", "comments": "Accepted as a Spotlight talk at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most graph kernels are an instance of the class of $\\mathcal{R}$-Convolution\nkernels, which measure the similarity of objects by comparing their\nsubstructures. Despite their empirical success, most graph kernels use a naive\naggregation of the final set of substructures, usually a sum or average,\nthereby potentially discarding valuable information about the distribution of\nindividual components. Furthermore, only a limited instance of these approaches\ncan be extended to continuously attributed graphs. We propose a novel method\nthat relies on the Wasserstein distance between the node feature vector\ndistributions of two graphs, which allows to find subtler differences in data\nsets by considering graphs as high-dimensional objects, rather than simple\nmeans. We further propose a Weisfeiler-Lehman inspired embedding scheme for\ngraphs with continuous node attributes and weighted edges, enhance it with the\ncomputed Wasserstein distance, and thus improve the state-of-the-art prediction\nperformance on several graph classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:52:47 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 14:25:05 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Togninalli", "Matteo", ""], ["Ghisu", "Elisabetta", ""], ["Llinares-L\u00f3pez", "Felipe", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1906.01279", "submitter": "Christian Gei{\\ss}ler", "authors": "Weijia Shao, Christian Gei{\\ss}ler, Fikret Sivrikaya", "title": "Graduated Optimization of Black-Box Functions", "comments": "Accepted Workshop Submission for the 6th ICML Workshop on Automated\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of tuning hyperparameters in machine learning, we\npresent a new approach for gradually and adaptively optimizing an unknown\nfunction using estimated gradients. We validate the empirical performance of\nthe proposed idea on both low and high dimensional problems. The experimental\nresults demonstrate the advantages of our approach for tuning high dimensional\nhyperparameters in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:56:11 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Shao", "Weijia", ""], ["Gei\u00dfler", "Christian", ""], ["Sivrikaya", "Fikret", ""]]}, {"id": "1906.01288", "submitter": "Jie Hu", "authors": "Jie Hu, Rongrong Ji, ShengChuan Zhang, Xiaoshuai Sun, Qixiang Ye,\n  Chia-Wen Lin, Qi Tian", "title": "Information Competing Process for Learning Diversified Representations", "comments": "Accept as a NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations with diversified information remains as an open\nproblem. Towards learning diversified representations, a new approach, termed\nInformation Competing Process (ICP), is proposed in this paper. Aiming to\nenrich the information carried by feature representations, ICP separates a\nrepresentation into two parts with different mutual information constraints.\nThe separated parts are forced to accomplish the downstream task independently\nin a competitive environment which prevents the two parts from learning what\neach other learned for the downstream task. Such competing parts are then\ncombined synergistically to complete the task. By fusing representation parts\nlearned competitively under different conditions, ICP facilitates obtaining\ndiversified representations which contain rich information. Experiments on\nimage classification and image reconstruction tasks demonstrate the great\npotential of ICP to learn discriminative and disentangled representations in\nboth supervised and self-supervised learning settings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 09:10:43 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 09:19:32 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 04:17:10 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hu", "Jie", ""], ["Ji", "Rongrong", ""], ["Zhang", "ShengChuan", ""], ["Sun", "Xiaoshuai", ""], ["Ye", "Qixiang", ""], ["Lin", "Chia-Wen", ""], ["Tian", "Qi", ""]]}, {"id": "1906.01292", "submitter": "Emmanuel de B\\'ezenac", "authors": "Emmanuel de B\\'ezenac, Ibrahim Ayed, Patrick Gallinari", "title": "Optimal Unsupervised Domain Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Translation is the problem of finding a meaningful correspondence\nbetween two domains. Since in a majority of settings paired supervision is not\navailable, much work focuses on Unsupervised Domain Translation (UDT) where\ndata samples from each domain are unpaired. Following the seminal work of\nCycleGAN for UDT, many variants and extensions of this model have been\nproposed. However, there is still little theoretical understanding behind their\nsuccess. We observe that these methods yield solutions which are approximately\nminimal w.r.t. a given transportation cost, leading us to reformulate the\nproblem in the Optimal Transport (OT) framework. This viewpoint gives us a new\nperspective on Unsupervised Domain Translation and allows us to prove the\nexistence and uniqueness of the retrieved mapping, given a large family of\ntransport costs. We then propose a novel framework to efficiently compute\noptimal mappings in a dynamical setting. We show that it generalizes previous\nmethods and enables a more explicit control over the computed optimal mapping.\nIt also provides smooth interpolations between the two domains. Experiments on\ntoy and real world datasets illustrate the behavior of our method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 09:19:47 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["de B\u00e9zenac", "Emmanuel", ""], ["Ayed", "Ibrahim", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1906.01297", "submitter": "Xavier Renard", "authors": "Xavier Renard, Nicolas Woloszko, Jonathan Aigrain, Marcin Detyniecki", "title": "Concept Tree: High-Level Representation of Variables for More\n  Interpretable Surrogate Decision Trees", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable surrogates of black-box predictors trained on high-dimensional\ntabular datasets can struggle to generate comprehensible explanations in the\npresence of correlated variables. We propose a model-agnostic interpretable\nsurrogate that provides global and local explanations of black-box classifiers\nto address this issue. We introduce the idea of concepts as intuitive groupings\nof variables that are either defined by a domain expert or automatically\ndiscovered using correlation coefficients. Concepts are embedded in a surrogate\ndecision tree to enhance its comprehensibility. First experiments on FRED-MD, a\nmacroeconomic database with 134 variables, show improvement in\nhuman-interpretability while accuracy and fidelity of the surrogate model are\npreserved.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 09:40:13 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Renard", "Xavier", ""], ["Woloszko", "Nicolas", ""], ["Aigrain", "Jonathan", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1906.01341", "submitter": "Toru Imai", "authors": "Toru Imai", "title": "Estimating Real Log Canonical Thresholds", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of the marginal likelihood plays an important role in model\nselection problems. The widely applicable Bayesian information criterion (WBIC)\nand singular Bayesian information criterion (sBIC) give approximations to the\nlog marginal likelihood, which can be applied to both regular and singular\nmodels. When the real log canonical thresholds are known, the performance of\nsBIC is considered to be better than that of WBIC, but only few real log\ncanonical thresholds are known. In this paper, we propose a new estimator of\nthe real log canonical thresholds based on the variance of thermodynamic\nintegration with an inverse temperature. In addition, we propose an application\nto make sBIC widely applicable. Finally, we investigate the performance of the\nestimator and model selection by simulation studies and application to real\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:59:33 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 07:14:18 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Imai", "Toru", ""]]}, {"id": "1906.01354", "submitter": "Zhun Deng", "authors": "Zhun Deng, Cynthia Dwork, Jialiang Wang, Yao Zhao", "title": "Architecture Selection via the Trade-off Between Accuracy and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a general framework for characterizing the trade-off between\naccuracy and robustness in supervised learning. We propose a method and define\nquantities to characterize the trade-off between accuracy and robustness for a\ngiven architecture, and provide theoretical insight into the trade-off.\nSpecifically we introduce a simple trade-off curve, define and study an\ninfluence function that captures the sensitivity, under adversarial attack, of\nthe optima of a given loss function. We further show how adversarial training\nregularizes the parameters in an over-parameterized linear model, recovering\nthe LASSO and ridge regression as special cases, which also allows us to\ntheoretically analyze the behavior of the trade-off curve. In experiments, we\ndemonstrate the corresponding trade-off curves of neural networks and how they\nvary with respect to factors such as number of layers, neurons, and across\ndifferent network structures. Such information provides a useful guideline to\narchitecture selection.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:36:16 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Deng", "Zhun", ""], ["Dwork", "Cynthia", ""], ["Wang", "Jialiang", ""], ["Zhao", "Yao", ""]]}, {"id": "1906.01374", "submitter": "Vieri Giuliano Santucci", "authors": "Vieri Giuliano Santucci and Gianluca Baldassarre and Emilio Cartoni", "title": "Autonomous Reinforcement Learning of Multiple Interrelated Tasks", "comments": "Accepted to \"The 9th Joint IEEE International Conference on\n  Development and Learning and on Epigenetic Robotics\" (ICDL-EpiRob2019). arXiv\n  admin note: substantial text overlap with arXiv:1905.02690", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous multiple tasks learning is a fundamental capability to develop\nversatile artificial agents that can act in complex environments. In real-world\nscenarios, tasks may be interrelated (or \"hierarchical\") so that a robot has to\nfirst learn to achieve some of them to set the preconditions for learning other\nones. Even though different strategies have been used in robotics to tackle the\nacquisition of interrelated tasks, in particular within the developmental\nrobotics framework, autonomous learning in this kind of scenarios is still an\nopen question. Building on previous research in the framework of intrinsically\nmotivated open-ended learning, in this work we describe how this question can\nbe addressed working on the level of task selection, in particular considering\nthe multiple interrelated tasks scenario as an MDP where the system is trying\nto maximise its competence over all the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 12:30:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Santucci", "Vieri Giuliano", ""], ["Baldassarre", "Gianluca", ""], ["Cartoni", "Emilio", ""]]}, {"id": "1906.01376", "submitter": "Armin Lederer", "authors": "Armin Lederer, Jonas Umlauft, Sandra Hirche", "title": "Uniform Error Bounds for Gaussian Process Regression with Application to\n  Safe Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven models are subject to model errors due to limited and noisy\ntraining data. Key to the application of such models in safety-critical domains\nis the quantification of their model error. Gaussian processes provide such a\nmeasure and uniform error bounds have been derived, which allow safe control\nbased on these models. However, existing error bounds require restrictive\nassumptions. In this paper, we employ the Gaussian process distribution and\ncontinuity arguments to derive a novel uniform error bound under weaker\nassumptions. Furthermore, we demonstrate how this distribution can be used to\nderive probabilistic Lipschitz constants and analyze the asymptotic behavior of\nour bound. Finally, we derive safety conditions for the control of unknown\ndynamical systems based on Gaussian process models and evaluate them in\nsimulations of a robotic manipulator.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 12:37:45 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 09:59:04 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Lederer", "Armin", ""], ["Umlauft", "Jonas", ""], ["Hirche", "Sandra", ""]]}, {"id": "1906.01401", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Michael Garcia Ortiz", "title": "Unsupervised Emergence of Egocentric Spatial Structure from Sensorimotor\n  Prediction", "comments": "27 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its omnipresence in robotics application, the nature of spatial\nknowledge and the mechanisms that underlie its emergence in autonomous agents\nare still poorly understood. Recent theoretical works suggest that the\nEuclidean structure of space induces invariants in an agent's raw sensorimotor\nexperience. We hypothesize that capturing these invariants is beneficial for\nsensorimotor prediction and that, under certain exploratory conditions, a motor\nrepresentation capturing the structure of the external space should emerge as a\nbyproduct of learning to predict future sensory experiences. We propose a\nsimple sensorimotor predictive scheme, apply it to different agents and types\nof exploration, and evaluate the pertinence of these hypotheses. We show that a\nnaive agent can capture the topology and metric regularity of its sensor's\nposition in an egocentric spatial frame without any a priori knowledge, nor\nextraneous supervision.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:13:31 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 10:17:17 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 10:50:45 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Ortiz", "Michael Garcia", ""]]}, {"id": "1906.01404", "submitter": "Armin Lederer", "authors": "Armin Lederer, Jonas Umlauft, Sandra Hirche", "title": "Posterior Variance Analysis of Gaussian Processes with Application to\n  Average Learning Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posterior variance of Gaussian processes is a valuable measure of the\nlearning error which is exploited in various applications such as safe\nreinforcement learning and control design. However, suitable analysis of the\nposterior variance which captures its behavior for finite and infinite number\nof training data is missing. This paper derives a novel bound for the posterior\nvariance function which requires only local information because it depends only\non the number of training samples in the proximity of a considered test point.\nFurthermore, we prove sufficient conditions which ensure the convergence of the\nposterior variance to zero. Finally, we demonstrate that the extension of our\nbound to an average learning bound outperforms existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:25:17 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lederer", "Armin", ""], ["Umlauft", "Jonas", ""], ["Hirche", "Sandra", ""]]}, {"id": "1906.01407", "submitter": "Hao Lu", "authors": "Hao Lu, Mengdi Wang", "title": "RL4health: Crowdsourcing Reinforcement Learning for Knee Replacement\n  Pathway Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint replacement is the most common inpatient surgical treatment in the US.\nWe investigate the clinical pathway optimization for knee replacement, which is\na sequential decision process from onset to recovery. Based on episodic claims\nfrom previous cases, we view the pathway optimization as an intelligence\ncrowdsourcing problem and learn the optimal decision policy from data by\nimitating the best expert at every intermediate state. We develop a\nreinforcement learning-based pipeline that uses value iteration, state\ncompression and aggregation learning, kernel representation and cross\nvalidation to predict the best treatment policy. It also provides forecast of\nthe clinical pathway under the optimized policy. Empirical validation shows\nthat the optimized policy reduces the overall cost by 7 percent and reduces the\nexcessive cost premium by 33 percent.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:12:02 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lu", "Hao", ""], ["Wang", "Mengdi", ""]]}, {"id": "1906.01408", "submitter": "Caleb Chuck", "authors": "Caleb Chuck, Supawit Chockchowwat, Scott Niekum", "title": "Hypothesis-Driven Skill Discovery for Hierarchical Deep Reinforcement\n  Learning", "comments": "Submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is capable of learning high-performing\npolicies on a variety of complex high-dimensional tasks, ranging from video\ngames to robotic manipulation. However, standard DRL methods often suffer from\npoor sample efficiency, partially because they aim to be entirely\nproblem-agnostic. In this work, we introduce a novel approach to exploration\nand hierarchical skill learning that derives its sample efficiency from\nintuitive assumptions it makes about the behavior of objects both in the\nphysical world and simulations which mimic physics. Specifically, we propose\nthe Hypothesis Proposal and Evaluation (HyPE) algorithm, which discovers\nobjects from raw pixel data, generates hypotheses about the controllability of\nobserved changes in object state, and learns a hierarchy of skills to test\nthese hypotheses. We demonstrate that HyPE can dramatically improve the sample\nefficiency of policy learning in two different domains: a simulated robotic\nblock-pushing domain, and a popular benchmark task: Breakout. In these domains,\nHyPE learns high-scoring policies an order of magnitude faster than several\nstate-of-the-art reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:17:35 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 22:33:11 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 17:59:13 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chuck", "Caleb", ""], ["Chockchowwat", "Supawit", ""], ["Niekum", "Scott", ""]]}, {"id": "1906.01431", "submitter": "Gregory Plumb", "authors": "Gregory Plumb, Maruan Al-Shedivat, Eric Xing, Ameet Talwalkar", "title": "Regularizing Black-box Models for Improved Interpretability (HILL 2019\n  Version)", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA. arXiv admin note: substantial text overlap with\n  arXiv:1902.06787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the work on interpretable machine learning has focused on designing\neither inherently interpretable models, which typically trade-off accuracy for\ninterpretability, or post-hoc explanation systems, which lack guarantees about\ntheir explanation quality. We propose an alternative to these approaches by\ndirectly regularizing a black-box model for interpretability at training time.\nOur approach explicitly connects three key aspects of interpretable machine\nlearning: (i) the model's innate explainability, (ii) the explanation system\nused at test time, and (iii) the metrics that measure explanation quality. Our\nregularization results in substantial improvement in terms of the explanation\nfidelity and stability metrics across a range of datasets and black-box\nexplanation systems while slightly improving accuracy. Further, if the\nresulting model is still not sufficiently interpretable, the weight of the\nregularization term can be adjusted to achieve the desired trade-off between\naccuracy and interpretability. Finally, we justify theoretically that the\nbenefits of explanation-based regularization generalize to unseen points.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:18:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Plumb", "Gregory", ""], ["Al-Shedivat", "Maruan", ""], ["Xing", "Eric", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1906.01432", "submitter": "Mayukh Das", "authors": "Mayukh Das, Devendra Singh Dhami, Yang Yu, Gautam Kunapuli, Sriraam\n  Natarajan", "title": "Knowledge-augmented Column Networks: Guiding Deep Learning with Advice", "comments": "Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA. arXiv admin note: substantial text overlap with\n  arXiv:1904.06950", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep models have had considerable success in several tasks,\nespecially with low-level representations. However, effective learning from\nsparse noisy samples is a major challenge in most deep models, especially in\ndomains with structured representations. Inspired by the proven success of\nhuman guided machine learning, we propose Knowledge-augmented Column Networks,\na relational deep learning framework that leverages human advice/knowledge to\nlearn better models in presence of sparsity and systematic noise.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 21:09:21 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Das", "Mayukh", ""], ["Dhami", "Devendra Singh", ""], ["Yu", "Yang", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1906.01437", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Nhat Ho, Michael I. Jordan", "title": "On the Efficiency of the Sinkhorn and Greenkhorn Algorithms and Their\n  Acceleration for Optimal Transport", "comments": "A preliminary version [arXiv:1901.06482] of this paper, with a subset\n  of the results that are presented here, was presented at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new complexity results for several algorithms that approximately\nsolve the regularized optimal transport (OT) problem between two discrete\nprobability measures with at most $n$ atoms. First, we show that a greedy\nvariant of the classical Sinkhorn algorithm, known as the \\textit{Greenkhorn}\nalgorithm, achieves the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-2})$, which improves the best known\nbound $\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-3})$. Notably, this matches the\nbest known complexity bound of the Sinkhorn algorithm and explains the superior\nperformance of the Greenkhorn algorithm in practice. Furthermore, we generalize\nan adaptive primal-dual accelerated gradient descent (APDAGD) algorithm with\nmirror mapping $\\phi$ and show that the resulting \\textit{adaptive primal-dual\naccelerated mirror descent} (APDAMD) algorithm achieves the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^2\\sqrt{\\delta}\\varepsilon^{-1})$ where $\\delta>0$\ndepends on $\\phi$. We point out that an existing complexity bound for the\nAPDAGD algorithm is not valid in general using a simple counterexample and then\nestablish the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^{5/2}\\varepsilon^{-1})$ by exploiting the connection\nbetween the APDAMD and APDAGD algorithms. Moreover, we introduce accelerated\nSinkhorn and Greenkhorn algorithms that achieve the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^{7/3}\\varepsilon^{-1})$, which improves on the\ncomplexity bounds $\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-2})$ of Sinkhorn\nand Greenkhorn algorithms in terms of $\\varepsilon$. Experimental results on\nsynthetic and real datasets demonstrate the favorable performance of new\nalgorithms in practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 05:33:05 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 07:16:49 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2019 04:21:58 GMT"}, {"version": "v4", "created": "Sun, 4 Aug 2019 18:15:07 GMT"}, {"version": "v5", "created": "Thu, 17 Oct 2019 23:25:15 GMT"}, {"version": "v6", "created": "Tue, 24 Mar 2020 02:50:47 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lin", "Tianyi", ""], ["Ho", "Nhat", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.01450", "submitter": "Saurabh Verma", "authors": "Saurabh Agrawal, Saurabh Verma, Anuj Karpatne, Stefan Liess,\n  Snigdhansu Chatterjee, Vipin Kumar", "title": "A Fast-Optimal Guaranteed Algorithm For Learning Sub-Interval\n  Relationships in Time Series", "comments": "Accepted at The Thirty-sixth International Conference on Machine\n  Learning (ICML 2019), Time Series Workshop. arXiv admin note: substantial\n  text overlap with arXiv:1802.06095", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches focus on finding relationships between two entire time\nseries, however, many interesting relationships exist in small sub-intervals of\ntime and remain feeble during other sub-intervals. We define the notion of a\nsub-interval relationship (SIR) to capture such interactions that are prominent\nonly in certain sub-intervals of time. To that end, we propose a fast-optimal\nguaranteed algorithm to find most interesting SIR relationship in a pair of\ntime series. Lastly, we demonstrate the utility of our method in climate\nscience domain based on a real-world dataset along with its scalability scope\nand obtain useful domain insights.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 01:00:47 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Agrawal", "Saurabh", ""], ["Verma", "Saurabh", ""], ["Karpatne", "Anuj", ""], ["Liess", "Stefan", ""], ["Chatterjee", "Snigdhansu", ""], ["Kumar", "Vipin", ""]]}, {"id": "1906.01470", "submitter": "Alexander Vezhnevets", "authors": "Alexander Sasha Vezhnevets, Yuhuai Wu, Remi Leblond, Joel Z. Leibo", "title": "Options as responses: Grounding behavioural hierarchies in multi-agent\n  RL", "comments": "First two authors contributed equally", "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates generalisation in multi-agent games, where the\ngenerality of the agent can be evaluated by playing against opponents it hasn't\nseen during training. We propose two new games with concealed information and\ncomplex, non-transitive reward structure (think rock/paper/scissors). It turns\nout that most current deep reinforcement learning methods fail to efficiently\nexplore the strategy space, thus learning policies that generalise poorly to\nunseen opponents. We then propose a novel hierarchical agent architecture,\nwhere the hierarchy is grounded in the game-theoretic structure of the game --\nthe top level chooses strategic responses to opponents, while the low level\nimplements them into policy over primitive actions. This grounding facilitates\ncredit assignment across the levels of hierarchy. Our experiments show that the\nproposed hierarchical agent is capable of generalisation to unseen opponents,\nwhile conventional baselines fail to generalise whatsoever.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:18:47 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 15:10:59 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 13:31:16 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Vezhnevets", "Alexander Sasha", ""], ["Wu", "Yuhuai", ""], ["Leblond", "Remi", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1906.01476", "submitter": "Debasish Chatterjee", "authors": "Mishal Assif P K, Debasish Chatterjee, Ravi Banavar", "title": "Scenario approach for minmax optimization with emphasis on the nonconvex\n  case: positive results and caveats", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat the so-called scenario approach, a popular probabilistic\napproximation method for robust minmax optimization problems via independent\nand indentically distributed (i.i.d) sampling from the uncertainty set, from\nvarious perspectives. The scenario approach is well-studied in the important\ncase of convex robust optimization problems, and here we examine how the\nphenomenon of concentration of measures affects the i.i.d sampling aspect of\nthe scenario approach in high dimensions and its relation with the optimal\nvalues. Moreover, we perform a detailed study of both the asymptotic behaviour\n(consistency) and finite time behaviour of the scenario approach in the more\ngeneral setting of nonconvex minmax optimization problems. In the direction of\nthe asymptotic behaviour of the scenario approach, we present an obstruction to\nconsistency that arises when the decision set is noncompact. In the direction\nof finite sample guarantees, we establish a general methodology for extracting\n`probably approximately correct' type estimates for the finite sample behaviour\nof the scenario approach for a large class of nonconvex problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:32:39 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 05:45:16 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["K", "Mishal Assif P", ""], ["Chatterjee", "Debasish", ""], ["Banavar", "Ravi", ""]]}, {"id": "1906.01478", "submitter": "Vegard Antun", "authors": "Laura Thesing, Vegard Antun and Anders C. Hansen", "title": "What do AI algorithms actually learn? - On false structures in deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two big unsolved mathematical questions in artificial intelligence\n(AI): (1) Why is deep learning so successful in classification problems and (2)\nwhy are neural nets based on deep learning at the same time universally\nunstable, where the instabilities make the networks vulnerable to adversarial\nattacks. We present a solution to these questions that can be summed up in two\nwords; false structures. Indeed, deep learning does not learn the original\nstructures that humans use when recognising images (cats have whiskers, paws,\nfur, pointy ears, etc), but rather different false structures that correlate\nwith the original structure and hence yield the success. However, the false\nstructure, unlike the original structure, is unstable. The false structure is\nsimpler than the original structure, hence easier to learn with less data and\nthe numerical algorithm used in the training will more easily converge to the\nneural network that captures the false structure. We formally define the\nconcept of false structures and formulate the solution as a conjecture. Given\nthat trained neural networks always are computed with approximations, this\nconjecture can only be established through a combination of theoretical and\ncomputational results similar to how one establishes a postulate in theoretical\nphysics (e.g. the speed of light is constant). Establishing the conjecture\nfully will require a vast research program characterising the false structures.\nWe provide the foundations for such a program establishing the existence of the\nfalse structures in practice. Finally, we discuss the far reaching consequences\nthe existence of the false structures has on state-of-the-art AI and Smale's\n18th problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:35:32 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Thesing", "Laura", ""], ["Antun", "Vegard", ""], ["Hansen", "Anders C.", ""]]}, {"id": "1906.01496", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz, Nikolaos Pappas, James Henderson, Banriskhem K.\n  Khonglah, Srikanth Madikeri", "title": "Regularization Advantages of Multilingual Neural Language Models for Low\n  Resource Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language modeling (LM) has led to significant improvements in several\napplications, including Automatic Speech Recognition. However, they typically\nrequire large amounts of training data, which is not available for many domains\nand languages. In this study, we propose a multilingual neural language model\narchitecture, trained jointly on the domain-specific data of several\nlow-resource languages. The proposed multilingual LM consists of language\nspecific word embeddings in the encoder and decoder, and one language specific\nLSTM layer, plus two LSTM layers with shared parameters across the languages.\nThis multilingual LM model facilitates transfer learning across the languages,\nacting as an extra regularizer in very low-resource scenarios. We integrate our\nproposed multilingual approach with a state-of-the-art highly-regularized\nneural LM, and evaluate on the conversational data domain for four languages\nover a range of training data sizes. Compared to monolingual LMs, the results\nshow significant improvements of our proposed multilingual LM when the amount\nof available training data is limited, indicating the advantages of\ncross-lingual parameter sharing in very low-resource language modeling.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:27:11 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Rekabsaz", "Navid", ""], ["Pappas", "Nikolaos", ""], ["Henderson", "James", ""], ["Khonglah", "Banriskhem K.", ""], ["Madikeri", "Srikanth", ""]]}, {"id": "1906.01498", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Julien Hogan, Andrew B. Adams, Raymond J. Lynch, Rachel\n  E. Patzer, Jinho D. Choi", "title": "Multimodal Ensemble Approach to Incorporate Various Types of Clinical\n  Notes for Predicting Readmission", "comments": "4 pages, IEEE BHI 2019", "journal-ref": "Proceedings of the IEEE-EMBS International Conference on\n  Biomedical and Health Informatics, 2019 (BHI'19)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHRs) have been heavily used to predict various\ndownstream clinical tasks such as readmission or mortality. One of the\nmodalities in EHRs, clinical notes, has not been fully explored for these tasks\ndue to its unstructured and inexplicable nature. Although recent advances in\ndeep learning (DL) enables models to extract interpretable features from\nunstructured data, they often require a large amount of training data. However,\nmany tasks in medical domains inherently consist of small sample data with\nlengthy documents; for a kidney transplant as an example, data from only a few\nthousand of patients are available and each patient's document consists of a\ncouple of millions of words in major hospitals. Thus, complex DL methods cannot\nbe applied to these kinds of domains. In this paper, we present a comprehensive\nensemble model using vector space modeling and topic modeling. Our proposed\nmodel is evaluated on the readmission task of kidney transplant patients and\nimproves 0.0211 in terms of c-statistics from the previous state-of-the-art\napproach using structured data, while typical DL methods fail to beat this\napproach. The proposed architecture provides the interpretable score for each\nfeature from both modalities, structured and unstructured data, which is shown\nto be meaningful through a physician's evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:25:06 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Shin", "Bonggun", ""], ["Hogan", "Julien", ""], ["Adams", "Andrew B.", ""], ["Lynch", "Raymond J.", ""], ["Patzer", "Rachel E.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1906.01504", "submitter": "Matteo Fischetti", "authors": "Matteo Fischetti and Matteo Stringher", "title": "Embedded hyper-parameter tuning by Simulated Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new metaheuristic training scheme that combines Stochastic\nGradient Descent (SGD) and Discrete Optimization in an unconventional way. Our\nidea is to define a discrete neighborhood of the current SGD point containing a\nnumber of \"potentially good moves\" that exploit gradient information, and to\nsearch this neighborhood by using a classical metaheuristic scheme borrowed\nfrom Discrete Optimization.\n  In the present paper we investigate the use of a simple Simulated Annealing\n(SA) metaheuristic that accepts/rejects a candidate new solution in the\nneighborhood with a probability that depends both on the new solution quality\nand on a parameter (the temperature) which is modified over time to lower the\nprobability of accepting worsening moves. We use this scheme as an automatic\nway to perform hyper-parameter tuning, hence the title of the paper. A\ndistinctive feature of our scheme is that hyper-parameters are modified within\na single SGD execution (and not in an external loop, as customary) and\nevaluated on the fly on the current minibatch, i.e., their tuning is fully\nembedded within the SGD algorithm.\n  The use of SA for training is not new, but previous proposals were mainly\nintended for non-differentiable objective functions for which SGD is not\napplied due to the lack of gradients. On the contrary, our SA method requires\ndifferentiability of (a proxy of) the loss function, and leverages on the\navailability of a gradient direction to define local moves that have a large\nprobability to improve the current solution.\n  Computational results on image classification (CIFAR-10) are reported,\nshowing that the proposed approach leads to an improvement of the final\nvalidation accuracy for modern Deep Neural Networks such as ResNet34 and VGG16.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:14:36 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Fischetti", "Matteo", ""], ["Stringher", "Matteo", ""]]}, {"id": "1906.01507", "submitter": "Matthew Burfitt", "authors": "Francisco Belch\\'i, Jacek Brodzki, Matthew Burfitt, Mahesan Niranjan", "title": "A numerical measure of the instability of Mapper-type algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapper is an unsupervised machine learning algorithm generalising the notion\nof clustering to obtain a geometric description of a dataset. The procedure\nsplits the data into possibly overlapping bins which are then clustered. The\noutput of the algorithm is a graph where nodes represent clusters and edges\nrepresent the sharing of data points between two clusters. However, several\nparameters must be selected before applying Mapper and the resulting graph may\nvary dramatically with the choice of parameters.\n  We define an intrinsic notion of Mapper instability that measures the\nvariability of the output as a function of the choice of parameters required to\nconstruct a Mapper output. Our results and discussion are general and apply to\nall Mapper-type algorithms. We derive theoretical results that provide\nestimates for the instability and suggest practical ways to control it. We\nprovide also experiments to illustrate our results and in particular we\ndemonstrate that a reliable candidate Mapper output can be identified as a\nlocal minimum of instability regarded as a function of Mapper input parameters.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:15:14 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Belch\u00ed", "Francisco", ""], ["Brodzki", "Jacek", ""], ["Burfitt", "Matthew", ""], ["Niranjan", "Mahesan", ""]]}, {"id": "1906.01510", "submitter": "Jiri Navratil", "authors": "Jiri Navratil, Alan King, Jesus Rios, Georgios Kollias, Ruben Torrado,\n  Andres Codas", "title": "Accelerating Physics-Based Simulations Using Neural Network Proxies: An\n  Application in Oil Reservoir Modeling", "comments": "9 pages, submitted to FEED-2019 KDD Workshop & Frontiers in Big Data", "journal-ref": "Front. Big Data, 20 September 2019", "doi": "10.3389/fdata.2019.00033", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a proxy model based on deep learning methods to accelerate the\nsimulations of oil reservoirs--by three orders of magnitude--compared to\nindustry-strength physics-based PDE solvers. This paper describes a new\narchitectural approach to this task, accompanied by a thorough experimental\nevaluation on a publicly available reservoir model. We demonstrate that in a\npractical setting a speedup of more than 2000X can be achieved with an average\nsequence error of about 10\\% relative to the oil-field simulator. The proxy\nmodel is contrasted with a high-quality physics-based acceleration baseline and\nis shown to outperform it by several orders of magnitude. We believe the\noutcomes presented here are extremely promising and offer a valuable benchmark\nfor continuing research in oil field development optimization. Due to its\ndomain-agnostic architecture, the presented approach can be extended to many\napplications beyond the field of oil and gas exploration.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:09:13 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Navratil", "Jiri", ""], ["King", "Alan", ""], ["Rios", "Jesus", ""], ["Kollias", "Georgios", ""], ["Torrado", "Ruben", ""], ["Codas", "Andres", ""]]}, {"id": "1906.01515", "submitter": "Piotr Niewinski", "authors": "Piotr Niewinski, Aleksander Wawer, Maria Pszona, Maria Janicka", "title": "TMLab SRPOL at SemEval-2019 Task 8: Fact Checking in Community Question\n  Answering Forums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes our submission to SemEval 2019 Task 8 on Fact-Checking\nin Community Forums. The systems under discussion participated in Subtask A:\ndecide whether a question asks for factual information, opinion/advice or is\njust socializing. Our primary submission was ranked as the second one among all\nparticipants in the official evaluation phase. The article presents our primary\nsolution: Deeply Regularized Residual Neural Network (DRR NN) with Universal\nSentence Encoder embeddings. This is followed by a description of two\ncontrastive solutions based on ensemble methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:31:26 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Niewinski", "Piotr", ""], ["Wawer", "Aleksander", ""], ["Pszona", "Maria", ""], ["Janicka", "Maria", ""]]}, {"id": "1906.01527", "submitter": "Kevin Roth", "authors": "Kevin Roth, Yannic Kilcher and Thomas Hofmann", "title": "Adversarial Training is a Form of Data-dependent Operator Norm\n  Regularization", "comments": "NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a theoretical link between adversarial training and operator\nnorm regularization for deep neural networks. Specifically, we prove that\n$\\ell_p$-norm constrained projected gradient ascent based adversarial training\nwith an $\\ell_q$-norm loss on the logits of clean and perturbed inputs is\nequivalent to data-dependent (p, q) operator norm regularization. This\nfundamental connection confirms the long-standing argument that a network's\nsensitivity to adversarial examples is tied to its spectral properties and\nhints at novel ways to robustify and defend against adversarial attacks. We\nprovide extensive empirical evidence on state-of-the-art network architectures\nto support our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:40:28 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 16:39:44 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 19:03:25 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 17:47:53 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 14:26:39 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Roth", "Kevin", ""], ["Kilcher", "Yannic", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1906.01528", "submitter": "Zhe Feng", "authors": "Zhe Feng, David C. Parkes, Haifeng Xu", "title": "The Intrinsic Robustness of Stochastic Bandits to Strategic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by economic applications such as recommender systems, we study the\nbehavior of stochastic bandits algorithms under \\emph{strategic behavior}\nconducted by rational actors, i.e., the arms. Each arm is a\n\\emph{self-interested} strategic player who can modify its own reward whenever\npulled, subject to a cross-period budget constraint, in order to maximize its\nown expected number of times of being pulled. We analyze the robustness of\nthree popular bandit algorithms: UCB, $\\varepsilon$-Greedy, and Thompson\nSampling. We prove that all three algorithms achieve a regret upper bound\n$\\mathcal{O}(\\max \\{ B, K\\ln T\\})$ where $B$ is the total budget across arms,\n$K$ is the total number of arms and $T$ is length of the time horizon. This\nregret guarantee holds under \\emph{arbitrary adaptive} manipulation strategy of\narms. Our second set of main results shows that this regret bound is\n\\emph{tight} -- in fact for UCB it is tight even when we restrict the arms'\nmanipulation strategies to form a \\emph{Nash equilibrium}. The lower bound\nmakes use of a simple manipulation strategy, the same for all three algorithms,\nyielding a bound of $\\Omega(\\max \\{ B, K\\ln T\\})$. Our results illustrate the\nrobustness of classic bandits algorithms against strategic manipulations as\nlong as $B=o(T)$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:40:49 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 21:56:33 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Feng", "Zhe", ""], ["Parkes", "David C.", ""], ["Xu", "Haifeng", ""]]}, {"id": "1906.01537", "submitter": "Raul Astudillo", "authors": "Raul Astudillo, Peter I. Frazier", "title": "Bayesian Optimization of Composite Functions", "comments": "In Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:354-363, 2019", "journal-ref": "In Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:354-363, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimization of composite objective functions, i.e., of the form\n$f(x)=g(h(x))$, where $h$ is a black-box derivative-free expensive-to-evaluate\nfunction with vector-valued outputs, and $g$ is a cheap-to-evaluate real-valued\nfunction. While these problems can be solved with standard Bayesian\noptimization, we propose a novel approach that exploits the composite structure\nof the objective function to substantially improve sampling efficiency. Our\napproach models $h$ using a multi-output Gaussian process and chooses where to\nsample using the expected improvement evaluated on the implied non-Gaussian\nposterior on $f$, which we call expected improvement for composite functions\n(\\ei). Although \\ei\\ cannot be computed in closed form, we provide a novel\nstochastic gradient estimator that allows its efficient maximization. We also\nshow that our approach is asymptotically consistent, i.e., that it recovers a\nglobally optimal solution as sampling effort grows to infinity, generalizing\nprevious convergence results for classical expected improvement. Numerical\nexperiments show that our approach dramatically outperforms standard Bayesian\noptimization benchmarks, reducing simple regret by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:51:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Astudillo", "Raul", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1906.01549", "submitter": "Josue Nassar", "authors": "Yuan Zhao, Josue Nassar, Ian Jordan, M\\'onica Bugallo, Il Memming Park", "title": "Streaming Variational Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear state-space models are powerful tools to describe dynamical\nstructures in complex time series. In a streaming setting where data are\nprocessed one sample at a time, simultaneous inference of the state and its\nnonlinear dynamics has posed significant challenges in practice. We develop a\nnovel online learning framework, leveraging variational inference and\nsequential Monte Carlo, which enables flexible and accurate Bayesian joint\nfiltering. Our method provides an approximation of the filtering posterior\nwhich can be made arbitrarily close to the true filtering distribution for a\nwide class of dynamics models and observation models. Specifically, the\nproposed framework can efficiently approximate a posterior over the dynamics\nusing sparse Gaussian processes, allowing for an interpretable model of the\nlatent dynamics. Constant time complexity per sample makes our approach\namenable to online learning scenarios and suitable for real-time applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:07:07 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 21:59:33 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 23:36:06 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhao", "Yuan", ""], ["Nassar", "Josue", ""], ["Jordan", "Ian", ""], ["Bugallo", "M\u00f3nica", ""], ["Park", "Il Memming", ""]]}, {"id": "1906.01550", "submitter": "Scott Yak", "authors": "Scott Yak, Javier Gonzalvo, Hanna Mazzawi", "title": "Towards Task and Architecture-Independent Generalization Gap Predictors", "comments": "8 pages, 6 figures, 2 tables. To be presented at ICML 2019\n  \"Understanding and Improving Generalization in Deep Learning\" Workshop\n  (poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Can we use deep learning to predict when deep learning works? Our results\nsuggest the affirmative. We created a dataset by training 13,500 neural\nnetworks with different architectures, on different variations of spiral\ndatasets, and using different optimization parameters. We used this dataset to\ntrain task-independent and architecture-independent generalization gap\npredictors for those neural networks. We extend Jiang et al. (2018) to also use\nDNNs and RNNs and show that they outperform the linear model, obtaining\n$R^2=0.965$. We also show results for architecture-independent,\ntask-independent, and out-of-distribution generalization gap prediction tasks.\nBoth DNNs and RNNs consistently and significantly outperform linear models,\nwith RNNs obtaining $R^2=0.584$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:10:15 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Yak", "Scott", ""], ["Gonzalvo", "Javier", ""], ["Mazzawi", "Hanna", ""]]}, {"id": "1906.01552", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Angela Zhou", "title": "Assessing Disparate Impacts of Personalized Interventions:\n  Identifiability and Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized interventions in social services, education, and healthcare\nleverage individual-level causal effect predictions in order to give the best\ntreatment to each individual or to prioritize program interventions for the\nindividuals most likely to benefit. While the sensitivity of these domains\ncompels us to evaluate the fairness of such policies, we show that actually\nauditing their disparate impacts per standard observational metrics, such as\ntrue positive rates, is impossible since ground truths are unknown. Whether our\ndata is experimental or observational, an individual's actual outcome under an\nintervention different than that received can never be known, only predicted\nbased on features. We prove how we can nonetheless point-identify these\nquantities under the additional assumption of monotone treatment response,\nwhich may be reasonable in many applications. We further provide a sensitivity\nanalysis for this assumption by means of sharp partial-identification bounds\nunder violations of monotonicity of varying strengths. We show how to use our\nresults to audit personalized interventions using partially-identified ROC and\nxROC curves and demonstrate this in a case study of a French job training\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:11:07 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "1906.01578", "submitter": "Johann Brehmer Mr", "authors": "Johann Brehmer, Kyle Cranmer, Irina Espejo, Felix Kling, Gilles\n  Louppe, and Juan Pavez", "title": "Effective LHC measurements with matrix elements and machine learning", "comments": "Keynote at the 19th International Workshop on Advanced Computing and\n  Analysis Techniques in Physics Research (ACAT 2019)", "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012022", "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major challenge for the legacy measurements at the LHC is that the\nlikelihood function is not tractable when the collected data is\nhigh-dimensional and the detector response has to be modeled. We review how\ndifferent analysis strategies solve this issue, including the traditional\nhistogram approach used in most particle physics analyses, the Matrix Element\nMethod, Optimal Observables, and modern techniques based on neural density\nestimation. We then discuss powerful new inference methods that use a\ncombination of matrix element information and machine learning to accurately\nestimate the likelihood function. The MadMiner package automates all necessary\ndata-processing steps. In first studies we find that these new techniques have\nthe potential to substantially improve the sensitivity of the LHC legacy\nmeasurements.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:46:42 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Brehmer", "Johann", ""], ["Cranmer", "Kyle", ""], ["Espejo", "Irina", ""], ["Kling", "Felix", ""], ["Louppe", "Gilles", ""], ["Pavez", "Juan", ""]]}, {"id": "1906.01581", "submitter": "Hoang Son Pham", "authors": "Hoang Son Pham, Gwendal Virlet, Dominique Lavenier, Alexandre Termier", "title": "Statistically Significant Discriminative Patterns Searching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminative pattern mining is an essential task of data mining. This task\naims to discover patterns which occur more frequently in a class than other\nclasses in a class-labeled dataset. This type of patterns is valuable in\nvarious domains such as bioinformatics, data classification. In this paper, we\npropose a novel algorithm, named SSDPS, to discover patterns in two-class\ndatasets. The SSDPS algorithm owes its efficiency to an original enumeration\nstrategy of the patterns, which allows to exploit some degrees of\nanti-monotonicity on the measures of discriminance and statistical\nsignificance. Experimental results demonstrate that the performance of the\nSSDPS algorithm is better than others. In addition, the number of generated\npatterns is much less than the number of other algorithms. Experiment on real\ndata also shows that SSDPS efficiently detects multiple SNPs combinations in\ngenetic data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 11:51:50 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Pham", "Hoang Son", ""], ["Virlet", "Gwendal", ""], ["Lavenier", "Dominique", ""], ["Termier", "Alexandre", ""]]}, {"id": "1906.01584", "submitter": "Jack Umenberger", "authors": "Jack Umenberger, Mina Ferizbegovic, Thomas B. Sch\\\"on, H{\\aa}kan\n  Hjalmarsson", "title": "Robust exploration in linear quadratic reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the problem of learning control policies for an unknown\nlinear dynamical system to minimize a quadratic cost function. We present a\nmethod, based on convex optimization, that accomplishes this task robustly:\ni.e., we minimize the worst-case cost, accounting for system uncertainty given\nthe observed data. The method balances exploitation and exploration, exciting\nthe system in such a way so as to reduce uncertainty in the model parameters to\nwhich the worst-case cost is most sensitive. Numerical simulations and\napplication to a hardware-in-the-loop servo-mechanism demonstrate the approach,\nwith appreciable performance and robustness gains over alternative methods\nobserved in both.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:57:37 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Umenberger", "Jack", ""], ["Ferizbegovic", "Mina", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Hjalmarsson", "H\u00e5kan", ""]]}, {"id": "1906.01600", "submitter": "Georgios Leontidis", "authors": "George Onoufriou, Ronald Bickerton, Simon Pearson, Georgios Leontidis", "title": "Nemesyst: A Hybrid Parallelism Deep Learning-Based Framework Applied for\n  Internet of Things Enabled Food Retailing Refrigeration Systems", "comments": "25 pages, 13 figures, 4 tables, 2 appendices", "journal-ref": "Computers in Industry, 2019", "doi": "10.1016/j.compind.2019.103133", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has attracted considerable attention across multiple\napplication domains, including computer vision, signal processing and natural\nlanguage processing. Although quite a few single node deep learning frameworks\nexist, such as tensorflow, pytorch and keras, we still lack a complete\nprocessing structure that can accommodate large scale data processing, version\ncontrol, and deployment, all while staying agnostic of any specific single node\nframework. To bridge this gap, this paper proposes a new, higher level\nframework, i.e. Nemesyst, which uses databases along with model\nsequentialisation to allow processes to be fed unique and transformed data at\nthe point of need. This facilitates near real-time application and makes models\navailable for further training or use at any node that has access to the\ndatabase simultaneously. Nemesyst is well suited as an application framework\nfor internet of things aggregated control systems, deploying deep learning\ntechniques to optimise individual machines in massive networks. To demonstrate\nthis framework, we adopted a case study in a novel domain; deploying deep\nlearning to optimise the high speed control of electrical power consumed by a\nmassive internet of things network of retail refrigeration systems in\nproportion to load available on the UK National Grid (a demand side response).\nThe case study demonstrated for the first time in such a setting how deep\nlearning models, such as Recurrent Neural Networks (vanilla and Long-Short-Term\nMemory) and Generative Adversarial Networks paired with Nemesyst, achieve\ncompelling performance, whilst still being malleable to future adjustments as\nboth the data and requirements inevitably change over time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:23:09 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 22:55:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Onoufriou", "George", ""], ["Bickerton", "Ronald", ""], ["Pearson", "Simon", ""], ["Leontidis", "Georgios", ""]]}, {"id": "1906.01601", "submitter": "Li Chen", "authors": "Cencheng Shen, Li Chen, Yuexiao Dong, Carey Priebe", "title": "Sparse Representation Classification via Screening for Graphs", "comments": "Accepted at Learning and Reasoning with Graph-Structured\n  Representations in International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse representation classifier (SRC) is shown to work well for image\nrecognition problems that satisfy a subspace assumption. In this paper we\npropose a new implementation of SRC via screening, establish its equivalence to\nthe original SRC under regularity conditions, and prove its classification\nconsistency for random graphs drawn from stochastic blockmodels. The results\nare demonstrated via simulations and real data experiments, where the new\nalgorithm achieves comparable numerical performance but significantly faster.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:23:45 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Shen", "Cencheng", ""], ["Chen", "Li", ""], ["Dong", "Yuexiao", ""], ["Priebe", "Carey", ""]]}, {"id": "1906.01604", "submitter": "Mitchell Stern", "authors": "William Chan, Nikita Kitaev, Kelvin Guu, Mitchell Stern, Jakob\n  Uszkoreit", "title": "KERMIT: Generative Insertion-Based Modeling for Sequences", "comments": "William Chan, Nikita Kitaev, Kelvin Guu, and Mitchell Stern\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present KERMIT, a simple insertion-based approach to generative modeling\nfor sequences and sequence pairs. KERMIT models the joint distribution and its\ndecompositions (i.e., marginals and conditionals) using a single neural network\nand, unlike much prior work, does not rely on a prespecified factorization of\nthe data distribution. During training, one can feed KERMIT paired data $(x,\ny)$ to learn the joint distribution $p(x, y)$, and optionally mix in unpaired\ndata $x$ or $y$ to refine the marginals $p(x)$ or $p(y)$. During inference, we\nhave access to the conditionals $p(x \\mid y)$ and $p(y \\mid x)$ in both\ndirections. We can also sample from the joint distribution or the marginals.\nThe model supports both serial fully autoregressive decoding and parallel\npartially autoregressive decoding, with the latter exhibiting an empirically\nlogarithmic runtime. We demonstrate through experiments in machine translation,\nrepresentation learning, and zero-shot cloze question answering that our\nunified approach is capable of matching or exceeding the performance of\ndedicated state-of-the-art systems across a wide range of tasks without the\nneed for problem-specific architectural adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:35:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chan", "William", ""], ["Kitaev", "Nikita", ""], ["Guu", "Kelvin", ""], ["Stern", "Mitchell", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1906.01611", "submitter": "Nikolaos Ignatiadis", "authors": "Nikolaos Ignatiadis, Stefan Wager", "title": "Covariate-Powered Empirical Bayes Estimation", "comments": "Advances in Neural Information Processing Systems 32 (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for simultaneous analysis of many noisy experiments in the\npresence of rich covariate information. The goal of the analyst is to optimally\nestimate the true effect underlying each experiment. Both the noisy\nexperimental results and the auxiliary covariates are useful for this purpose,\nbut neither data source on its own captures all the information available to\nthe analyst. In this paper, we propose a flexible plug-in empirical Bayes\nestimator that synthesizes both sources of information and may leverage any\nblack-box predictive model. We show that our approach is within a constant\nfactor of minimax for a simple data-generating model. Furthermore, we establish\nrobust convergence guarantees for our method that hold under considerable\ngenerality, and exhibit promising empirical performance on both real and\nsimulated data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:44:25 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 02:26:53 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ignatiadis", "Nikolaos", ""], ["Wager", "Stefan", ""]]}, {"id": "1906.01614", "submitter": "Nian Si", "authors": "Jose Blanchet, Karthyek Murthy, Nian Si", "title": "Confidence Regions in Wasserstein Distributionally Robust Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distributionally robust optimization estimators are obtained as\nsolutions of min-max problems in which the statistician selects a parameter\nminimizing the worst-case loss among all probability models within a certain\ndistance (in a Wasserstein sense) from the underlying empirical measure. While\nmotivated by the need to identify optimal model parameters or decision choices\nthat are robust to model misspecification, these distributionally robust\nestimators recover a wide range of regularized estimators, including\nsquare-root lasso and support vector machines, among others, as particular\ncases. This paper studies the asymptotic normality of these distributionally\nrobust estimators as well as the properties of an optimal (in a suitable sense)\nconfidence region induced by the Wasserstein distributionally robust\noptimization formulation. In addition, key properties of min-max\ndistributionally robust optimization problems are also studied, for example, we\nshow that distributionally robust estimators regularize the loss based on its\nderivative and we also derive general sufficient conditions which show the\nequivalence between the min-max distributionally robust optimization problem\nand the corresponding max-min formulation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:45:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 11:43:52 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 06:42:17 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 08:21:04 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Blanchet", "Jose", ""], ["Murthy", "Karthyek", ""], ["Si", "Nian", ""]]}, {"id": "1906.01620", "submitter": "Fredrik K. Gustafsson", "authors": "Fredrik K. Gustafsson, Martin Danelljan, Thomas B. Sch\\\"on", "title": "Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer\n  Vision", "comments": "CVPR Workshops 2020. Code is available at\n  https://github.com/fregu856/evaluating_bdl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have become the go-to approach in computer vision,\nthe vast majority of these models fail to properly capture the uncertainty\ninherent in their predictions. Estimating this predictive uncertainty can be\ncrucial, for example in automotive applications. In Bayesian deep learning,\npredictive uncertainty is commonly decomposed into the distinct types of\naleatoric and epistemic uncertainty. The former can be estimated by letting a\nneural network output the parameters of a certain probability distribution.\nEpistemic uncertainty estimation is a more challenging problem, and while\ndifferent scalable methods recently have emerged, no extensive comparison has\nbeen performed in a real-world setting. We therefore accept this task and\npropose a comprehensive evaluation framework for scalable epistemic uncertainty\nestimation methods in deep learning. Our proposed framework is specifically\ndesigned to test the robustness required in real-world computer vision\napplications. We also apply this framework to provide the first properly\nextensive and conclusive comparison of the two current state-of-the-art\nscalable methods: ensembling and MC-dropout. Our comparison demonstrates that\nensembling consistently provides more reliable and practically useful\nuncertainty estimates. Code is available at\nhttps://github.com/fregu856/evaluating_bdl.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:54:20 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 10:48:25 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 12:49:00 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Gustafsson", "Fredrik K.", ""], ["Danelljan", "Martin", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1906.01621", "submitter": "Brian Bullins", "authors": "Brian Bullins, Richard Peng", "title": "Higher-Order Accelerated Methods for Faster Non-Smooth Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide improved convergence rates for various \\emph{non-smooth}\noptimization problems via higher-order accelerated methods. In the case of\n$\\ell_\\infty$ regression, we achieves an $O(\\epsilon^{-4/5})$ iteration\ncomplexity, breaking the $O(\\epsilon^{-1})$ barrier so far present for previous\nmethods. We arrive at a similar rate for the problem of $\\ell_1$-SVM, going\nbeyond what is attainable by first-order methods with prox-oracle access for\nnon-smooth non-strongly convex problems. We further show how to achieve even\nfaster rates by introducing higher-order regularization.\n  Our results rely on recent advances in near-optimal accelerated methods for\nhigher-order smooth convex optimization. In particular, we extend Nesterov's\nsmoothing technique to show that the standard softmax approximation is not only\nsmooth in the usual sense, but also \\emph{higher-order} smooth. With this\nobservation in hand, we provide the first example of higher-order acceleration\ntechniques yielding faster rates for \\emph{non-smooth} optimization, to the\nbest of our knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:54:44 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Bullins", "Brian", ""], ["Peng", "Richard", ""]]}, {"id": "1906.01624", "submitter": "Alexander Irpan", "authors": "Alex Irpan, Kanishka Rao, Konstantinos Bousmalis, Chris Harris, Julian\n  Ibarz, Sergey Levine", "title": "Off-Policy Evaluation via Off-Policy Classification", "comments": "Accepted to NeurIPS 2019. Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of model selection for deep\nreinforcement learning (RL) in real-world environments. Typically, the\nperformance of deep RL algorithms is evaluated via on-policy interactions with\nthe target environment. However, comparing models in a real-world environment\nfor the purposes of early stopping or hyperparameter tuning is costly and often\npractically infeasible. This leads us to examine off-policy policy evaluation\n(OPE) in such settings. We focus on OPE for value-based methods, which are of\nparticular interest in deep RL, with applications like robotics, where\noff-policy algorithms based on Q-function estimation can often attain better\nsample complexity than direct policy optimization. Existing OPE metrics either\nrely on a model of the environment, or the use of importance sampling (IS) to\ncorrect for the data being off-policy. However, for high-dimensional\nobservations, such as images, models of the environment can be difficult to fit\nand value-based methods can make IS hard to use or even ill-conditioned,\nespecially when dealing with continuous action spaces. In this paper, we focus\non the specific case of MDPs with continuous action spaces and sparse binary\nrewards, which is representative of many important real-world applications. We\npropose an alternative metric that relies on neither models nor IS, by framing\nOPE as a positive-unlabeled (PU) classification problem with the Q-function as\nthe decision function. We experimentally show that this metric outperforms\nbaselines on a number of tasks. Most importantly, it can reliably predict the\nrelative performance of different policies in a number of generalization\nscenarios, including the transfer to the real-world of policies trained in\nsimulation for an image-based robotic manipulation task.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:57:06 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:05:40 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 01:19:09 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Irpan", "Alex", ""], ["Rao", "Kanishka", ""], ["Bousmalis", "Konstantinos", ""], ["Harris", "Chris", ""], ["Ibarz", "Julian", ""], ["Levine", "Sergey", ""]]}, {"id": "1906.01626", "submitter": "Ameya Joshi", "authors": "Viraj Shah, Ameya Joshi, Sambuddha Ghosal, Balaji Pokuri, Soumik\n  Sarkar, Baskar Ganapathysubramanian, Chinmay Hegde", "title": "Encoding Invariances in Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable training of generative adversarial networks (GANs) typically require\nmassive datasets in order to model complicated distributions. However, in\nseveral applications, training samples obey invariances that are \\textit{a\npriori} known; for example, in complex physics simulations, the training data\nobey universal laws encoded as well-defined mathematical equations. In this\npaper, we propose a new generative modeling approach, InvNet, that can\nefficiently model data spaces with known invariances. We devise an adversarial\ntraining algorithm to encode them into data distribution. We validate our\nframework in three experimental settings: generating images with fixed motifs;\nsolving nonlinear partial differential equations (PDEs); and reconstructing\ntwo-phase microstructures with desired statistical properties. We complement\nour experiments with several theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:57:57 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Shah", "Viraj", ""], ["Joshi", "Ameya", ""], ["Ghosal", "Sambuddha", ""], ["Pokuri", "Balaji", ""], ["Sarkar", "Soumik", ""], ["Ganapathysubramanian", "Baskar", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1906.01629", "submitter": "Maxime Gasse", "authors": "Maxime Gasse, Didier Ch\\'etelat, Nicola Ferroni, Laurent Charlin,\n  Andrea Lodi", "title": "Exact Combinatorial Optimization with Graph Convolutional Neural\n  Networks", "comments": "Accepted paper at the NeurIPS 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combinatorial optimization problems are typically tackled by the\nbranch-and-bound paradigm. We propose a new graph convolutional neural network\nmodel for learning branch-and-bound variable selection policies, which\nleverages the natural variable-constraint bipartite graph representation of\nmixed-integer linear programs. We train our model via imitation learning from\nthe strong branching expert rule, and demonstrate on a series of hard problems\nthat our approach produces policies that improve upon state-of-the-art\nmachine-learning methods for branching and generalize to instances\nsignificantly larger than seen during training. Moreover, we improve for the\nfirst time over expert-designed branching rules implemented in a\nstate-of-the-art solver on large problems. Code for reproducing all the\nexperiments can be found at https://github.com/ds4dm/learn2branch.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:59:40 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 20:29:32 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 15:21:45 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Gasse", "Maxime", ""], ["Ch\u00e9telat", "Didier", ""], ["Ferroni", "Nicola", ""], ["Charlin", "Laurent", ""], ["Lodi", "Andrea", ""]]}, {"id": "1906.01635", "submitter": "Stephan Sloth Lorenzen", "authors": "Magnus Stavngaard, August S{\\o}rensen, Stephan Lorenzen, Niklas\n  Hjuler, Stephen Alstrup", "title": "Detecting Ghostwriters in High Schools", "comments": "Presented at ESANN 2019", "journal-ref": "Proceedings. ESANN 2019: 27th European Symposium on Artificial\n  Neural Networks, Computational Intelligence and Machine Learning. ed. Michel\n  Verleysen. 2019. p 197-202", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students hiring ghostwriters to write their assignments is an increasing\nproblem in educational institutions all over the world, with companies selling\nthese services as a product. In this work, we develop automatic techniques with\nspecial focus on detecting such ghostwriting in high school assignments. This\nis done by training deep neural networks on an unprecedented large amount of\ndata supplied by the Danish company MaCom, which covers 90% of Danish high\nschools. We achieve an accuracy of 0.875 and a AUC score of 0.947 on an evenly\nsplit data set.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:03:38 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Stavngaard", "Magnus", ""], ["S\u00f8rensen", "August", ""], ["Lorenzen", "Stephan", ""], ["Hjuler", "Niklas", ""], ["Alstrup", "Stephen", ""]]}, {"id": "1906.01637", "submitter": "Chanyoung Park", "authors": "Chanyoung Park, Donghyun Kim, Xing Xie, Hwanjo Yu", "title": "Collaborative Translational Metric Learning", "comments": "ICDM 2018 Full Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, matrix factorization-based recommendation methods have been\ncriticized for the problem raised by the triangle inequality violation.\nAlthough several metric learning-based approaches have been proposed to\novercome this issue, existing approaches typically project each user to a\nsingle point in the metric space, and thus do not suffice for properly modeling\nthe intensity and the heterogeneity of user-item relationships in implicit\nfeedback. In this paper, we propose TransCF to discover such latent user-item\nrelationships embodied in implicit user-item interactions. Inspired by the\ntranslation mechanism popularized by knowledge graph embedding, we construct\nuser-item specific translation vectors by employing the neighborhood\ninformation of users and items, and translate each user toward items according\nto the user's relationships with the items. Our proposed method outperforms\nseveral state-of-the-art methods for top-N recommendation on seven real-world\ndata by up to 17% in terms of hit ratio. We also conduct extensive qualitative\nevaluations on the translation vectors learned by our proposed method to\nascertain the benefit of adopting the translation mechanism for implicit\nfeedback-based recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:23:25 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Park", "Chanyoung", ""], ["Kim", "Donghyun", ""], ["Xie", "Xing", ""], ["Yu", "Hwanjo", ""]]}, {"id": "1906.01668", "submitter": "Sandeep Madireddy", "authors": "Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash", "title": "Neuromorphic Architecture Optimization for Task-Specific Dynamic\n  Learning", "comments": null, "journal-ref": "Proceedings of the International Conference on Neuromorphic\n  Systems 2019. ACM, New York, NY, USA, Article 5, 5 pages", "doi": "10.1145/3354265.3354270", "report-no": "ANL/MCS-P9175-0419", "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn and adapt in real time is a central feature of\nbiological systems. Neuromorphic architectures demonstrating such versatility\ncan greatly enhance our ability to efficiently process information at the edge.\nA key challenge, however, is to understand which learning rules are best suited\nfor specific tasks and how the relevant hyperparameters can be fine-tuned. In\nthis work, we introduce a conceptual framework in which the learning process is\nintegrated into the network itself. This allows us to cast meta-learning as a\nmathematical optimization problem. We employ DeepHyper, a scalable,\nasynchronous model-based search, to simultaneously optimize the choice of\nmeta-learning rules and their hyperparameters. We demonstrate our approach with\ntwo different datasets, MNIST and FashionMNIST, using a network architecture\ninspired by the learning center of the insect brain. Our results show that\noptimal learning rules can be dataset-dependent even within similar tasks. This\ndependency demonstrates the importance of introducing versatility and\nflexibility in the learning algorithms. It also illuminates experimental\nfindings in insect neuroscience that have shown a heterogeneity of learning\nrules within the insect mushroom body.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:20:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Madireddy", "Sandeep", ""], ["Yanguas-Gil", "Angel", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1906.01681", "submitter": "Alhussein Fawzi", "authors": "Alhussein Fawzi and Mateusz Malinowski and Hamza Fawzi and Omar Fawzi", "title": "Learning dynamic polynomial proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial inequalities lie at the heart of many mathematical disciplines. In\nthis paper, we consider the fundamental computational task of automatically\nsearching for proofs of polynomial inequalities. We adopt the framework of\nsemi-algebraic proof systems that manipulate polynomial inequalities via\nelementary inference rules that infer new inequalities from the premises. These\nproof systems are known to be very powerful, but searching for proofs remains a\nmajor difficulty. In this work, we introduce a machine learning based method to\nsearch for a dynamic proof within these proof systems. We propose a deep\nreinforcement learning framework that learns an embedding of the polynomials\nand guides the choice of inference rules, taking the inherent symmetries of the\nproblem as an inductive bias. We compare our approach with powerful and\nwidely-studied linear programming hierarchies based on static proof systems,\nand show that our method reduces the size of the linear program by several\norders of magnitude while also improving performance. These results hence pave\nthe way towards augmenting powerful and well-studied semi-algebraic proof\nsystems with machine learning guiding strategies for enhancing the expressivity\nof such proof systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:58:40 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Fawzi", "Alhussein", ""], ["Malinowski", "Mateusz", ""], ["Fawzi", "Hamza", ""], ["Fawzi", "Omar", ""]]}, {"id": "1906.01684", "submitter": "Rafael Gomes Mantovani", "authors": "Rafael Gomes Mantovani, Andr\\'e Luis Debiaso Rossi, Edesio\n  Alcoba\\c{c}a, Joaquin Vanschoren, Andr\\'e Carlos Ponce de Leon Ferreira de\n  Carvalho", "title": "A meta-learning recommender system for hyperparameter tuning: predicting\n  when tuning improves SVM classifiers", "comments": "49 pages, 11 figures", "journal-ref": "Information Sciences, Volume 501, 2019. Pages 193-221, ISSN\n  0020-0255", "doi": "10.1016/j.ins.2019.06.005", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many machine learning algorithms, predictive performance is critically\naffected by the hyperparameter values used to train them. However, tuning these\nhyperparameters can come at a high computational cost, especially on larger\ndatasets, while the tuned settings do not always significantly outperform the\ndefault values. This paper proposes a recommender system based on meta-learning\nto identify exactly when it is better to use default values and when to tune\nhyperparameters for each new dataset. Besides, an in-depth analysis is\nperformed to understand what they take into account for their decisions,\nproviding useful insights. An extensive analysis of different categories of\nmeta-features, meta-learners, and setups across 156 datasets is performed.\nResults show that it is possible to accurately predict when tuning will\nsignificantly improve the performance of the induced models. The proposed\nsystem reduces the time spent on optimization processes, without reducing the\npredictive performance of the induced models (when compared with the ones\nobtained using tuned hyperparameters). We also explain the decision-making\nprocess of the meta-learners in terms of linear separability-based hypotheses.\nAlthough this analysis is focused on the tuning of Support Vector Machines, it\ncan also be applied to other algorithms, as shown in experiments performed with\ndecision trees.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:03:07 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 21:58:43 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Mantovani", "Rafael Gomes", ""], ["Rossi", "Andr\u00e9 Luis Debiaso", ""], ["Alcoba\u00e7a", "Edesio", ""], ["Vanschoren", "Joaquin", ""], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""]]}, {"id": "1906.01687", "submitter": "Tamara Kolda", "authors": "Tamara G. Kolda and David Hong", "title": "Stochastic Gradients for Large-Scale Tensor Decomposition", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science, Vol. 2, No. 4, pp.\n  1066-1095, 2020", "doi": "10.1137/19m1266265", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition is a well-known tool for multiway data analysis. This\nwork proposes using stochastic gradients for efficient generalized canonical\npolyadic (GCP) tensor decomposition of large-scale tensors. GCP tensor\ndecomposition is a recently proposed version of tensor decomposition that\nallows for a variety of loss functions such as Bernoulli loss for binary data\nor Huber loss for robust estimation. The stochastic gradient is formed from\nrandomly sampled elements of the tensor and is efficient because it can be\ncomputed using the sparse matricized-tensor-times-Khatri-Rao product (MTTKRP)\ntensor kernel. For dense tensors, we simply use uniform sampling. For sparse\ntensors, we propose two types of stratified sampling that give precedence to\nsampling nonzeros. Numerical results demonstrate the advantages of the proposed\napproach and its scalability to large-scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:10:14 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 00:33:03 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 01:18:02 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kolda", "Tamara G.", ""], ["Hong", "David", ""]]}, {"id": "1906.01695", "submitter": "Wachirawit Ponghiran", "authors": "Wachirawit Ponghiran, Gopalakrishnan Srinivasan, and Kaushik Roy", "title": "Reinforcement Learning with Low-Complexity Liquid State Machines", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose reinforcement learning on simple networks consisting of random\nconnections of spiking neurons (both recurrent and feed-forward) that can learn\ncomplex tasks with very little trainable parameters. Such sparse and randomly\ninterconnected recurrent spiking networks exhibit highly non-linear dynamics\nthat transform the inputs into rich high-dimensional representations based on\npast context. The random input representations can be efficiently interpreted\nby an output (or readout) layer with trainable parameters. Systematic\ninitialization of the random connections and training of the readout layer\nusing Q-learning algorithm enable such small random spiking networks to learn\noptimally and achieve the same learning efficiency as humans on complex\nreinforcement learning tasks like Atari games. The spike-based approach using\nsmall random recurrent networks provides a computationally efficient\nalternative to state-of-the-art deep reinforcement learning networks with\nseveral layers of trainable parameters. The low-complexity spiking networks can\nlead to improved energy efficiency in event-driven neuromorphic hardware for\ncomplex reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:35:44 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ponghiran", "Wachirawit", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Roy", "Kaushik", ""]]}, {"id": "1906.01724", "submitter": "Meet Vadera", "authors": "Meet P. Vadera, Benjamin M. Marlin", "title": "Assessing the Robustness of Bayesian Dark Knowledge to Posterior\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Dark Knowledge is a method for compressing the posterior predictive\ndistribution of a neural network model into a more compact form. Specifically,\nthe method attempts to compress a Monte Carlo approximation to the parameter\nposterior into a single network representing the posterior predictive\ndistribution. Further, the authors show that this approach is successful in the\nclassification setting using a student network whose architecture matches that\nof a single network in the teacher ensemble. In this work, we examine the\nrobustness of Bayesian Dark Knowledge to higher levels of posterior\nuncertainty. We show that using a student network that matches the teacher\narchitecture may fail to yield acceptable performance. We study an approach to\nclose the resulting performance gap by increasing student model capacity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:00:52 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 16:29:23 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Vadera", "Meet P.", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "1906.01727", "submitter": "Ramy Baly", "authors": "Tsvetomila Mihaylova (1), Georgi Karadjov (2), Pepa Atanasova (3),\n  Ramy Baly (4), Mitra Mohtarami (4), Preslav Nakov (5) ((1) Instituto de\n  Telecomunica\\c{c}\\~oes, Lisbon, Portugal, (2) SiteGround Hosting EOOD,\n  Bulgaria, (3) University of Copenhagen, Denmark, (4) MIT Computer Science and\n  Artificial Intelligence Laboratory, Cambridge, MA, (5) Qatar Computing\n  Research Institute, HBKU)", "title": "SemEval-2019 Task 8: Fact Checking in Community Question Answering\n  Forums", "comments": "Fact checking, community question answering, community fora,\n  semeval-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SemEval-2019 Task 8 on Fact Checking in Community Question\nAnswering Forums, which features two subtasks. Subtask A is about deciding\nwhether a question asks for factual information vs. an opinion/advice vs. just\nsocializing. Subtask B asks to predict whether an answer to a factual question\nis true, false or not a proper answer. We received 17 official submissions for\nsubtask A and 11 official submissions for Subtask B. For subtask A, all systems\nimproved over the majority class baseline. For Subtask B, all systems were\nbelow a majority class baseline, but several systems were very close to it. The\nleaderboard and the data from the competition can be found at\nhttp://competitions.codalab.org/competitions/20022\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:46:49 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Mihaylova", "Tsvetomila", ""], ["Karadjov", "Georgi", ""], ["Atanasova", "Pepa", ""], ["Baly", "Ramy", ""], ["Mohtarami", "Mitra", ""], ["Nakov", "Preslav", ""]]}, {"id": "1906.01732", "submitter": "Ruibo Tu", "authors": "Ruibo Tu, Kun Zhang, Bo Christer Bertilson, Hedvig Kjellstr\\\"om, Cheng\n  Zhang", "title": "Neuropathic Pain Diagnosis Simulator for Causal Discovery Algorithm\n  Evaluation", "comments": "Accepted by NeurIPS 2019, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of causal relations from observational data is essential for many\ndisciplines of science and real-world applications. However, unlike other\nmachine learning algorithms, whose development has been greatly fostered by a\nlarge amount of available benchmark datasets, causal discovery algorithms are\nnotoriously difficult to be systematically evaluated because few datasets with\nknown ground-truth causal relations are available. In this work, we handle the\nproblem of evaluating causal discovery algorithms by building a flexible\nsimulator in the medical setting. We develop a neuropathic pain diagnosis\nsimulator, inspired by the fact that the biological processes of neuropathic\npathophysiology are well studied with well-understood causal influences. Our\nsimulator exploits the causal graph of the neuropathic pain pathology and its\nparameters in the generator are estimated from real-life patient cases. We show\nthat the data generated from our simulator have similar statistics as\nreal-world data. As a clear advantage, the simulator can produce infinite\nsamples without jeopardizing the privacy of real-world patients. Our simulator\nprovides a natural tool for evaluating various types of causal discovery\nalgorithms, including those to deal with practical issues in causal discovery,\nsuch as unknown confounders, selection bias, and missing data. Using our\nsimulator, we have evaluated extensively causal discovery algorithms under\nvarious settings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:25:23 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:48:05 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 08:18:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tu", "Ruibo", ""], ["Zhang", "Kun", ""], ["Bertilson", "Bo Christer", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Zhang", "Cheng", ""]]}, {"id": "1906.01736", "submitter": "Xiangyi Chen", "authors": "Xiangyi Chen, Tiancong Chen, Haoran Sun, Zhiwei Steven Wu, Mingyi Hong", "title": "Distributed Training with Heterogeneous Data: Bridging Median- and\n  Mean-Based Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is a growing interest in the study of median-based algorithms\nfor distributed non-convex optimization. Two prominent such algorithms include\nsignSGD with majority vote, an effective approach for communication reduction\nvia 1-bit compression on the local gradients, and medianSGD, an algorithm\nrecently proposed to ensure robustness against Byzantine workers. The\nconvergence analyses for these algorithms critically rely on the assumption\nthat all the distributed data are drawn iid from the same distribution.\nHowever, in applications such as Federated Learning, the data across different\nnodes or machines can be inherently heterogeneous, which violates such an iid\nassumption. This work analyzes signSGD and medianSGD in distributed settings\nwith heterogeneous data. We show that these algorithms are non-convergent\nwhenever there is some disparity between the expected median and mean over the\nlocal gradients. To overcome this gap, we provide a novel gradient correction\nmechanism that perturbs the local gradients with noise, together with a series\nresults that provable close the gap between mean and median of the gradients.\nThe proposed methods largely preserve nice properties of these methods, such as\nthe low per-iteration communication complexity of signSGD, and further enjoy\nglobal convergence to stationary solutions. Our perturbation technique can be\nof independent interest when one wishes to estimate mean through a median\nestimator.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:48:50 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 08:04:54 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Chen", "Xiangyi", ""], ["Chen", "Tiancong", ""], ["Sun", "Haoran", ""], ["Wu", "Zhiwei Steven", ""], ["Hong", "Mingyi", ""]]}, {"id": "1906.01741", "submitter": "Louis Capitaine", "authors": "Louis Capitaine, J\\'er\\'emie Bigot, Rodolphe Thi\\'ebaut and Robin\n  Genuer", "title": "Fr\\'echet random forests for metric space valued regression with non\n  euclidean predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are a statistical learning method widely used in many areas of\nscientific research because of its ability to learn complex relationships\nbetween input and output variables and also their capacity to handle\nhigh-dimensional data. However, current random forest approaches are not\nflexible enough to handle heterogeneous data such as curves, images and shapes.\nIn this paper, we introduce Fr\\'echet trees and Fr\\'echet random forests, which\nallow to handle data for which input and output variables take values in\ngeneral metric spaces (which can be unordered). To this end, a new way of\nsplitting the nodes of trees is introduced and the prediction procedures of\ntrees and forests are generalized. Then, random forests out-of-bag error and\nvariable importance score are naturally adapted. A consistency theorem for\nFr\\'echet regressogram predictor using data-driven partitions is given and\napplied to Fr\\'echet purely uniformly random trees. The method is studied\nthrough several simulation scenarios on heterogeneous data combining\nlongitudinal, image and scalar data. Finally, two real datasets from HIV\nvaccine trials are analyzed with the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 22:07:24 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 13:10:50 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Capitaine", "Louis", ""], ["Bigot", "J\u00e9r\u00e9mie", ""], ["Thi\u00e9baut", "Rodolphe", ""], ["Genuer", "Robin", ""]]}, {"id": "1906.01761", "submitter": "Dennis Wei", "authors": "Dennis Wei, Sanjeeb Dash, Tian Gao, Oktay G\\\"unl\\\"uk", "title": "Generalized Linear Rule Models", "comments": "Published in the Proceedings of the 36th International Conference on\n  Machine Learning (ICML), PMLR 97:6687-6696, 2019. 17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers generalized linear models using rule-based features,\nalso referred to as rule ensembles, for regression and probabilistic\nclassification. Rules facilitate model interpretation while also capturing\nnonlinear dependences and interactions. Our problem formulation accordingly\ntrades off rule set complexity and prediction accuracy. Column generation is\nused to optimize over an exponentially large space of rules without\npre-generating a large subset of candidates or greedily boosting rules one by\none. The column generation subproblem is solved using either integer\nprogramming or a heuristic optimizing the same objective. In experiments\ninvolving logistic and linear regression, the proposed methods obtain better\naccuracy-complexity trade-offs than existing rule ensemble algorithms. At one\nend of the trade-off, the methods are competitive with less interpretable\nbenchmark models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 00:23:42 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Wei", "Dennis", ""], ["Dash", "Sanjeeb", ""], ["Gao", "Tian", ""], ["G\u00fcnl\u00fck", "Oktay", ""]]}, {"id": "1906.01770", "submitter": "Yash Chandak", "authors": "Yash Chandak, Georgios Theocharous, Chris Nota, Philip S. Thomas", "title": "Lifelong Learning with a Changing Action Set", "comments": "Thirty-fourth Conference on Artificial Intelligence (AAAI 2020)\n  [Outstanding Student Paper Honorable Mention. ]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world sequential decision making problems, the number of\navailable actions (decisions) can vary over time. While problems like\ncatastrophic forgetting, changing transition dynamics, changing rewards\nfunctions, etc. have been well-studied in the lifelong learning literature, the\nsetting where the action set changes remains unaddressed. In this paper, we\npresent an algorithm that autonomously adapts to an action set whose size\nchanges over time. To tackle this open problem, we break it into two problems\nthat can be solved iteratively: inferring the underlying, unknown, structure in\nthe space of actions and optimizing a policy that leverages this structure. We\ndemonstrate the efficiency of this approach on large-scale real-world lifelong\nlearning problems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 00:59:25 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 18:22:54 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 01:27:17 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Chandak", "Yash", ""], ["Theocharous", "Georgios", ""], ["Nota", "Chris", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1906.01772", "submitter": "Yash Chandak", "authors": "Yash Chandak, Georgios Theocharous, Blossom Metevier, Philip S. Thomas", "title": "Reinforcement Learning When All Actions are Not Always Available", "comments": "Thirty-fourth Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Markov decision process (MDP) formulation used to model many real-world\nsequential decision making problems does not efficiently capture the setting\nwhere the set of available decisions (actions) at each time step is stochastic.\nRecently, the stochastic action set Markov decision process (SAS-MDP)\nformulation has been proposed, which better captures the concept of a\nstochastic action set. In this paper we argue that existing RL algorithms for\nSAS-MDPs can suffer from potential divergence issues, and present new policy\ngradient algorithms for SAS-MDPs that incorporate variance reduction techniques\nunique to this setting, and provide conditions for their convergence. We\nconclude with experiments that demonstrate the practicality of our approaches\non tasks inspired by real-life use cases wherein the action set is stochastic.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 01:02:45 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 18:17:52 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chandak", "Yash", ""], ["Theocharous", "Georgios", ""], ["Metevier", "Blossom", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1906.01786", "submitter": "Jalaj Bhandari", "authors": "Jalaj Bhandari and Daniel Russo", "title": "Global Optimality Guarantees For Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradients methods apply to complex, poorly understood, control\nproblems by performing stochastic gradient descent over a parameterized class\nof polices. Unfortunately, even for simple control problems solvable by\nstandard dynamic programming techniques, policy gradient algorithms face\nnon-convex optimization problems and are widely understood to converge only to\na stationary point. This work identifies structural properties -- shared by\nseveral classic control problems -- that ensure the policy gradient objective\nfunction has no suboptimal stationary points despite being non-convex. When\nthese conditions are strengthened, this objective satisfies a\nPolyak-lojasiewicz (gradient dominance) condition that yields convergence\nrates. We also provide bounds on the optimality gap of any stationary point\nwhen some of these conditions are relaxed.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:12:22 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 06:30:38 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Bhandari", "Jalaj", ""], ["Russo", "Daniel", ""]]}, {"id": "1906.01819", "submitter": "Junyoung Park", "authors": "Junyoung Park, Subin Yi, Yongseok Choi, Dong-Yeon Cho, Jiwon Kim", "title": "Discriminative Few-Shot Learning Based on Directional Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric-based few-shot learning methods try to overcome the difficulty due to\nthe lack of training examples by learning embedding to make comparison easy. We\npropose a novel algorithm to generate class representatives for few-shot\nclassification tasks. As a probabilistic model for learned features of inputs,\nwe consider a mixture of von Mises-Fisher distributions which is known to be\nmore expressive than Gaussian in a high dimensional space. Then, from a\ndiscriminative classifier perspective, we get a better class representative\nconsidering inter-class correlation which has not been addressed by\nconventional few-shot learning algorithms. We apply our method to\n\\emph{mini}ImageNet and \\emph{tiered}ImageNet datasets, and show that the\nproposed approach outperforms other comparable methods in few-shot\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 04:34:10 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Park", "Junyoung", ""], ["Yi", "Subin", ""], ["Choi", "Yongseok", ""], ["Cho", "Dong-Yeon", ""], ["Kim", "Jiwon", ""]]}, {"id": "1906.01824", "submitter": "Sudipto Mukherjee", "authors": "Sudipto Mukherjee, Himanshu Asnani, Sreeram Kannan", "title": "CCMI : Classifier based Conditional Mutual Information Estimation", "comments": "Mutual Information and Conditional Mutual Information estimation;\n  Conditional Independence Testing; Classifier two-sample likelihood ratio", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Mutual Information (CMI) is a measure of conditional dependence\nbetween random variables X and Y, given another random variable Z. It can be\nused to quantify conditional dependence among variables in many data-driven\ninference problems such as graphical models, causal learning, feature selection\nand time-series analysis. While k-nearest neighbor (kNN) based estimators as\nwell as kernel-based methods have been widely used for CMI estimation, they\nsuffer severely from the curse of dimensionality. In this paper, we leverage\nadvances in classifiers and generative models to design methods for CMI\nestimation. Specifically, we introduce an estimator for KL-Divergence based on\nthe likelihood ratio by training a classifier to distinguish the observed joint\ndistribution from the product distribution. We then show how to construct\nseveral CMI estimators using this basic divergence estimator by drawing ideas\nfrom conditional generative models. We demonstrate that the estimates from our\nproposed approaches do not degrade in performance with increasing dimension and\nobtain significant improvement over the widely used KSG estimator. Finally, as\nan application of accurate CMI estimation, we use our best estimator for\nconditional independence testing and achieve superior performance than the\nstate-of-the-art tester on both simulated and real data-sets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 04:58:22 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Mukherjee", "Sudipto", ""], ["Asnani", "Himanshu", ""], ["Kannan", "Sreeram", ""]]}, {"id": "1906.01827", "submitter": "Baharan Mirzasoleiman", "authors": "Baharan Mirzasoleiman, Jeff Bilmes, Jure Leskovec", "title": "Coresets for Data-efficient Training of Machine Learning Models", "comments": null, "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental gradient (IG) methods, such as stochastic gradient descent and\nits variants are commonly used for large scale optimization in machine\nlearning. Despite the sustained effort to make IG methods more data-efficient,\nit remains an open question how to select a training data subset that can\ntheoretically and practically perform on par with the full dataset. Here we\ndevelop CRAIG, a method to select a weighted subset (or coreset) of training\ndata that closely estimates the full gradient by maximizing a submodular\nfunction. We prove that applying IG to this subset is guaranteed to converge to\nthe (near)optimal solution with the same convergence rate as that of IG for\nconvex optimization. As a result, CRAIG achieves a speedup that is inversely\nproportional to the size of the subset. To our knowledge, this is the first\nrigorous method for data-efficient training of general machine learning models.\nOur extensive set of experiments show that CRAIG, while achieving practically\nthe same solution, speeds up various IG methods by up to 6x for logistic\nregression and 3x for training deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:10:37 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 17:04:20 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 20:58:39 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Mirzasoleiman", "Baharan", ""], ["Bilmes", "Jeff", ""], ["Leskovec", "Jure", ""]]}, {"id": "1906.01830", "submitter": "Ramy Baly", "authors": "Ramy Baly (1), Alaa Khaddaj (2), Hazem Hajj (2), Wassim El-Hajj (3),\n  Khaled Bashir Shaban (4) ((1) MIT Computer Science and Artificial\n  Intelligence Laboratory, Cambridge, MA, USA, (2) American University of\n  Beirut, Electrical and Computer Engineering Department, Beirut, Lebanon, (3)\n  American University of Beirut, Computer Science Department, Beirut, Lebanon,\n  (4) Qatar University, Computer Science and Engineering Department, Doha,\n  Qatar)", "title": "ArSentD-LEV: A Multi-Topic Corpus for Target-based Sentiment Analysis in\n  Arabic Levantine Tweets", "comments": "Corpus development, Levantine tweets, multi-topic, sentiment\n  analysis, sentiment target, LREC-2018, OSACT-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a highly subjective and challenging task. Its\ncomplexity further increases when applied to the Arabic language, mainly\nbecause of the large variety of dialects that are unstandardized and widely\nused in the Web, especially in social media. While many datasets have been\nreleased to train sentiment classifiers in Arabic, most of these datasets\ncontain shallow annotation, only marking the sentiment of the text unit, as a\nword, a sentence or a document. In this paper, we present the Arabic Sentiment\nTwitter Dataset for the Levantine dialect (ArSenTD-LEV). Based on findings from\nanalyzing tweets from the Levant region, we created a dataset of 4,000 tweets\nwith the following annotations: the overall sentiment of the tweet, the target\nto which the sentiment was expressed, how the sentiment was expressed, and the\ntopic of the tweet. Results confirm the importance of these annotations at\nimproving the performance of a baseline sentiment classifier. They also confirm\nthe gap of training in a certain domain, and testing in another domain.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 13:31:52 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Baly", "Ramy", ""], ["Khaddaj", "Alaa", ""], ["Hajj", "Hazem", ""], ["El-Hajj", "Wassim", ""], ["Shaban", "Khaled Bashir", ""]]}, {"id": "1906.01845", "submitter": "Egor Kraev", "authors": "Egor Kraev and Mark Harley", "title": "Probabilistic hypergraph grammars for efficient molecular optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to make molecular optimization more efficient. We\ninfer a hypergraph replacement grammar from the ChEMBL database, count the\nfrequencies of particular rules being used to expand particular nonterminals in\nother rules, and use these as conditional priors for the policy model.\nSimulating random molecules from the resulting probabilistic grammar, we show\nthat conditional priors result in a molecular distribution closer to the\ntraining set than using equal rule probabilities or unconditional priors. We\nthen treat molecular optimization as a reinforcement learning problem, using a\nnovel modification of the policy gradient algorithm - batch-advantage: using\nindividual rewards minus the batch average reward to weight the log probability\nloss. The reinforcement learning agent is tasked with building molecules using\nthis grammar, with the goal of maximizing benchmark scores available from the\nliterature. To do so, the agent has policies both to choose the next node in\nthe graph to expand and to select the next grammar rule to apply. The policies\nare implemented using the Transformer architecture with the partially expanded\ngraph as the input at each step. We show that using the empirical priors as the\nstarting point for a policy eliminates the need for pre-training, and allows us\nto reach optima faster. We achieve competitive performance on common benchmarks\nfrom the literature, such as penalized logP and QED, with only hundreds of\ntraining steps on a budget GPU instance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 06:41:01 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kraev", "Egor", ""], ["Harley", "Mark", ""]]}, {"id": "1906.01851", "submitter": "Yusuke Mukuta", "authors": "Yusuke Mukuta, Tatsuaki Machida and Tatsuya Harada", "title": "Compact Approximation for Polynomial of Covariance Feature", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance pooling is a feature pooling method with good classification\naccuracy. Because covariance features consist of second-order statistics, the\nscale of the feature elements are varied. Therefore, normalizing covariance\nfeatures using a matrix square root affects the performance improvement. When\npooling methods are applied to local features extracted from CNN models, the\naccuracy increases when the pooling function is back-propagatable and the\nfeature-extraction model is learned in an end-to-end manner. Recently, the\niterative polynomial approximation method for the matrix square root of a\ncovariance feature was proposed, and resulted in a faster and more stable\ntraining than the methods based on singular-value decomposition. In this paper,\nwe propose an extension of compact bilinear pooling, which is a compact\napproximation of the standard covariance feature, to the polynomials of the\ncovariance feature. Subsequently, we apply the proposed approximation to the\npolynomial corresponding to the matrix square root to obtain a compact\napproximation for the square root of the covariance feature. Our method\napproximates a higher-dimensional polynomial of a covariance by the weighted\nsum of the approximate features corresponding to a pair of local features based\non the similarity of the local features. We apply our method for standard\nfine-grained image recognition datasets and demonstrate that the proposed\nmethod shows comparable accuracy with fewer dimensions than the original\nfeature.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 06:46:58 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Mukuta", "Yusuke", ""], ["Machida", "Tatsuaki", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1906.01852", "submitter": "Edwin Bonilla", "authors": "Pantelis Elinas, Edwin V. Bonilla and Louis Tiao", "title": "Variational Inference for Graph Convolutional Networks in the Absence of\n  Graph Data and Adversarial Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework that lifts the capabilities of graph convolutional\nnetworks (GCNs) to scenarios where no input graph is given and increases their\nrobustness to adversarial attacks. We formulate a joint probabilistic model\nthat considers a prior distribution over graphs along with a GCN-based\nlikelihood and develop a stochastic variational inference algorithm to estimate\nthe graph posterior and the GCN parameters jointly. To address the problem of\npropagating gradients through latent variables drawn from discrete\ndistributions, we use their continuous relaxations known as Concrete\ndistributions. We show that, on real datasets, our approach can outperform\nstate-of-the-art Bayesian and non-Bayesian graph neural network algorithms on\nthe task of semi-supervised classification in the absence of graph data and\nwhen the network structure is subjected to adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 06:47:46 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 01:54:33 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 06:48:24 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 00:07:34 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 00:23:25 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Elinas", "Pantelis", ""], ["Bonilla", "Edwin V.", ""], ["Tiao", "Louis", ""]]}, {"id": "1906.01857", "submitter": "Yusuke Mukuta", "authors": "Yusuke Mukuta and Tatsuya Harada", "title": "Invariant Tensor Feature Coding", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel feature coding method that exploits invariance. We\nconsider the setting where the transformations that preserve the image contents\ncompose a finite group of orthogonal matrices. This is the case in many image\ntransformations, such as image rotations and image flipping. We prove that the\ngroup-invariant feature vector contains sufficient discriminative information\nwhen learning a linear classifier using convex loss minimization. From this\nresult, we propose a novel feature modeling for principal component analysis\nand k-means clustering, which are used for most feature coding methods, and\nglobal feature functions that explicitly consider the group action. Although\nthe global feature functions are complex nonlinear functions in general, we can\ncalculate the group action on this space easily by constructing the functions\nas the tensor product representations of basic representations, resulting in\nthe explicit form of invariant feature functions. We demonstrate the\neffectiveness of our methods on several image datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:15:17 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 09:03:50 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Mukuta", "Yusuke", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1906.01861", "submitter": "Wataru Kawai", "authors": "Wataru Kawai, Yusuke Mukuta, Tatsuya Harada", "title": "Scalable Generative Models for Graphs with Graph Attention Mechanism", "comments": "22 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are ubiquitous real-world data structures, and generative models that\napproximate distributions over graphs and derive new samples from them have\nsignificant importance. Among the known challenges in graph generation tasks,\nscalability handling of large graphs and datasets is one of the most important\nfor practical applications. Recently, an increasing number of graph generative\nmodels have been proposed and have demonstrated impressive results. However,\nscalability is still an unresolved problem due to the complex generation\nprocess or difficulty in training parallelization. In this paper, we first\ndefine scalability from three different perspectives: number of nodes, data,\nand node/edge labels. Then, we propose GRAM, a generative model for graphs that\nis scalable in all three contexts, especially in training. We aim to achieve\nscalability by employing a novel graph attention mechanism, formulating the\nlikelihood of graphs in a simple and general manner. Also, we apply two\ntechniques to reduce computational complexity. Furthermore, we construct a\nunified and non-domain-specific evaluation metric in node/edge-labeled graph\ngeneration tasks by combining a graph kernel and Maximum Mean Discrepancy. Our\nexperiments on synthetic and real-world graphs demonstrated the scalability of\nour models and their superior performance compared with baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:33:06 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 12:07:53 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Kawai", "Wataru", ""], ["Mukuta", "Yusuke", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1906.01874", "submitter": "Hamid Mirisaee", "authors": "Hamid Mirisaee, Eric Gaussier, Cedric Lagnier, Agnes Guerraz", "title": "Terminology-based Text Embedding for Computing Document Similarities on\n  Technical Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper a new, hybrid document embedding approach in order\nto address the problem of document similarities with respect to the technical\ncontent. To do so, we employ a state-of-the-art graph techniques to first\nextract the keyphrases (composite keywords) of documents and, then, use them to\nscore the sentences. Using the ranked sentences, we propose two approaches to\nembed documents and show their performances with respect to two baselines. With\ndomain expert annotations, we illustrate that the proposed methods can find\nmore relevant documents and outperform the baselines up to 27% in terms of\nNDCG.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 08:16:42 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 08:19:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mirisaee", "Hamid", ""], ["Gaussier", "Eric", ""], ["Lagnier", "Cedric", ""], ["Guerraz", "Agnes", ""]]}, {"id": "1906.01876", "submitter": "Kentaro Kanamori", "authors": "Kentaro Kanamori and Satoshi Hara and Masakazu Ishihata and Hiroki\n  Arimura", "title": "Enumeration of Distinct Support Vectors for Interactive Decision Making", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional prediction tasks, a machine learning algorithm outputs a\nsingle best model that globally optimizes its objective function, which\ntypically is accuracy. Therefore, users cannot access the other models\nexplicitly. In contrast to this, multiple model enumeration attracts increasing\ninterests in non-standard machine learning applications where other criteria,\ne.g., interpretability or fairness, than accuracy are main concern and a user\nmay want to access more than one non-optimal, but suitable models. In this\npaper, we propose a K-best model enumeration algorithm for Support Vector\nMachines (SVM) that given a dataset S and an integer K>0, enumerates the K-best\nmodels on S with distinct support vectors in the descending order of the\nobjective function values in the dual SVM problem. Based on analysis of the\nlattice structure of support vectors, our algorithm efficiently finds the next\nbest model with small latency. This is useful in supporting users's interactive\nexamination of their requirements on enumerated models. By experiments on real\ndatasets, we evaluated the efficiency and usefulness of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 08:22:16 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kanamori", "Kentaro", ""], ["Hara", "Satoshi", ""], ["Ishihata", "Masakazu", ""], ["Arimura", "Hiroki", ""]]}, {"id": "1906.01908", "submitter": "Guillaume Ausset", "authors": "Guillaume Ausset, St\\'ephan Cl\\'emen\\c{c}on, Fran\\c{c}ois Portier", "title": "Empirical Risk Minimization under Random Censorship: Theory and Practice", "comments": "Submitted to JMLR. 18 pages + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classic supervised learning problem, where a continuous\nnon-negative random label $Y$ (i.e. a random duration) is to be predicted based\nupon observing a random vector $X$ valued in $\\mathbb{R}^d$ with $d\\geq 1$ by\nmeans of a regression rule with minimum least square error. In various\napplications, ranging from industrial quality control to public health through\ncredit risk analysis for instance, training observations can be right censored,\nmeaning that, rather than on independent copies of $(X,Y)$, statistical\nlearning relies on a collection of $n\\geq 1$ independent realizations of the\ntriplet $(X, \\; \\min\\{Y,\\; C\\},\\; \\delta)$, where $C$ is a nonnegative r.v.\nwith unknown distribution, modeling censorship and $\\delta=\\mathbb{I}\\{Y\\leq\nC\\}$ indicates whether the duration is right censored or not. As ignoring\ncensorship in the risk computation may clearly lead to a severe underestimation\nof the target duration and jeopardize prediction, we propose to consider a\nplug-in estimate of the true risk based on a Kaplan-Meier estimator of the\nconditional survival function of the censorship $C$ given $X$, referred to as\nKaplan-Meier risk, in order to perform empirical risk minimization. It is\nestablished, under mild conditions, that the learning rate of minimizers of\nthis biased/weighted empirical risk functional is of order\n$O_{\\mathbb{P}}(\\sqrt{\\log(n)/n})$ when ignoring model bias issues inherent to\nplug-in estimation, as can be attained in absence of censorship. Beyond\ntheoretical results, numerical experiments are presented in order to illustrate\nthe relevance of the approach developed.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 09:40:41 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ausset", "Guillaume", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1906.01930", "submitter": "Alexander Immer", "authors": "Mohammad Emtiyaz Khan, Alexander Immer, Ehsan Abedi, Maciej Korzepa", "title": "Approximate Inference Turns Deep Networks into Gaussian Processes", "comments": "published at NeurIPS 2019:\n  https://papers.nips.cc/paper/8573-approximate-inference-turns-deep-networks-into-gaussian-processes.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) and Gaussian processes (GP) are two powerful\nmodels with several theoretical connections relating them, but the relationship\nbetween their training methods is not well understood. In this paper, we show\nthat certain Gaussian posterior approximations for Bayesian DNNs are equivalent\nto GP posteriors. This enables us to relate solutions and iterations of a\ndeep-learning algorithm to GP inference. As a result, we can obtain a GP kernel\nand a nonlinear feature map while training a DNN. Surprisingly, the resulting\nkernel is the neural tangent kernel. We show kernels obtained on real datasets\nand demonstrate the use of the GP marginal likelihood to tune hyperparameters\nof DNNs. Our work aims to facilitate further research on combining DNNs and GPs\nin practical settings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 10:43:20 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 03:21:09 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 21:28:11 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Immer", "Alexander", ""], ["Abedi", "Ehsan", ""], ["Korzepa", "Maciej", ""]]}, {"id": "1906.01935", "submitter": "Antonio Bevilacqua", "authors": "Antonio Bevilacqua and Kyle MacDonald and Aamina Rangarej and Venessa\n  Widjaya and Brian Caulfield and Tahar Kechadi", "title": "Human Activity Recognition with Convolutional Neural Netowrks", "comments": "13 pages total, 12 pages of content, 1 page of references, 9 pictures\n  in PDF format", "journal-ref": null, "doi": "10.1007/978-3-030-10997-4_33", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic identification of physical activities performed by\nhuman subjects is referred to as Human Activity Recognition (HAR). There exist\nseveral techniques to measure motion characteristics during these physical\nactivities, such as Inertial Measurement Units (IMUs). IMUs have a cornerstone\nposition in this context, and are characterized by usage flexibility, low cost,\nand reduced privacy impact. With the use of inertial sensors, it is possible to\nsample some measures such as acceleration and angular velocity of a body, and\nuse them to learn models that are capable of correctly classifying activities\nto their corresponding classes. In this paper, we propose to use Convolutional\nNeural Networks (CNNs) to classify human activities. Our models use raw data\nobtained from a set of inertial sensors. We explore several combinations of\nactivities and sensors, showing how motion signals can be adapted to be fed\ninto CNNs by using different network architectures. We also compare the\nperformance of different groups of sensors, investigating the classification\npotential of single, double and triple sensor systems. The experimental results\nobtained on a dataset of 16 lower-limb activities, collected from a group of\nparticipants with the use of five different sensors, are very promising.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 10:54:06 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Bevilacqua", "Antonio", ""], ["MacDonald", "Kyle", ""], ["Rangarej", "Aamina", ""], ["Widjaya", "Venessa", ""], ["Caulfield", "Brian", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1906.01975", "submitter": "Nithin Nagaraj", "authors": "Snehanshu Saha, Nithin Nagaraj, Archana Mathur, Rahul Yedida", "title": "Evolution of Novel Activation Functions in Neural Network Training with\n  Applications to Classification of Exoplanets", "comments": "41 pages, 11 figures", "journal-ref": null, "doi": "10.1140/epjst/e2020-000098-9", "report-no": null, "categories": "astro-ph.IM cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present analytical exploration of novel activation functions as\nconsequence of integration of several ideas leading to implementation and\nsubsequent use in habitability classification of exoplanets. Neural networks,\nalthough a powerful engine in supervised methods, often require expensive\ntuning efforts for optimized performance. Habitability classes are hard to\ndiscriminate, especially when attributes used as hard markers of separation are\nremoved from the data set. The solution is approached from the point of\ninvestigating analytical properties of the proposed activation functions. The\ntheory of ordinary differential equations and fixed point are exploited to\njustify the \"lack of tuning efforts\" to achieve optimal performance compared to\ntraditional activation functions. Additionally, the relationship between the\nproposed activation functions and the more popular ones is established through\nextensive analytical and empirical evidence. Finally, the activation functions\nhave been implemented in plain vanilla feed-forward neural network to classify\nexoplanets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 11:08:49 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Saha", "Snehanshu", ""], ["Nagaraj", "Nithin", ""], ["Mathur", "Archana", ""], ["Yedida", "Rahul", ""]]}, {"id": "1906.01981", "submitter": "Cheuk Hang Leung", "authors": "Qi Wu, Shumin Ma, Cheuk Hang Leung, Wei Liu and Nanbo Peng", "title": "Understanding Distributional Ambiguity via Non-robust Chance Constraint", "comments": "8 pages, 3 figures, Accepted for publication in ICAIF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG q-fin.PM q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a non-robust interpretation of the distributionally\nrobust optimization (DRO) problem by relating the distributional uncertainties\nto the chance probabilities. Our analysis allows a decision-maker to interpret\nthe size of the ambiguity set, which is often lack of business meaning, through\nthe chance parameters constraining the objective function. We first show that,\nfor general $\\phi$-divergences, a DRO problem is asymptotically equivalent to a\nclass of mean-deviation problems. These mean-deviation problems are not subject\nto uncertain distributions, and the ambiguity radius in the original DRO\nproblem now plays the role of controlling the risk preference of the\ndecision-maker. We then demonstrate that a DRO problem can be cast as a\nchance-constrained optimization (CCO) problem when a boundedness constraint is\nadded to the decision variables. Without the boundedness constraint, the CCO\nproblem is shown to perform uniformly better than the DRO problem, irrespective\nof the radius of the ambiguity set, the choice of the divergence measure, or\nthe tail heaviness of the center distribution. Thanks to our high-order\nexpansion result, a notable feature of our analysis is that it applies to\ndivergence measures that accommodate well heavy tail distributions such as the\nstudent $t$-distribution and the lognormal distribution, besides the\nwidely-used Kullback-Leibler (KL) divergence, which requires the distribution\nof the objective function to be exponentially bounded. Using the portfolio\nselection problem as an example, our comprehensive testings on multivariate\nheavy-tail datasets, both synthetic and real-world, shows that this\nbusiness-interpretation approach is indeed useful and insightful.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 06:13:13 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 06:49:34 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 03:25:13 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 14:04:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wu", "Qi", ""], ["Ma", "Shumin", ""], ["Leung", "Cheuk Hang", ""], ["Liu", "Wei", ""], ["Peng", "Nanbo", ""]]}, {"id": "1906.01998", "submitter": "Cynthia Rudin", "authors": "Cynthia Rudin and David Carlson", "title": "The Secrets of Machine Learning: Ten Things You Wish You Had Known\n  Earlier to be More Effective at Data Analysis", "comments": "INFORMS TutORial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the widespread usage of machine learning throughout organizations,\nthere are some key principles that are commonly missed. In particular: 1) There\nare at least four main families for supervised learning: logical modeling\nmethods, linear combination methods, case-based reasoning methods, and\niterative summarization methods. 2) For many application domains, almost all\nmachine learning methods perform similarly (with some caveats). Deep learning\nmethods, which are the leading technique for computer vision problems, do not\nmaintain an edge over other methods for most problems (and there are reasons\nwhy). 3) Neural networks are hard to train and weird stuff often happens when\nyou try to train them. 4) If you don't use an interpretable model, you can make\nbad mistakes. 5) Explanations can be misleading and you can't trust them. 6)\nYou can pretty much always find an accurate-yet-interpretable model, even for\ndeep neural networks. 7) Special properties such as decision making or\nrobustness must be built in, they don't happen on their own. 8) Causal\ninference is different than prediction (correlation is not causation). 9) There\nis a method to the madness of deep neural architectures, but not always. 10) It\nis a myth that artificial intelligence can do anything.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:49:45 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Rudin", "Cynthia", ""], ["Carlson", "David", ""]]}, {"id": "1906.02003", "submitter": "Fredrik Bagge Carlson", "authors": "Fredrik Bagge Carlson", "title": "Machine Learning and System Identification for Estimation in Physical\n  Systems", "comments": "184 pages, PhD thesis, Lund University, 2018", "journal-ref": null, "doi": null, "report-no": "TFRT-1122", "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we draw inspiration from both classical system identification\nand modern machine learning in order to solve estimation problems for\nreal-world, physical systems. The main approach to estimation and learning\nadopted is optimization based. Concepts such as regularization will be utilized\nfor encoding of prior knowledge and basis-function expansions will be used to\nadd nonlinear modeling power while keeping data requirements practical. The\nthesis covers a wide range of applications, many inspired by applications\nwithin robotics, but also extending outside this already wide field. Usage of\nthe proposed methods and algorithms are in many cases illustrated in the\nreal-world applications that motivated the research. Topics covered include\ndynamics modeling and estimation, model-based reinforcement learning, spectral\nestimation, friction modeling and state estimation and calibration in robotic\nmachining. In the work on modeling and identification of dynamics, we develop\nregularization strategies that allow us to incorporate prior domain knowledge\ninto flexible, overparameterized models. We make use of classical control\ntheory to gain insight into training and regularization while using flexible\ntools from modern deep learning. A particular focus of the work is to allow use\nof modern methods in scenarios where gathering data is associated with a high\ncost. In the robotics-inspired parts of the thesis, we develop methods that are\npractically motivated and ensure that they are implementable also outside the\nresearch setting. We demonstrate this by performing experiments in realistic\nsettings and providing open-source implementations of all proposed methods and\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 12:54:27 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Carlson", "Fredrik Bagge", ""]]}, {"id": "1906.02004", "submitter": "Frederik Harder", "authors": "Frederik Harder, Matthias Bauer, Mijung Park", "title": "Interpretable and Differentially Private Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable predictions, where it is clear why a machine learning model has\nmade a particular decision, can compromise privacy by revealing the\ncharacteristics of individual data points. This raises the central question\naddressed in this paper: Can models be interpretable without compromising\nprivacy? For complex big data fit by correspondingly rich models, balancing\nprivacy and explainability is particularly challenging, such that this question\nhas remained largely unexplored. In this paper, we propose a family of simple\nmodels in the aim of approximating complex models using several locally linear\nmaps per class to provide high classification accuracy, as well as\ndifferentially private explanations on the classification. We illustrate the\nusefulness of our approach on several image benchmark datasets as well as a\nmedical dataset.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 12:56:28 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:37:42 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 08:50:42 GMT"}, {"version": "v4", "created": "Sun, 5 Apr 2020 11:07:44 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Harder", "Frederik", ""], ["Bauer", "Matthias", ""], ["Park", "Mijung", ""]]}, {"id": "1906.02027", "submitter": "Kevin A. Lai", "authors": "Jacob Abernethy, Kevin A. Lai, Andre Wibisono", "title": "Last-iterate convergence rates for min-max optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classic work in convex-concave min-max optimization relies on\naverage-iterate convergence results, the emergence of nonconvex applications\nsuch as training Generative Adversarial Networks has led to renewed interest in\nlast-iterate convergence guarantees. Proving last-iterate convergence is\nchallenging because many natural algorithms, such as Simultaneous Gradient\nDescent/Ascent, provably diverge or cycle even in simple convex-concave min-max\nsettings, and previous work on global last-iterate convergence rates has been\nlimited to the bilinear and convex-strongly concave settings. In this work, we\nshow that the Hamiltonian Gradient Descent (HGD) algorithm achieves linear\nconvergence in a variety of more general settings, including convex-concave\nproblems that satisfy a \"sufficiently bilinear\" condition. We also prove\nsimilar convergence rates for the Consensus Optimization (CO) algorithm of\n[MNG17] for some parameter settings of CO.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 13:41:36 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 20:18:10 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 19:20:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Abernethy", "Jacob", ""], ["Lai", "Kevin A.", ""], ["Wibisono", "Andre", ""]]}, {"id": "1906.02032", "submitter": "Minh Vu", "authors": "Minh N. Vu, Truc D. Nguyen, NhatHai Phan, Ralucca Gera and My T. Thai", "title": "c-Eval: A Unified Metric to Evaluate Feature-based Explanations via\n  Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many modern image-classification applications, understanding the cause of\nmodel's prediction can be as critical as the prediction's accuracy itself.\nVarious feature-based local explanations generation methods have been designed\nto give us more insights on the decision of complex classifiers. Nevertheless,\nthere is no consensus on evaluating the quality of different explanations. In\nresponse to this lack of comprehensive evaluation, we introduce the c-Eval\nmetric and its corresponding framework to quantify the feature-based local\nexplanation's quality. Given a classifier's prediction and the corresponding\nexplanation on that prediction, c-Eval is the minimum-distortion perturbation\nthat successfully alters the prediction while keeping the explanation's\nfeatures unchanged. We then demonstrate how c-Eval can be computed using some\nmodifications on existing adversarial generation libraries. To show that c-Eval\ncaptures the importance of input's features, we establish the connection\nbetween c-Eval and the features returned by explainers in affine and\nnearly-affine classifiers. We then introduce the c-Eval plot, which not only\ndisplays a strong connection between c-Eval and explainers' quality, but also\nhelps automatically determine explainer's parameters. Since the generation of\nc-Eval relies on adversarial generation, we provide a demo of c-Eval on\nadversarial-robust models and show that the metric is applicable in those\nmodels. Finally, extensive experiments of explainers on different datasets are\nconducted to support the adoption of c-Eval in evaluating explainers'\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 13:50:27 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 18:18:21 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Vu", "Minh N.", ""], ["Nguyen", "Truc D.", ""], ["Phan", "NhatHai", ""], ["Gera", "Ralucca", ""], ["Thai", "My T.", ""]]}, {"id": "1906.02037", "submitter": "Nan Wang", "authors": "Yiyi Tao, Yiling Jia, Nan Wang, Hongning Wang", "title": "The FacT: Taming Latent Factor Models for Explainability with\n  Factorization Trees", "comments": "In proceedings of SIGIR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Latent factor models have achieved great success in personalized\nrecommendations, but they are also notoriously difficult to explain. In this\nwork, we integrate regression trees to guide the learning of latent factor\nmodels for recommendation, and use the learnt tree structure to explain the\nresulting latent factors. Specifically, we build regression trees on users and\nitems respectively with user-generated reviews, and associate a latent profile\nto each node on the trees to represent users and items. With the growth of\nregression tree, the latent factors are gradually refined under the\nregularization imposed by the tree structure. As a result, we are able to track\nthe creation of latent profiles by looking into the path of each factor on\nregression trees, which thus serves as an explanation for the resulting\nrecommendations. Extensive experiments on two large collections of Amazon and\nYelp reviews demonstrate the advantage of our model over several competitive\nbaseline algorithms. Besides, our extensive user study also confirms the\npractical value of explainable recommendations generated by our model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 20:31:57 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Tao", "Yiyi", ""], ["Jia", "Yiling", ""], ["Wang", "Nan", ""], ["Wang", "Hongning", ""]]}, {"id": "1906.02076", "submitter": "David Calhas", "authors": "David Calhas, Enrique Romero, Rui Henriques", "title": "On the use of Pairwise Distance Learning for Brain Signal Classification\n  with Limited Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.SP q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The increasing access to brain signal data using electroencephalography\ncreates new opportunities to study electrophysiological brain activity and\nperform ambulatory diagnoses of neuronal diseases. This work proposes a\npairwise distance learning approach for Schizophrenia classification relying on\nthe spectral properties of the signal. Given the limited number of observations\n(i.e. the case and/or control individuals) in clinical trials, we propose a\nSiamese neural network architecture to learn a discriminative feature space\nfrom pairwise combinations of observations per channel. In this way, the\nmultivariate order of the signal is used as a form of data augmentation,\nfurther supporting the network generalization ability. Convolutional layers\nwith parameters learned under a cosine contrastive loss are proposed to\nadequately explore spectral images derived from the brain signal. Results on a\ncase-control population show that the features extracted using the proposed\nneural network lead to an improved Schizophrenia diagnosis (+10pp in accuracy\nand sensitivity) against spectral features, thus suggesting the existence of\nnon-trivial, discriminative electrophysiological brain patterns.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:36:57 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 11:40:27 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Calhas", "David", ""], ["Romero", "Enrique", ""], ["Henriques", "Rui", ""]]}, {"id": "1906.02085", "submitter": "Hermina Petric Maretic", "authors": "Hermina Petric Maretic, Mireille EL Gheche, Giovanni Chierchia, Pascal\n  Frossard", "title": "GOT: An Optimal Transport framework for Graph comparison", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework based on optimal transport for the challenging\nproblem of comparing graphs. Specifically, we exploit the probabilistic\ndistribution of smooth graph signals defined with respect to the graph\ntopology. This allows us to derive an explicit expression of the Wasserstein\ndistance between graph signal distributions in terms of the graph Laplacian\nmatrices. This leads to a structurally meaningful measure for comparing graphs,\nwhich is able to take into account the global structure of graphs, while most\nother measures merely observe local changes independently. Our measure is then\nused for formulating a new graph alignment problem, whose objective is to\nestimate the permutation that minimizes the distance between two graphs. We\nfurther propose an efficient stochastic algorithm based on Bayesian exploration\nto accommodate for the non-convexity of the graph alignment problem. We finally\ndemonstrate the performance of our novel framework on different tasks like\ngraph alignment, graph classification and graph signal prediction, and we show\nthat our method leads to significant improvement with respect to\nthe-state-of-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:44:45 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 22:16:33 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Maretic", "Hermina Petric", ""], ["Gheche", "Mireille EL", ""], ["Chierchia", "Giovanni", ""], ["Frossard", "Pascal", ""]]}, {"id": "1906.02101", "submitter": "Christopher Tosh", "authors": "Christopher Tosh and Daniel Hsu", "title": "Diameter-based Interactive Structure Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce interactive structure discovery, a generic framework that\nencompasses many interactive learning settings, including active learning,\ntop-k item identification, interactive drug discovery, and others. We adapt a\nrecently developed active learning algorithm of Tosh and Dasgupta (2017) for\ninteractive structure discovery, and show that the new algorithm can be made\nnoise-tolerant and enjoys favorable query complexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:18:40 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 16:40:04 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Tosh", "Christopher", ""], ["Hsu", "Daniel", ""]]}, {"id": "1906.02104", "submitter": "Danica J. Sutherland", "authors": "Danica J. Sutherland", "title": "Unbiased estimators for the variance of MMD estimators", "comments": "Fixes and extends the appendices of arXiv:1611.04488 and\n  arXiv:1511.04581", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum mean discrepancy (MMD) is a kernel-based distance between\nprobability distributions useful in many applications (Gretton et al. 2012),\nbearing a simple estimator with pleasing computational and statistical\nproperties. Being able to efficiently estimate the variance of this estimator\nis very helpful to various problems in two-sample testing. Towards this end,\nBounliphone et al. (2016) used the theory of U-statistics to derive estimators\nfor the variance of an MMD estimator, and differences between two such\nestimators. Their estimator, however, drops lower-order terms, and is\nunnecessarily biased. We show in this note - extending and correcting work of\nSutherland et al. (2017) - that we can find a truly unbiased estimator for the\nactual variance of both the squared MMD estimator and the difference of two\ncorrelated squared MMD estimators, at essentially no additional computational\ncost.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:26:46 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:07:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sutherland", "Danica J.", ""]]}, {"id": "1906.02107", "submitter": "James Widdicombe Mr", "authors": "Koen Helwegen, James Widdicombe, Lukas Geiger, Zechun Liu, Kwang-Ting\n  Cheng, Roeland Nusselder", "title": "Latent Weights Do Not Exist: Rethinking Binarized Neural Network\n  Optimization", "comments": "Accepted at 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada - Updated ImageNet results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of Binarized Neural Networks (BNNs) currently relies on\nreal-valued latent weights to accumulate small update steps. In this paper, we\nargue that these latent weights cannot be treated analogously to weights in\nreal-valued networks. Instead their main role is to provide inertia during\ntraining. We interpret current methods in terms of inertia and provide novel\ninsights into the optimization of BNNs. We subsequently introduce the first\noptimizer specifically designed for BNNs, Binary Optimizer (Bop), and\ndemonstrate its performance on CIFAR-10 and ImageNet. Together, the\nredefinition of latent weights as inertia and the introduction of Bop enable a\nbetter understanding of BNN optimization and open up the way for further\nimprovements in training methodologies for BNNs. Code is available at:\nhttps://github.com/plumerai/rethinking-bnn-optimization\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:32:39 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 16:40:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Helwegen", "Koen", ""], ["Widdicombe", "James", ""], ["Geiger", "Lukas", ""], ["Liu", "Zechun", ""], ["Cheng", "Kwang-Ting", ""], ["Nusselder", "Roeland", ""]]}, {"id": "1906.02108", "submitter": "Alexander Warnecke", "authors": "Alexander Warnecke, Daniel Arp, Christian Wressnegger, Konrad Rieck", "title": "Evaluating Explanation Methods for Deep Learning in Security", "comments": "IEEE European Symposium on Security and Privacy, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly used as a building block of security systems.\nUnfortunately, neural networks are hard to interpret and typically opaque to\nthe practitioner. The machine learning community has started to address this\nproblem by developing methods for explaining the predictions of neural\nnetworks. While several of these approaches have been successfully applied in\nthe area of computer vision, their application in security has received little\nattention so far. It is an open question which explanation methods are\nappropriate for computer security and what requirements they need to satisfy.\nIn this paper, we introduce criteria for comparing and evaluating explanation\nmethods in the context of computer security. These cover general properties,\nsuch as the accuracy of explanations, as well as security-focused aspects, such\nas the completeness, efficiency, and robustness. Based on our criteria, we\ninvestigate six popular explanation methods and assess their utility in\nsecurity systems for malware detection and vulnerability discovery. We observe\nsignificant differences between the methods and build on these to derive\ngeneral recommendations for selecting and applying explanation methods in\ncomputer security.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:36:22 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 11:40:02 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 10:50:48 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 08:10:51 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Warnecke", "Alexander", ""], ["Arp", "Daniel", ""], ["Wressnegger", "Christian", ""], ["Rieck", "Konrad", ""]]}, {"id": "1906.02111", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi,\n  Le Song", "title": "Can Graph Neural Networks Help Logic Reasoning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively combining logic reasoning and probabilistic inference has been a\nlong-standing goal of machine learning: the former has the ability to\ngeneralize with small training data, while the latter provides a principled\nframework for dealing with noisy data. However, existing methods for combining\nthe best of both worlds are typically computationally intensive. In this paper,\nwe focus on Markov Logic Networks and explore the use of graph neural networks\n(GNNs) for representing probabilistic logic inference. It is revealed from our\nanalysis that the representation power of GNN alone is not enough for such a\ntask. We instead propose a more expressive variant, called ExpressGNN, which\ncan perform effective probabilistic logic inference while being able to scale\nto a large number of entities. We demonstrate by several benchmark datasets\nthat ExpressGNN has the potential to advance probabilistic logic reasoning to\nthe next stage.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:40:47 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 19:13:16 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 20:43:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zhang", "Yuyu", ""], ["Chen", "Xinshi", ""], ["Yang", "Yuan", ""], ["Ramamurthy", "Arun", ""], ["Li", "Bo", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "1906.02120", "submitter": "Claudia Shi", "authors": "Claudia Shi, David M. Blei, Victor Veitch", "title": "Adapting Neural Networks for the Estimation of Treatment Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the use of neural networks for the estimation of\ntreatment effects from observational data. Generally, estimation proceeds in\ntwo stages. First, we fit models for the expected outcome and the probability\nof treatment (propensity score) for each unit. Second, we plug these fitted\nmodels into a downstream estimator of the effect. Neural networks are a natural\nchoice for the models in the first step. The question we address is: how can we\nadapt the design and training of the neural networks used in the first step in\norder to improve the quality of the final estimate of the treatment effect? We\npropose two adaptations based on insights from the statistical literature on\nthe estimation of treatment effects. The first is a new architecture, the\nDragonnet, that exploits the sufficiency of the propensity score for estimation\nadjustment. The second is a regularization procedure, targeted regularization,\nthat induces a bias towards models that have non-parametrically optimal\nasymptotic properties `out-of-the-box`. Studies on benchmark datasets for\ncausal inference show these adaptations outperform existing methods. Code is\navailable at github.com/claudiashi57/dragonnet.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:47:13 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 18:05:31 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shi", "Claudia", ""], ["Blei", "David M.", ""], ["Veitch", "Victor", ""]]}, {"id": "1906.02124", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on fine-tuning a pre-trained BERT model and applying it\nto patent classification. When applied to large datasets of over two millions\npatents, our approach outperforms the state of the art by an approach using CNN\nwith word embeddings. In addition, we focus on patent claims without other\nparts in patent documents. Our contributions include: (1) a new\nstate-of-the-art method based on pre-trained BERT model and fine-tuning for\npatent classification, (2) a large dataset USPTO-3M at the CPC subclass level\nwith SQL statements that can be used by future researchers, (3) showing that\npatent claims alone are sufficient for classification task, in contrast to\nconventional wisdom.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:33:08 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 01:48:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "1906.02125", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Yao Chong Lim, Yao-Hung Hubert Tsai, Ruslan\n  Salakhutdinov, Louis-Philippe Morency", "title": "Strong and Simple Baselines for Multimodal Utterance Embeddings", "comments": "NAACL 2019 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language is a rich multimodal signal consisting of spoken words, facial\nexpressions, body gestures, and vocal intonations. Learning representations for\nthese spoken utterances is a complex research problem due to the presence of\nmultiple heterogeneous sources of information. Recent advances in multimodal\nlearning have followed the general trend of building more complex models that\nutilize various attention, memory and recurrent components. In this paper, we\npropose two simple but strong baselines to learn embeddings of multimodal\nutterances. The first baseline assumes a conditional factorization of the\nutterance into unimodal factors. Each unimodal factor is modeled using the\nsimple form of a likelihood function obtained via a linear transformation of\nthe embedding. We show that the optimal embedding can be derived in closed form\nby taking a weighted average of the unimodal features. In order to capture\nricher representations, our second baseline extends the first by factorizing\ninto unimodal, bimodal, and trimodal factors, while retaining simplicity and\nefficiency during learning and inference. From a set of experiments across two\ntasks, we show strong performance on both supervised and semi-supervised\nmultimodal prediction, as well as significant (10 times) speedups over neural\nmodels during inference. Overall, we believe that our strong baseline models\noffer new benchmarking options for future research in multimodal learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 13:44:37 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 07:01:32 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liang", "Paul Pu", ""], ["Lim", "Yao Chong", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1906.02145", "submitter": "George Papamakarios", "authors": "Conor Durkan, Artur Bekasov, Iain Murray, George Papamakarios", "title": "Cubic-Spline Flows", "comments": "Appeared at the 1st Workshop on Invertible Neural Networks and\n  Normalizing Flows at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A normalizing flow models a complex probability density as an invertible\ntransformation of a simple density. The invertibility means that we can\nevaluate densities and generate samples from a flow. In practice,\nautoregressive flow-based models are slow to invert, making either density\nestimation or sample generation slow. Flows based on coupling transforms are\nfast for both tasks, but have previously performed less well at density\nestimation than autoregressive flows. We stack a new coupling transform, based\non monotonic cubic splines, with LU-decomposed linear layers. The resulting\ncubic-spline flow retains an exact one-pass inverse, can be used to generate\nhigh-quality images, and closes the gap with autoregressive flows on a suite of\ndensity-estimation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:05:53 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Durkan", "Conor", ""], ["Bekasov", "Artur", ""], ["Murray", "Iain", ""], ["Papamakarios", "George", ""]]}, {"id": "1906.02160", "submitter": "Daniel L. Marino", "authors": "Daniel L. Marino, Milos Manic", "title": "Physics Enhanced Data-Driven Models with Variational Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centuries of development in natural sciences and mathematical modeling\nprovide valuable domain expert knowledge that has yet to be explored for the\ndevelopment of machine learning models. When modeling complex physical systems,\nboth domain knowledge and data provide necessary information about the system.\nIn this paper, we present a data-driven model that takes advantage of partial\ndomain knowledge in order to improve generalization and interpretability. The\npresented approach, which we call EVGP (Explicit Variational GaussianProcess),\nhas the following advantages: 1) using available domain knowledge to improve\nthe assumptions(inductive bias) of the model, 2) scalability to large datasets,\n3) improved interpretability. We show how the EVGP model can be used to learn\nsystem dynamics using basic Newtonian mechanics as prior knowledge. We\ndemonstrate how the addition of prior domain-knowledge to data-driven models\noutperforms purely data-driven models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:44:29 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 03:33:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Marino", "Daniel L.", ""], ["Manic", "Milos", ""]]}, {"id": "1906.02164", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis, Vijay Keswani, Nisheeth K. Vishnoi", "title": "Data preprocessing to mitigate bias: A maximum entropy based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data containing human or social attributes may over- or under-represent\ngroups with respect to salient social attributes such as gender or race, which\ncan lead to biases in downstream applications. This paper presents an\nalgorithmic framework that can be used as a data preprocessing method towards\nmitigating such bias. Unlike prior work, it can efficiently learn distributions\nover large domains, controllably adjust the representation rates of protected\ngroups and achieve target fairness metrics such as statistical parity, yet\nremains close to the empirical distribution induced by the given dataset. Our\napproach leverages the principle of maximum entropy - amongst all distributions\nsatisfying a given set of constraints, we should choose the one closest in\nKL-divergence to a given prior. While maximum entropy distributions can\nsuccinctly encode distributions over large domains, they can be difficult to\ncompute. Our main contribution is an instantiation of this framework for our\nset of constraints and priors, which encode our bias mitigation goals, and that\nruns in time polynomial in the dimension of the data. Empirically, we observe\nthat samples from the learned distribution have desired representation rates\nand statistical rates, and when used for training a classifier incurs only a\nslight loss in accuracy while maintaining fairness properties.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:54:00 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:07:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1906.02168", "submitter": "Vaishaal Shankar", "authors": "Vaishaal Shankar, Achal Dave, Rebecca Roelofs, Deva Ramanan, Benjamin\n  Recht, Ludwig Schmidt", "title": "Do Image Classifiers Generalize Across Time?", "comments": "23 pages, 11 tables, 11 figures. Paper Website:\n  https://modestyachts.github.io/natural-perturbations-website/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness of image classifiers to temporal perturbations\nderived from videos. As part of this study, we construct two datasets,\nImageNet-Vid-Robust and YTBB-Robust , containing a total 57,897 images grouped\ninto 3,139 sets of perceptually similar images. Our datasets were derived from\nImageNet-Vid and Youtube-BB respectively and thoroughly re-annotated by human\nexperts for image similarity. We evaluate a diverse array of classifiers\npre-trained on ImageNet and show a median classification accuracy drop of 16\nand 10 on our two datasets. Additionally, we evaluate three detection models\nand show that natural perturbations induce both classification as well as\nlocalization errors, leading to a median drop in detection mAP of 14 points.\nOur analysis demonstrates that perturbations occurring naturally in videos pose\na substantial and realistic challenge to deploying convolutional neural\nnetworks in environments that require both reliable and low-latency predictions\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:55:42 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 18:03:18 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 17:30:11 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Shankar", "Vaishaal", ""], ["Dave", "Achal", ""], ["Roelofs", "Rebecca", ""], ["Ramanan", "Deva", ""], ["Recht", "Benjamin", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "1906.02171", "submitter": "Silu Zhang", "authors": "Silu Zhang, Xin Dang, Dao Nguyen, Dawn Wilkins, Yixin Chen", "title": "Estimating Feature-Label Dependence Using Gini Distance Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying statistical dependence between the features and the label is a\nfundamental problem in supervised learning. This paper presents a framework for\nestimating dependence between numerical features and a categorical label using\ngeneralized Gini distance, an energy distance in reproducing kernel Hilbert\nspaces (RKHS). Two Gini distance based dependence measures are explored: Gini\ndistance covariance and Gini distance correlation. Unlike Pearson covariance\nand correlation, which do not characterize independence, the above Gini\ndistance based measures define dependence as well as independence of random\nvariables. The test statistics are simple to calculate and do not require\nprobability density estimation. Uniform convergence bounds and asymptotic\nbounds are derived for the test statistics. Comparisons with distance\ncovariance statistics are provided. It is shown that Gini distance statistics\nconverge faster than distance covariance statistics in the uniform convergence\nbounds, hence tighter upper bounds on both Type I and Type II errors. Moreover,\nthe probability of Gini distance covariance statistic under-performing the\ndistance covariance statistic in Type II error decreases to 0 exponentially\nwith the increase of the sample size. Extensive experimental results are\npresented to demonstrate the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:57:51 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Zhang", "Silu", ""], ["Dang", "Xin", ""], ["Nguyen", "Dao", ""], ["Wilkins", "Dawn", ""], ["Chen", "Yixin", ""]]}, {"id": "1906.02174", "submitter": "Mingde Zhao", "authors": "Sitao Luan and Mingde Zhao and Xiao-Wen Chang and Doina Precup", "title": "Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional\n  Networks", "comments": "Accepted and to be published by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network based approaches have achieved significant\nimprovement for solving large, complex, graph-structured problems. However,\ntheir bottlenecks still need to be addressed, and the advantages of multi-scale\ninformation and deep architectures have not been sufficiently exploited. In\nthis paper, we theoretically analyze how existing Graph Convolutional Networks\n(GCNs) have limited expressive power due to the constraint of the activation\nfunctions and their architectures. We generalize spectral graph convolution and\ndeep GCN in block Krylov subspace forms and devise two architectures, both with\nthe potential to be scaled deeper but each making use of the multi-scale\ninformation in different ways. We further show that the equivalence of these\ntwo architectures can be established under certain conditions. On several node\nclassification tasks, with or without the help of validation, the two new\narchitectures achieve better performance compared to many state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:59:39 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:52:27 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 16:22:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Luan", "Sitao", ""], ["Zhao", "Mingde", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "1906.02179", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Lam Si Tung Ho, Huan Xu, Vu Dinh, Binh Nguyen", "title": "Bayesian Active Learning With Abstention Feedbacks", "comments": "Poster presented at 2019 ICML Workshop on Human in the Loop Learning\n  2019 (non-archival). arXiv admin note: substantial text overlap with\n  arXiv:1705.08481", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pool-based active learning with abstention feedbacks where a labeler\ncan abstain from labeling a queried example with some unknown abstention rate.\nThis is an important problem with many useful applications. We take a Bayesian\napproach to the problem and develop two new greedy algorithms that learn both\nthe classification problem and the unknown abstention rate at the same time.\nThese are achieved by simply incorporating the estimated average abstention\nrate into the greedy criteria. We prove that both algorithms have\nnear-optimality guarantees: they respectively achieve a ${(1-\\frac{1}{e})}$\nconstant factor approximation of the optimal expected or worst-case value of a\nuseful utility function. Our experiments show the algorithms perform well in\nvarious practical scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:18:17 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 20:35:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Ho", "Lam Si Tung", ""], ["Xu", "Huan", ""], ["Dinh", "Vu", ""], ["Nguyen", "Binh", ""]]}, {"id": "1906.02181", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Yi Yang, Siyang Yuan, Dinghan Shen, Lawrence Carin", "title": "Syntax-Infused Variational Autoencoder for Text Generation", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a syntax-infused variational autoencoder (SIVAE), that integrates\nsentences with their syntactic trees to improve the grammar of generated\nsentences. Distinct from existing VAE-based text generative models, SIVAE\ncontains two separate latent spaces, for sentences and syntactic trees. The\nevidence lower bound objective is redesigned correspondingly, by optimizing a\njoint distribution that accommodates two encoders and two decoders. SIVAE works\nwith long short-term memory architectures to simultaneously generate sentences\nand syntactic trees. Two versions of SIVAE are proposed: one captures the\ndependencies between the latent variables through a conditional prior network,\nand the other treats the latent variables independently such that\nsyntactically-controlled sentence generation can be performed. Experimental\nresults demonstrate the generative superiority of SIVAE on both reconstruction\nand targeted syntactic evaluations. Finally, we show that the proposed models\ncan be used for unsupervised paraphrasing given different syntactic tree\ntemplates.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 22:48:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Yang", "Yi", ""], ["Yuan", "Siyang", ""], ["Shen", "Dinghan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.02191", "submitter": "Roger David Soberanis-Mukul", "authors": "Roger D. Soberanis-Mukul and Nassir Navab and Shadi Albarqouni", "title": "Uncertainty-based graph convolutional networks for organ segmentation\n  refinement", "comments": "Accepted at MIDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organ segmentation in CT volumes is an important pre-processing step in many\ncomputer assisted intervention and diagnosis methods. In recent years,\nconvolutional neural networks have dominated the state of the art in this task.\nHowever, since this problem presents a challenging environment due to high\nvariability in the organ's shape and similarity between tissues, the generation\nof false negative and false positive regions in the output segmentation is a\ncommon issue. Recent works have shown that the uncertainty analysis of the\nmodel can provide us with useful information about potential errors in the\nsegmentation. In this context, we proposed a segmentation refinement method\nbased on uncertainty analysis and graph convolutional networks. We employ the\nuncertainty levels of the convolutional network in a particular input volume to\nformulate a semi-supervised graph learning problem that is solved by training a\ngraph convolutional network. To test our method we refine the initial output of\na 2D U-Net. We validate our framework with the NIH pancreas dataset and the\nspleen dataset of the medical segmentation decathlon. We show that our method\noutperforms the state-of-the art CRF refinement method by improving the dice\nscore by 1% for the pancreas and 2% for spleen, with respect to the original\nU-Net's prediction. Finally, we discuss the results and current limitations of\nthe model for future work in this research direction. For reproducibility\npurposes, we make our code publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 13:00:13 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 11:07:32 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 10:10:53 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Soberanis-Mukul", "Roger D.", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "1906.02226", "submitter": "S\\'ebastien Lachapelle", "authors": "S\\'ebastien Lachapelle, Philippe Brouillard, Tristan Deleu, Simon\n  Lacoste-Julien", "title": "Gradient-Based Neural DAG Learning", "comments": "Appears in: Proceedings of the Eighth International Conference on\n  Learning Representations (ICLR 2020). 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel score-based approach to learning a directed acyclic graph\n(DAG) from observational data. We adapt a recently proposed continuous\nconstrained optimization formulation to allow for nonlinear relationships\nbetween variables using neural networks. This extension allows to model complex\ninteractions while avoiding the combinatorial nature of the problem. In\naddition to comparing our method to existing continuous optimization methods,\nwe provide missing empirical comparisons to nonlinear greedy search methods. On\nboth synthetic and real-world data sets, this new method outperforms current\ncontinuous methods on most tasks, while being competitive with existing greedy\nsearch methods on important metrics for causal inference.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:09:55 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 14:49:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lachapelle", "S\u00e9bastien", ""], ["Brouillard", "Philippe", ""], ["Deleu", "Tristan", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1906.02236", "submitter": "Jean-Francois Ton", "authors": "Jean-Francois Ton, Lucian Chan, Yee Whye Teh, Dino Sejdinovic", "title": "Noise Contrastive Meta-Learning for Conditional Density Estimation using\n  Kernel Mean Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current meta-learning approaches focus on learning functional representations\nof relationships between variables, i.e. on estimating conditional expectations\nin regression. In many applications, however, we are faced with conditional\ndistributions which cannot be meaningfully summarized using expectation only\n(due to e.g. multimodality). Hence, we consider the problem of conditional\ndensity estimation in the meta-learning setting. We introduce a novel technique\nfor meta-learning which combines neural representation and noise-contrastive\nestimation with the established literature of conditional mean embeddings into\nreproducing kernel Hilbert spaces. The method is validated on synthetic and\nreal-world problems, demonstrating the utility of sharing learned\nrepresentations across multiple conditional density estimation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:28:42 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 19:31:19 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ton", "Jean-Francois", ""], ["Chan", "Lucian", ""], ["Teh", "Yee Whye", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1906.02249", "submitter": "Dmitry Kopitkov", "authors": "Dmitry Kopitkov and Vadim Indelman", "title": "General Purpose Incremental Covariance Update and Efficient Belief Space\n  Planning via Factor-Graph Propagation Action Tree", "comments": null, "journal-ref": null, "doi": "10.1177/0278364919875199", "report-no": null, "categories": "cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast covariance calculation is required both for SLAM (e.g.~in order to solve\ndata association) and for evaluating the information-theoretic term for\ndifferent candidate actions in belief space planning (BSP). In this paper we\nmake two primary contributions. First, we develop a novel general-purpose\nincremental covariance update technique, which efficiently recovers specific\ncovariance entries after any change in the inference problem, such as\nintroduction of new observations/variables or re-linearization of the state\nvector. Our approach is shown to recover them faster than other\nstate-of-the-art methods. Second, we present a computationally efficient\napproach for BSP in high-dimensional state spaces, leveraging our incremental\ncovariance update method. State of the art BSP approaches perform belief\npropagation for each candidate action and then evaluate an objective function\nthat typically includes an information-theoretic term, such as entropy or\ninformation gain. Yet, candidate actions often have similar parts (e.g. common\ntrajectory parts), which are however evaluated separately for each candidate.\nMoreover, calculating the information-theoretic term involves a costly\ndeterminant computation of the entire information (covariance) matrix which is\nO(n^3) with n being dimension of the state or costly Schur complement\noperations if only marginal posterior covariance of certain variables is of\ninterest. Our approach, rAMDL-Tree, extends our previous BSP method rAMDL, by\nexploiting incremental covariance calculation and performing calculation re-use\nbetween common parts of non-myopic candidate actions, such that these parts are\nevaluated only once, in contrast to existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:58:44 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kopitkov", "Dmitry", ""], ["Indelman", "Vadim", ""]]}, {"id": "1906.02252", "submitter": "Feng Liu", "authors": "Feng Liu, Li Wang, Yifei Lou, Rencang Li, Patrick Purdon", "title": "Probabilistic Structure Learning for EEG/MEG Source Imaging with\n  Hierarchical Graph Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain source imaging is an important method for noninvasively characterizing\nbrain activity using Electroencephalogram (EEG) or Magnetoencephalography (MEG)\nrecordings. Traditional EEG/MEG Source Imaging (ESI) methods usually assume\nthat either source activity at different time points is unrelated, or that\nsimilar spatiotemporal patterns exist across an entire study period. The former\nassumption makes ESI analyses sensitive to noise, while the latter renders ESI\nanalyses unable to account for time-varying patterns of activity. To\neffectively deal with noise while maintaining flexibility and continuity among\nbrain activation patterns, we propose a novel probabilistic ESI model based on\na hierarchical graph prior. Under our method, a spanning tree constraint\nensures that activity patterns have spatiotemporal continuity. An efficient\nalgorithm based on alternating convex search is presented to solve the proposed\nmodel and is provably convergent. Comprehensive numerical studies using\nsynthetic data on a real brain model are conducted under different levels of\nsignal-to-noise ratio (SNR) from both sensor and source spaces. We also examine\nthe EEG/MEG data in a real application, in which our ESI reconstructions are\nneurologically plausible. All the results demonstrate significant improvements\nof the proposed algorithm over the benchmark methods in terms of source\nlocalization performance, especially at high noise levels.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:03:26 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Liu", "Feng", ""], ["Wang", "Li", ""], ["Lou", "Yifei", ""], ["Li", "Rencang", ""], ["Purdon", "Patrick", ""]]}, {"id": "1906.02275", "submitter": "Pin Wang", "authors": "Pin Wang, Hanhan Li, Ching-Yao Chan", "title": "Continuous Control for Automated Lane Change Behavior Based on Deep\n  Deterministic Policy Gradient Algorithm", "comments": "Published at the 30th IEEE Intelligent Vehicles Symposium (IV), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lane change is a challenging task which requires delicate actions to ensure\nsafety and comfort. Some recent studies have attempted to solve the lane-change\ncontrol problem with Reinforcement Learning (RL), yet the action is confined to\ndiscrete action space. To overcome this limitation, we formulate the lane\nchange behavior with continuous action in a model-free dynamic driving\nenvironment based on Deep Deterministic Policy Gradient (DDPG). The reward\nfunction, which is critical for learning the optimal policy, is defined by\ncontrol values, position deviation status, and maneuvering time to provide the\nRL agent informative signals. The RL agent is trained from scratch without\nresorting to any prior knowledge of the environment and vehicle dynamics since\nthey are not easy to obtain. Seven models under different hyperparameter\nsettings are compared. A video showing the learning progress of the driving\nbehavior is available. It demonstrates the RL vehicle agent initially runs out\nof road boundary frequently, but eventually has managed to smoothly and stably\nchange to the target lane with a success rate of 100% under diverse driving\nsituations in simulation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:40:20 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wang", "Pin", ""], ["Li", "Hanhan", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1906.02280", "submitter": "Laura D'Arcy", "authors": "Laura D'Arcy, Padraig Corcoran, Alun Preece", "title": "Deep Q-Learning for Directed Acyclic Graph Generation", "comments": "Accepted to Learning and Reasoning with Graph-Structured\n  Representations, ICML 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a method to generate directed acyclic graphs (DAGs) using deep\nreinforcement learning, specifically deep Q-learning. Generating graphs with\nspecified structures is an important and challenging task in various\napplication fields, however most current graph generation methods produce\ngraphs with undirected edges. We demonstrate that this method is capable of\ngenerating DAGs with topology and node types satisfying specified criteria in\nhighly sparse reward environments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:56:44 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["D'Arcy", "Laura", ""], ["Corcoran", "Padraig", ""], ["Preece", "Alun", ""]]}, {"id": "1906.02282", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Yizheng Chen, Ahmed Abdou, Suman Jana", "title": "Enhancing Gradient-based Attacks with Symbolic Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in defenses against adversarial examples, like\nadversarial training, make the neural networks robust against various classes\nof attackers (e.g., first-order gradient-based attacks). However, it is an open\nquestion whether the adversarially trained networks are truly robust under\nunknown attacks. In this paper, we present interval attacks, a new technique to\nfind adversarial examples to evaluate the robustness of neural networks.\nInterval attacks leverage symbolic interval propagation, a bound propagation\ntechnique that can exploit a broader view around the current input to locate\npromising areas containing adversarial instances, which in turn can be searched\nwith existing gradient-guided attacks. We can obtain such a broader view using\nsound bound propagation methods to track and over-approximate the errors of the\nnetwork within given input ranges. Our results show that, on state-of-the-art\nadversarially trained networks, interval attack can find on average 47%\nrelatively more violations than the state-of-the-art gradient-guided PGD\nattack.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:58:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wang", "Shiqi", ""], ["Chen", "Yizheng", ""], ["Abdou", "Ahmed", ""], ["Jana", "Suman", ""]]}, {"id": "1906.02287", "submitter": "Sherif Sakr", "authors": "Radwa Elshawi and Mohamed Maher and Sherif Sakr", "title": "Automated Machine Learning: State-of-The-Art and Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the continuous and vast increase in the amount of data in our digital\nworld, it has been acknowledged that the number of knowledgeable data\nscientists can not scale to address these challenges. Thus, there was a crucial\nneed for automating the process of building good machine learning models. In\nthe last few years, several techniques and frameworks have been introduced to\ntackle the challenge of automating the process of Combined Algorithm Selection\nand Hyper-parameter tuning (CASH) in the machine learning domain. The main aim\nof these techniques is to reduce the role of the human in the loop and fill the\ngap for non-expert machine learning users by playing the role of the domain\nexpert.\n  In this paper, we present a comprehensive survey for the state-of-the-art\nefforts in tackling the CASH problem. In addition, we highlight the research\nwork of automating the other steps of the full complex machine learning\npipeline (AutoML) from data understanding till model deployment. Furthermore,\nwe provide comprehensive coverage for the various tools and frameworks that\nhave been introduced in this domain. Finally, we discuss some of the research\ndirections and open challenges that need to be addressed in order to achieve\nthe vision and goals of the AutoML process.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:07:13 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 08:10:13 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Elshawi", "Radwa", ""], ["Maher", "Mohamed", ""], ["Sakr", "Sherif", ""]]}, {"id": "1906.02292", "submitter": "Konstantinos Slavakis", "authors": "Cong Ye, Konstantinos Slavakis, Pratik V. Patil, Sarah F. Muldoon,\n  John Medaglia", "title": "Brain-Network Clustering via Kernel-ARMA Modeling and the Grassmannian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neuroscience and in the technology of functional magnetic\nresonance imaging (fMRI) and electro-encephalography (EEG) have propelled a\ngrowing interest in brain-network clustering via time-series analysis.\nNotwithstanding, most of the brain-network clustering methods revolve around\nstate clustering and/or node clustering (a.k.a. community detection or topology\ninference) within states. This work answers first the need of capturing\nnon-linear nodal dependencies by bringing forth a novel feature-extraction\nmechanism via kernel autoregressive-moving-average modeling. The extracted\nfeatures are mapped to the Grassmann manifold (Grassmannian), which consists of\nall linear subspaces of a fixed rank. By virtue of the Riemannian geometry of\nthe Grassmannian, a unifying clustering framework is offered to tackle all\npossible clustering problems in a network: Cluster multiple states, detect\ncommunities within states, and even identify/track subnetwork state sequences.\nThe effectiveness of the proposed approach is underlined by extensive numerical\ntests on synthetic and real fMRI/EEG data which demonstrate that the advocated\nlearning method compares favorably versus several state-of-the-art clustering\nschemes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:19:05 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ye", "Cong", ""], ["Slavakis", "Konstantinos", ""], ["Patil", "Pratik V.", ""], ["Muldoon", "Sarah F.", ""], ["Medaglia", "John", ""]]}, {"id": "1906.02299", "submitter": "Michael Hind", "authors": "Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy,\n  Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra\n  Mojsilovi\\'c", "title": "Teaching AI to Explain its Decisions Using Embeddings and Multi-Task\n  Learning", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA. arXiv admin note: substantial text overlap with\n  arXiv:1805.11648", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using machine learning in high-stakes applications often requires predictions\nto be accompanied by explanations comprehensible to the domain user, who has\nultimate responsibility for decisions and outcomes. Recently, a new framework\nfor providing explanations, called TED, has been proposed to provide meaningful\nexplanations for predictions. This framework augments training data to include\nexplanations elicited from domain users, in addition to features and labels.\nThis approach ensures that explanations for predictions are tailored to the\ncomplexity expectations and domain knowledge of the consumer. In this paper, we\nbuild on this foundational work, by exploring more sophisticated instantiations\nof the TED framework and empirically evaluate their effectiveness in two\ndiverse domains, chemical odor and skin cancer prediction. Results demonstrate\nthat meaningful explanations can be reliably taught to machine learning\nalgorithms, and in some cases, improving modeling accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:42:14 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Codella", "Noel C. F.", ""], ["Hind", "Michael", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Campbell", "Murray", ""], ["Dhurandhar", "Amit", ""], ["Varshney", "Kush R.", ""], ["Wei", "Dennis", ""], ["Mojsilovi\u0107", "Aleksandra", ""]]}, {"id": "1906.02314", "submitter": "Tyler Sypherd", "authors": "Tyler Sypherd, Mario Diaz, John Kevin Cava, Gautam Dasarathy, Peter\n  Kairouz, Lalitha Sankar", "title": "A Tunable Loss Function for Robust Classification: Calibration,\n  Landscape, and Generalization", "comments": "Submitted to T-IT. Many new theoretical and experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a tunable loss function called $\\alpha$-loss, parameterized by\n$\\alpha \\in (0,\\infty]$, which interpolates between the exponential loss\n($\\alpha = 1/2$), the log-loss ($\\alpha = 1$), and the 0-1 loss ($\\alpha =\n\\infty$), for the machine learning setting of classification. Theoretically, we\nillustrate a fundamental connection between $\\alpha$-loss and Arimoto\nconditional entropy, verify the classification-calibration of $\\alpha$-loss in\norder to demonstrate asymptotic optimality via Rademacher complexity\ngeneralization techniques, and build-upon a notion called strictly local\nquasi-convexity in order to quantitatively characterize the optimization\nlandscape of $\\alpha$-loss. Practically, we perform class imbalance,\nrobustness, and classification experiments on benchmark image datasets using\nconvolutional-neural-networks. Our main practical conclusion is that certain\ntasks may benefit from tuning $\\alpha$-loss away from log-loss ($\\alpha = 1$),\nand to this end we provide simple heuristics for the practitioner. In\nparticular, navigating the $\\alpha$ hyperparameter can readily provide superior\nmodel robustness to label flips ($\\alpha > 1$) and sensitivity to imbalanced\nclasses ($\\alpha < 1$).\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 21:16:48 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 20:50:16 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 06:43:04 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 15:04:31 GMT"}, {"version": "v5", "created": "Fri, 22 Jan 2021 19:05:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Sypherd", "Tyler", ""], ["Diaz", "Mario", ""], ["Cava", "John Kevin", ""], ["Dasarathy", "Gautam", ""], ["Kairouz", "Peter", ""], ["Sankar", "Lalitha", ""]]}, {"id": "1906.02319", "submitter": "Jun Wu", "authors": "Jun Wu and Jingrui He and Jiejun Xu", "title": "DEMO-Net: Degree-specific Graph Neural Networks for Node and Graph\n  Classification", "comments": "Accepted by KDD2019 Research track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph data widely exist in many high-impact applications. Inspired by the\nsuccess of deep learning in grid-structured data, graph neural network models\nhave been proposed to learn powerful node-level or graph-level representation.\nHowever, most of the existing graph neural networks suffer from the following\nlimitations: (1) there is limited analysis regarding the graph convolution\nproperties, such as seed-oriented, degree-aware and order-free; (2) the node's\ndegree-specific graph structure is not explicitly expressed in graph\nconvolution for distinguishing structure-aware node neighborhoods; (3) the\ntheoretical explanation regarding the graph-level pooling schemes is unclear.\n  To address these problems, we propose a generic degree-specific graph neural\nnetwork named DEMO-Net motivated by Weisfeiler-Lehman graph isomorphism test\nthat recursively identifies 1-hop neighborhood structures. In order to\nexplicitly capture the graph topology integrated with node attributes, we argue\nthat graph convolution should have three properties: seed-oriented,\ndegree-aware, order-free. To this end, we propose multi-task graph convolution\nwhere each task represents node representation learning for nodes with a\nspecific degree value, thus leading to preserving the degree-specific graph\nstructure. In particular, we design two multi-task learning methods:\ndegree-specific weight and hashing functions for graph convolution. In\naddition, we propose a novel graph-level pooling/readout scheme for learning\ngraph representation provably lying in a degree-specific Hilbert kernel space.\nThe experimental results on several node and graph classification benchmark\ndata sets demonstrate the effectiveness and efficiency of our proposed DEMO-Net\nover state-of-the-art graph neural network models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 21:39:59 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wu", "Jun", ""], ["He", "Jingrui", ""], ["Xu", "Jiejun", ""]]}, {"id": "1906.02327", "submitter": "Hongki Lim", "authors": "Hongki Lim, Il Yong Chun, Yuni K. Dewaraja, Jeffrey A. Fessler", "title": "Improved low-count quantitative PET reconstruction with an iterative\n  neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Image reconstruction in low-count PET is particularly challenging because\ngammas from natural radioactivity in Lu-based crystals cause high random\nfractions that lower the measurement signal-to-noise-ratio (SNR). In\nmodel-based image reconstruction (MBIR), using more iterations of an\nunregularized method may increase the noise, so incorporating regularization\ninto the image reconstruction is desirable to control the noise. New\nregularization methods based on learned convolutional operators are emerging in\nMBIR. We modify the architecture of an iterative neural network, BCD-Net, for\nPET MBIR, and demonstrate the efficacy of the trained BCD-Net using XCAT\nphantom data that simulates the low true coincidence count-rates with high\nrandom fractions typical for Y-90 PET patient imaging after Y-90 microsphere\nradioembolization. Numerical results show that the proposed BCD-Net\nsignificantly improves CNR and RMSE of the reconstructed images compared to\nMBIR methods using non-trained regularizers, total variation (TV) and non-local\nmeans (NLM). Moreover, BCD-Net successfully generalizes to test data that\ndiffers from the training data. Improvements were also demonstrated for the\nclinically relevant phantom measurement data where we used training and testing\ndatasets having very different activity distributions and count-levels.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 21:58:51 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 03:49:38 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 16:46:53 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 18:31:42 GMT"}, {"version": "v5", "created": "Mon, 25 May 2020 22:39:52 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Lim", "Hongki", ""], ["Chun", "Il Yong", ""], ["Dewaraja", "Yuni K.", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1906.02330", "submitter": "Max Kleiman-Weiner", "authors": "Jack Serrino, Max Kleiman-Weiner, David C. Parkes, Joshua B. Tenenbaum", "title": "Finding Friend and Foe in Multi-Agent Games", "comments": "Jack Serrino and Max Kleiman-Weiner contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in AI for multi-agent games like Go, Poker, and Dota,\nhave seen great strides in recent years. Yet none of these games address the\nreal-life challenge of cooperation in the presence of unknown and uncertain\nteammates. This challenge is a key game mechanism in hidden role games. Here we\ndevelop the DeepRole algorithm, a multi-agent reinforcement learning agent that\nwe test on The Resistance: Avalon, the most popular hidden role game. DeepRole\ncombines counterfactual regret minimization (CFR) with deep value networks\ntrained through self-play. Our algorithm integrates deductive reasoning into\nvector-form CFR to reason about joint beliefs and deduce partially observable\nactions. We augment deep value networks with constraints that yield\ninterpretable representations of win probabilities. These innovations enable\nDeepRole to scale to the full Avalon game. Empirical game-theoretic methods\nshow that DeepRole outperforms other hand-crafted and learned agents in\nfive-player Avalon. DeepRole played with and against human players on the web\nin hybrid human-agent teams. We find that DeepRole outperforms human players as\nboth a cooperator and a competitor.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 22:07:27 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Serrino", "Jack", ""], ["Kleiman-Weiner", "Max", ""], ["Parkes", "David C.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1906.02341", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Victor Campos, Yoshua Bengio", "title": "How to Initialize your Network? Robust Initialization for WeightNorm &\n  ResNets", "comments": "First two authors have equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual networks (ResNet) and weight normalization play an important role in\nvarious deep learning applications. However, parameter initialization\nstrategies have not been studied previously for weight normalized networks and,\nin practice, initialization methods designed for un-normalized networks are\nused as a proxy. Similarly, initialization for ResNets have also been studied\nfor un-normalized networks and often under simplified settings ignoring the\nshortcut connection. To address these issues, we propose a novel parameter\ninitialization strategy that avoids explosion/vanishment of information across\nlayers for weight normalized networks with and without residual connections.\nThe proposed strategy is based on a theoretical analysis using mean field\napproximation. We run over 2,500 experiments and evaluate our proposal on image\ndatasets showing that the proposed initialization outperforms existing\ninitialization methods in terms of generalization performance, robustness to\nhyper-parameter values and variance between seeds, especially when networks get\ndeeper in which case existing methods fail to even start training. Finally, we\nshow that using our initialization in conjunction with learning rate warmup is\nable to reduce the gap between the performance of weight normalized and batch\nnormalized networks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 22:38:17 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:13:58 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Arpit", "Devansh", ""], ["Campos", "Victor", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.02351", "submitter": "Bingcong Li", "authors": "Bingcong Li, Meng Ma, Georgios B. Giannakis", "title": "On the Convergence of SARAH and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main theme of this work is a unifying algorithm,\n\\textbf{L}oop\\textbf{L}ess \\textbf{S}ARAH (L2S) for problems formulated as\nsummation of $n$ individual loss functions. L2S broadens a recently developed\nvariance reduction method known as SARAH. To find an $\\epsilon$-accurate\nsolution, L2S enjoys a complexity of ${\\cal O}\\big( (n+\\kappa) \\ln\n(1/\\epsilon)\\big)$ for strongly convex problems. For convex problems, when\nadopting an $n$-dependent step size, the complexity of L2S is ${\\cal O}(n+\n\\sqrt{n}/\\epsilon)$; while for more frequently adopted $n$-independent step\nsize, the complexity is ${\\cal O}(n+ n/\\epsilon)$. Distinct from SARAH, our\ntheoretical findings support an $n$-independent step size in convex problems\nwithout extra assumptions. For nonconvex problems, the complexity of L2S is\n${\\cal O}(n+ \\sqrt{n}/\\epsilon)$. Our numerical tests on neural networks\nsuggest that L2S can have better generalization properties than SARAH. Along\nwith L2S, our side results include the linear convergence of the last iteration\nfor SARAH in strongly convex problems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 23:02:46 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 17:54:07 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Li", "Bingcong", ""], ["Ma", "Meng", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1906.02353", "submitter": "Yi Ren", "authors": "Yi Ren, Donald Goldfarb", "title": "Efficient Subsampled Gauss-Newton and Natural Gradient Methods for\n  Training Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present practical Levenberg-Marquardt variants of Gauss-Newton and natural\ngradient methods for solving non-convex optimization problems that arise in\ntraining deep neural networks involving enormous numbers of variables and huge\ndata sets. Our methods use subsampled Gauss-Newton or Fisher information\nmatrices and either subsampled gradient estimates (fully stochastic) or full\ngradients (semi-stochastic), which, in the latter case, we prove convergent to\na stationary point. By using the Sherman-Morrison-Woodbury formula with\nautomatic differentiation (backpropagation) we show how our methods can be\nimplemented to perform efficiently. Finally, numerical results are presented to\ndemonstrate the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 23:13:42 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ren", "Yi", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1906.02355", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Tesi Xiao, Si Si, Qin Cao, Sanjiv Kumar, Cho-Jui Hsieh", "title": "Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equation (Neural ODE) has been proposed as a\ncontinuous approximation to the ResNet architecture. Some commonly used\nregularization mechanisms in discrete neural networks (e.g. dropout, Gaussian\nnoise) are missing in current Neural ODE networks. In this paper, we propose a\nnew continuous neural network framework called Neural Stochastic Differential\nEquation (Neural SDE) network, which naturally incorporates various commonly\nused regularization mechanisms based on random noise injection. Our framework\ncan model various types of noise injection frequently used in discrete networks\nfor regularization purpose, such as dropout and additive/multiplicative noise\nin each block. We provide theoretical analysis explaining the improved\nrobustness of Neural SDE models against input perturbations/adversarial\nattacks. Furthermore, we demonstrate that the Neural SDE network can achieve\nbetter generalization than the Neural ODE and is more resistant to adversarial\nand non-adversarial input perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 23:19:50 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Liu", "Xuanqing", ""], ["Xiao", "Tesi", ""], ["Si", "Si", ""], ["Cao", "Qin", ""], ["Kumar", "Sanjiv", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.02367", "submitter": "Deepesh Data", "authors": "Debraj Basu, Deepesh Data, Can Karakus, Suhas Diggavi", "title": "Qsparse-local-SGD: Distributed SGD with Quantization, Sparsification,\n  and Local Computations", "comments": "50 pages; 8 figures; full version of a paper in NeurIPS 2019 with the\n  same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication bottleneck has been identified as a significant issue in\ndistributed optimization of large-scale learning models. Recently, several\napproaches to mitigate this problem have been proposed, including different\nforms of gradient compression or computing local models and mixing them\niteratively. In this paper, we propose \\emph{Qsparse-local-SGD} algorithm,\nwhich combines aggressive sparsification with quantization and local\ncomputation along with error compensation, by keeping track of the difference\nbetween the true and compressed gradients. We propose both synchronous and\nasynchronous implementations of \\emph{Qsparse-local-SGD}. We analyze\nconvergence for \\emph{Qsparse-local-SGD} in the \\emph{distributed} setting for\nsmooth non-convex and convex objective functions. We demonstrate that\n\\emph{Qsparse-local-SGD} converges at the same rate as vanilla distributed SGD\nfor many important classes of sparsifiers and quantizers. We use\n\\emph{Qsparse-local-SGD} to train ResNet-50 on ImageNet and show that it\nresults in significant savings over the state-of-the-art, in the number of bits\ntransmitted to reach target accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 00:46:30 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 20:28:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Basu", "Debraj", ""], ["Data", "Deepesh", ""], ["Karakus", "Can", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1906.02384", "submitter": "Sayan Dasgupta", "authors": "Sayan Dasgupta and Ying Huang", "title": "Selecting Biomarkers for building optimal treatment selection rules\n  using Kernel Machines", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimal biomarker combinations for treatment-selection can be derived by\nminimizing total burden to the population caused by the targeted disease and\nits treatment. However, when multiple biomarkers are present, including all in\nthe model can be expensive and hurt model performance. To remedy this, we\nconsider feature selection in optimization by minimizing an extended total\nburden that additionally incorporates biomarker measurement costs. Formulating\nit as a 0-norm penalized weighted classification, we develop various procedures\nfor estimating linear and nonlinear combinations. Through simulations and a\nreal data example, we demonstrate the importance of incorporating\nfeature-selection and marker cost when deriving treatment-selection rules.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 02:17:48 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Dasgupta", "Sayan", ""], ["Huang", "Ying", ""]]}, {"id": "1906.02385", "submitter": "Frederick Eberhardt", "authors": "Zhalama and Jiji Zhang and Frederick Eberhardt and Wolfgang Mayer and\n  Mark Junjie Li", "title": "ASP-based Discovery of Semi-Markovian Causal Models under Weaker\n  Assumptions", "comments": "12 pages, 6 figures, IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the possibility of relaxing the so-called Faithfulness\nassumption in automated causal discovery has been investigated. The\ninvestigation showed (1) that the Faithfulness assumption can be weakened in\nvarious ways that in an important sense preserve its power, and (2) that\nweakening of Faithfulness may help to speed up methods based on Answer Set\nProgramming. However, this line of work has so far only considered the\ndiscovery of causal models without latent variables. In this paper, we study\nweakenings of Faithfulness for constraint-based discovery of semi-Markovian\ncausal models, which accommodate the possibility of latent variables, and show\nthat both (1) and (2) remain the case in this more realistic setting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 02:23:18 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Zhalama", "", ""], ["Zhang", "Jiji", ""], ["Eberhardt", "Frederick", ""], ["Mayer", "Wolfgang", ""], ["Li", "Mark Junjie", ""]]}, {"id": "1906.02387", "submitter": "Linning Xu", "authors": "Linning Xu, Feng Yin, Jiawei Zhang, Zhi-Quan Luo, Shuguang Cui", "title": "A General $\\mathcal{O}(n^2)$ Hyper-Parameter Optimization for Gaussian\n  Process Regression with Cross-Validation and Non-linearly Constrained ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-parameter optimization remains as the core issue of Gaussian process\n(GP) for machine learning nowadays. The benchmark method using maximum\nlikelihood (ML) estimation and gradient descent (GD) is impractical for\nprocessing big data due to its $O(n^3)$ complexity. Many sophisticated global\nor local approximation models, for instance, sparse GP, distributed GP, have\nbeen proposed to address such complexity issue. In this paper, we propose two\nnovel and general-purpose GP hyper-parameter training schemes (GPCV-ADMM) by\nreplacing ML with cross-validation (CV) as the fitting criterion and replacing\nGD with a non-linearly constrained alternating direction method of multipliers\n(ADMM) as the optimization method. The proposed schemes are of $O(n^2)$\ncomplexity for any covariance matrix without special structure. We conduct\nvarious experiments based on both synthetic and real data sets, wherein the\nproposed schemes show excellent performance in terms of convergence,\nhyper-parameter estimation accuracy, and computational time in comparison with\nthe traditional ML based routines given in the GPML toolbox.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 02:33:09 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 01:44:00 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Xu", "Linning", ""], ["Yin", "Feng", ""], ["Zhang", "Jiawei", ""], ["Luo", "Zhi-Quan", ""], ["Cui", "Shuguang", ""]]}, {"id": "1906.02399", "submitter": "Alireza Abedin Varamin", "authors": "Alireza Abedin, S. Hamid Rezatofighi, Qinfeng Shi, Damith C.\n  Ranasinghe", "title": "SparseSense: Human Activity Recognition from Highly Sparse Sensor\n  Data-streams Using Set-based Neural Networks", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batteryless or so called passive wearables are providing new and innovative\nmethods for human activity recognition (HAR), especially in healthcare\napplications for older people. Passive sensors are low cost, lightweight,\nunobtrusive and desirably disposable; attractive attributes for healthcare\napplications in hospitals and nursing homes. Despite the compelling\npropositions for sensing applications, the data streams from these sensors are\ncharacterised by high sparsity---the time intervals between sensor readings are\nirregular while the number of readings per unit time are often limited. In this\npaper, we rigorously explore the problem of learning activity recognition\nmodels from temporally sparse data. We describe how to learn directly from\nsparse data using a deep learning paradigm in an end-to-end manner. We\ndemonstrate significant classification performance improvements on real-world\npassive sensor datasets from older people over the state-of-the-art deep\nlearning human activity recognition models. Further, we provide insights into\nthe model's behaviour through complementary experiments on a benchmark dataset\nand visualisation of the learned activity feature spaces.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 03:50:33 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Abedin", "Alireza", ""], ["Rezatofighi", "S. Hamid", ""], ["Shi", "Qinfeng", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "1906.02416", "submitter": "Alexander Terenin", "authors": "Alexander Terenin, M{\\aa}ns Magnusson, Leif Jonsson", "title": "Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models", "comments": null, "journal-ref": "Conference on Empirical Methods in Natural Language Processing,\n  2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To scale non-parametric extensions of probabilistic topic models such as\nLatent Dirichlet allocation to larger data sets, practitioners rely\nincreasingly on parallel and distributed systems. In this work, we study\ndata-parallel training for the hierarchical Dirichlet process (HDP) topic\nmodel. Based upon a representation of certain conditional distributions within\nan HDP, we propose a doubly sparse data-parallel sampler for the HDP topic\nmodel. This sampler utilizes all available sources of sparsity found in natural\nlanguage - an important way to make computation efficient. We benchmark our\nmethod on a well-known corpus (PubMed) with 8m documents and 768m tokens, using\na single multi-core machine in under four days.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:04:08 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 12:00:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Terenin", "Alexander", ""], ["Magnusson", "M\u00e5ns", ""], ["Jonsson", "Leif", ""]]}, {"id": "1906.02425", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, Marcus Rohrbach", "title": "Uncertainty-guided Continual Learning with Bayesian Neural Networks", "comments": "Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to learn new tasks without forgetting previously\nlearned ones. This is especially challenging when one cannot access data from\nprevious tasks and when the model has a fixed capacity. Current\nregularization-based continual learning algorithms need an external\nrepresentation and extra computation to measure the parameters'\n\\textit{importance}. In contrast, we propose Uncertainty-guided Continual\nBayesian Neural Networks (UCB), where the learning rate adapts according to the\nuncertainty defined in the probability distribution of the weights in networks.\nUncertainty is a natural way to identify \\textit{what to remember} and\n\\textit{what to change} as we continually learn, and thus mitigate catastrophic\nforgetting. We also show a variant of our model, which uses uncertainty for\nweight pruning and retains task performance after pruning by saving binary\nmasks per tasks. We evaluate our UCB approach extensively on diverse object\nclassification datasets with short and long sequences of tasks and report\nsuperior or on-par performance compared to existing approaches. Additionally,\nwe show that our model does not necessarily need task information at test time,\ni.e. it does not presume knowledge of which task a sample belongs to.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:40:25 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 01:08:22 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Elhoseiny", "Mohamed", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1906.02428", "submitter": "Yiming Yan", "authors": "Yiming Yan, Melissa Ailem, Fei Sha", "title": "Amortized Inference of Variational Bounds for Learning Noisy-OR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical approaches for approximate inference depend on cleverly designed\nvariational distributions and bounds. Modern approaches employ amortized\nvariational inference, which uses a neural network to approximate any posterior\nwithout leveraging the structures of the generative models. In this paper, we\npropose Amortized Conjugate Posterior (ACP), a hybrid approach taking\nadvantages of both types of approaches. Specifically, we use the classical\nmethods to derive specific forms of posterior distributions and then learn the\nvariational parameters using amortized inference. We study the effectiveness of\nthe proposed approach on the noisy-or model and compare to both the classical\nand the modern approaches for approximate inference and parameter learning. Our\nresults show that the proposed method outperforms or are at par with other\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:55:39 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 04:21:39 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Yan", "Yiming", ""], ["Ailem", "Melissa", ""], ["Sha", "Fei", ""]]}, {"id": "1906.02433", "submitter": "Cho Ying Wu", "authors": "Cho-Ying Wu, Jian-Jiun Ding", "title": "Nonconvex Approach for Sparse and Low-Rank Constrained Models with Dual\n  Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we research on the behaviors of surrogates for the rank\nfunction on different image processing problems and their optimization\nalgorithms. We first propose a novel nonconvex rank surrogate on the general\nrank minimization problem and apply this to the corrupted image completion\nproblem. Then, we propose that nonconvex rank surrogates can be introduced into\ntwo well-known sparse and low-rank models: Robust Principal Component Analysis\n(RPCA) and Low-Rank Representation (LRR). For optimization, we use alternating\ndirection method of multipliers (ADMM) and propose a trick, which is called the\ndual momentum. We add the difference of the dual variable between the current\nand the last iteration with a weight. This trick can avoid the local minimum\nproblem and make the algorithm converge to a solution with smaller recovery\nerror in the nonconvex optimization problem. Also, it can boost the convergence\nwhen the variable updates too slowly. We also give a severe proof and verify\nthat the proposed algorithms are convergent. Then, several experiments are\nconducted, including image completion, denoising, and spectral clustering with\noutlier detection. These experiments show that the proposed methods are\neffective in image and signal processing applications, and have the best\nperformance compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 06:05:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wu", "Cho-Ying", ""], ["Ding", "Jian-Jiun", ""]]}, {"id": "1906.02435", "submitter": "Yuexiang Zhai", "authors": "Yuexiang Zhai, Zitong Yang, Zhenyu Liao, John Wright, and Yi Ma", "title": "Complete Dictionary Learning via $\\ell^4$-Norm Maximization over the\n  Orthogonal Group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the fundamental problem of learning a complete\n(orthogonal) dictionary from samples of sparsely generated signals. Most\nexisting methods solve the dictionary (and sparse representations) based on\nheuristic algorithms, usually without theoretical guarantees for either\noptimality or complexity. The recent $\\ell^1$-minimization based methods do\nprovide such guarantees but the associated algorithms recover the dictionary\none column at a time. In this work, we propose a new formulation that maximizes\nthe $\\ell^4$-norm over the orthogonal group, to learn the entire dictionary. We\nprove that under a random data model, with nearly minimum sample complexity,\nthe global optima of the $\\ell^4$ norm are very close to signed permutations of\nthe ground truth. Inspired by this observation, we give a conceptually simple\nand yet effective algorithm based on \"matching, stretching, and projection\"\n(MSP). The algorithm provably converges locally at a superlinear (cubic) rate\nand cost per iteration is merely an SVD. In addition to strong theoretical\nguarantees, experiments show that the new algorithm is significantly more\nefficient and effective than existing methods, including KSVD and\n$\\ell^1$-based methods. Preliminary experimental results on mixed real imagery\ndata clearly demonstrate advantages of so learned dictionary over classic PCA\nbases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 06:19:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 17:10:21 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 18:46:02 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 17:43:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zhai", "Yuexiang", ""], ["Yang", "Zitong", ""], ["Liao", "Zhenyu", ""], ["Wright", "John", ""], ["Ma", "Yi", ""]]}, {"id": "1906.02436", "submitter": "Qi Lei", "authors": "Qi Lei, Jiacheng Zhuo, Constantine Caramanis, Inderjit S. Dhillon,\n  Alexandros G. Dimakis", "title": "Primal-Dual Block Frank-Wolfe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a variant of the Frank-Wolfe algorithm for solving a class of\nsparse/low-rank optimization problems. Our formulation includes Elastic Net,\nregularized SVMs and phase retrieval as special cases. The proposed Primal-Dual\nBlock Frank-Wolfe algorithm reduces the per-iteration cost while maintaining\nlinear convergence rate. The per iteration cost of our method depends on the\nstructural complexity of the solution (i.e. sparsity/low-rank) instead of the\nambient dimension. We empirically show that our algorithm outperforms the\nstate-of-the-art methods on (multi-class) classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 06:25:37 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Lei", "Qi", ""], ["Zhuo", "Jiacheng", ""], ["Caramanis", "Constantine", ""], ["Dhillon", "Inderjit S.", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1906.02439", "submitter": "Ayon Sen", "authors": "Ayon Sen, Xiaojin Zhu, Liam Marshall, Robert Nowak", "title": "Should Adversarial Attacks Use Pixel p-Norm?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks aim to confound machine learning systems, while remaining\nvirtually imperceptible to humans. Attacks on image classification systems are\ntypically gauged in terms of $p$-norm distortions in the pixel feature space.\nWe perform a behavioral study, demonstrating that the pixel $p$-norm for any\n$0\\le p \\le \\infty$, and several alternative measures including earth mover's\ndistance, structural similarity index, and deep net embedding, do not fit human\nperception. Our result has the potential to improve the understanding of\nadversarial attack and defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 06:47:55 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Sen", "Ayon", ""], ["Zhu", "Xiaojin", ""], ["Marshall", "Liam", ""], ["Nowak", "Robert", ""]]}, {"id": "1906.02444", "submitter": "Davor Kolar", "authors": "Davor Kolar, Dragutin Lisjak, Michal Pajak, Danijel Pavkovic", "title": "Fault Diagnosis of Rotary Machines using Deep Convolutional Neural\n  Network with three axis signal input", "comments": "I need to do a major revision of this article to make it publishable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends focusing on Industry 4.0 concept and smart manufacturing arise\na data-driven fault diagnosis as key topic in condition-based maintenance.\nFault diagnosis is considered as an essential task in rotary machinery since\npossibility of an early detection and diagnosis of the faulty condition can\nsave both time and money. Traditional data-driven techniques of fault diagnosis\nrequire signal processing for feature extraction, as they are unable to work\nwith raw signal data, consequently leading to need for expert knowledge and\nhuman work. The emergence of deep learning architectures in condition-based\nmaintenance promises to ensure high performance fault diagnosis while lowering\nnecessity for expert knowledge and human work. This paper presents developed\ntechnique for deep learning-based data-driven fault diagnosis of rotary\nmachinery. The proposed technique input raw three axis accelerometer signal as\nhigh-definition image into deep learning layers which automatically extract\nsignal features, enabling high classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:05:49 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 07:55:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kolar", "Davor", ""], ["Lisjak", "Dragutin", ""], ["Pajak", "Michal", ""], ["Pavkovic", "Danijel", ""]]}, {"id": "1906.02448", "submitter": "Wen Zhang", "authors": "Wen Zhang, Yang Feng, Fandong Meng, Di You and Qun Liu", "title": "Bridging the Gap between Training and Inference for Neural Machine\n  Translation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) generates target words sequentially in the\nway of predicting the next word conditioned on the context words. At training\ntime, it predicts with the ground truth words as context while at inference it\nhas to generate the entire sequence from scratch. This discrepancy of the fed\ncontext leads to error accumulation among the way. Furthermore, word-level\ntraining requires strict matching between the generated sequence and the ground\ntruth sequence which leads to overcorrection over different but reasonable\ntranslations. In this paper, we address these issues by sampling context words\nnot only from the ground truth sequence but also from the predicted sequence by\nthe model during training, where the predicted sequence is selected with a\nsentence-level optimum. Experiment results on Chinese->English and WMT'14\nEnglish->German translation tasks demonstrate that our approach can achieve\nsignificant improvements on multiple datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:15:52 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 11:54:01 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Wen", ""], ["Feng", "Yang", ""], ["Meng", "Fandong", ""], ["You", "Di", ""], ["Liu", "Qun", ""]]}, {"id": "1906.02457", "submitter": "Xiao Ma", "authors": "Xiao Ma, Shen-Yi Zhao and Wu-Jun Li", "title": "Clustered Reinforcement Learning", "comments": "16pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration strategy design is one of the challenging problems in\nreinforcement learning~(RL), especially when the environment contains a large\nstate space or sparse rewards. During exploration, the agent tries to discover\nnovel areas or high reward~(quality) areas. In most existing methods, the\nnovelty and quality in the neighboring area of the current state are not well\nutilized to guide the exploration of the agent. To tackle this problem, we\npropose a novel RL framework, called \\underline{c}lustered\n\\underline{r}einforcement \\underline{l}earning~(CRL), for efficient exploration\nin RL. CRL adopts clustering to divide the collected states into several\nclusters, based on which a bonus reward reflecting both novelty and quality in\nthe neighboring area~(cluster) of the current state is given to the agent.\nExperiments on a continuous control task and several \\emph{Atari 2600} games\nshow that CRL can outperform other state-of-the-art methods to achieve the best\nperformance in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:35:02 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ma", "Xiao", ""], ["Zhao", "Shen-Yi", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1906.02473", "submitter": "Tilman Klaeger", "authors": "Tilman Klaeger, Andre Schult, Lukas Oehm", "title": "Using anomaly detection to support classification of fast running\n  (packaging) processes", "comments": null, "journal-ref": null, "doi": "10.1109/INDIN41052.2019.8972081", "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new method to assist in labeling data arriving\nfrom fast running processes using anomaly detection. A result is the\npossibility to manually classify data arriving at a high rates to train machine\nlearning models. To circumvent the problem of not having a real ground truth we\npropose specific metrics for model selection and validation of the results.\n  The use case is taken from the food packaging industry, where processes are\naffected by regular but short breakdowns causing interruptions in the\nproduction process. Fast production rates make it hard for machine operators to\nidentify the source and thus the cause of the breakdown. Self learning\nassistance systems can help them finding the root cause of the problem and\nassist the machine operator in applying lasting solutions. These learning\nsystems need to be trained to identify reoccurring problems using data\nanalytics. Training is not easy as the process is too fast to be manually\nmonitored to add specific classifications on the single data points.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 08:24:12 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:23:49 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Klaeger", "Tilman", ""], ["Schult", "Andre", ""], ["Oehm", "Lukas", ""]]}, {"id": "1906.02481", "submitter": "Pim De Haan", "authors": "Miranda C. N. Cheng, Vassilis Anagiannis, Maurice Weiler, Pim de Haan,\n  Taco S. Cohen and Max Welling", "title": "Covariance in Physics and Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proceeding we give an overview of the idea of covariance (or\nequivariance) featured in the recent development of convolutional neural\nnetworks (CNNs). We study the similarities and differences between the use of\ncovariance in theoretical physics and in the CNN context. Additionally, we\ndemonstrate that the simple assumption of covariance, together with the\nrequired properties of locality, linearity and weight sharing, is sufficient to\nuniquely determine the form of the convolution.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 08:51:50 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Cheng", "Miranda C. N.", ""], ["Anagiannis", "Vassilis", ""], ["Weiler", "Maurice", ""], ["de Haan", "Pim", ""], ["Cohen", "Taco S.", ""], ["Welling", "Max", ""]]}, {"id": "1906.02494", "submitter": "Yujun Shi", "authors": "Yujun Shi, Benben Liao, Guangyong Chen, Yun Liu, Ming-Ming Cheng,\n  Jiashi Feng", "title": "Understanding Adversarial Behavior of DNNs by Disentangling Non-Robust\n  and Robust Components in Performance Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability to slight input perturbations is a worrying yet intriguing\nproperty of deep neural networks (DNNs). Despite many previous works studying\nthe reason behind such adversarial behavior, the relationship between the\ngeneralization performance and adversarial behavior of DNNs is still little\nunderstood. In this work, we reveal such relation by introducing a metric\ncharacterizing the generalization performance of a DNN. The metric can be\ndisentangled into an information-theoretic non-robust component, responsible\nfor adversarial behavior, and a robust component. Then, we show by experiments\nthat current DNNs rely heavily on optimizing the non-robust component in\nachieving decent performance. We also demonstrate that current state-of-the-art\nadversarial training algorithms indeed try to robustify the DNNs by preventing\nthem from using the non-robust component to distinguish samples from different\ncategories. Also, based on our findings, we take a step forward and point out\nthe possible direction for achieving decent standard performance and\nadversarial robustness simultaneously. We believe that our theory could further\ninspire the community to make more interesting discoveries about the\nrelationship between standard generalization and adversarial generalization of\ndeep learning models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:31:14 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Shi", "Yujun", ""], ["Liao", "Benben", ""], ["Chen", "Guangyong", ""], ["Liu", "Yun", ""], ["Cheng", "Ming-Ming", ""], ["Feng", "Jiashi", ""]]}, {"id": "1906.02500", "submitter": "Daniel Zoran", "authors": "Alex Mott, Daniel Zoran, Mike Chrzanowski, Daan Wierstra, Danilo J.\n  Rezende", "title": "Towards Interpretable Reinforcement Learning Using Attention Augmented\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent work in attention models for image captioning and question\nanswering, we present a soft attention model for the reinforcement learning\ndomain. This model uses a soft, top-down attention mechanism to create a\nbottleneck in the agent, forcing it to focus on task-relevant information by\nsequentially querying its view of the environment. The output of the attention\nmechanism allows direct observation of the information used by the agent to\nselect its actions, enabling easier interpretation of this model than of\ntraditional models. We analyze different strategies that the agents learn and\nshow that a handful of strategies arise repeatedly across different games. We\nalso show that the model learns to query separately about space and content\n(`where' vs. `what'). We demonstrate that an agent using this mechanism can\nachieve performance competitive with state-of-the-art models on ATARI tasks\nwhile still being interpretable.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 10:02:52 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Mott", "Alex", ""], ["Zoran", "Daniel", ""], ["Chrzanowski", "Mike", ""], ["Wierstra", "Daan", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "1906.02502", "submitter": "Yanyan Wang", "authors": "Yanyan Wang, Qun Chen, Jiquan Shen, Boyi Hou, Murtadha Ahmed, Zhanhuai\n  Li", "title": "Gradual Machine Learning for Aspect-level Sentiment Analysis", "comments": "arXiv admin note: text overlap with arXiv:1810.12125", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art solutions for Aspect-Level Sentiment Analysis (ALSA)\nwere built on a variety of deep neural networks (DNN), whose efficacy depends\non large amounts of accurately labeled training data. Unfortunately,\nhigh-quality labeled training data usually require expensive manual work, and\nmay thus not be readily available in real scenarios. In this paper, we propose\na novel solution for ALSA based on the recently proposed paradigm of gradual\nmachine learning, which can enable effective machine labeling without the\nrequirement for manual labeling effort. It begins with some easy instances in\nan ALSA task, which can be automatically labeled by the machine with high\naccuracy, and then gradually labels the more challenging instances by iterative\nfactor graph inference. In the process of gradual machine learning, the hard\ninstances are gradually labeled in small stages based on the estimated\nevidential certainty provided by the labeled easier instances. Our extensive\nexperiments on the benchmark datasets have shown that the performance of the\nproposed solution is considerably better than its unsupervised alternatives,\nand also highly competitive compared to the state-of-the-art supervised DNN\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 10:15:31 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 01:46:23 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Yanyan", ""], ["Chen", "Qun", ""], ["Shen", "Jiquan", ""], ["Hou", "Boyi", ""], ["Ahmed", "Murtadha", ""], ["Li", "Zhanhuai", ""]]}, {"id": "1906.02506", "submitter": "Kazuki Osawa", "authors": "Kazuki Osawa, Siddharth Swaroop, Anirudh Jain, Runa Eschenhagen,\n  Richard E. Turner, Rio Yokota, Mohammad Emtiyaz Khan", "title": "Practical Deep Learning with Bayesian Principles", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian methods promise to fix many shortcomings of deep learning, but they\nare impractical and rarely match the performance of standard methods, let alone\nimprove them. In this paper, we demonstrate practical training of deep networks\nwith natural-gradient variational inference. By applying techniques such as\nbatch normalisation, data augmentation, and distributed training, we achieve\nsimilar performance in about the same number of epochs as the Adam optimiser,\neven on large datasets such as ImageNet. Importantly, the benefits of Bayesian\nprinciples are preserved: predictive probabilities are well-calibrated,\nuncertainties on out-of-distribution data are improved, and continual-learning\nperformance is boosted. This work enables practical deep learning while\npreserving benefits of Bayesian principles. A PyTorch implementation is\navailable as a plug-and-play optimiser.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 10:22:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 02:01:14 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Osawa", "Kazuki", ""], ["Swaroop", "Siddharth", ""], ["Jain", "Anirudh", ""], ["Eschenhagen", "Runa", ""], ["Turner", "Richard E.", ""], ["Yokota", "Rio", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "1906.02517", "submitter": "Liwei Lin", "authors": "Liwei Lin, Xiangdong Wang, Hong Liu and Yueliang Qian", "title": "Guided learning for weakly-labeled semi-supervised sound event detection", "comments": "Accepted by ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple but efficient method termed Guided Learning for\nweakly-labeled semi-supervised sound event detection (SED). There are two\nsub-targets implied in weakly-labeled SED: audio tagging and boundary\ndetection. Instead of designing a single model by considering a trade-off\nbetween the two sub-targets, we design a teacher model aiming at audio tagging\nto guide a student model aiming at boundary detection to learn using the\nunlabeled data. The guidance is guaranteed by the audio tagging performance gap\nof the two models. In the meantime, the student model liberated from the\ntrade-off is able to provide more excellent boundary detection results. We\npropose a principle to design such two models based on the relation between the\ntemporal compression scale and the two sub-targets. We also propose an\nend-to-end semi-supervised learning process for these two models to enable\ntheir abilities to rise alternately. Experiments on the DCASE2018 Task4 dataset\nshow that our approach achieves competitive performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 11:02:41 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 03:03:47 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 07:18:45 GMT"}, {"version": "v4", "created": "Tue, 22 Oct 2019 17:41:22 GMT"}, {"version": "v5", "created": "Tue, 4 Feb 2020 09:03:00 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lin", "Liwei", ""], ["Wang", "Xiangdong", ""], ["Liu", "Hong", ""], ["Qian", "Yueliang", ""]]}, {"id": "1906.02530", "submitter": "Jasper Snoek", "authors": "Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, D Sculley,\n  Sebastian Nowozin, Joshua V. Dillon, Balaji Lakshminarayanan, Jasper Snoek", "title": "Can You Trust Your Model's Uncertainty? Evaluating Predictive\n  Uncertainty Under Dataset Shift", "comments": "Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning methods including deep learning have achieved great\nsuccess in predictive accuracy for supervised learning tasks, but may still\nfall short in giving useful estimates of their predictive {\\em uncertainty}.\nQuantifying uncertainty is especially critical in real-world settings, which\noften involve input distributions that are shifted from the training\ndistribution due to a variety of factors including sample bias and\nnon-stationarity. In such settings, well calibrated uncertainty estimates\nconvey information about when a model's output should (or should not) be\ntrusted. Many probabilistic deep learning methods, including Bayesian-and\nnon-Bayesian methods, have been proposed in the literature for quantifying\npredictive uncertainty, but to our knowledge there has not previously been a\nrigorous large-scale empirical comparison of these methods under dataset shift.\nWe present a large-scale benchmark of existing state-of-the-art methods on\nclassification problems and investigate the effect of dataset shift on accuracy\nand calibration. We find that traditional post-hoc calibration does indeed fall\nshort, as do several other previous methods. However, some methods that\nmarginalize over models give surprisingly strong results across a broad\nspectrum of tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 11:42:53 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:30:28 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ovadia", "Yaniv", ""], ["Fertig", "Emily", ""], ["Ren", "Jie", ""], ["Nado", "Zachary", ""], ["Sculley", "D", ""], ["Nowozin", "Sebastian", ""], ["Dillon", "Joshua V.", ""], ["Lakshminarayanan", "Balaji", ""], ["Snoek", "Jasper", ""]]}, {"id": "1906.02535", "submitter": "Marc Riera", "authors": "Marc Riera, Jose-Maria Arnau, and Antonio Gonzalez", "title": "(Pen-) Ultimate DNN Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN pruning reduces memory footprint and computational work of DNN-based\nsolutions to improve performance and energy-efficiency. An effective pruning\nscheme should be able to systematically remove connections and/or neurons that\nare unnecessary or redundant, reducing the DNN size without any loss in\naccuracy. In this paper we show that prior pruning schemes require an extremely\ntime-consuming iterative process that requires retraining the DNN many times to\ntune the pruning hyperparameters. We propose a DNN pruning scheme based on\nPrincipal Component Analysis and relative importance of each neuron's\nconnection that automatically finds the optimized DNN in one shot without\nrequiring hand-tuning of multiple parameters.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 11:51:48 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Riera", "Marc", ""], ["Arnau", "Jose-Maria", ""], ["Gonzalez", "Antonio", ""]]}, {"id": "1906.02547", "submitter": "Victor Garcia Satorras", "authors": "Victor Garcia Satorras, Zeynep Akata, Max Welling", "title": "Combining Generative and Discriminative Models for Hybrid Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graphical model is a structured representation of the data generating\nprocess. The traditional method to reason over random variables is to perform\ninference in this graphical model. However, in many cases the generating\nprocess is only a poor approximation of the much more complex true data\ngenerating process, leading to suboptimal estimation. The subtleties of the\ngenerative process are however captured in the data itself and we can `learn to\ninfer', that is, learn a direct mapping from observations to explanatory latent\nvariables. In this work we propose a hybrid model that combines graphical\ninference with a learned inverse model, which we structure as in a graph neural\nnetwork, while the iterative algorithm as a whole is formulated as a recurrent\nneural network. By using cross-validation we can automatically balance the\namount of work performed by graphical inference versus learned inference. We\napply our ideas to the Kalman filter, a Gaussian hidden Markov model for time\nsequences, and show, among other things, that our model can estimate the\ntrajectory of a noisy chaotic Lorenz Attractor much more accurately than either\nthe learned or graphical inference run in isolation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 12:29:32 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 20:20:27 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 12:28:56 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 13:24:06 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Satorras", "Victor Garcia", ""], ["Akata", "Zeynep", ""], ["Welling", "Max", ""]]}, {"id": "1906.02568", "submitter": "Felix Wiewel", "authors": "Felix Wiewel and Bin Yang", "title": "Localizing Catastrophic Forgetting in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) suffer from catastrophic forgetting when\ntrained on a sequence of tasks. While this phenomenon was studied in the past,\nthere is only very limited recent research on this phenomenon. We propose a\nmethod for determining the contribution of individual parameters in an ANN to\ncatastrophic forgetting. The method is used to analyze an ANNs response to\nthree different continual learning scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:18:03 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wiewel", "Felix", ""], ["Yang", "Bin", ""]]}, {"id": "1906.02569", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman\n  Alfozan, James Zou", "title": "Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild", "comments": "Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accessibility is a major challenge of machine learning (ML). Typical ML\nmodels are built by specialists and require specialized hardware/software as\nwell as ML experience to validate. This makes it challenging for non-technical\ncollaborators and endpoint users (e.g. physicians) to easily provide feedback\non model development and to gain trust in ML. The accessibility challenge also\nmakes collaboration more difficult and limits the ML researcher's exposure to\nrealistic data and scenarios that occur in the wild. To improve accessibility\nand facilitate collaboration, we developed an open-source Python package,\nGradio, which allows researchers to rapidly generate a visual interface for\ntheir ML models. Gradio makes accessing any ML model as easy as sharing a URL.\nOur development of Gradio is informed by interviews with a number of machine\nlearning researchers who participate in interdisciplinary collaborations. Their\nfeedback identified that Gradio should support a variety of interfaces and\nframeworks, allow for easy sharing of the interface, allow for input\nmanipulation and interactive inference by the domain expert, as well as allow\nembedding the interface in iPython notebooks. We developed these features and\ncarried out a case study to understand Gradio's usefulness and usability in the\nsetting of a machine learning collaboration between a researcher and a\ncardiologist.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:18:47 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Abid", "Abubakar", ""], ["Abdalla", "Ali", ""], ["Abid", "Ali", ""], ["Khan", "Dawood", ""], ["Alfozan", "Abdulrahman", ""], ["Zou", "James", ""]]}, {"id": "1906.02576", "submitter": "Bernhard C. Geiger", "authors": "Rana Ali Amjad and Bernhard C. Geiger", "title": "Class-Conditional Compression and Disentanglement: Bridging the Gap\n  between Neural Networks and Naive Bayes Classifiers", "comments": "draft; work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this draft, which reports on work in progress, we 1) adapt the information\nbottleneck functional by replacing the compression term by class-conditional\ncompression, 2) relax this functional using a variational bound related to\nclass-conditional disentanglement, 3) consider this functional as a training\nobjective for stochastic neural networks, and 4) show that the latent\nrepresentations are learned such that they can be used in a naive Bayes\nclassifier. We continue by suggesting a series of experiments along the lines\nof Nonlinear In-formation Bottleneck [Kolchinsky et al., 2018], Deep\nVariational Information Bottleneck [Alemi et al., 2017], and Information\nDropout [Achille and Soatto, 2018]. We furthermore suggest a neural network\nwhere the decoder architecture is a parameterized naive Bayes decoder.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:32:54 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Amjad", "Rana Ali", ""], ["Geiger", "Bernhard C.", ""]]}, {"id": "1906.02589", "submitter": "Elliot Creager", "authors": "Elliot Creager, David Madras, J\\\"orn-Henrik Jacobsen, Marissa A. Weis,\n  Kevin Swersky, Toniann Pitassi, Richard Zemel", "title": "Flexibly Fair Representation Learning by Disentanglement", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning\n  (ICML), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning representations that achieve group and\nsubgroup fairness with respect to multiple sensitive attributes. Taking\ninspiration from the disentangled representation learning literature, we\npropose an algorithm for learning compact representations of datasets that are\nuseful for reconstruction and prediction, but are also \\emph{flexibly fair},\nmeaning they can be easily modified at test time to achieve subgroup\ndemographic parity with respect to multiple sensitive attributes and their\nconjunctions. We show empirically that the resulting encoder---which does not\nrequire the sensitive attributes for inference---enables the adaptation of a\nsingle representation to a variety of fair classification tasks with new target\nlabels and subgroup definitions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:56:24 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Creager", "Elliot", ""], ["Madras", "David", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Weis", "Marissa A.", ""], ["Swersky", "Kevin", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1906.02590", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Mark Crowley", "title": "Linear and Quadratic Discriminant Analysis: Tutorial", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial explains Linear Discriminant Analysis (LDA) and Quadratic\nDiscriminant Analysis (QDA) as two fundamental classification methods in\nstatistical and probabilistic learning. We start with the optimization of\ndecision boundary on which the posteriors are equal. Then, LDA and QDA are\nderived for binary and multiple classes. The estimation of parameters in LDA\nand QDA are also covered. Then, we explain how LDA and QDA are related to\nmetric learning, kernel principal component analysis, Mahalanobis distance,\nlogistic regression, Bayes optimal classifier, Gaussian naive Bayes, and\nlikelihood ratio test. We also prove that LDA and Fisher discriminant analysis\nare equivalent. We finally clarify some of the theoretical concepts with\nsimulations we provide.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 23:45:34 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Crowley", "Mark", ""]]}, {"id": "1906.02605", "submitter": "Yifeng Fan", "authors": "Yifeng Fan and Zhizhen Zhao", "title": "Multi-Frequency Vector Diffusion Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce multi-frequency vector diffusion maps (MFVDM), a new framework\nfor organizing and analyzing high dimensional datasets. The new method is a\nmathematical and algorithmic generalization of vector diffusion maps (VDM) and\nother non-linear dimensionality reduction methods. MFVDM combines different\nnonlinear embeddings of the data points defined with multiple unitary\nirreducible representations of the alignment group that connect two nodes in\nthe graph. We illustrate the efficacy of MFVDM on synthetic data generated\naccording to a random graph model and cryo-electron microscopy image dataset.\nThe new method achieves better nearest neighbor search and alignment estimation\nthan the state-of-the-arts VDM and diffusion maps (DM) on extremely noisy data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 14:16:37 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Fan", "Yifeng", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1906.02606", "submitter": "Yanan Li", "authors": "Yanan Li, Xuebin Ren, Shusen Yang, and Xinyu Yang", "title": "Impact of Prior Knowledge and Data Correlation on Privacy Leakage: A\n  Unified Analysis", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security, vol. 14,\n  no. 9, pp. 2342-2357, Sept. 2019", "doi": "10.1109/TIFS.2019.2895970", "report-no": null, "categories": "cs.LG cs.CR math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been widely understood that differential privacy (DP) can guarantee\nrigorous privacy against adversaries with arbitrary prior knowledge. However,\nrecent studies demonstrate that this may not be true for correlated data, and\nindicate that three factors could influence privacy leakage: the data\ncorrelation pattern, prior knowledge of adversaries, and sensitivity of the\nquery function. This poses a fundamental problem: what is the mathematical\nrelationship between the three factors and privacy leakage? In this paper, we\npresent a unified analysis of this problem. A new privacy definition, named\n\\textit{prior differential privacy (PDP)}, is proposed to evaluate privacy\nleakage considering the exact prior knowledge possessed by the adversary. We\nuse two models, the weighted hierarchical graph (WHG) and the multivariate\nGaussian model to analyze discrete and continuous data, respectively. We\ndemonstrate that positive, negative, and hybrid correlations have distinct\nimpacts on privacy leakage. Considering general correlations, a closed-form\nexpression of privacy leakage is derived for continuous data, and a chain rule\nis presented for discrete data. Our results are valid for general linear\nqueries, including count, sum, mean, and histogram. Numerical experiments are\npresented to verify our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:16:13 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Li", "Yanan", ""], ["Ren", "Xuebin", ""], ["Yang", "Shusen", ""], ["Yang", "Xinyu", ""]]}, {"id": "1906.02611", "submitter": "Raphael Gontijo Lopes", "authors": "Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer, Ekin D.\n  Cubuk", "title": "Improving Robustness Without Sacrificing Accuracy with Patch Gaussian\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying machine learning systems in the real world requires both high\naccuracy on clean data and robustness to naturally occurring corruptions. While\narchitectural advances have led to improved accuracy, building robust models\nremains challenging. Prior work has argued that there is an inherent trade-off\nbetween robustness and accuracy, which is exemplified by standard data augment\ntechniques such as Cutout, which improves clean accuracy but not robustness,\nand additive Gaussian noise, which improves robustness but hurts accuracy. To\novercome this trade-off, we introduce Patch Gaussian, a simple augmentation\nscheme that adds noise to randomly selected patches in an input image. Models\ntrained with Patch Gaussian achieve state of the art on the CIFAR-10 and\nImageNetCommon Corruptions benchmarks while also improving accuracy on clean\ndata. We find that this augmentation leads to reduced sensitivity to high\nfrequency noise(similar to Gaussian) while retaining the ability to take\nadvantage of relevant high frequency information in the image (similar to\nCutout). Finally, we show that Patch Gaussian can be used in conjunction with\nother regularization methods and data augmentation policies such as\nAutoAugment, and improves performance on the COCO object detection benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:54:24 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Lopes", "Raphael Gontijo", ""], ["Yin", "Dong", ""], ["Poole", "Ben", ""], ["Gilmer", "Justin", ""], ["Cubuk", "Ekin D.", ""]]}, {"id": "1906.02613", "submitter": "Shengchao Liu", "authors": "Shengchao Liu, Dimitris Papailiopoulos, Dimitris Achlioptas", "title": "Bad Global Minima Exist and SGD Can Reach Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works have aimed to explain why overparameterized neural networks\ngeneralize well when trained by Stochastic Gradient Descent (SGD). The\nconsensus explanation that has emerged credits the randomized nature of SGD for\nthe bias of the training process towards low-complexity models and, thus, for\nimplicit regularization. We take a careful look at this explanation in the\ncontext of image classification with common deep neural network architectures.\nWe find that if we do not regularize \\emph{explicitly}, then SGD can be easily\nmade to converge to poorly-generalizing, high-complexity models: all it takes\nis to first train on a random labeling on the data, before switching to\nproperly training with the correct labels. In contrast, we find that in the\npresence of explicit regularization, pretraining with random labels has no\ndetrimental effect on SGD. We believe that our results give evidence that\nexplicit regularization plays a far more important role in the success of\noverparameterized neural networks than what has been understood until now.\nSpecifically, by penalizing complicated models independently of their fit to\nthe data, regularization affects training dynamics also far away from optima,\nmaking simple models that fit the data well discoverable by local methods, such\nas SGD.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 14:24:56 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 02:58:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Shengchao", ""], ["Papailiopoulos", "Dimitris", ""], ["Achlioptas", "Dimitris", ""]]}, {"id": "1906.02629", "submitter": "Rafael M\\\"uller", "authors": "Rafael M\\\"uller, Simon Kornblith, Geoffrey Hinton", "title": "When Does Label Smoothing Help?", "comments": "Accepted at NeurIPS 2019, corrected mutual information formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization and learning speed of a multi-class neural network can\noften be significantly improved by using soft targets that are a weighted\naverage of the hard targets and the uniform distribution over labels. Smoothing\nthe labels in this way prevents the network from becoming over-confident and\nlabel smoothing has been used in many state-of-the-art models, including image\nclassification, language translation and speech recognition. Despite its\nwidespread use, label smoothing is still poorly understood. Here we show\nempirically that in addition to improving generalization, label smoothing\nimproves model calibration which can significantly improve beam-search.\nHowever, we also observe that if a teacher network is trained with label\nsmoothing, knowledge distillation into a student network is much less\neffective. To explain these observations, we visualize how label smoothing\nchanges the representations learned by the penultimate layer of the network. We\nshow that label smoothing encourages the representations of training examples\nfrom the same class to group in tight clusters. This results in loss of\ninformation in the logits about resemblances between instances of different\nclasses, which is necessary for distillation, but does not hurt generalization\nor calibration of the model's predictions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:03:11 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:01:20 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 18:18:17 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["M\u00fcller", "Rafael", ""], ["Kornblith", "Simon", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1906.02635", "submitter": "Susan Athey", "authors": "Rob Donnelly, Francisco R. Ruiz, David Blei, and Susan Athey", "title": "Counterfactual Inference for Consumer Choice Across Many Product\n  Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for estimating consumer preferences among\ndiscrete choices, where the consumer chooses at most one product in a category,\nbut selects from multiple categories in parallel. The consumer's utility is\nadditive in the different categories. Her preferences about product attributes\nas well as her price sensitivity vary across products and are in general\ncorrelated across products. We build on techniques from the machine learning\nliterature on probabilistic models of matrix factorization, extending the\nmethods to account for time-varying product attributes and products going out\nof stock. We evaluate the performance of the model using held-out data from\nweeks with price changes or out of stock products. We show that our model\nimproves over traditional modeling approaches that consider each category in\nisolation. One source of the improvement is the ability of the model to\naccurately estimate heterogeneity in preferences (by pooling information across\ncategories); another source of improvement is its ability to estimate the\npreferences of consumers who have rarely or never made a purchase in a given\ncategory in the training data. Using held-out data, we show that our model can\naccurately distinguish which consumers are most price sensitive to a given\nproduct. We consider counterfactuals such as personally targeted price\ndiscounts, showing that using a richer model such as the one we propose\nsubstantially increases the benefits of personalization in discounts.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:11:01 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Donnelly", "Rob", ""], ["Ruiz", "Francisco R.", ""], ["Blei", "David", ""], ["Athey", "Susan", ""]]}, {"id": "1906.02640", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Sepideh Mahabadi", "title": "Near Neighbor: Who is the Fairest of Them All?", "comments": "To appear in NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\newcommand{\\ball}{\\mathbb{B}}\\newcommand{\\dsQ}{{\\mathcal{Q}}}\\newcommand{\\dsS}{{\\mathcal{S}}}$In\nthis work we study a fair variant of the near neighbor problem. Namely, given a\nset of $n$ points $P$ and a parameter $r$, the goal is to preprocess the\npoints, such that given a query point $q$, any point in the $r$-neighborhood of\nthe query, i.e., $\\ball(q,r)$, have the same probability of being reported as\nthe near neighbor.\n  We show that LSH based algorithms can be made fair, without a significant\nloss in efficiency. Specifically, we show an algorithm that reports a point in\nthe $r$-neighborhood of a query $q$ with almost uniform probability. The query\ntime is proportional to $O\\bigl( \\mathrm{dns}(q.r) \\dsQ(n,c) \\bigr)$, and its\nspace is $O(\\dsS(n,c))$, where $\\dsQ(n,c)$ and $\\dsS(n,c)$ are the query time\nand space of an LSH algorithm for $c$-approximate near neighbor, and\n$\\mathrm{dns}(q,r)$ is a function of the local density around $q$.\n  Our approach works more generally for sampling uniformly from a\nsub-collection of sets of a given collection and can be used in a few other\napplications. Finally, we run experiments to show performance of our approach\non real data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:18:01 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 22:53:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Mahabadi", "Sepideh", ""]]}, {"id": "1906.02641", "submitter": "Matthew Rahtz", "authors": "Matthew Rahtz, James Fang, Anca D. Dragan and Dylan Hadfield-Menell", "title": "An Extensible Interactive Interface for Agent Design", "comments": "Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In artificial intelligence, we often specify tasks through a reward function.\nWhile this works well in some settings, many tasks are hard to specify this\nway. In deep reinforcement learning, for example, directly specifying a reward\nas a function of a high-dimensional observation is challenging. Instead, we\npresent an interface for specifying tasks interactively using demonstrations.\nOur approach defines a set of increasingly complex policies. The interface\nallows the user to switch between these policies at fixed intervals to generate\ndemonstrations of novel, more complex, tasks. We train new policies based on\nthese demonstrations and repeat the process. We present a case study of our\napproach in the Lunar Lander domain, and show that this simple approach can\nquickly learn a successful landing policy and outperforms an existing\ncomparison-based deep RL method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:18:40 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 11:06:46 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 11:58:45 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Rahtz", "Matthew", ""], ["Fang", "James", ""], ["Dragan", "Anca D.", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "1906.02652", "submitter": "Nika Haghtalab", "authors": "Nika Haghtalab, Cameron Musco, Bo Waggoner", "title": "Toward a Characterization of Loss Functions for Distribution Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study loss functions for learning and evaluating probability\ndistributions over large discrete domains. Unlike classification or regression\nwhere a wide variety of loss functions are used, in the distribution learning\nand density estimation literature, very few losses outside the dominant $log\\\nloss$ are applied. We aim to understand this fact, taking an axiomatic approach\nto the design of loss functions for learning distributions. We start by\nproposing a set of desirable criteria that any good loss function should\nsatisfy. Intuitively, these criteria require that the loss function faithfully\nevaluates a candidate distribution, both in expectation and when estimated on a\nfew samples. Interestingly, we observe that \\emph{no loss function} possesses\nall of these criteria. However, one can circumvent this issue by introducing a\nnatural restriction on the set of candidate distributions. Specifically, we\nrequire that candidates are $calibrated$ with respect to the target\ndistribution, i.e., they may contain less information than the target but\notherwise do not significantly distort the truth. We show that, after\nrestricting to this set of distributions, the log loss, along with a large\nvariety of other losses satisfy the desired criteria. These results pave the\nway for future investigations of distribution learning that look beyond the log\nloss, choosing a loss function based on application or domain need.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:36:08 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 03:39:57 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Haghtalab", "Nika", ""], ["Musco", "Cameron", ""], ["Waggoner", "Bo", ""]]}, {"id": "1906.02664", "submitter": "Gal Levy-Fix", "authors": "Gal Levy-Fix, Gilad J. Kuperman, No\\'emie Elhadad", "title": "Machine Learning and Visualization in Clinical Decision Support: Current\n  State and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, an area of machine learning, is set to revolutionize patient\ncare. But it is not yet part of standard of care, especially when it comes to\nindividual patient care. In fact, it is unclear to what extent data-driven\ntechniques are being used to support clinical decision making (CDS).\nHeretofore, there has not been a review of ways in which research in machine\nlearning and other types of data-driven techniques can contribute effectively\nto clinical care and the types of support they can bring to clinicians. In this\npaper, we consider ways in which two data driven domains - machine learning and\ndata visualizations - can contribute to the next generation of clinical\ndecision support systems. We review the literature regarding the ways heuristic\nknowledge, machine learning, and visualization are - and can be - applied to\nthree types of CDS. There has been substantial research into the use of\npredictive modeling for alerts, however current CDS systems are not utilizing\nthese methods. Approaches that leverage interactive visualizations and\nmachine-learning inferences to organize and review patient data are gaining\npopularity but are still at the prototype stage and are not yet in use. CDS\nsystems that could benefit from prescriptive machine learning (e.g., treatment\nrecommendations for specific patients) have not yet been developed. We discuss\npotential reasons for the lack of deployment of data-driven methods in CDS and\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:03:46 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Levy-Fix", "Gal", ""], ["Kuperman", "Gilad J.", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "1906.02667", "submitter": "Alexey Zaytsev", "authors": "Ekaterina Gurina, Nikita Klyuchnikov, Alexey Zaytsev, Evgenya\n  Romanenkova, Ksenia Antipova, Igor Simon, Victor Makarov, Dmitry Koroteev", "title": "Application of Machine Learning to accidents detection at directional\n  drilling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven algorithm and mathematical model for anomaly\nalarming at directional drilling. The algorithm is based on machine learning.\nIt compares the real-time drilling telemetry with one corresponding to past\naccidents and analyses the level of similarity. The model performs a\ntime-series comparison using aggregated statistics and Gradient Boosting\nclassification. It is trained on historical data containing the drilling\ntelemetry of $80$ wells drilled within $19$ oilfields. The model can detect an\nanomaly and identify its type by comparing the real-time measurements while\ndrilling with the ones from the database of past accidents. Validation tests\nshow that our algorithm identifies half of the anomalies with about $0.53$\nfalse alarms per day on average. The model performance ensures sufficient time\nand cost savings as it enables partial prevention of the failures and accidents\nat the well construction.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:10:20 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 10:41:42 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Gurina", "Ekaterina", ""], ["Klyuchnikov", "Nikita", ""], ["Zaytsev", "Alexey", ""], ["Romanenkova", "Evgenya", ""], ["Antipova", "Ksenia", ""], ["Simon", "Igor", ""], ["Makarov", "Victor", ""], ["Koroteev", "Dmitry", ""]]}, {"id": "1906.02679", "submitter": "Yan Shi", "authors": "Yan Shi, Dezhi Feng, and Subir Biswas", "title": "A Natural Language-Inspired Multi-label Video Streaming Traffic\n  Classification Method Based on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1007/s11760-020-01844-8", "report-no": null, "categories": "eess.SP cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep-learning based traffic classification method for\nidentifying multiple streaming video sources at the same time within an\nencrypted tunnel. The work defines a novel feature inspired by Natural Language\nProcessing (NLP) that allows existing NLP techniques to help the traffic\nclassification. The feature extraction method is described, and a large dataset\ncontaining video streaming and web traffic is created to verify its\neffectiveness. Results are obtained by applying several NLP methods to show\nthat the proposed method performs well on both binary and multilabel traffic\nclassification problems. We also show the ability to achieve zero-shot learning\nwith the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 00:21:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Shi", "Yan", ""], ["Feng", "Dezhi", ""], ["Biswas", "Subir", ""]]}, {"id": "1906.02685", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Andreas Krause", "title": "Stochastic Bandits with Context Distributions", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a stochastic contextual bandit model where at each time step the\nenvironment chooses a distribution over a context set and samples the context\nfrom this distribution. The learner observes only the context distribution\nwhile the exact context realization remains hidden. This allows for a broad\nrange of applications where the context is stochastic or when the learner needs\nto predict the context. We leverage the UCB algorithm to this setting and show\nthat it achieves an order-optimal high-probability bound on the cumulative\nregret for linear and kernelized reward functions. Our results strictly\ngeneralize previous work in the sense that both our model and the algorithm\nreduce to the standard setting when the environment chooses only Dirac delta\ndistributions and therefore provides the exact context to the learner. We\nfurther analyze a variant where the learner observes the realized context after\nchoosing the action. Finally, we demonstrate the proposed method on synthetic\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:31:18 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 10:58:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kirschner", "Johannes", ""], ["Krause", "Andreas", ""]]}, {"id": "1906.02687", "submitter": "David Sabbagh", "authors": "David Sabbagh, Pierre Ablin, Gael Varoquaux, Alexandre Gramfort, Denis\n  A. Engemann", "title": "Manifold-regression to predict from MEG/EEG brain signals without source\n  modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography and electroencephalography (M/EEG) can reveal neuronal\ndynamics non-invasively in real-time and are therefore appreciated methods in\nmedicine and neuroscience. Recent advances in modeling brain-behavior\nrelationships have highlighted the effectiveness of Riemannian geometry for\nsummarizing the spatially correlated time-series from M/EEG in terms of their\ncovariance. However, after artefact-suppression, M/EEG data is often rank\ndeficient which limits the application of Riemannian concepts. In this article,\nwe focus on the task of regression with rank-reduced covariance matrices. We\nstudy two Riemannian approaches that vectorize the M/EEG covariance\nbetween-sensors through projection into a tangent space. The Wasserstein\ndistance readily applies to rank-reduced data but lacks affine-invariance. This\ncan be overcome by finding a common subspace in which the covariance matrices\nare full rank, enabling the affine-invariant geometric distance. We\ninvestigated the implications of these two approaches in synthetic generative\nmodels, which allowed us to control estimation bias of a linear model for\nprediction. We show that Wasserstein and geometric distances allow perfect\nout-of-sample prediction on the generative models. We then evaluated the\nmethods on real data with regard to their effectiveness in predicting age from\nM/EEG covariance matrices. The findings suggest that the data-driven Riemannian\nmethods outperform different sensor-space estimators and that they get close to\nthe performance of biophysics-driven source-localization model that requires\nMRI acquisitions and tedious data processing. Our study suggests that the\nproposed Riemannian methods can serve as fundamental building-blocks for\nautomated large-scale analysis of M/EEG.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:31:36 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 20:13:48 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 16:45:39 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Sabbagh", "David", ""], ["Ablin", "Pierre", ""], ["Varoquaux", "Gael", ""], ["Gramfort", "Alexandre", ""], ["Engemann", "Denis A.", ""]]}, {"id": "1906.02688", "submitter": "Vihari Piratla Mr.", "authors": "Vihari Piratla, Sunita Sarawagi, Soumen Chakrabarti", "title": "Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in\n  Pretrained Embeddings", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a small corpus $\\mathcal D_T$ pertaining to a limited set of focused\ntopics, our goal is to train embeddings that accurately capture the sense of\nwords in the topic in spite of the limited size of $\\mathcal D_T$. These\nembeddings may be used in various tasks involving $\\mathcal D_T$. A popular\nstrategy in limited data settings is to adapt pre-trained embeddings $\\mathcal\nE$ trained on a large corpus. To correct for sense drift, fine-tuning,\nregularization, projection, and pivoting have been proposed recently. Among\nthese, regularization informed by a word's corpus frequency performed well, but\nwe improve upon it using a new regularizer based on the stability of its\ncooccurrence with other words. However, a thorough comparison across ten\ntopics, spanning three tasks, with standardized settings of hyper-parameters,\nreveals that even the best embedding adaptation strategies provide small gains\nbeyond well-tuned baselines, which many earlier comparisons ignored. In a bold\ndeparture from adapting pretrained embeddings, we propose using $\\mathcal D_T$\nto probe, attend to, and borrow fragments from any large, topic-rich source\ncorpus (such as Wikipedia), which need not be the corpus used to pretrain\nembeddings. This step is made scalable and practical by suitable indexing. We\nreach the surprising conclusion that even limited corpus augmentation is more\nuseful than adapting embeddings, which suggests that non-dominant sense\ninformation may be irrevocably obliterated from pretrained embeddings and\ncannot be salvaged by adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:15:06 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 10:59:36 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Piratla", "Vihari", ""], ["Sarawagi", "Sunita", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1906.02691", "submitter": "Diederik P. Kingma Dr.", "authors": "Diederik P. Kingma and Max Welling", "title": "An Introduction to Variational Autoencoders", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning: Vol. 12 (2019): No. 4,\n  pp 307-392", "doi": "10.1561/2200000056", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders provide a principled framework for learning deep\nlatent-variable models and corresponding inference models. In this work, we\nprovide an introduction to variational autoencoders and some important\nextensions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:35:38 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 05:44:14 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 17:33:13 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Kingma", "Diederik P.", ""], ["Welling", "Max", ""]]}, {"id": "1906.02694", "submitter": "Lukas Ruff", "authors": "Lukas Ruff, Robert A. Vandermeulen, Nico G\\\"ornitz, Alexander Binder,\n  Emmanuel M\\\"uller, Klaus-Robert M\\\"uller and Marius Kloft", "title": "Deep Semi-Supervised Anomaly Detection", "comments": "23 pages, Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep approaches to anomaly detection have recently shown promising results\nover shallow methods on large and complex datasets. Typically anomaly detection\nis treated as an unsupervised learning problem. In practice however, one may\nhave---in addition to a large set of unlabeled samples---access to a small pool\nof labeled samples, e.g. a subset verified by some domain expert as being\nnormal or anomalous. Semi-supervised approaches to anomaly detection aim to\nutilize such labeled samples, but most proposed methods are limited to merely\nincluding labeled normal samples. Only a few methods take advantage of labeled\nanomalies, with existing deep approaches being domain-specific. In this work we\npresent Deep SAD, an end-to-end deep methodology for general semi-supervised\nanomaly detection. We further introduce an information-theoretic framework for\ndeep anomaly detection based on the idea that the entropy of the latent\ndistribution for normal data should be lower than the entropy of the anomalous\ndistribution, which can serve as a theoretical interpretation for our method.\nIn extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with\nother anomaly detection benchmark datasets, we demonstrate that our method is\non par or outperforms shallow, hybrid, and deep competitors, yielding\nappreciable performance improvements even when provided with only little\nlabeled data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:46:56 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 10:10:15 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ruff", "Lukas", ""], ["Vandermeulen", "Robert A.", ""], ["G\u00f6rnitz", "Nico", ""], ["Binder", "Alexander", ""], ["M\u00fcller", "Emmanuel", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Kloft", "Marius", ""]]}, {"id": "1906.02707", "submitter": "Yifeng Fan", "authors": "Yifeng Fan, Tingran Gao, Zhizhen Zhao", "title": "Unsupervised Co-Learning on $\\mathcal{G}$-Manifolds Across Irreducible\n  Representations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel co-learning paradigm for manifolds naturally equipped\nwith a group action, motivated by recent developments on learning a manifold\nfrom attached fibre bundle structures. We utilize a representation theoretic\nmechanism that canonically associates multiple independent vector bundles over\na common base manifold, which provides multiple views for the geometry of the\nunderlying manifold. The consistency across these fibre bundles provide a\ncommon base for performing unsupervised manifold co-learning through the\nredundancy created artificially across irreducible representations of the\ntransformation group. We demonstrate the efficacy of the proposed algorithmic\nparadigm through drastically improved robust nearest neighbor search and\ncommunity detection on rotation-invariant cryo-electron microscopy image\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:17:02 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 05:34:33 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 03:20:34 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Fan", "Yifeng", ""], ["Gao", "Tingran", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1906.02715", "submitter": "Ann Yuan", "authors": "Andy Coenen, Emily Reif, Ann Yuan, Been Kim, Adam Pearce, Fernanda\n  Vi\\'egas, Martin Wattenberg", "title": "Visualizing and Measuring the Geometry of BERT", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer architectures show significant promise for natural language\nprocessing. Given that a single pretrained model can be fine-tuned to perform\nwell on many different tasks, these networks appear to extract generally useful\nlinguistic features. A natural question is how such networks represent this\ninformation internally. This paper describes qualitative and quantitative\ninvestigations of one particularly effective model, BERT. At a high level,\nlinguistic features seem to be represented in separate semantic and syntactic\nsubspaces. We find evidence of a fine-grained geometric representation of word\nsenses. We also present empirical descriptions of syntactic representations in\nboth attention matrices and individual word embeddings, as well as a\nmathematical argument to explain the geometry of these representations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:33:22 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:53:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Coenen", "Andy", ""], ["Reif", "Emily", ""], ["Yuan", "Ann", ""], ["Kim", "Been", ""], ["Pearce", "Adam", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""]]}, {"id": "1906.02717", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar", "title": "Adaptive Gradient-Based Meta-Learning Methods", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a theoretical framework for designing and understanding practical\nmeta-learning methods that integrates sophisticated formalizations of\ntask-similarity with the extensive literature on online convex optimization and\nsequential prediction algorithms. Our approach enables the task-similarity to\nbe learned adaptively, provides sharper transfer-risk bounds in the setting of\nstatistical learning-to-learn, and leads to straightforward derivations of\naverage-case regret bounds for efficient algorithms in settings where the\ntask-environment changes dynamically or the tasks share a certain geometric\nstructure. We use our theory to modify several popular meta-learning algorithms\nand improve their meta-test-time performance on standard problems in few-shot\nlearning and federated learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:36:34 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 14:38:19 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 03:50:47 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Khodak", "Mikhail", ""], ["Balcan", "Maria-Florina", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1906.02719", "submitter": "Bogdan Mazoure", "authors": "Cody Mazza-Anthony, Bogdan Mazoure, Mark Coates", "title": "Learning Gaussian Graphical Models with Ordered Weighted L1\n  Regularization", "comments": "Published in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of identifying densely connected subsets of multivariate\nGaussian random variables within a graphical model framework. We propose two\nnovel estimators based on the Ordered Weighted $\\ell_1$ (OWL) norm: 1) The\nGraphical OWL (GOWL) is a penalized likelihood method that applies the OWL norm\nto the lower triangle components of the precision matrix. 2) The\ncolumn-by-column Graphical OWL (ccGOWL) estimates the precision matrix by\nperforming OWL regularized linear regressions. Both methods can simultaneously\nidentify highly correlated groups of variables and control the sparsity in the\nresulting precision matrix. We formulate GOWL such that it solves a composite\noptimization problem and establish that the estimator has a unique global\nsolution. In addition, we prove sufficient grouping conditions for each column\nof the ccGOWL precision matrix estimate. We propose proximal descent algorithms\nto find the optimum for both estimators. For synthetic data where group\nstructure is present, the ccGOWL estimator requires significantly reduced\ncomputation and achieves similar or greater accuracy than state-of-the-art\nestimators. Timing comparisons are presented and demonstrates the superior\ncomputational efficiency of the ccGOWL. We illustrate the grouping performance\nof the ccGOWL method on a cancer gene expression data set and an equities data\nset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:39:48 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 14:56:57 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mazza-Anthony", "Cody", ""], ["Mazoure", "Bogdan", ""], ["Coates", "Mark", ""]]}, {"id": "1906.02732", "submitter": "Bhavya Kailkhura", "authors": "Bhavya Kailkhura, Jayaraman J. Thiagarajan, Qunwei Li, Peer-Timo\n  Bremer", "title": "A Look at the Effect of Sample Design on Generalization through the Lens\n  of Spectral Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a general framework to study the effect of sampling\nproperties of training data on the generalization error of the learned machine\nlearning (ML) models. Specifically, we propose a new spectral analysis of the\ngeneralization error, expressed in terms of the power spectra of the sampling\npattern and the function involved. The framework is build in the Euclidean\nspace using Fourier analysis and establishes a connection between some high\ndimensional geometric objects and optimal spectral form of different\nstate-of-the-art sampling patterns. Subsequently, we estimate the expected\nerror bounds and convergence rate of different state-of-the-art sampling\npatterns, as the number of samples and dimensions increase. We make several\nobservations about generalization error which are valid irrespective of the\napproximation scheme (or learning architecture) and training (or optimization)\nalgorithms. Our result also sheds light on ways to formulate design principles\nfor constructing optimal sampling methods for particular problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:51:51 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 05:31:19 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Li", "Qunwei", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1906.02735", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Jens Behrmann, David Duvenaud, J\\\"orn-Henrik\n  Jacobsen", "title": "Residual Flows for Invertible Generative Modeling", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models parameterize probability distributions through\nan invertible transformation and can be trained by maximum likelihood.\nInvertible residual networks provide a flexible family of transformations where\nonly Lipschitz conditions rather than strict architectural constraints are\nneeded for enforcing invertibility. However, prior work trained invertible\nresidual networks for density estimation by relying on biased log-density\nestimates whose bias increased with the network's expressiveness. We give a\ntractable unbiased estimate of the log density using a \"Russian roulette\"\nestimator, and reduce the memory required during training by using an\nalternative infinite series for the gradient. Furthermore, we improve\ninvertible residual blocks by proposing the use of activation functions that\navoid derivative saturation and generalizing the Lipschitz condition to induced\nmixed norms. The resulting approach, called Residual Flows, achieves\nstate-of-the-art performance on density estimation amongst flow-based models,\nand outperforms networks that use coupling blocks at joint generative and\ndiscriminative modeling.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:55:01 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:46:49 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 16:30:55 GMT"}, {"version": "v4", "created": "Sat, 7 Dec 2019 12:31:54 GMT"}, {"version": "v5", "created": "Sun, 23 Feb 2020 17:53:20 GMT"}, {"version": "v6", "created": "Fri, 24 Jul 2020 02:15:24 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Behrmann", "Jens", ""], ["Duvenaud", "David", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "1906.02736", "submitter": "Jacob Buckman", "authors": "Carles Gelada, Saurabh Kumar, Jacob Buckman, Ofir Nachum, Marc G.\n  Bellemare", "title": "DeepMDP: Learning Continuous Latent Space Models for Representation\n  Learning", "comments": "13 pages main text, 16 pages appendix. ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) tasks provide the agent with\nhigh-dimensional observations that can be simplified into low-dimensional\ncontinuous states. To formalize this process, we introduce the concept of a\nDeepMDP, a parameterized latent space model that is trained via the\nminimization of two tractable losses: prediction of rewards and prediction of\nthe distribution over next latent states. We show that the optimization of\nthese objectives guarantees (1) the quality of the latent space as a\nrepresentation of the state space and (2) the quality of the DeepMDP as a model\nof the environment. We connect these results to prior work in the bisimulation\nliterature, and explore the use of a variety of metrics. Our theoretical\nfindings are substantiated by the experimental result that a trained DeepMDP\nrecovers the latent structure underlying high-dimensional observations on a\nsynthetic environment. Finally, we show that learning a DeepMDP as an auxiliary\ntask in the Atari 2600 domain leads to large performance improvements over\nmodel-free RL.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:55:17 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Gelada", "Carles", ""], ["Kumar", "Saurabh", ""], ["Buckman", "Jacob", ""], ["Nachum", "Ofir", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1906.02745", "submitter": "Xinghua Yao", "authors": "Xinghua Yao, Qiang Cheng, and Guo-Qiang Zhang", "title": "Automated Classification of Seizures against Nonseizures: A Deep\n  Learning Approach", "comments": "12 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:1903.09326", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current clinical practice, electroencephalograms (EEG) are reviewed and\nanalyzed by well-trained neurologists to provide supports for therapeutic\ndecisions. The way of manual reviewing is labor-intensive and error prone.\nAutomatic and accurate seizure/nonseizure classification methods are needed.\nOne major problem is that the EEG signals for seizure state and nonseizure\nstate exhibit considerable variations. In order to capture essential seizure\nfeatures, this paper integrates an emerging deep learning model, the\nindependently recurrent neural network (IndRNN), with a dense structure and an\nattention mechanism to exploit temporal and spatial discriminating features and\novercome seizure variabilities. The dense structure is to ensure maximum\ninformation flow between layers. The attention mechanism is to capture spatial\nfeatures. Evaluations are performed in cross-validation experiments over the\nnoisy CHB-MIT data set. The obtained average sensitivity, specificity and\nprecision of 88.80%, 88.60% and 88.69% are better than using the current\nstate-of-the-art methods. In addition, we explore how the segment length\naffects the classification performance. Thirteen different segment lengths are\nassessed, showing that the classification performance varies over the segment\nlengths, and the maximal fluctuating margin is more than 4%. Thus, the segment\nlength is an important factor influencing the classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 04:55:40 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Yao", "Xinghua", ""], ["Cheng", "Qiang", ""], ["Zhang", "Guo-Qiang", ""]]}, {"id": "1906.02746", "submitter": "Mihai Cucuringu", "authors": "Alexandre d'Aspremont, Mihai Cucuringu, Hemant Tyagi", "title": "Ranking and synchronization from pairwise measurements via SVD", "comments": "49 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a measurement graph $G= (V,E)$ and an unknown signal $r \\in\n\\mathbb{R}^n$, we investigate algorithms for recovering $r$ from pairwise\nmeasurements of the form $r_i - r_j$; $\\{i,j\\} \\in E$. This problem arises in a\nvariety of applications, such as ranking teams in sports data and time\nsynchronization of distributed networks. Framed in the context of ranking, the\ntask is to recover the ranking of $n$ teams (induced by $r$) given a small\nsubset of noisy pairwise rank offsets. We propose a simple SVD-based\nalgorithmic pipeline for both the problem of time synchronization and ranking.\nWe provide a detailed theoretical analysis in terms of robustness against both\nsampling sparsity and noise perturbations with outliers, using results from\nmatrix perturbation and random matrix theory. Our theoretical findings are\ncomplemented by a detailed set of numerical experiments on both synthetic and\nreal data, showcasing the competitiveness of our proposed algorithms with other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:17:36 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 19:46:59 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 15:22:50 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["d'Aspremont", "Alexandre", ""], ["Cucuringu", "Mihai", ""], ["Tyagi", "Hemant", ""]]}, {"id": "1906.02762", "submitter": "Zhuohan Li", "authors": "Yiping Lu, Zhuohan Li, Di He, Zhiqing Sun, Bin Dong, Tao Qin, Liwei\n  Wang, Tie-Yan Liu", "title": "Understanding and Improving Transformer From a Multi-Particle Dynamic\n  System Point of View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer architecture is widely used in natural language processing.\nDespite its success, the design principle of the Transformer remains elusive.\nIn this paper, we provide a novel perspective towards understanding the\narchitecture: we show that the Transformer can be mathematically interpreted as\na numerical Ordinary Differential Equation (ODE) solver for a\nconvection-diffusion equation in a multi-particle dynamic system. In\nparticular, how words in a sentence are abstracted into contexts by passing\nthrough the layers of the Transformer can be interpreted as approximating\nmultiple particles' movement in the space using the Lie-Trotter splitting\nscheme and the Euler's method. Given this ODE's perspective, the rich\nliterature of numerical analysis can be brought to guide us in designing\neffective structures beyond the Transformer. As an example, we propose to\nreplace the Lie-Trotter splitting scheme by the Strang-Marchuk splitting\nscheme, a scheme that is more commonly used and with much lower local\ntruncation errors. The Strang-Marchuk splitting scheme suggests that the\nself-attention and position-wise feed-forward network (FFN) sub-layers should\nnot be treated equally. Instead, in each layer, two position-wise FFN\nsub-layers should be used, and the self-attention sub-layer is placed in\nbetween. This leads to a brand new architecture. Such an FFN-attention-FFN\nlayer is \"Macaron-like\", and thus we call the network with this new\narchitecture the Macaron Net. Through extensive experiments, we show that the\nMacaron Net is superior to the Transformer on both supervised and unsupervised\nlearning tasks. The reproducible codes and pretrained models can be found at\nhttps://github.com/zhuohan123/macaron-net\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:10:08 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lu", "Yiping", ""], ["Li", "Zhuohan", ""], ["He", "Di", ""], ["Sun", "Zhiqing", ""], ["Dong", "Bin", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1906.02768", "submitter": "Ari Morcos", "authors": "Haonan Yu, Sergey Edunov, Yuandong Tian, and Ari S. Morcos", "title": "Playing the lottery with rewards and multiple languages: lottery tickets\n  in RL and NLP", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lottery ticket hypothesis proposes that over-parameterization of deep\nneural networks (DNNs) aids training by increasing the probability of a \"lucky\"\nsub-network initialization being present rather than by helping the\noptimization process (Frankle & Carbin, 2019). Intriguingly, this phenomenon\nsuggests that initialization strategies for DNNs can be improved substantially,\nbut the lottery ticket hypothesis has only previously been tested in the\ncontext of supervised learning for natural image tasks. Here, we evaluate\nwhether \"winning ticket\" initializations exist in two different domains:\nnatural language processing (NLP) and reinforcement learning (RL).For NLP, we\nexamined both recurrent LSTM models and large-scale Transformer models (Vaswani\net al., 2017). For RL, we analyzed a number of discrete-action space tasks,\nincluding both classic control and pixel control. Consistent with workin\nsupervised image classification, we confirm that winning ticket initializations\ngenerally outperform parameter-matched random initializations, even at extreme\npruning rates for both NLP and RL. Notably, we are able to find winning ticket\ninitializations for Transformers which enable models one-third the size to\nachieve nearly equivalent performance. Together, these results suggest that the\nlottery ticket hypothesis is not restricted to supervised learning of natural\nimages, but rather represents a broader phenomenon in DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:38:38 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:33:34 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 21:50:07 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Yu", "Haonan", ""], ["Edunov", "Sergey", ""], ["Tian", "Yuandong", ""], ["Morcos", "Ari S.", ""]]}, {"id": "1906.02771", "submitter": "Ariella Smofsky", "authors": "Patrick Nadeem Ward and Ariella Smofsky and Avishek Joey Bose", "title": "Improving Exploration in Soft-Actor-Critic with Normalizing Flows\n  Policies", "comments": "INNF workshop, International Conference on Machine Learning 2019,\n  Long Beach CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) algorithms for continuous action spaces are\nknown to be brittle toward hyperparameters as well as \\cut{being}sample\ninefficient. Soft Actor Critic (SAC) proposes an off-policy deep actor critic\nalgorithm within the maximum entropy RL framework which offers greater\nstability and empirical gains. The choice of policy distribution, a factored\nGaussian, is motivated by \\cut{chosen due}its easy re-parametrization rather\nthan its modeling power. We introduce Normalizing Flow policies within the SAC\nframework that learn more expressive classes of policies than simple factored\nGaussians. \\cut{We also present a series of stabilization tricks that enable\neffective training of these policies in the RL setting.}We show empirically on\ncontinuous grid world tasks that our approach increases stability and is better\nsuited to difficult exploration in sparse reward settings.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:43:19 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ward", "Patrick Nadeem", ""], ["Smofsky", "Ariella", ""], ["Bose", "Avishek Joey", ""]]}, {"id": "1906.02773", "submitter": "Ari Morcos", "authors": "Ari S. Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian", "title": "One ticket to win them all: generalizing lottery ticket initializations\n  across datasets and optimizers", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of lottery ticket initializations (Frankle and Carbin, 2019)\nsuggests that small, sparsified networks can be trained so long as the network\nis initialized appropriately. Unfortunately, finding these \"winning ticket\"\ninitializations is computationally expensive. One potential solution is to\nreuse the same winning tickets across a variety of datasets and optimizers.\nHowever, the generality of winning ticket initializations remains unclear.\nHere, we attempt to answer this question by generating winning tickets for one\ntraining configuration (optimizer and dataset) and evaluating their performance\non another configuration. Perhaps surprisingly, we found that, within the\nnatural images domain, winning ticket initializations generalized across a\nvariety of datasets, including Fashion MNIST, SVHN, CIFAR-10/100, ImageNet, and\nPlaces365, often achieving performance close to that of winning tickets\ngenerated on the same dataset. Moreover, winning tickets generated using larger\ndatasets consistently transferred better than those generated using smaller\ndatasets. We also found that winning ticket initializations generalize across\noptimizers with high performance. These results suggest that winning ticket\ninitializations generated by sufficiently large datasets contain inductive\nbiases generic to neural networks more broadly which improve training across\nmany settings and provide hope for the development of better initialization\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:46:39 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 18:10:27 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Morcos", "Ari S.", ""], ["Yu", "Haonan", ""], ["Paganini", "Michela", ""], ["Tian", "Yuandong", ""]]}, {"id": "1906.02777", "submitter": "Ashok Makkuva", "authors": "Ashok Vardhan Makkuva, Sewoong Oh, Sreeram Kannan, Pramod Viswanath", "title": "Learning in Gated Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gating is a key feature in modern neural networks including LSTMs, GRUs and\nsparsely-gated deep neural networks. The backbone of such gated networks is a\nmixture-of-experts layer, where several experts make regression decisions and\ngating controls how to weigh the decisions in an input-dependent manner.\nDespite having such a prominent role in both modern and classical machine\nlearning, very little is understood about parameter recovery of\nmixture-of-experts since gradient descent and EM algorithms are known to be\nstuck in local optima in such models.\n  In this paper, we perform a careful analysis of the optimization landscape\nand show that with appropriately designed loss functions, gradient descent can\nindeed learn the parameters accurately. A key idea underpinning our results is\nthe design of two {\\em distinct} loss functions, one for recovering the expert\nparameters and another for recovering the gating parameters. We demonstrate the\nfirst sample complexity results for parameter recovery in this model for any\nalgorithm and demonstrate significant performance gains over standard loss\nfunctions in numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 19:04:11 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:55:28 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Makkuva", "Ashok Vardhan", ""], ["Oh", "Sewoong", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1906.02795", "submitter": "Yan Zhang", "authors": "Yan Zhang and Jonathon Hare and Adam Pr\\\"ugel-Bennett", "title": "FSPool: Learning Set Representations with Featurewise Sort Pooling", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional set prediction models can struggle with simple datasets due to an\nissue we call the responsibility problem. We introduce a pooling method for\nsets of feature vectors based on sorting features across elements of the set.\nThis can be used to construct a permutation-equivariant auto-encoder that\navoids this responsibility problem. On a toy dataset of polygons and a set\nversion of MNIST, we show that such an auto-encoder produces considerably\nbetter reconstructions and representations. Replacing the pooling function in\nexisting set encoders with FSPool improves accuracy and convergence speed on a\nvariety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 20:16:40 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 22:43:55 GMT"}, {"version": "v3", "created": "Thu, 26 Dec 2019 12:02:15 GMT"}, {"version": "v4", "created": "Fri, 1 May 2020 09:40:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Yan", ""], ["Hare", "Jonathon", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1906.02815", "submitter": "Pin Wang", "authors": "Long Xin, Pin Wang, Ching-Yao Chan, Jianyu Chen, Shengbo Eben Li, Bo\n  Cheng", "title": "Intention-aware Long Horizon Trajectory Prediction of Surrounding\n  Vehicles using Dual LSTM Networks", "comments": "Published at the 21st International Conference on Intelligent\n  Transportation Systems (ITSC), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomous vehicles (AVs) need to interact with other road users, it is of\nimportance to comprehensively understand the dynamic traffic environment,\nespecially the future possible trajectories of surrounding vehicles. This paper\npresents an algorithm for long-horizon trajectory prediction of surrounding\nvehicles using a dual long short term memory (LSTM) network, which is capable\nof effectively improving prediction accuracy in strongly interactive driving\nenvironments. In contrast to traditional approaches which require trajectory\nmatching and manual feature selection, this method can automatically learn\nhigh-level spatial-temporal features of driver behaviors from naturalistic\ndriving data through sequence learning. By employing two blocks of LSTMs, the\nproposed method feeds the sequential trajectory to the first LSTM for driver\nintention recognition as an intermediate indicator, which is immediately\nfollowed by a second LSTM for future trajectory prediction. Test results from\nreal-world highway driving data show that the proposed method can, in\ncomparison to state-of-art methods, output more accurate and reasonable\nestimate of different future trajectories over 5s time horizon with root mean\nsquare error (RMSE) for longitudinal and lateral prediction less than 5.77m and\n0.49m, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:05:59 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Xin", "Long", ""], ["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""], ["Chen", "Jianyu", ""], ["Li", "Shengbo Eben", ""], ["Cheng", "Bo", ""]]}, {"id": "1906.02816", "submitter": "Juan Carlos Perdomo", "authors": "Juan C. Perdomo, Yaron Singer", "title": "Robust Attacks against Multiple Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of designing optimal adversarial noise algorithms\nfor settings where a learner has access to multiple classifiers. We demonstrate\nhow this problem can be framed as finding strategies at equilibrium in a\ntwo-player, zero-sum game between a learner and an adversary. In doing so, we\nillustrate the need for randomization in adversarial attacks. In order to\ncompute Nash equilibrium, our main technical focus is on the design of best\nresponse oracles that can then be implemented within a Multiplicative Weights\nUpdate framework to boost deterministic perturbations against a set of models\ninto optimal mixed strategies. We demonstrate the practical effectiveness of\nour approach on a series of image classification tasks using both linear\nclassifiers and deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:06:28 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Perdomo", "Juan C.", ""], ["Singer", "Yaron", ""]]}, {"id": "1906.02825", "submitter": "Tolga Bolukbasi", "authors": "Andrei Kapishnikov, Tolga Bolukbasi, Fernanda Vi\\'egas, Michael Terry", "title": "XRAI: Better Attributions Through Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods can aid understanding of deep neural networks. Recent years\nhave witnessed many improvements to saliency methods, as well as new ways for\nevaluating them. In this paper, we 1) present a novel region-based attribution\nmethod, XRAI, that builds upon integrated gradients (Sundararajan et al. 2017),\n2) introduce evaluation methods for empirically assessing the quality of\nimage-based saliency maps (Performance Information Curves (PICs)), and 3)\ncontribute an axiom-based sanity check for attribution methods. Through\nempirical experiments and example results, we show that XRAI produces better\nresults than other saliency methods for common models and the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:21:39 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 21:09:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Kapishnikov", "Andrei", ""], ["Bolukbasi", "Tolga", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Terry", "Michael", ""]]}, {"id": "1906.02826", "submitter": "Yu Liu", "authors": "Yu Liu, Li Deng, Jianshu Chen, Chang Wen Chen", "title": "From Caesar Cipher to Unsupervised Learning: A New Method for Classifier\n  Parameter Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important classification problems, such as object classification, speech\nrecognition, and machine translation, have been tackled by the supervised\nlearning paradigm in the past, where training corpora of parallel input-output\npairs are required with high cost. To remove the need for the parallel training\ncorpora has practical significance for real-world applications, and it is one\nof the main goals of unsupervised learning. Recently, encouraging progress in\nunsupervised learning for solving such classification problems has been made\nand the nature of the challenges has been clarified. In this article, we review\nthis progress and disseminate a class of promising new methods to facilitate\nunderstanding the methods for machine learning researchers. In particular, we\nemphasize the key information that enables the success of unsupervised learning\n- the sequential statistics as the distributional prior in the labels.\nExploitation of such sequential statistics makes it possible to estimate\nparameters of classifiers without the need of paired input-output data.\n  In this paper, we first introduce the concept of Caesar Cipher and its\ndecryption, which motivated the construction of the novel loss function for\nunsupervised learning we use throughout the paper. Then we use a simple but\nrepresentative binary classification task as an example to derive and describe\nthe unsupervised learning algorithm in a step-by-step, easy-to-understand\nfashion. We include two cases, one with Bigram language model as the sequential\nstatistics for use in unsupervised parameter estimation, and another with a\nsimpler Unigram language model. For both cases, detailed derivation steps for\nthe learning algorithm are included. Further, a summary table compares\ncomputational steps of the two cases in executing the unsupervised learning\nalgorithm for learning binary classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:33:18 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Liu", "Yu", ""], ["Deng", "Li", ""], ["Chen", "Jianshu", ""], ["Chen", "Chang Wen", ""]]}, {"id": "1906.02840", "submitter": "Andrew Zammit-Mangion", "authors": "Andrew Zammit-Mangion, Tin Lok James Ng, Quan Vu and Maurizio\n  Filippone", "title": "Deep Compositional Spatial Models", "comments": "46 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial processes with nonstationary and anisotropic covariance structure are\noften used when modelling, analysing and predicting complex environmental\nphenomena. Such processes may often be expressed as ones that have stationary\nand isotropic covariance structure on a warped spatial domain. However, the\nwarping function is generally difficult to fit and not constrained to be\ninjective, often resulting in `space-folding.' Here, we propose modelling an\ninjective warping function through a composition of multiple elemental\ninjective functions in a deep-learning framework. We consider two cases; first,\nwhen these functions are known up to some weights that need to be estimated,\nand, second, when the weights in each layer are random. Inspired by recent\nmethodological and technological advances in deep learning and deep Gaussian\nprocesses, we employ approximate Bayesian methods to make inference with these\nmodels using graphics processing units. Through simulation studies in one and\ntwo dimensions we show that the deep compositional spatial models are quick to\nfit, and are able to provide better predictions and uncertainty quantification\nthan other deep stochastic models of similar complexity. We also show their\nremarkable capacity to model nonstationary, anisotropic spatial data using\nradiances from the MODIS instrument aboard the Aqua satellite.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 23:31:18 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 16:05:52 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Zammit-Mangion", "Andrew", ""], ["Ng", "Tin Lok James", ""], ["Vu", "Quan", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1906.02845", "submitter": "Jie Ren", "authors": "Jie Ren, Peter J. Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark\n  A. DePristo, Joshua V. Dillon, Balaji Lakshminarayanan", "title": "Likelihood Ratios for Out-of-Distribution Detection", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminative neural networks offer little or no performance guarantees when\ndeployed on data not generated by the same process as the training\ndistribution. On such out-of-distribution (OOD) inputs, the prediction may not\nonly be erroneous, but confidently so, limiting the safe deployment of\nclassifiers in real-world applications. One such challenging application is\nbacteria identification based on genomic sequences, which holds the promise of\nearly detection of diseases, but requires a model that can output low\nconfidence predictions on OOD genomic sequences from new bacteria that were not\npresent in the training data. We introduce a genomics dataset for OOD detection\nthat allows other researchers to benchmark progress on this important problem.\nWe investigate deep generative model based approaches for OOD detection and\nobserve that the likelihood score is heavily affected by population level\nbackground statistics. We propose a likelihood ratio method for deep generative\nmodels which effectively corrects for these confounding background statistics.\nWe benchmark the OOD detection performance of the proposed method against\nexisting approaches on the genomics dataset and show that our method achieves\nstate-of-the-art performance. We demonstrate the generality of the proposed\nmethod by showing that it significantly improves OOD detection when applied to\ndeep generative models of images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 00:01:42 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 19:59:35 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Ren", "Jie", ""], ["Liu", "Peter J.", ""], ["Fertig", "Emily", ""], ["Snoek", "Jasper", ""], ["Poplin", "Ryan", ""], ["DePristo", "Mark A.", ""], ["Dillon", "Joshua V.", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1906.02846", "submitter": "Yiqiu Shen", "authors": "Yiqiu Shen, Nan Wu, Jason Phang, Jungkyu Park, Gene Kim, Linda Moy,\n  Kyunghyun Cho, Krzysztof J. Geras", "title": "Globally-Aware Multiple Instance Classifier for Breast Cancer Screening", "comments": "Accepted to MLMI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models designed for visual classification tasks on natural\nimages have become prevalent in medical image analysis. However, medical images\ndiffer from typical natural images in many ways, such as significantly higher\nresolutions and smaller regions of interest. Moreover, both the global\nstructure and local details play important roles in medical image analysis\ntasks. To address these unique properties of medical images, we propose a\nneural network that is able to classify breast cancer lesions utilizing\ninformation from both a global saliency map and multiple local patches. The\nproposed model outperforms the ResNet-based baseline and achieves\nradiologist-level performance in the interpretation of screening mammography.\nAlthough our model is trained only with image-level labels, it is able to\ngenerate pixel-level saliency maps that provide localization of possible\nmalignant findings.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 00:43:22 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 03:50:22 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Phang", "Jason", ""], ["Park", "Jungkyu", ""], ["Kim", "Gene", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "1906.02852", "submitter": "Jun Zhang", "authors": "Jun Zhang, Yao-Kun Lei, Xing Che, Zhen Zhang, Yi Isaac Yang, Yi Qin\n  Gao", "title": "Learning Clustered Representation for Complex Free Energy Landscapes", "comments": "6 figures, 1 table in the main text", "journal-ref": "J. Phys. Chem. Lett. 2019,10,5571-5576", "doi": "10.1021/acs.jpclett.9b02012", "report-no": null, "categories": "cond-mat.stat-mech physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we first analyzed the inductive bias underlying the data\nscattered across complex free energy landscapes (FEL), and exploited it to\ntrain deep neural networks which yield reduced and clustered representation for\nthe FEL. Our parametric method, called Information Distilling of Metastability\n(IDM), is end-to-end differentiable thus scalable to ultra-large dataset. IDM\nis also a clustering algorithm and is able to cluster the samples in the\nmeantime of reducing the dimensions. Besides, as an unsupervised learning\nmethod, IDM differs from many existing dimensionality reduction and clustering\nmethods in that it neither requires a cherry-picked distance metric nor the\nground-true number of clusters, and that it can be used to unroll and zoom-in\nthe hierarchical FEL with respect to different timescales. Through multiple\nexperiments, we show that IDM can achieve physically meaningful representations\nwhich partition the FEL into well-defined metastable states hence are amenable\nfor downstream tasks such as mechanism analysis and kinetic modeling.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 00:59:21 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zhang", "Jun", ""], ["Lei", "Yao-Kun", ""], ["Che", "Xing", ""], ["Zhang", "Zhen", ""], ["Yang", "Yi Isaac", ""], ["Gao", "Yi Qin", ""]]}, {"id": "1906.02869", "submitter": "Minsu Cho", "authors": "Minsu Cho, Mohammadreza Soltani, Chinmay Hegde", "title": "One-Shot Neural Architecture Search via Compressive Sensing", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS), or automated design of neural network\nmodels, remains a very challenging meta-learning problem. Several recent works\n(called \"one-shot\" approaches) have focused on dramatically reducing NAS\nrunning time by leveraging proxy models that still provide architectures with\ncompetitive performance. In our work, we propose a new meta-learning algorithm\nthat we call CoNAS, or Compressive sensing-based Neural Architecture Search.\nOur approach merges ideas from one-shot approaches with iterative techniques\nfor learning low-degree sparse Boolean polynomial functions. We validate our\napproach on several standard test datasets, discover novel architectures\nhitherto unreported, and achieve competitive (or better) results in both\nperformance and search time compared to existing NAS approaches. Further, we\nsupport our algorithm with a theoretical analysis, providing upper bounds on\nthe number of measurements needed to perform reliable meta-learning; to our\nknowledge, these analysis tools are novel to the NAS literature and may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:35:52 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Cho", "Minsu", ""], ["Soltani", "Mohammadreza", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1906.02870", "submitter": "Daniel Russo", "authors": "Daniel Russo", "title": "Worst-Case Regret Bounds for Exploration via Randomized Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a recent proposal to use randomized value functions to\ndrive exploration in reinforcement learning. These randomized value functions\nare generated by injecting random noise into the training data, making the\napproach compatible with many popular methods for estimating parameterized\nvalue functions. By providing a worst-case regret bound for tabular\nfinite-horizon Markov decision processes, we show that planning with respect to\nthese randomized value functions can induce provably efficient exploration.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:36:00 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 09:40:10 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 22:43:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Russo", "Daniel", ""]]}, {"id": "1906.02872", "submitter": "Yifan Ou Mr", "authors": "Yifan Ou, Reza Samavi", "title": "Mixed Strategy Game Model Against Data Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use game theory to model poisoning attack scenarios. We\nprove the non-existence of pure strategy Nash Equilibrium in the attacker and\ndefender game. We then propose a mixed extension of our game model and an\nalgorithm to approximate the Nash Equilibrium strategy for the defender. We\nthen demonstrate the effectiveness of the mixed defence strategy generated by\nthe algorithm, in an experiment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:48:56 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ou", "Yifan", ""], ["Samavi", "Reza", ""]]}, {"id": "1906.02876", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Jesse Beu, Dibakar Gope, Chu Zhou, Igor Fedorov,\n  Ganesh Dasika, Matthew Mattina", "title": "Compressing RNNs for IoT devices by 15-38x using Kronecker Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) can be difficult to deploy on resource\nconstrained devices due to their size.As a result, there is a need for\ncompression techniques that can significantly compress RNNs without negatively\nimpacting task accuracy. This paper introduces a method to compress RNNs for\nresource constrained environments using Kronecker product (KP). KPs can\ncompress RNN layers by 15-38x with minimal accuracy loss. By quantizing the\nresulting models to 8-bits, we further push the compression factor to 50x. We\nshow that KP can beat the task accuracy achieved by other state-of-the-art\ncompression techniques across 5 benchmarks spanning 3 different applications,\nwhile simultaneously improving inference run-time. We show that the KP\ncompression mechanism does introduce an accuracy loss, which can be mitigated\nby a proposed hybrid KP (HKP) approach. Our HKP algorithm provides fine-grained\ncontrol over the compression ratio, enabling us to regain accuracy lost during\ncompression by adding a small number of model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 03:09:23 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 02:00:13 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 23:24:24 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 21:35:07 GMT"}, {"version": "v5", "created": "Fri, 31 Jan 2020 05:36:19 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Thakker", "Urmish", ""], ["Beu", "Jesse", ""], ["Gope", "Dibakar", ""], ["Zhou", "Chu", ""], ["Fedorov", "Igor", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1906.02881", "submitter": "Hayden Helm", "authors": "Hayden Helm, Joshua Vogelstein, Carey Priebe", "title": "Vertex Classification on Weighted Networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a discrimination technique for vertices in a weighted\nnetwork. We assume that the edge weights and adjacencies in the network are\nconditionally independent and that both sources of information encode class\nmembership information. In particular, we introduce a edge weight distribution\nmatrix to the standard K-Block Stochastic Block Model to model weighted\nnetworks. This allows us to develop simple yet powerful extensions of\nclassification techniques using the spectral embedding of the unweighted\nadjacency matrix. We consider two assumptions on the edge weight distributions\nand propose classification procedures in both settings. We show the\neffectiveness of the proposed classifiers by comparing them to quadratic\ndiscriminant analysis following the spectral embedding of a transformed\nweighted network. Moreover, we discuss and show how the methods perform when\nthe edge weights do not encode class membership information.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 03:16:08 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Helm", "Hayden", ""], ["Vogelstein", "Joshua", ""], ["Priebe", "Carey", ""]]}, {"id": "1906.02884", "submitter": "Nghia Nguyen", "authors": "Nghia Nguyen, Minh-Ngoc Tran, David Gunawan and R. Kohn", "title": "A long short-term memory stochastic volatility model", "comments": "34 pages, 14 figure, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Volatility (SV) models are widely used in the financial sector\nwhile Long Short-Term Memory (LSTM) models are successfully used in many\nlarge-scale industrial applications of Deep Learning. Our article combines\nthese two methods in a non-trivial way and proposes a model, which we call the\nLSTM-SV model, to capture the dynamics of stochastic volatility. The proposed\nmodel overcomes the short-term memory problem in conventional SV models, is\nable to capture non-linear dependence in the latent volatility process, and\noften has a better out-of-sample forecast performance than SV models. These\nproperties are illustrated through simulation study and applications to three\nfinancial time series datasets: The US stock market weekly index SP500, the\nAustralian stock weekly index ASX200 and the Australian-US dollar daily\nexchange rates. Based on our analysis, we argue that there are significant\ndifferences in the underlying dynamics between the volatility process of the\nSP500 and ASX200 datasets and that of the exchange rate dataset. For the stock\nindex data, there is strong evidence of long-term memory and non-linear\ndependence in the volatility process, while this is not the case for the\nexchange rates. An user-friendly software package together with the examples\nreported in the paper are available at https://github.com/vbayeslab.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 03:29:46 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 11:45:48 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Nguyen", "Nghia", ""], ["Tran", "Minh-Ngoc", ""], ["Gunawan", "David", ""], ["Kohn", "R.", ""]]}, {"id": "1906.02896", "submitter": "Walt Woods", "authors": "Walt Woods, Jack Chen, Christof Teuscher", "title": "Adversarial Explanations for Understanding Image Classification\n  Decisions and Improved Neural Network Robustness", "comments": "23 pages with a 14 page appendix. Submitted to Nature ML for peer\n  review", "journal-ref": "Nature Machine Intelligence (2019)", "doi": "10.1038/s42256-019-0104-6", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sensitive problems, such as medical imaging or fraud detection, Neural\nNetwork (NN) adoption has been slow due to concerns about their reliability,\nleading to a number of algorithms for explaining their decisions. NNs have also\nbeen found vulnerable to a class of imperceptible attacks, called adversarial\nexamples, which arbitrarily alter the output of the network. Here we\ndemonstrate both that these attacks can invalidate prior attempts to explain\nthe decisions of NNs, and that with very robust networks, the attacks\nthemselves may be leveraged as explanations with greater fidelity to the model.\nWe show that the introduction of a novel regularization technique inspired by\nthe Lipschitz constraint, alongside other proposed improvements, greatly\nimproves an NN's resistance to adversarial examples. On the ImageNet\nclassification task, we demonstrate a network with an Accuracy-Robustness Area\n(ARA) of 0.0053, an ARA 2.4x greater than the previous state of the art.\nImproving the mechanisms by which NN decisions are understood is an important\ndirection for both establishing trust in sensitive domains and learning more\nabout the stimuli to which NNs respond.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 04:52:01 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 21:11:01 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Woods", "Walt", ""], ["Chen", "Jack", ""], ["Teuscher", "Christof", ""]]}, {"id": "1906.02898", "submitter": "Shengpu Tang", "authors": "Jeeheh Oh, Jiaxuan Wang, Shengpu Tang, Michael Sjoding, Jenna Wiens", "title": "Relaxed Parameter Sharing: Effectively Modeling Time-Varying\n  Relationships in Clinical Time-Series", "comments": "Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are commonly applied to clinical time-series\ndata with the goal of learning patient risk stratification models. Their\neffectiveness is due, in part, to their use of parameter sharing over time\n(i.e., cells are repeated hence the name recurrent). We hypothesize, however,\nthat this trait also contributes to the increased difficulty such models have\nwith learning relationships that change over time. Conditional shift, i.e.,\nchanges in the relationship between the input X and the output y, arises when\nrisk factors associated with the event of interest change over the course of a\npatient admission. While in theory, RNNs and gated RNNs (e.g., LSTMs) in\nparticular should be capable of learning time-varying relationships, when\ntraining data are limited, such models often fail to accurately capture these\ndynamics. We illustrate the advantages and disadvantages of complete parameter\nsharing (RNNs) by comparing an LSTM with shared parameters to a sequential\narchitecture with time-varying parameters on prediction tasks involving three\nclinically-relevant outcomes: acute respiratory failure (ARF), shock, and\nin-hospital mortality. In experiments using synthetic data, we demonstrate how\nparameter sharing in LSTMs leads to worse performance in the presence of\nconditional shift. To improve upon the dichotomy between complete parameter\nsharing and no parameter sharing, we propose a novel RNN formulation based on a\nmixture model in which we relax parameter sharing over time. The proposed\nmethod outperforms standard LSTMs and other state-of-the-art baselines across\nall tasks. In settings with limited data, relaxed parameter sharing can lead to\nimproved patient risk stratification performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:04:07 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 10:52:30 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Oh", "Jeeheh", ""], ["Wang", "Jiaxuan", ""], ["Tang", "Shengpu", ""], ["Sjoding", "Michael", ""], ["Wiens", "Jenna", ""]]}, {"id": "1906.02901", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Michael T. C. Ying, Danny Z. Chen", "title": "Decompose-and-Integrate Learning for Multi-class Segmentation in Medical\n  Images", "comments": "To appear in MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation maps of medical images annotated by medical experts contain rich\nspatial information. In this paper, we propose to decompose annotation maps to\nlearn disentangled and richer feature transforms for segmentation problems in\nmedical images. Our new scheme consists of two main stages: decompose and\nintegrate. Decompose: by annotation map decomposition, the original\nsegmentation problem is decomposed into multiple segmentation sub-problems;\nthese new segmentation sub-problems are modeled by training multiple deep\nlearning modules, each with its own set of feature transforms. Integrate: a\nprocedure summarizes the solutions of the modules in the previous stage; a\nfinal solution is then formed for the original segmentation problem. Multiple\nways of annotation map decomposition are presented and a new end-to-end\ntrainable K-to-1 deep network framework is developed for implementing our\nproposed \"decompose-and-integrate\" learning scheme. In experiments, we\ndemonstrate that our decompose-and-integrate segmentation, utilizing\nstate-of-the-art fully convolutional networks (e.g., DenseVoxNet in 3D and\nCUMedNet in 2D), improves segmentation performance on multiple 3D and 2D\ndatasets. Ablation study confirms the effectiveness of our proposed learning\nscheme for medical images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:10:35 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Zhang", "Yizhe", ""], ["Ying", "Michael T. C.", ""], ["Chen", "Danny Z.", ""]]}, {"id": "1906.02903", "submitter": "Hongji Wei", "authors": "T. Tony Cai, Hongji Wei", "title": "Transfer Learning for Nonparametric Classification: Minimax Rate and\n  Adaptive Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human learners have the natural ability to use knowledge gained in one\nsetting for learning in a different but related setting. This ability to\ntransfer knowledge from one task to another is essential for effective\nlearning. In this paper, we study transfer learning in the context of\nnonparametric classification based on observations from different distributions\nunder the posterior drift model, which is a general framework and arises in\nmany practical problems.\n  We first establish the minimax rate of convergence and construct a\nrate-optimal two-sample weighted $K$-NN classifier. The results characterize\nprecisely the contribution of the observations from the source distribution to\nthe classification task under the target distribution. A data-driven adaptive\nclassifier is then proposed and is shown to simultaneously attain within a\nlogarithmic factor of the optimal rate over a large collection of parameter\nspaces. Simulation studies and real data applications are carried out where the\nnumerical results further illustrate the theoretical analysis. Extensions to\nthe case of multiple source distributions are also considered.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:29:48 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Cai", "T. Tony", ""], ["Wei", "Hongji", ""]]}, {"id": "1906.02909", "submitter": "Wei Wen", "authors": "Wei Wen, Feng Yan, Yiran Chen, Hai Li", "title": "AutoGrow: Automatic Layer Growing in Deep Convolutional Networks", "comments": "KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth is a key component of Deep Neural Networks (DNNs), however, designing\ndepth is heuristic and requires many human efforts. We propose AutoGrow to\nautomate depth discovery in DNNs: starting from a shallow seed architecture,\nAutoGrow grows new layers if the growth improves the accuracy; otherwise, stops\ngrowing and thus discovers the depth. We propose robust growing and stopping\npolicies to generalize to different network architectures and datasets. Our\nexperiments show that by applying the same policy to different network\narchitectures, AutoGrow can always discover near-optimal depth on various\ndatasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet. For\nexample, in terms of accuracy-computation trade-off, AutoGrow discovers a\nbetter depth combination in ResNets than human experts. Our AutoGrow is\nefficient. It discovers depth within similar time of training a single DNN. Our\ncode is available at https://github.com/wenwei202/autogrow.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:54:41 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 01:57:53 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 00:04:22 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 17:06:41 GMT"}, {"version": "v5", "created": "Mon, 15 Jun 2020 18:09:02 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wen", "Wei", ""], ["Yan", "Feng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1906.02914", "submitter": "Wu Lin", "authors": "Wu Lin, Mohammad Emtiyaz Khan, Mark Schmidt", "title": "Fast and Simple Natural-Gradient Variational Inference with Mixture of\n  Exponential-family Approximations", "comments": "Corrected some typos and updated the appendix (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural-gradient methods enable fast and simple algorithms for variational\ninference, but due to computational difficulties, their use is mostly limited\nto \\emph{minimal} exponential-family (EF) approximations. In this paper, we\nextend their application to estimate \\emph{structured} approximations such as\nmixtures of EF distributions. Such approximations can fit complex, multimodal\nposterior distributions and are generally more accurate than unimodal EF\napproximations. By using a \\emph{minimal conditional-EF} representation of such\napproximations, we derive simple natural-gradient updates. Our empirical\nresults demonstrate a faster convergence of our natural-gradient method\ncompared to black-box gradient-based methods with reparameterization gradients.\nOur work expands the scope of natural gradients for Bayesian inference and\nmakes them more widely applicable than before.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:16:04 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 18:59:48 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 06:40:05 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Lin", "Wu", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Schmidt", "Mark", ""]]}, {"id": "1906.02915", "submitter": "Eyke H\\\"ullermeier", "authors": "Robin Senge, Juan Jos\\'e del Coz, Eyke H\\\"ullermeier", "title": "Rectifying Classifier Chains for Multi-Label Classification", "comments": "18 pages, 3 figures, 4 tables, extended version of: Robin Senge,\n  Jos\\'e del Coz, E. H\\\"ullermeier. Rectifying Classifier Chains for\n  Multi-Label Classification. Proceedings Workshop LWA 2013,\n  Lernen-Wissensentdeckung-Adaptivit\\\"at,151-158, Bamberg, Germany, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier chains have recently been proposed as an appealing method for\ntackling the multi-label classification task. In addition to several empirical\nstudies showing its state-of-the-art performance, especially when being used in\nits ensemble variant, there are also some first results on theoretical\nproperties of classifier chains. Continuing along this line, we analyze the\ninfluence of a potential pitfall of the learning process, namely the\ndiscrepancy between the feature spaces used in training and testing: While true\nclass labels are used as supplementary attributes for training the binary\nmodels along the chain, the same models need to rely on estimations of these\nlabels at prediction time. We elucidate under which circumstances the attribute\nnoise thus created can affect the overall prediction performance. As a result\nof our findings, we propose two modifications of classifier chains that are\nmeant to overcome this problem. Experimentally, we show that our variants are\nindeed able to produce better results in cases where the original chaining\nprocess is likely to fail.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:22:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Senge", "Robin", ""], ["del Coz", "Juan Jos\u00e9", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1906.02922", "submitter": "Ruihao Zhu", "authors": "Wang Chi Cheung and David Simchi-Levi and Ruihao Zhu", "title": "Non-Stationary Reinforcement Learning: The Blessing of (More) Optimism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider un-discounted reinforcement learning (RL) in Markov decision\nprocesses (MDPs) under temporal drifts, ie, both the reward and state\ntransition distributions are allowed to evolve over time, as long as their\nrespective total variations, quantified by suitable metrics, do not exceed\ncertain variation budgets. This setting captures the endogeneity, exogeneity,\nuncertainty, and partial feedback in sequential decision-making scenarios, and\nfinds applications in vehicle remarketing and real-time bidding. We first\ndevelop the Sliding Window Upper-Confidence bound for Reinforcement Learning\nwith Confidence Widening (SWUCRL2-CW) algorithm, and establish its dynamic\nregret bound when the variation budgets are known. In addition, we propose the\nBandit-over-Reinforcement Learning (BORL) algorithm to adaptively tune the\nSWUCRL2-CW algorithm to achieve the same dynamic regret bound, but in a\nparameter-free manner, ie, without knowing the variation budgets. Finally, we\nconduct numerical experiments to show that our proposed algorithms achieve\nsuperior empirical performance compared to existing algorithms.\n  Notably, the interplay between endogeneity and exogeneity presents a unique\nchallenge, absent in existing (stationary and non-stationary) stochastic online\nlearning settings, when we apply the conventional Optimism in Face of\nUncertainty principle to design algorithms with provably low dynamic regret for\nRL in drifting MDPs. We overcome the challenge by a novel confidence widening\ntechnique that incorporates additional optimism into our learning algorithms to\nensure low dynamic regret bounds. To extend our theoretical findings, we apply\nour framework to inventory control problems, and demonstrate how one can\nalternatively leverage special structures on the state transition distributions\nto bypass the difficulty in exploring time-varying environments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:32:25 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 04:05:23 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 17:23:21 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 16:34:50 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Simchi-Levi", "David", ""], ["Zhu", "Ruihao", ""]]}, {"id": "1906.02926", "submitter": "Ryo Karakida", "authors": "Ryo Karakida and Shotaro Akaho and Shun-ichi Amari", "title": "The Normalization Method for Alleviating Pathological Sharpness in Wide\n  Neural Networks", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization methods play an important role in enhancing the performance of\ndeep learning while their theoretical understandings have been limited. To\ntheoretically elucidate the effectiveness of normalization, we quantify the\ngeometry of the parameter space determined by the Fisher information matrix\n(FIM), which also corresponds to the local shape of the loss landscape under\ncertain conditions. We analyze deep neural networks with random initialization,\nwhich is known to suffer from a pathologically sharp shape of the landscape\nwhen the network becomes sufficiently wide. We reveal that batch normalization\nin the last layer contributes to drastically decreasing such pathological\nsharpness if the width and sample number satisfy a specific condition. In\ncontrast, it is hard for batch normalization in the middle hidden layers to\nalleviate pathological sharpness in many settings. We also found that layer\nnormalization cannot alleviate pathological sharpness either. Thus, we can\nconclude that batch normalization in the last layer significantly contributes\nto decreasing the sharpness induced by the FIM.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:59:48 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 16:26:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Karakida", "Ryo", ""], ["Akaho", "Shotaro", ""], ["Amari", "Shun-ichi", ""]]}, {"id": "1906.02931", "submitter": "Yan  Li", "authors": "Yan Li, Ethan X.Fang, Huan Xu, Tuo Zhao", "title": "Inductive Bias of Gradient Descent based Adversarial Training on\n  Separable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a principled approach for training robust neural\nnetworks. Despite of tremendous successes in practice, its theoretical\nproperties still remain largely unexplored. In this paper, we provide new\ntheoretical insights of gradient descent based adversarial training by studying\nits computational properties, specifically on its inductive bias. We take the\nbinary classification task on linearly separable data as an illustrative\nexample, where the loss asymptotically attains its infimum as the parameter\ndiverges to infinity along certain directions. Specifically, we show that when\nthe adversarial perturbation during training has bounded $\\ell_2$-norm, the\nclassifier learned by gradient descent based adversarial training converges in\ndirection to the maximum $\\ell_2$-norm margin classifier at the rate of\n$\\tilde{\\mathcal{O}}(1/\\sqrt{T})$, significantly faster than the rate\n$\\mathcal{O}(1/\\log T)$ of training with clean data. In addition, when the\nadversarial perturbation during training has bounded $\\ell_q$-norm for some\n$q\\ge 1$, the resulting classifier converges in direction to a maximum\nmixed-norm margin classifier, which has a natural interpretation of robustness,\nas being the maximum $\\ell_2$-norm margin classifier under worst-case\n$\\ell_q$-norm perturbation to the data. Our findings provide theoretical\nbackups for adversarial training that it indeed promotes robustness against\nadversarial perturbation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 07:22:56 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 19:24:27 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 14:58:47 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Li", "Yan", ""], ["Fang", "Ethan X.", ""], ["Xu", "Huan", ""], ["Zhao", "Tuo", ""]]}, {"id": "1906.02940", "submitter": "Trieu Trinh", "authors": "Trieu H. Trinh, Minh-Thang Luong, Quoc V. Le", "title": "Selfie: Self-supervised Pretraining for Image Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a pretraining technique called Selfie, which stands for SELFie\nsupervised Image Embedding. Selfie generalizes the concept of masked language\nmodeling of BERT (Devlin et al., 2019) to continuous data, such as images, by\nmaking use of the Contrastive Predictive Coding loss (Oord et al., 2018). Given\nmasked-out patches in an input image, our method learns to select the correct\npatch, among other \"distractor\" patches sampled from the same image, to fill in\nthe masked location. This classification objective sidesteps the need for\npredicting exact pixel values of the target patches. The pretraining\narchitecture of Selfie includes a network of convolutional blocks to process\npatches followed by an attention pooling network to summarize the content of\nunmasked patches before predicting masked ones. During finetuning, we reuse the\nconvolutional weights found by pretraining. We evaluate Selfie on three\nbenchmarks (CIFAR-10, ImageNet 32 x 32, and ImageNet 224 x 224) with varying\namounts of labeled data, from 5% to 100% of the training sets. Our pretraining\nmethod provides consistent improvements to ResNet-50 across all settings\ncompared to the standard supervised training of the same network. Notably, on\nImageNet 224 x 224 with 60 examples per class (5%), our method improves the\nmean accuracy of ResNet-50 from 35.6% to 46.7%, an improvement of 11.1 points\nin absolute accuracy. Our pretraining method also improves ResNet-50 training\nstability, especially on low data regime, by significantly lowering the\nstandard deviation of test accuracies across different runs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 07:47:24 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 01:30:56 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 08:03:46 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Trinh", "Trieu H.", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""]]}, {"id": "1906.02956", "submitter": "Simon Meyer Lauritsen", "authors": "Simon Meyer Lauritsen, Mads Ellersgaard Kal{\\o}r, Emil Lund\n  Kongsgaard, Katrine Meyer Lauritsen, Marianne Johansson J{\\o}rgensen, Jeppe\n  Lange, Bo Thiesson", "title": "Early detection of sepsis utilizing deep learning on electronic health\n  record event sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The timeliness of detection of a sepsis event in progress is a crucial factor\nin the outcome for the patient. Machine learning models built from data in\nelectronic health records can be used as an effective tool for improving this\ntimeliness, but so far the potential for clinical implementations has been\nlargely limited to studies in intensive care units. This study will employ a\nricher data set that will expand the applicability of these models beyond\nintensive care units. Furthermore, we will circumvent several important\nlimitations that have been found in the literature: 1) Models are evaluated\nshortly before sepsis onset without considering interventions already\ninitiated. 2) Machine learning models are built on a restricted set of clinical\nparameters, which are not necessarily measured in all departments. 3) Model\nperformance is limited by current knowledge of sepsis, as feature interactions\nand time dependencies are hardcoded into the model. In this study, we present a\nmodel to overcome these shortcomings using a deep learning approach on a\ndiverse multicenter data set. We used retrospective data from multiple Danish\nhospitals over a seven-year period. Our sepsis detection system is constructed\nas a combination of a convolutional neural network and a long short-term memory\nnetwork. We suggest a retrospective assessment of interventions by looking at\nintravenous antibiotics and blood cultures preceding the prediction time.\nResults show performance ranging from AUROC 0.856 (3 hours before sepsis onset)\nto AUROC 0.756 (24 hours before sepsis onset). We present a deep learning\nsystem for early detection of sepsis that is able to learn characteristics of\nthe key factors and interactions from the raw event sequence data itself,\nwithout relying on a labor-intensive feature extraction work.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 08:38:02 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lauritsen", "Simon Meyer", ""], ["Kal\u00f8r", "Mads Ellersgaard", ""], ["Kongsgaard", "Emil Lund", ""], ["Lauritsen", "Katrine Meyer", ""], ["J\u00f8rgensen", "Marianne Johansson", ""], ["Lange", "Jeppe", ""], ["Thiesson", "Bo", ""]]}, {"id": "1906.02972", "submitter": "Xudong Sun", "authors": "Xudong Sun, Alexej Gossmann, Yu Wang, Bernd Bischl", "title": "Variational Resampling Based Assessment of Deep Neural Networks under\n  Distribution Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A novel variational inference based resampling framework is proposed to\nevaluate the robustness and generalization capability of deep learning models\nwith respect to distribution shift. We use Auto Encoding Variational Bayes to\nfind a latent representation of the data, on which a Variational Gaussian\nMixture Model is applied to deliberately create distribution shift by dividing\nthe dataset into different clusters. Wasserstein distance is used to\ncharacterize the extent of distribution shift between the generated data\nsplits. We compare several popular Convolutional Neural Network (CNN)\narchitectures and Bayesian CNN models for image classification on the\nFashion-MNIST dataset, to assess their robustness and generalization behavior\nunder the deliberately created distribution shift, as well as under random\nCross Validation. Our method of creating artificial domain splits of a single\ndataset can also be used to establish novel model selection criteria and\nassessment tools in machine learning, as well as benchmark methods for domain\nadaptation and domain generalization approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 09:05:32 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 15:26:54 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 10:47:31 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 09:59:14 GMT"}, {"version": "v5", "created": "Tue, 22 Oct 2019 15:53:31 GMT"}, {"version": "v6", "created": "Sun, 27 Oct 2019 20:41:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sun", "Xudong", ""], ["Gossmann", "Alexej", ""], ["Wang", "Yu", ""], ["Bischl", "Bernd", ""]]}, {"id": "1906.02975", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Manoj Plakal, Frederic Font, Daniel P. W. Ellis and\n  Xavier Serra", "title": "Audio tagging with noisy labels and minimal supervision", "comments": "DCASE2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces Task 2 of the DCASE2019 Challenge, titled \"Audio\ntagging with noisy labels and minimal supervision\". This task was hosted on the\nKaggle platform as \"Freesound Audio Tagging 2019\". The task evaluates systems\nfor multi-label audio tagging using a large set of noisy-labeled data, and a\nmuch smaller set of manually-labeled data, under a large vocabulary setting of\n80 everyday sound classes. In addition, the proposed dataset poses an acoustic\nmismatch problem between the noisy train set and the test set due to the fact\nthat they come from different web audio sources. This can correspond to a\nrealistic scenario given by the difficulty in gathering large amounts of\nmanually labeled data. We present the task setup, the FSDKaggle2019 dataset\nprepared for this scientific evaluation, and a baseline system consisting of a\nconvolutional neural network. All these resources are freely available.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 09:09:56 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 23:05:39 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 17:39:18 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 00:26:57 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Plakal", "Manoj", ""], ["Font", "Frederic", ""], ["Ellis", "Daniel P. W.", ""], ["Serra", "Xavier", ""]]}, {"id": "1906.02989", "submitter": "Mital Kinderkhedia", "authors": "Mital Kinderkhedia", "title": "Learning Representations of Graph Data -- A Survey", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.33978.64961/1", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have shown tremendous success in the area of object\nrecognition, image classification and natural language processing. However,\ndesigning optimal Neural Network architectures that can learn and output\narbitrary graphs is an ongoing research problem. The objective of this survey\nis to summarize and discuss the latest advances in methods to Learn\nRepresentations of Graph Data. We start by identifying commonly used types of\ngraph data and review basics of graph theory. This is followed by a discussion\nof the relationships between graph kernel methods and neural networks. Next we\nidentify the major approaches used for learning representations of graph data\nnamely: Kernel approaches, Convolutional approaches, Graph neural networks\napproaches, Graph embedding approaches and Probabilistic approaches. A variety\nof methods under each of the approaches are discussed and the survey is\nconcluded with a brief discussion of the future of learning representation of\ngraph data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 09:52:53 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 16:26:01 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kinderkhedia", "Mital", ""]]}, {"id": "1906.02994", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Balaji\n  Lakshminarayanan", "title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using\n  Typicality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep generative models can assign higher\nlikelihood to out-of-distribution data sets than to their training data\n(Nalisnick et al., 2019; Choi et al., 2019). We posit that this phenomenon is\ncaused by a mismatch between the model's typical set and its areas of high\nprobability density. In-distribution inputs should reside in the former but not\nnecessarily in the latter, as previous work has presumed. To determine whether\nor not inputs reside in the typical set, we propose a statistically principled,\neasy-to-implement test using the empirical distribution of model likelihoods.\nThe test is model agnostic and widely applicable, only requiring that the\nlikelihood can be computed or closely approximated. We report experiments\nshowing that our procedure can successfully detect the out-of-distribution sets\nin several of the challenging cases reported by Nalisnick et al. (2019).\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 10:03:16 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 13:43:36 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Nalisnick", "Eric", ""], ["Matsukawa", "Akihiro", ""], ["Teh", "Yee Whye", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1906.03001", "submitter": "Yang-Wen Sun", "authors": "Yang-Wen Sun, Katerina Papagiannouli, Vladmir Spokoiny", "title": "Online Graph-Based Change-Point Detection for High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online change-point detection (OCPD) is important for application in various\nareas such as finance, biology, and the Internet of Things (IoT). However, OCPD\nfaces major challenges due to high-dimensionality, and it is still rarely\nstudied in literature. In this paper, we propose a novel, online, graph-based,\nchange-point detection algorithm to detect change of distribution in low- to\nhigh-dimensional data. We introduce a similarity measure, which is derived from\nthe graph-spanning ratio, to test statistically if a change occurs. Through\nnumerical study using artificial online datasets, our data-driven approach\ndemonstrates high detection power for high-dimensional data, while the false\nalarm rate (type I error) is controlled at a nominal significant level. In\nparticular, our graph-spanning approach has desirable power with small and\nmultiple scanning window, which allows timely detection of change-point in the\nonline setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 10:40:45 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Sun", "Yang-Wen", ""], ["Papagiannouli", "Katerina", ""], ["Spokoiny", "Vladmir", ""]]}, {"id": "1906.03028", "submitter": "Maria I. Gorinova", "authors": "Maria I. Gorinova, Dave Moore, Matthew D. Hoffman", "title": "Automatic Reparameterisation of Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic programming has emerged as a powerful paradigm in statistics,\napplied science, and machine learning: by decoupling modelling from inference,\nit promises to allow modellers to directly reason about the processes\ngenerating data. However, the performance of inference algorithms can be\ndramatically affected by the parameterisation used to express a model,\nrequiring users to transform their programs in non-intuitive ways. We argue for\nautomating these transformations, and demonstrate that mechanisms available in\nrecent modeling frameworks can implement non-centring and related\nreparameterisations. This enables new inference algorithms, and we propose two:\na simple approach using interleaved sampling and a novel variational\nformulation that searches over a continuous space of parameterisations. We show\nthat these approaches enable robust inference across a range of models, and can\nyield more efficient samplers than the best fixed parameterisation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 11:56:42 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Gorinova", "Maria I.", ""], ["Moore", "Dave", ""], ["Hoffman", "Matthew D.", ""]]}, {"id": "1906.03038", "submitter": "Divyat Mahajan", "authors": "Varun Khare, Divyat Mahajan, Homanga Bharadhwaj, Vinay Verma, Piyush\n  Rai", "title": "A Generative Framework for Zero-Shot Learning with Adversarial Domain\n  Adaptation", "comments": "Proceedings of Winter Conference on Applications of Computer Vision\n  (WACV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a domain adaptation based generative framework for zero-shot\nlearning. Our framework addresses the problem of domain shift between the seen\nand unseen class distributions in zero-shot learning and minimizes the shift by\ndeveloping a generative model trained via adversarial domain adaptation. Our\napproach is based on end-to-end learning of the class distributions of seen\nclasses and unseen classes. To enable the model to learn the class\ndistributions of unseen classes, we parameterize these class distributions in\nterms of the class attribute information (which is available for both seen and\nunseen classes). This provides a very simple way to learn the class\ndistribution of any unseen class, given only its class attribute information,\nand no labeled training data. Training this model with adversarial domain\nadaptation further provides robustness against the distribution mismatch\nbetween the data from seen and unseen classes. Our approach also provides a\nnovel way for training neural net based classifiers to overcome the hubness\nproblem in zero-shot learning. Through a comprehensive set of experiments, we\nshow that our model yields superior accuracies as compared to various\nstate-of-the-art zero shot learning models, on a variety of benchmark datasets.\nCode for the experiments is available at github.com/vkkhare/ZSL-ADA\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 12:11:22 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 20:38:42 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 18:49:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Khare", "Varun", ""], ["Mahajan", "Divyat", ""], ["Bharadhwaj", "Homanga", ""], ["Verma", "Vinay", ""], ["Rai", "Piyush", ""]]}, {"id": "1906.03040", "submitter": "Sebastien Blandin", "authors": "Sebastien Blandin, Laura Wynter, Hasan Poonawala, Sean Laguna, Basile\n  Dura", "title": "FASTER: Fusion AnalyticS for public Transport Event Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing urban concentration raises operational challenges that can benefit\nfrom integrated monitoring and decision support. Such complex systems need to\nleverage the full stack of analytical methods, from state estimation using\nmulti-sensor fusion for situational awareness, to prediction and computation of\noptimal responses. The FASTER platform that we describe in this work, deployed\nat nation scale and handling 1.5 billion public transport trips a year, offers\nsuch a full stack of techniques for this large-scale, real-time problem. FASTER\nprovides fine-grained situational awareness and real-time decision support with\nthe objective of improving the public transport commuter experience. The\nmethods employed range from statistical machine learning to agent-based\nsimulation and mixed-integer optimization. In this work we present an overview\nof the challenges and methods involved, with details of the commuter movement\nprediction module, as well as a discussion of open problems.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 05:26:19 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Blandin", "Sebastien", ""], ["Wynter", "Laura", ""], ["Poonawala", "Hasan", ""], ["Laguna", "Sean", ""], ["Dura", "Basile", ""]]}, {"id": "1906.03049", "submitter": "Antti Koskela", "authors": "Antti Koskela, Joonas J\\\"alk\\\"o and Antti Honkela", "title": "Computing Tight Differential Privacy Guarantees Using FFT", "comments": "43 pages, 7 figures", "journal-ref": "AISTATS (2020) 2560-2569", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentially private (DP) machine learning has recently become popular. The\nprivacy loss of DP algorithms is commonly reported using\n$(\\varepsilon,\\delta)$-DP. In this paper, we propose a numerical accountant for\nevaluating the privacy loss for algorithms with continuous one dimensional\noutput. This accountant can be applied to the subsampled multidimensional\nGaussian mechanism which underlies the popular DP stochastic gradient descent.\nThe proposed method is based on a numerical approximation of an integral\nformula which gives the exact $(\\varepsilon,\\delta)$-values. The approximation\nis carried out by discretising the integral and by evaluating discrete\nconvolutions using the fast Fourier transform algorithm. We give both\ntheoretical error bounds and numerical error estimates for the approximation.\nExperimental comparisons with state-of-the-art techniques demonstrate\nsignificant improvements in bound tightness and/or computation time. Python\ncode for the method can be found in Github\n(https://github.com/DPBayes/PLD-Accountant/).\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 12:33:46 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 10:28:15 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Koskela", "Antti", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Honkela", "Antti", ""]]}, {"id": "1906.03063", "submitter": "Philip Thomas", "authors": "Philip S. Thomas, Scott M. Jordan, Yash Chandak, Chris Nota, James\n  Kostas", "title": "Classical Policy Gradient: Preserving Bellman's Principle of Optimality", "comments": "1 page, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new objective function for finite-horizon episodic Markov\ndecision processes that better captures Bellman's principle of optimality, and\nprovide an expression for the gradient of the objective.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:09:01 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Thomas", "Philip S.", ""], ["Jordan", "Scott M.", ""], ["Chandak", "Yash", ""], ["Nota", "Chris", ""], ["Kostas", "James", ""]]}, {"id": "1906.03072", "submitter": "Stephan Sloth Lorenzen", "authors": "Stephan Lorenzen, Niklas Hjuler, Stephen Alstrup", "title": "Investigating Writing Style Development in High School", "comments": "A short version of this paper will be presented at EDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we do the first large scale analysis of writing style\ndevelopment among Danish high school students. More than 10K students with more\nthan 100K essays are analyzed. Writing style itself is often studied in the\nnatural language processing community, but usually with the goal of verifying\nauthorship, assessing quality or popularity, or other kinds of predictions.\n  In this work, we analyze writing style changes over time, with the goal of\ndetecting global development trends among students, and identifying at-risk\nstudents. We train a Siamese neural network to compute the similarity between\ntwo texts. Using this similarity measure, a student's newer essays are compared\nto their first essays, and a writing style development profile is constructed\nfor the student. We cluster these student profiles and analyze the resulting\nclusters in order to detect general development patterns. We evaluate clusters\nwith respect to writing style quality indicators, and identify optimal\nclusters, showing significant improvement in writing style, while also\nobserving suboptimal clusters, exhibiting periods of limited development and\neven setbacks.\n  Furthermore, we identify general development trends between high school\nstudents, showing that as students progress through high school, their writing\nstyle deviates, leaving students less similar when they finish high school,\nthan when they start.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:20:40 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lorenzen", "Stephan", ""], ["Hjuler", "Niklas", ""], ["Alstrup", "Stephen", ""]]}, {"id": "1906.03077", "submitter": "Kalai Ramea", "authors": "Kalai Ramea", "title": "Unsupervised Temporal Clustering to Monitor the Performance of\n  Alternative Fueling Infrastructure", "comments": null, "journal-ref": "International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero Emission Vehicles (ZEV) play an important role in the decarbonization of\nthe transportation sector. For a wider adoption of ZEVs, providing a reliable\ninfrastructure is critical. We present a machine learning approach that uses\nunsupervised temporal clustering algorithm along with survey analysis to\ndetermine infrastructure performance and reliability of alternative fuels. We\nillustrate this approach for the hydrogen fueling stations in California, but\nthis can be generalized for other regions and fuels.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 00:49:23 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ramea", "Kalai", ""]]}, {"id": "1906.03080", "submitter": "Azin Asgarian", "authors": "Mehdi Sadeqi, Azin Asgarian, Ariel Sibilia", "title": "Prediction of Workplace Injuries", "comments": "AI for Social Good (AISG) Workshop at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Workplace injuries result in substantial human and financial losses. As\nreported by the International Labour Organization (ILO), there are more than\n374 million work-related injuries reported every year. In this study, we\ninvestigate the problem of injury risk prediction and prevention in a work\nenvironment. While injuries represent a significant number across all\norganizations, they are rare events within a single organization. Hence,\ncollecting a sufficiently large dataset from a single organization is extremely\ndifficult. In addition, the collected datasets are often highly imbalanced\nwhich increases the problem difficulty. Finally, risk predictions need to\nprovide additional context for injuries to be prevented. We propose and\nevaluate the following for a complete solution: 1) several ensemble-based\nresampling methods to address the class imbalance issues, 2) a novel transfer\nlearning approach to transfer the knowledge across organizations, and 3)\nvarious techniques to uncover the association and causal effect of different\nvariables on injury risk, while controlling for relevant confounding factors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:22:39 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Sadeqi", "Mehdi", ""], ["Asgarian", "Azin", ""], ["Sibilia", "Ariel", ""]]}, {"id": "1906.03098", "submitter": "Oggi Rudovic", "authors": "Ognjen Rudovic, Meiru Zhang, Bjorn Schuller and Rosalind W. Picard", "title": "Multi-modal Active Learning From Human Data: A Deep Reinforcement\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human behavior expression and experience are inherently multi-modal, and\ncharacterized by vast individual and contextual heterogeneity. To achieve\nmeaningful human-computer and human-robot interactions, multi-modal models of\nthe users states (e.g., engagement) are therefore needed. Most of the existing\nworks that try to build classifiers for the users states assume that the data\nto train the models are fully labeled. Nevertheless, data labeling is costly\nand tedious, and also prone to subjective interpretations by the human coders.\nThis is even more pronounced when the data are multi-modal (e.g., some users\nare more expressive with their facial expressions, some with their voice).\nThus, building models that can accurately estimate the users states during an\ninteraction is challenging. To tackle this, we propose a novel multi-modal\nactive learning (AL) approach that uses the notion of deep reinforcement\nlearning (RL) to find an optimal policy for active selection of the users data,\nneeded to train the target (modality-specific) models. We investigate different\nstrategies for multi-modal data fusion, and show that the proposed model-level\nfusion coupled with RL outperforms the feature-level and modality-specific\nmodels, and the naive AL strategies such as random sampling, and the standard\nheuristics such as uncertainty sampling. We show the benefits of this approach\non the task of engagement estimation from real-world child-robot interactions\nduring an autism therapy. Importantly, we show that the proposed multi-modal AL\napproach can be used to efficiently personalize the engagement classifiers to\nthe target user using a small amount of actively selected users data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:46:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Rudovic", "Ognjen", ""], ["Zhang", "Meiru", ""], ["Schuller", "Bjorn", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1906.03118", "submitter": "SungYub Kim", "authors": "Sungyub Kim, Yongsu Baek, Sung Ju Hwang, Eunho Yang", "title": "Reliable Estimation of Individual Treatment Effect with Causal\n  Information Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating individual level treatment effects (ITE) from observational data\nis a challenging and important area in causal machine learning and is commonly\nconsidered in diverse mission-critical applications. In this paper, we propose\nan information theoretic approach in order to find more reliable\nrepresentations for estimating ITE. We leverage the Information Bottleneck (IB)\nprinciple, which addresses the trade-off between conciseness and predictive\npower of representation. With the introduction of an extended graphical model\nfor causal information bottleneck, we encourage the independence between the\nlearned representation and the treatment type. We also introduce an additional\nform of a regularizer from the perspective of understanding ITE in the\nsemi-supervised learning framework to ensure more reliable representations.\nExperimental results show that our model achieves the state-of-the-art results\nand exhibits more reliable prediction performances with uncertainty information\non real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:15:55 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Kim", "Sungyub", ""], ["Baek", "Yongsu", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "1906.03123", "submitter": "Waldyn Martinez", "authors": "Waldyn Martinez, J. Brian Gray", "title": "On the Current State of Research in Explaining Ensemble Performance\n  Using Margins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evidence shows that ensembles, such as bagging, boosting, random\nand rotation forests, generally perform better in terms of their generalization\nerror than individual classifiers. To explain this performance, Schapire et al.\n(1998) developed an upper bound on the generalization error of an ensemble\nbased on the margins of the training data, from which it was concluded that\nlarger margins should lead to lower generalization error, everything else being\nequal. Many other researchers have backed this assumption and presented tighter\nbounds on the generalization error based on either the margins or functions of\nthe margins. For instance, Shen and Li (2010) provide evidence suggesting that\nthe generalization error of a voting classifier might be reduced by increasing\nthe mean and decreasing the variance of the margins. In this article we propose\nseveral techniques and empirically test whether the current state of research\nin explaining ensemble performance holds. We evaluate the proposed methods\nthrough experiments with real and simulated data sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:23:29 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Martinez", "Waldyn", ""], ["Gray", "J. Brian", ""]]}, {"id": "1906.03139", "submitter": "Karel Lenc", "authors": "Karel Lenc, Erich Elsen, Tom Schaul, Karen Simonyan", "title": "Non-Differentiable Supervised Learning with Evolution Strategies and\n  Hybrid Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that Evolution Strategies (ES) are a viable method for\nlearning non-differentiable parameters of large supervised models. ES are\nblack-box optimization algorithms that estimate distributions of model\nparameters; however they have only been used for relatively small problems so\nfar. We show that it is possible to scale ES to more complex tasks and models\nwith millions of parameters. While using ES for differentiable parameters is\ncomputationally impractical (although possible), we show that a hybrid approach\nis practically feasible in the case where the model has both differentiable and\nnon-differentiable parameters. In this approach we use standard gradient-based\nmethods for learning differentiable weights, while using ES for learning\nnon-differentiable parameters - in our case sparsity masks of the weights. This\nproposed method is surprisingly competitive, and when parallelized over\nmultiple devices has only negligible training time overhead compared to\ntraining with gradient descent. Additionally, this method allows to train\nsparse models from the first training step, so they can be much larger than\nwhen using methods that require training dense models first. We present results\nand analysis of supervised feed-forward models (such as MNIST and CIFAR-10\nclassification), as well as recurrent models, such as SparseWaveRNN for\ntext-to-speech.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:52:19 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lenc", "Karel", ""], ["Elsen", "Erich", ""], ["Schaul", "Tom", ""], ["Simonyan", "Karen", ""]]}, {"id": "1906.03148", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Mark Crowley", "title": "Unsupervised and Supervised Principal Component Analysis: Tutorial", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a detailed tutorial paper which explains the Principal Component\nAnalysis (PCA), Supervised PCA (SPCA), kernel PCA, and kernel SPCA. We start\nwith projection, PCA with eigen-decomposition, PCA with one and multiple\nprojection directions, properties of the projection matrix, reconstruction\nerror minimization, and we connect to auto-encoder. Then, PCA with singular\nvalue decomposition, dual PCA, and kernel PCA are covered. SPCA using both\nscoring and Hilbert-Schmidt independence criterion are explained. Kernel SPCA\nusing both direct and dual approaches are then introduced. We cover all cases\nof projection and reconstruction of training and out-of-sample data. Finally,\nsome simulations are provided on Frey and AT&T face datasets for verifying the\ntheory in practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 23:26:38 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Crowley", "Mark", ""]]}, {"id": "1906.03155", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu, Weiping Wang", "title": "Distributed Learning with Random Features", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning and random projections are the most common techniques in\nlarge scale nonparametric statistical learning. In this paper, we study the\ngeneralization properties of kernel ridge regression using both distributed\nmethods and random features. Theoretical analysis shows the combination\nremarkably reduces computational cost while preserving the optimal\ngeneralization accuracy under standard assumptions. In a benign case,\n$\\mathcal{O}(\\sqrt{N})$ partitions and $\\mathcal{O}(\\sqrt{N})$ random features\nare sufficient to achieve $\\mathcal{O}(1/N)$ learning rate, where $N$ is the\nlabeled sample size. Further, we derive more refined results by using\nadditional unlabeled data to enlarge the number of partitions and by generating\nfeatures in a data-dependent way to reduce the number of random features.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:19:58 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 01:59:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "1906.03161", "submitter": "Virginia Aglietti", "authors": "Virginia Aglietti, Edwin V. Bonilla, Theodoros Damoulas, Sally Cripps", "title": "Structured Variational Inference in Continuous Cox Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable framework for inference in an inhomogeneous Poisson\nprocess modeled by a continuous sigmoidal Cox process that assumes the\ncorresponding intensity function is given by a Gaussian process (GP) prior\ntransformed with a scaled logistic sigmoid function. We present a tractable\nrepresentation of the likelihood through augmentation with a superposition of\nPoisson processes. This view enables a structured variational approximation\ncapturing dependencies across variables in the model. Our framework avoids\ndiscretization of the domain, does not require accurate numerical integration\nover the input space and is not limited to GPs with squared exponential\nkernels. We evaluate our approach on synthetic and real-world data showing that\nits benefits are particularly pronounced on multivariate input settings where\nit overcomes the limitations of mean-field methods and sampling schemes. We\nprovide the state of-the-art in terms of speed, accuracy and uncertainty\nquantification trade-offs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:31:02 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Aglietti", "Virginia", ""], ["Bonilla", "Edwin V.", ""], ["Damoulas", "Theodoros", ""], ["Cripps", "Sally", ""]]}, {"id": "1906.03164", "submitter": "Taylor Killian", "authors": "Taylor Killian, Justin Goodwin, Olivia Brown, Sung-Hyun Son", "title": "Kernelized Capsule Networks", "comments": "Paper accepted to the ICML 2019 Workshop on Understanding and\n  Improving Generalization in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks attempt to represent patterns in images in a way that\npreserves hierarchical spatial relationships. Additionally, research has\ndemonstrated that these techniques may be robust against adversarial\nperturbations. We present an improvement to training capsule networks with\nadded robustness via non-parametric kernel methods. The representations learned\nthrough the capsule network are used to construct covariance kernels for\nGaussian processes (GPs). We demonstrate that this approach achieves comparable\nprediction performance to Capsule Networks while improving robustness to\nadversarial perturbations and providing a meaningful measure of uncertainty\nthat may aid in the detection of adversarial inputs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:34:00 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Killian", "Taylor", ""], ["Goodwin", "Justin", ""], ["Brown", "Olivia", ""], ["Son", "Sung-Hyun", ""]]}, {"id": "1906.03169", "submitter": "Jinzhi Lin", "authors": "Jinzhi Lin, Shengzhong Feng, Zhile Yang, Yun Zhang, Yong Zhang", "title": "A Novel Deep Neural Network Based Approach for Sparse Code Multiple\n  Access", "comments": "21 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse code multiple access (SCMA) has been one of non-orthogonal multiple\naccess (NOMA) schemes aiming to support high spectral efficiency and ubiquitous\naccess requirements for 5G wireless communication networks. Conventional SCMA\napproaches are confronting remarkable challenges in designing low complexity\nhigh accuracy decoding algorithm and constructing optimum codebooks.\nFortunately, the recent spotlighted deep learning technologies are of\nsignificant potentials in solving many communication engineering problems.\nInspired by this, we explore approaches to improve SCMA performances with the\nhelp of deep learning methods. We propose and train a deep neural network (DNN)\ncalled DL-SCMA to learn to decode SCMA modulated signals corrupted by additive\nwhite Gaussian noise (AWGN). Putting encoding and decoding together, an\nautoencoder called AE-SCMA is established and trained to generate optimal SCMA\ncodewords and reconstruct original bits. Furthermore, by manipulating the\nmapping vectors, an autoencoder is able to generalize SCMA, thus a dense code\nmultiple access (DCMA) scheme is proposed. Simulations show that the DNN SCMA\ndecoder significantly outperforms the conventional message passing algorithm\n(MPA) in terms of bit error rate (BER), symbol error rate (SER) and\ncomputational complexity, and AE-SCMA also demonstrates better performances via\nconstructing better SCMA codebooks. The performance of deep learning aided DCMA\nis superior to the SCMA.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:51:08 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 01:53:07 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Lin", "Jinzhi", ""], ["Feng", "Shengzhong", ""], ["Yang", "Zhile", ""], ["Zhang", "Yun", ""], ["Zhang", "Yong", ""]]}, {"id": "1906.03193", "submitter": "Mark Grobman", "authors": "Alexander Finkelstein, Uri Almog, Mark Grobman", "title": "Fighting Quantization Bias With Bias", "comments": "Accepted to ECV workshop at CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision representation of deep neural networks (DNNs) is critical for\nefficient deployment of deep learning application on embedded platforms,\nhowever, converting the network to low precision degrades its performance.\nCrucially, networks that are designed for embedded applications usually suffer\nfrom increased degradation since they have less redundancy. This is most\nevident for the ubiquitous MobileNet architecture which requires a costly\nquantization-aware training cycle to achieve acceptable performance when\nquantized to 8-bits. In this paper, we trace the source of the degradation in\nMobileNets to a shift in the mean activation value. This shift is caused by an\ninherent bias in the quantization process which builds up across layers,\nshifting all network statistics away from the learned distribution. We show\nthat this phenomenon happens in other architectures as well. We propose a\nsimple remedy - compensating for the quantization induced shift by adding a\nconstant to the additive bias term of each channel. We develop two simple\nmethods for estimating the correction constants - one using iterative\nevaluation of the quantized network and one where the constants are set using a\nshort training phase. Both methods are fast and require only a small amount of\nunlabeled data, making them appealing for rapid deployment of neural networks.\nUsing the above methods we are able to match the performance of training-based\nquantization of MobileNets at a fraction of the cost.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:00:35 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Finkelstein", "Alexander", ""], ["Almog", "Uri", ""], ["Grobman", "Mark", ""]]}, {"id": "1906.03200", "submitter": "Dexiong Chen", "authors": "Dexiong Chen, Laurent Jacob, Julien Mairal", "title": "Recurrent Kernel Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Dec\n  2019, Vancouver, Canada", "doi": null, "report-no": "hal-02151135", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substring kernels are classical tools for representing biological sequences\nor text. However, when large amounts of annotated data are available, models\nthat allow end-to-end training such as neural networks are often preferred.\nLinks between recurrent neural networks (RNNs) and substring kernels have\nrecently been drawn, by formally showing that RNNs with specific activation\nfunctions were points in a reproducing kernel Hilbert space (RKHS). In this\npaper, we revisit this link by generalizing convolutional kernel\nnetworks---originally related to a relaxation of the mismatch kernel---to model\ngaps in sequences. It results in a new type of recurrent neural network which\ncan be trained end-to-end with backpropagation, or without supervision by using\nkernel approximation techniques. We experimentally show that our approach is\nwell suited to biological sequences, where it outperforms existing methods for\nprotein classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:08:50 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 14:51:37 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Chen", "Dexiong", ""], ["Jacob", "Laurent", ""], ["Mairal", "Julien", ""]]}, {"id": "1906.03214", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, Sridhama Prakhya, Jinyao Yan, Srinivas Turaga,\n  Kristin Branson", "title": "Importance Weighted Adversarial Variational Autoencoders for Spike\n  Inference from Calcium Imaging Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Importance Weighted Auto Encoder (IWAE) objective has been shown to\nimprove the training of generative models over the standard Variational Auto\nEncoder (VAE) objective. Here, we derive importance weighted extensions to AVB\nand AAE. These latent variable models use implicitly defined inference networks\nwhose approximate posterior density q_\\phi(z|x) cannot be directly evaluated,\nan essential ingredient for importance weighting. We show improved training and\ninference in latent variable models with our adversarially trained importance\nweighting method, and derive new theoretical connections between adversarial\ngenerative model training criteria and marginal likelihood based methods. We\napply these methods to the important problem of inferring spiking neural\nactivity from calcium imaging data, a challenging posterior inference problem\nin neuroscience, and show that posterior samples from the adversarial methods\noutperform factorized posteriors used in VAEs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:24:12 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 22:27:21 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 02:43:30 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Prakhya", "Sridhama", ""], ["Yan", "Jinyao", ""], ["Turaga", "Srinivas", ""], ["Branson", "Kristin", ""]]}, {"id": "1906.03220", "submitter": "Bert Huang", "authors": "Shuangfei Fan, Bert Huang", "title": "Labeled Graph Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new approach to train generative models, \\emph{generative adversarial\nnetworks} (GANs) have achieved considerable success in image generation. This\nframework has also recently been applied to data with graph structures. We\npropose labeled-graph generative adversarial networks (LGGAN) to train deep\ngenerative models for graph-structured data with node labels. We test the\napproach on various types of graph datasets, such as collections of citation\nnetworks and protein graphs. Experiment results show that our model can\ngenerate diverse labeled graphs that match the structural characteristics of\nthe training data and outperforms all alternative approaches in quality and\ngenerality. To further evaluate the quality of the generated graphs, we use\nthem on a downstream task of graph classification, and the results show that\nLGGAN can faithfully capture the important aspects of the graph structure.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:35:56 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:52:46 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fan", "Shuangfei", ""], ["Huang", "Bert", ""]]}, {"id": "1906.03231", "submitter": "Kevin Shi", "authors": "Kevin Shi, Daniel Hsu, Allison Bishop", "title": "A cryptographic approach to black box adversarial machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new randomized ensemble technique with a provable security\nguarantee against black-box transfer attacks. Our proof constructs a new\nsecurity problem for random binary classifiers which is easier to empirically\nverify and a reduction from the security of this new model to the security of\nthe ensemble classifier. We provide experimental evidence of the security of\nour random binary classifiers, as well as empirical results of the adversarial\naccuracy of the overall ensemble to black-box attacks. Our construction\ncrucially leverages hidden randomness in the multiclass-to-binary reduction.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:44:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 19:24:15 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shi", "Kevin", ""], ["Hsu", "Daniel", ""], ["Bishop", "Allison", ""]]}, {"id": "1906.03232", "submitter": "Brandon Da Silva", "authors": "Brandon Da Silva and Sylvie Shang Shi", "title": "Style Transfer with Time Series: Generating Synthetic Financial Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep learning models that generalize well to live deployment is a\nchallenging problem in the financial markets. The challenge arises because of\nhigh dimensionality, limited observations, changing data distributions, and a\nlow signal-to-noise ratio. High dimensionality can be dealt with using robust\nfeature selection or dimensionality reduction, but limited observations often\nresult in a model that overfits due to the large parameter space of most deep\nneural networks. We propose a generative model for financial time series, which\nallows us to train deep learning models on millions of simulated paths. We show\nthat our generative model is able to create realistic paths that embed the\nunderlying structure of the markets in a way stochastic processes cannot.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 03:33:14 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 21:27:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Da Silva", "Brandon", ""], ["Shi", "Sylvie Shang", ""]]}, {"id": "1906.03233", "submitter": "Logan Ward", "authors": "Logan Ward, Ben Blaiszik, Ian Foster, Rajeev S. Assary, Badri\n  Narayanan, Larry Curtiss", "title": "Machine Learning Prediction of Accurate Atomization Energies of Organic\n  Molecules from Low-Fidelity Quantum Chemical Calculations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies illustrate how machine learning (ML) can be used to bypass a\ncore challenge of molecular modeling: the tradeoff between accuracy and\ncomputational cost. Here, we assess multiple ML approaches for predicting the\natomization energy of organic molecules. Our resulting models learn the\ndifference between low-fidelity, B3LYP, and high-accuracy, G4MP2, atomization\nenergies, and predict the G4MP2 atomization energy to 0.005 eV (mean absolute\nerror) for molecules with less than 9 heavy atoms and 0.012 eV for a small set\nof molecules with between 10 and 14 heavy atoms. Our two best models, which\nhave different accuracy/speed tradeoffs, enable the efficient prediction of\nG4MP2-level energies for large molecules and are available through a simple web\ninterface.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:46:22 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ward", "Logan", ""], ["Blaiszik", "Ben", ""], ["Foster", "Ian", ""], ["Assary", "Rajeev S.", ""], ["Narayanan", "Badri", ""], ["Curtiss", "Larry", ""]]}, {"id": "1906.03247", "submitter": "Waldyn Martinez", "authors": "Waldyn Martinez", "title": "Ensemble Pruning via Margin Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble models refer to methods that combine a typically large number of\nclassifiers into a compound prediction. The output of an ensemble method is the\nresult of fitting a base-learning algorithm to a given data set, and obtaining\ndiverse answers by reweighting the observations or by resampling them using a\ngiven probabilistic selection. A key challenge of using ensembles in\nlarge-scale multidimensional data lies in the complexity and the computational\nburden associated with them. The models created by ensembles are often\ndifficult, if not impossible, to interpret and their implementation requires\nmore computational power than single classifiers. Recent research effort in the\nfield has concentrated in reducing ensemble size, while maintaining their\npredictive accuracy. We propose a method to prune an ensemble solution by\noptimizing its margin distribution, while increasing its diversity. The\nproposed algorithm results in an ensemble that uses only a fraction of the\noriginal classifiers, with improved or similar generalization performance. We\nanalyze and test our method on both synthetic and real data sets. The\nsimulations show that the proposed method compares favorably to the original\nensemble solutions and to other existing ensemble pruning methodologies.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:22:31 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Martinez", "Waldyn", ""]]}, {"id": "1906.03255", "submitter": "Stefan Bauer", "authors": "{\\DJ}or{\\dj}e Miladinovi\\'c and Muhammad Waleed Gondal and Bernhard\n  Sch\\\"olkopf and Joachim M. Buhmann and Stefan Bauer", "title": "Disentangled State Space Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential data often originates from diverse domains across which\nstatistical regularities and domain specifics exist. To specifically learn\ncross-domain sequence representations, we introduce disentangled state space\nmodels (DSSM) -- a class of SSM in which domain-invariant state dynamics is\nexplicitly disentangled from domain-specific information governing that\ndynamics. We analyze how such separation can improve knowledge transfer to new\ndomains, and enable robust prediction, sequence manipulation and domain\ncharacterization. We furthermore propose an unsupervised VAE-based training\nprocedure to implement DSSM in form of Bayesian filters. In our experiments, we\napplied VAE-DSSM framework to achieve competitive performance in online ODE\nsystem identification and regression across experimental settings, and\ncontrolled generation and prediction of bouncing ball video sequences across\nvarying gravitational influences.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:48:34 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Miladinovi\u0107", "\u0110or\u0111e", ""], ["Gondal", "Muhammad Waleed", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Buhmann", "Joachim M.", ""], ["Bauer", "Stefan", ""]]}, {"id": "1906.03260", "submitter": "Martin J{\\o}rgensen", "authors": "Nicki S. Detlefsen, Martin J{\\o}rgensen, S{\\o}ren Hauberg", "title": "Reliable training and estimation of variance networks", "comments": "Appeared at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate new complementary methodologies for estimating\npredictive variance networks in regression neural networks. We derive a locally\naware mini-batching scheme that result in sparse robust gradients, and show how\nto make unbiased weight updates to a variance network. Further, we formulate a\nheuristic for robustly fitting both the mean and variance networks post hoc.\nFinally, we take inspiration from posterior Gaussian processes and propose a\nnetwork architecture with similar extrapolation properties to Gaussian\nprocesses. The proposed methodologies are complementary, and improve upon\nbaseline methods individually. Experimentally, we investigate the impact on\npredictive uncertainty on multiple datasets and tasks ranging from regression,\nactive learning and generative modeling. Experiments consistently show\nsignificant improvements in predictive uncertainty estimation over\nstate-of-the-art methods across tasks and datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:14:58 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 12:29:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Detlefsen", "Nicki S.", ""], ["J\u00f8rgensen", "Martin", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "1906.03281", "submitter": "Jake Levinson", "authors": "Jake Levinson, Avneesh Sud, Ameesh Makadia", "title": "Latent feature disentanglement for 3D meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modeling of 3D shapes has become an important problem due to its\nrelevance to many applications across Computer Vision, Graphics, and VR. In\nthis paper we build upon recently introduced 3D mesh-convolutional Variational\nAutoEncoders which have shown great promise for learning rich representations\nof deformable 3D shapes. We introduce a supervised generative 3D mesh model\nthat disentangles the latent shape representation into independent generative\nfactors. Our extensive experimental analysis shows that learning an explicitly\ndisentangled representation can both improve random shape generation as well as\nsuccessfully address downstream tasks such as pose and shape transfer,\nshape-invariant temporal synchronization, and pose-invariant shape matching.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:19:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Levinson", "Jake", ""], ["Sud", "Avneesh", ""], ["Makadia", "Ameesh", ""]]}, {"id": "1906.03284", "submitter": "Matth\\\"aus Kleindessner", "authors": "Pranjal Awasthi, Matth\\\"aus Kleindessner, Jamie Morgenstern", "title": "Equalized odds postprocessing under imperfect group information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches aiming to ensure a model's fairness with respect to a\nprotected attribute (such as gender or race) assume to know the true value of\nthe attribute for every data point. In this paper, we ask to what extent\nfairness interventions can be effective even when only imperfect information\nabout the protected attribute is available. In particular, we study the\nprominent equalized odds postprocessing method of Hardt et al. (2016) under a\nperturbation of the attribute. We identify conditions on the perturbation that\nguarantee that the bias of a classifier is reduced even by running equalized\nodds with the perturbed attribute. We also study the error of the resulting\nclassifier. We empirically observe that under our identified conditions most\noften the error does not suffer from a perturbation of the protected attribute.\nFor a special case, we formally prove this observation to be true.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:26:48 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 21:35:09 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 03:39:16 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Kleindessner", "Matth\u00e4us", ""], ["Morgenstern", "Jamie", ""]]}, {"id": "1906.03288", "submitter": "Tingting Zhao", "authors": "Tingting Zhao, Zifeng Wang, Aria Masoomi, Jennifer G. Dy", "title": "Streaming Adaptive Nonparametric Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a data driven approach to perform clustering and end-to-end\nfeature learning simultaneously for streaming data that can adaptively detect\nnovel clusters in emerging data. Our approach, Adaptive Nonparametric\nVariational Autoencoder (AdapVAE), learns the cluster membership through a\nBayesian Nonparametric (BNP) modeling framework with Deep Neural Networks\n(DNNs) for feature learning. We develop a joint online variational inference\nalgorithm to learn feature representations and clustering assignments\nsimultaneously via iteratively optimizing the Evidence Lower Bound (ELBO). We\nresolve the catastrophic forgetting \\citep{kirkpatrick2017overcoming}\nchallenges with streaming data by adopting generative samples from the trained\nAdapVAE using previous data, which avoids the need of storing and reusing past\ndata. We demonstrate the advantages of our model including adaptive novel\ncluster detection without discarding useful information learned from past data,\nhigh quality sample generation and comparable clustering performance as\nend-to-end batch mode clustering methods on both image and text corpora\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:32:46 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 16:32:47 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Zhao", "Tingting", ""], ["Wang", "Zifeng", ""], ["Masoomi", "Aria", ""], ["Dy", "Jennifer G.", ""]]}, {"id": "1906.03291", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Zeyad Emam, Micah Goldblum, Liam Fowl, Justin K.\n  Terry, Furong Huang, Tom Goldstein", "title": "Understanding Generalization through Visualizations", "comments": "8 pages (excluding acknowledgments and references), 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of neural networks lies in their ability to generalize to unseen\ndata, yet the underlying reasons for this phenomenon remain elusive. Numerous\nrigorous attempts have been made to explain generalization, but available\nbounds are still quite loose, and analysis does not always lead to true\nunderstanding. The goal of this work is to make generalization more intuitive.\nUsing visualization methods, we discuss the mystery of generalization, the\ngeometry of loss landscapes, and how the curse (or, rather, the blessing) of\ndimensionality causes optimizers to settle into minima that generalize well.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:43:20 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 07:35:35 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 06:25:25 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 20:23:52 GMT"}, {"version": "v5", "created": "Sun, 28 Jun 2020 03:04:17 GMT"}, {"version": "v6", "created": "Sun, 15 Nov 2020 00:16:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Huang", "W. Ronny", ""], ["Emam", "Zeyad", ""], ["Goldblum", "Micah", ""], ["Fowl", "Liam", ""], ["Terry", "Justin K.", ""], ["Huang", "Furong", ""], ["Goldstein", "Tom", ""]]}, {"id": "1906.03292", "submitter": "Muhammad Waleed Gondal", "authors": "Muhammad Waleed Gondal and Manuel W\\\"uthrich and {\\DJ}or{\\dj}e\n  Miladinovi\\'c and Francesco Locatello and Martin Breidt and Valentin Volchkov\n  and Joel Akpo and Olivier Bachem and Bernhard Sch\\\"olkopf and Stefan Bauer", "title": "On the Transfer of Inductive Bias from Simulation to the Real World: a\n  New Disentanglement Dataset", "comments": "NeurIPS 2019 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful and compact representations with disentangled semantic\naspects is considered to be of key importance in representation learning. Since\nreal-world data is notoriously costly to collect, many recent state-of-the-art\ndisentanglement models have heavily relied on synthetic toy data-sets. In this\npaper, we propose a novel data-set which consists of over one million images of\nphysical 3D objects with seven factors of variation, such as object color,\nshape, size and position. In order to be able to control all the factors of\nvariation precisely, we built an experimental platform where the objects are\nbeing moved by a robotic arm. In addition, we provide two more datasets which\nconsist of simulations of the experimental setup. These datasets provide for\nthe first time the possibility to systematically investigate how well different\ndisentanglement methods perform on real data in comparison to simulation, and\nhow simulated data can be leveraged to build better representations of the real\nworld. We provide a first experimental study of these questions and our results\nindicate that learned models transfer poorly, but that model and hyperparameter\nselection is an effective means of transferring information to the real world.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:45:27 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 10:50:13 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 20:45:13 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gondal", "Muhammad Waleed", ""], ["W\u00fcthrich", "Manuel", ""], ["Miladinovi\u0107", "\u0110or\u0111e", ""], ["Locatello", "Francesco", ""], ["Breidt", "Martin", ""], ["Volchkov", "Valentin", ""], ["Akpo", "Joel", ""], ["Bachem", "Olivier", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "1906.03305", "submitter": "Andreea Minca", "authors": "Xin Qian, Yudong Chen, Andreea Minca", "title": "Clustering Degree-Corrected Stochastic Block Model with Outliers", "comments": "32 pages, 8 Fig", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the degree corrected stochastic block model in the presence of arbitrary\nor even adversarial outliers, we develop a convex-optimization-based clustering\nalgorithm that includes a penalization term depending on the positive deviation\nof a node from the expected number of edges to other inliers. We prove that\nunder mild conditions, this method achieves exact recovery of the underlying\nclusters. Our synthetic experiments show that our algorithm performs well on\nheterogeneous networks, and in particular those with Pareto degree\ndistributions, for which outliers have a broad range of possible degrees that\nmay enhance their adversarial power. We also demonstrate that our method allows\nfor recovery with significantly lower error rates compared to existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:28:27 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Qian", "Xin", ""], ["Chen", "Yudong", ""], ["Minca", "Andreea", ""]]}, {"id": "1906.03310", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Yizhen Wang, Kamalika Chaudhuri", "title": "Robustness for Non-Parametric Classification: A Generic Attack and\n  Defense", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially robust machine learning has received much recent attention.\nHowever, prior attacks and defenses for non-parametric classifiers have been\ndeveloped in an ad-hoc or classifier-specific basis. In this work, we take a\nholistic look at adversarial examples for non-parametric classifiers, including\nnearest neighbors, decision trees, and random forests. We provide a general\ndefense method, adversarial pruning, that works by preprocessing the dataset to\nbecome well-separated. To test our defense, we provide a novel attack that\napplies to a wide range of non-parametric classifiers. Theoretically, we derive\nan optimally robust classifier, which is analogous to the Bayes Optimal. We\nshow that adversarial pruning can be viewed as a finite sample approximation to\nthis optimal classifier. We empirically show that our defense and attack are\neither better than or competitive with prior work on non-parametric\nclassifiers. Overall, our results provide a strong and broadly-applicable\nbaseline for future work on robust non-parametrics. Code available at\nhttps://github.com/yangarbiter/adversarial-nonparametrics/ .\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:45:52 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 23:12:27 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Wang", "Yizhen", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1906.03317", "submitter": "Saied Mahdian", "authors": "Saied Mahdian, Jose Blanchet, Peter Glynn", "title": "Optimal Transport Relaxations with Application to Wasserstein GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of relaxations of the optimal transport problem which\nregularize the problem by introducing an additional minimization step over a\nsmall region around one of the underlying transporting measures. The type of\nregularization that we obtain is related to smoothing techniques studied in the\noptimization literature. When using our approach to estimate optimal transport\ncosts based on empirical measures, we obtain statistical learning bounds which\nare useful to guide the amount of regularization, while maintaining good\ngeneralization properties. To illustrate the computational advantages of our\nregularization approach, we apply our method to training Wasserstein GANs. We\nobtain running time improvements, relative to current benchmarks, with no\ndeterioration in testing performance (via FID). The running time improvement\noccurs because our new optimality-based threshold criterion reduces the number\nof expensive iterates of the generating networks, while increasing the number\nof actor-critic iterations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:01:56 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Mahdian", "Saied", ""], ["Blanchet", "Jose", ""], ["Glynn", "Peter", ""]]}, {"id": "1906.03318", "submitter": "Stephen Keeley", "authors": "Stephen L. Keeley, David M. Zoltowski, Yiyi Yu, Jacob L. Yates,\n  Spencer L. Smith, Jonathan W. Pillow", "title": "Efficient non-conjugate Gaussian process factor models for spike count\n  data using polynomial approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Gaussian Process Factor Analysis (GPFA) has been broadly applied to the\nproblem of identifying smooth, low-dimensional temporal structure underlying\nlarge-scale neural recordings. However, spike trains are non-Gaussian, which\nmotivates combining GPFA with discrete observation models for binned spike\ncount data. The drawback to this approach is that GPFA priors are not conjugate\nto count model likelihoods, which makes inference challenging. Here we address\nthis obstacle by introducing a fast, approximate inference method for\nnon-conjugate GPFA models. Our approach uses orthogonal second-order\npolynomials to approximate the nonlinear terms in the non-conjugate\nlog-likelihood, resulting in a method we refer to as \\textit{polynomial\napproximate log-likelihood} (PAL) estimators. This approximation allows for\naccurate closed-form evaluation of marginal likelihoods and fast numerical\noptimization for parameters and hyperparameters. We derive PAL estimators for\nGPFA models with binomial, Poisson, and negative binomial observations and find\nthe PAL estimation is highly accurate, and achieves faster convergence times\ncompared to existing state-of-the-art inference methods. We also find that PAL\nhyperparameters can provide sensible initialization for black box variational\ninference (BBVI), which improves BBVI accuracy. We demonstrate that PAL\nestimators achieve fast and accurate extraction of latent structure from\nmulti-neuron spike train data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:15:00 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 21:44:50 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Keeley", "Stephen L.", ""], ["Zoltowski", "David M.", ""], ["Yu", "Yiyi", ""], ["Yates", "Jacob L.", ""], ["Smith", "Spencer L.", ""], ["Pillow", "Jonathan W.", ""]]}, {"id": "1906.03323", "submitter": "Nikos Karampatziakis", "authors": "Nikos Karampatziakis, John Langford, Paul Mineiro", "title": "Empirical Likelihood for Contextual Bandits", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an estimator and confidence interval for computing the value of a\npolicy from off-policy data in the contextual bandit setting. To this end we\napply empirical likelihood techniques to formulate our estimator and confidence\ninterval as simple convex optimization problems. Using the lower bound of our\nconfidence interval, we then propose an off-policy policy optimization\nalgorithm that searches for policies with large reward lower bound. We\nempirically find that both our estimator and confidence interval improve over\nprevious proposals in finite sample regimes. Finally, the policy optimization\nalgorithm we propose outperforms a strong baseline system for learning from\noff-policy data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:26:18 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 21:02:02 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 23:09:08 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 06:30:28 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Karampatziakis", "Nikos", ""], ["Langford", "John", ""], ["Mineiro", "Paul", ""]]}, {"id": "1906.03329", "submitter": "Trevor Campbell", "authors": "Trevor Campbell and Boyan Beronov", "title": "Sparse Variational Inference: Bayesian Coresets from Scratch", "comments": "In Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of automated inference algorithms in Bayesian statistics\nhas provided practitioners newfound access to fast, reproducible data analysis\nand powerful statistical models. Designing automated methods that are also both\ncomputationally scalable and theoretically sound, however, remains a\nsignificant challenge. Recent work on Bayesian coresets takes the approach of\ncompressing the dataset before running a standard inference algorithm,\nproviding both scalability and guarantees on posterior approximation error. But\nthe automation of past coreset methods is limited because they depend on the\navailability of a reasonable coarse posterior approximation, which is difficult\nto specify in practice. In the present work we remove this requirement by\nformulating coreset construction as sparsity-constrained variational inference\nwithin an exponential family. This perspective leads to a novel construction\nvia greedy optimization, and also provides a unifying information-geometric\nview of present and past methods. The proposed Riemannian coreset construction\nalgorithm is fully automated, requiring no problem-specific inputs aside from\nthe probabilistic model and dataset. In addition to being significantly easier\nto use than past methods, experiments demonstrate that past coreset\nconstructions are fundamentally limited by the fixed coarse posterior\napproximation; in contrast, the proposed algorithm is able to continually\nimprove the coreset, providing state-of-the-art Bayesian dataset summarization\nwith orders-of-magnitude reduction in KL divergence to the exact posterior.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:54:35 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 08:33:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Campbell", "Trevor", ""], ["Beronov", "Boyan", ""]]}, {"id": "1906.03333", "submitter": "Fanyou Wu", "authors": "Fanyou Wu, Rado Gazo, Eva Haviarova, Bedrich Benes", "title": "Efficient Project Gradient Descent for Ensemble Adversarial Attack", "comments": "6 pages, 2 figures, submit to IJCAI 19 AIBS workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances show that deep neural networks are not robust to deliberately\ncrafted adversarial examples which many are generated by adding human\nimperceptible perturbation to clear input. Consider $l_2$ norms attacks,\nProject Gradient Descent (PGD) and the Carlini and Wagner (C\\&W) attacks are\nthe two main methods, where PGD control max perturbation for adversarial\nexamples while C\\&W approach treats perturbation as a regularization term\noptimized it with loss function together. If we carefully set parameters for\nany individual input, both methods become similar. In general, PGD attacks\nperform faster but obtains larger perturbation to find adversarial examples\nthan the C\\&W when fixing the parameters for all inputs. In this report, we\npropose an efficient modified PGD method for attacking ensemble models by\nautomatically changing ensemble weights and step size per iteration per input.\nThis method generates smaller perturbation adversarial examples than PGD method\nwhile remains efficient as compared to C\\&W method. Our method won the first\nplace in IJCAI19 Targeted Adversarial Attack competition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 21:07:02 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wu", "Fanyou", ""], ["Gazo", "Rado", ""], ["Haviarova", "Eva", ""], ["Benes", "Bedrich", ""]]}, {"id": "1906.03336", "submitter": "Kayla Frisoli", "authors": "Xiao Hui Tai, Kayla Frisoli", "title": "Benchmarking Minimax Linkage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax linkage was first introduced by Ao et al. [3] in 2004, as an\nalternative to standard linkage methods used in hierarchical clustering.\nMinimax linkage relies on distances to a prototype for each cluster; this\nprototype can be thought of as a representative object in the cluster, hence\nimproving the interpretability of clustering results. Bien and Tibshirani\nanalyzed properties of this method in 2011 [2], popularizing the method within\nthe statistics community. Additionally, they performed comparisons of minimax\nlinkage to standard linkage methods, making use of five data sets and two\ndifferent evaluation metrics (distance to prototype and misclassification\nrate). In an effort to expand upon their work and evaluate minimax linkage more\ncomprehensively, our benchmark study focuses on thorough method evaluation via\nmultiple performance metrics on several well-described data sets. We also make\nall code and data publicly available through an R package, for full\nreproducibility. Similarly to [2], we find that minimax linkage often produces\nthe smallest maximum minimax radius of all linkage methods, meaning that\nminimax linkage produces clusters where objects in a cluster are tightly\nclustered around their prototype. This is true across a range of values for the\ntotal number of clusters (k). However, this is not always the case, and special\nattention should be paid to the case when k is the true known value. For true\nk, minimax linkage does not always perform the best in terms of all the\nevaluation metrics studied, including maximum minimax radius. This paper was\nmotivated by the IFCS Cluster Benchmarking Task Force's call for clustering\nbenchmark studies and the white paper [5], which put forth guidelines and\nprinciples for comprehensive benchmarking in clustering. Our work is designed\nto be a neutral benchmark study of minimax linkage.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 21:25:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tai", "Xiao Hui", ""], ["Frisoli", "Kayla", ""]]}, {"id": "1906.03351", "submitter": "Marc'Aurelio Ranzato", "authors": "Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marc'Aurelio\n  Ranzato, Arthur Szlam", "title": "Real or Fake? Learning to Discriminate Machine from Human Generated Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs), a.k.a. un-normalized models, have had recent\nsuccesses in continuous spaces. However, they have not been successfully\napplied to model text sequences. While decreasing the energy at training\nsamples is straightforward, mining (negative) samples where the energy should\nbe increased is difficult. In part, this is because standard gradient-based\nmethods are not readily applicable when the input is high-dimensional and\ndiscrete. Here, we side-step this issue by generating negatives using\npre-trained auto-regressive language models. The EBM then works in the residual\nof the language model; and is trained to discriminate real text from text\ngenerated by the auto-regressive models. We investigate the generalization\nability of residual EBMs, a pre-requisite for using them in other applications.\nWe extensively analyze generalization for the task of classifying whether an\ninput is machine or human generated, a natural task given the training loss and\nhow we mine negatives. Overall, we observe that EBMs can generalize remarkably\nwell to changes in the architecture of the generators producing negatives.\nHowever, EBMs exhibit more sensitivity to the training set used by such\ngenerators.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 22:45:33 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 16:21:00 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bakhtin", "Anton", ""], ["Gross", "Sam", ""], ["Ott", "Myle", ""], ["Deng", "Yuntian", ""], ["Ranzato", "Marc'Aurelio", ""], ["Szlam", "Arthur", ""]]}, {"id": "1906.03352", "submitter": "Allan Zhou", "authors": "Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari,\n  Paul Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, Chelsea Finn", "title": "Watch, Try, Learn: Meta-Learning from Demonstrations and Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning allows agents to learn complex behaviors from\ndemonstrations. However, learning a complex vision-based task may require an\nimpractical number of demonstrations. Meta-imitation learning is a promising\napproach towards enabling agents to learn a new task from one or a few\ndemonstrations by leveraging experience from learning similar tasks. In the\npresence of task ambiguity or unobserved dynamics, demonstrations alone may not\nprovide enough information; an agent must also try the task to successfully\ninfer a policy. In this work, we propose a method that can learn to learn from\nboth demonstrations and trial-and-error experience with sparse reward feedback.\nIn comparison to meta-imitation, this approach enables the agent to effectively\nand efficiently improve itself autonomously beyond the demonstration data. In\ncomparison to meta-reinforcement learning, we can scale to substantially\nbroader distributions of tasks, as the demonstration reduces the burden of\nexploration. Our experiments show that our method significantly outperforms\nprior approaches on a set of challenging, vision-based control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 22:46:35 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 16:21:21 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 03:06:23 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 23:13:01 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhou", "Allan", ""], ["Jang", "Eric", ""], ["Kappler", "Daniel", ""], ["Herzog", "Alex", ""], ["Khansari", "Mohi", ""], ["Wohlhart", "Paul", ""], ["Bai", "Yunfei", ""], ["Kalakrishnan", "Mrinal", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1906.03361", "submitter": "Ehsan Amid", "authors": "Ehsan Amid, Manfred K. Warmuth, Rohan Anil, Tomer Koren", "title": "Robust Bi-Tempered Logistic Loss Based on Bregman Divergences", "comments": null, "journal-ref": "Neural Information Processing Systems 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a temperature into the exponential function and replace the\nsoftmax output layer of neural nets by a high temperature generalization.\nSimilarly, the logarithm in the log loss we use for training is replaced by a\nlow temperature logarithm. By tuning the two temperatures we create loss\nfunctions that are non-convex already in the single layer case. When replacing\nthe last layer of the neural nets by our bi-temperature generalization of\nlogistic loss, the training becomes more robust to noise. We visualize the\neffect of tuning the two temperatures in a simple setting and show the efficacy\nof our method on large data sets. Our methodology is based on Bregman\ndivergences and is superior to a related two-temperature method using the\nTsallis divergence.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 00:08:38 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 21:13:27 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 16:08:54 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""], ["Anil", "Rohan", ""], ["Koren", "Tomer", ""]]}, {"id": "1906.03362", "submitter": "Sinong Geng", "authors": "Sinong Geng, Minhao Yan, Mladen Kolar, and Oluwasanmi Koyejo", "title": "Partially Linear Additive Gaussian Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a partially linear additive Gaussian graphical model (PLA-GGM) for\nthe estimation of associations between random variables distorted by observed\nconfounders. Model parameters are estimated using an $L_1$-regularized maximal\npseudo-profile likelihood estimator (MaPPLE) for which we prove\n$\\sqrt{n}$-sparsistency. Importantly, our approach avoids parametric\nconstraints on the effects of confounders on the estimated graphical model\nstructure. Empirically, the PLA-GGM is applied to both synthetic and real-world\ndatasets, demonstrating superior performance compared to competing methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 00:30:53 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Geng", "Sinong", ""], ["Yan", "Minhao", ""], ["Kolar", "Mladen", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1906.03364", "submitter": "Dheeraj Baby", "authors": "Dheeraj Baby and Yu-Xiang Wang", "title": "Online Forecasting of Total-Variation-bounded Sequences", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of online forecasting of sequences of length $n$ with\ntotal-variation at most $C_n$ using observations contaminated by independent\n$\\sigma$-subgaussian noise. We design an $O(n\\log n)$-time algorithm that\nachieves a cumulative square error of $\\tilde{O}(n^{1/3}C_n^{2/3}\\sigma^{4/3} +\nC_n^2)$ with high probability.We also prove a lower bound that matches the\nupper bound in all parameters (up to a $\\log(n)$ factor). To the best of our\nknowledge, this is the first \\emph{polynomial-time} algorithm that achieves the\noptimal $O(n^{1/3})$ rate in forecasting total variation bounded sequences and\nthe first algorithm that \\emph{adapts to unknown} $C_n$. Our proof techniques\nleverage the special localized structure of Haar wavelet basis and the\nadaptivity to unknown smoothness parameters in the classical wavelet smoothing\n[Donoho et al., 1998]. We also compare our model to the rich literature of\ndynamic regret minimization and nonstationary stochastic optimization, where\nour problem can be treated as a special case. We show that the workhorse in\nthose settings --- online gradient descent and its variants with a fixed\nrestarting schedule --- are instances of a class of \\emph{linear forecasters}\nthat require a suboptimal regret of $\\tilde{\\Omega}(\\sqrt{n})$. This implies\nthat the use of more adaptive algorithms is necessary to obtain the optimal\nrate.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 00:48:26 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 21:55:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Baby", "Dheeraj", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1906.03367", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Jonathon Shlens, Jascha\n  Sohl-Dickstein, Ekin D. Cubuk", "title": "Using learned optimizers to make models robust to input noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the art vision models can achieve superhuman performance on image\nclassification tasks when testing and training data come from the same\ndistribution. However, when models are tested on corrupted images (e.g. due to\nscale changes, translations, or shifts in brightness or contrast), performance\ndegrades significantly. Here, we explore the possibility of meta-training a\nlearned optimizer that can train image classification models such that they are\nrobust to common image corruptions. Specifically, we are interested training\nmodels that are more robust to noise distributions not present in the training\ndata. We find that a learned optimizer meta-trained to produce models which are\nrobust to Gaussian noise trains models that are more robust to Gaussian noise\nat other scales compared to traditional optimizers like Adam. The effect of\nmeta-training is more complicated when targeting a more general set of noise\ndistributions, but led to improved performance on half of held-out corruption\ntasks. Our results suggest that meta-learning provides a novel approach for\nstudying and improving the robustness of deep learning models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 01:08:36 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Shlens", "Jonathon", ""], ["Sohl-Dickstein", "Jascha", ""], ["Cubuk", "Ekin D.", ""]]}, {"id": "1906.03374", "submitter": "Galit Shmueli", "authors": "Galit Shmueli", "title": "Lift Up and Act! Classifier Performance in Resource-Constrained\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification tasks are common across many fields and applications where the\ndecision maker's action is limited by resource constraints. In direct marketing\nonly a subset of customers is contacted; scarce human resources limit the\nnumber of interviews to the most promising job candidates; limited donated\norgans are prioritized to those with best fit. In such scenarios, performance\nmeasures such as the classification matrix, ROC analysis, and even ranking\nmetrics such as AUC measures outcomes different from the action of interest. At\nthe same time, gains and lift that do measure the relevant outcome are rarely\nused by machine learners. In this paper we define resource-constrained\nclassifier performance as a task distinguished from classification and ranking.\nWe explain how gains and lift can lead to different algorithm choices and\ndiscuss the effect of class distribution.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 02:34:50 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 06:44:58 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shmueli", "Galit", ""]]}, {"id": "1906.03393", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Yifei Ma, Yu-Xiang Wang", "title": "Towards Optimal Off-Policy Evaluation for Reinforcement Learning with\n  Marginalized Importance Sampling", "comments": "Published at the Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the many real-world applications of reinforcement learning (RL)\nthat require safe-policy iterations, we consider the problem of off-policy\nevaluation (OPE) -- the problem of evaluating a new policy using the historical\ndata obtained by different behavior policies -- under the model of\nnonstationary episodic Markov Decision Processes (MDP) with a long horizon and\na large action space. Existing importance sampling (IS) methods often suffer\nfrom large variance that depends exponentially on the RL horizon $H$. To solve\nthis problem, we consider a marginalized importance sampling (MIS) estimator\nthat recursively estimates the state marginal distribution for the target\npolicy at every step. MIS achieves a mean-squared error of $$ \\frac{1}{n}\n\\sum\\nolimits_{t=1}^H\\mathbb{E}_{\\mu}\\left[\\frac{d_t^\\pi(s_t)^2}{d_t^\\mu(s_t)^2}\n\\mathrm{Var}_{\\mu}\\left[\\frac{\\pi_t(a_t|s_t)}{\\mu_t(a_t|s_t)}\\big(\nV_{t+1}^\\pi(s_{t+1}) + r_t\\big) \\middle| s_t\\right]\\right] +\n\\tilde{O}(n^{-1.5}) $$ where $\\mu$ and $\\pi$ are the logging and target\npolicies, $d_t^{\\mu}(s_t)$ and $d_t^{\\pi}(s_t)$ are the marginal distribution\nof the state at $t$th step, $H$ is the horizon, $n$ is the sample size and\n$V_{t+1}^\\pi$ is the value function of the MDP under $\\pi$. The result matches\nthe Cramer-Rao lower bound in \\citet{jiang2016doubly} up to a multiplicative\nfactor of $H$. To the best of our knowledge, this is the first OPE estimation\nerror bound with a polynomial dependence on $H$. Besides theory, we show\nempirical superiority of our method in time-varying, partially observable, and\nlong-horizon RL environments.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 05:15:34 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 01:35:04 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 03:31:06 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 02:16:55 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xie", "Tengyang", ""], ["Ma", "Yifei", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1906.03397", "submitter": "Mika Juuti Mr", "authors": "Mika Juuti, Buse Gul Atli, N. Asokan", "title": "Making targeted black-box evasion attacks effective and efficient", "comments": "12 pages, 10 figures", "journal-ref": "AISec 2019: Proceedings of the 12th ACM Workshop on Artificial\n  Intelligence and Security", "doi": "10.1145/3338501.3357366", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how an adversary can optimally use its query budget for\ntargeted evasion attacks against deep neural networks in a black-box setting.\nWe formalize the problem setting and systematically evaluate what benefits the\nadversary can gain by using substitute models. We show that there is an\nexploration-exploitation tradeoff in that query efficiency comes at the cost of\neffectiveness. We present two new attack strategies for using substitute models\nand show that they are as effective as previous query-only techniques but\nrequire significantly fewer queries, by up to three orders of magnitude. We\nalso show that an agile adversary capable of switching through different attack\ntechniques can achieve pareto-optimal efficiency. We demonstrate our attack\nagainst Google Cloud Vision showing that the difficulty of black-box attacks\nagainst real-world prediction APIs is significantly easier than previously\nthought (requiring approximately 500 queries instead of approximately 20,000 as\nin previous works).\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 06:22:25 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Juuti", "Mika", ""], ["Atli", "Buse Gul", ""], ["Asokan", "N.", ""]]}, {"id": "1906.03401", "submitter": "Preetam Nandy", "authors": "Kinjal Basu and Preetam Nandy", "title": "Optimal Convergence for Stochastic Optimization with Multiple\n  Expectation Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the problem of stochastic optimization where the\nobjective function can be written as an expectation function over a closed\nconvex set. We also consider multiple expectation constraints which restrict\nthe domain of the problem. We extend the cooperative stochastic approximation\nalgorithm from Lan and Zhou [2016] to solve the particular problem. We close\nthe gaps in the previous analysis and provide a novel proof technique to show\nthat our algorithm attains the optimal rate of convergence for both optimality\ngap and constraint violation when the functions are generally convex. We also\ncompare our algorithm empirically to the state-of-the-art and show improved\nconvergence in many situations.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 06:56:39 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 17:08:45 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Basu", "Kinjal", ""], ["Nandy", "Preetam", ""]]}, {"id": "1906.03412", "submitter": "Xavier Bresson", "authors": "Xavier Bresson and Thomas Laurent", "title": "A Two-Step Graph Convolutional Decoder for Molecule Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple auto-encoder framework for molecule generation. The\nmolecular graph is first encoded into a continuous latent representation $z$,\nwhich is then decoded back to a molecule. The encoding process is easy, but the\ndecoding process remains challenging. In this work, we introduce a simple\ntwo-step decoding process. In a first step, a fully connected neural network\nuses the latent vector $z$ to produce a molecular formula, for example CO$_2$\n(one carbon and two oxygen atoms). In a second step, a graph convolutional\nneural network uses the same latent vector $z$ to place bonds between the atoms\nthat were produced in the first step (for example a double bond will be placed\nbetween the carbon and each of the oxygens). This two-step process, in which a\nbag of atoms is first generated, and then assembled, provides a simple\nframework that allows us to develop an efficient molecule auto-encoder.\nNumerical experiments on basic tasks such as novelty, uniqueness, validity and\noptimized chemical property for the 250k ZINC molecules demonstrate the\nperformances of the proposed system. Particularly, we achieve the highest\nreconstruction rate of 90.5\\%, improving the previous rate of 76.7\\%. We also\nreport the best property improvement results when optimization is constrained\nby the molecular distance between the original and generated molecules.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 07:59:26 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 16:11:45 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bresson", "Xavier", ""], ["Laurent", "Thomas", ""]]}, {"id": "1906.03455", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, Emil C. Lupu", "title": "Sensitivity of Deep Convolutional Networks to Gabor Noise", "comments": "Accepted to ICML 2019 Workshop on Identifying and Understanding Deep\n  Learning Phenomena", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Networks (DCNs) have been shown to be sensitive to\nUniversal Adversarial Perturbations (UAPs): input-agnostic perturbations that\nfool a model on large portions of a dataset. These UAPs exhibit interesting\nvisual patterns, but this phenomena is, as yet, poorly understood. Our work\nshows that visually similar procedural noise patterns also act as UAPs. In\nparticular, we demonstrate that different DCN architectures are sensitive to\nGabor noise patterns. This behaviour, its causes, and implications deserve\nfurther in-depth study.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 13:41:38 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 02:57:48 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1906.03471", "submitter": "Matus Telgarsky", "authors": "Yucheng Chen, Matus Telgarsky, Chao Zhang, Bolton Bailey, Daniel Hsu,\n  Jian Peng", "title": "A gradual, semi-discrete approach to generative network training via\n  explicit Wasserstein minimization", "comments": "Appears in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a simple procedure to fit generative networks to target\ndistributions, with the goal of a small Wasserstein distance (or other optimal\ntransport costs). The approach is based on two principles: (a) if the source\nrandomness of the network is a continuous distribution (the \"semi-discrete\"\nsetting), then the Wasserstein distance is realized by a deterministic optimal\ntransport mapping; (b) given an optimal transport mapping between a generator\nnetwork and a target distribution, the Wasserstein distance may be decreased\nvia a regression between the generated data and the mapped target points. The\nprocedure here therefore alternates these two steps, forming an optimal\ntransport and regressing against it, gradually adjusting the generator network\ntowards the target distribution. Mathematically, this approach is shown to\nminimize the Wasserstein distance to both the empirical target distribution,\nand also its underlying population counterpart. Empirically, good performance\nis demonstrated on the training and testing sets of the MNIST and Thin-8 data.\nThe paper closes with a discussion of the unsuitability of the Wasserstein\ndistance for certain tasks, as has been identified in prior work [Arora et al.,\n2017, Huang et al., 2017].\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 14:42:54 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 15:00:09 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Chen", "Yucheng", ""], ["Telgarsky", "Matus", ""], ["Zhang", "Chao", ""], ["Bailey", "Bolton", ""], ["Hsu", "Daniel", ""], ["Peng", "Jian", ""]]}, {"id": "1906.03479", "submitter": "Shubhankar Deshpande", "authors": "Shubhankar Deshpande, Brian D. Bue, David R. Thompson, Vijay Natraj,\n  Mario Parente", "title": "Learning Radiative Transfer Models for Climate Change Applications in\n  Imaging Spectroscopy", "comments": "Accepted to International Conference on Machine Learning (ICML) 2019\n  Workshop: Climate Change: How Can AI Help?", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to a recent investigation, an estimated 33-50% of the world's coral\nreefs have undergone degradation, believed to be as a result of climate change.\nA strong driver of climate change and the subsequent environmental impact are\ngreenhouse gases such as methane. However, the exact relation climate change\nhas to the environmental condition cannot be easily established. Remote sensing\nmethods are increasingly being used to quantify and draw connections between\nrapidly changing climatic conditions and environmental impact. A crucial part\nof this analysis is processing spectroscopy data using radiative transfer\nmodels (RTMs) which is a computationally expensive process and limits their use\nwith high volume imaging spectrometers. This work presents an algorithm that\ncan efficiently emulate RTMs using neural networks leading to a multifold\nspeedup in processing time, and yielding multiple downstream benefits.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 15:39:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Deshpande", "Shubhankar", ""], ["Bue", "Brian D.", ""], ["Thompson", "David R.", ""], ["Natraj", "Vijay", ""], ["Parente", "Mario", ""]]}, {"id": "1906.03499", "submitter": "Puyudi Yang", "authors": "Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I.\n  Jordan", "title": "ML-LOO: Detecting Adversarial Examples with Feature Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks obtain state-of-the-art performance on a series of\ntasks. However, they are easily fooled by adding a small adversarial\nperturbation to input. The perturbation is often human imperceptible on image\ndata. We observe a significant difference in feature attributions of\nadversarially crafted examples from those of original ones. Based on this\nobservation, we introduce a new framework to detect adversarial examples\nthrough thresholding a scale estimate of feature attribution scores.\nFurthermore, we extend our method to include multi-layer feature attributions\nin order to tackle the attacks with mixed confidence levels. Through vast\nexperiments, our method achieves superior performances in distinguishing\nadversarial examples from popular attack methods on a variety of real data sets\namong state-of-the-art detection methods. In particular, our method is able to\ndetect adversarial examples of mixed confidence levels, and transfer between\ndifferent attacking methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 18:36:16 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Yang", "Puyudi", ""], ["Chen", "Jianbo", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Jane-Ling", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.03502", "submitter": "Vinod Kumar Kurmi", "authors": "Vinod Kumar Kurmi, Shanu Kumar and Vinay P Namboodiri", "title": "Attending to Discriminative Certainty for Domain Adaptation", "comments": "CVPR 2019 Accepted, Project: https://delta-lab-iitk.github.io/CADA/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we aim to solve for unsupervised domain adaptation of\nclassifiers where we have access to label information for the source domain\nwhile these are not available for a target domain. While various methods have\nbeen proposed for solving these including adversarial discriminator based\nmethods, most approaches have focused on the entire image based domain\nadaptation. In an image, there would be regions that can be adapted better, for\ninstance, the foreground object may be similar in nature. To obtain such\nregions, we propose methods that consider the probabilistic certainty estimate\nof various regions and specify focus on these during classification for\nadaptation. We observe that just by incorporating the probabilistic certainty\nof the discriminator while training the classifier, we are able to obtain state\nof the art results on various datasets as compared against all the recent\nmethods. We provide a thorough empirical analysis of the method by providing\nablation analysis, statistical significance test, and visualization of the\nattention maps and t-SNE embeddings. These evaluations convincingly demonstrate\nthe effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:04:38 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 14:51:38 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kurmi", "Vinod Kumar", ""], ["Kumar", "Shanu", ""], ["Namboodiri", "Vinay P", ""]]}, {"id": "1906.03504", "submitter": "Michael Iuzzolino", "authors": "Michael Iuzzolino, Yoram Singer, Michael C. Mozer", "title": "Convolutional Bipartite Attractor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human perception and cognition, a fundamental operation that brains\nperform is interpretation: constructing coherent neural states from noisy,\nincomplete, and intrinsically ambiguous evidence. The problem of interpretation\nis well matched to an early and often overlooked architecture, the attractor\nnetwork---a recurrent neural net that performs constraint satisfaction,\nimputation of missing features, and clean up of noisy data via energy\nminimization dynamics. We revisit attractor nets in light of modern deep\nlearning methods and propose a convolutional bipartite architecture with a\nnovel training loss, activation function, and connectivity constraints. We\ntackle larger problems than have been previously explored with attractor nets\nand demonstrate their potential for image completion and super-resolution. We\nargue that this architecture is better motivated than ever-deeper feedforward\nmodels and is a viable alternative to more costly sampling-based generative\nmethods on a range of supervised and unsupervised tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:13:26 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 03:20:12 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 23:39:37 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Iuzzolino", "Michael", ""], ["Singer", "Yoram", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1906.03509", "submitter": "Aristotelis Papadopoulos", "authors": "Aristotelis-Angelos Papadopoulos, Mohammad Reza Rajati, Nazim Shaikh,\n  Jiamian Wang", "title": "Outlier Exposure with Confidence Control for Out-of-Distribution\n  Detection", "comments": "Accepted as a Journal paper at Neurocomputing. PyTorch code available\n  at https://github.com/nazim1021/OOD-detection-using-OECC", "journal-ref": "Neurocomputing 441 (2021) 138-150", "doi": "10.1016/j.neucom.2021.02.007", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved great success in classification tasks\nduring the last years. However, one major problem to the path towards\nartificial intelligence is the inability of neural networks to accurately\ndetect samples from novel class distributions and therefore, most of the\nexistent classification algorithms assume that all classes are known prior to\nthe training stage. In this work, we propose a methodology for training a\nneural network that allows it to efficiently detect out-of-distribution (OOD)\nexamples without compromising much of its classification accuracy on the test\nexamples from known classes. We propose a novel loss function that gives rise\nto a novel method, Outlier Exposure with Confidence Control (OECC), which\nachieves superior results in OOD detection with OE both on image and text\nclassification tasks without requiring access to OOD samples. Additionally, we\nexperimentally show that the combination of OECC with state-of-the-art\npost-training OOD detection methods, like the Mahalanobis Detector (MD) and the\nGramian Matrices (GM) methods, further improves their performance in the OOD\ndetection task, demonstrating the potential of combining training and\npost-training methods for OOD detection.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:30:24 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 19:55:12 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 01:52:26 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 22:31:14 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Papadopoulos", "Aristotelis-Angelos", ""], ["Rajati", "Mohammad Reza", ""], ["Shaikh", "Nazim", ""], ["Wang", "Jiamian", ""]]}, {"id": "1906.03518", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Aditi Raghunathan, Percy Liang", "title": "Maximum Weighted Loss Discrepancy", "comments": "ICLR 2019 Workshop. Safe Machine Learning: Specification, Robustness,\n  and Assurance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though machine learning algorithms excel at minimizing the average loss over\na population, this might lead to large discrepancies between the losses across\ngroups within the population. To capture this inequality, we introduce and\nstudy a notion we call maximum weighted loss discrepancy (MWLD), the maximum\n(weighted) difference between the loss of a group and the loss of the\npopulation. We relate MWLD to group fairness notions and robustness to\ndemographic shifts. We then show MWLD satisfies the following three properties:\n1) It is statistically impossible to estimate MWLD when all groups have equal\nweights. 2) For a particular family of weighting functions, we can estimate\nMWLD efficiently. 3) MWLD is related to loss variance, a quantity that arises\nin generalization bounds. We estimate MWLD with different weighting functions\non four common datasets from the fairness literature. We finally show that loss\nvariance regularization can halve the loss variance of a classifier and hence\nreduce MWLD without suffering a significant drop in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 20:25:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Khani", "Fereshte", ""], ["Raghunathan", "Aditi", ""], ["Liang", "Percy", ""]]}, {"id": "1906.03526", "submitter": "Maksym Andriushchenko", "authors": "Maksym Andriushchenko, Matthias Hein", "title": "Provably Robust Boosted Decision Stumps and Trees against Adversarial\n  Attacks", "comments": "Camera-ready version (accepted at NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial robustness has been studied extensively for neural\nnetworks. However, for boosted decision trees and decision stumps there are\nalmost no results, even though they are widely used in practice (e.g. XGBoost)\ndue to their accuracy, interpretability, and efficiency. We show in this paper\nthat for boosted decision stumps the \\textit{exact} min-max robust loss and\ntest error for an $l_\\infty$-attack can be computed in $O(T\\log T)$ time per\ninput, where $T$ is the number of decision stumps and the optimal update step\nof the ensemble can be done in $O(n^2\\,T\\log T)$, where $n$ is the number of\ndata points. For boosted trees we show how to efficiently calculate and\noptimize an upper bound on the robust loss, which leads to state-of-the-art\nrobust test error for boosted trees on MNIST (12.5% for $\\epsilon_\\infty=0.3$),\nFMNIST (23.2% for $\\epsilon_\\infty=0.1$), and CIFAR-10 (74.7% for\n$\\epsilon_\\infty=8/255$). Moreover, the robust test error rates we achieve are\ncompetitive to the ones of provably robust convolutional networks. The code of\nall our experiments is available at\nhttp://github.com/max-andr/provably-robust-boosting\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 21:44:34 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:57:31 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Andriushchenko", "Maksym", ""], ["Hein", "Matthias", ""]]}, {"id": "1906.03532", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M. R. Arnold, Pierre-Antoine Manzagol, Reza Babanezhad,\n  Ioannis Mitliagkas, Nicolas Le Roux", "title": "Reducing the variance in online optimization by transporting past\n  gradients", "comments": "Open-source implementation available at:\n  https://github.com/seba-1511/igt.pth", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most stochastic optimization methods use gradients once before discarding\nthem. While variance reduction methods have shown that reusing past gradients\ncan be beneficial when there is a finite number of datapoints, they do not\neasily extend to the online setting. One issue is the staleness due to using\npast gradients. We propose to correct this staleness using the idea of implicit\ngradient transport (IGT) which transforms gradients computed at previous\niterates into gradients evaluated at the current iterate without using the\nHessian explicitly. In addition to reducing the variance and bias of our\nupdates over time, IGT can be used as a drop-in replacement for the gradient\nestimate in a number of well-understood methods such as heavy ball or Adam. We\nshow experimentally that it achieves state-of-the-art results on a wide range\nof architectures and benchmarks. Additionally, the IGT gradient estimator\nyields the optimal asymptotic convergence rate for online stochastic\noptimization in the restricted setting where the Hessians of all component\nfunctions are equal.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 22:02:28 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 17:12:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Manzagol", "Pierre-Antoine", ""], ["Babanezhad", "Reza", ""], ["Mitliagkas", "Ioannis", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "1906.03533", "submitter": "Patrick Hall", "authors": "Patrick Hall and Navdeep Gill and Nicholas Schmidt", "title": "Proposed Guidelines for the Responsible Use of Explainable Machine\n  Learning", "comments": "Errata and updates available here:\n  https://github.com/jphall663/responsible_xai", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable machine learning (ML) enables human learning from ML, human\nappeal of automated model decisions, regulatory compliance, and security audits\nof ML models. Explainable ML (i.e. explainable artificial intelligence or XAI)\nhas been implemented in numerous open source and commercial packages and\nexplainable ML is also an important, mandatory, or embedded aspect of\ncommercial predictive modeling in industries like financial services. However,\nlike many technologies, explainable ML can be misused, particularly as a faulty\nsafeguard for harmful black-boxes, e.g. fairwashing or scaffolding, and for\nother malevolent purposes like stealing models and sensitive training data. To\npromote best-practice discussions for this already in-flight technology, this\nshort text presents internal definitions and a few examples before covering the\nproposed guidelines. This text concludes with a seemingly natural argument for\nthe use of interpretable models and explanatory, debugging, and disparate\nimpact testing methods in life- or mission-critical ML systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 22:12:11 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 19:11:26 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 22:30:16 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hall", "Patrick", ""], ["Gill", "Navdeep", ""], ["Schmidt", "Nicholas", ""]]}, {"id": "1906.03543", "submitter": "Jacob Schreiber", "authors": "Jacob Schreiber and Jeffrey Bilmes and William Stafford Noble", "title": "apricot: Submodular selection for data summarization in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present apricot, an open source Python package for selecting\nrepresentative subsets from large data sets using submodular optimization. The\npackage implements an efficient greedy selection algorithm that offers strong\ntheoretical guarantees on the quality of the selected set. Two submodular set\nfunctions are implemented in apricot: facility location, which is broadly\napplicable but requires memory quadratic in the number of examples in the data\nset, and a feature-based function that is less broadly applicable but can scale\nto millions of examples. Apricot is extremely efficient, using both algorithmic\nspeedups such as the lazy greedy algorithm and code optimizers such as numba.\nWe demonstrate the use of subset selection by training machine learning models\nto comparable accuracy using either the full data set or a representative\nsubset thereof. This paper presents an explanation of submodular selection, an\noverview of the features in apricot, and an application to several data sets.\nThe code and tutorial Jupyter notebooks are available at\nhttps://github.com/jmschrei/apricot\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 23:53:57 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Schreiber", "Jacob", ""], ["Bilmes", "Jeffrey", ""], ["Noble", "William Stafford", ""]]}, {"id": "1906.03548", "submitter": "Cecilia Summers", "authors": "Cecilia Summers, Michael J. Dinneen", "title": "Four Things Everyone Should Know to Improve Batch Normalization", "comments": "ICLR 2020, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key component of most neural network architectures is the use of\nnormalization layers, such as Batch Normalization. Despite its common use and\nlarge utility in optimizing deep architectures, it has been challenging both to\ngenerically improve upon Batch Normalization and to understand the\ncircumstances that lend themselves to other enhancements. In this paper, we\nidentify four improvements to the generic form of Batch Normalization and the\ncircumstances under which they work, yielding performance gains across all\nbatch sizes while requiring no additional computation during training. These\ncontributions include proposing a method for reasoning about the current\nexample in inference normalization statistics, fixing a training vs. inference\ndiscrepancy; recognizing and validating the powerful regularization effect of\nGhost Batch Normalization for small and medium batch sizes; examining the\neffect of weight decay regularization on the scaling and shifting parameters\ngamma and beta; and identifying a new normalization algorithm for very small\nbatch sizes by combining the strengths of Batch and Group Normalization. We\nvalidate our results empirically on six datasets: CIFAR-100, SVHN, Caltech-256,\nOxford Flowers-102, CUB-2011, and ImageNet.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 01:14:48 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 05:20:53 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Summers", "Cecilia", ""], ["Dinneen", "Michael J.", ""]]}, {"id": "1906.03559", "submitter": "Qian Qian", "authors": "Qian Qian and Xiaoyuan Qian", "title": "The Implicit Bias of AdaGrad on Separable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the implicit bias of AdaGrad on separable linear classification\nproblems. We show that AdaGrad converges to a direction that can be\ncharacterized as the solution of a quadratic optimization problem with the same\nfeasible set as the hard SVM problem. We also give a discussion about how\ndifferent choices of the hyperparameters of AdaGrad might impact this\ndirection. This provides a deeper understanding of why adaptive methods do not\nseem to have the generalization ability as good as gradient descent does in\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 04:11:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Qian", "Qian", ""], ["Qian", "Xiaoyuan", ""]]}, {"id": "1906.03563", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Tianyun Zhang, Sijia Liu, Pin-Yu Chen, Jiacen Xu, Makan\n  Fardad, Bo Li", "title": "Towards A Unified Min-Max Framework for Adversarial Exploration and\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worst-case training principle that minimizes the maximal adversarial\nloss, also known as adversarial training (AT), has shown to be a\nstate-of-the-art approach for enhancing adversarial robustness against\nnorm-ball bounded input perturbations. Nonetheless, min-max optimization beyond\nthe purpose of AT has not been rigorously explored in the research of\nadversarial attack and defense. In particular, given a set of risk sources\n(domains), minimizing the maximal loss induced from the domain set can be\nreformulated as a general min-max problem that is different from AT. Examples\nof this general formulation include attacking model ensembles, devising\nuniversal perturbation under multiple inputs or data transformations, and\ngeneralized AT over different types of attack models. We show that these\nproblems can be solved under a unified and theoretically principled min-max\noptimization framework. We also show that the self-adjusted domain weights\nlearned from our method provides a means to explain the difficulty level of\nattack and defense over multiple domains. Extensive experiments show that our\napproach leads to substantial performance improvement over the conventional\naveraging strategy.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 04:32:13 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 15:49:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Jingkang", ""], ["Zhang", "Tianyun", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Xu", "Jiacen", ""], ["Fardad", "Makan", ""], ["Li", "Bo", ""]]}, {"id": "1906.03574", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Eeshan Gunesh Dhekane, Riashat Islam", "title": "Transfer Learning by Modeling a Distribution over Policies", "comments": "Accepted at the ICML 2019 workshop on Multi-Task and Lifelong\n  Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration and adaptation to new tasks in a transfer learning setup is a\ncentral challenge in reinforcement learning. In this work, we build on the idea\nof modeling a distribution over policies in a Bayesian deep reinforcement\nlearning setup to propose a transfer strategy. Recent works have shown to\ninduce diversity in the learned policies by maximizing the entropy of a\ndistribution of policies (Bachman et al., 2018; Garnelo et al., 2018) and thus,\nwe postulate that our proposed approach leads to faster exploration resulting\nin improved transfer learning. We support our hypothesis by demonstrating\nfavorable experimental results on a variety of settings on fully-observable\nGridWorld and partially observable MiniGrid (Chevalier-Boisvert et al., 2018)\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 06:00:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Shrivastava", "Disha", ""], ["Dhekane", "Eeshan Gunesh", ""], ["Islam", "Riashat", ""]]}, {"id": "1906.03579", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Sewoong Oh, Ashish Khetan", "title": "Robust conditional GANs under missing or uncertain labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching the performance of conditional Generative Adversarial Networks with\nlittle supervision is an important task, especially in venturing into new\ndomains. We design a new training algorithm, which is robust to missing or\nambiguous labels. The main idea is to intentionally corrupt the labels of\ngenerated examples to match the statistics of the real data, and have a\ndiscriminator process the real and generated examples with corrupted labels. We\nshowcase the robustness of this proposed approach both theoretically and\nempirically. We show that minimizing the proposed loss is equivalent to\nminimizing true divergence between real and generated data up to a\nmultiplicative factor, and characterize this multiplicative factor as a\nfunction of the statistics of the uncertain labels. Experiments on MNIST\ndataset demonstrates that proposed architecture is able to achieve high\naccuracy in generating examples faithful to the class even with only a few\nexamples per class.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 06:37:06 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Oh", "Sewoong", ""], ["Khetan", "Ashish", ""]]}, {"id": "1906.03580", "submitter": "Paul Grigas", "authors": "Paul Grigas, Alfonso Lobos, Nathan Vermeersch", "title": "Stochastic In-Face Frank-Wolfe Methods for Non-Convex Optimization and\n  Sparse Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frank-Wolfe method and its extensions are well-suited for delivering\nsolutions with desirable structural properties, such as sparsity or low-rank\nstructure. We introduce a new variant of the Frank-Wolfe method that combines\nFrank-Wolfe steps and steepest descent steps, as well as a novel modification\nof the \"Frank-Wolfe gap\" to measure convergence in the non-convex case. We\nfurther extend this method to incorporate in-face directions for preserving\nstructured solutions as well as block coordinate steps, and we demonstrate\ncomputational guarantees in terms of the modified Frank-Wolfe gap for all of\nthese variants. We are particularly motivated by the application of this\nmethodology to the training of neural networks with sparse properties, and we\napply our block coordinate method to the problem of $\\ell_1$ regularized neural\nnetwork training. We present the results of several numerical experiments on\nboth artificial and real datasets demonstrating significant improvements of our\nmethod in training sparse neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:14:11 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Grigas", "Paul", ""], ["Lobos", "Alfonso", ""], ["Vermeersch", "Nathan", ""]]}, {"id": "1906.03586", "submitter": "Qiran Gong", "authors": "Hao Peng, Jianxin Li, Hao Yan, Qiran Gong, Senzhang Wang, Lin Liu,\n  Lihong Wang, Xiang Ren", "title": "Dynamic Network Embedding via Incremental Skip-gram with Negative\n  Sampling", "comments": "Accepted by China Science Information Science. arXiv admin note: text\n  overlap with arXiv:1811.05932 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning, as an approach to learn low dimensional\nrepresentations of vertices, has attracted considerable research attention\nrecently. It has been proven extremely useful in many machine learning tasks\nover large graph. Most existing methods focus on learning the structural\nrepresentations of vertices in a static network, but cannot guarantee an\naccurate and efficient embedding in a dynamic network scenario. To address this\nissue, we present an efficient incremental skip-gram algorithm with negative\nsampling for dynamic network embedding, and provide a set of theoretical\nanalyses to characterize the performance guarantee. Specifically, we first\npartition a dynamic network into the updated, including addition/deletion of\nlinks and vertices, and the retained networks over time. Then we factorize the\nobjective function of network embedding into the added, vanished and retained\nparts of the network. Next we provide a new stochastic gradient-based method,\nguided by the partitions of the network, to update the nodes and the parameter\nvectors. The proposed algorithm is proven to yield an objective function value\nwith a bounded difference to that of the original objective function.\nExperimental results show that our proposal can significantly reduce the\ntraining time while preserving the comparable performance. We also demonstrate\nthe correctness of the theoretical analysis and the practical usefulness of the\ndynamic network embedding. We perform extensive experiments on multiple\nreal-world large network datasets over multi-label classification and link\nprediction tasks to evaluate the effectiveness and efficiency of the proposed\nframework, and up to 22 times speedup has been achieved.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:42:39 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Yan", "Hao", ""], ["Gong", "Qiran", ""], ["Wang", "Senzhang", ""], ["Liu", "Lin", ""], ["Wang", "Lihong", ""], ["Ren", "Xiang", ""]]}, {"id": "1906.03590", "submitter": "Chao Zhai", "authors": "Chao Zhai and Hung D. Nguyen", "title": "Region of Attraction for Power Systems using Gaussian Process and\n  Converse Lyapunov Function -- Part I: Theoretical Framework and Off-line\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel framework to construct the region of attraction\n(ROA) of a power system centered around a stable equilibrium by using stable\nstate trajectories of system dynamics. Most existing works on estimating ROA\nrely on analytical Lyapunov functions, which are subject to two limitations:\nthe analytic Lyapunov functions may not be always readily available, and the\nresulting ROA may be overly conservative. This work overcomes these two\nlimitations by leveraging the converse Lyapunov theorem in control theory to\neliminate the need of an analytic Lyapunov function and learning the unknown\nLyapunov function with the Gaussian Process (GP) approach. In addition, a\nGaussian Process Upper Confidence Bound (GP-UCB) based sampling algorithm is\ndesigned to reconcile the trade-off between the exploitation for enlarging the\nROA and the exploration for reducing the uncertainty of sampling region. Within\nthe constructed ROA, it is guaranteed in probability that the system state will\nconverge to the stable equilibrium with a confidence level. Numerical\nsimulations are also conducted to validate the assessment approach for the ROA\nof the single machine infinite bus system and the New England $39$-bus system.\nNumerical results demonstrate that our approach can significantly enlarge the\nestimated ROA compared to that of the analytic Lyapunov counterpart.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 08:13:16 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhai", "Chao", ""], ["Nguyen", "Hung D.", ""]]}, {"id": "1906.03593", "submitter": "Xin Yang", "authors": "Zhao Song, Xin Yang", "title": "Quadratic Suffices for Over-parametrization via Matrix Chernoff Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the over-parametrization size over two beautiful results [Li and\nLiang' 2018] and [Du, Zhai, Poczos and Singh' 2019] in deep learning theory.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 08:36:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:17:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Song", "Zhao", ""], ["Yang", "Xin", ""]]}, {"id": "1906.03612", "submitter": "Tobias Uelwer", "authors": "Felix Michels, Tobias Uelwer, Eric Upschulte, Stefan Harmeling", "title": "On the Vulnerability of Capsule Networks to Adversarial Attacks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extensively evaluates the vulnerability of capsule networks to\ndifferent adversarial attacks. Recent work suggests that these architectures\nare more robust towards adversarial attacks than other neural networks.\nHowever, our experiments show that capsule networks can be fooled as easily as\nconvolutional neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 10:22:52 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Michels", "Felix", ""], ["Uelwer", "Tobias", ""], ["Upschulte", "Eric", ""], ["Harmeling", "Stefan", ""]]}, {"id": "1906.03626", "submitter": "Ruihan Yang", "authors": "Ruihan Yang, Dingsu Wang, Ziyu Wang, Tianyao Chen, Junyan Jiang and\n  Gus Xia", "title": "Deep Music Analogy Via Latent Representation Disentanglement", "comments": "Accepted at the International Society for Music Information Retrieval\n  (ISMIR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogy-making is a key method for computer algorithms to generate both\nnatural and creative music pieces. In general, an analogy is made by partially\ntransferring the music abstractions, i.e., high-level representations and their\nrelationships, from one piece to another; however, this procedure requires\ndisentangling music representations, which usually takes little effort for\nmusicians but is non-trivial for computers. Three sub-problems arise:\nextracting latent representations from the observation, disentangling the\nrepresentations so that each part has a unique semantic interpretation, and\nmapping the latent representations back to actual music. In this paper, we\ncontribute an explicitly-constrained variational autoencoder (EC$^2$-VAE) as a\nunified solution to all three sub-problems. We focus on disentangling the pitch\nand rhythm representations of 8-beat music clips conditioned on chords. In\nproducing music analogies, this model helps us to realize the imaginary\nsituation of \"what if\" a piece is composed using a different pitch contour,\nrhythm pattern, or chord progression by borrowing the representations from\nother pieces. Finally, we validate the proposed disentanglement method using\nobjective measurements and evaluate the analogy examples by a subjective study.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 12:22:06 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 10:10:52 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 12:40:00 GMT"}, {"version": "v4", "created": "Sun, 20 Oct 2019 03:57:00 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yang", "Ruihan", ""], ["Wang", "Dingsu", ""], ["Wang", "Ziyu", ""], ["Chen", "Tianyao", ""], ["Jiang", "Junyan", ""], ["Xia", "Gus", ""]]}, {"id": "1906.03639", "submitter": "Dufan Wu", "authors": "Dufan Wu, Kuang Gong, Kyungsang Kim, Quanzheng Li", "title": "Consensus Neural Network for Medical Imaging Denoising with Only Noisy\n  Training Samples", "comments": "9 pages, 2 figures, accepted by MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been proved efficient for medical image denoising.\nCurrent training methods require both noisy and clean images. However, clean\nimages cannot be acquired for many practical medical applications due to\nnaturally noisy signal, such as dynamic imaging, spectral computed tomography,\narterial spin labeling magnetic resonance imaging, etc. In this paper we\nproposed a training method which learned denoising neural networks from noisy\ntraining samples only. Training data in the acquisition domain was split to two\nsubsets and the network was trained to map one noisy set to the other. A\nconsensus loss function was further proposed to efficiently combine the outputs\nfrom both subsets. A mathematical proof was provided that the proposed training\nscheme was equivalent to training with noisy and clean samples when the noise\nin the two subsets was uncorrelated and zero-mean. The method was validated on\nLow-dose CT Challenge dataset and NYU MRI dataset and achieved improved\nperformance compared to existing unsupervised methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 13:37:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wu", "Dufan", ""], ["Gong", "Kuang", ""], ["Kim", "Kyungsang", ""], ["Li", "Quanzheng", ""]]}, {"id": "1906.03644", "submitter": "Kirill Neklyudov", "authors": "Kirill Neklyudov, Evgenii Egorov, Dmitry Vetrov", "title": "The Implicit Metropolis-Hastings Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works propose using the discriminator of a GAN to filter out\nunrealistic samples of the generator. We generalize these ideas by introducing\nthe implicit Metropolis-Hastings algorithm. For any implicit probabilistic\nmodel and a target distribution represented by a set of samples, implicit\nMetropolis-Hastings operates by learning a discriminator to estimate the\ndensity-ratio and then generating a chain of samples. Since the approximation\nof density ratio introduces an error on every step of the chain, it is crucial\nto analyze the stationary distribution of such chain. For that purpose, we\npresent a theoretical result stating that the discriminator loss upper bounds\nthe total variation distance between the target distribution and the stationary\ndistribution. Finally, we validate the proposed algorithm both for independent\nand Markov proposals on CIFAR-10 and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 14:05:30 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Neklyudov", "Kirill", ""], ["Egorov", "Evgenii", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1906.03647", "submitter": "Shiliang Sun", "authors": "Jing Zhao, Jingjing Fei, Shiliang Sun", "title": "A Variant of Gaussian Process Dynamical Systems", "comments": "Technical Report, East China Normal University, November 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to better model high-dimensional sequential data, we propose a\ncollaborative multi-output Gaussian process dynamical system (CGPDS), which is\na novel variant of GPDSs. The proposed model assumes that the output on each\ndimension is controlled by a shared global latent process and a private local\nlatent process. Thus, the dependence among different dimensions of the\nsequences can be captured, and the unique characteristics of each dimension of\nthe sequences can be maintained. For training models and making prediction, we\nintroduce inducing points and adopt stochastic variational inference methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 14:22:44 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhao", "Jing", ""], ["Fei", "Jingjing", ""], ["Sun", "Shiliang", ""]]}, {"id": "1906.03663", "submitter": "Shaowu Pan", "authors": "Shaowu Pan, Karthik Duraisamy", "title": "Physics-Informed Probabilistic Learning of Linear Embeddings of\n  Non-linear Dynamics With Guaranteed Stability", "comments": "31 pages", "journal-ref": "SIAM Journal on Applied Dynamical Systems 19.1 (2020): 480-509", "doi": "10.1137/19M1267246", "report-no": null, "categories": "math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Koopman operator has emerged as a powerful tool for the analysis of\nnonlinear dynamical systems as it provides coordinate transformations to\nglobally linearize the dynamics. While recent deep learning approaches have\nbeen useful in extracting the Koopman operator from a data-driven perspective,\nseveral challenges remain. In this work, we formalize the problem of learning\nthe continuous-time Koopman operator with deep neural networks in a\nmeasure-theoretic framework. Our approach induces two types of models:\ndifferential and recurrent form, the choice of which depends on the\navailability of the governing equations and data. We then enforce a structural\nparameterization that renders the realization of the Koopman operator provably\nstable. A new autoencoder architecture is constructed, such that only the\nresidual of the dynamic mode decomposition is learned. Finally, we employ\nmean-field variational inference (MFVI) on the aforementioned framework in a\nhierarchical Bayesian setting to quantify uncertainties in the characterization\nand prediction of the dynamics of observables. The framework is evaluated on a\nsimple polynomial system, the Duffing oscillator, and an unstable cylinder wake\nflow with noisy measurements.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:03:45 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 19:17:03 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 19:02:43 GMT"}, {"version": "v4", "created": "Fri, 13 Dec 2019 18:07:03 GMT"}, {"version": "v5", "created": "Sun, 21 Jun 2020 02:58:21 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Pan", "Shaowu", ""], ["Duraisamy", "Karthik", ""]]}, {"id": "1906.03667", "submitter": "Partha Mitra", "authors": "Partha P Mitra", "title": "Understanding overfitting peaks in generalization error: Analytical risk\n  curves for $l_2$ and $l_1$ penalized interpolation", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally in regression one minimizes the number of fitting parameters or\nuses smoothing/regularization to trade training (TE) and generalization error\n(GE). Driving TE to zero by increasing fitting degrees of freedom (dof) is\nexpected to increase GE. However modern big-data approaches, including deep\nnets, seem to over-parametrize and send TE to zero (data interpolation) without\nimpacting GE. Overparametrization has the benefit that global minima of the\nempirical loss function proliferate and become easier to find. These phenomena\nhave drawn theoretical attention. Regression and classification algorithms have\nbeen shown that interpolate data but also generalize optimally. An interesting\nrelated phenomenon has been noted: the existence of non-monotonic risk curves,\nwith a peak in GE with increasing dof. It was suggested that this peak\nseparates a classical regime from a modern regime where over-parametrization\nimproves performance. Similar over-fitting peaks were reported previously\n(statistical physics approach to learning) and attributed to increased fitting\nmodel flexibility. We introduce a generative and fitting model pair\n(\"Misparametrized Sparse Regression\" or MiSpaR) and show that the overfitting\npeak can be dissociated from the point at which the fitting function gains\nenough dof's to match the data generative model and thus provides good\ngeneralization. This complicates the interpretation of overfitting peaks as\nseparating a \"classical\" from a \"modern\" regime. Data interpolation itself\ncannot guarantee good generalization: we need to study the interpolation with\ndifferent penalty terms. We present analytical formulae for GE curves for\nMiSpaR with $l_2$ and $l_1$ penalties, in the interpolating limit\n$\\lambda\\rightarrow 0$.These risk curves exhibit important differences and help\nelucidate the underlying phenomena.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:40:25 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Mitra", "Partha P", ""]]}, {"id": "1906.03671", "submitter": "Jordan Ash", "authors": "Jordan T. Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford,\n  Alekh Agarwal", "title": "Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds", "comments": null, "journal-ref": "2020 International Conference on Learning Representations", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new algorithm for batch active learning with deep neural network\nmodels. Our algorithm, Batch Active learning by Diverse Gradient Embeddings\n(BADGE), samples groups of points that are disparate and high-magnitude when\nrepresented in a hallucinated gradient space, a strategy designed to\nincorporate both predictive uncertainty and sample diversity into every\nselected batch. Crucially, BADGE trades off between diversity and uncertainty\nwithout requiring any hand-tuned hyperparameters. We show that while other\napproaches sometimes succeed for particular batch sizes or architectures, BADGE\nconsistently performs as well or better, making it a versatile option for\npractical active learning problems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:52:09 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 02:14:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ash", "Jordan T.", ""], ["Zhang", "Chicheng", ""], ["Krishnamurthy", "Akshay", ""], ["Langford", "John", ""], ["Agarwal", "Alekh", ""]]}, {"id": "1906.03674", "submitter": "Katerina Margatina", "authors": "Katerina Margatina, Christos Baziotis, Alexandros Potamianos", "title": "Attention-based Conditioning Methods for External Knowledge Integration", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for incorporating external\nknowledge in Recurrent Neural Networks (RNNs). We propose the integration of\nlexicon features into the self-attention mechanism of RNN-based architectures.\nThis form of conditioning on the attention distribution, enforces the\ncontribution of the most salient words for the task at hand. We introduce three\nmethods, namely attentional concatenation, feature-based gating and affine\ntransformation. Experiments on six benchmark datasets show the effectiveness of\nour methods. Attentional feature-based gating yields consistent performance\nimprovement across tasks. Our approach is implemented as a simple add-on module\nfor RNN-based models with minimal computational overhead and can be adapted to\nany deep neural architecture.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 17:06:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Margatina", "Katerina", ""], ["Baziotis", "Christos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1906.03685", "submitter": "Valerie Chen", "authors": "Valerie Chen, Man-Ki Yoon, Zhong Shao", "title": "Novelty Detection via Network Saliency in Visual-based Deep Learning", "comments": "To be published in Dependable and Secure Machine Learning (DSML)\n  workshop co-located with the IEEE Conference on Dependable Systems and\n  Networks 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning driven safety-critical autonomous systems, such as\nself-driving cars, must be able to detect situations where its trained model is\nnot able to make a trustworthy prediction. Often viewed as a black-box, it is\nnon-obvious to determine when a model will make a safe decision and when it\nwill make an erroneous, perhaps life-threatening one. Prior work on novelty\ndetection deal with highly structured data and do not translate well to\ndynamic, real-world situations. This paper proposes a multi-step framework for\nthe detection of novel scenarios in vision-based autonomous systems by\nleveraging information learned by the trained prediction model and a new image\nsimilarity metric. We demonstrate the efficacy of this method through\nexperiments on a real-world driving dataset as well as on our in-house indoor\nracing environment.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 18:23:57 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chen", "Valerie", ""], ["Yoon", "Man-Ki", ""], ["Shao", "Zhong", ""]]}, {"id": "1906.03691", "submitter": "Xiangrui Li", "authors": "Xiangrui Li, Jasmine Hect, Moriah Thomason and Dongxiao Zhu", "title": "Interpreting Age Effects of Human Fetal Brain from Spontaneous fMRI\n  using Deep 3D Convolutional Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human fetal neurodevelopment is of great clinical importance as\nabnormal development is linked to adverse neuropsychiatric outcomes after\nbirth. Recent advances in functional Magnetic Resonance Imaging (fMRI) have\nprovided new insight into development of the human brain before birth, but\nthese studies have predominately focused on brain functional connectivity (i.e.\nFisher z-score), which requires manual processing steps for feature extraction\nfrom fMRI images. Deep learning approaches (i.e., Convolutional Neural\nNetworks) have achieved remarkable success on learning directly from image\ndata, yet have not been applied on fetal fMRI for understanding fetal\nneurodevelopment. Here, we bridge this gap by applying a novel application of\ndeep 3D CNN to fetal blood oxygen-level dependence (BOLD) resting-state fMRI\ndata. Specifically, we test a supervised CNN framework as a data-driven\napproach to isolate variation in fMRI signals that relate to younger v.s. older\nfetal age groups. Based on the learned CNN, we further perform sensitivity\nanalysis to identify brain regions in which changes in BOLD signal are strongly\nassociated with fetal brain age. The findings demonstrate that deep CNNs are a\npromising approach for identifying spontaneous functional patterns in fetal\nbrain activity that discriminate age groups. Further, we discovered that\nregions that most strongly differentiate groups are largely bilateral, share\nsimilar distribution in older and younger age groups, and are areas of\nheightened metabolic activity in early human development.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 19:00:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Li", "Xiangrui", ""], ["Hect", "Jasmine", ""], ["Thomason", "Moriah", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1906.03694", "submitter": "Arjun Sondhi", "authors": "Arjun Sondhi, David Arbour, Drew Dimmery", "title": "Balanced off-policy evaluation in general action spaces", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of importance sampling weights for off-policy evaluation of\ncontextual bandits often results in imbalance - a mismatch between the desired\nand the actual distribution of state-action pairs after weighting. In this work\nwe present balanced off-policy evaluation (B-OPE), a generic method for\nestimating weights which minimize this imbalance. Estimation of these weights\nreduces to a binary classification problem regardless of action type. We show\nthat minimizing the risk of the classifier implies minimization of imbalance to\nthe desired counterfactual distribution of state-action pairs. The classifier\nloss is tied to the error of the off-policy estimate, allowing for easy tuning\nof hyperparameters. We provide experimental evidence that B-OPE improves\nweighting-based approaches for offline policy evaluation in both discrete and\ncontinuous action spaces.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 19:25:17 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 15:51:01 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 16:28:49 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 04:33:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Sondhi", "Arjun", ""], ["Arbour", "David", ""], ["Dimmery", "Drew", ""]]}, {"id": "1906.03700", "submitter": "Shengxi Li", "authors": "Shengxi Li, Zeyang Yu, Min Xiang and Danilo Mandic", "title": "Solving general elliptical mixture models through an approximate\n  Wasserstein manifold", "comments": "This work has been accepted to AAAI2020. Note that this version also\n  corrects a small error on the Equation (16) in proof", "journal-ref": null, "doi": "10.1609/aaai.v34i04.5897", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the estimation problem for general finite mixture models, with a\nparticular focus on the elliptical mixture models (EMMs). Compared to the\nwidely adopted Kullback-Leibler divergence, we show that the Wasserstein\ndistance provides a more desirable optimisation space. We thus provide a stable\nsolution to the EMMs that is both robust to initialisations and reaches a\nsuperior optimum by adaptively optimising along a manifold of an approximate\nWasserstein distance. To this end, we first provide a unifying account of\ncomputable and identifiable EMMs, which serves as a basis to rigorously address\nthe underpinning optimisation problem. Due to a probability constraint, solving\nthis problem is extremely cumbersome and unstable, especially under the\nWasserstein distance. To relieve this issue, we introduce an efficient\noptimisation method on a statistical manifold defined under an approximate\nWasserstein distance, which allows for explicit metrics and computable\noperations, thus significantly stabilising and improving the EMM estimation. We\nfurther propose an adaptive method to accelerate the convergence. Experimental\nresults demonstrate the excellent performance of the proposed EMM solver.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 20:04:59 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 16:04:30 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 13:06:57 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 20:53:42 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Li", "Shengxi", ""], ["Yu", "Zeyang", ""], ["Xiang", "Min", ""], ["Mandic", "Danilo", ""]]}, {"id": "1906.03704", "submitter": "Ahmed Touati", "authors": "Zilun Peng, Ahmed Touati, Pascal Vincent and Doina Precup", "title": "SVRG for Policy Evaluation with Fewer Gradient Evaluations", "comments": "Short version of the paper is published in the proceedings of the\n  29th International Joint Conference on Artificial Intelligence and the 17th\n  Pacific Rim International Conference on Artificial Intelligence\n  (IJCAI-PRICAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance-reduced gradient (SVRG) is an optimization method\noriginally designed for tackling machine learning problems with a finite sum\nstructure. SVRG was later shown to work for policy evaluation, a problem in\nreinforcement learning in which one aims to estimate the value function of a\ngiven policy. SVRG makes use of gradient estimates at two scales. At the slower\nscale, SVRG computes a full gradient over the whole dataset, which could lead\nto prohibitive computation costs. In this work, we show that two variants of\nSVRG for policy evaluation could significantly diminish the number of gradient\ncalculations while preserving a linear convergence speed. More importantly, our\ntheoretical result implies that one does not need to use the entire dataset in\nevery epoch of SVRG when it is applied to policy evaluation with linear\nfunction approximation. Our experiments demonstrate large computational savings\nprovided by the proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 20:59:02 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 16:54:45 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Peng", "Zilun", ""], ["Touati", "Ahmed", ""], ["Vincent", "Pascal", ""], ["Precup", "Doina", ""]]}, {"id": "1906.03707", "submitter": "Zhihao Jia", "authors": "Zhihao Jia, Sina Lin, Rex Ying, Jiaxuan You, Jure Leskovec, Alex Aiken", "title": "Redundancy-Free Computation Graphs for Graph Neural Networks", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are based on repeated aggregations of\ninformation across nodes' neighbors in a graph. However, because common\nneighbors are shared between different nodes, this leads to repeated and\ninefficient computations. We propose Hierarchically Aggregated computation\nGraphs (HAGs), a new GNN graph representation that explicitly avoids redundancy\nby managing intermediate aggregation results hierarchically, eliminating\nrepeated computations and unnecessary data transfers in GNN training and\ninference. We introduce an accurate cost function to quantitatively evaluate\nthe runtime performance of different HAGs and use a novel HAG search algorithm\nto find optimized HAGs. Experiments show that the HAG representation\nsignificantly outperforms the standard GNN graph representation by increasing\nthe end-to-end training throughput by up to 2.8x and reducing the aggregations\nand data transfers in GNN training by up to 6.3x and 5.6x, while maintaining\nthe original model accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:06:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Jia", "Zhihao", ""], ["Lin", "Sina", ""], ["Ying", "Rex", ""], ["You", "Jiaxuan", ""], ["Leskovec", "Jure", ""], ["Aiken", "Alex", ""]]}, {"id": "1906.03708", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang and Aaron Courville", "title": "Note on the bias and variance of variational inference", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we study the relationship between the variational gap and the\nvariance of the (log) likelihood ratio. We show that the gap can be upper\nbounded by some form of dispersion measure of the likelihood ratio, which\nsuggests the bias of variational inference can be reduced by making the\ndistribution of the likelihood ratio more concentrated, such as via averaging\nand variance reduction.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:08:35 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Courville", "Aaron", ""]]}, {"id": "1906.03710", "submitter": "John Lanier B", "authors": "John B. Lanier, Stephen McAleer, Pierre Baldi", "title": "Curiosity-Driven Multi-Criteria Hindsight Experience Replay", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dealing with sparse rewards is a longstanding challenge in reinforcement\nlearning. The recent use of hindsight methods have achieved success on a\nvariety of sparse-reward tasks, but they fail on complex tasks such as stacking\nmultiple blocks with a robot arm in simulation. Curiosity-driven exploration\nusing the prediction error of a learned dynamics model as an intrinsic reward\nhas been shown to be effective for exploring a number of sparse-reward\nenvironments. We present a method that combines hindsight with curiosity-driven\nexploration and curriculum learning in order to solve the challenging\nsparse-reward block stacking task. We are the first to stack more than two\nblocks using only sparse reward without human demonstrations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:11:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Lanier", "John B.", ""], ["McAleer", "Stephen", ""], ["Baldi", "Pierre", ""]]}, {"id": "1906.03711", "submitter": "Valentina Fedorova", "authors": "Nadezhda Bugakova, Valentina Fedorova, Gleb Gusev, Alexey Drutsa", "title": "Aggregation of pairwise comparisons with reduction of biases", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of ranking from crowdsourced pairwise comparisons.\nAnswers to pairwise tasks are known to be affected by the position of items on\nthe screen, however, previous models for aggregation of pairwise comparisons do\nnot focus on modeling such kind of biases. We introduce a new aggregation model\nfactorBT for pairwise comparisons, which accounts for certain factors of\npairwise tasks that are known to be irrelevant to the result of comparisons but\nmay affect workers' answers due to perceptual reasons. By modeling biases that\ninfluence workers, factorBT is able to reduce the effect of biased pairwise\ncomparisons on the resulted ranking. Our empirical studies on real-world data\nsets showed that factorBT produces more accurate ranking from crowdsourced\npairwise comparisons than previously established models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:12:43 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Bugakova", "Nadezhda", ""], ["Fedorova", "Valentina", ""], ["Gusev", "Gleb", ""], ["Drutsa", "Alexey", ""]]}, {"id": "1906.03722", "submitter": "Eric Lock", "authors": "Jun Young Park and Eric F. Lock", "title": "Integrative Factorization of Bidimensionally Linked Matrices", "comments": "27 pages, 4 figures", "journal-ref": "Biometrics, 2019", "doi": "10.1111/biom.13141", "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in molecular \"omics'\" technologies have motivated new methodology\nfor the integration of multiple sources of high-content biomedical data.\nHowever, most statistical methods for integrating multiple data matrices only\nconsider data shared vertically (one cohort on multiple platforms) or\nhorizontally (different cohorts on a single platform). This is limiting for\ndata that take the form of bidimensionally linked matrices (e.g., multiple\ncohorts measured on multiple platforms), which are increasingly common in\nlarge-scale biomedical studies. In this paper, we propose BIDIFAC\n(Bidimensional Integrative Factorization) for integrative dimension reduction\nand signal approximation of bidimensionally linked data matrices. Our method\nfactorizes the data into (i) globally shared, (ii) row-shared, (iii)\ncolumn-shared, and (iv) single-matrix structural components, facilitating the\ninvestigation of shared and unique patterns of variability. For estimation we\nuse a penalized objective function that extends the nuclear norm penalization\nfor a single matrix. As an alternative to the complicated rank selection\nproblem, we use results from random matrix theory to choose tuning parameters.\nWe apply our method to integrate two genomics platforms (mRNA and miRNA\nexpression) across two sample cohorts (tumor samples and normal tissue samples)\nusing the breast cancer data from TCGA. We provide R code for fitting BIDIFAC,\nimputing missing values, and generating simulated data.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:50:19 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Park", "Jun Young", ""], ["Lock", "Eric F.", ""]]}, {"id": "1906.03728", "submitter": "Brian Bartoldson", "authors": "Brian R. Bartoldson, Ari S. Morcos, Adrian Barbu, Gordon Erlebacher", "title": "The Generalization-Stability Tradeoff In Neural Network Pruning", "comments": "NeurIPS 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning neural network parameters is often viewed as a means to compress\nmodels, but pruning has also been motivated by the desire to prevent\noverfitting. This motivation is particularly relevant given the perhaps\nsurprising observation that a wide variety of pruning approaches increase test\naccuracy despite sometimes massive reductions in parameter counts. To better\nunderstand this phenomenon, we analyze the behavior of pruning over the course\nof training, finding that pruning's benefit to generalization increases with\npruning's instability (defined as the drop in test accuracy immediately\nfollowing pruning). We demonstrate that this \"generalization-stability\ntradeoff\" is present across a wide variety of pruning settings and propose a\nmechanism for its cause: pruning regularizes similarly to noise injection.\nSupporting this, we find less pruning stability leads to more model flatness\nand the benefits of pruning do not depend on permanent parameter removal. These\nresults explain the compatibility of pruning-based generalization improvements\nand the high generalization recently observed in overparameterized networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 22:35:00 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 23:57:25 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 18:57:13 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 22:24:16 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bartoldson", "Brian R.", ""], ["Morcos", "Ari S.", ""], ["Barbu", "Adrian", ""], ["Erlebacher", "Gordon", ""]]}, {"id": "1906.03735", "submitter": "Masatoshi Uehara", "authors": "Nathan Kallus, Masatoshi Uehara", "title": "Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in both contextual bandits and reinforcement\nlearning allows one to evaluate novel decision policies without needing to\nconduct exploration, which is often costly or otherwise infeasible. The\nproblem's importance has attracted many proposed solutions, including\nimportance sampling (IS), self-normalized IS (SNIS), and doubly robust (DR)\nestimates. DR and its variants ensure semiparametric local efficiency if\nQ-functions are well-specified, but if they are not they can be worse than both\nIS and SNIS. It also does not enjoy SNIS's inherent stability and boundedness.\nWe propose new estimators for OPE based on empirical likelihood that are always\nmore efficient than IS, SNIS, and DR and satisfy the same stability and\nboundedness properties as SNIS. On the way, we categorize various properties\nand classify existing estimators by them. Besides the theoretical guarantees,\nempirical studies suggest the new estimators provide advantages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 23:15:49 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1906.03737", "submitter": "Qingyun Wu", "authors": "Qingyun Wu, Zhige Li, Huazheng Wang, Wei Chen, Hongning Wang", "title": "Factorization Bandits for Online Influence Maximization", "comments": "11 pages (including SUPPLEMENT)", "journal-ref": null, "doi": "10.1145/3292500.3330874", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online influence maximization in social networks. In\nthis problem, a learner aims to identify the set of \"best influencers\" in a\nnetwork by interacting with it, i.e., repeatedly selecting seed nodes and\nobserving activation feedback in the network. We capitalize on an important\nproperty of the influence maximization problem named network assortativity,\nwhich is ignored by most existing works in online influence maximization. To\nrealize network assortativity, we factorize the activation probability on the\nedges into latent factors on the corresponding nodes, including influence\nfactor on the giving nodes and susceptibility factor on the receiving nodes. We\npropose an upper confidence bound based online learning solution to estimate\nthe latent factors, and therefore the activation probabilities. Considerable\nregret reduction is achieved by our factorization based online influence\nmaximization algorithm. And extensive empirical evaluations on two real-world\nnetworks showed the effectiveness of our proposed solution.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 23:43:03 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 03:46:26 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wu", "Qingyun", ""], ["Li", "Zhige", ""], ["Wang", "Huazheng", ""], ["Chen", "Wei", ""], ["Wang", "Hongning", ""]]}, {"id": "1906.03742", "submitter": "Morteza Mardani", "authors": "Morteza Mardani, Qingyun Sun, Vardan Papyan, Shreyas Vasanawala, John\n  Pauly, and David Donoho", "title": "Degrees of Freedom Analysis of Unrolled Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unrolled neural networks emerged recently as an effective model for learning\ninverse maps appearing in image restoration tasks. However, their\ngeneralization risk (i.e., test mean-squared-error) and its link to network\ndesign and train sample size remains mysterious. Leveraging the Stein's\nUnbiased Risk Estimator (SURE), this paper analyzes the generalization risk\nwith its bias and variance components for recurrent unrolled networks. We\nparticularly investigate the degrees-of-freedom (DOF) component of SURE, trace\nof the end-to-end network Jacobian, to quantify the prediction variance. We\nprove that DOF is well-approximated by the weighted \\textit{path sparsity} of\nthe network under incoherence conditions on the trained weights. Empirically,\nwe examine the SURE components as a function of train sample size for both\nrecurrent and non-recurrent (with many more parameters) unrolled networks. Our\nkey observations indicate that: 1) DOF increases with train sample size and\nconverges to the generalization risk for both recurrent and non-recurrent\nschemes; 2) recurrent network converges significantly faster (with less train\nsamples) compared with non-recurrent scheme, hence recurrence serves as a\nregularization for low sample size regimes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:28:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Mardani", "Morteza", ""], ["Sun", "Qingyun", ""], ["Papyan", "Vardan", ""], ["Vasanawala", "Shreyas", ""], ["Pauly", "John", ""], ["Donoho", "David", ""]]}, {"id": "1906.03744", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Soheil Kolouri, James McClelland, Praveen Pilly", "title": "Generative Continual Concept Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After learning a concept, humans are also able to continually generalize\ntheir learned concepts to new domains by observing only a few labeled instances\nwithout any interference with the past learned knowledge. In contrast, learning\nconcepts efficiently in a continual learning setting remains an open challenge\nfor current Artificial Intelligence algorithms as persistent model retraining\nis necessary. Inspired by the Parallel Distributed Processing learning and the\nComplementary Learning Systems theories, we develop a computational model that\nis able to expand its previously learned concepts efficiently to new domains\nusing a few labeled samples. We couple the new form of a concept to its past\nlearned forms in an embedding space for effective continual learning. Doing so,\na generative distribution is learned such that it is shared across the tasks in\nthe embedding space and models the abstract concepts. This procedure enables\nthe model to generate pseudo-data points to replay the past experience to\ntackle catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:30:06 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 05:06:43 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Rostami", "Mohammad", ""], ["Kolouri", "Soheil", ""], ["McClelland", "James", ""], ["Pilly", "Praveen", ""]]}, {"id": "1906.03749", "submitter": "Cecilia Summers", "authors": "Cecilia Summers, Michael J. Dinneen", "title": "Improved Adversarial Robustness via Logit Regularization Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great progress has been made at making neural networks effective across\na wide range of visual tasks, most models are surprisingly vulnerable. This\nfrailness takes the form of small, carefully chosen perturbations of their\ninput, known as adversarial examples, which represent a security threat for\nlearned vision models in the wild -- a threat which should be responsibly\ndefended against in safety-critical applications of computer vision. In this\npaper, we advocate for and experimentally investigate the use of a family of\nlogit regularization techniques as an adversarial defense, which can be used in\nconjunction with other methods for creating adversarial robustness at little to\nno marginal cost. We also demonstrate that much of the effectiveness of one\nrecent adversarial defense mechanism can in fact be attributed to logit\nregularization, and show how to improve its defense against both white-box and\nblack-box attacks, in the process creating a stronger black-box attack against\nPGD-based models. We validate our methods on three datasets and include results\non both gradient-free attacks and strong gradient-based iterative attacks with\nas many as 1,000 steps.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:51:44 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Summers", "Cecilia", ""], ["Dinneen", "Michael J.", ""]]}, {"id": "1906.03750", "submitter": "Yao Ma", "authors": "Yao Ma, Suhang Wang, Tyler Derr, Lingfei Wu and Jiliang Tang", "title": "Attacking Graph Convolutional Networks via Rewiring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have boosted the performance of many graph\nrelated tasks such as node classification and graph classification. Recent\nresearches show that graph neural networks are vulnerable to adversarial\nattacks, which deliberately add carefully created unnoticeable perturbation to\nthe graph structure. The perturbation is usually created by adding/deleting a\nfew edges, which might be noticeable even when the number of edges modified is\nsmall. In this paper, we propose a graph rewiring operation which affects the\ngraph in a less noticeable way compared to adding/deleting edges. We then use\nreinforcement learning to learn the attack strategy based on the proposed\nrewiring operation. Experiments on real world graphs demonstrate the\neffectiveness of the proposed framework. To understand the proposed framework,\nwe further analyze how its generated perturbation to the graph structure\naffects the output of the target model.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:00:07 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 21:58:52 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ma", "Yao", ""], ["Wang", "Suhang", ""], ["Derr", "Tyler", ""], ["Wu", "Lingfei", ""], ["Tang", "Jiliang", ""]]}, {"id": "1906.03751", "submitter": "Qingsong Wen", "authors": "Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Jian Tan", "title": "RobustTrend: A Huber Loss with a Combined First and Second Order\n  Difference Regularization for Time Series Trend Filtering", "comments": "Accepted to the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019), 7 pages. v2: added related references and adjusted\n  font size in figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting the underlying trend signal is a crucial step to facilitate time\nseries analysis like forecasting and anomaly detection. Besides noise signal,\ntime series can contain not only outliers but also abrupt trend changes in\nreal-world scenarios. To deal with these challenges, we propose a robust trend\nfiltering algorithm based on robust statistics and sparse learning.\nSpecifically, we adopt the Huber loss to suppress outliers, and utilize a\ncombination of the first order and second order difference on the trend\ncomponent as regularization to capture both slow and abrupt trend changes.\nFurthermore, an efficient method is designed to solve the proposed robust trend\nfiltering based on majorization minimization (MM) and alternative direction\nmethod of multipliers (ADMM). We compared our proposed robust trend filter with\nother nine state-of-the-art trend filtering algorithms on both synthetic and\nreal-world datasets. The experiments demonstrate that our algorithm outperforms\nexisting methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:00:36 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 00:48:34 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wen", "Qingsong", ""], ["Gao", "Jingkun", ""], ["Song", "Xiaomin", ""], ["Sun", "Liang", ""], ["Tan", "Jian", ""]]}, {"id": "1906.03761", "submitter": "Fariborz Salehi", "authors": "Fariborz Salehi, Ehsan Abbasi, Babak Hassibi", "title": "The Impact of Regularization on High-dimensional Logistic Regression", "comments": null, "journal-ref": "Proceedings of NeurIPS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is commonly used for modeling dichotomous outcomes. In\nthe classical setting, where the number of observations is much larger than the\nnumber of parameters, properties of the maximum likelihood estimator in\nlogistic regression are well understood. Recently, Sur and Candes have studied\nlogistic regression in the high-dimensional regime, where the number of\nobservations and parameters are comparable, and show, among other things, that\nthe maximum likelihood estimator is biased. In the high-dimensional regime the\nunderlying parameter vector is often structured (sparse, block-sparse,\nfinite-alphabet, etc.) and so in this paper we study regularized logistic\nregression (RLR), where a convex regularizer that encourages the desired\nstructure is added to the negative of the log-likelihood function. An advantage\nof RLR is that it allows parameter recovery even for instances where the\n(unconstrained) maximum likelihood estimate does not exist. We provide a\nprecise analysis of the performance of RLR via the solution of a system of six\nnonlinear equations, through which any performance metric of interest (mean,\nmean-squared error, probability of support recovery, etc.) can be explicitly\ncomputed. Our results generalize those of Sur and Candes and we provide a\ndetailed study for the cases of $\\ell_2^2$-RLR and sparse\n($\\ell_1$-regularized) logistic regression. In both cases, we obtain explicit\nexpressions for various performance metrics and can find the values of the\nregularizer parameter that optimizes the desired performance. The theory is\nvalidated by extensive numerical simulations across a range of parameter values\nand problem instances.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:45:00 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 04:29:57 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 19:36:31 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 07:10:57 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Salehi", "Fariborz", ""], ["Abbasi", "Ehsan", ""], ["Hassibi", "Babak", ""]]}, {"id": "1906.03768", "submitter": "Jiangning Chen", "authors": "Jiangning Chen, Zhibo Dai, Juntao Duan, Qianli Hu, Ruilin Li, Heinrich\n  Matzinger, Ionel Popescu, Haoyan Zhai", "title": "A cost-reducing partial labeling estimator in text classification\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to address the text classification problems when\nlearning with partial labels is beneficial. Instead of offering each training\nsample a set of candidate labels, we assign negative-oriented labels to the\nambiguous training examples if they are unlikely fall into certain classes. We\nconstruct our new maximum likelihood estimators with self-correction property,\nand prove that under some conditions, our estimators converge faster. Also we\ndiscuss the advantages of applying one of our estimator to a fully supervised\nlearning problem. The proposed method has potential applicability in many\nareas, such as crowdsourcing, natural language processing and medical image\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 02:22:58 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chen", "Jiangning", ""], ["Dai", "Zhibo", ""], ["Duan", "Juntao", ""], ["Hu", "Qianli", ""], ["Li", "Ruilin", ""], ["Matzinger", "Heinrich", ""], ["Popescu", "Ionel", ""], ["Zhai", "Haoyan", ""]]}, {"id": "1906.03773", "submitter": "Darren Yates", "authors": "Darren Yates, Md Zahidul Islam, Junbin Gao", "title": "DataLearner: A Data Mining and Knowledge Discovery Tool for Android\n  Smartphones and Tablets", "comments": "15 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have become the ultimate 'personal' computer, yet despite this,\ngeneral-purpose data-mining and knowledge discovery tools for mobile devices\nare surprisingly rare. DataLearner is a new data-mining application designed\nspecifically for Android devices that imports the Weka data-mining engine and\naugments it with algorithms developed by Charles Sturt University. Moreover,\nDataLearner can be expanded with additional algorithms. Combined, DataLearner\ndelivers 40 classification, clustering and association rule mining algorithms\nfor model training and evaluation without need for cloud computing resources or\nnetwork connectivity. It provides the same classification accuracy as PCs and\nlaptops, while doing so with acceptable processing speed and consuming\nnegligible battery life. With its ability to provide easy-to-use data-mining on\na phone-size screen, DataLearner is a new portable, self-contained data-mining\ntool for remote, personalised and learning applications alike. DataLearner\nfeatures four elements - this paper, the app available on Google Play, the\nGPL3-licensed source code on GitHub and a short video on YouTube.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 02:41:21 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Yates", "Darren", ""], ["Islam", "Md Zahidul", ""], ["Gao", "Junbin", ""]]}, {"id": "1906.03776", "submitter": "Wentao Ouyang", "authors": "Wentao Ouyang, Xiuwu Zhang, Li Li, Heng Zou, Xin Xing, Zhaojie Liu,\n  Yanlong Du", "title": "Deep Spatio-Temporal Neural Networks for Click-Through Rate Prediction", "comments": "Accepted by KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330655", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a critical task in online advertising\nsystems. A large body of research considers each ad independently, but ignores\nits relationship to other ads that may impact the CTR. In this paper, we\ninvestigate various types of auxiliary ads for improving the CTR prediction of\nthe target ad. In particular, we explore auxiliary ads from two viewpoints: one\nis from the spatial domain, where we consider the contextual ads shown above\nthe target ad on the same page; the other is from the temporal domain, where we\nconsider historically clicked and unclicked ads of the user. The intuitions are\nthat ads shown together may influence each other, clicked ads reflect a user's\npreferences, and unclicked ads may indicate what a user dislikes to certain\nextent. In order to effectively utilize these auxiliary data, we propose the\nDeep Spatio-Temporal neural Networks (DSTNs) for CTR prediction. Our model is\nable to learn the interactions between each type of auxiliary data and the\ntarget ad, to emphasize more important hidden information, and to fuse\nheterogeneous data in a unified framework. Offline experiments on one public\ndataset and two industrial datasets show that DSTNs outperform several\nstate-of-the-art methods for CTR prediction. We have deployed the\nbest-performing DSTN in Shenma Search, which is the second largest search\nengine in China. The A/B test results show that the online CTR is also\nsignificantly improved compared to our last serving model.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 02:49:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 09:07:09 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Ouyang", "Wentao", ""], ["Zhang", "Xiuwu", ""], ["Li", "Li", ""], ["Zou", "Heng", ""], ["Xing", "Xin", ""], ["Liu", "Zhaojie", ""], ["Du", "Yanlong", ""]]}, {"id": "1906.03794", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "The Broad Optimality of Profile Maximum Likelihood", "comments": "Added a new section (Section 8) about truncated PML (TPML) and\n  derived several new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three fundamental statistical-learning problems: distribution\nestimation, property estimation, and property testing. We establish the profile\nmaximum likelihood (PML) estimator as the first unified sample-optimal approach\nto a wide range of learning tasks. In particular, for every alphabet size $k$\nand desired accuracy $\\varepsilon$:\n  $\\textbf{Distribution estimation}$ Under $\\ell_1$ distance, PML yields\noptimal $\\Theta(k/(\\varepsilon^2\\log k))$ sample complexity for\nsorted-distribution estimation, and a PML-based estimator empirically\noutperforms the Good-Turing estimator on the actual distribution;\n  $\\textbf{Additive property estimation}$ For a broad class of additive\nproperties, the PML plug-in estimator uses just four times the sample size\nrequired by the best estimator to achieve roughly twice its error, with\nexponentially higher confidence;\n  $\\boldsymbol{\\alpha}\\textbf{-R\\'enyi entropy estimation}$ For integer\n$\\alpha>1$, the PML plug-in estimator has optimal $k^{1-1/\\alpha}$ sample\ncomplexity; for non-integer $\\alpha>3/4$, the PML plug-in estimator has sample\ncomplexity lower than the state of the art;\n  $\\textbf{Identity testing}$ In testing whether an unknown distribution is\nequal to or at least $\\varepsilon$ far from a given distribution in $\\ell_1$\ndistance, a PML-based tester achieves the optimal sample complexity up to\nlogarithmic factors of $k$.\n  Most of these results also hold for a near-linear-time computable variant of\nPML. Stronger results hold for a different and novel variant called truncated\nPML (TPML).\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 04:59:45 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 17:54:50 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 06:01:20 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1906.03804", "submitter": "Lin Yang", "authors": "Alekh Agarwal, Sham Kakade, Lin F. Yang", "title": "Model-Based Reinforcement Learning with a Generative Model is Minimax\n  Optimal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the sample and computational complexity of obtaining an\n$\\epsilon$-optimal policy in a discounted Markov Decision Process (MDP), given\nonly access to a generative model. In this work, we study the effectiveness of\nthe most natural plug-in approach to model-based planning: we build the maximum\nlikelihood estimate of the transition model in the MDP from observations and\nthen find an optimal policy in this empirical MDP. We ask arguably the most\nbasic and unresolved question in model based planning: is the naive \"plug-in\"\napproach, non-asymptotically, minimax optimal in the quality of the policy it\nfinds, given a fixed sample size? Here, the non-asymptotic regime refers to\nwhen the sample size is sublinear in the model size.\n  With access to a generative model, we resolve this question in the strongest\npossible sense: our main result shows that \\emph{any} high accuracy solution in\nthe plug-in model constructed with $N$ samples, provides an $\\epsilon$-optimal\npolicy in the true underlying MDP (where $\\epsilon$ is the minimax accuracy\nwith $N$ samples at every state, action pair). In comparison, all prior\n(non-asymptotically) minimax optimal results use model free approaches, such as\nthe Variance Reduced Q-value iteration algorithm (Sidford et al 2018), while\nthe best known model-based results (e.g. Azar et al 2013) require larger sample\nsizes in their dependence on the planning horizon or the state space. Notably,\nwe show that the model-based approach allows the use of \\emph{any} efficient\nplanning algorithm in the empirical MDP, which simplifies algorithm design as\nthis approach does not tie the algorithm to the sampling procedure. The core of\nour analysis is avnovel \"absorbing MDP\" construction to address the statistical\ndependency issues that arise in the analysis of model-based planning\napproaches, a construction which may be helpful more generally.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 05:50:03 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 15:13:06 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 03:25:37 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Agarwal", "Alekh", ""], ["Kakade", "Sham", ""], ["Yang", "Lin F.", ""]]}, {"id": "1906.03805", "submitter": "Dilin Wang", "authors": "Dilin Wang, Chengyue Gong, Qiang Liu", "title": "Improving Neural Language Modeling via Adversarial Training", "comments": null, "journal-ref": "International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, substantial progress has been made in language modeling by using\ndeep neural networks. However, in practice, large scale neural language models\nhave been shown to be prone to overfitting. In this paper, we present a simple\nyet highly effective adversarial training mechanism for regularizing neural\nlanguage models. The idea is to introduce adversarial noise to the output\nembedding layer while training the models. We show that the optimal adversarial\nnoise yields a simple closed-form solution, thus allowing us to develop a\nsimple and time efficient algorithm. Theoretically, we show that our\nadversarial mechanism effectively encourages the diversity of the embedding\nvectors, helping to increase the robustness of models. Empirically, we show\nthat our method improves on the single model state-of-the-art results for\nlanguage modeling on Penn Treebank (PTB) and Wikitext-2, achieving test\nperplexity scores of 46.01 and 38.07, respectively. When applied to machine\ntranslation, our method improves over various transformer-based translation\nbaselines in BLEU scores on the WMT14 English-German and IWSLT14 German-English\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 05:55:08 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:04:21 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Dilin", ""], ["Gong", "Chengyue", ""], ["Liu", "Qiang", ""]]}, {"id": "1906.03807", "submitter": "Miaoyan Wang", "authors": "Miaoyan Wang and Yuchen Zeng", "title": "Multiway clustering via tensor block models", "comments": "add the supplements", "journal-ref": "Advances in Neural Information Processing Systems 32 (NeurIPS\n  2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of identifying multiway block structure from a large\nnoisy tensor. Such problems arise frequently in applications such as genomics,\nrecommendation system, topic modeling, and sensor network localization. We\npropose a tensor block model, develop a unified least-square estimation, and\nobtain the theoretical accuracy guarantees for multiway clustering. The\nstatistical convergence of the estimator is established, and we show that the\nassociated clustering procedure achieves partition consistency. A sparse\nregularization is further developed for identifying important blocks with\nelevated means. The proposal handles a broad range of data types, including\nbinary, continuous, and hybrid observations. Through simulation and application\nto two real datasets, we demonstrate the outperformance of our approach over\nprevious methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 06:07:41 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 22:10:42 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 06:14:01 GMT"}, {"version": "v4", "created": "Sat, 2 Jan 2021 23:25:41 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wang", "Miaoyan", ""], ["Zeng", "Yuchen", ""]]}, {"id": "1906.03808", "submitter": "Hossein Mobahi", "authors": "Vighnesh Birodkar, Hossein Mobahi, Dilip Krishnan, Samy Bengio", "title": "A Closed-Form Learned Pooling for Deep Classification Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern computer vision tasks, convolutional neural networks (CNNs) are\nindispensable for image classification tasks due to their efficiency and\neffectiveness. Part of their superiority compared to other architectures, comes\nfrom the fact that a single, local filter is shared across the entire image.\nHowever, there are scenarios where we may need to treat spatial locations in\nnon-uniform manner. We see this in nature when considering how humans have\nevolved foveation to process different areas in their field of vision with\nvarying levels of detail. In this paper we propose a way to enable CNNs to\nlearn different pooling weights for each pixel location. We do so by\nintroducing an extended definition of a pooling operator. This operator can\nlearn a strict super-set of what can be learned by average pooling or\nconvolutions. It has the benefit of being shared across feature maps and can be\nencouraged to be local or diffuse depending on the data. We show that for fixed\nnetwork weights, our pooling operator can be computed in closed-form by\nspectral decomposition of matrices associated with class separability. Through\nexperiments, we show that this operator benefits generalization for ResNets and\nCNNs on the CIFAR-10, CIFAR-100 and SVHN datasets and improves robustness to\ngeometric corruptions and perturbations on the CIFAR-10-C and CIFAR-10-P test\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 06:24:21 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Birodkar", "Vighnesh", ""], ["Mobahi", "Hossein", ""], ["Krishnan", "Dilip", ""], ["Bengio", "Samy", ""]]}, {"id": "1906.03813", "submitter": "Michael McCourt", "authors": "Michael McCourt, Ian Dewancker", "title": "Sampling Humans for Optimizing Preferences in Coloring Artwork", "comments": "6 pages, 4 figures, presented at 2019 ICML Workshop on Human in the\n  Loop Learning (HILL 2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many circumstances of practical importance have performance or success\nmetrics which exist implicitly---in the eye of the beholder, so to speak.\nTuning aspects of such problems requires working without defined metrics and\nonly considering pairwise comparisons or rankings. In this paper, we review an\nexisting Bayesian optimization strategy for determining most-preferred\noutcomes, and identify an adaptation to allow it to handle ties. We then\ndiscuss some of the issues we have encountered when humans use this\noptimization strategy to optimize coloring a piece of abstract artwork. We hope\nthat, by participating in this workshop, we can learn how other researchers\nencounter difficulties unique to working with humans in the loop.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 06:46:41 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["McCourt", "Michael", ""], ["Dewancker", "Ian", ""]]}, {"id": "1906.03814", "submitter": "Yi Wei", "authors": "Yi Wei, Ming-Min Zhao, Mingyi Hong, Min-jian Zhao and Ming Lei", "title": "Learned Conjugate Gradient Descent Network for Massive MIMO Detection", "comments": "Part of this work has been accepted by IEEE ICC 2020", "journal-ref": null, "doi": "10.1109/TSP.2020.3035832", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the use of model-driven deep learning techniques\nfor massive multiple-input multiple-output (MIMO) detection. Compared with\nconventional MIMO systems, massive MIMO promises improved spectral efficiency,\ncoverage and range. Unfortunately, these benefits are coming at the cost of\nsignificantly increased computational complexity. To reduce the complexity of\nsignal detection and guarantee the performance, we present a learned conjugate\ngradient descent network (LcgNet), which is constructed by unfolding the\niterative conjugate gradient descent (CG) detector. In the proposed network,\ninstead of calculating the exact values of the scalar step-sizes, we explicitly\nlearn their universal values. Also, we can enhance the proposed network by\naugmenting the dimensions of these step-sizes. Furthermore, in order to reduce\nthe memory costs, a novel quantized LcgNet is proposed, where a low-resolution\nnonuniform quantizer is integrated into the LcgNet to smartly quantize the\naforementioned step-sizes. The quantizer is based on a specially designed soft\nstaircase function with learnable parameters to adjust its shape. Meanwhile,\ndue to fact that the number of learnable parameters is limited, the proposed\nnetworks are easy and fast to train. Numerical results demonstrate that the\nproposed network can achieve promising performance with much lower complexity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 06:49:40 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 06:16:53 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 15:09:07 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 07:13:55 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Wei", "Yi", ""], ["Zhao", "Ming-Min", ""], ["Hong", "Mingyi", ""], ["Zhao", "Min-jian", ""], ["Lei", "Ming", ""]]}, {"id": "1906.03821", "submitter": "Hansheng Ren", "authors": "Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu\n  Kou, Tony Xing, Mao Yang, Jie Tong, Qi Zhang", "title": "Time-Series Anomaly Detection Service at Microsoft", "comments": "KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330680", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large companies need to monitor various metrics (for example, Page Views and\nRevenue) of their applications and services in real time. At Microsoft, we\ndevelop a time-series anomaly detection service which helps customers to\nmonitor the time-series continuously and alert for potential incidents on time.\nIn this paper, we introduce the pipeline and algorithm of our anomaly detection\nservice, which is designed to be accurate, efficient and general. The pipeline\nconsists of three major modules, including data ingestion, experimentation\nplatform and online compute. To tackle the problem of time-series anomaly\ndetection, we propose a novel algorithm based on Spectral Residual (SR) and\nConvolutional Neural Network (CNN). Our work is the first attempt to borrow the\nSR model from visual saliency detection domain to time-series anomaly\ndetection. Moreover, we innovatively combine SR and CNN together to improve the\nperformance of SR model. Our approach achieves superior experimental results\ncompared with state-of-the-art baselines on both public datasets and Microsoft\nproduction data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 07:31:40 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ren", "Hansheng", ""], ["Xu", "Bixiong", ""], ["Wang", "Yujing", ""], ["Yi", "Chao", ""], ["Huang", "Congrui", ""], ["Kou", "Xiaoyu", ""], ["Xing", "Tony", ""], ["Yang", "Mao", ""], ["Tong", "Jie", ""], ["Zhang", "Qi", ""]]}, {"id": "1906.03822", "submitter": "Gyeong-In Yu", "authors": "Gyeong-In Yu, Saeed Amizadeh, Sehoon Kim, Artidoro Pagnoni, Byung-Gon\n  Chun, Markus Weimer, Matteo Interlandi", "title": "Making Classical Machine Learning Pipelines Differentiable: A Neural\n  Translation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical Machine Learning (ML) pipelines often comprise of multiple ML\nmodels where models, within a pipeline, are trained in isolation. Conversely,\nwhen training neural network models, layers composing the neural models are\nsimultaneously trained using backpropagation. We argue that the isolated\ntraining scheme of ML pipelines is sub-optimal, since it cannot jointly\noptimize multiple components. To this end, we propose a framework that\ntranslates a pre-trained ML pipeline into a neural network and fine-tunes the\nML models within the pipeline jointly using backpropagation. Our experiments\nshow that fine-tuning of the translated pipelines is a promising technique able\nto increase the final accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 07:43:32 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 15:29:10 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yu", "Gyeong-In", ""], ["Amizadeh", "Saeed", ""], ["Kim", "Sehoon", ""], ["Pagnoni", "Artidoro", ""], ["Chun", "Byung-Gon", ""], ["Weimer", "Markus", ""], ["Interlandi", "Matteo", ""]]}, {"id": "1906.03826", "submitter": "Yasutoshi Ida", "authors": "Yasutoshi Ida and Yasuhiro Fujiwara", "title": "Network Implosion: Effective Model Compression for ResNets via Static\n  Layer Pruning and Retraining", "comments": "Preprint of International Joint Conference on Neural Networks (IJCNN)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual Networks with convolutional layers are widely used in the field of\nmachine learning. Since they effectively extract features from input data by\nstacking multiple layers, they can achieve high accuracy in many applications.\nHowever, the stacking of many layers raises their computation costs. To address\nthis problem, we propose Network Implosion, it erases multiple layers from\nResidual Networks without degrading accuracy. Our key idea is to introduce a\npriority term that identifies the importance of a layer; we can select\nunimportant layers according to the priority and erase them after the training.\nIn addition, we retrain the networks to avoid critical drops in accuracy after\nlayer erasure. A theoretical assessment reveals that our erasure and retraining\nscheme can erase layers without accuracy drop, and achieve higher accuracy than\nis possible with training from scratch. Our experiments show that Network\nImplosion can, for classification on Cifar-10/100 and ImageNet, reduce the\nnumber of layers by 24.00 to 42.86 percent without any drop in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 07:53:18 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ida", "Yasutoshi", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "1906.03830", "submitter": "Navid Azizan Ruhi", "authors": "Navid Azizan, Sahin Lale, Babak Hassibi", "title": "Stochastic Mirror Descent on Overparameterized Nonlinear Models:\n  Convergence, Implicit Regularization, and Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern learning problems are highly overparameterized, meaning that\nthere are many more parameters than the number of training data points, and as\na result, the training loss may have infinitely many global minima (parameter\nvectors that perfectly interpolate the training data). Therefore, it is\nimportant to understand which interpolating solutions we converge to, how they\ndepend on the initialization point and the learning algorithm, and whether they\nlead to different generalization performances. In this paper, we study these\nquestions for the family of stochastic mirror descent (SMD) algorithms, of\nwhich the popular stochastic gradient descent (SGD) is a special case. Our\ncontributions are both theoretical and experimental. On the theory side, we\nshow that in the overparameterized nonlinear setting, if the initialization is\nclose enough to the manifold of global minima (something that comes for free in\nthe highly overparameterized case), SMD with sufficiently small step size\nconverges to a global minimum that is approximately the closest one in Bregman\ndivergence. On the experimental side, our extensive experiments on standard\ndatasets and models, using various initializations, various mirror descents,\nand various Bregman divergences, consistently confirms that this phenomenon\nhappens in deep learning. Our experiments further indicate that there is a\nclear difference in the generalization performance of the solutions obtained by\ndifferent SMD algorithms. Experimenting on a standard image dataset and network\narchitecture with SMD with different kinds of implicit regularization, $\\ell_1$\nto encourage sparsity, $\\ell_2$ yielding SGD, and $\\ell_{10}$ to discourage\nlarge components in the parameter vector, consistently and definitively shows\nthat $\\ell_{10}$-SMD has better generalization performance than SGD, which in\nturn has better generalization performance than $\\ell_1$-SMD.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:01:27 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Azizan", "Navid", ""], ["Lale", "Sahin", ""], ["Hassibi", "Babak", ""]]}, {"id": "1906.03835", "submitter": "Nghi D. Q. Bui", "authors": "Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang", "title": "SAR: Learning Cross-Language API Mappings with Little Knowledge", "comments": "Accepted at the 27th ACM Joint European Software Engineering\n  Conference and Symposium on the Foundations of Software Engineering\n  (ESEC/FSE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To save manual effort, developers often translate programs from one\nprogramming language to another, instead of implementing it from scratch.\nTranslating application program interfaces (APIs) used in one language to\nfunctionally equivalent ones available in another language is an important\naspect of program translation. Existing approaches facilitate the translation\nby automatically identifying the API mappings across programming languages.\nHowever, all these approaches still require large amount of manual effort in\npreparing parallel program corpora, ranging from pairs of APIs, to manually\nidentified code in different languages that are considered as functionally\nequivalent. To minimize the manual effort in identifying parallel program\ncorpora and API mappings, this paper aims at an automated approach to map APIs\nacross languages with much less knowledge a priori needed than other existing\napproaches. The approach is based on an realization of the notion of domain\nadaption combined with code embedding, which can better align two vector\nspaces: taking as input large sets of programs, our approach first generates\nnumeric vector representations of the programs, especially the APIs used in\neach language, and it adapts generative adversarial networks (GAN) to align the\nvectors from the spaces of two languages. For a better alignment, we initialize\nthe GAN with parameters derived from optional API mapping seeds that can be\nidentified accurately with a simple automatic signature-based matching\nheuristic. Then the cross-language API mappings can be identified via\nnearest-neighbors queries in the aligned vector spaces.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:13:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Yu", "Yijun", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "1906.03842", "submitter": "Michael Dusenberry", "authors": "Michael W. Dusenberry, Dustin Tran, Edward Choi, Jonas Kemp, Jeremy\n  Nixon, Ghassen Jerfel, Katherine Heller, Andrew M. Dai", "title": "Analyzing the Role of Model Uncertainty for Electronic Health Records", "comments": "Published in the ACM Conference on Health, Inference, and Learning\n  (CHIL) 2020. Code available at\n  https://github.com/Google-Health/records-research", "journal-ref": null, "doi": "10.1145/3368555.3384457", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medicine, both ethical and monetary costs of incorrect predictions can be\nsignificant, and the complexity of the problems often necessitates increasingly\ncomplex models. Recent work has shown that changing just the random seed is\nenough for otherwise well-tuned deep neural networks to vary in their\nindividual predicted probabilities. In light of this, we investigate the role\nof model uncertainty methods in the medical domain. Using RNN ensembles and\nvarious Bayesian RNNs, we show that population-level metrics, such as AUC-PR,\nAUC-ROC, log-likelihood, and calibration error, do not capture model\nuncertainty. Meanwhile, the presence of significant variability in\npatient-specific predictions and optimal decisions motivates the need for\ncapturing model uncertainty. Understanding the uncertainty for individual\npatients is an area with clear clinical impact, such as determining when a\nmodel decision is likely to be brittle. We further show that RNNs with only\nBayesian embeddings can be a more efficient way to capture model uncertainty\ncompared to ensembles, and we analyze how model uncertainty is impacted across\nindividual input features and patient subgroups.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:46:24 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 02:03:58 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 22:38:20 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Dusenberry", "Michael W.", ""], ["Tran", "Dustin", ""], ["Choi", "Edward", ""], ["Kemp", "Jonas", ""], ["Nixon", "Jeremy", ""], ["Jerfel", "Ghassen", ""], ["Heller", "Katherine", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1906.03843", "submitter": "YooJung Choi", "authors": "YooJung Choi, Golnoosh Farnadi, Behrouz Babaki, Guy Van den Broeck", "title": "Learning Fair Naive Bayes Classifiers by Discovering and Eliminating\n  Discrimination Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to make real-world decisions, recent\nresearch efforts aim to define and ensure fairness in algorithmic decision\nmaking. Existing methods often assume a fixed set of observable features to\ndefine individuals, but lack a discussion of certain features not being\nobserved at test time. In this paper, we study fairness of naive Bayes\nclassifiers, which allow partial observations. In particular, we introduce the\nnotion of a discrimination pattern, which refers to an individual receiving\ndifferent classifications depending on whether some sensitive attributes were\nobserved. Then a model is considered fair if it has no such pattern. We propose\nan algorithm to discover and mine for discrimination patterns in a naive Bayes\nclassifier, and show how to learn maximum likelihood parameters subject to\nthese fairness constraints. Our approach iteratively discovers and eliminates\ndiscrimination patterns until a fair model is learned. An empirical evaluation\non three real-world datasets demonstrates that we can remove exponentially many\ndiscrimination patterns by only adding a small fraction of them as constraints.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:48:19 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 22:46:36 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "YooJung", ""], ["Farnadi", "Golnoosh", ""], ["Babaki", "Behrouz", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1906.03849", "submitter": "Hongge Chen", "authors": "Hongge Chen, Huan Zhang, Si Si, Yang Li, Duane Boning and Cho-Jui\n  Hsieh", "title": "Robustness Verification of Tree-based Models", "comments": "Hongge Chen and Huan Zhang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness verification problem for tree-based models, including\ndecision trees, random forests (RFs) and gradient boosted decision trees\n(GBDTs). Formal robustness verification of decision tree ensembles involves\nfinding the exact minimal adversarial perturbation or a guaranteed lower bound\nof it. Existing approaches find the minimal adversarial perturbation by a mixed\ninteger linear programming (MILP) problem, which takes exponential time so is\nimpractical for large ensembles. Although this verification problem is\nNP-complete in general, we give a more precise complexity characterization. We\nshow that there is a simple linear time algorithm for verifying a single tree,\nand for tree ensembles, the verification problem can be cast as a max-clique\nproblem on a multi-partite graph with bounded boxicity. For low dimensional\nproblems when boxicity can be viewed as constant, this reformulation leads to a\npolynomial time algorithm. For general problems, by exploiting the boxicity of\nthe graph, we develop an efficient multi-level verification algorithm that can\ngive tight lower bounds on the robustness of decision tree ensembles, while\nallowing iterative improvement and any-time termination. OnRF/GBDT models\ntrained on 10 datasets, our algorithm is hundreds of times faster than the\nprevious approach that requires solving MILPs, and is able to give tight\nrobustness verification bounds on large GBDTs with hundreds of deep trees.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:57:31 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 20:52:15 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 23:43:07 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Chen", "Hongge", ""], ["Zhang", "Huan", ""], ["Si", "Si", ""], ["Li", "Yang", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.03855", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues, Nicola Ortelli, Michel Bierlaire, Francisco Pereira", "title": "Bayesian Automatic Relevance Determination for Utility Function\n  Specification in Discrete Choice Models", "comments": "21 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specifying utility functions is a key step towards applying the discrete\nchoice framework for understanding the behaviour processes that govern user\nchoices. However, identifying the utility function specifications that best\nmodel and explain the observed choices can be a very challenging and\ntime-consuming task. This paper seeks to help modellers by leveraging the\nBayesian framework and the concept of automatic relevance determination (ARD),\nin order to automatically determine an optimal utility function specification\nfrom an exponentially large set of possible specifications in a purely\ndata-driven manner. Based on recent advances in approximate Bayesian inference,\na doubly stochastic variational inference is developed, which allows the\nproposed DCM-ARD model to scale to very large and high-dimensional datasets.\nUsing semi-artificial choice data, the proposed approach is shown to very\naccurately recover the true utility function specifications that govern the\nobserved choices. Moreover, when applied to real choice data, DCM-ARD is shown\nto be able discover high quality specifications that can outperform previous\nones from the literature according to multiple criteria, thereby demonstrating\nits practical applicability.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 09:14:39 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Ortelli", "Nicola", ""], ["Bierlaire", "Michel", ""], ["Pereira", "Francisco", ""]]}, {"id": "1906.03859", "submitter": "Yuval Atzmon", "authors": "Roman Visotsky, Yuval Atzmon, Gal Chechik", "title": "Few-Shot Learning with Per-Sample Rich Supervision", "comments": "Accepted to AGI 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with few samples is a major challenge for parameter-rich models like\ndeep networks. In contrast, people learn complex new concepts even from very\nfew examples, suggesting that the sample complexity of learning can often be\nreduced. Many approaches to few-shot learning build on transferring a\nrepresentation from well-sampled classes, or using meta learning to favor\narchitectures that can learn with few samples. Unfortunately, such approaches\noften struggle when learning in an online way or with non-stationary data\nstreams. Here we describe a new approach to learn with fewer samples, by using\nadditional information that is provided per sample. Specifically, we show how\nthe sample complexity can be reduced by providing semantic information about\nthe relevance of features per sample, like information about the presence of\nobjects in a scene or confidence of detecting attributes in an image. We\nprovide an improved generalization error bound for this case. We cast the\nproblem of using per-sample feature relevance by using a new ellipsoid-margin\nloss, and develop an online algorithm that minimizes this loss effectively.\nEmpirical evaluation on two machine vision benchmarks for scene classification\nand fine-grain bird classification demonstrate the benefits of this approach\nfor few-shot learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 09:17:30 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Visotsky", "Roman", ""], ["Atzmon", "Yuval", ""], ["Chechik", "Gal", ""]]}, {"id": "1906.03866", "submitter": "David Rindt", "authors": "David Rindt, Dino Sejdinovic, David Steinsaltz", "title": "A kernel- and optimal transport- based test of independence between\n  covariates and right-censored lifetimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric test of independence, termed optHSIC, between a\ncovariate and a right-censored lifetime. Because the presence of censoring\ncreates a challenge in applying the standard permutation-based testing\napproaches, we use optimal transport to transform the censored dataset into an\nuncensored one, while preserving the relevant dependencies. We then apply a\npermutation test using the kernel-based dependence measure as a statistic to\nthe transformed dataset. The type 1 error is proven to be correct in the case\nwhere censoring is independent of the covariate. Experiments indicate that\noptHSIC has power against a much wider class of alternatives than Cox\nproportional hazards regression and that it has the correct type 1 control even\nin the challenging cases where censoring strongly depends on the covariate.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 09:32:57 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:02:36 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 13:58:01 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Rindt", "David", ""], ["Sejdinovic", "Dino", ""], ["Steinsaltz", "David", ""]]}, {"id": "1906.03886", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Taiji Suzuki", "title": "Goodness-of-fit Test for Latent Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent block models are used for probabilistic biclustering, which is shown\nto be an effective method for analyzing various relational data sets. However,\nthere has been no statistical test method for determining the row and column\ncluster numbers of latent block models. Recent studies have constructed\nstatistical-test-based methods for stochastic block models, which assume that\nthe observed matrix is a square symmetric matrix and that the cluster\nassignments are the same for rows and columns. In this study, we developed a\nnew goodness-of-fit test for latent block models to test whether an observed\ndata matrix fits a given set of row and column cluster numbers, or it consists\nof more clusters in at least one direction of the row and the column. To\nconstruct the test method, we used a result from the random matrix theory for a\nsample covariance matrix. We experimentally demonstrated the effectiveness of\nthe proposed method by showing the asymptotic behavior of the test statistic\nand measuring the test accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 10:38:18 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 13:55:44 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 13:20:43 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 18:20:09 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2020 05:54:02 GMT"}, {"version": "v6", "created": "Mon, 6 Jul 2020 03:46:47 GMT"}, {"version": "v7", "created": "Thu, 17 Sep 2020 03:30:37 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1906.03923", "submitter": "Kun Xu", "authors": "Kun Xu, Chongxuan Li, Jun Zhu, Bo Zhang", "title": "Multi-objects Generation with Amortized Structural Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models (DGMs) have shown promise in image generation.\nHowever, most of the existing work learn the model by simply optimizing a\ndivergence between the marginal distributions of the model and the data, and\noften fail to capture the rich structures and relations in multi-object images.\nHuman knowledge is a critical element to the success of DGMs to infer these\nstructures. In this paper, we propose the amortized structural regularization\n(ASR) framework, which adopts the posterior regularization (PR) to embed human\nknowledge into DGMs via a set of structural constraints. We derive a lower\nbound of the regularized log-likelihood, which can be jointly optimized with\nrespect to the generative model and recognition model efficiently. Empirical\nresults show that ASR significantly outperforms the DGM baselines in terms of\ninference accuracy and sample quality.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 12:09:55 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Xu", "Kun", ""], ["Li", "Chongxuan", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1906.03926", "submitter": "Nantas Nardelli", "authors": "Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster,\n  Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rockt\\\"aschel", "title": "A Survey of Reinforcement Learning Informed by Natural Language", "comments": "Published at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be successful in real-world tasks, Reinforcement Learning (RL) needs to\nexploit the compositional, relational, and hierarchical structure of the world,\nand learn to transfer it to the task at hand. Recent advances in representation\nlearning for language make it possible to build models that acquire world\nknowledge from text corpora and integrate this knowledge into downstream\ndecision making problems. We thus argue that the time is right to investigate a\ntight integration of natural language understanding into RL in particular. We\nsurvey the state of the field, including work on instruction following, text\ngames, and learning from textual domain knowledge. Finally, we call for the\ndevelopment of new environments as well as further investigation into the\npotential uses of recent Natural Language Processing (NLP) techniques for such\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 12:17:45 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Luketina", "Jelena", ""], ["Nardelli", "Nantas", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Andreas", "Jacob", ""], ["Grefenstette", "Edward", ""], ["Whiteson", "Shimon", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1906.03939", "submitter": "Adam Katona", "authors": "Adam Katona, Ryan Spick, Victoria Hodge, Simon Demediuk, Florian\n  Block, Anders Drachen, James Alfred Walker", "title": "Time to Die: Death Prediction in Dota 2 using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Esports have become major international sports with hundreds of millions of\nspectators. Esports games generate massive amounts of telemetry data. Using\nthese to predict the outcome of esports matches has received considerable\nattention, but micro-predictions, which seek to predict events inside a match,\nis as yet unknown territory. Micro-predictions are however of perennial\ninterest across esports commentators and audience, because they provide the\nability to observe events that might otherwise be missed: esports games are\nhighly complex with fast-moving action where the balance of a game can change\nin the span of seconds, and where events can happen in multiple areas of the\nplaying field at the same time. Such events can happen rapidly, and it is easy\nfor commentators and viewers alike to miss an event and only observe the\nfollowing impact of events. In Dota 2, a player hero being killed by the\nopposing team is a key event of interest to commentators and audience. We\npresent a deep learning network with shared weights which provides accurate\ndeath predictions within a five-second window. The network is trained on a vast\nselection of Dota 2 gameplay features and professional/semi-professional level\nmatch dataset. Even though death events are rare within a game (1\\% of the\ndata), the model achieves 0.377 precision with 0.725 recall on test data when\nprompted to predict which of any of the 10 players of either team will die\nwithin 5 seconds. An example of the system applied to a Dota 2 match is\npresented. This model enables real-time micro-predictions of kills in Dota 2,\none of the most played esports titles in the world, giving commentators and\nviewers time to move their attention to these key events.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:36:56 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Katona", "Adam", ""], ["Spick", "Ryan", ""], ["Hodge", "Victoria", ""], ["Demediuk", "Simon", ""], ["Block", "Florian", ""], ["Drachen", "Anders", ""], ["Walker", "James Alfred", ""]]}, {"id": "1906.03950", "submitter": "Seonguk Seo", "authors": "Woong-Gi Chang, Tackgeun You, Seonguk Seo, Suha Kwak, Bohyung Han", "title": "Domain-Specific Batch Normalization for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel unsupervised domain adaptation framework based on\ndomain-specific batch normalization in deep neural networks. We aim to adapt to\nboth domains by specializing batch normalization layers in convolutional neural\nnetworks while allowing them to share all other model parameters, which is\nrealized by a two-stage algorithm. In the first stage, we estimate\npseudo-labels for the examples in the target domain using an external\nunsupervised domain adaptation algorithm---for example, MSTN or\nCPUA---integrating the proposed domain-specific batch normalization. The second\nstage learns the final models using a multi-task classification loss for the\nsource and target domains. Note that the two domains have separate batch\nnormalization layers in both stages. Our framework can be easily incorporated\ninto the domain adaptation techniques based on deep neural networks with batch\nnormalization layers. We also present that our approach can be extended to the\nproblem with multiple source domains. The proposed algorithm is evaluated on\nmultiple benchmark datasets and achieves the state-of-the-art accuracy in the\nstandard setting and the multi-source domain adaption scenario.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:46:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chang", "Woong-Gi", ""], ["You", "Tackgeun", ""], ["Seo", "Seonguk", ""], ["Kwak", "Suha", ""], ["Han", "Bohyung", ""]]}, {"id": "1906.03951", "submitter": "Linfeng Zhang", "authors": "Linfeng Zhang, Zhanhong Tan, Jiebo Song, Jingwei Chen, Chenglong Bao,\n  Kaisheng Ma", "title": "SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remarkable achievements have been attained by deep neural networks in various\napplications. However, the increasing depth and width of such models also lead\nto explosive growth in both storage and computation, which has restricted the\ndeployment of deep neural networks on resource-limited edge devices. To address\nthis problem, we propose the so-called SCAN framework for networks training and\ninference, which is orthogonal and complementary to existing acceleration and\ncompression methods. The proposed SCAN firstly divides neural networks into\nmultiple sections according to their depth and constructs shallow classifiers\nupon the intermediate features of different sections. Moreover, attention\nmodules and knowledge distillation are utilized to enhance the accuracy of\nshallow classifiers. Based on this architecture, we further propose a threshold\ncontrolled scalable inference mechanism to approach human-like sample-specific\ninference. Experimental results show that SCAN can be easily equipped on\nvarious neural networks without any adjustment on hyper-parameters or neural\nnetworks architectures, yielding significant performance gain on CIFAR100 and\nImageNet. Codes will be released on github soon.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:11:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Linfeng", ""], ["Tan", "Zhanhong", ""], ["Song", "Jiebo", ""], ["Chen", "Jingwei", ""], ["Bao", "Chenglong", ""], ["Ma", "Kaisheng", ""]]}, {"id": "1906.03956", "submitter": "Evgeny Burnaev", "authors": "Rodrigo Rivera-Castro and Polina Pilyugina and Alexander Pletnev and\n  Ivan Maksimov and Wanyi Wyz and Evgeny Burnaev", "title": "Topological Data Analysis of Time Series Data for B2B Customer\n  Relationship Management", "comments": "9 pages, 2 figures, 1 table", "journal-ref": "Industrial Marketing & Purchasing Group Conference (IMP19), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) is a recent approach to analyze data sets\nfrom the perspective of their topological structure. Its use for time series\ndata has been limited to the field of financial time series primarily and as a\nmethod for feature generation in machine learning applications. In this work,\nTDA is presented as a technique to gain additional understanding of the\ncustomers' loyalty for business-to-business customer relationship management.\nIncreasing loyalty and strengthening relationships with key accounts remain an\nactive topic of discussion both for researchers and managers. Using two public\nand two proprietary data sets of commercial data, this research shows that the\ntechnique enables analysts to better understand their customer base and\nidentify prospective opportunities. In addition, the approach can be used as a\nclustering method to increase the accuracy of a predictive model for loyalty\nscoring. This work thus seeks to introduce TDA as a viable tool for data\nanalysis to the quantitate marketing practitioner.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 03:09:10 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 11:54:18 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Pilyugina", "Polina", ""], ["Pletnev", "Alexander", ""], ["Maksimov", "Ivan", ""], ["Wyz", "Wanyi", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1906.03967", "submitter": "Adrien Laversanne-Finot", "authors": "Adrien Laversanne-Finot and Alexandre P\\'er\\'e and Pierre-Yves Oudeyer", "title": "Autonomous Goal Exploration using Learned Goal Spaces for Visuomotor\n  Skill Acquisition in Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic and efficient discovery of skills, without supervision, for\nlong-living autonomous agents, remains a challenge of Artificial Intelligence.\nIntrinsically Motivated Goal Exploration Processes give learning agents a\nhuman-inspired mechanism to sequentially select goals to achieve. This approach\ngives a new perspective on the lifelong learning problem, with promising\nresults on both simulated and real-world experiments. Until recently, those\nalgorithms were restricted to domains with experimenter-knowledge, since the\nGoal Space used by the agents was built on engineered feature extractors. The\nrecent advances of deep representation learning, enables new ways of designing\nthose feature extractors, using directly the agent experience. Recent work has\nshown the potential of those methods on simple yet challenging simulated\ndomains. In this paper, we present recent results showing the applicability of\nthose principles on a real-world robotic setup, where a 6-joint robotic arm\nlearns to manipulate a ball inside an arena, by choosing goals in a space\nlearned from its past experience.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:31:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Laversanne-Finot", "Adrien", ""], ["P\u00e9r\u00e9", "Alexandre", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1906.03972", "submitter": "Lu Wang", "authors": "Lu Wang, Xuanqing Liu, Jinfeng Yi, Zhi-Hua Zhou, Cho-Jui Hsieh", "title": "Evaluating the Robustness of Nearest Neighbor Classifiers: A Primal-Dual\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing the minimum adversarial perturbation of the\nNearest Neighbor (NN) classifiers. Previous attempts either conduct attacks on\ncontinuous approximations of NN models or search for the perturbation by some\nheuristic methods. In this paper, we propose the first algorithm that is able\nto compute the minimum adversarial perturbation. The main idea is to formulate\nthe problem as a list of convex quadratic programming (QP) problems that can be\nefficiently solved by the proposed algorithms for 1-NN models. Furthermore, we\nshow that dual solutions for these QP problems could give us a valid lower\nbound of the adversarial perturbation that can be used for formal robustness\nverification, giving us a nice view of attack/verification for NN models. For\n$K$-NN models with larger $K$, we show that the same formulation can help us\nefficiently compute the upper and lower bounds of the minimum adversarial\nperturbation, which can be used for attack and verification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:38:23 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Lu", ""], ["Liu", "Xuanqing", ""], ["Yi", "Jinfeng", ""], ["Zhou", "Zhi-Hua", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.03979", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf, Srinivasan Parthasarathy, Horst Samulowitz, Martin\n  Wistub", "title": "Optimal Exploitation of Clustering and History Information in\n  Multi-Armed Bandit", "comments": "IJCAI 2019, International Joint Conferences on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic multi-armed bandit problem and the contextual\nbandit problem with historical observations and pre-clustered arms. The\nhistorical observations can contain any number of instances for each arm, and\nthe pre-clustering information is a fixed clustering of arms provided as part\nof the input. We develop a variety of algorithms which incorporate this offline\ninformation effectively during the online exploration phase and derive their\nregret bounds. In particular, we develop the META algorithm which effectively\nhedges between two other algorithms: one which uses both historical\nobservations and clustering, and another which uses only the historical\nobservations. The former outperforms the latter when the clustering quality is\ngood, and vice-versa. Extensive experiments on synthetic and real world\ndatasets on Warafin drug dosage and web server selection for latency\nminimization validate our theoretical insights and demonstrate that META is a\nrobust strategy for optimally exploiting the pre-clustering information.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:27:58 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Bouneffouf", "Djallel", ""], ["Parthasarathy", "Srinivasan", ""], ["Samulowitz", "Horst", ""], ["Wistub", "Martin", ""]]}, {"id": "1906.03986", "submitter": "Rachana Sathish", "authors": "Rachana Sathish and Debdoot Sheet", "title": "Unit Impulse Response as an Explainer of Redundancy in a Deep\n  Convolutional Neural Network", "comments": "Workshop on Expalainable AI, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) are generally designed with a heuristic\ninitialization of network architecture and trained for a certain task. This\noften leads to overparametrization after learning and induces redundancy in the\ninformation flow paths within the network. This robustness and reliability is\nat the increased cost of redundant computations. Several methods have been\nproposed which leverage metrics that quantify the redundancy in each layer.\nHowever, layer-wise evaluation in these methods disregards the long-range\nredundancy which exists across depth on account of the distributed nature of\nthe features learned by the model. In this paper, we propose (i) a mechanism to\nempirically demonstrate the robustness in performance of a CNN on account of\nredundancy across its depth, (ii) a method to identify the systemic redundancy\nin response of a CNN across depth using the understanding of unit impulse\nresponse, we subsequently demonstrate use of these methods to interpret\nredundancy in few networks as example. These techniques provide better insights\ninto the internal dynamics of a CNN\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:02:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sathish", "Rachana", ""], ["Sheet", "Debdoot", ""]]}, {"id": "1906.03989", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang, Reza Ashrafi, Anne Juuti, Kirsi Pietil\\\"ainen, Pekka\n  Marttinen", "title": "Errors-in-variables Modeling of Personalized Treatment-Response\n  Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the effect of a treatment on a given outcome, conditioned on a\nvector of covariates, is central in many applications. However, learning the\nimpact of a treatment on a continuous temporal response, when the covariates\nsuffer extensively from measurement error and even the timing of the treatments\nis uncertain, has not been addressed. We introduce a novel data-driven method\nthat can estimate treatment-response trajectories in this challenging scenario.\nWe model personalized treatment-response curves as a combination of parametric\nresponse functions, hierarchically sharing information across individuals, and\na sparse Gaussian process for the baseline trend. Importantly, our model\nconsiders measurement error not only in treatment covariates, but also in\ntreatment times, a problem which arises in practice for example when treatment\ninformation is based on self-reporting. In a challenging and timely problem of\nestimating the impact of diet on continuous blood glucose measurements, our\nmodel leads to significant improvements in estimation accuracy and prediction.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:03:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Guangyi", ""], ["Ashrafi", "Reza", ""], ["Juuti", "Anne", ""], ["Pietil\u00e4inen", "Kirsi", ""], ["Marttinen", "Pekka", ""]]}, {"id": "1906.03999", "submitter": "Hema Venkata Krishna Giri Narra", "authors": "Krishna Narra, Zhifeng Lin, Ganesh Ananthanarayanan, Salman\n  Avestimehr, Murali Annavaram", "title": "Collage Inference: Achieving low tail latency during distributed image\n  classification using coded redundancy models", "comments": "4 pages, CodML workshop at International Conference on Machine\n  Learning (ICML 2019). arXiv admin note: text overlap with arXiv:1904.12222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the latency variance in machine learning inference is a key\nrequirement in many applications. Variance is harder to control in a cloud\ndeployment in the presence of stragglers. In spite of this challenge, inference\nis increasingly being done in the cloud, due to the advent of affordable\nmachine learning as a service (MLaaS) platforms. Existing approaches to reduce\nvariance rely on replication which is expensive and partially negates the\naffordability of MLaaS. In this work, we argue that MLaaS platforms also\nprovide unique opportunities to cut the cost of redundancy. In MLaaS platforms,\nmultiple inference requests are concurrently received by a load balancer which\ncan then create a more cost-efficient redundancy coding across a larger\ncollection of images. We propose a novel convolutional neural network model,\nCollage-CNN, to provide a low-cost redundancy framework. A Collage-CNN model\ntakes a collage formed by combining multiple images and performs multi-image\nclassification in one shot, albeit at slightly lower accuracy. We then augment\na collection of traditional single image classifiers with a single Collage-CNN\nclassifier which acts as a low-cost redundant backup. Collage-CNN then provides\nbackup classification results if a single image classification straggles.\nDeploying the Collage-CNN models in the cloud, we demonstrate that the 99th\npercentile tail latency of inference can be reduced by 1.47X compared to\nreplication based approaches while providing high accuracy. Also, variation in\ninference latency can be reduced by 9X with a slight increase in average\ninference latency.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:18:58 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Narra", "Krishna", ""], ["Lin", "Zhifeng", ""], ["Ananthanarayanan", "Ganesh", ""], ["Avestimehr", "Salman", ""], ["Annavaram", "Murali", ""]]}, {"id": "1906.04009", "submitter": "Che Wang", "authors": "Che Wang, Keith Ross", "title": "Boosting Soft Actor-Critic: Emphasizing Recent Experience without\n  Forgetting the Past", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft Actor-Critic (SAC) is an off-policy actor-critic deep reinforcement\nlearning (DRL) algorithm based on maximum entropy reinforcement learning. By\ncombining off-policy updates with an actor-critic formulation, SAC achieves\nstate-of-the-art performance on a range of continuous-action benchmark tasks,\noutperforming prior on-policy and off-policy methods. The off-policy method\nemployed by SAC samples data uniformly from past experience when performing\nparameter updates. We propose Emphasizing Recent Experience (ERE), a simple but\npowerful off-policy sampling technique, which emphasizes recently observed data\nwhile not forgetting the past. The ERE algorithm samples more aggressively from\nrecent experience, and also orders the updates to ensure that updates from old\ndata do not overwrite updates from new data. We compare vanilla SAC and\nSAC+ERE, and show that ERE is more sample efficient than vanilla SAC for\ncontinuous-action Mujoco tasks. We also consider combining SAC with Priority\nExperience Replay (PER), a scheme originally proposed for deep Q-learning which\nprioritizes the data based on temporal-difference (TD) error. We show that\nSAC+PER can marginally improve the sample efficiency performance of SAC, but\nmuch less so than SAC+ERE. Finally, we propose an algorithm which integrates\nERE and PER and show that this hybrid algorithm can give the best results for\nsome of the Mujoco tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:27:13 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Che", ""], ["Ross", "Keith", ""]]}, {"id": "1906.04015", "submitter": "Truong Son Hy", "authors": "Brandon Anderson and Truong-Son Hy and Risi Kondor", "title": "Cormorant: Covariant Molecular Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Cormorant, a rotationally covariant neural network architecture\nfor learning the behavior and properties of complex many-body physical systems.\nWe apply these networks to molecular systems with two goals: learning atomic\npotential energy surfaces for use in Molecular Dynamics simulations, and\nlearning ground state properties of molecules calculated by Density Functional\nTheory. Some of the key features of our network are that (a) each neuron\nexplicitly corresponds to a subset of atoms; (b) the activation of each neuron\nis covariant to rotations, ensuring that overall the network is fully\nrotationally invariant. Furthermore, the non-linearity in our network is based\nupon tensor products and the Clebsch-Gordan decomposition, allowing the network\nto operate entirely in Fourier space. Cormorant significantly outperforms\ncompeting algorithms in learning molecular Potential Energy Surfaces from\nconformational geometries in the MD-17 dataset, and is competitive with other\nmethods at learning geometric, energetic, electronic, and thermodynamic\nproperties of molecules on the GDB-9 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:53:32 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 18:49:07 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 19:35:06 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Anderson", "Brandon", ""], ["Hy", "Truong-Son", ""], ["Kondor", "Risi", ""]]}, {"id": "1906.04017", "submitter": "Mauricio Tano", "authors": "Mauricio Tano, Jean Ragusa", "title": "Acceleration of Radiation Transport Solves Using Artificial Neural\n  Networks", "comments": "29 pages, 9 Figures, in submission process to Journal of\n  Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discontinuous Finite Element Methods (DFEM) have been widely used for solving\n$S_n$ radiation transport problems in participative and non-participative\nmedia. In the DFEM $S_n$ methodology, the transport equation is discretized\ninto a set of algebraic equations that have to be solved for each spatial cell\nand angular direction, strictly preserving the following of radiation in the\nsystem. At the core of a DFEM solver a small matrix-vector system (of 8\nindependent equations for tri-linear DFEM in 3D hexehdral cells) has to be\nassembled and solved for each cell, angle, energy group, and time step. These\nsystems are generally solved by direct Gaussian Elimination. The computational\ncost of the Gaussian Elimination, repeated for each phase-space cell, amounts\nto a large fraction to the total compute time. Here, we have designed a Machine\nLearning algorithm based in a shallow Artificial Neural Networks (ANNs) to\nreplace that Gaussian Elimination step, enabling a sizeable speed up in the\nsolution process. The key idea is to train an ANN with a large set of solutions\nof random one-cell transport problems and then to use the trained ANN to\nreplace Gaussian Elimination large scale transport solvers. It has been\nobserved that ANNs decrease the solution times by at least a factor of 4, while\nintroducing mean absolute errors between 1-3 \\% in large scale transport\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 23:00:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tano", "Mauricio", ""], ["Ragusa", "Jean", ""]]}, {"id": "1906.04026", "submitter": "Xiangrui Li", "authors": "Xiangrui Li and Dongxiao Zhu", "title": "CRCEN: A Generalized Cost-sensitive Neural Network Approach for\n  Imbalanced Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification on imbalanced datasets is a challenging task in real-world\napplications. Training conventional classification algorithms directly by\nminimizing classification error in this scenario can compromise model\nperformance for minority class while optimizing performance for majority class.\nTraditional approaches to the imbalance problem include re-sampling and\ncost-sensitive methods. In this paper, we propose a neural network model with\nnovel loss function, CRCEN, for imbalanced classification. Based on the\nweighted version of cross entropy loss, we provide a theoretical relation for\nmodel predicted probability, imbalance ratio and the weighting mechanism. To\ndemonstrate the effectiveness of our proposed model, CRCEN is tested on several\nbenchmark datasets and compared with baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:37:57 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 14:56:22 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 23:02:04 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Li", "Xiangrui", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1906.04032", "submitter": "Artur Bekasov", "authors": "Conor Durkan, Artur Bekasov, Iain Murray, George Papamakarios", "title": "Neural Spline Flows", "comments": "Published at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A normalizing flow models a complex probability density as an invertible\ntransformation of a simple base density. Flows based on either coupling or\nautoregressive transforms both offer exact density evaluation and sampling, but\nrely on the parameterization of an easily invertible elementwise\ntransformation, whose choice determines the flexibility of these models.\nBuilding upon recent work, we propose a fully-differentiable module based on\nmonotonic rational-quadratic splines, which enhances the flexibility of both\ncoupling and autoregressive transforms while retaining analytic invertibility.\nWe demonstrate that neural spline flows improve density estimation, variational\ninference, and generative modeling of images.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:43:23 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 11:16:22 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Durkan", "Conor", ""], ["Bekasov", "Artur", ""], ["Murray", "Iain", ""], ["Papamakarios", "George", ""]]}, {"id": "1906.04045", "submitter": "Christian Baumgartner", "authors": "Christian F. Baumgartner, Kerem C. Tezcan, Krishna Chaitanya, Andreas\n  M. H\\\"otker, Urs J. Muehlematter, Khoschy Schawkat, Anton S. Becker, Olivio\n  Donati, Ender Konukoglu", "title": "PHiSeg: Capturing Uncertainty in Medical Image Segmentation", "comments": "Accepted to MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of anatomical structures and pathologies is inherently\nambiguous. For instance, structure borders may not be clearly visible or\ndifferent experts may have different styles of annotating. The majority of\ncurrent state-of-the-art methods do not account for such ambiguities but rather\nlearn a single mapping from image to segmentation. In this work, we propose a\nnovel method to model the conditional probability distribution of the\nsegmentations given an input image. We derive a hierarchical probabilistic\nmodel, in which separate latent variables are responsible for modelling the\nsegmentation at different resolutions. Inference in this model can be\nefficiently performed using the variational autoencoder framework. We show that\nour proposed method can be used to generate significantly more realistic and\ndiverse segmentation samples compared to recent related work, both, when\ntrained with annotations from a single or multiple annotators.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:17:18 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:36:03 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Baumgartner", "Christian F.", ""], ["Tezcan", "Kerem C.", ""], ["Chaitanya", "Krishna", ""], ["H\u00f6tker", "Andreas M.", ""], ["Muehlematter", "Urs J.", ""], ["Schawkat", "Khoschy", ""], ["Becker", "Anton S.", ""], ["Donati", "Olivio", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1906.04053", "submitter": "Dong-Dong Chen", "authors": "Dong-Dong Chen, Yisen Wang, Jinfeng Yi, Zaiyi Chen, Zhi-Hua Zhou", "title": "Joint Semantic Domain Alignment and Target Classifier Learning for\n  Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aims to transfer the classifier learned from\nthe source domain to the target domain in an unsupervised manner. With the help\nof target pseudo-labels, aligning class-level distributions and learning the\nclassifier in the target domain are two widely used objectives. Existing\nmethods often separately optimize these two individual objectives, which makes\nthem suffer from the neglect of the other. However, optimizing these two\naspects together is not trivial. To alleviate the above issues, we propose a\nnovel method that jointly optimizes semantic domain alignment and target\nclassifier learning in a holistic way. The joint optimization mechanism can not\nonly eliminate their weaknesses but also complement their strengths. The\ntheoretical analysis also verifies the favor of the joint optimization\nmechanism. Extensive experiments on benchmark datasets show that the proposed\nmethod yields the best performance in comparison with the state-of-the-art\nunsupervised domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:57:52 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chen", "Dong-Dong", ""], ["Wang", "Yisen", ""], ["Yi", "Jinfeng", ""], ["Chen", "Zaiyi", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1906.04063", "submitter": "Waldyn Martinez", "authors": "Waldyn Martinez, J. Brian Gray", "title": "On the Insufficiency of the Large Margins Theory in Explaining the\n  Performance of Ensemble Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting and other ensemble methods combine a large number of weak\nclassifiers through weighted voting to produce stronger predictive models. To\nexplain the successful performance of boosting algorithms, Schapire et al.\n(1998) showed that AdaBoost is especially effective at increasing the margins\nof the training data. Schapire et al. (1998) also developed an upper bound on\nthe generalization error of any ensemble based on the margins of the training\ndata, from which it was concluded that larger margins should lead to lower\ngeneralization error, everything else being equal (sometimes referred to as the\n``large margins theory''). Tighter bounds have been derived and have reinforced\nthe large margins theory hypothesis. For instance, Wang et al. (2011) suggest\nthat specific margin instances, such as the equilibrium margin, can better\nsummarize the margins distribution. These results have led many researchers to\nconsider direct optimization of the margins to improve ensemble generalization\nerror with mixed results. We show that the large margins theory is not\nsufficient for explaining the performance of voting classifiers. We do this by\nillustrating how it is possible to improve upon the margin distribution of an\nensemble solution, while keeping the complexity fixed, yet not improve the test\nset performance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:09:24 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Martinez", "Waldyn", ""], ["Gray", "J. Brian", ""]]}, {"id": "1906.04066", "submitter": "Jingyan Wang", "authors": "Jingyan Wang and Nihar B. Shah and R. Ravi", "title": "Stretching the Effectiveness of MLE from Accuracy to Bias for Pairwise\n  Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of applications (e.g., AI bot tournaments, sports, peer grading,\ncrowdsourcing) use pairwise comparison data and the Bradley-Terry-Luce (BTL)\nmodel to evaluate a given collection of items (e.g., bots, teams, students,\nsearch results). Past work has shown that under the BTL model, the widely-used\nmaximum-likelihood estimator (MLE) is minimax-optimal in estimating the item\nparameters, in terms of the mean squared error. However, another important\ndesideratum for designing estimators is fairness. In this work, we consider\nfairness modeled by the notion of bias in statistics. We show that the MLE\nincurs a suboptimal rate in terms of bias. We then propose a simple\nmodification to the MLE, which \"stretches\" the bounding box of the\nmaximum-likelihood optimizer by a small constant factor from the underlying\nground truth domain. We show that this simple modification leads to an improved\nrate in bias, while maintaining minimax-optimality in the mean squared error.\nIn this manner, our proposed class of estimators provably improves fairness\nrepresented by bias without loss in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:19:04 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Wang", "Jingyan", ""], ["Shah", "Nihar B.", ""], ["Ravi", "R.", ""]]}, {"id": "1906.04072", "submitter": "Wesley Tansey", "authors": "Wesley Tansey, Christopher Tosh, David M. Blei", "title": "A Bayesian Model of Dose-Response for Cancer Drug Studies", "comments": "Extended to handle covariates; additional benchmarks comparing to\n  related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploratory cancer drug studies test multiple tumor cell lines against\nmultiple candidate drugs. The goal in each paired (cell line, drug) experiment\nis to map out the dose-response curve of the cell line as the dose level of the\ndrug increases. We propose Bayesian Tensor Filtering (BTF), a hierarchical\nBayesian model for dose-response modeling in multi-sample, multi-treatment\ncancer drug studies. BTF uses low-dimensional embeddings to share statistical\nstrength between similar drugs and similar cell lines. Structured shrinkage\npriors in BTF encourage smoothness in the dose-response curves while remaining\nadaptive to sharp jumps when the data call for it. We focus on a pair of cancer\ndrug studies exhibiting a particular pathology in their experimental design,\nleading us to a non-conjugate monotone mixture-of-Gammas likelihood. To perform\nposterior inference, we develop a variant of the elliptical slice sampling\nalgorithm for sampling from linearly-constrained multivariate normal priors\nwith non-conjugate likelihoods. In benchmarks, BTF outperforms state-of-the-art\nmethods for covariance regression and dynamic Poisson matrix factorization. On\nthe two cancer drug studies, BTF outperforms the current standard approach in\nbiology and reveals potential new biomarkers of drug sensitivity in cancer.\nCode is available at https://github.com/tansey/functionalmf.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:26:39 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 15:34:45 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 16:34:11 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Tansey", "Wesley", ""], ["Tosh", "Christopher", ""], ["Blei", "David M.", ""]]}, {"id": "1906.04109", "submitter": "Quanshi Zhang", "authors": "Haotian Ma, Yinqing Zhang, Fan Zhou, Quanshi Zhang", "title": "Quantifying Layerwise Information Discarding of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method to explain how input information is discarded\nthrough intermediate layers of a neural network during the forward propagation,\nin order to quantify and diagnose knowledge representations of pre-trained deep\nneural networks. We define two types of entropy-based metrics, i.e., the strict\ninformation discarding and the reconstruction uncertainty, which measure input\ninformation of a specific layer from two perspectives. We develop a method to\nenable efficient computation of such entropy-based metrics. Our method can be\nbroadly applied to various neural networks and enable comprehensive comparisons\nbetween different layers of different networks. Preliminary experiments have\nshown the effectiveness of our metrics in analyzing benchmark networks and\nexplaining existing deep-learning techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:33:03 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ma", "Haotian", ""], ["Zhang", "Yinqing", ""], ["Zhou", "Fan", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1906.04113", "submitter": "Elliot J. Crowley", "authors": "Jack Turner, Elliot J. Crowley, Michael O'Boyle, Amos Storkey, Gavin\n  Gray", "title": "BlockSwap: Fisher-guided Block Substitution for Network Compression on a\n  Budget", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The desire to map neural networks to varying-capacity devices has led to the\ndevelopment of a wealth of compression techniques, many of which involve\nreplacing standard convolutional blocks in a large network with cheap\nalternative blocks. However, not all blocks are created equally; for a required\ncompute budget there may exist a potent combination of many different cheap\nblocks, though exhaustively searching for such a combination is prohibitively\nexpensive. In this work, we develop BlockSwap: a fast algorithm for choosing\nnetworks with interleaved block types by passing a single minibatch of training\ndata through randomly initialised networks and gauging their Fisher potential.\nThese networks can then be used as students and distilled with the original\nlarge network as a teacher. We demonstrate the effectiveness of the chosen\nnetworks across CIFAR-10 and ImageNet for classification, and COCO for\ndetection, and provide a comprehensive ablation study of our approach.\nBlockSwap quickly explores possible block configurations using a simple\narchitecture ranking system, yielding highly competitive networks in orders of\nmagnitude less time than most architecture search techniques (e.g. under 5\nminutes on a single GPU for CIFAR-10). Code is available at\nhttps://github.com/BayesWatch/pytorch-blockswap.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:39:53 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 16:05:59 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Turner", "Jack", ""], ["Crowley", "Elliot J.", ""], ["O'Boyle", "Michael", ""], ["Storkey", "Amos", ""], ["Gray", "Gavin", ""]]}, {"id": "1906.04115", "submitter": "Siddharth Roheda", "authors": "Siddharth Roheda, Hamid Krim, Benjamin S. Riggan", "title": "Robust Multi-Modal Sensor Fusion: An Adversarial Approach", "comments": null, "journal-ref": null, "doi": "10.1109/JSEN.2020.3018698", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, multi-modal fusion has attracted a lot of research interest,\nboth in academia, and in industry. Multimodal fusion entails the combination of\ninformation from a set of different types of sensors. Exploiting complementary\ninformation from different sensors, we show that target detection and\nclassification problems can greatly benefit from this fusion approach and\nresult in a performance increase. To achieve this gain, the information fusion\nfrom various sensors is shown to require some principled strategy to ensure\nthat additional information is constructively used, and has a positive impact\non performance. We subsequently demonstrate the viability of the proposed\nfusion approach by weakening the strong dependence on the functionality of all\nsensors, hence introducing additional flexibility in our solution and lifting\nthe severe limitation in unconstrained surveillance settings with potential\nenvironmental impact. Our proposed data driven approach to multimodal fusion,\nexploits selected optimal features from an estimated latent space of data\nacross all modalities. This hidden space is learned via a generative network\nconditioned on individual sensor modalities. The hidden space, as an intrinsic\nstructure, is then exploited in detecting damaged sensors, and in subsequently\nsafeguarding the performance of the fused sensor system. Experimental results\nshow that such an approach can achieve automatic system robustness against\nnoisy/damaged sensors.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:43:18 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 17:08:17 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 03:46:16 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Roheda", "Siddharth", ""], ["Krim", "Hamid", ""], ["Riggan", "Benjamin S.", ""]]}, {"id": "1906.04119", "submitter": "Dirk Tasche", "authors": "Dirk Tasche", "title": "Confidence intervals for class prevalences under prior probability shift", "comments": "28 pages, 1 figure, 5 tables", "journal-ref": "Machine Learning and Knowledge Extraction 1, 805-831, 2019", "doi": "10.3390/make1030047", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point estimation of class prevalences in the presence of data set shift has\nbeen a popular research topic for more than two decades. Less attention has\nbeen paid to the construction of confidence and prediction intervals for\nestimates of class prevalences. One little considered question is whether or\nnot it is necessary for practical purposes to distinguish confidence and\nprediction intervals. Another question so far not yet conclusively answered is\nwhether or not the discriminatory power of the classifier or score at the basis\nof an estimation method matters for the accuracy of the estimates of the class\nprevalences. This paper presents a simulation study aimed at shedding some\nlight on these and other related questions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:50:08 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 15:03:11 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Tasche", "Dirk", ""]]}, {"id": "1906.04133", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski and Feynman Liang and Michael W. Mahoney", "title": "Bayesian experimental design using regularized determinantal point\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In experimental design, we are given $n$ vectors in $d$ dimensions, and our\ngoal is to select $k\\ll n$ of them to perform expensive measurements, e.g., to\nobtain labels/responses, for a linear regression task. Many statistical\ncriteria have been proposed for choosing the optimal design, with popular\nchoices including A- and D-optimality. If prior knowledge is given, typically\nin the form of a $d\\times d$ precision matrix $\\mathbf A$, then all of the\ncriteria can be extended to incorporate that information via a Bayesian\nframework. In this paper, we demonstrate a new fundamental connection between\nBayesian experimental design and determinantal point processes, the latter\nbeing widely used for sampling diverse subsets of data. We use this connection\nto develop new efficient algorithms for finding $(1+\\epsilon)$-approximations\nof optimal designs under four optimality criteria: A, C, D and V. Our\nalgorithms can achieve this when the desired subset size $k$ is\n$\\Omega(\\frac{d_{\\mathbf A}}{\\epsilon} + \\frac{\\log 1/\\epsilon}{\\epsilon^2})$,\nwhere $d_{\\mathbf A}\\leq d$ is the $\\mathbf A$-effective dimension, which can\noften be much smaller than $d$. Our results offer direct improvements over a\nnumber of prior works, for both Bayesian and classical experimental design, in\nterms of algorithm efficiency, approximation quality, and range of applicable\ncriteria.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:10:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Liang", "Feynman", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1906.04159", "submitter": "Cong Ma", "authors": "Yuxin Chen, Jianqing Fan, Cong Ma, Yuling Yan", "title": "Inference and Uncertainty Quantification for Noisy Matrix Completion", "comments": "published at Proceedings of the National Academy of Sciences Nov\n  2019, 116 (46) 22931-22937", "journal-ref": null, "doi": "10.1073/pnas.1910053116", "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy matrix completion aims at estimating a low-rank matrix given only\npartial and corrupted entries. Despite substantial progress in designing\nefficient estimation algorithms, it remains largely unclear how to assess the\nuncertainty of the obtained estimates and how to perform statistical inference\non the unknown matrix (e.g.~constructing a valid and short confidence interval\nfor an unseen entry).\n  This paper takes a step towards inference and uncertainty quantification for\nnoisy matrix completion. We develop a simple procedure to compensate for the\nbias of the widely used convex and nonconvex estimators. The resulting\nde-biased estimators admit nearly precise non-asymptotic distributional\ncharacterizations, which in turn enable optimal construction of confidence\nintervals\\,/\\,regions for, say, the missing entries and the low-rank factors.\nOur inferential procedures do not rely on sample splitting, thus avoiding\nunnecessary loss of data efficiency. As a byproduct, we obtain a sharp\ncharacterization of the estimation accuracy of our de-biased estimators, which,\nto the best of our knowledge, are the first tractable algorithms that provably\nachieve full statistical efficiency (including the preconstant). The analysis\nherein is built upon the intimate link between convex and nonconvex\noptimization --- an appealing feature recently discovered by\n\\cite{chen2019noisy}.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:57:03 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 14:37:59 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""], ["Yan", "Yuling", ""]]}, {"id": "1906.04161", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Dhiraj Gandhi, Abhinav Gupta", "title": "Self-Supervised Exploration via Disagreement", "comments": "Accepted at ICML 2019. Website at\n  https://pathak22.github.io/exploration-by-disagreement/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is a long-standing problem in sensorimotor learning.\nMajor advances have been demonstrated in noise-free, non-stochastic domains\nsuch as video games and simulation. However, most of these formulations either\nget stuck in environments with stochastic dynamics or are too inefficient to be\nscalable to real robotics setups. In this paper, we propose a formulation for\nexploration inspired by the work in active learning literature. Specifically,\nwe train an ensemble of dynamics models and incentivize the agent to explore\nsuch that the disagreement of those ensembles is maximized. This allows the\nagent to learn skills by exploring in a self-supervised manner without any\nexternal reward. Notably, we further leverage the disagreement objective to\noptimize the agent's policy in a differentiable manner, without using\nreinforcement learning, which results in a sample-efficient exploration. We\ndemonstrate the efficacy of this formulation across a variety of benchmark\nenvironments including stochastic-Atari, Mujoco and Unity. Finally, we\nimplement our differentiable exploration on a real robot which learns to\ninteract with objects completely from scratch. Project videos and code are at\nhttps://pathak22.github.io/exploration-by-disagreement/\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:58:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Pathak", "Deepak", ""], ["Gandhi", "Dhiraj", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1906.04164", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Wei Fang, Brian Xu, Mitra Mohtarami, James Glass", "title": "FAKTA: An Automatic End-to-End Fact Checking System", "comments": "Accepted to NAACL '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FAKTA which is a unified framework that integrates various\ncomponents of a fact checking process: document retrieval from media sources\nwith various types of reliability, stance detection of documents with respect\nto given claims, evidence extraction, and linguistic analysis. FAKTA predicts\nthe factuality of given claims and provides evidence at the document and\nsentence level to explain its predictions\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:49:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Nadeem", "Moin", ""], ["Fang", "Wei", ""], ["Xu", "Brian", ""], ["Mohtarami", "Mitra", ""], ["Glass", "James", ""]]}, {"id": "1906.04165", "submitter": "Derek Miller", "authors": "Derek Miller", "title": "Leveraging BERT for Extractive Text Summarization on Lectures", "comments": "7 Pages, First Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, automatic extractive text summarization on lectures\nhas demonstrated to be a useful tool for collecting key phrases and sentences\nthat best represent the content. However, many current approaches utilize dated\napproaches, producing sub-par outputs or requiring several hours of manual\ntuning to produce meaningful results. Recently, new machine learning\narchitectures have provided mechanisms for extractive summarization through the\nclustering of output embeddings from deep learning models. This paper reports\non the project called Lecture Summarization Service, a python based RESTful\nservice that utilizes the BERT model for text embeddings and KMeans clustering\nto identify sentences closes to the centroid for summary selection. The purpose\nof the service was to provide students a utility that could summarize lecture\ncontent, based on their desired number of sentences. On top of the summary\nwork, the service also includes lecture and summary management, storing content\non the cloud which can be used for collaboration. While the results of\nutilizing BERT for extractive summarization were promising, there were still\nareas where the model struggled, providing feature research opportunities for\nfurther improvement.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:50:30 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Miller", "Derek", ""]]}, {"id": "1906.04175", "submitter": "Mariusz Kubkowski", "authors": "Mariusz Kubkowski, Jan Mielniczuk", "title": "Selection consistency of Lasso-based procedures for misspecified\n  high-dimensional binary model and random regressors", "comments": null, "journal-ref": null, "doi": "10.3390/e22020153", "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider selection of random predictors for high-dimensional regression\nproblem with binary response for a general loss function. Important special\ncase is when the binary model is semiparametric and the response function is\nmisspecified under parametric model fit. Selection for such a scenario aims at\nrecovering the support of the minimizer of the associated risk with large\nprobability. We propose a two-step selection procedure which consists of\nscreening and ordering predictors by Lasso method and then selecting a subset\nof predictors which minimizes Generalized Information Criterion on the\ncorresponding nested family of models. We prove consistency of the selection\nmethod under conditions which allow for much larger number of predictors than\nnumber of observations. For the semiparametric case when distribution of random\npredictors satisfies linear regression conditions the true and the estimated\nparameters are collinear and their common support can be consistently\nidentified.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:25:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kubkowski", "Mariusz", ""], ["Mielniczuk", "Jan", ""]]}, {"id": "1906.04214", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi\n  Hong, Xue Lin", "title": "Topology Attack and Defense for Graph Neural Networks: An Optimization\n  Perspective", "comments": "Accepted by IJCAI 2019, the 28th International Joint Conference on\n  Artificial Intelligence", "journal-ref": "International Joint Conference on Artificial Intelligence\n  (IJCAI-2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) which apply the deep neural networks to graph\ndata have achieved significant performance for the task of semi-supervised node\nclassification. However, only few work has addressed the adversarial robustness\nof GNNs. In this paper, we first present a novel gradient-based attack method\nthat facilitates the difficulty of tackling discrete graph data. When comparing\nto current adversarial attacks on GNNs, the results show that by only\nperturbing a small number of edge perturbations, including addition and\ndeletion, our optimization-based attack can lead to a noticeable decrease in\nclassification performance. Moreover, leveraging our gradient-based attack, we\npropose the first optimization-based adversarial training for GNNs. Our method\nyields higher robustness against both different gradient based and greedy\nattack methods without sacrificing classification accuracy on original graph.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:20:09 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 22:24:33 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 22:09:35 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Xu", "Kaidi", ""], ["Chen", "Hongge", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Weng", "Tsui-Wei", ""], ["Hong", "Mingyi", ""], ["Lin", "Xue", ""]]}, {"id": "1906.04233", "submitter": "Zack Hodari", "authors": "Zack Hodari, Oliver Watts, Simon King", "title": "Using generative modelling to produce varied intonation for speech\n  synthesis", "comments": "Accepted for the 10th ISCA Speech Synthesis Workshop (SSW10)", "journal-ref": null, "doi": "10.21437/SSW.2019-43", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike human speakers, typical text-to-speech (TTS) systems are unable to\nproduce multiple distinct renditions of a given sentence. This has previously\nbeen addressed by adding explicit external control. In contrast, generative\nmodels are able to capture a distribution over multiple renditions and thus\nproduce varied renditions using sampling. Typical neural TTS models learn the\naverage of the data because they minimise mean squared error. In the context of\nprosody, taking the average produces flatter, more boring speech: an \"average\nprosody\". A generative model that can synthesise multiple prosodies will, by\ndesign, not model average prosody. We use variational autoencoders (VAEs) which\nexplicitly place the most \"average\" data close to the mean of the Gaussian\nprior. We propose that by moving towards the tails of the prior distribution,\nthe model will transition towards generating more idiosyncratic, varied\nrenditions. Focusing here on intonation, we investigate the trade-off between\nnaturalness and intonation variation and find that typical acoustic models can\neither be natural, or varied, but not both. However, sampling from the tails of\nthe VAE prior produces much more varied intonation than the traditional\napproaches, whilst maintaining the same level of naturalness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:05:03 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 10:14:38 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hodari", "Zack", ""], ["Watts", "Oliver", ""], ["King", "Simon", ""]]}, {"id": "1906.04239", "submitter": "Shih-Yuan Yu", "authors": "Shih Yuan Yu, Sujit Rokka Chhetri, Arquimedes Canedo, Palash Goyal,\n  Mohammad Abdullah Al Faruque", "title": "Pykg2vec: A Python Library for Knowledge Graph Embedding", "comments": "5 pages, 5 figures, few code snippets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pykg2vec is an open-source Python library for learning the representations of\nthe entities and relations in knowledge graphs. Pykg2vec's flexible and modular\nsoftware architecture currently implements 16 state-of-the-art knowledge graph\nembedding algorithms, and is designed to easily incorporate new algorithms. The\ngoal of pykg2vec is to provide a practical and educational platform to\naccelerate research in knowledge graph representation learning. Pykg2vec is\nbuilt on top of TensorFlow and Python's multiprocessing framework and provides\nmodules for batch generation, Bayesian hyperparameter optimization, mean rank\nevaluation, embedding, and result visualization. Pykg2vec is released under the\nMIT License and is also available in the Python Package Index (PyPI). The\nsource code of pykg2vec is available at https://github.com/Sujit-O/pykg2vec.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:22:32 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Yu", "Shih Yuan", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""], ["Goyal", "Palash", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "1906.04267", "submitter": "Aaron Defazio", "authors": "Aaron Defazio, L\\'eon Bottou", "title": "Beyond Folklore: A Scaling Calculus for the Design and Initialization of\n  ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a system for calculating a \"scaling constant\" for layers and\nweights of neural networks. We relate this scaling constant to two important\nquantities that relate to the optimizability of neural networks, and argue that\na network that is \"preconditioned\" via scaling, in the sense that all weights\nhave the same scaling constant, will be easier to train. This scaling calculus\nresults in a number of consequences, among them the fact that the geometric\nmean of the fan-in and fan-out, rather than the fan-in, fan-out, or arithmetic\nmean, should be used for the initialization of the variance of weights in a\nneural network. Our system allows for the off-line design & engineering of ReLU\nneural networks, potentially replacing blind experimentation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 20:38:18 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:18:15 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 19:06:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Defazio", "Aaron", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1906.04278", "submitter": "Jiawen Liu", "authors": "Jie Liu, Jiawen Liu, Wan Du, Dong Li", "title": "Performance Analysis and Characterization of Training Deep Learning\n  Models on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep learning models on mobile devices recently becomes possible,\nbecause of increasing computation power on mobile hardware and the advantages\nof enabling high user experiences. Most of the existing work on machine\nlearning at mobile devices is focused on the inference of deep learning models\n(particularly convolutional neural network and recurrent neural network), but\nnot training. The performance characterization of training deep learning models\non mobile devices is largely unexplored, although understanding the performance\ncharacterization is critical for designing and implementing deep learning\nmodels on mobile devices.\n  In this paper, we perform a variety of experiments on a representative mobile\ndevice (the NVIDIA TX2) to study the performance of training deep learning\nmodels. We introduce a benchmark suite and tools to study performance of\ntraining deep learning models on mobile devices, from the perspectives of\nmemory consumption, hardware utilization, and power consumption. The tools can\ncorrelate performance results with fine-grained operations in deep learning\nmodels, providing capabilities to capture performance variance and problems at\na fine granularity. We reveal interesting performance problems and\nopportunities, including under-utilization of heterogeneous hardware, large\nenergy consumption of the memory, and high predictability of workload\ncharacterization. Based on the performance analysis, we suggest interesting\nresearch directions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:16:57 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 16:27:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Liu", "Jie", ""], ["Liu", "Jiawen", ""], ["Du", "Wan", ""], ["Li", "Dong", ""]]}, {"id": "1906.04279", "submitter": "Zhizhou Ren", "authors": "Zhizhou Ren, Kefan Dong, Yuan Zhou, Qiang Liu, Jian Peng", "title": "Exploration via Hindsight Goal Generation", "comments": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented reinforcement learning has recently been a practical framework\nfor robotic manipulation tasks, in which an agent is required to reach a\ncertain goal defined by a function on the state space. However, the sparsity of\nsuch reward definition makes traditional reinforcement learning algorithms very\ninefficient. Hindsight Experience Replay (HER), a recent advance, has greatly\nimproved sample efficiency and practical applicability for such problems. It\nexploits previous replays by constructing imaginary goals in a simple heuristic\nway, acting like an implicit curriculum to alleviate the challenge of sparse\nreward signal. In this paper, we introduce Hindsight Goal Generation (HGG), a\nnovel algorithmic framework that generates valuable hindsight goals which are\neasy for an agent to achieve in the short term and are also potential for\nguiding the agent to reach the actual goal in the long term. We have\nextensively evaluated our goal generation algorithm on a number of robotic\nmanipulation tasks and demonstrated substantially improvement over the original\nHER in terms of sample efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:21:18 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 05:35:33 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 04:31:39 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Ren", "Zhizhou", ""], ["Dong", "Kefan", ""], ["Zhou", "Yuan", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1906.04280", "submitter": "Gabor Lugosi", "authors": "Gabor Lugosi and Shahar Mendelson", "title": "Mean estimation and regression under heavy-tailed distributions--a\n  survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey some of the recent advances in mean estimation and regression\nfunction estimation. In particular, we describe sub-Gaussian mean estimators\nfor possibly heavy-tailed data both in the univariate and multivariate\nsettings. We focus on estimators based on median-of-means techniques but other\nmethods such as the trimmed mean and Catoni's estimator are also reviewed. We\ngive detailed proofs for the cornerstone results. We dedicate a section on\nstatistical learning problems--in particular, regression function\nestimation--in the presence of possibly heavy-tailed data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:25:55 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lugosi", "Gabor", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1906.04281", "submitter": "Chunyuan Li", "authors": "Sam Lobel, Chunyuan Li, Jianfeng Gao, Lawrence Carin", "title": "Towards Amortized Ranking-Critical Training for Collaborative Filtering", "comments": "The first two authors contributed equally to this manuscript. Code:\n  https://github.com/samlobel/RaCT_CF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering is widely used in modern recommender systems. Recent\nresearch shows that variational autoencoders (VAEs) yield state-of-the-art\nperformance by integrating flexible representations from deep neural networks\ninto latent variable models, mitigating limitations of traditional linear\nfactor models. VAEs are typically trained by maximizing the likelihood (MLE) of\nusers interacting with ground-truth items. While simple and often effective,\nMLE-based training does not directly maximize the recommendation-quality\nmetrics one typically cares about, such as top-N ranking. In this paper we\ninvestigate new methods for training collaborative filtering models based on\nactor-critic reinforcement learning, to directly optimize the\nnon-differentiable quality metrics of interest. Specifically, we train a critic\nnetwork to approximate ranking-based metrics, and then update the actor network\n(represented here by a VAE) to directly optimize against the learned metrics.\nIn contrast to traditional learning-to-rank methods that require to re-run the\noptimization procedure for new lists, our critic-based method amortizes the\nscoring process with a neural network, and can directly provide the\n(approximate) ranking scores for new lists. Empirically, we show that the\nproposed methods outperform several state-of-the-art baselines, including\nrecently-proposed deep learning approaches, on three large-scale real-world\ndatasets. The code to reproduce the experimental results and figure plots is on\nGithub: https://github.com/samlobel/RaCT_CF\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:30:16 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:48:28 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lobel", "Sam", ""], ["Li", "Chunyuan", ""], ["Gao", "Jianfeng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.04282", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Ahmed Touati, Pascal Vincent, Gintare Karolina\n  Dziugaite, Alexandre Lacoste, Aaron Courville", "title": "Stochastic Neural Network with Kronecker Flow", "comments": "Proceedings of the 23rdInternational Conference on\n  ArtificialIntelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in variational inference enable the modelling of highly\nstructured joint distributions, but are limited in their capacity to scale to\nthe high-dimensional setting of stochastic neural networks. This limitation\nmotivates a need for scalable parameterizations of the noise generation\nprocess, in a manner that adequately captures the dependencies among the\nvarious parameters. In this work, we address this need and present the\nKronecker Flow, a generalization of the Kronecker product to invertible\nmappings designed for stochastic neural networks. We apply our method to\nvariational Bayesian neural networks on predictive tasks, PAC-Bayes\ngeneralization bound estimation, and approximate Thompson sampling in\ncontextual bandits. In all setups, our methods prove to be competitive with\nexisting methods and better than the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:33:25 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:41:38 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Touati", "Ahmed", ""], ["Vincent", "Pascal", ""], ["Dziugaite", "Gintare Karolina", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1906.04284", "submitter": "Jesse Vig", "authors": "Jesse Vig and Yonatan Belinkov", "title": "Analyzing the Structure of Attention in a Transformer Language Model", "comments": "To appear in ACL BlackboxNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer is a fully attention-based alternative to recurrent networks\nthat has achieved state-of-the-art results across a range of NLP tasks. In this\npaper, we analyze the structure of attention in a Transformer language model,\nthe GPT-2 small pretrained model. We visualize attention for individual\ninstances and analyze the interaction between attention and syntax over a large\ncorpus. We find that attention targets different parts of speech at different\nlayer depths within the model, and that attention aligns with dependency\nrelations most strongly in the middle layers. We also find that the deepest\nlayers of the model capture the most distant relationships. Finally, we extract\nexemplar sentences that reveal highly specific patterns targeted by particular\nattention heads.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:58:49 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 19:42:31 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Vig", "Jesse", ""], ["Belinkov", "Yonatan", ""]]}, {"id": "1906.04285", "submitter": "Nikola Kovachki", "authors": "Nikola B. Kovachki, Andrew M. Stuart", "title": "Continuous Time Analysis of Momentum Methods", "comments": "40 pages, 7 figures", "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-40", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent-based optimization methods underpin the parameter training\nof neural networks, and hence comprise a significant component in the\nimpressive test results found in a number of applications. Introducing\nstochasticity is key to their success in practical problems, and there is some\nunderstanding of the role of stochastic gradient descent in this context.\nMomentum modifications of gradient descent such as Polyak's Heavy Ball method\n(HB) and Nesterov's method of accelerated gradients (NAG), are also widely\nadopted. In this work our focus is on understanding the role of momentum in the\ntraining of neural networks, concentrating on the common situation in which the\nmomentum contribution is fixed at each step of the algorithm. To expose the\nideas simply we work in the deterministic setting.\n  Our approach is to derive continuous time approximations of the discrete\nalgorithms; these continuous time approximations provide insights into the\nmechanisms at play within the discrete algorithms. We prove three such\napproximations. Firstly we show that standard implementations of fixed momentum\nmethods approximate a time-rescaled gradient descent flow, asymptotically as\nthe learning rate shrinks to zero; this result does not distinguish momentum\nmethods from pure gradient descent, in the limit of vanishing learning rate. We\nthen proceed to prove two results aimed at understanding the observed practical\nadvantages of fixed momentum methods over gradient descent. We achieve this by\nproving approximations to continuous time limits in which the small but fixed\nlearning rate appears as a parameter. Furthermore in a third result we show\nthat the momentum methods admit an exponentially attractive invariant manifold\non which the dynamics reduces, approximately, to a gradient flow with respect\nto a modified loss function.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:36:42 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 19:32:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kovachki", "Nikola B.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1906.04286", "submitter": "Angel Beltre", "authors": "Angel Beltre, Shehtab Zaman, Kenneth Chiu, Sudhakar Pamidighantam,\n  Xingye Qiao, Madhusudhan Govindaraju", "title": "Towards Run Time Estimation of the Gaussian Chemistry Code for SEAGrid\n  Science Gateway", "comments": "8 pages, 4 Figures, conference", "journal-ref": "ACM, PEARC 2019", "doi": "10.1145/3332186.3338101", "report-no": "126", "categories": "physics.comp-ph cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of the run time of computational codes has a number of\nsignificant advantages for scientific computing. It is required information for\noptimal resource allocation, improving turnaround times and utilization of\nscience gateways. Furthermore, it allows users to better plan and schedule\ntheir research, streamlining workflows and improving the overall productivity\nof cyberinfrastructure. Predicting run time is challenging, however. The inputs\nto scientific codes can be complex and high dimensional. Their relationship to\nthe run time may be highly non-linear, and, in the most general case is\ncompletely arbitrary and thus unpredictable (i.e., simply a random mapping from\ninputs to run time). Most codes are not so arbitrary, however, and there has\nbeen significant prior research on predicting the run time of applications and\nworkloads. Such predictions are generally application-specific, however. In\nthis paper, we focus on the Gaussian computational chemistry code. We\ncharacterize a data set of runs from the SEAGrid science gateway with a number\nof different studies. We also explore a number of different potential\nregression methods and present promising future directions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 04:00:03 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Beltre", "Angel", ""], ["Zaman", "Shehtab", ""], ["Chiu", "Kenneth", ""], ["Pamidighantam", "Sudhakar", ""], ["Qiao", "Xingye", ""], ["Govindaraju", "Madhusudhan", ""]]}, {"id": "1906.04301", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Won-Sook Lee", "title": "Transfer Learning for Ultrasound Tongue Contour Extraction with\n  Different Domains", "comments": "3 figures, 9 pages, 1 table, 16 references", "journal-ref": "The Journal of the Acoustical Society of America 146, 2940 (2019)", "doi": "10.1121/1.5137211", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical ultrasound technology is widely used in routine clinical applications\nsuch as disease diagnosis and treatment as well as other applications like\nreal-time monitoring of human tongue shapes and motions as visual feedback in\nsecond language training. Due to the low-contrast characteristic and noisy\nnature of ultrasound images, it might require expertise for non-expert users to\nrecognize tongue gestures. Manual tongue segmentation is a cumbersome,\nsubjective, and error-prone task. Furthermore, it is not a feasible solution\nfor real-time applications. In the last few years, deep learning methods have\nbeen used for delineating and tracking tongue dorsum. Deep convolutional neural\nnetworks (DCNNs), which have shown to be successful in medical image analysis\ntasks, are typically weak for the same task on different domains. In many\ncases, DCNNs trained on data acquired with one ultrasound device, do not\nperform well on data of varying ultrasound device or acquisition protocol.\nDomain adaptation is an alternative solution for this difficulty by\ntransferring the weights from the model trained on a large annotated legacy\ndataset to a new model for adapting on another different dataset using\nfine-tuning. In this study, after conducting extensive experiments, we\naddressed the problem of domain adaptation on small ultrasound datasets for\ntongue contour extraction. We trained a U-net network comprises of an\nencoder-decoder path from scratch, and then with several surrogate scenarios,\nsome parts of the trained network were fine-tuned on another dataset as the\ndomain-adapted networks. We repeat scenarios from target to source domains to\nfind a balance point for knowledge transfer from source to target and vice\nversa. The performance of new fine-tuned networks was evaluated on the same\ntask with images from different domains.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 22:17:08 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Lee", "Won-Sook", ""]]}, {"id": "1906.04304", "submitter": "Jack Rae", "authors": "Jack W Rae, Sergey Bartunov, Timothy P Lillicrap", "title": "Meta-Learning Neural Bloom Filters", "comments": "International Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent trend in training neural networks to replace data\nstructures that have been crafted by hand, with an aim for faster execution,\nbetter accuracy, or greater compression. In this setting, a neural data\nstructure is instantiated by training a network over many epochs of its inputs\nuntil convergence. In applications where inputs arrive at high throughput, or\nare ephemeral, training a network from scratch is not practical. This motivates\nthe need for few-shot neural data structures. In this paper we explore the\nlearning of approximate set membership over a set of data in one-shot via\nmeta-learning. We propose a novel memory architecture, the Neural Bloom Filter,\nwhich is able to achieve significant compression gains over classical Bloom\nFilters and existing memory-augmented neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 22:23:14 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Rae", "Jack W", ""], ["Bartunov", "Sergey", ""], ["Lillicrap", "Timothy P", ""]]}, {"id": "1906.04309", "submitter": "Hamed Omidvar", "authors": "Hamed Omidvar, Vahideh Akhlaghi, Massimo Franceschetti, Rajesh K.\n  Gupta", "title": "Associative Convolutional Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the necessity for parameter efficiency in distributed machine\nlearning and AI-enabled edge devices, we provide a general and easy to\nimplement method for significantly reducing the number of parameters of\nConvolutional Neural Networks (CNNs), during both the training and inference\nphases. We introduce a simple auxiliary neural network which can generate the\nconvolutional filters of any CNN architecture from a low dimensional latent\nspace. This auxiliary neural network, which we call \"Convolutional Slice\nGenerator\" (CSG), is unique to the network and provides the association between\nits convolutional layers. During the training of the CNN, instead of training\nthe filters of the convolutional layers, only the parameters of the CSG and\ntheir corresponding \"code vectors\" are trained. This results in a significant\nreduction of the number of parameters due to the fact that the CNN can be fully\nrepresented using only the parameters of the CSG, the code vectors, the fully\nconnected layers, and the architecture of the CNN. We evaluate our approach by\napplying it to ResNet and DenseNet models when trained on CIFAR-10 and ImageNet\ndatasets. While reducing the number of parameters by $\\approx 2 \\times$ on\naverage, the accuracies of these networks remain within 1$\\%$ of their original\ncounterparts and in some cases there is an increase in the accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 22:36:43 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 00:16:05 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 23:21:00 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Omidvar", "Hamed", ""], ["Akhlaghi", "Vahideh", ""], ["Franceschetti", "Massimo", ""], ["Gupta", "Rajesh K.", ""]]}, {"id": "1906.04324", "submitter": "Chandrasekaran Anirudh Bhardwaj", "authors": "Chandrasekaran Anirudh Bhardwaj", "title": "Adaptively Preconditioned Stochastic Gradient Langevin Dynamics", "comments": "International Conference on Machine Learning (ICML) 2019 Workshop on\n  Understanding and Improving Generalization in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Langevin Dynamics infuses isotropic gradient noise to SGD\nto help navigate pathological curvature in the loss landscape for deep\nnetworks. Isotropic nature of the noise leads to poor scaling, and adaptive\nmethods based on higher order curvature information such as Fisher Scoring have\nbeen proposed to precondition the noise in order to achieve better convergence.\nIn this paper, we describe an adaptive method to estimate the parameters of the\nnoise and conduct experiments on well-known model architectures to show that\nthe adaptively preconditioned SGLD method achieves convergence with the speed\nof adaptive first order methods such as Adam, AdaGrad etc. and achieves\ngeneralization equivalent of SGD in the test set.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 23:38:54 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:50:58 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Bhardwaj", "Chandrasekaran Anirudh", ""]]}, {"id": "1906.04328", "submitter": "Matthew Schlegel", "authors": "Matthew Schlegel, Wesley Chung, Daniel Graves, Jian Qian, Martha White", "title": "Importance Resampling for Off-policy Prediction", "comments": "Recently published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling (IS) is a common reweighting strategy for off-policy\nprediction in reinforcement learning. While it is consistent and unbiased, it\ncan result in high variance updates to the weights for the value function. In\nthis work, we explore a resampling strategy as an alternative to reweighting.\nWe propose Importance Resampling (IR) for off-policy prediction, which\nresamples experience from a replay buffer and applies standard on-policy\nupdates. The approach avoids using importance sampling ratios in the update,\ninstead correcting the distribution before the update. We characterize the bias\nand consistency of IR, particularly compared to Weighted IS (WIS). We\ndemonstrate in several microworlds that IR has improved sample efficiency and\nlower variance updates, as compared to IS and several variance-reduced IS\nstrategies, including variants of WIS and V-trace which clips IS ratios. We\nalso provide a demonstration showing IR improves over IS for learning a value\nfunction from images in a racing car simulator.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 00:30:17 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 19:47:24 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Schlegel", "Matthew", ""], ["Chung", "Wesley", ""], ["Graves", "Daniel", ""], ["Qian", "Jian", ""], ["White", "Martha", ""]]}, {"id": "1906.04338", "submitter": "Jayaraman J. Thiagarajan", "authors": "Kowshik Thopalli, Jayaraman J. Thiagarajan, Rushil Anirudh, Pavan\n  Turaga", "title": "SALT: Subspace Alignment as an Auxiliary Learning Task for Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aims to transfer and adapt knowledge learned\nfrom a labeled source domain to an unlabeled target domain. Key components of\nunsupervised domain adaptation include: (a) maximizing performance on the\ntarget, and (b) aligning the source and target domains. Traditionally, these\ntasks have either been considered as separate, or assumed to be implicitly\naddressed together with high-capacity feature extractors. When considered\nseparately, alignment is usually viewed as a problem of aligning data\ndistributions, either through geometric approaches such as subspace alignment\nor through distributional alignment such as optimal transport. This paper\nrepresents a hybrid approach, where we assume simplified data geometry in the\nform of subspaces, and consider alignment as an auxiliary task to the primary\ntask of maximizing performance on the source. The alignment is made rather\nsimple by leveraging tractable data geometry in the form of subspaces. We\nsynergistically allow certain parameters derived from the closed-form auxiliary\nsolution, to be affected by gradients from the primary task. The proposed\napproach represents a unique fusion of geometric and model-based alignment with\ngradients from a data-driven primary task. Our approach termed SALT, is a\nsimple framework that achieves comparable or sometimes outperforms\nstate-of-the-art on multiple standard benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 01:20:12 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 02:10:38 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Thopalli", "Kowshik", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Anirudh", "Rushil", ""], ["Turaga", "Pavan", ""]]}, {"id": "1906.04346", "submitter": "Shikang Liu", "authors": "Shikang Liu, Fatemeh Vahedian, David Hachen, Omar Lizardo, Christian\n  Poellabauer, Aaron Striegel, and Tijana Milenkovic", "title": "Heterogeneous network approach to predict individuals' mental health", "comments": "Revised on Dec. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depression and anxiety are critical public health issues affecting millions\nof people around the world. To identify individuals who are vulnerable to\ndepression and anxiety, predictive models have been built that typically\nutilize data from one source. Unlike these traditional models, in this study,\nwe leverage a rich heterogeneous data set from the University of Notre Dame's\nNetHealth study that collected individuals' (student participants') social\ninteraction data via smartphones, health-related behavioral data via wearables\n(Fitbit), and trait data from surveys. To integrate the different types of\ninformation, we model the NetHealth data as a heterogeneous information network\n(HIN). Then, we redefine the problem of predicting individuals' mental health\nconditions (depression or anxiety) in a novel manner, as applying to our HIN a\npopular paradigm of a recommender system (RS), which is typically used to\npredict the preference that a person would give to an item (e.g., a movie or\nbook). In our case, the items are the individuals' different mental health\nstates. We evaluate four state-of-the-art RS approaches. Also, we model the\nprediction of individuals' mental health as another problem type - that of node\nclassification (NC) in our HIN, evaluating in the process four node features\nunder logistic regression as a proof-of-concept classifier. We find that our RS\nand NC network methods produce more accurate predictions than a logistic\nregression model using the same NetHealth data in the traditional non-network\nfashion as well as a random-approach. Also, we find that the best of the\nconsidered RS approaches outperforms all considered NC approaches. This is the\nfirst study to integrate smartphone, wearable sensor, and survey data in an HIN\nmanner and use RS or NC on the HIN to predict individuals' mental health\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 01:56:08 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 02:15:15 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Liu", "Shikang", ""], ["Vahedian", "Fatemeh", ""], ["Hachen", "David", ""], ["Lizardo", "Omar", ""], ["Poellabauer", "Christian", ""], ["Striegel", "Aaron", ""], ["Milenkovic", "Tijana", ""]]}, {"id": "1906.04347", "submitter": "Scott Sisson", "authors": "G. S. Rodrigues and D. J. Nott and S. A. Sisson", "title": "Likelihood-free approximate Gibbs sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free methods such as approximate Bayesian computation (ABC) have\nextended the reach of statistical inference to problems with computationally\nintractable likelihoods. Such approaches perform well for small-to-moderate\ndimensional problems, but suffer a curse of dimensionality in the number of\nmodel parameters. We introduce a likelihood-free approximate Gibbs sampler that\nnaturally circumvents the dimensionality issue by focusing on lower-dimensional\nconditional distributions. These distributions are estimated by flexible\nregression models either before the sampler is run, or adaptively during\nsampler implementation. As a result, and in comparison to Metropolis-Hastings\nbased approaches, we are able to fit substantially more challenging statistical\nmodels than would otherwise be possible. We demonstrate the sampler's\nperformance via two simulated examples, and a real analysis of Airbnb rental\nprices using a intractable high-dimensional multivariate non-linear state space\nmodel containing 13,140 parameters, which presents a real challenge to standard\nABC techniques.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 01:56:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Rodrigues", "G. S.", ""], ["Nott", "D. J.", ""], ["Sisson", "S. A.", ""]]}, {"id": "1906.04349", "submitter": "Jack Parker-Holder", "authors": "Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang, Anna Choromanska,\n  Krzysztof Choromanski, Michael I. Jordan", "title": "Learning to Score Behaviors for Guided Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach for comparing reinforcement learning policies,\nusing Wasserstein distances (WDs) in a newly defined latent behavioral space.\nWe show that by utilizing the dual formulation of the WD, we can learn score\nfunctions over policy behaviors that can in turn be used to lead policy\noptimization towards (or away from) (un)desired behaviors. Combined with\nsmoothed WDs, the dual formulation allows us to devise efficient algorithms\nthat take stochastic gradient descent steps through WD regularizers. We\nincorporate these regularizers into two novel on-policy algorithms,\nBehavior-Guided Policy Gradient and Behavior-Guided Evolution Strategies, which\nwe demonstrate can outperform existing methods in a variety of challenging\nenvironments. We also provide an open source demo.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:06:51 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 14:57:54 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 16:02:32 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 08:27:28 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Pacchiano", "Aldo", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""], ["Choromanska", "Anna", ""], ["Choromanski", "Krzysztof", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.04355", "submitter": "Shagun Sodhani", "authors": "Shagun Sodhani, Anirudh Goyal, Tristan Deleu, Yoshua Bengio, Sergey\n  Levine, Jian Tang", "title": "Learning Powerful Policies by Using Consistent Dynamics Model", "comments": "Accpted at RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Reinforcement Learning approaches have the promise of being\nsample efficient. Much of the progress in learning dynamics models in RL has\nbeen made by learning models via supervised learning. But traditional\nmodel-based approaches lead to `compounding errors' when the model is unrolled\nstep by step. Essentially, the state transitions that the learner predicts (by\nunrolling the model for multiple steps) and the state transitions that the\nlearner experiences (by acting in the environment) may not be consistent. There\nis enough evidence that humans build a model of the environment, not only by\nobserving the environment but also by interacting with the environment.\nInteraction with the environment allows humans to carry out experiments: taking\nactions that help uncover true causal relationships which can be used for\nbuilding better dynamics models. Analogously, we would expect such interactions\nto be helpful for a learning agent while learning to model the environment\ndynamics. In this paper, we build upon this intuition by using an auxiliary\ncost function to ensure consistency between what the agent observes (by acting\nin the real world) and what it imagines (by acting in the `learned' world). We\nconsider several tasks - Mujoco based control tasks and Atari games - and show\nthat the proposed approach helps to train powerful policies and better dynamics\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:31:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Sodhani", "Shagun", ""], ["Goyal", "Anirudh", ""], ["Deleu", "Tristan", ""], ["Bengio", "Yoshua", ""], ["Levine", "Sergey", ""], ["Tang", "Jian", ""]]}, {"id": "1906.04356", "submitter": "Tavor Baharav", "authors": "Tavor Z. Baharav, David N. Tse", "title": "Ultra Fast Medoid Identification via Correlated Sequential Halving", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medoid of a set of n points is the point in the set that minimizes the\nsum of distances to other points. It can be determined exactly in O(n^2) time\nby computing the distances between all pairs of points. Previous works show\nthat one can significantly reduce the number of distance computations needed by\nadaptively querying distances. The resulting randomized algorithm is obtained\nby a direct conversion of the computation problem to a multi-armed bandit\nstatistical inference problem. In this work, we show that we can better exploit\nthe structure of the underlying computation problem by modifying the\ntraditional bandit sampling strategy and using it in conjunction with a\nsuitably chosen multi-armed bandit algorithm. Four to five orders of magnitude\ngains over exact computation are obtained on real data, in terms of both number\nof distance computations needed and wall clock time. Theoretical results are\nobtained to quantify such gains in terms of data parameters. Our code is\npublicly available online at\nhttps://github.com/TavorB/Correlated-Sequential-Halving.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:32:29 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:22:11 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Baharav", "Tavor Z.", ""], ["Tse", "David N.", ""]]}, {"id": "1906.04358", "submitter": "David Ha", "authors": "Adam Gaier and David Ha", "title": "Weight Agnostic Neural Networks", "comments": "To appear at NeurIPS 2019, selected for a spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Not all neural network architectures are created equal, some perform much\nbetter than others for certain tasks. But how important are the weight\nparameters of a neural network compared to its architecture? In this work, we\nquestion to what extent neural network architectures alone, without learning\nany weight parameters, can encode solutions for a given task. We propose a\nsearch method for neural network architectures that can already perform a task\nwithout any explicit weight training. To evaluate these networks, we populate\nthe connections with a single shared weight parameter sampled from a uniform\nrandom distribution, and measure the expected performance. We demonstrate that\nour method can find minimal neural network architectures that can perform\nseveral reinforcement learning tasks without weight training. On a supervised\nlearning domain, we find network architectures that achieve much higher than\nchance accuracy on MNIST using random weights. Interactive version of this\npaper at https://weightagnostic.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:40:11 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 07:54:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gaier", "Adam", ""], ["Ha", "David", ""]]}, {"id": "1906.04359", "submitter": "Shanshan Wang", "authors": "Shanshan Wang, Huitao Cheng, Leslie Ying, Taohui Xiao, Ziwen Ke, Xin\n  Liu, Hairong Zheng, Dong Liang", "title": "DeepcomplexMRI: Exploiting deep residual network for fast parallel MR\n  imaging with complex convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a multi-channel image reconstruction method, named\nDeepcomplexMRI, to accelerate parallel MR imaging with residual complex\nconvolutional neural network. Different from most existing works which rely on\nthe utilization of the coil sensitivities or prior information of predefined\ntransforms, DeepcomplexMRI takes advantage of the availability of a large\nnumber of existing multi-channel groudtruth images and uses them as labeled\ndata to train the deep residual convolutional neural network offline. In\nparticular, a complex convolutional network is proposed to take into account\nthe correlation between the real and imaginary parts of MR images. In addition,\nthe k space data consistency is further enforced repeatedly in between layers\nof the network. The evaluations on in vivo datasets show that the proposed\nmethod has the capability to recover the desired multi-channel images. Its\ncomparison with state-of-the-art method also demonstrates that the proposed\nmethod can reconstruct the desired MR images more accurately.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:41:52 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 15:04:38 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wang", "Shanshan", ""], ["Cheng", "Huitao", ""], ["Ying", "Leslie", ""], ["Xiao", "Taohui", ""], ["Ke", "Ziwen", ""], ["Liu", "Xin", ""], ["Zheng", "Hairong", ""], ["Liang", "Dong", ""]]}, {"id": "1906.04365", "submitter": "Wentao Ouyang", "authors": "Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Chao Qi, Zhaojie Liu, Yanlong\n  Du", "title": "Representation Learning-Assisted Click-Through Rate Prediction", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a critical task in online advertising\nsystems. Most existing methods mainly model the feature-CTR relationship and\nsuffer from the data sparsity issue. In this paper, we propose DeepMCP, which\nmodels other types of relationships in order to learn more informative and\nstatistically reliable feature representations, and in consequence to improve\nthe performance of CTR prediction. In particular, DeepMCP contains three parts:\na matching subnet, a correlation subnet and a prediction subnet. These subnets\nmodel the user-ad, ad-ad and feature-CTR relationship respectively. When these\nsubnets are jointly optimized under the supervision of the target labels, the\nlearned feature representations have both good prediction powers and good\nrepresentation abilities. Experiments on two large-scale datasets demonstrate\nthat DeepMCP outperforms several state-of-the-art models for CTR prediction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 03:08:35 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 10:58:36 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 09:12:04 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Ouyang", "Wentao", ""], ["Zhang", "Xiuwu", ""], ["Ren", "Shukui", ""], ["Qi", "Chao", ""], ["Liu", "Zhaojie", ""], ["Du", "Yanlong", ""]]}, {"id": "1906.04370", "submitter": "Michael Arbel", "authors": "Michael Arbel and Anna Korba and Adil Salim and Arthur Gretton", "title": "Maximum Mean Discrepancy Gradient Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a Wasserstein gradient flow of the maximum mean discrepancy\n(MMD) and study its convergence properties.\n  The MMD is an integral probability metric defined for a reproducing kernel\nHilbert space (RKHS), and serves as a metric on probability measures for a\nsufficiently rich RKHS. We obtain conditions for convergence of the gradient\nflow towards a global optimum, that can be related to particle transport when\noptimizing neural networks.\n  We also propose a way to regularize this MMD flow, based on an injection of\nnoise in the gradient. This algorithmic fix comes with theoretical and\nempirical evidence. The practical implementation of the flow is\nstraightforward, since both the MMD and its gradient have simple closed-form\nexpressions, which can be easily estimated with samples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 03:19:04 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 11:43:36 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Arbel", "Michael", ""], ["Korba", "Anna", ""], ["Salim", "Adil", ""], ["Gretton", "Arthur", ""]]}, {"id": "1906.04386", "submitter": "Qingquan Song", "authors": "Qingquan Song, Shiyu Chang and Xia Hu", "title": "Coupled Variational Recurrent Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of streaming recommender system and explore novel\ncollaborative filtering algorithms to handle the data dynamicity and complexity\nin a streaming manner. Although deep neural networks have demonstrated the\neffectiveness of recommendation tasks, it is lack of explorations on\nintegrating probabilistic models and deep architectures under streaming\nrecommendation settings. Conjoining the complementary advantages of\nprobabilistic models and deep neural networks could enhance both model\neffectiveness and the understanding of inference uncertainties. To bridge the\ngap, in this paper, we propose a Coupled Variational Recurrent Collaborative\nFiltering (CVRCF) framework based on the idea of Deep Bayesian Learning to\nhandle the streaming recommendation problem. The framework jointly combines\nstochastic processes and deep factorization models under a Bayesian paradigm to\nmodel the generation and evolution of users' preferences and items'\npopularities. To ensure efficient optimization and streaming update, we further\npropose a sequential variational inference algorithm based on a cross\nvariational recurrent neural network structure. Experimental results on three\nbenchmark datasets demonstrate that the proposed framework performs favorably\nagainst the state-of-the-art methods in terms of both temporal dependency\nmodeling and predictive accuracy. The learned latent variables also provide\nvisualized interpretations for the evolution of temporal dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 04:29:07 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Song", "Qingquan", ""], ["Chang", "Shiyu", ""], ["Hu", "Xia", ""]]}, {"id": "1906.04397", "submitter": "Yanfei Kang", "authors": "Yitian Chen, Yanfei Kang, Yixiong Chen, Zizhuo Wang", "title": "Probabilistic Forecasting with Temporal Convolutional Neural Network", "comments": "24 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic forecasting framework based on convolutional\nneural network for multiple related time series forecasting. The framework can\nbe applied to estimate probability density under both parametric and\nnon-parametric settings. More specifically, stacked residual blocks based on\ndilated causal convolutional nets are constructed to capture the temporal\ndependencies of the series. Combined with representation learning, our approach\nis able to learn complex patterns such as seasonality, holiday effects within\nand across series, and to leverage those patterns for more accurate forecasts,\nespecially when historical data is sparse or unavailable. Extensive empirical\nstudies are performed on several real-world datasets, including datasets from\nJD.com, China's largest online retailer. The results show that our framework\noutperforms other state-of-the-art methods in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 05:26:11 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 02:31:57 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 04:21:03 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Yitian", ""], ["Kang", "Yanfei", ""], ["Chen", "Yixiong", ""], ["Wang", "Zizhuo", ""]]}, {"id": "1906.04411", "submitter": "Jia Guo", "authors": "Jia Guo, Miodrag Potkonjak", "title": "Evolutionary Trigger Set Generation for DNN Black-Box Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The commercialization of deep learning creates a compelling need for\nintellectual property (IP) protection. Deep neural network (DNN) watermarking\nhas been proposed as a promising tool to help model owners prove ownership and\nfight piracy. A popular approach of watermarking is to train a DNN to recognize\nimages with certain \\textit{trigger} patterns. In this paper, we propose a\nnovel evolutionary algorithm-based method to generate and optimize trigger\npatterns. Our method brings a siginificant reduction in false positive rates,\nleading to compelling proof of ownership. At the same time, it maintains the\nrobustness of the watermark against attacks. We compare our method with the\nprior art and demonstrate its effectiveness on popular models and datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 06:46:20 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 03:38:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Jia", ""], ["Potkonjak", "Miodrag", ""]]}, {"id": "1906.04436", "submitter": "Jos\\'e Lic\\'on-Sal\\'aiz", "authors": "Henri Riihim\\\"aki, Jos\\'e Lic\\'on-Sal\\'aiz", "title": "Metrics for Learning in Topological Persistence", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology analysis provides means to capture the connectivity\nstructure of data sets in various dimensions. On the mathematical level, by\ndefining a metric between the objects that persistence attaches to data sets,\nwe can stabilize invariants characterizing these objects. We outline how so\ncalled contour functions induce relevant metrics for stabilizing the rank\ninvariant. On the practical level, the stable ranks are used as fingerprints\nfor data. Different choices of contour lead to different stable ranks and the\ntopological learning is then the question of finding the optimal contour. We\noutline our analysis pipeline and show how it can enhance classification of\nphysical activities data. As our main application we study how stable ranks and\ncontours provide robust descriptors of spatial patterns of atmospheric cloud\nfields.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:17:17 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Riihim\u00e4ki", "Henri", ""], ["Lic\u00f3n-Sal\u00e1iz", "Jos\u00e9", ""]]}, {"id": "1906.04448", "submitter": "Fabrizio Carpi", "authors": "Fabrizio Carpi, Christian H\\\"ager, Marco Martal\\`o, Riccardo Raheli,\n  Henry D. Pfister", "title": "Reinforcement Learning for Channel Coding: Learned Bit-Flipping Decoding", "comments": null, "journal-ref": null, "doi": "10.1109/ALLERTON.2019.8919799", "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use reinforcement learning to find effective decoding\nstrategies for binary linear codes. We start by reviewing several iterative\ndecoding algorithms that involve a decision-making process at each step,\nincluding bit-flipping (BF) decoding, residual belief propagation, and anchor\ndecoding. We then illustrate how such algorithms can be mapped to Markov\ndecision processes allowing for data-driven learning of optimal decision\nstrategies, rather than basing decisions on heuristics or intuition. As a case\nstudy, we consider BF decoding for both the binary symmetric and additive white\nGaussian noise channel. Our results show that learned BF decoders can offer a\nrange of performance-complexity trade-offs for the considered Reed-Muller and\nBCH codes, and achieve near-optimal performance in some cases. We also\ndemonstrate learning convergence speed-ups when biasing the learning process\ntowards correct decoding decisions, as opposed to relying only on random\nexplorations and past knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:58:11 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 12:48:03 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Carpi", "Fabrizio", ""], ["H\u00e4ger", "Christian", ""], ["Martal\u00f2", "Marco", ""], ["Raheli", "Riccardo", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1906.04450", "submitter": "Qingyang Wu", "authors": "Qingyang Wu, He Li, Lexin Li, Zhou Yu", "title": "Quantifying Intrinsic Uncertainty in Classification via Deep Dirichlet\n  Mixture Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread success of deep neural networks in science and\ntechnology, it is becoming increasingly important to quantify the uncertainty\nof the predictions produced by deep learning. In this paper, we introduce a new\nmethod that attaches an explicit uncertainty statement to the probabilities of\nclassification using deep neural networks. Precisely, we view that the\nclassification probabilities are sampled from an unknown distribution, and we\npropose to learn this distribution through the Dirichlet mixture that is\nflexible enough for approximating any continuous distribution on the simplex.\nWe then construct credible intervals from the learned distribution to assess\nthe uncertainty of the classification probabilities. Our approach is easy to\nimplement, computationally efficient, and can be coupled with any deep neural\nnetwork architecture. Our method leverages the crucial observation that, in\nmany classification applications such as medical diagnosis, more than one class\nlabels are available for each observational unit. We demonstrate the usefulness\nof our approach through simulations and a real data example.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:02:35 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 17:52:37 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wu", "Qingyang", ""], ["Li", "He", ""], ["Li", "Lexin", ""], ["Yu", "Zhou", ""]]}, {"id": "1906.04452", "submitter": "Kalifou Ren\\'e Traor\\'e", "authors": "Ren\\'e Traor\\'e, Hugo Caselles-Dupr\\'e, Timoth\\'ee Lesort, Te Sun,\n  Natalia D\\'iaz-Rodr\\'iguez, David Filliat", "title": "Continual Reinforcement Learning deployed in Real-life using Policy\n  Distillation and Sim2Real Transfer", "comments": "accepted to the Workshop on Multi-Task and Lifelong Reinforcement\n  Learning, ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of teaching a robot to solve tasks presented\nsequentially, i.e., in a continual learning scenario. The robot should be able\nto solve all tasks it has encountered, without forgetting past tasks. We\nprovide preliminary work on applying Reinforcement Learning to such setting, on\n2D navigation tasks for a 3 wheel omni-directional robot. Our approach takes\nadvantage of state representation learning and policy distillation. Policies\nare trained using learned features as input, rather than raw observations,\nallowing better sample efficiency. Policy distillation is used to combine\nmultiple policies into a single one that solves all encountered tasks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:06:19 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Traor\u00e9", "Ren\u00e9", ""], ["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesort", "Timoth\u00e9e", ""], ["Sun", "Te", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1906.04477", "submitter": "Shengyu Zhu", "authors": "Shengyu Zhu, Ignavier Ng, Zhitang Chen", "title": "Causal Discovery with Reinforcement Learning", "comments": "ICLR 2020 (oral). This version: minor edits in the appendix. Codes,\n  datasets, and training logs have been made available at\n  https://github.com/huawei-noah/trustworthyAI/tree/master/Causal_Structure_Learning/Causal_Discovery_RL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering causal structure among a set of variables is a fundamental\nproblem in many empirical sciences. Traditional score-based casual discovery\nmethods rely on various local heuristics to search for a Directed Acyclic Graph\n(DAG) according to a predefined score function. While these methods, e.g.,\ngreedy equivalence search, may have attractive results with infinite samples\nand certain model assumptions, they are usually less satisfactory in practice\ndue to finite data and possible violation of assumptions. Motivated by recent\nadvances in neural combinatorial optimization, we propose to use Reinforcement\nLearning (RL) to search for the DAG with the best scoring. Our encoder-decoder\nmodel takes observable data as input and generates graph adjacency matrices\nthat are used to compute rewards. The reward incorporates both the predefined\nscore function and two penalty terms for enforcing acyclicity. In contrast with\ntypical RL applications where the goal is to learn a policy, we use RL as a\nsearch strategy and our final output would be the graph, among all graphs\ngenerated during training, that achieves the best reward. We conduct\nexperiments on both synthetic and real datasets, and show that the proposed\napproach not only has an improved search ability but also allows a flexible\nscore function under the acyclicity constraint.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:09:35 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 14:18:52 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 13:59:12 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 14:48:29 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhu", "Shengyu", ""], ["Ng", "Ignavier", ""], ["Chen", "Zhitang", ""]]}, {"id": "1906.04479", "submitter": "Th\\'eophile Griveau-Billion", "authors": "Th\\'eophile Griveau-Billion and Ben Calderhead", "title": "Efficient structure learning with automatic sparsity selection for\n  causal graph processes", "comments": "11 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for efficiently computing a sparse directed\nadjacency matrix from a group of time series following a causal graph process.\nOur solution is scalable for both dense and sparse graphs and automatically\nselects the LASSO coefficient to obtain an appropriate number of edges in the\nadjacency matrix. Current state-of-the-art approaches rely on\nsparse-matrix-computation libraries to scale, and either avoid automatic\nselection of the LASSO penalty coefficient or rely on the prediction mean\nsquared error, which is not directly related to the correct number of edges.\nInstead, we propose a cyclical coordinate descent algorithm that employs two\nnew non-parametric error metrics to automatically select the LASSO coefficient.\nWe demonstrate state-of-the-art performance of our algorithm on simulated\nstochastic block models and a real dataset of stocks from the S\\&P$500$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:11:15 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 09:28:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Griveau-Billion", "Th\u00e9ophile", ""], ["Calderhead", "Ben", ""]]}, {"id": "1906.04488", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky and Osvaldo Simeone", "title": "Optimizing Pipelined Computation and Communication for\n  Latency-Constrained Edge Learning", "comments": "to be published in IEEE Communication Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a device that is connected to an edge processor via a communication\nchannel. The device holds local data that is to be offloaded to the edge\nprocessor so as to train a machine learning model, e.g., for regression or\nclassification. Transmission of the data to the learning processor, as well as\ntraining based on Stochastic Gradient Descent (SGD), must be both completed\nwithin a time limit. Assuming that communication and computation can be\npipelined, this letter investigates the optimal choice for the packet payload\nsize, given the overhead of each data packet transmission and the ratio between\nthe computation and the communication rates. This amounts to a tradeoff between\nbias and variance, since communicating the entire data set first reduces the\nbias of the training process but it may not leave sufficient time for learning.\nAnalytical bounds on the expected optimality gap are derived so as to enable an\neffective optimization, which is validated in numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:38:09 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 09:52:46 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1906.04507", "submitter": "Nikolaos Gianniotis", "authors": "Nikolaos Gianniotis and Christoph Schn\\\"orr and Christian Molkenthin\n  and Sanjay Singh Bora", "title": "Approximate Variational Inference Based on a Finite Sample of Gaussian\n  Latent Variables", "comments": "published in Pattern Analysis and Applications", "journal-ref": "Pattern Anal Applic (2016) 19: 475", "doi": "10.1007/s10044-015-0496-9", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational methods are employed in situations where exact Bayesian inference\nbecomes intractable due to the difficulty in performing certain integrals.\nTypically, variational methods postulate a tractable posterior and formulate a\nlower bound on the desired integral to be approximated, e.g. marginal\nlikelihood. The lower bound is then optimised with respect to its free\nparameters, the so called variational parameters. However, this is not always\npossible as for certain integrals it is very challenging (or tedious) to come\nup with a suitable lower bound. Here we propose a simple scheme that overcomes\nsome of the awkward cases where the usual variational treatment becomes\ndifficult. The scheme relies on a rewriting of the lower bound on the model\nlog-likelihood. We demonstrate the proposed scheme on a number of synthetic and\nreal examples, as well as on a real geophysical model for which the standard\nvariational approaches are inapplicable.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 11:56:47 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Gianniotis", "Nikolaos", ""], ["Schn\u00f6rr", "Christoph", ""], ["Molkenthin", "Christian", ""], ["Bora", "Sanjay Singh", ""]]}, {"id": "1906.04509", "submitter": "Muhammad Tayyab", "authors": "Muhammad Tayyab and Abhijit Mahalanobis", "title": "BasisConv: A method for compressed representation and learning in CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Convolutional Neural Networks (CNNs) have significant\nredundancy in their filter weights. Various methods have been proposed in the\nliterature to compress trained CNNs. These include techniques like pruning\nweights, filter quantization and representing filters in terms of a basis\nfunctions. Our approach falls in this latter class of strategies, but is\ndistinct in that that we show both compressed learning and representation can\nbe achieved without significant modifications of popular CNN architectures.\nSpecifically, any convolution layer of the CNN is easily replaced by two\nsuccessive convolution layers: the first is a set of fixed filters (that\nrepresent the knowledge space of the entire layer and do not change), which is\nfollowed by a layer of one-dimensional filters (that represent the learned\nknowledge in this space). For the pre-trained networks, the fixed layer is just\nthe truncated eigen-decompositions of the original filters. The 1D filters are\ninitialized as the weights of linear combination, but are fine-tuned to recover\nany performance loss due to the truncation. For training networks from scratch,\nwe use a set of random orthogonal fixed filters (that never change), and learn\nthe 1D weight vector directly from the labeled data. Our method substantially\nreduces i) the number of learnable parameters during training, and ii) the\nnumber of multiplication operations and filter storage requirements during\nimplementation. It does so without requiring any special operators in the\nconvolution layer, and extends to all known popular CNN architectures. We apply\nour method to four well known network architectures trained with three\ndifferent data sets. Results show a consistent reduction in i) the number of\noperations by up to a factor of 5, and ii) number of learnable parameters by up\nto a factor of 18, with less than 3% drop in performance on the CIFAR100\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:07:48 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Tayyab", "Muhammad", ""], ["Mahalanobis", "Abhijit", ""]]}, {"id": "1906.04516", "submitter": "Kimia Nadjahi", "authors": "Kimia Nadjahi, Alain Durmus, Umut \\c{S}im\\c{s}ekli, Roland Badeau", "title": "Asymptotic Guarantees for Learning Generative Models with the\n  Sliced-Wasserstein Distance", "comments": "Accepted at NeurIPS 2019 (publication and spotlight presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum expected distance estimation (MEDE) algorithms have been widely used\nfor probabilistic models with intractable likelihood functions and they have\nbecome increasingly popular due to their use in implicit generative modeling\n(e.g. Wasserstein generative adversarial networks, Wasserstein autoencoders).\nEmerging from computational optimal transport, the Sliced-Wasserstein (SW)\ndistance has become a popular choice in MEDE thanks to its simplicity and\ncomputational benefits. While several studies have reported empirical success\non generative modeling with SW, the theoretical properties of such estimators\nhave not yet been established. In this study, we investigate the asymptotic\nproperties of estimators that are obtained by minimizing SW. We first show that\nconvergence in SW implies weak convergence of probability measures in general\nWasserstein spaces. Then we show that estimators obtained by minimizing SW (and\nalso an approximate version of SW) are asymptotically consistent. We finally\nprove a central limit theorem, which characterizes the asymptotic distribution\nof the estimators and establish a convergence rate of $\\sqrt{n}$, where $n$\ndenotes the number of observed data points. We illustrate the validity of our\ntheory on both synthetic data and neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:13:12 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 13:56:43 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Nadjahi", "Kimia", ""], ["Durmus", "Alain", ""], ["\u015eim\u015fekli", "Umut", ""], ["Badeau", "Roland", ""]]}, {"id": "1906.04536", "submitter": "Armand Boschin", "authors": "Armand Boschin, Thomas Bonald", "title": "WikiDataSets: Standardized sub-graphs from Wikidata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing new ideas and algorithms in the fields of graph processing and\nrelational learning requires public datasets. While Wikidata is the largest\nopen source knowledge graph, involving more than fifty million entities, it is\nlarger than needed in many cases and even too large to be processed easily.\nStill, it is a goldmine of relevant facts and relations. Using this knowledge\ngraph is time consuming and prone to task specific tuning which can affect\nreproducibility of results. Providing a unified framework to extract\ntopic-specific subgraphs solves this problem and allows researchers to evaluate\nalgorithms on common datasets. This paper presents various topic-specific\nsubgraphs of Wikidata along with the generic Python code used to extract them.\nThese datasets can help develop new methods of knowledge graph processing and\nrelational learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:47:59 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 18:08:38 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 13:27:17 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Boschin", "Armand", ""], ["Bonald", "Thomas", ""]]}, {"id": "1906.04540", "submitter": "Matus Telgarsky", "authors": "Ziwei Ji and Matus Telgarsky", "title": "Characterizing the implicit bias via a primal-dual analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that the implicit bias of gradient descent on linearly\nseparable data is exactly characterized by the optimal solution of a dual\noptimization problem given by a smoothed margin, even for general losses. This\nis in contrast to prior results, which are often tailored to\nexponentially-tailed losses. For the exponential loss specifically, with $n$\ntraining examples and $t$ gradient descent steps, our dual analysis further\nallows us to prove an $O(\\ln(n)/\\ln(t))$ convergence rate to the $\\ell_2$\nmaximum margin direction, when a constant step size is used. This rate is tight\nin both $n$ and $t$, which has not been presented by prior work. On the other\nhand, with a properly chosen but aggressive step size schedule, we prove\n$O(1/t)$ rates for both $\\ell_2$ margin maximization and implicit bias, whereas\nprior work (including all first-order methods for the general hard-margin\nlinear SVM problem) proved $\\widetilde{O}(1/\\sqrt{t})$ margin rates, or\n$O(1/t)$ margin rates to a suboptimal margin, with an implied (slower) bias\nrate. Our key observations include that gradient descent on the primal variable\nnaturally induces a mirror descent update on the dual variable, and that the\ndual objective in this setting is smooth enough to give a faster rate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:53:38 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 08:28:05 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 17:07:58 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1906.04542", "submitter": "Henry WJ Reeve", "authors": "Henry W. J. Reeve, Ata Kaban", "title": "Fast Rates for a kNN Classifier Robust to Unknown Asymmetric Label Noise", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider classification in the presence of class-dependent asymmetric\nlabel noise with unknown noise probabilities. In this setting, identifiability\nconditions are known, but additional assumptions were shown to be required for\nfinite sample rates, and so far only the parametric rate has been obtained.\nAssuming these identifiability conditions, together with a measure-smoothness\ncondition on the regression function and Tsybakov's margin condition, we show\nthat the Robust kNN classifier of Gao et al. attains, the minimax optimal rates\nof the noise-free setting, up to a log factor, even when trained on data with\nunknown asymmetric label noise. Hence, our results provide a solid theoretical\nbacking for this empirically successful algorithm. By contrast the standard kNN\nis not even consistent in the setting of asymmetric label noise. A key idea in\nour analysis is a simple kNN based method for estimating the maximum of a\nfunction that requires far less assumptions than existing mode estimators do,\nand which may be of independent interest for noise proportion estimation and\nrandomised optimisation problems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:56:25 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Reeve", "Henry W. J.", ""], ["Kaban", "Ata", ""]]}, {"id": "1906.04548", "submitter": "Egor Samosvat", "authors": "Yana Kashinskaya, Egor Samosvat, Akmal Artikov", "title": "Spring-Electrical Models For Link Prediction", "comments": "Accepted to WSDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a link prediction algorithm that is based on spring-electrical\nmodels. The idea to study these models came from the fact that\nspring-electrical models have been successfully used for networks\nvisualization. A good network visualization usually implies that nodes similar\nin terms of network topology, e.g., connected and/or belonging to one cluster,\ntend to be visualized close to each other. Therefore, we assumed that the\nEuclidean distance between nodes in the obtained network layout correlates with\na probability of a link between them. We evaluate the proposed method against\nseveral popular baselines and demonstrate its flexibility by applying it to\nundirected, directed and bipartite networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:47:44 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Kashinskaya", "Yana", ""], ["Samosvat", "Egor", ""], ["Artikov", "Akmal", ""]]}, {"id": "1906.04554", "submitter": "Florent Krzakala", "authors": "Julien Launay, Iacopo Poli and Florent Krzakala", "title": "Principled Training of Neural Networks with Direct Feedback Alignment", "comments": "10 pages, 4 figures, 4 tables, github repo at:\n  https://github.com/lightonai/principled-dfa-training", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm has long been the canonical training method for\nneural networks. Modern paradigms are implicitly optimized for it, and numerous\nguidelines exist to ensure its proper use. Recently, synthetic gradients\nmethods -where the error gradient is only roughly approximated - have garnered\ninterest. These methods not only better portray how biological brains are\nlearning, but also open new computational possibilities, such as updating\nlayers asynchronously. Even so, they have failed to scale past simple tasks\nlike MNIST or CIFAR-10. This is in part due to a lack of standards, leading to\nill-suited models and practices forbidding such methods from performing to the\nbest of their abilities. In this work, we focus on direct feedback alignment\nand present a set of best practices justified by observations of the alignment\nangles. We characterize a bottleneck effect that prevents alignment in narrow\nlayers, and hypothesize it may explain why feedback alignment methods have yet\nto scale to large convolutional networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:08:19 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Launay", "Julien", ""], ["Poli", "Iacopo", ""], ["Krzakala", "Florent", ""]]}, {"id": "1906.04556", "submitter": "Matthieu Zimmer", "authors": "Matthieu Zimmer, Paul Weng", "title": "Exploiting the Sign of the Advantage Function to Learn Deterministic\n  Policies in Continuous Domains", "comments": "International Joint Conferences on Artificial Intelligence", "journal-ref": null, "doi": "10.24963/ijcai.2019/625", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of learning deterministic policies in continuous domains, we\nrevisit an approach, which was first proposed in Continuous Actor Critic\nLearning Automaton (CACLA) and later extended in Neural Fitted Actor Critic\n(NFAC). This approach is based on a policy update different from that of\ndeterministic policy gradient (DPG). Previous work has observed its excellent\nperformance empirically, but a theoretical justification is lacking. To fill\nthis gap, we provide a theoretical explanation to motivate this unorthodox\npolicy update by relating it to another update and making explicit the\nobjective function of the latter. We furthermore discuss in depth the\nproperties of these updates to get a deeper understanding of the overall\napproach. In addition, we extend it and propose a new trust region algorithm,\nPenalized NFAC (PeNFAC). Finally, we experimentally demonstrate in several\nclassic control problems that it surpasses the state-of-the-art algorithms to\nlearn deterministic policies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 03:07:00 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 02:55:34 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zimmer", "Matthieu", ""], ["Weng", "Paul", ""]]}, {"id": "1906.04559", "submitter": "Jasper Kyle Catapang", "authors": "Jasper Kyle Catapang", "title": "k-Nearest Neighbor Optimization via Randomized Hyperstructure Convex\n  Hull", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.3244260", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the k-nearest neighbor algorithm (k-NN), the determination of classes for\ntest instances is usually performed via a majority vote system, which may\nignore the similarities among data. In this research, the researcher proposes\nan approach to fine-tune the selection of neighbors to be passed to the\nmajority vote system through the construction of a random n-dimensional\nhyperstructure around the test instance by introducing a new threshold\nparameter. The accuracy of the proposed k-NN algorithm is 85.71%, while the\naccuracy of the conventional k-NN algorithm is 80.95% when performed on the\nHaberman's Cancer Survival dataset, and 94.44% for the proposed k-NN algorithm,\ncompared to the conventional's 88.89% accuracy score on the Seeds dataset. The\nproposed k-NN algorithm is also on par with the conventional support vector\nmachine algorithm accuracy, even on the Banknote Authentication and Iris\ndatasets, even surpassing the accuracy of support vector machine on the Seeds\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:38:17 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Catapang", "Jasper Kyle", ""]]}, {"id": "1906.04563", "submitter": "Clifford Anderson-Bergman", "authors": "Clifford Anderson-Bergman, Phan Nguyen and Jose Cadena Pico", "title": "Latent Channel Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Euclidean embedding models a given network by representing each node\nin a Euclidean space, where the probability of two nodes sharing an edge is a\nfunction of the distances between the nodes. This implies that for two nodes to\nshare an edge with high probability, they must be relatively close in all\ndimensions. This constraint may be overly restrictive for describing modern\nnetworks, in which having similarities in at least one area may be sufficient\nfor having a high edge probability. We introduce a new model, which we call\nLatent Channel Networks, which allows for such features of a network. We\npresent an EM algorithm for fitting the model, for which the computational\ncomplexity is linear in the number of edges and number of channels and apply\nthe algorithm to both synthetic and classic network datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:50:06 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 22:47:51 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Anderson-Bergman", "Clifford", ""], ["Nguyen", "Phan", ""], ["Pico", "Jose Cadena", ""]]}, {"id": "1906.04569", "submitter": "Hien Nguyen", "authors": "Aryan Mobiny, Hien V. Nguyen, Supratik Moulik, Naveen Garg, Carol C.\n  Wu", "title": "DropConnect Is Effective in Modeling Uncertainty of Bayesian Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved state-of-the-art performances in\nmany important domains, including medical diagnosis, security, and autonomous\ndriving. In these domains where safety is highly critical, an erroneous\ndecision can result in serious consequences. While a perfect prediction\naccuracy is not always achievable, recent work on Bayesian deep networks shows\nthat it is possible to know when DNNs are more likely to make mistakes. Knowing\nwhat DNNs do not know is desirable to increase the safety of deep learning\ntechnology in sensitive applications. Bayesian neural networks attempt to\naddress this challenge. However, traditional approaches are computationally\nintractable and do not scale well to large, complex neural network\narchitectures. In this paper, we develop a theoretical framework to approximate\nBayesian inference for DNNs by imposing a Bernoulli distribution on the model\nweights. This method, called MC-DropConnect, gives us a tool to represent the\nmodel uncertainty with little change in the overall model structure or\ncomputational cost. We extensively validate the proposed algorithm on multiple\nnetwork architectures and datasets for classification and semantic segmentation\ntasks. We also propose new metrics to quantify the uncertainty estimates. This\nenables an objective comparison between MC-DropConnect and prior approaches.\nOur empirical results demonstrate that the proposed framework yields\nsignificant improvement in both prediction accuracy and uncertainty estimation\nquality compared to the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:51:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Mobiny", "Aryan", ""], ["Nguyen", "Hien V.", ""], ["Moulik", "Supratik", ""], ["Garg", "Naveen", ""], ["Wu", "Carol C.", ""]]}, {"id": "1906.04580", "submitter": "Qiran Gong", "authors": "Hao Peng, Jianxin Li, Qiran Gong, Yangqiu Song, Yuanxing Ning, Kunfeng\n  Lai, Philip S. Yu", "title": "Fine-grained Event Categorization with Heterogeneous Graph Convolutional\n  Networks", "comments": "Accepted by IJCAI'19(International Joint Conference on Artificial\n  Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events are happening in real-world and real-time, which can be planned and\norganized occasions involving multiple people and objects. Social media\nplatforms publish a lot of text messages containing public events with\ncomprehensive topics. However, mining social events is challenging due to the\nheterogeneous event elements in texts and explicit and implicit social network\nstructures. In this paper, we design an event meta-schema to characterize the\nsemantic relatedness of social events and build an event-based heterogeneous\ninformation network (HIN) integrating information from external knowledge base,\nand propose a novel Pair-wise Popularity Graph Convolutional Network (PP-GCN)\nbased fine-grained social event categorization model. We propose a\nKnowledgeable meta-paths Instances based social Event Similarity (KIES) between\nevents and build a weighted adjacent matrix as input to the PP-GCN model.\nComprehensive experiments on real data collections are conducted to compare\nvarious social event detection and clustering tasks. Experimental results\ndemonstrate that our proposed framework outperforms other alternative social\nevent categorization techniques.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:08:20 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Gong", "Qiran", ""], ["Song", "Yangqiu", ""], ["Ning", "Yuanxing", ""], ["Lai", "Kunfeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1906.04584", "submitter": "Hadi Salman", "authors": "Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya\n  Razenshteyn, Sebastien Bubeck", "title": "Provably Robust Deep Learning via Adversarially Trained Smoothed\n  Classifiers", "comments": "Spotlight at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada; 9 pages main text; 31 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown the effectiveness of randomized smoothing as a\nscalable technique for building neural network-based classifiers that are\nprovably robust to $\\ell_2$-norm adversarial perturbations. In this paper, we\nemploy adversarial training to improve the performance of randomized smoothing.\nWe design an adapted attack for smoothed classifiers, and we show how this\nattack can be used in an adversarial training setting to boost the provable\nrobustness of smoothed classifiers. We demonstrate through extensive\nexperimentation that our method consistently outperforms all existing provably\n$\\ell_2$-robust classifiers by a significant margin on ImageNet and CIFAR-10,\nestablishing the state-of-the-art for provable $\\ell_2$-defenses. Moreover, we\nfind that pre-training and semi-supervised learning boost adversarially trained\nsmoothed classifiers even further. Our code and trained models are available at\nhttp://github.com/Hadisalman/smoothing-adversarial .\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 15:55:21 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 06:08:27 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 06:28:54 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 09:26:29 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 00:03:27 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Salman", "Hadi", ""], ["Yang", "Greg", ""], ["Li", "Jerry", ""], ["Zhang", "Pengchuan", ""], ["Zhang", "Huan", ""], ["Razenshteyn", "Ilya", ""], ["Bubeck", "Sebastien", ""]]}, {"id": "1906.04585", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran, Joshua Romoff, Nicolas Ballas, Joelle Pineau, Michael\n  Rabbat", "title": "Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (2019)\n  13299-13309", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-simulator training has contributed to the recent success of Deep\nReinforcement Learning by stabilizing learning and allowing for higher training\nthroughputs. We propose Gossip-based Actor-Learner Architectures (GALA) where\nseveral actor-learners (such as A2C agents) are organized in a peer-to-peer\ncommunication topology, and exchange information through asynchronous gossip in\norder to take advantage of a large number of distributed simulators. We prove\nthat GALA agents remain within an epsilon-ball of one-another during training\nwhen using loosely coupled asynchronous communication. By reducing the amount\nof synchronization between agents, GALA is more computationally efficient and\nscalable compared to A2C, its fully-synchronous counterpart. GALA also\noutperforms A2C, being more robust and sample efficient. We show that we can\nrun several loosely coupled GALA agents in parallel on a single GPU and achieve\nsignificantly higher hardware utilization and frame-rates than vanilla A2C at\ncomparable power draws.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:15:43 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 23:56:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Assran", "Mahmoud", ""], ["Romoff", "Joshua", ""], ["Ballas", "Nicolas", ""], ["Pineau", "Joelle", ""], ["Rabbat", "Michael", ""]]}, {"id": "1906.04586", "submitter": "Ons Khemiri", "authors": "Ons Khemiri", "title": "Proposition d'une nouvelle approche d'extraction des motifs ferm\\'es\n  fr\\'equents", "comments": "in French. arXiv admin note: substantial text overlap with\n  arXiv:1810.07116, arXiv:1312.1558 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is done as part of a master's thesis project. The increase in the\nvolume of data has given rise to various issues related to the collection,\nstorage, analysis and exploitation of these data in order to create an added\nvalue. In this master, we are interested in the search of frequent closed\npatterns in the transaction bases. One way to process data is to partition the\nsearch space into subcontexts, and then explore the subcontexts simultaneously.\nIn this context, we have proposed a new approach for extracting frequent closed\nitemsets. The main idea is to update frequent closed patterns with their\nminimal generators by applying a strategy of partitioning of the initial\nextraction context. Our new approach called UFCIGs-DAC was designed and\nimplemented to perform a search in the test bases. The main originality of this\napproach is the simultaneous exploration of the research space by the update of\nthe frequent closed patterns and the minimal generators. Moreover, our approach\ncan be adapted to any algorithm of extraction of the frequent closed patterns\nwith their minimal generators.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 19:07:37 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Khemiri", "Ons", ""]]}, {"id": "1906.04594", "submitter": "Yuxiu Hua", "authors": "Chen Qi, Yuxiu Hua, Rongpeng Li, Zhifeng Zhao, Honggang Zhang", "title": "Deep Reinforcement Learning with Discrete Normalized Advantage Functions\n  for Resource Management in Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing promises to provision diversified services with distinct\nrequirements in one infrastructure. Deep reinforcement learning (e.g., deep\n$\\mathcal{Q}$-learning, DQL) is assumed to be an appropriate algorithm to solve\nthe demand-aware inter-slice resource management issue in network slicing by\nregarding the varying demands and the allocated bandwidth as the environment\nstate and the action, respectively. However, allocating bandwidth in a finer\nresolution usually implies larger action space, and unfortunately DQL fails to\nquickly converge in this case. In this paper, we introduce discrete normalized\nadvantage functions (DNAF) into DQL, by separating the $\\mathcal{Q}$-value\nfunction as a state-value function term and an advantage term and exploiting a\ndeterministic policy gradient descent (DPGD) algorithm to avoid the unnecessary\ncalculation of $\\mathcal{Q}$-value for every state-action pair. Furthermore, as\nDPGD only works in continuous action space, we embed a k-nearest neighbor\nalgorithm into DQL to quickly find a valid action in the discrete space nearest\nto the DPGD output. Finally, we verify the faster convergence of the DNAF-based\nDQL through extensive simulations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 05:28:44 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Qi", "Chen", ""], ["Hua", "Yuxiu", ""], ["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Zhang", "Honggang", ""]]}, {"id": "1906.04595", "submitter": "Chaopeng Shen", "authors": "Kuai Fang, Chaopeng Shen, Daniel Kifer", "title": "Evaluating aleatoric and epistemic uncertainties of time series deep\n  learning models for soil moisture predictions", "comments": null, "journal-ref": "Water Resources Research (2020)", "doi": "10.1029/2020WR028095", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soil moisture is an important variable that determines floods, vegetation\nhealth, agriculture productivity, and land surface feedbacks to the atmosphere,\netc. Accurately modeling soil moisture has important implications in both\nweather and climate models. The recently available satellite-based observations\ngive us a unique opportunity to build data-driven models to predict soil\nmoisture instead of using land surface models, but previously there was no\nuncertainty estimate. We tested Monte Carlo dropout (MCD) with an aleatoric\nterm for our long short-term memory models for this problem, and asked if the\nuncertainty terms behave as they were argued to. We show that the method\nsuccessfully captures the predictive error after tuning a hyperparameter on a\nrepresentative training dataset. We show the MCD uncertainty estimate, as\npreviously argued, does detect dissimilarity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:18:35 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fang", "Kuai", ""], ["Shen", "Chaopeng", ""], ["Kifer", "Daniel", ""]]}, {"id": "1906.04596", "submitter": "Amir Gholami", "authors": "Tianjun Zhang and Zhewei Yao and Amir Gholami and Kurt Keutzer and\n  Joseph Gonzalez and George Biros and Michael Mahoney", "title": "ANODEV2: A Coupled Neural ODE Evolution Framework", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that residual networks can be viewed as the explicit\nEuler discretization of an Ordinary Differential Equation (ODE). This\nobservation motivated the introduction of so-called Neural ODEs, which allow\nmore general discretization schemes with adaptive time stepping. Here, we\npropose ANODEV2, which is an extension of this approach that also allows\nevolution of the neural network parameters, in a coupled ODE-based formulation.\nThe Neural ODE method introduced earlier is in fact a special case of this new\nmore general framework. We present the formulation of ANODEV2, derive\noptimality conditions, and implement a coupled reaction-diffusion-advection\nversion of this framework in PyTorch. We present empirical results using\nseveral different configurations of ANODEV2, testing them on multiple models on\nCIFAR-10. We report results showing that this coupled ODE-based framework is\nindeed trainable, and that it achieves higher accuracy, as compared to the\nbaseline models as well as the recently-proposed Neural ODE approach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:45:47 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zhang", "Tianjun", ""], ["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Keutzer", "Kurt", ""], ["Gonzalez", "Joseph", ""], ["Biros", "George", ""], ["Mahoney", "Michael", ""]]}, {"id": "1906.04608", "submitter": "Tomoyuki Kubota", "authors": "Tomoyuki Kubota, Hirokazu Takahashi, and Kohei Nakajima", "title": "A Unifying Framework for Information Processing in Stochastically Driven\n  Dynamical Systems", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A dynamical system can be regarded as an information processing apparatus\nthat encodes input streams from the external environment to its state and\nprocesses them through state transitions. The information processing capacity\n(IPC) is an excellent tool that comprehensively evaluates these processed\ninputs, providing details of unknown information processing in black box\nsystems; however, this measure can be applied to only time-invariant systems.\nThis paper extends the applicable range to time-variant systems and further\nreveals that the IPC is equivalent to coefficients of polynomial chaos (PC)\nexpansion in more general dynamical systems. To achieve this objective, we\ntackle three issues. First, we establish a connection between the IPC for\ntime-invariant systems and PC expansion, which is a type of polynomial\nexpansion using orthogonal functions of input history as bases. We prove that\nthe IPC corresponds to the squared norm of the coefficient vector of the basis\nin the PC expansion. Second, we show that an input following an arbitrary\ndistribution can be used for the IPC, removing previous restrictions to\nspecific input distributions. Third, we extend the conventional orthogonal\nbases to functions of both time and input history and propose the IPC for\ntime-variant systems. To show the significance of our approach, we demonstrate\nthat our measure can reveal information representations in not only machine\nlearning networks but also a real, cultured neural network. Our generalized\nmeasure paves the way for unveiling the information processing capabilities of\na wide variety of physical dynamics which has been left behind in nature.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:59:33 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 05:22:47 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 07:33:44 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 04:13:43 GMT"}, {"version": "v5", "created": "Fri, 28 May 2021 00:57:31 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Kubota", "Tomoyuki", ""], ["Takahashi", "Hirokazu", ""], ["Nakajima", "Kohei", ""]]}, {"id": "1906.04610", "submitter": "Mehrdad Khani", "authors": "Mehrdad Khani, Mohammad Alizadeh, Jakob Hoydis, Phil Fleming", "title": "Adaptive Neural Signal Detection for Massive MIMO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbol detection for Massive Multiple-Input Multiple-Output (MIMO) is a\nchallenging problem for which traditional algorithms are either impractical or\nsuffer from performance limitations. Several recently proposed learning-based\napproaches achieve promising results on simple channel models (e.g., i.i.d.\nGaussian). However, their performance degrades significantly on real-world\nchannels with spatial correlation. We propose MMNet, a deep learning MIMO\ndetection scheme that significantly outperforms existing approaches on\nrealistic channels with the same or lower computational complexity. MMNet's\ndesign builds on the theory of iterative soft-thresholding algorithms and uses\na novel training algorithm that leverages temporal and spectral correlation to\naccelerate training. Together, these innovations allow MMNet to train online\nfor every realization of the channel. On i.i.d. Gaussian channels, MMNet\nrequires two orders of magnitude fewer operations than existing deep learning\nschemes but achieves near-optimal performance. On spatially-correlated\nchannels, it achieves the same error rate as the next-best learning scheme\n(OAMPNet) at 2.5dB lower SNR and with at least 10x less computational\ncomplexity. MMNet is also 4--8dB better overall than a classic linear scheme\nlike the minimum mean square error (MMSE) detector.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:07:37 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Khani", "Mehrdad", ""], ["Alizadeh", "Mohammad", ""], ["Hoydis", "Jakob", ""], ["Fleming", "Phil", ""]]}, {"id": "1906.04659", "submitter": "Amartya Sanyal", "authors": "Amartya Sanyal, Philip H.S. Torr, Puneet K. Dokania", "title": "Stable Rank Normalization for Improved Generalization in Neural Networks\n  and GANs", "comments": "Accepted at the International Conference in Learning Representations,\n  2020, Addis Ababa, Ethiopia", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exciting new work on the generalization bounds for neural networks (NN) given\nby Neyshabur et al. , Bartlett et al. closely depend on two\nparameter-depenedent quantities: the Lipschitz constant upper-bound and the\nstable rank (a softer version of the rank operator). This leads to an\ninteresting question of whether controlling these quantities might improve the\ngeneralization behaviour of NNs. To this end, we propose stable rank\nnormalization (SRN), a novel, optimal, and computationally efficient\nweight-normalization scheme which minimizes the stable rank of a linear\noperator. Surprisingly we find that SRN, inspite of being non-convex problem,\ncan be shown to have a unique optimal solution. Moreover, we show that SRN\nallows control of the data-dependent empirical Lipschitz constant, which in\ncontrast to the Lipschitz upper-bound, reflects the true behaviour of a model\non a given dataset. We provide thorough analyses to show that SRN, when applied\nto the linear layers of a NN for classification, provides striking\nimprovements-11.3% on the generalization gap compared to the standard NN along\nwith significant reduction in memorization. When applied to the discriminator\nof GANs (called SRN-GAN) it improves Inception, FID, and Neural divergence\nscores on the CIFAR 10/100 and CelebA datasets, while learning mappings with\nlow empirical Lipschitz constants.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:37:49 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 00:38:09 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 11:24:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Sanyal", "Amartya", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "1906.04661", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge, David Woodruff", "title": "Faster Algorithms for High-Dimensional Robust Covariance Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the covariance matrix of a\nhigh-dimensional distribution when a small constant fraction of the samples can\nbe arbitrarily corrupted. Recent work gave the first polynomial time algorithms\nfor this problem with near-optimal error guarantees for several natural\nstructured distributions. Our main contribution is to develop faster algorithms\nfor this problem whose running time nearly matches that of computing the\nempirical covariance.\n  Given $N = \\tilde{\\Omega}(d^2/\\epsilon^2)$ samples from a $d$-dimensional\nGaussian distribution, an $\\epsilon$-fraction of which may be arbitrarily\ncorrupted, our algorithm runs in time\n$\\tilde{O}(d^{3.26})/\\mathrm{poly}(\\epsilon)$ and approximates the unknown\ncovariance matrix to optimal error up to a logarithmic factor. Previous robust\nalgorithms with comparable error guarantees all have runtimes\n$\\tilde{\\Omega}(d^{2 \\omega})$ when $\\epsilon = \\Omega(1)$, where $\\omega$ is\nthe exponent of matrix multiplication. We also provide evidence that improving\nthe running time of our algorithm may require new algorithmic techniques.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:41:44 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Ge", "Rong", ""], ["Woodruff", "David", ""]]}, {"id": "1906.04664", "submitter": "Conner Chyung", "authors": "Conner Chyung, Michael Tsang, Yan Liu", "title": "Extracting Interpretable Concept-Based Decision Trees from CNNs", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to gather a deeper understanding of how convolutional neural\nnetworks (CNNs) reason about human-understandable concepts, we present a method\nto infer labeled concept data from hidden layer activations and interpret the\nconcepts through a shallow decision tree. The decision tree can provide\ninformation about which concepts a model deems important, as well as provide an\nunderstanding of how the concepts interact with each other. Experiments\ndemonstrate that the extracted decision tree is capable of accurately\nrepresenting the original CNN's classifications at low tree depths, thus\nencouraging human-in-the-loop understanding of discriminative concepts.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:46:23 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 17:46:50 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Chyung", "Conner", ""], ["Tsang", "Michael", ""], ["Liu", "Yan", ""]]}, {"id": "1906.04673", "submitter": "Stefan Oehmcke", "authors": "Stefan Oehmcke and Fabian Gieseke", "title": "Learning Selection Masks for Deep Neural Networks", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data have often to be moved between servers and clients during the inference\nphase. For instance, modern virtual assistants collect data on mobile devices\nand the data are sent to remote servers for the analysis. A related scenario is\nthat clients have to access and download large amounts of data stored on\nservers in order to apply machine learning models. Depending on the available\nbandwidth, this data transfer can be a serious bottleneck, which can\nsignificantly limit the application machine learning models. In this work, we\npropose a simple yet effective framework that allows to select certain parts of\nthe input data needed for the subsequent application of a given neural network.\nBoth the masks as well as the neural network are trained simultaneously such\nthat a good model performance is achieved while, at the same time, only a\nminimal amount of data is selected by the masks. During the inference phase,\nonly the parts selected by the masks have to be transferred between the server\nand the client. Our experimental evaluation indicates that it is, for certain\nlearning tasks, possible to significantly reduce the amount of data needed to\nbe transferred without affecting the model performance much.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:05:09 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Oehmcke", "Stefan", ""], ["Gieseke", "Fabian", ""]]}, {"id": "1906.04675", "submitter": "Kaveena Persand", "authors": "Kaveena Persand, Andrew Anderson, David Gregg", "title": "Taxonomy of Saliency Metrics for Channel Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning unimportant parameters can allow deep neural networks (DNNs) to\nreduce their heavy computation and memory requirements. A saliency metric\nestimates which parameters can be safely pruned with little impact on the\nclassification performance of the DNN. Many saliency metrics have been\nproposed, each within the context of a wider pruning algorithm. The result is\nthat it is difficult to separate the effectiveness of the saliency metric from\nthe wider pruning algorithm that surrounds it. Similar-looking saliency metrics\ncan yield very different results because of apparently minor design choices. We\npropose a taxonomy of saliency metrics based on four mostly-orthogonal\nprincipal components. We show that a broad range of metrics from the pruning\nliterature can be grouped according to these components. Our taxonomy not only\nserves as a guide to prior work, but allows us to construct new saliency\nmetrics by exploring novel combinations of our taxonomic components. We perform\nan in-depth experimental investigation of more than 300 saliency metrics. Our\nresults provide decisive answers to open research questions, and demonstrate\nthe importance of reduction and scaling when pruning groups of weights. We find\nthat some of our constructed metrics can outperform the best existing\nstate-of-the-art metrics for convolutional neural network channel pruning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:14:26 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 17:30:18 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Persand", "Kaveena", ""], ["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}, {"id": "1906.04680", "submitter": "Stanislav Fedorov", "authors": "Antonio Candelieri, Stanislav Fedorov, Enza Messina", "title": "Efficient Kernel-based Subsequence Search for User Identification from\n  Walking Activity", "comments": "Keywords: Subsequence Search on Streaming Data, Dynamic Time Warping,\n  Kernel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient approach for subsequence search in data\nstreams. The problem consists in identifying coherent repetitions of a given\nreference time-series, eventually multi-variate, within a longer data stream.\nDynamic Time Warping (DTW) is the metric most widely used to implement pattern\nquery, but its computational complexity is a well-known issue. In this paper we\npresent an approach aimed at learning a kernel able to approximate DTW to be\nused for efficiently analyse streaming data collected from wearable sensors,\nreducing the burden of computation. Contrary to kernel, DTW allows for\ncomparing time series with different length. Thus, to use a kernel, a feature\nembedding is used to represent a time-series as a fixed length vector. Each\nvector component is the DTW between the given time-series and a set of 'basis'\nseries, usually randomly chosen. The vector size is the number of basis series\nused for the feature embedding. Searching for the portion of the data stream\nminimizing the DTW with the reference subsequence leads to a global\noptimization problem. The proposed approach has been validated on a benchmark\ndataset related to the identification of users depending on their walking\nactivity. A comparison with a traditional DTW implementation is also provided.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:24:45 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 14:29:34 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Candelieri", "Antonio", ""], ["Fedorov", "Stanislav", ""], ["Messina", "Enza", ""]]}, {"id": "1906.04681", "submitter": "Nicolo' Savioli", "authors": "Nicol\\'o Savioli", "title": "A Hybrid Approach Between Adversarial Generative Networks and\n  Actor-Critic Policy Gradient for Low Rate High-Resolution Image Compression", "comments": "4 pages, 2 figures, IEEE Conference on Computer Vision and Pattern\n  Recognition, Workshop and Challenge on Learned Image Compression (CLIC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image compression is an essential approach for decreasing the size in bytes\nof the image without deteriorating the quality of it. Typically, classic\nalgorithms are used but recently deep-learning has been successfully applied.\nIn this work, is presented a deep super-resolution work-flow for image\ncompression that maps low-resolution JPEG image to the high-resolution. The\npipeline consists of two components: first, an encoder-decoder neural network\nlearns how to transform the downsampling JPEG images to high resolution.\nSecond, a combination between Generative Adversarial Networks (GANs) and\nreinforcement learning Actor-Critic (A3C) loss pushes the encoder-decoder to\nindirectly maximize High Peak Signal-to-Noise Ratio (PSNR). Although PSNR is a\nfully differentiable metric, this work opens the doors to new solutions for\nmaximizing non-differential metrics through an end-to-end approach between\nencoder-decoder networks and reinforcement learning policy gradient methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:27:51 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 23:07:58 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Savioli", "Nicol\u00f3", ""]]}, {"id": "1906.04688", "submitter": "Quanquan Gu", "authors": "Difan Zou and Quanquan Gu", "title": "An Improved Analysis of Training Over-parameterized Deep Neural Networks", "comments": "30 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of research has shown that gradient-based algorithms with\nrandom initialization can converge to the global minima of the training loss\nfor over-parameterized (i.e., sufficiently wide) deep neural networks. However,\nthe condition on the width of the neural network to ensure the global\nconvergence is very stringent, which is often a high-degree polynomial in the\ntraining sample size $n$ (e.g., $O(n^{24})$). In this paper, we provide an\nimproved analysis of the global convergence of (stochastic) gradient descent\nfor training deep neural networks, which only requires a milder\nover-parameterization condition than previous work in terms of the training\nsample size and other problem-dependent parameters. The main technical\ncontributions of our analysis include (a) a tighter gradient lower bound that\nleads to a faster convergence of the algorithm, and (b) a sharper\ncharacterization of the trajectory length of the algorithm. By specializing our\nresult to two-layer (i.e., one-hidden-layer) neural networks, it also provides\na milder over-parameterization condition than the best-known result in prior\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:40:46 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Zou", "Difan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1906.04691", "submitter": "Taewan Kim", "authors": "Taewan Kim, Joydeep Ghosh", "title": "On Single Source Robustness in Deep Fusion Models", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that fuse multiple input sources benefit from both complementary\nand shared information. Shared information may provide robustness against\nfaulty or noisy inputs, which is indispensable for safety-critical applications\nlike self-driving cars. We investigate learning fusion algorithms that are\nrobust against noise added to a single source. We first demonstrate that\nrobustness against single source noise is not guaranteed in a linear fusion\nmodel. Motivated by this discovery, two possible approaches are proposed to\nincrease robustness: a carefully designed loss with corresponding training\nalgorithms for deep fusion models, and a simple convolutional fusion layer that\nhas a structural advantage in dealing with noise. Experimental results show\nthat both training algorithms and our fusion layer make a deep fusion-based 3D\nobject detector robust against noise applied to a single source, while\npreserving the original performance on clean data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:47:56 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 05:32:13 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kim", "Taewan", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1906.04697", "submitter": "Martin Wainwright", "authors": "Martin J. Wainwright", "title": "Variance-reduced $Q$-learning is minimax optimal", "comments": "Update from v1: new Proposition 1 on minimax optimality; updated\n  referencing and discussion of related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze a form of variance-reduced $Q$-learning. For\n$\\gamma$-discounted MDPs with finite state space $\\mathcal{X}$ and action space\n$\\mathcal{U}$, we prove that it yields an $\\epsilon$-accurate estimate of the\noptimal $Q$-function in the $\\ell_\\infty$-norm using $\\mathcal{O}\n\\left(\\left(\\frac{D}{ \\epsilon^2 (1-\\gamma)^3} \\right) \\; \\log \\left(\n\\frac{D}{(1-\\gamma)} \\right) \\right)$ samples, where $D = |\\mathcal{X}| \\times\n|\\mathcal{U}|$. This guarantee matches known minimax lower bounds up to a\nlogarithmic factor in the discount complexity. In contrast, our past work shows\nthat ordinary $Q$-learning has worst-case quartic scaling in the discount\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:58:54 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 17:33:58 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Wainwright", "Martin J.", ""]]}, {"id": "1906.04705", "submitter": "Alaa Maalouf", "authors": "Alaa Maalouf and Ibrahim Jubran and Dan Feldman", "title": "Fast and Accurate Least-Mean-Squares Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least-mean squares (LMS) solvers such as Linear / Ridge / Lasso-Regression,\nSVD and Elastic-Net not only solve fundamental machine learning problems, but\nare also the building blocks in a variety of other methods, such as decision\ntrees and matrix factorizations.\n  We suggest an algorithm that gets a finite set of $n$ $d$-dimensional real\nvectors and returns a weighted subset of $d+1$ vectors whose sum is\n\\emph{exactly} the same. The proof in Caratheodory's Theorem (1907) computes\nsuch a subset in $O(n^2d^2)$ time and thus not used in practice. Our algorithm\ncomputes this subset in $O(nd+d^4\\log{n})$ time, using $O(\\log n)$ calls to\nCaratheodory's construction on small but \"smart\" subsets. This is based on a\nnovel paradigm of fusion between different data summarization techniques, known\nas sketches and coresets.\n  For large values of $d$, we suggest a faster construction that takes $O(nd)$\ntime (linear in the input's size) and returns a weighted subset of $O(d)$\nsparsified input points. Here, sparsified point means that some of its entries\nwere replaced by zeroes.\n  As an example application, we show how it can be used to boost the\nperformance of existing LMS solvers, such as those in scikit-learn library, up\nto x100. Generalization for streaming and distributed (big) data is trivial.\nExtensive experimental results and complete open source code are also provided.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:12:02 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 14:50:39 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Maalouf", "Alaa", ""], ["Jubran", "Ibrahim", ""], ["Feldman", "Dan", ""]]}, {"id": "1906.04709", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Daniel M. Kane and\n  Sankeerth Rao", "title": "Communication and Memory Efficient Testing of Discrete Distributions", "comments": "Full version of COLT 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distribution testing with communication and memory constraints in\nthe following computational models: (1) The {\\em one-pass streaming model}\nwhere the goal is to minimize the sample complexity of the protocol subject to\na memory constraint, and (2) A {\\em distributed model} where the data samples\nreside at multiple machines and the goal is to minimize the communication cost\nof the protocol. In both these models, we provide efficient algorithms for\nuniformity/identity testing (goodness of fit) and closeness testing (two sample\ntesting). Moreover, we show nearly-tight lower bounds on (1) the sample\ncomplexity of any one-pass streaming tester for uniformity, subject to the\nmemory constraint, and (2) the communication cost of any uniformity testing\nprotocol, in a restricted `one-pass' model of communication.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:26:21 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Kane", "Daniel M.", ""], ["Rao", "Sankeerth", ""]]}, {"id": "1906.04716", "submitter": "Edward Choi", "authors": "Edward Choi, Zhen Xu, Yujia Li, Michael W. Dusenberry, Gerardo Flores,\n  Yuan Xue, Andrew M. Dai", "title": "Learning the Graphical Structure of Electronic Health Records with Graph\n  Convolutional Transformer", "comments": "To be presented at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective modeling of electronic health records (EHR) is rapidly becoming an\nimportant topic in both academia and industry. A recent study showed that using\nthe graphical structure underlying EHR data (e.g. relationship between\ndiagnoses and treatments) improves the performance of prediction tasks such as\nheart failure prediction. However, EHR data do not always contain complete\nstructure information. Moreover, when it comes to claims data, structure\ninformation is completely unavailable to begin with. Under such circumstances,\ncan we still do better than just treating EHR data as a flat-structured\nbag-of-features? In this paper, we study the possibility of jointly learning\nthe hidden structure of EHR while performing supervised prediction tasks on EHR\ndata. Specifically, we discuss that Transformer is a suitable basis model to\nlearn the hidden EHR structure, and propose Graph Convolutional Transformer,\nwhich uses data statistics to guide the structure learning process. The\nproposed model consistently outperformed previous approaches empirically, on\nboth synthetic data and publicly available EHR data, for various prediction\ntasks such as graph reconstruction and readmission prediction, indicating that\nit can serve as an effective general-purpose representation learning algorithm\nfor EHR data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:40:49 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 05:17:51 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 01:28:00 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Choi", "Edward", ""], ["Xu", "Zhen", ""], ["Li", "Yujia", ""], ["Dusenberry", "Michael W.", ""], ["Flores", "Gerardo", ""], ["Xue", "Yuan", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1906.04721", "submitter": "Markus Nagel", "authors": "Markus Nagel, Mart van Baalen, Tijmen Blankevoort, Max Welling", "title": "Data-Free Quantization Through Weight Equalization and Bias Correction", "comments": "ICCV 2019", "journal-ref": "The IEEE International Conference on Computer Vision (ICCV), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a data-free quantization method for deep neural networks that\ndoes not require fine-tuning or hyperparameter selection. It achieves\nnear-original model performance on common computer vision architectures and\ntasks. 8-bit fixed-point quantization is essential for efficient inference on\nmodern deep learning hardware. However, quantizing models to run in 8-bit is a\nnon-trivial task, frequently leading to either significant performance\nreduction or engineering time spent on training a network to be amenable to\nquantization. Our approach relies on equalizing the weight ranges in the\nnetwork by making use of a scale-equivariance property of activation functions.\nIn addition the method corrects biases in the error that are introduced during\nquantization. This improves quantization accuracy performance, and can be\napplied to many common computer vision architectures with a straight forward\nAPI call. For common architectures, such as the MobileNet family, we achieve\nstate-of-the-art quantized model performance. We further show that the method\nalso extends to other computer vision architectures and tasks such as semantic\nsegmentation and object detection.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:47:51 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:56:06 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 15:00:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Nagel", "Markus", ""], ["van Baalen", "Mart", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "1906.04724", "submitter": "Stanislav Fort", "authors": "Stanislav Fort, Stanislaw Jastrzebski", "title": "Large Scale Structure of Neural Network Loss Landscapes", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many surprising and perhaps counter-intuitive properties of\noptimization of deep neural networks. We propose and experimentally verify a\nunified phenomenological model of the loss landscape that incorporates many of\nthem. High dimensionality plays a key role in our model. Our core idea is to\nmodel the loss landscape as a set of high dimensional \\emph{wedges} that\ntogether form a large-scale, inter-connected structure and towards which\noptimization is drawn. We first show that hyperparameter choices such as\nlearning rate, network width and $L_2$ regularization, affect the path\noptimizer takes through the landscape in a similar ways, influencing the large\nscale curvature of the regions the optimizer explores. Finally, we predict and\ndemonstrate new counter-intuitive properties of the loss-landscape. We show an\nexistence of low loss subspaces connecting a set (not only a pair) of\nsolutions, and verify it experimentally. Finally, we analyze recently popular\nensembling techniques for deep networks in the light of our model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:54:47 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Fort", "Stanislav", ""], ["Jastrzebski", "Stanislaw", ""]]}, {"id": "1906.04733", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Yinlam Chow, Bo Dai, Lihong Li", "title": "DualDICE: Behavior-Agnostic Estimation of Discounted Stationary\n  Distribution Corrections", "comments": "Appearing in NeurIPS 2019 Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world reinforcement learning applications, access to the\nenvironment is limited to a fixed dataset, instead of direct (online)\ninteraction with the environment. When using this data for either evaluation or\ntraining of a new policy, accurate estimates of discounted stationary\ndistribution ratios -- correction terms which quantify the likelihood that the\nnew policy will experience a certain state-action pair normalized by the\nprobability with which the state-action pair appears in the dataset -- can\nimprove accuracy and performance. In this work, we propose an algorithm,\nDualDICE, for estimating these quantities. In contrast to previous approaches,\nour algorithm is agnostic to knowledge of the behavior policy (or policies)\nused to generate the dataset. Furthermore, it eschews any direct use of\nimportance weights, thus avoiding potential optimization instabilities endemic\nof previous methods. In addition to providing theoretical guarantees, we\npresent an empirical study of our algorithm applied to off-policy policy\nevaluation and find that our algorithm significantly improves accuracy compared\nto existing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:33:00 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 22:01:49 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Nachum", "Ofir", ""], ["Chow", "Yinlam", ""], ["Dai", "Bo", ""], ["Li", "Lihong", ""]]}, {"id": "1906.04734", "submitter": "Zikuang He", "authors": "Qiuyu Zhu and Zikuang He and Xin Ye", "title": "Incremental Classifier Learning Based on PEDCC-Loss and Cosine Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of incremental learning is to learn new knowledge while not\nforgetting the knowledge which have been learned before. At present, the main\nchallenge in this area is the catastrophe forgetting, namely the network will\nlose their performance in the old tasks after training for new tasks. In this\npaper, we introduce an ensemble method of incremental classifier to alleviate\nthis problem, which is based on the cosine distance between the output feature\nand the pre-defined center, and can let each task to be preserved in different\nnetworks. During training, we make use of PEDCC-Loss to train the CNN network.\nIn the stage of testing, the prediction is determined by the cosine distance\nbetween the network latent features and pre-defined center. The experimental\nresults on EMINST and CIFAR100 show that our method outperforms the recent LwF\nmethod, which use the knowledge distillation, and iCaRL method, which keep some\nold samples while training for new task. The method can achieve the goal of not\nforgetting old knowledge while training new classes, and solve the problem of\ncatastrophic forgetting better.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 04:23:14 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Zhu", "Qiuyu", ""], ["He", "Zikuang", ""], ["Ye", "Xin", ""]]}, {"id": "1906.04735", "submitter": "Florent Krzakala", "authors": "Alia Abbara, Antoine Baker, Florent Krzakala and Lenka Zdeborov\\'a", "title": "On the Universality of Noiseless Linear Estimation with Respect to the\n  Measurement Matrix", "comments": "13 pages, 4 figures", "journal-ref": "Journal of Physics A: Mathematical and Theoretical (2019)", "doi": "10.1088/1751-8121/ab59ef", "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a noiseless linear estimation problem, one aims to reconstruct a vector x*\nfrom the knowledge of its linear projections y=Phi x*. There have been many\ntheoretical works concentrating on the case where the matrix Phi is a random\ni.i.d. one, but a number of heuristic evidence suggests that many of these\nresults are universal and extend well beyond this restricted case. Here we\nrevisit this problematic through the prism of development of message passing\nmethods, and consider not only the universality of the l1 transition, as\npreviously addressed, but also the one of the optimal Bayesian reconstruction.\nWe observed that the universality extends to the Bayes-optimal minimum\nmean-squared (MMSE) error, and to a range of structured matrices.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:10:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Abbara", "Alia", ""], ["Baker", "Antoine", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1906.04736", "submitter": "Michele Alberti", "authors": "Michele Alberti, Vinaychandran Pondenkandath, Lars V\\\"ogtlin, Marcel\n  W\\\"ursch, Rolf Ingold, and Marcus Liwicki", "title": "Improving Reproducible Deep Learning Workflows with DeepDIVA", "comments": null, "journal-ref": "6th Swiss Conference on Data Science (SDS), Bern, Switzerland,\n  2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep learning is experiencing a trend towards producing\nreproducible research. Nevertheless, it is still often a frustrating experience\nto reproduce scientific results. This is especially true in the machine\nlearning community, where it is considered acceptable to have black boxes in\nyour experiments. We present DeepDIVA, a framework designed to facilitate easy\nexperimentation and their reproduction. This framework allows researchers to\nshare their experiments with others, while providing functionality that allows\nfor easy experimentation, such as: boilerplate code, experiment management,\nhyper-parameter optimization, verification of data integrity and visualization\nof data and results. Additionally, the code of DeepDIVA is well-documented and\nsupported by several tutorials that allow a new user to quickly familiarize\nthemselves with the framework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:38:34 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Alberti", "Michele", ""], ["Pondenkandath", "Vinaychandran", ""], ["V\u00f6gtlin", "Lars", ""], ["W\u00fcrsch", "Marcel", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1906.04737", "submitter": "Georgios Papoudakis", "authors": "Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, Stefano V.\n  Albrecht", "title": "Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in deep reinforcement learning are concerned with\ncreating decision-making agents which can perform well in various complex\ndomains. A particular approach which has received increasing attention is\nmulti-agent reinforcement learning, in which multiple agents learn concurrently\nto coordinate their actions. In such multi-agent environments, additional\nlearning problems arise due to the continually changing decision-making\npolicies of agents. This paper surveys recent works that address the\nnon-stationarity problem in multi-agent deep reinforcement learning. The\nsurveyed methods range from modifications in the training procedure, such as\ncentralized training, to learning representations of the opponent's policy,\nmeta-learning, communication, and decentralized learning. The survey concludes\nwith a list of open problems and possible lines of future research.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:42:00 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Christianos", "Filippos", ""], ["Rahman", "Arrasy", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "1906.04739", "submitter": "Adriana-Simona Mihaita Dr.", "authors": "Sajjad Shafiei, Adriana-Simona Mihaita, Chen Cai", "title": "Trip Table Estimation and Prediction for Dynamic Traffic Assignment\n  Applications", "comments": "6 pages, 6 figures, preprint at the 26th ITS World Congress 21-25 Oct\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study focuses on estimating and predicting time-varying origin to\ndestination (OD) trip tables for a dynamic traffic assignment (DTA) model. A\nbi-level optimisation problem is formulated and solved to estimate OD flows\nfrom pre-existent demand matrix and historical traffic flow counts. The\nestimated demand is then considered as an input for a time series OD demand\nprediction model to support the DTA model for short-term traffic condition\nforecasting. Results show a high capability of the proposed OD demand\nestimation method to reduce the DTA model error through an iterative solution\nalgorithm. Moreover, the applicability of the OD demand prediction approach is\ninvestigated for an incident analysis application for a major corridor in\nSydney, Australia.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:42:12 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Shafiei", "Sajjad", ""], ["Mihaita", "Adriana-Simona", ""], ["Cai", "Chen", ""]]}, {"id": "1906.04762", "submitter": "Ziyi Wang", "authors": "Marcus A Pereira, Ziyi Wang, Tianrong Chen, Emily Reed and Evangelos A\n  Theodorou", "title": "Deep 2FBSDEs For Systems With Control Multiplicative Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep recurrent neural network architecture to solve a class of\nstochastic optimal control problems described by fully nonlinear Hamilton\nJacobi Bellmanpartial differential equations. Such PDEs arise when one\nconsiders stochastic dynamics characterized by uncertainties that are additive\nand control multiplicative. Stochastic models with the aforementioned\ncharacteristics have been used in computational neuroscience, biology, finance\nand aerospace systems and provide a more accurate representation of actuation\nthan models with additive uncertainty. Previous literature has established the\ninadequacy of the linear HJB theory and instead rely on a non-linear\nFeynman-Kac lemma resulting in a second order forward-backward stochastic\ndifferential equations representation. However, the proposed solutions that use\nthis representation suffer from compounding errors and computational complexity\nleading to lack of scalability. In this paper, we propose a deep learning based\nalgorithm that leverages the second order Forward-Backward SDE representation\nand LSTM based recurrent neural networks to not only solve such Stochastic\nOptimal Control problems but also overcome the problems faced by previous\napproaches and scales well to high dimensional systems. The resulting control\nalgorithm is tested on non-linear systems in robotics and biomechanics to\ndemonstrate feasibility and out-performance against previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 18:21:23 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 00:10:37 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 23:08:09 GMT"}, {"version": "v4", "created": "Sat, 21 Dec 2019 04:20:09 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Pereira", "Marcus A", ""], ["Wang", "Ziyi", ""], ["Chen", "Tianrong", ""], ["Reed", "Emily", ""], ["Theodorou", "Evangelos A", ""]]}, {"id": "1906.04771", "submitter": "Ziyi Wang", "authors": "Ziyi Wang, Keuntaek Lee, Marcus A. Pereira, Ioannis Exarchos and\n  Evangelos A. Theodorou", "title": "Deep Forward-Backward SDEs for Min-max Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to numerically solve stochastic\ndifferential games for nonlinear systems. The proposed approach relies on the\nnonlinear Feynman-Kac theorem that establishes a connection between parabolic\ndeterministic partial differential equations and forward-backward stochastic\ndifferential equations. Using this theorem the Hamilton-Jacobi-Isaacs partial\ndifferential equation associated with differential games is represented by a\nsystem of forward-backward stochastic differential equations. Numerical\nsolution of the aforementioned system of stochastic differential equations is\nperformed using importance sampling and a Long-Short Term Memory recurrent\nneural network, which is trained in an offline fashion. The resulting algorithm\nis tested on two example systems in simulation and compared against the\nstandard risk neutral stochastic optimal control formulations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 18:58:06 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wang", "Ziyi", ""], ["Lee", "Keuntaek", ""], ["Pereira", "Marcus A.", ""], ["Exarchos", "Ioannis", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1906.04774", "submitter": "Thibault Laugel", "authors": "Thibault Laugel and Marie-Jeanne Lesot and Christophe Marsala and\n  Marcin Detyniecki", "title": "Issues with post-hoc counterfactual explanations: a discussion", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual post-hoc interpretability approaches have been proven to be\nuseful tools to generate explanations for the predictions of a trained blackbox\nclassifier. However, the assumptions they make about the data and the\nclassifier make them unreliable in many contexts. In this paper, we discuss\nthree desirable properties and approaches to quantify them: proximity,\nconnectedness and stability. In addition, we illustrate that there is a risk\nfor post-hoc counterfactual approaches to not satisfy these properties.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 19:04:54 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1906.04784", "submitter": "Fernando Gama", "authors": "Fernando Gama, Joan Bruna, Alejandro Ribeiro", "title": "Stability of Graph Scattering Transforms", "comments": "Submitted to Conference on Neural Information Processing Systems\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scattering transforms are non-trainable deep convolutional architectures that\nexploit the multi-scale resolution of a wavelet filter bank to obtain an\nappropriate representation of data. More importantly, they are proven invariant\nto translations, and stable to perturbations that are close to translations.\nThis stability property dons the scattering transform with a robustness to\nsmall changes in the metric domain of the data. When considering network data,\nregular convolutions do not hold since the data domain presents an irregular\nstructure given by the network topology.\n  In this work, we extend scattering transforms to network data by using\nmultiresolution graph wavelets, whose computation can be obtained by means of\ngraph convolutions. Furthermore, we prove that the resulting graph scattering\ntransforms are stable to metric perturbations of the underlying network. This\nrenders graph scattering transforms robust to changes on the network topology,\nmaking it particularly useful for cases of transfer learning, topology\nestimation or time-varying graphs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 19:42:36 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Gama", "Fernando", ""], ["Bruna", "Joan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1906.04787", "submitter": "Marco Baiesi", "authors": "Marco Baiesi", "title": "Power Gradient Descent", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of machine learning is promoting the search for fast and\nstable minimization algorithms. To this end, we suggest a change in the current\ngradient descent methods that should speed up the motion in flat regions and\nslow it down in steep directions of the function to minimize. It is based on a\n\"power gradient\", in which each component of the gradient is replaced by its\nversus-preserving $H$-th power, with $0<H<1$. We test three modern gradient\ndescent methods fed by such variant and by standard gradients, finding the new\nversion to achieve significantly better performances for the Nesterov\naccelerated gradient and AMSGrad. We also propose an effective new take on the\nADAM algorithm, which includes power gradients with varying $H$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 19:48:01 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Baiesi", "Marco", ""]]}, {"id": "1906.04798", "submitter": "Michele Covell", "authors": "Michele Covell, David Marwood, Shumeet Baluja, Nick Johnston", "title": "Table-Based Neural Units: Fully Quantizing Networks for Multiply-Free\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to quantize all parts of standard classification\nnetworks and replace the activation-weight--multiply step with a simple\ntable-based lookup. This approach results in networks that are free of\nfloating-point operations and free of multiplications, suitable for direct FPGA\nand ASIC implementations. It also provides us with two simple measures of\nper-layer and network-wide compactness as well as insight into the distribution\ncharacteristics of activationoutput and weight values. We run controlled\nstudies across different quantization schemes, both fixed and adaptive and,\nwithin the set of adaptive approaches, both parametric and model-free. We\nimplement our approach to quantization with minimal, localized changes to the\ntraining process, allowing us to benefit from advances in training\ncontinuous-valued network architectures. We apply our approach successfully to\nAlexNet, ResNet, and MobileNet. We show results that are within 1.6% of the\nreported, non-quantized performance on MobileNet using only 40 entries in our\ntable. This performance gap narrows to zero when we allow tables with 320\nentries. Our results give the best accuracies among multiply-free networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 20:19:11 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Covell", "Michele", ""], ["Marwood", "David", ""], ["Baluja", "Shumeet", ""], ["Johnston", "Nick", ""]]}, {"id": "1906.04813", "submitter": "Jacobo Roa-Vicens", "authors": "Jacobo Roa-Vicens, Cyrine Chtourou, Angelos Filos, Francisco Rullan,\n  Yarin Gal, Ricardo Silva", "title": "Towards Inverse Reinforcement Learning for Limit Order Book Dynamics", "comments": "Published as a workshop paper on AI in Finance: Applications and\n  Infrastructure for Multi-Agent Learning at the 36th International Conference\n  on Machine Learning (ICML), Long Beach, California, PMLR97, 2019. Copyright\n  2019 by the author(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent learning is a promising method to simulate aggregate competitive\nbehaviour in finance. Learning expert agents' reward functions through their\nexternal demonstrations is hence particularly relevant for subsequent design of\nrealistic agent-based simulations. Inverse Reinforcement Learning (IRL) aims at\nacquiring such reward functions through inference, allowing to generalize the\nresulting policy to states not observed in the past. This paper investigates\nwhether IRL can infer such rewards from agents within real financial stochastic\nenvironments: limit order books (LOB). We introduce a simple one-level LOB,\nwhere the interactions of a number of stochastic agents and an expert trading\nagent are modelled as a Markov decision process. We consider two cases for the\nexpert's reward: either a simple linear function of state features; or a\ncomplex, more realistic non-linear function. Given the expert agent's\ndemonstrations, we attempt to discover their strategy by modelling their latent\nreward function using linear and Gaussian process (GP) regressors from previous\nliterature, and our own approach through Bayesian neural networks (BNN). While\nthe three methods can learn the linear case, only the GP-based and our proposed\nBNN methods are able to discover the non-linear reward case. Our BNN IRL\nalgorithm outperforms the other two approaches as the number of samples\nincreases. These results illustrate that complex behaviours, induced by\nnon-linear reward functions amid agent-based stochastic scenarios, can be\ndeduced through inference, encouraging the use of inverse reinforcement\nlearning for opponent-modelling in multi-agent systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 20:47:24 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Roa-Vicens", "Jacobo", ""], ["Chtourou", "Cyrine", ""], ["Filos", "Angelos", ""], ["Rullan", "Francisco", ""], ["Gal", "Yarin", ""], ["Silva", "Ricardo", ""]]}, {"id": "1906.04817", "submitter": "Jiaxuan You", "authors": "Jiaxuan You, Rex Ying, Jure Leskovec", "title": "Position-aware Graph Neural Networks", "comments": "ICML 2019, long oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning node embeddings that capture a node's position within the broader\ngraph structure is crucial for many prediction tasks on graphs. However,\nexisting Graph Neural Network (GNN) architectures have limited power in\ncapturing the position/location of a given node with respect to all other nodes\nof the graph. Here we propose Position-aware Graph Neural Networks (P-GNNs), a\nnew class of GNNs for computing position-aware node embeddings. P-GNN first\nsamples sets of anchor nodes, computes the distance of a given target node to\neach anchor-set,and then learns a non-linear distance-weighted aggregation\nscheme over the anchor-sets. This way P-GNNs can capture positions/locations of\nnodes with respect to the anchor nodes. P-GNNs have several advantages: they\nare inductive, scalable,and can incorporate node feature information. We apply\nP-GNNs to multiple prediction tasks including link prediction and community\ndetection. We show that P-GNNs consistently outperform state of the art GNNs,\nwith up to 66% improvement in terms of the ROC AUC score.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 20:52:37 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 18:00:29 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["You", "Jiaxuan", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""]]}, {"id": "1906.04818", "submitter": "Hossein Sangrody", "authors": "Arghavan Zare-Noghabi and Morteza Shabanzadeh and Hossein Sangrody", "title": "Medium-Term Load Forecasting Using Support Vector Regression, Feature\n  Selection, and Symbiotic Organism Search Optimization", "comments": "2019 IEEE PES General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate load forecasting has always been one of the main indispensable\nparts in the operation and planning of power systems. Among different time\nhorizons of forecasting, while short-term load forecasting (STLF) and long-term\nload forecasting (LTLF) have respectively got benefits of accurate predictors\nand probabilistic forecasting, medium-term load forecasting (MTLF) demands more\nattention due to its vital role in power system operation and planning such as\noptimal scheduling of generation units, robust planning program for customer\nservice, and economic supply. In this study, a hybrid method, composed of\nSupport Vector Regression (SVR) and Symbiotic Organism Search Optimization\n(SOSO) method, is proposed for MTLF. In the proposed forecasting model, SVR is\nthe main part of the forecasting algorithm while SOSO is embedded into it to\noptimize the parameters of SVR. In addition, a minimum redundancy-maximum\nrelevance feature selection algorithm is used to in the preprocessing of input\ndata. The proposed method is tested on EUNITE competition dataset to\ndemonstrate its proper performance. Furthermore, it is compared with some\nprevious works to show eligibility of our method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 20:58:25 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Zare-Noghabi", "Arghavan", ""], ["Shabanzadeh", "Morteza", ""], ["Sangrody", "Hossein", ""]]}, {"id": "1906.04819", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Hao Gao, Wu-Jun Li", "title": "ADASS: Adaptive Sample Selection for Training Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient decent~(SGD) and its variants, including some accelerated\nvariants, have become popular for training in machine learning. However, in all\nexisting SGD and its variants, the sample size in each iteration~(epoch) of\ntraining is the same as the size of the full training set. In this paper, we\npropose a new method, called \\underline{ada}ptive \\underline{s}ample\n\\underline{s}election~(ADASS), for training acceleration. During different\nepoches of training, ADASS only need to visit different training subsets which\nare adaptively selected from the full training set according to the Lipschitz\nconstants of the loss functions on samples. It means that in ADASS the sample\nsize in each epoch of training can be smaller than the size of the full\ntraining set, by discarding some samples. ADASS can be seamlessly integrated\nwith existing optimization methods, such as SGD and momentum SGD, for training\nacceleration. Theoretical results show that the learning accuracy of ADASS is\ncomparable to that of counterparts with full training set. Furthermore,\nempirical results on both shallow models and deep models also show that ADASS\ncan accelerate the training process of existing methods without sacrificing\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:00:10 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 17:19:56 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Gao", "Hao", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1906.04845", "submitter": "Edo Liberty", "authors": "Zohar Karnin and Edo Liberty", "title": "Discrepancy, Coresets, and Sketches in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines the notion of class discrepancy for families of functions.\nIt shows that low discrepancy classes admit small offline and streaming\ncoresets. We provide general techniques for bounding the class discrepancy of\nmachine learning problems. As corollaries of the general technique we bound the\ndiscrepancy (and therefore coreset complexity) of logistic regression, sigmoid\nactivation loss, matrix covariance, kernel density and any analytic function of\nthe dot product or the squared distance. Our results prove the existence of\nepsilon-approximation O(sqrt{d}/epsilon) sized coresets for the above problems.\nThis resolves the long-standing open problem regarding the coreset complexity\nof Gaussian kernel density estimation. We provide two more related but\nindependent results. First, an exponential improvement of the widely used\nmerge-and-reduce trick which gives improved streaming sketches for any low\ndiscrepancy problem. Second, an extremely simple deterministic algorithm for\nfinding low discrepancy sequences (and therefore coresets) for any positive\nsemi-definite kernel. This paper establishes some explicit connections between\nclass discrepancy, coreset complexity, learnability, and streaming algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 22:21:19 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Karnin", "Zohar", ""], ["Liberty", "Edo", ""]]}, {"id": "1906.04848", "submitter": "Hugo Berard", "authors": "Hugo Berard, Gauthier Gidel, Amjad Almahairi, Pascal Vincent, Simon\n  Lacoste-Julien", "title": "A Closer Look at the Optimization Landscapes of Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have been very successful in generative\nmodeling, however they remain relatively challenging to train compared to\nstandard deep neural networks. In this paper, we propose new visualization\ntechniques for the optimization landscapes of GANs that enable us to study the\ngame vector field resulting from the concatenation of the gradient of both\nplayers. Using these visualization techniques we try to bridge the gap between\ntheory and practice by showing empirically that the training of GANs exhibits\nsignificant rotations around Local Stable Stationary Points (LSSP), similar to\nthe one predicted by theory on toy examples. Moreover, we provide empirical\nevidence that GAN training converge to a stable stationary point which is a\nsaddle point for the generator loss, not a minimum, while still achieving\nexcellent performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 22:34:19 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 11:48:50 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 16:38:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Berard", "Hugo", ""], ["Gidel", "Gauthier", ""], ["Almahairi", "Amjad", ""], ["Vincent", "Pascal", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1906.04859", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Shipra Agrawal, Yuri Faenza", "title": "Reinforcement Learning for Integer Programming: Learning to Cut", "comments": "Accepted at International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integer programming (IP) is a general optimization framework widely\napplicable to a variety of unstructured and structured problems arising in,\ne.g., scheduling, production planning, and graph optimization. As IP models\nmany provably hard to solve problems, modern IP solvers rely on many\nheuristics. These heuristics are usually human-designed, and naturally prone to\nsuboptimality. The goal of this work is to show that the performance of those\nsolvers can be greatly enhanced using reinforcement learning (RL). In\nparticular, we investigate a specific methodology for solving IPs, known as the\nCutting Plane Method. This method is employed as a subroutine by all modern IP\nsolvers. We present a deep RL formulation, network architecture, and algorithms\nfor intelligent adaptive selection of cutting planes (aka cuts). Across a wide\nrange of IP tasks, we show that the trained RL agent significantly outperforms\nhuman-designed heuristics, and effectively generalizes to 10X larger instances\nand across IP problem classes. The trained agent is also demonstrated to\nbenefit the popular downstream application of cutting plane methods in\nBranch-and-Cut algorithm, which is the backbone of state-of-the-art commercial\nIP solvers.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 23:14:46 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 20:34:20 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 12:57:19 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Tang", "Yunhao", ""], ["Agrawal", "Shipra", ""], ["Faenza", "Yuri", ""]]}, {"id": "1906.04863", "submitter": "Kimon Fountoulakis", "authors": "Wooseok Ha and Kimon Fountoulakis and Michael W. Mahoney", "title": "Statistical guarantees for local graph clustering", "comments": "52 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local graph clustering methods aim to find small clusters in very large\ngraphs. These methods take as input a graph and a seed node, and they return as\noutput a good cluster in a running time that depends on the size of the output\ncluster but that is independent of the size of the input graph. In this paper,\nwe adopt a statistical perspective on local graph clustering, and we analyze\nthe performance of the l1-regularized PageRank method~(Fountoulakis et. al.)\nfor the recovery of a single target cluster, given a seed node inside the\ncluster. Assuming the target cluster has been generated by a random model, we\npresent two results. In the first, we show that the optimal support of\nl1-regularized PageRank recovers the full target cluster, with bounded false\npositives. In the second, we show that if the seed node is connected solely to\nthe target cluster then the optimal support of l1-regularized PageRank recovers\nexactly the target cluster. We also show empirically that l1-regularized\nPageRank has a state-of-the-art performance on many real graphs, demonstrating\nthe superiority of the method. From a computational perspective, we show that\nthe solution path of l1-regularized PageRank is monotonic. This allows for the\napplication of the forward stagewise algorithm, which approximates the solution\npath in running time that does not depend on the size of the whole graph.\nFinally, we show that l1-regularized PageRank and approximate personalized\nPageRank (APPR), another very popular method for local graph clustering, are\nequivalent in the sense that we can lower and upper bound the output of one\nwith the output of the other. Based on this relation, we establish for APPR\nsimilar results to those we establish for l1-regularized PageRank.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 23:40:32 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 04:29:17 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 02:51:57 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ha", "Wooseok", ""], ["Fountoulakis", "Kimon", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1906.04866", "submitter": "Peichang Guo", "authors": "Peichang Guo and Qiang Ye", "title": "On regularization for a convolutional kernel in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network is an important model in deep learning. To avoid\nexploding/vanishing gradient problems and to improve the generalizability of a\nneural network, it is desirable to have a convolution operation that nearly\npreserves the norm, or to have the singular values of the transformation matrix\ncorresponding to a convolutional kernel bounded around $1$. We propose a\npenalty function that can be used in the optimization of a convolutional neural\nnetwork to constrain the singular values of the transformation matrix around\n$1$. We derive an algorithm to carry out the gradient descent minimization of\nthis penalty function in terms of convolution kernels. Numerical examples are\npresented to demonstrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 00:07:32 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 19:46:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Guo", "Peichang", ""], ["Ye", "Qiang", ""]]}, {"id": "1906.04868", "submitter": "Kenji Fukumizu Dr.", "authors": "Kenji Fukumizu, Shoichiro Yamaguchi, Yoh-ichi Mototake, Mirai Tanaka", "title": "Semi-flat minima and saddle points by embedding neural networks to\n  overparameterization", "comments": "38 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically study the landscape of the training error for neural\nnetworks in overparameterized cases. We consider three basic methods for\nembedding a network into a wider one with more hidden units, and discuss\nwhether a minimum point of the narrower network gives a minimum or saddle point\nof the wider one. Our results show that the networks with smooth and ReLU\nactivation have different partially flat landscapes around the embedded point.\nWe also relate these results to a difference of their generalization abilities\nin overparameterized realization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 00:12:15 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 07:25:18 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Fukumizu", "Kenji", ""], ["Yamaguchi", "Shoichiro", ""], ["Mototake", "Yoh-ichi", ""], ["Tanaka", "Mirai", ""]]}, {"id": "1906.04870", "submitter": "Yongyi Guo", "authors": "Jianqing Fan, Yongyi Guo, Kaizheng Wang", "title": "Communication-Efficient Accurate Statistical Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the data are stored in a distributed manner, direct application of\ntraditional statistical inference procedures is often prohibitive due to\ncommunication cost and privacy concerns. This paper develops and investigates\ntwo Communication-Efficient Accurate Statistical Estimators (CEASE),\nimplemented through iterative algorithms for distributed optimization. In each\niteration, node machines carry out computation in parallel and communicate with\nthe central processor, which then broadcasts aggregated information to node\nmachines for new updates. The algorithms adapt to the similarity among loss\nfunctions on node machines, and converge rapidly when each node machine has\nlarge enough sample size. Moreover, they do not require good initialization and\nenjoy linear converge guarantees under general conditions. The contraction rate\nof optimization errors is presented explicitly, with dependence on the local\nsample size unveiled. In addition, the improved statistical accuracy per\niteration is derived. By regarding the proposed method as a multi-step\nstatistical estimator, we show that statistical efficiency can be achieved in\nfinite steps in typical statistical applications. In addition, we give the\nconditions under which the one-step CEASE estimator is statistically efficient.\nExtensive numerical experiments on both synthetic and real data validate the\ntheoretical results and demonstrate the superior performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 00:41:12 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Fan", "Jianqing", ""], ["Guo", "Yongyi", ""], ["Wang", "Kaizheng", ""]]}, {"id": "1906.04881", "submitter": "Ming Tu", "authors": "Ming Tu, Jing Huang, Xiaodong He, Bowen Zhou", "title": "Multiple instance learning with graph neural networks", "comments": "Accepted to ICML 2019 Workshop on Learning and Reasoning with\n  Graph-Structured Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple instance learning (MIL) aims to learn the mapping between a bag of\ninstances and the bag-level label. In this paper, we propose a new end-to-end\ngraph neural network (GNN) based algorithm for MIL: we treat each bag as a\ngraph and use GNN to learn the bag embedding, in order to explore the useful\nstructural information among instances in bags. The final graph representation\nis fed into a classifier for label prediction. Our algorithm is the first\nattempt to use GNN for MIL. We empirically show that the proposed algorithm\nachieves the state of the art performance on several popular MIL data sets\nwithout losing model interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 01:45:26 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Tu", "Ming", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1906.04886", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Jesse Beu, Dibakar Gope, Ganesh Dasika, Matthew\n  Mattina", "title": "Run-Time Efficient RNN Compression for Inference on Edge Devices", "comments": "Published at 4th edition of Workshop on Energy Efficient Machine\n  Learning and Cognitive Computing for Embedded Applications at International\n  Symposium of Computer Architecture 2019, Phoenix, Arizona\n  (https://www.emc2-workshop.com/isca-19) colocated with ISCA 2019", "journal-ref": "2019 2nd Workshop on Energy Efficient Machine Learning and\n  Cognitive Computing for Embedded Applications (EMC2)", "doi": "10.1109/EMC249363.2019.00013", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks can be large and compute-intensive, yet many\napplications that benefit from RNNs run on small devices with very limited\ncompute and storage capabilities while still having run-time constraints. As a\nresult, there is a need for compression techniques that can achieve significant\ncompression without negatively impacting inference run-time and task accuracy.\nThis paper explores a new compressed RNN cell implementation called Hybrid\nMatrix Decomposition (HMD) that achieves this dual objective. This scheme\ndivides the weight matrix into two parts - an unconstrained upper half and a\nlower half composed of rank-1 blocks. This results in output features where the\nupper sub-vector has \"richer\" features while the lower-sub vector has\n\"constrained features\". HMD can compress RNNs by a factor of 2-4x while having\na faster run-time than pruning (Zhu &Gupta, 2017) and retaining more model\naccuracy than matrix factorization (Grachev et al., 2017). We evaluate this\ntechnique on 5 benchmarks spanning 3 different applications, illustrating its\ngenerality in the domain of edge computing.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 01:59:44 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 23:13:15 GMT"}, {"version": "v3", "created": "Sun, 5 Jan 2020 21:54:18 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 22:36:34 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Thakker", "Urmish", ""], ["Beu", "Jesse", ""], ["Gope", "Dibakar", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1906.04887", "submitter": "Sam Shleifer", "authors": "Sam Shleifer and Eric Prokop", "title": "Using Small Proxy Datasets to Accelerate Hyperparameter Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest bottlenecks in a machine learning workflow is waiting for\nmodels to train. Depending on the available computing resources, it can take\ndays to weeks to train a neural network on a large dataset with many classes\nsuch as ImageNet. For researchers experimenting with new algorithmic\napproaches, this is impractically time consuming and costly. We aim to generate\nsmaller \"proxy datasets\" where experiments are cheaper to run but results are\nhighly correlated with experimental results on the full dataset. We generate\nthese proxy datasets using by randomly sampling from examples or classes,\ntraining on only the easiest or hardest examples and training on synthetic\nexamples generated by \"data distillation\". We compare these techniques to the\nmore widely used baseline of training on the full dataset for fewer epochs. For\neach proxying strategy, we estimate three measures of \"proxy quality\": how much\nof the variance in experimental results on the full dataset can be explained by\nexperimental results on the proxy dataset.\n  Experiments on Imagenette and Imagewoof (Howard, 2019) show that running\nhyperparameter search on the easiest 10% of examples explains 81% of the\nvariance in experiment results on the target task, and using the easiest 50% of\nexamples can explain 95% of the variance, significantly more than training on\nall the data for fewer epochs, a more widely used baseline. These \"easy\"\nproxies are higher quality than training on the full dataset for a reduced\nnumber of epochs (but equivalent computational cost), and, unexpectedly, higher\nquality than proxies constructed from the hardest examples. Without access to a\ntrained model, researchers can improve proxy quality by restricting the subset\nto fewer classes; proxies built on half the classes are higher quality than\nthose with an equivalent number of examples spread across all classes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:01:30 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Shleifer", "Sam", ""], ["Prokop", "Eric", ""]]}, {"id": "1906.04890", "submitter": "Andrew Ferguson", "authors": "Hythem Sidky, Wei Chen, and Andrew L. Ferguson", "title": "High-resolution Markov state models for the dynamics of Trp-cage\n  miniprotein constructed over slow folding modes identified by state-free\n  reversible VAMPnets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-free reversible VAMPnets (SRVs) are a neural network-based framework\ncapable of learning the leading eigenfunctions of the transfer operator of a\ndynamical system from trajectory data. In molecular dynamics simulations, these\ndata-driven collective variables (CVs) capture the slowest modes of the\ndynamics and are useful for enhanced sampling and free energy estimation. In\nthis work, we employ SRV coordinates as a feature set for Markov state model\n(MSM) construction. Compared to the current state of the art, MSMs constructed\nfrom SRV coordinates are more robust to the choice of input features, exhibit\nfaster implied timescale convergence, and permit the use of shorter lagtimes to\nconstruct higher kinetic resolution models. We apply this methodology to study\nthe folding kinetics and conformational landscape of the Trp-cage miniprotein.\nFolding and unfolding mean first passage times are in good agreement with prior\nliterature, and a nine macrostate model is presented. The unfolded ensemble\ncomprises a central kinetic hub with interconversions to several metastable\nunfolded conformations and which serves as the gateway to the folded ensemble.\nThe folded ensemble comprises the native state, a partially unfolded\nintermediate \"loop\" state, and a previously unreported short-lived intermediate\nthat we were able to resolve due to the high time-resolution of the SRV-MSM. We\npropose SRVs as an excellent candidate for integration into modern MSM\nconstruction pipelines.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:10:51 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Sidky", "Hythem", ""], ["Chen", "Wei", ""], ["Ferguson", "Andrew L.", ""]]}, {"id": "1906.04893", "submitter": "Mahyar Fazlyab", "authors": "Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, George\n  J. Pappas", "title": "Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tight estimation of the Lipschitz constant for deep neural networks (DNNs) is\nuseful in many applications ranging from robustness certification of\nclassifiers to stability analysis of closed-loop systems with reinforcement\nlearning controllers. Existing methods in the literature for estimating the\nLipschitz constant suffer from either lack of accuracy or poor scalability. In\nthis paper, we present a convex optimization framework to compute guaranteed\nupper bounds on the Lipschitz constant of DNNs both accurately and efficiently.\nOur main idea is to interpret activation functions as gradients of convex\npotential functions. Hence, they satisfy certain properties that can be\ndescribed by quadratic constraints. This particular description allows us to\npose the Lipschitz constant estimation problem as a semidefinite program (SDP).\nThe resulting SDP can be adapted to increase either the estimation accuracy (by\ncapturing the interaction between activation functions of different layers) or\nscalability (by decomposition and parallel implementation). We illustrate the\nutility of our approach with a variety of experiments on randomly generated\nnetworks and on classifiers trained on the MNIST and Iris datasets. In\nparticular, we experimentally demonstrate that our Lipschitz bounds are the\nmost accurate compared to those in the literature. We also study the impact of\nadversarial training methods on the Lipschitz bounds of the resulting\nclassifiers and show that our bounds can be used to efficiently provide\nrobustness guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:18:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Fazlyab", "Mahyar", ""], ["Robey", "Alexander", ""], ["Hassani", "Hamed", ""], ["Morari", "Manfred", ""], ["Pappas", "George J.", ""]]}, {"id": "1906.04895", "submitter": "Dan Feldman PhD", "authors": "Dan Feldman, Zahi Kfir, Xuan Wu", "title": "Coresets for Gaussian Mixture Models of Any Shape", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $\\varepsilon$-coreset for a given set $D$ of $n$ points, is usually a\nsmall weighted set, such that querying the coreset \\emph{provably} yields a\n$(1+\\varepsilon)$-factor approximation to the original (full) dataset, for a\ngiven family of queries. Using existing techniques, coresets can be maintained\nfor streaming, dynamic (insertion/deletions), and distributed data in parallel,\ne.g. on a network, GPU or cloud.\n  We suggest the first coresets that approximate the negative log-likelihood\nfor $k$-Gaussians Mixture Models (GMM) of arbitrary shapes (ratio between\neigenvalues of their covariance matrices). For example, for any input set $D$\nwhose coordinates are integers in $[-n^{100},n^{100}]$ and any fixed $k,d\\geq\n1$, the coreset size is $(\\log n)^{O(1)}/\\varepsilon^2$, and can be computed in\ntime near-linear in $n$, with high probability. The optimal GMM may then be\napproximated quickly by learning the small coreset.\n  Previous results [NIPS'11, JMLR'18] suggested such small coresets for the\ncase of semi-speherical unit Gaussians, i.e., where their corresponding\neigenvalues are constants between $\\frac{1}{2\\pi}$ to $2\\pi$.\n  Our main technique is a reduction between coresets for $k$-GMMs and\nprojective clustering problems. We implemented our algorithms, and provide open\ncode, and experimental results. Since our coresets are generic, with no special\ndependency on GMMs, we hope that they will be useful for many other functions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:23:24 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Feldman", "Dan", ""], ["Kfir", "Zahi", ""], ["Wu", "Xuan", ""]]}, {"id": "1906.04898", "submitter": "Qiran Gong", "authors": "Hao Peng, Jianxin Li, Qiran Gong, Senzhang Wang, Lifang He, Bo Li,\n  Lihong Wang, Philip S. Yu", "title": "Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for\n  Large-Scale Multi-Label Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNNs, RNNs, GCNs, and CapsNets have shown significant insights in\nrepresentation learning and are widely used in various text mining tasks such\nas large-scale multi-label text classification. However, most existing deep\nmodels for multi-label text classification consider either the non-consecutive\nand long-distance semantics or the sequential semantics, but how to consider\nthem both coherently is less studied. In addition, most existing methods treat\noutput labels as independent methods, but ignore the hierarchical relations\namong them, leading to useful semantic information loss. In this paper, we\npropose a novel hierarchical taxonomy-aware and attentional graph capsule\nrecurrent CNNs framework for large-scale multi-label text classification.\nSpecifically, we first propose to model each document as a word order preserved\ngraph-of-words and normalize it as a corresponding words-matrix representation\nwhich preserves both the non-consecutive, long-distance and local sequential\nsemantics. Then the words-matrix is input to the proposed attentional graph\ncapsule recurrent CNNs for more effectively learning the semantic features. To\nleverage the hierarchical relations among the class labels, we propose a\nhierarchical taxonomy embedding method to learn their representations, and\ndefine a novel weighted margin loss by incorporating the label representation\nsimilarity. Extensive evaluations on three datasets show that our model\nsignificantly improves the performance of large-scale multi-label text\nclassification by comparing with state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:23:45 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Gong", "Qiran", ""], ["Wang", "Senzhang", ""], ["He", "Lifang", ""], ["Li", "Bo", ""], ["Wang", "Lihong", ""], ["Yu", "Philip S.", ""]]}, {"id": "1906.04904", "submitter": "Xinqiang Ding", "authors": "Xinqiang Ding, David J. Freedman", "title": "Learning Deep Generative Models with Annealed Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference (VI) and Markov chain Monte Carlo (MCMC) are two main\napproximate approaches for learning deep generative models by maximizing\nmarginal likelihood. In this paper, we propose using annealed importance\nsampling for learning deep generative models. Our proposed approach bridges VI\nwith MCMC. It generalizes VI methods such as variational auto-encoders and\nimportance weighted auto-encoders (IWAE) and the MCMC method proposed in\n(Hoffman, 2017). It also provides insights into why running multiple short MCMC\nchains can help learning deep generative models. Through experiments, we show\nthat our approach yields better density models than IWAE and can effectively\ntrade computation for model accuracy without increasing memory cost.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:54:34 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:20:39 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 01:08:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ding", "Xinqiang", ""], ["Freedman", "David J.", ""]]}, {"id": "1906.04908", "submitter": "Sumith Kulal", "authors": "Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon,\n  Alex Aiken, Percy Liang", "title": "SPoC: Search-based Pseudocode to Code", "comments": "Under submission to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of mapping pseudocode to long programs that are\nfunctionally correct. Given test cases as a mechanism to validate programs, we\nsearch over the space of possible translations of the pseudocode to find a\nprogram that passes the validation. However, without proper credit assignment\nto localize the sources of program failures, it is difficult to guide search\ntoward more promising programs. We propose to perform credit assignment based\non signals from compilation errors, which constitute 88.7% of program failures.\nConcretely, we treat the translation of each pseudocode line as a discrete\nportion of the program, and whenever a synthesized program fails to compile, an\nerror localization method tries to identify the portion of the program\nresponsible for the failure. We then focus search over alternative translations\nof the pseudocode for those portions. For evaluation, we collected the SPoC\ndataset (Search-based Pseudocode to Code) containing 18,356 programs with\nhuman-authored pseudocode and test cases. Under a budget of 100 program\ncompilations, performing search improves the synthesis success rate over using\nthe top-one translation of the pseudocode from 25.6% to 44.7%.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 03:13:18 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Kulal", "Sumith", ""], ["Pasupat", "Panupong", ""], ["Chandra", "Kartik", ""], ["Lee", "Mina", ""], ["Padon", "Oded", ""], ["Aiken", "Alex", ""], ["Liang", "Percy", ""]]}, {"id": "1906.04914", "submitter": "Suraj Tripathi", "authors": "Abhay Kumar, Nishant Jain, Suraj Tripathi, Chirag Singh", "title": "From Fully Supervised to Zero Shot Settings for Twitter Hashtag\n  Recommendation", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a comprehensive end-to-end pipeline for Twitter hashtags\nrecommendation system including data collection, supervised training setting\nand zero shot training setting. In the supervised training setting, we have\nproposed and compared the performance of various deep learning architectures,\nnamely Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and\nTransformer Network. However, it is not feasible to collect data for all\npossible hashtag labels and train a classifier model on them. To overcome this\nlimitation, we propose a Zero Shot Learning (ZSL) paradigm for predicting\nunseen hashtag labels by learning the relationship between the semantic space\nof tweets and the embedding space of hashtag labels. We evaluated various\nstate-of-the-art ZSL methods like Convex combination of Semantic Embedding\n(ConSE), Embarrassingly Simple Zero-Shot Learning (ESZSL) and Deep Embedding\nModel for Zero-Shot Learning (DEM-ZSL) for the hashtag recommendation task. We\ndemonstrate the effectiveness and scalability of ZSL methods for the\nrecommendation of unseen hashtags. To the best of our knowledge, this is the\nfirst quantitative evaluation of ZSL methods to date for unseen hashtags\nrecommendations from tweet text.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:38:28 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Kumar", "Abhay", ""], ["Jain", "Nishant", ""], ["Tripathi", "Suraj", ""], ["Singh", "Chirag", ""]]}, {"id": "1906.04928", "submitter": "Senzhang Wang", "authors": "Senzhang Wang, Jiannong Cao, Philip S. Yu", "title": "Deep Learning for Spatio-Temporal Data Mining: A Survey", "comments": "arXiv admin note: text overlap with arXiv:1711.04710 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast development of various positioning techniques such as Global\nPosition System (GPS), mobile devices and remote sensing, spatio-temporal data\nhas become increasingly available nowadays. Mining valuable knowledge from\nspatio-temporal data is critically important to many real world applications\nincluding human mobility understanding, smart transportation, urban planning,\npublic safety, health care and environmental management. As the number, volume\nand resolution of spatio-temporal datasets increase rapidly, traditional data\nmining methods, especially statistics based methods for dealing with such data\nare becoming overwhelmed. Recently, with the advances of deep learning\ntechniques, deep leaning models such as convolutional neural network (CNN) and\nrecurrent neural network (RNN) have enjoyed considerable success in various\nmachine learning tasks due to their powerful hierarchical feature learning\nability in both spatial and temporal domains, and have been widely applied in\nvarious spatio-temporal data mining (STDM) tasks such as predictive learning,\nrepresentation learning, anomaly detection and classification. In this paper,\nwe provide a comprehensive survey on recent progress in applying deep learning\ntechniques for STDM. We first categorize the types of spatio-temporal data and\nbriefly introduce the popular deep learning models that are used in STDM. Then\na framework is introduced to show a general pipeline of the utilization of deep\nlearning models for STDM. Next we classify existing literatures based on the\ntypes of ST data, the data mining tasks, and the deep learning models, followed\nby the applications of deep learning for STDM in different domains including\ntransportation, climate science, human mobility, location based social network,\ncrime analysis, and neuroscience. Finally, we conclude the limitations of\ncurrent research and point out future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:43:54 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 08:17:06 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wang", "Senzhang", ""], ["Cao", "Jiannong", ""], ["Yu", "Philip S.", ""]]}, {"id": "1906.04933", "submitter": "Jonathan Wenger", "authors": "Jonathan Wenger and Hedvig Kjellstr\\\"om and Rudolph Triebel", "title": "Non-Parametric Calibration for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of classification methods not only require high accuracy\nbut also reliable estimation of predictive uncertainty. However, while many\ncurrent classification frameworks, in particular deep neural networks, achieve\nhigh accuracy, they tend to incorrectly estimate uncertainty. In this paper, we\npropose a method that adjusts the confidence estimates of a general classifier\nsuch that they approach the probability of classifying correctly. In contrast\nto existing approaches, our calibration method employs a non-parametric\nrepresentation using a latent Gaussian process, and is specifically designed\nfor multi-class classification. It can be applied to any classifier that\noutputs confidence estimates and is not limited to neural networks. We also\nprovide a theoretical analysis regarding the over- and underconfidence of a\nclassifier and its relationship to calibration, as well as an empirical outlook\nfor calibrated active learning. In experiments we show the universally strong\nperformance of our method across different classifiers and benchmark data sets,\nin particular for state-of-the art neural network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 04:11:48 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 11:41:47 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 14:20:33 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wenger", "Jonathan", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Triebel", "Rudolph", ""]]}, {"id": "1906.04937", "submitter": "Qiang Ning", "authors": "Qiang Ning, Hangfeng He, Chuchu Fan, Dan Roth", "title": "Partial Or Complete, That's The Question", "comments": "Long paper accepted by NAACL'19. 11 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many structured learning tasks, the data annotation process is complex\nand costly. Existing annotation schemes usually aim at acquiring completely\nannotated structures, under the common perception that partial structures are\nof low quality and could hurt the learning process. This paper questions this\ncommon perception, motivated by the fact that structures consist of\ninterdependent sets of variables. Thus, given a fixed budget, partly annotating\neach structure may provide the same level of supervision, while allowing for\nmore structures to be annotated. We provide an information theoretic\nformulation for this perspective and use it, in the context of three diverse\nstructured learning tasks, to show that learning from partial structures can\nsometimes outperform learning from complete ones. Our findings may provide\nimportant insights into structured data annotation schemes and could support\nprogress in learning protocols for structured tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 04:35:11 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Qiang", ""], ["He", "Hangfeng", ""], ["Fan", "Chuchu", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04948", "submitter": "Guang-He Lee", "authors": "Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi S. Jaakkola", "title": "Tight Certificates of Adversarial Robustness for Randomly Smoothed\n  Classifiers", "comments": "Published in Advances in Neural Information Processing Systems\n  (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong theoretical guarantees of robustness can be given for ensembles of\nclassifiers generated by input randomization. Specifically, an $\\ell_2$ bounded\nadversary cannot alter the ensemble prediction generated by an additive\nisotropic Gaussian noise, where the radius for the adversary depends on both\nthe variance of the distribution as well as the ensemble margin at the point of\ninterest. We build on and considerably expand this work across broad classes of\ndistributions. In particular, we offer adversarial robustness guarantees and\nassociated algorithms for the discrete case where the adversary is $\\ell_0$\nbounded. Moreover, we exemplify how the guarantees can be tightened with\nspecific assumptions about the function class of the classifier such as a\ndecision tree. We empirically illustrate these results with and without\nfunctional restrictions across image and molecule datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 05:22:18 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 23:37:41 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 19:46:57 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Lee", "Guang-He", ""], ["Yuan", "Yang", ""], ["Chang", "Shiyu", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1906.04985", "submitter": "Alexander Cowen-Rivers MSc", "authors": "Alexander I. Cowen-Rivers, Pasquale Minervini, Tim Rocktaschel, Matko\n  Bosnjak, Sebastian Riedel, Jun Wang", "title": "Neural Variational Inference For Estimating Uncertainty in Knowledge\n  Graph Embeddings", "comments": "Accepted at IJCAI 19 Neural-Symbolic Learning and Reasoning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Neural Variational Inference allowed for a renaissance in\nlatent variable models in a variety of domains involving high-dimensional data.\nWhile traditional variational methods derive an analytical approximation for\nthe intractable distribution over the latent variables, here we construct an\ninference network conditioned on the symbolic representation of entities and\nrelation types in the Knowledge Graph, to provide the variational\ndistributions. The new framework results in a highly-scalable method. Under a\nBernoulli sampling framework, we provide an alternative justification for\ncommonly used techniques in large-scale stochastic variational inference, which\ndrastically reduce training time at a cost of an additional approximation to\nthe variational lower bound. We introduce two models from this highly scalable\nprobabilistic framework, namely the Latent Information and Latent Fact models,\nfor reasoning over knowledge graph-based representations. Our Latent\nInformation and Latent Fact models improve upon baseline performance under\ncertain conditions. We use the learnt embedding variance to estimate predictive\nuncertainty during link prediction, and discuss the quality of these learnt\nuncertainty estimates. Our source code and datasets are publicly available\nonline at\nhttps://github.com/alexanderimanicowenrivers/Neural-Variational-Knowledge-Graphs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 07:52:02 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 03:01:30 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Cowen-Rivers", "Alexander I.", ""], ["Minervini", "Pasquale", ""], ["Rocktaschel", "Tim", ""], ["Bosnjak", "Matko", ""], ["Riedel", "Sebastian", ""], ["Wang", "Jun", ""]]}, {"id": "1906.05014", "submitter": "Nikita Puchkin", "authors": "Nikita Puchkin and Vladimir Spokoiny", "title": "Structure-adaptive manifold estimation", "comments": "53 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of manifold estimation from noisy observations. Many\nmanifold learning procedures locally approximate a manifold by a weighted\naverage over a small neighborhood. However, in the presence of large noise, the\nassigned weights become so corrupted that the averaged estimate shows very poor\nperformance. We suggest a novel computationally efficient structure-adaptive\nprocedure which simultaneously reconstructs a smooth manifold and estimates\nprojections of the point cloud onto this manifold. The proposed approach\niteratively refines the weights on each step, using the structural information\nobtained at previous steps. After several iterations, we obtain nearly \"oracle\"\nweights, so that the final estimates are nearly efficient even in the presence\nof relatively large noise. In our theoretical study we establish tight lower\nand upper bounds proving asymptotic optimality of the method for manifold\nestimation under the Hausdorff loss, provided that the noise degrades to zero\nfast enough.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:10:59 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 10:44:03 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 09:29:38 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 02:38:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Puchkin", "Nikita", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1906.05015", "submitter": "Ming Zhu", "authors": "Ming Zhu, Xiao-Yang Liu, and Xiaodong Wang", "title": "Deep Reinforcement Learning for Unmanned Aerial Vehicle-Assisted\n  Vehicular Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are envisioned to complement the 5G\ncommunication infrastructure in future smart cities. Hot spots easily appear in\nroad intersections, where effective communication among vehicles is\nchallenging. UAVs may serve as relays with the advantages of low price, easy\ndeployment, line-of-sight links, and flexible mobility. In this paper, we study\na UAV-assisted vehicular network where the UAV jointly adjusts its transmission\ncontrol (power and channel) and 3D flight to maximize the total throughput.\nFirst, we formulate a Markov decision process (MDP) problem by modeling the\nmobility of the UAV/vehicles and the state transitions. Secondly, we solve the\ntarget problem using a deep reinforcement learning method under unknown or\nunmeasurable environment variables especially in 5G, namely, the deep\ndeterministic policy gradient (DDPG), and propose three solutions with\ndifferent control objectives. Environment variables are unknown and\nunmeasurable, therefore, we use a deep reinforcement learning method. Moreover,\nconsidering the energy consumption of 3D flight, we extend the proposed\nsolutions to maximize the total throughput per energy unit by encouraging or\ndiscouraging the UAV's mobility. To achieve this goal, the DDPG framework is\nmodified. Thirdly, in a simplified model with small state space and action\nspace, we verify the optimality of proposed algorithms. Comparing with two\nbaseline schemes, we demonstrate the effectiveness of proposed algorithms in a\nrealistic model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:12:50 GMT"}, {"version": "v10", "created": "Wed, 4 Mar 2020 02:18:20 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 08:58:02 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 12:25:15 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 16:00:25 GMT"}, {"version": "v5", "created": "Tue, 9 Jul 2019 01:47:49 GMT"}, {"version": "v6", "created": "Fri, 12 Jul 2019 13:49:35 GMT"}, {"version": "v7", "created": "Sat, 27 Jul 2019 03:50:11 GMT"}, {"version": "v8", "created": "Mon, 12 Aug 2019 10:50:40 GMT"}, {"version": "v9", "created": "Tue, 3 Sep 2019 14:29:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zhu", "Ming", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1906.05022", "submitter": "Yudan Liu", "authors": "Yudan Liu, Kaikai Ge, Xu Zhang, Leyu Lin", "title": "Real-time Attention Based Look-alike Model for Recommender System", "comments": "Accepted by KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330707", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning models play more and more important roles in contents\nrecommender systems. However, although the performance of recommendations is\ngreatly improved, the \"Matthew effect\" becomes increasingly evident. While the\nhead contents get more and more popular, many competitive long-tail contents\nare difficult to achieve timely exposure because of lacking behavior features.\nThis issue has badly impacted the quality and diversity of recommendations. To\nsolve this problem, look-alike algorithm is a good choice to extend audience\nfor high quality long-tail contents. But the traditional look-alike models\nwhich widely used in online advertising are not suitable for recommender\nsystems because of the strict requirement of both real-time and effectiveness.\nThis paper introduces a real-time attention based look-alike model (RALM) for\nrecommender systems, which tackles the challenge of conflict between real-time\nand effectiveness. RALM realizes real-time look-alike audience extension\nbenefiting from seeds-to-user similarity prediction and improves the\neffectiveness through optimizing user representation learning and look-alike\nlearning modeling. For user representation learning, we propose a novel neural\nnetwork structure named attention merge layer to replace the concatenation\nlayer, which significantly improves the expressive ability of multi-fields\nfeature learning. On the other hand, considering the various members of seeds,\nwe design global attention unit and local attention unit to learn robust and\nadaptive seeds representation with respect to a certain target user. At last,\nwe introduce seeds clustering mechanism which not only reduces the time\ncomplexity of attention units prediction but also minimizes the loss of seeds\ninformation at the same time. According to our experiments, RALM shows superior\neffectiveness and performance than popular look-alike models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:21:16 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Liu", "Yudan", ""], ["Ge", "Kaikai", ""], ["Zhang", "Xu", ""], ["Lin", "Leyu", ""]]}, {"id": "1906.05029", "submitter": "Pieter Robberechts", "authors": "Pieter Robberechts, Jan Van Haaren and Jesse Davis", "title": "Who Will Win It? An In-game Win Probability Model for Football", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-game win probability is a statistical metric that provides a sports team's\nlikelihood of winning at any given point in a game, based on the performance of\nhistorical teams in the same situation. In-game win-probability models have\nbeen extensively studied in baseball, basketball and American football. These\nmodels serve as a tool to enhance the fan experience, evaluate in game-decision\nmaking and measure the risk-reward balance for coaching decisions. In contrast,\nthey have received less attention in association football, because its\nlow-scoring nature makes it far more challenging to analyze. In this paper, we\nbuild an in-game win probability model for football. Specifically, we first\nshow that porting existing approaches, both in terms of the predictive models\nemployed and the features considered, does not yield good in-game\nwin-probability estimates for football. Second, we introduce our own Bayesian\nstatistical model that utilizes a set of eight variables to predict the running\nwin, tie and loss probabilities for the home team. We train our model using\nevent data from the last four seasons of the major European football\ncompetitions. Our results indicate that our model provides well-calibrated\nprobabilities. Finally, we elaborate on two use cases for our win probability\nmetric: enhancing the fan experience and evaluating performance in crucial\nsituations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:38:07 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Robberechts", "Pieter", ""], ["Van Haaren", "Jan", ""], ["Davis", "Jesse", ""]]}, {"id": "1906.05030", "submitter": "Steven Hansen", "authors": "Steven Hansen, Will Dabney, Andre Barreto, Tom Van de Wiele, David\n  Warde-Farley, Volodymyr Mnih", "title": "Fast Task Inference with Variational Intrinsic Successor Features", "comments": "Accepted for publication at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been established that diverse behaviors spanning the controllable\nsubspace of an Markov decision process can be trained by rewarding a policy for\nbeing distinguishable from other policies \\citep{gregor2016variational,\neysenbach2018diversity, warde2018unsupervised}. However, one limitation of this\nformulation is generalizing behaviors beyond the finite set being explicitly\nlearned, as is needed for use on subsequent tasks. Successor features\n\\citep{dayan93improving, barreto2017successor} provide an appealing solution to\nthis generalization problem, but require defining the reward function as linear\nin some grounded feature space. In this paper, we show that these two\ntechniques can be combined, and that each method solves the other's primary\nlimitation. To do so we introduce Variational Intrinsic Successor FeatuRes\n(VISR), a novel algorithm which learns controllable features that can be\nleveraged to provide enhanced generalization and fast task inference through\nthe successor feature framework. We empirically validate VISR on the full Atari\nsuite, in a novel setup wherein the rewards are only exposed briefly after a\nlong unsupervised phase. Achieving human-level performance on 14 games and\nbeating all baselines, we believe VISR represents a step towards agents that\nrapidly learn from limited feedback.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:39:05 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 18:14:54 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hansen", "Steven", ""], ["Dabney", "Will", ""], ["Barreto", "Andre", ""], ["Van de Wiele", "Tom", ""], ["Warde-Farley", "David", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1906.05032", "submitter": "Eran Malach", "authors": "Jonathan Fiat, Eran Malach, Shai Shalev-Shwartz", "title": "Decoupling Gating from Linearity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ReLU neural-networks have been in the focus of many recent theoretical works,\ntrying to explain their empirical success. Nonetheless, there is still a gap\nbetween current theoretical results and empirical observations, even in the\ncase of shallow (one hidden-layer) networks. For example, in the task of\nmemorizing a random sample of size $m$ and dimension $d$, the best theoretical\nresult requires the size of the network to be $\\tilde{\\Omega}(\\frac{m^2}{d})$,\nwhile empirically a network of size slightly larger than $\\frac{m}{d}$ is\nsufficient. To bridge this gap, we turn to study a simplified model for ReLU\nnetworks. We observe that a ReLU neuron is a product of a linear function with\na gate (the latter determines whether the neuron is active or not), where both\nshare a jointly trained weight vector. In this spirit, we introduce the Gated\nLinear Unit (GaLU), which simply decouples the linearity from the gating by\nassigning different vectors for each role. We show that GaLU networks allow us\nto get optimization and generalization results that are much stronger than\nthose available for ReLU networks. Specifically, we show a memorization result\nfor networks of size $\\tilde{\\Omega}(\\frac{m}{d})$, and improved generalization\nbounds. Finally, we show that in some scenarios, GaLU networks behave similarly\nto ReLU networks, hence proving to be a good choice of a simplified model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:43:05 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Fiat", "Jonathan", ""], ["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1906.05059", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, Anup Rao, Sungchul Kim, Eunyee Koh, Nesreen K. Ahmed,\n  Gang Wu", "title": "Higher-Order Ranking and Link Prediction: From Closing Triangles to\n  Closing Higher-Order Motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the notion of motif closure and describe\nhigher-order ranking and link prediction methods based on the notion of closing\nhigher-order network motifs. The methods are fast and efficient for real-time\nranking and link prediction-based applications such as web search, online\nadvertising, and recommendation. In such applications, real-time performance is\ncritical. The proposed methods do not require any explicit training data, nor\ndo they derive an embedding from the graph data, or perform any explicit\nlearning. Existing methods with the above desired properties are all based on\nclosing triangles (common neighbors, Jaccard similarity, and the ilk). In this\nwork, we investigate higher-order network motifs and develop techniques based\non the notion of closing higher-order motifs that move beyond closing simple\ntriangles. All methods described in this work are fast with a runtime that is\nsublinear in the number of nodes. The experimental results indicate the\nimportance of closing higher-order motifs for ranking and link prediction\napplications. Finally, the proposed notion of higher-order motif closure can\nserve as a basis for studying and developing better ranking and link prediction\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:07:10 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Rao", "Anup", ""], ["Kim", "Sungchul", ""], ["Koh", "Eunyee", ""], ["Ahmed", "Nesreen K.", ""], ["Wu", "Gang", ""]]}, {"id": "1906.05065", "submitter": "Damien Ackerer", "authors": "Damien Ackerer, Natasa Tagasovska, Thibault Vatter", "title": "Deep Smoothing of the Implied Volatility Surface", "comments": "forthcoming NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural network (NN) approach to fit and predict implied\nvolatility surfaces (IVSs). Atypically to standard NN applications, financial\nindustry practitioners use such models equally to replicate market prices and\nto value other financial instruments. In other words, low training losses are\nas important as generalization capabilities. Importantly, IVS models need to\ngenerate realistic arbitrage-free option prices, meaning that no portfolio can\nlead to risk-free profits. We propose an approach guaranteeing the absence of\narbitrage opportunities by penalizing the loss using soft constraints.\nFurthermore, our method can be combined with standard IVS models in\nquantitative finance, thus providing a NN-based correction when such models\nfail at replicating observed market prices. This lets practitioners use our\napproach as a plug-in on top of classical methods. Empirical results show that\nthis approach is particularly useful when only sparse or erroneous data are\navailable. We also quantify the uncertainty of the model predictions in regions\nwith few or no observations. We further explore how deeper NNs improve over\nshallower ones, as well as other properties of the network architecture. We\nbenchmark our method against standard IVS models. By evaluating our method on\nboth training sets, and testing sets, namely, we highlight both their capacity\nto reproduce observed prices and predict new ones.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:31:13 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:34:21 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 10:53:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ackerer", "Damien", ""], ["Tagasovska", "Natasa", ""], ["Vatter", "Thibault", ""]]}, {"id": "1906.05082", "submitter": "Mohamed Hebiri", "authors": "Evgenii Chzhen (LAMA, LMO, CELESTE), Christophe Denis (LAMA), Mohamed\n  Hebiri (LAMA), Luca Oneto, Massimiliano Pontil (IIT, UCL)", "title": "Leveraging Labeled and Unlabeled Data for Consistent Fair Binary\n  Classification", "comments": null, "journal-ref": "NeurIPS 2019 - 33th Annual Conference on Neural Information\n  Processing Systems, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fair binary classification using the notion of Equal\nOpportunity. It requires the true positive rate to distribute equally across\nthe sensitive groups. Within this setting we show that the fair optimal\nclassifier is obtained by recalibrating the Bayes classifier by a\ngroup-dependent threshold. We provide a constructive expression for the\nthreshold. This result motivates us to devise a plug-in classification\nprocedure based on both unlabeled and labeled datasets. While the latter is\nused to learn the output conditional probability, the former is used for\ncalibration. The overall procedure can be computed in polynomial time and it is\nshown to be statistically consistent both in terms of the classification error\nand fairness measure. Finally, we present numerical experiments which indicate\nthat our method is often superior or competitive with the state-of-the-art\nmethods on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 12:25:25 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 07:30:31 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Chzhen", "Evgenii", "", "LAMA, LMO, CELESTE"], ["Denis", "Christophe", "", "LAMA"], ["Hebiri", "Mohamed", "", "LAMA"], ["Oneto", "Luca", "", "IIT, UCL"], ["Pontil", "Massimiliano", "", "IIT, UCL"]]}, {"id": "1906.05110", "submitter": "Zihan Zhang", "authors": "Zihan Zhang and Xiangyang Ji", "title": "Regret Minimization for Reinforcement Learning by Evaluating the Optimal\n  Bias Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm based on the \\emph{Optimism in the Face of\nUncertainty} (OFU) principle which is able to learn Reinforcement Learning (RL)\nmodeled by Markov decision process (MDP) with finite state-action space\nefficiently. By evaluating the state-pair difference of the optimal bias\nfunction $h^{*}$, the proposed algorithm achieves a regret bound of\n$\\tilde{O}(\\sqrt{SAHT})$\\footnote{The symbol $\\tilde{O}$ means $O$ with log\nfactors ignored. } for MDP with $S$ states and $A$ actions, in the case that an\nupper bound $H$ on the span of $h^{*}$, i.e., $sp(h^{*})$ is known. This result\noutperforms the best previous regret bounds $\\tilde{O}(S\\sqrt{AHT})\n$\\citep{fruit2019improved} by a factor of $\\sqrt{S}$. Furthermore, this regret\nbound matches the lower bound of $\\Omega(\\sqrt{SAHT}) $\\citep{jaksch2010near}\nup to a logarithmic factor. As a consequence, we show that there is a near\noptimal regret bound of $\\tilde{O}(\\sqrt{SADT})$ for MDPs with a finite\ndiameter $D$ compared to the lower bound of $\\Omega(\\sqrt{SADT})\n$\\citep{jaksch2010near}.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 13:00:53 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 14:18:09 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 09:22:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhang", "Zihan", ""], ["Ji", "Xiangyang", ""]]}, {"id": "1906.05168", "submitter": "Trung Hoang Le", "authors": "Huy Ngoc Pham, Trung Hoang Le", "title": "Attention-based Multi-Input Deep Learning Architecture for Biological\n  Activity Prediction: An Application in EGFR Inhibitors", "comments": "2019 11th International Conference on Knowledge and Systems\n  Engineering (KSE) - SS: Bioinformatics and Computational Biology (BCB) -\n  Camera-ready version Aug 20th, 2019", "journal-ref": null, "doi": null, "report-no": "31", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and deep learning have gained popularity and achieved\nimmense success in Drug discovery in recent decades. Historically, machine\nlearning and deep learning models were trained on either structural data or\nchemical properties by separated model. In this study, we proposed an\narchitecture training simultaneously both type of data in order to improve the\noverall performance. Given the molecular structure in the form of SMILES\nnotation and their label, we generated the SMILES-based feature matrix and\nmolecular descriptors. These data were trained on a deep learning model which\nwas also integrated with the Attention mechanism to facilitate training and\ninterpreting. Experiments showed that our model could raise the performance of\nprediction comparing to the reference. With the maximum MCC 0.58 and AUC 90% by\ncross-validation on EGFR inhibitors dataset, our architecture was outperforming\nthe referring model. We also successfully integrated Attention mechanism into\nour model, which helped to interpret the contribution of chemical structures on\nbioactivity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:27:10 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 16:15:11 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 04:19:05 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Pham", "Huy Ngoc", ""], ["Le", "Trung Hoang", ""]]}, {"id": "1906.05173", "submitter": "Jielei Chu", "authors": "Jielei Chu, Hongjun Wang, Jing Liu, Zeng Yu, Zhiguo Gong, and Tianrui\n  Li", "title": "UCRDNet: Unsupervised Collaborative Representation Deep Network for\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose an unsupervised collaborative representation deep\nnetwork (UCRDNet) which consists of novel collaborative representation RBM\n(crRBM) and collaborative representation GRBM (crGRBM). The UCRDNet is a novel\ndeep collaborative feature extractor for exploring more sophisticated\nprobabilistic models of real-valued and binary data. Unlike traditional\nrepresentation methods, one similarity relation between the input instances and\nanother similarity relation between the features of the input instances are\ncollaboratively fused together in the representation process of the crGRBM and\ncrRBM models. Here, we use the Locality Sensitive Hashing (LSH) method to\ndivide the input instance matrix into many mini blocks which contain similar\ninstance and local features. Then, we expect the hidden layer feature units of\neach block gather to block center as much as possible in the training processes\nof the crRBM and crGRBM. Hence, the correlations between the instances and\nfeatures as collaborative relations are fused in the hidden layer features. In\nthe experiments, we use K-means and Spectral Clustering (SC) algorithms based\non four contrast deep networks to verify the deep collaborative representation\ncapability of the UCRDNet architecture. One architecture of the UCRDNet is\ncomposed with a crGRBM and two crRBMs for modeling real-valued data and another\narchitecture of it is composed with three crRBMs for modeling binary data. The\nexperimental results show that the proposed UCRDNet has more outstanding\nperformance than the Autoencoder and DeepFS deep networks (without\ncollaborative representation strategy) for unsupervised clustering on the\nMSRA-MM2.0 and UCI datasets. Furthermore, the proposed UCRDNet shows more\nexcellent collaborative representation capabilities than the CDL deep\ncollaborative networks for unsupervised clustering.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:37:45 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 10:01:15 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 16:09:37 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Chu", "Jielei", ""], ["Wang", "Hongjun", ""], ["Liu", "Jing", ""], ["Yu", "Zeng", ""], ["Gong", "Zhiguo", ""], ["Li", "Tianrui", ""]]}, {"id": "1906.05180", "submitter": "G\\\"unther Schindler", "authors": "Guenther Schindler, Wolfgang Roth, Franz Pernkopf, Holger Froening", "title": "Parameterized Structured Pruning for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of the growing size of Deep Neural Networks (DNNs), the gap to\nhardware capabilities in terms of memory and compute increases. To effectively\ncompress DNNs, quantization and connection pruning are usually considered.\nHowever, unconstrained pruning usually leads to unstructured parallelism, which\nmaps poorly to massively parallel processors, and substantially reduces the\nefficiency of general-purpose processors. Similar applies to quantization,\nwhich often requires dedicated hardware. We propose Parameterized Structured\nPruning (PSP), a novel method to dynamically learn the shape of DNNs through\nstructured sparsity. PSP parameterizes structures (e.g. channel- or layer-wise)\nin a weight tensor and leverages weight decay to learn a clear distinction\nbetween important and unimportant structures. As a result, PSP maintains\nprediction performance, creates a substantial amount of sparsity that is\nstructured and, thus, easy and efficient to map to a variety of massively\nparallel processors, which are mandatory for utmost compute power and energy\nefficiency. PSP is experimentally validated on the popular CIFAR10/100 and\nILSVRC2012 datasets using ResNet and DenseNet architectures, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:46:01 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Schindler", "Guenther", ""], ["Roth", "Wolfgang", ""], ["Pernkopf", "Franz", ""], ["Froening", "Holger", ""]]}, {"id": "1906.05200", "submitter": "Zahra Rahimpour", "authors": "Zahra Rahimpour, Gregor Verbic and Archie C. Chapman", "title": "Macro-action Multi-time scale Dynamic Programming for Energy Management\n  in Buildings with Phase Change Materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on energy management in buildings with phase change\nmaterial (PCM), which is primarily used to improve thermal performance, but can\nalso serve as an energy storage system. In this setting, optimal scheduling of\nan HVAC system is challenging because of the nonlinear and non-convex\ncharacteristics of the PCM, which makes solving the corresponding optimization\nproblem using conventional optimization techniques impractical. Instead, we use\ndynamic programming (DP) to deal with the nonlinear nature of the PCM. To\novercome DP's curse of dimensionality, this paper proposes a novel methodology\nto reduce the computational burden, while maintaining the quality of the\nsolution. Specifically, the method incorporates approaches from sequential\ndecision making in artificial intelligence, including macro actions and\nmulti-time scale Markov decision processes, coupled with an underlying\nstate-space approximation to reduce the state-space and action-space size. The\nperformance of the method is demonstrated on an energy management problem for a\ntypical residential building located in Sydney, Australia. The results\ndemonstrate that the proposed method performs well with a computational\nspeed-up of up to 12,900 times compared to the direct application of DP.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:01:01 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 08:55:15 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Rahimpour", "Zahra", ""], ["Verbic", "Gregor", ""], ["Chapman", "Archie C.", ""]]}, {"id": "1906.05201", "submitter": "Xu He", "authors": "Xu He, Jakub Sygnowski, Alexandre Galashov, Andrei A. Rusu, Yee Whye\n  Teh, Razvan Pascanu", "title": "Task Agnostic Continual Learning via Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are powerful function approximators, they suffer from\ncatastrophic forgetting when the data distribution is not stationary. One\nparticular formalism that studies learning under non-stationary distribution is\nprovided by continual learning, where the non-stationarity is imposed by a\nsequence of distinct tasks. Most methods in this space assume, however, the\nknowledge of task boundaries, and focus on alleviating catastrophic forgetting.\nIn this work, we depart from this view and move the focus towards faster\nremembering -- i.e measuring how quickly the network recovers performance\nrather than measuring the network's performance without any adaptation. We\nargue that in many settings this can be more effective and that it opens the\ndoor to combining meta-learning and continual learning techniques, leveraging\ntheir complementary advantages. We propose a framework specific for the\nscenario where no information about task boundaries or task identity is given.\nIt relies on a separation of concerns into what task is being solved and how\nthe task should be solved. This framework is implemented by differentiating\ntask specific parameters from task agnostic parameters, where the latter are\noptimized in a continual meta learning fashion, without access to multiple\ntasks at the same time. We showcase this framework in a supervised learning\nscenario and discuss the implication of the proposed formalism.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:17:47 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["He", "Xu", ""], ["Sygnowski", "Jakub", ""], ["Galashov", "Alexandre", ""], ["Rusu", "Andrei A.", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1906.05202", "submitter": "Chia-Wen Kuo", "authors": "Chia-Wen Kuo, Chih-Yao Ma, Jia-Bin Huang, Zsolt Kira", "title": "Manifold Graph with Learned Prototypes for Semi-Supervised Image\n  Classification", "comments": "Project site:\n  https://sites.google.com/view/manifold-graph-with-prototypes/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in semi-supervised learning methods rely on estimating the\ncategories of unlabeled data using a model trained on the labeled data\n(pseudo-labeling) and using the unlabeled data for various consistency-based\nregularization. In this work, we propose to explicitly leverage the structure\nof the data manifold based on a Manifold Graph constructed over the image\ninstances within the feature space. Specifically, we propose an architecture\nbased on graph networks that jointly optimizes feature extraction, graph\nconnectivity, and feature propagation and aggregation to unlabeled data in an\nend-to-end manner. Further, we present a novel Prototype Generator for\nproducing a diverse set of prototypes that compactly represent each category,\nwhich supports feature propagation. To evaluate our method, we first contribute\na strong baseline that combines two consistency-based regularizers that already\nachieves state-of-the-art results especially with fewer labels. We then show\nthat when combined with these regularizers, the proposed method facilitates the\npropagation of information from generated prototypes to image data to further\nimprove results. We provide extensive qualitative and quantitative experimental\nresults on semi-supervised benchmarks demonstrating the improvements arising\nfrom our design and show that our method achieves state-of-the-art performance\nwhen compared with existing methods using a single model and comparable with\nensemble methods. Specifically, we achieve error rates of 3.35% on SVHN, 8.27%\non CIFAR-10, and 33.83% on CIFAR-100. With much fewer labels, we surpass the\nstate of the arts by significant margins of 41% relative error decrease on\naverage.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:18:36 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 02:46:21 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kuo", "Chia-Wen", ""], ["Ma", "Chih-Yao", ""], ["Huang", "Jia-Bin", ""], ["Kira", "Zsolt", ""]]}, {"id": "1906.05205", "submitter": "Deepak P", "authors": "Anish Mathew, Deepak P, Sahely Bhadra", "title": "Warping Resilient Time Series Embeddings", "comments": "Proceedings of the Time Series Workshop at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are ubiquitous in real world problems and computing distance\nbetween two time series is often required in several learning tasks. Computing\nsimilarity between time series by ignoring variations in speed or warping is\noften encountered and dynamic time warping (DTW) is the state of the art.\nHowever DTW is not applicable in algorithms which require kernel or vectors. In\nthis paper, we propose a mechanism named WaRTEm to generate vector embeddings\nof time series such that distance measures in the embedding space exhibit\nresilience to warping. Therefore, WaRTEm is more widely applicable than DTW.\nWaRTEm is based on a twin auto-encoder architecture and a training strategy\ninvolving warping operators for generating warping resilient embeddings for\ntime series datasets. We evaluate the performance of WaRTEm and observed more\nthan $20\\%$ improvement over DTW in multiple real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:20:52 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Mathew", "Anish", ""], ["P", "Deepak", ""], ["Bhadra", "Sahely", ""]]}, {"id": "1906.05212", "submitter": "Ellen de Mello Koch Ms", "authors": "Ellen de Mello Koch, Robert de Mello Koch, Ling Cheng", "title": "Is Deep Learning a Renormalization Group Flow?", "comments": "This article has been accepted for publication in a future issue of\n  this journal, but has not been fully edited. Content may change prior to\n  final publication. Citation information: DOI 10.1109/ACCESS.2020.3000901,\n  IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3000901", "report-no": null, "categories": "cs.LG cond-mat.stat-mech physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there has been a rapid development of practical applications,\ntheoretical explanations of deep learning are in their infancy. Deep learning\nperforms a sophisticated coarse graining. Since coarse graining is a key\ningredient of the renormalization group (RG), RG may provide a useful\ntheoretical framework directly relevant to deep learning. In this study we\npursue this possibility. A statistical mechanics model for a magnet, the Ising\nmodel, is used to train an unsupervised restricted Boltzmann machine (RBM). The\npatterns generated by the trained RBM are compared to the configurations\ngenerated through an RG treatment of the Ising model. Although we are motivated\nby the connection between deep learning and RG flow, in this study we focus\nmainly on comparing a single layer of a deep network to a single step in the RG\nflow. We argue that correlation functions between hidden and visible neurons\nare capable of diagnosing RG-like coarse graining. Numerical experiments show\nthe presence of RG-like patterns in correlators computed using the trained\nRBMs. The observables we consider are also able to exhibit important\ndifferences between RG and deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:33:43 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 07:51:51 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Koch", "Ellen de Mello", ""], ["Koch", "Robert de Mello", ""], ["Cheng", "Ling", ""]]}, {"id": "1906.05221", "submitter": "John Bradshaw", "authors": "John Bradshaw, Brooks Paige, Matt J. Kusner, Marwin H. S. Segler,\n  Jos\\'e Miguel Hern\\'andez-Lobato", "title": "A Model to Search for Synthesizable Molecules", "comments": "To appear in Advances in Neural Information Processing Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are able to suggest new organic molecules by\ngenerating strings, trees, and graphs representing their structure. While such\nmodels allow one to generate molecules with desirable properties, they give no\nguarantees that the molecules can actually be synthesized in practice. We\npropose a new molecule generation model, mirroring a more realistic real-world\nprocess, where (a) reactants are selected, and (b) combined to form more\ncomplex molecules. More specifically, our generative model proposes a bag of\ninitial reactants (selected from a pool of commercially-available molecules)\nand uses a reaction model to predict how they react together to generate new\nmolecules. We first show that the model can generate diverse, valid and unique\nmolecules due to the useful inductive biases of modeling reactions.\nFurthermore, our model allows chemists to interrogate not only the properties\nof the generated molecules but also the feasibility of the synthesis routes. We\nconclude by using our model to solve retrosynthesis problems, predicting a set\nof reactants that can produce a target product.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:53:47 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 16:29:54 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Bradshaw", "John", ""], ["Paige", "Brooks", ""], ["Kusner", "Matt J.", ""], ["Segler", "Marwin H. S.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1906.05243", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, Matteo Hessel, John Aslanides", "title": "When to use parametric models in reinforcement learning?", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the question of when and how parametric models are most useful in\nreinforcement learning. In particular, we look at commonalities and differences\nbetween parametric models and experience replay. Replay-based learning\nalgorithms share important traits with model-based approaches, including the\nability to plan: to use more computation without additional data to improve\npredictions and behaviour. We discuss when to expect benefits from either\napproach, and interpret prior work in this context. We hypothesise that, under\nsuitable conditions, replay-based algorithms should be competitive to or better\nthan model-based algorithms if the model is used only to generate fictional\ntransitions from observed states for an update rule that is otherwise\nmodel-free. We validated this hypothesis on Atari 2600 video games. The\nreplay-based algorithm attained state-of-the-art data efficiency, improving\nover prior results with parametric models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 16:57:00 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["van Hasselt", "Hado", ""], ["Hessel", "Matteo", ""], ["Aslanides", "John", ""]]}, {"id": "1906.05247", "submitter": "Botao Hao", "authors": "Botao Hao and Yasin Abbasi-Yadkori and Zheng Wen and Guang Cheng", "title": "Bootstrapping Upper Confidence Bound", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Upper Confidence Bound (UCB) method is arguably the most celebrated one used\nin online decision making with partial information feedback. Existing\ntechniques for constructing confidence bounds are typically built upon various\nconcentration inequalities, which thus lead to over-exploration. In this paper,\nwe propose a non-parametric and data-dependent UCB algorithm based on the\nmultiplier bootstrap. To improve its finite sample performance, we further\nincorporate second-order correction into the above construction. In theory, we\nderive both problem-dependent and problem-independent regret bounds for\nmulti-armed bandits under a much weaker tail assumption than the standard\nsub-Gaussianity. Numerical results demonstrate significant regret reductions by\nour method, in comparison with several baselines in a range of multi-armed and\nlinear bandit problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:11:41 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 17:06:01 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 01:15:32 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Hao", "Botao", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Wen", "Zheng", ""], ["Cheng", "Guang", ""]]}, {"id": "1906.05248", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "Multitask Learning for Network Traffic Classification", "comments": null, "journal-ref": null, "doi": "10.1109/ICCCN49398.2020.9209652", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic classification has various applications in today's Internet, from\nresource allocation, billing and QoS purposes in ISPs to firewall and malware\ndetection in clients. Classical machine learning algorithms and deep learning\nmodels have been widely used to solve the traffic classification task. However,\ntraining such models requires a large amount of labeled data. Labeling data is\noften the most difficult and time-consuming process in building a classifier.\nTo solve this challenge, we reformulate the traffic classification into a\nmulti-task learning framework where bandwidth requirement and duration of a\nflow are predicted along with the traffic class. The motivation of this\napproach is twofold: First, bandwidth requirement and duration are useful in\nmany applications, including routing, resource allocation, and QoS\nprovisioning. Second, these two values can be obtained from each flow easily\nwithout the need for human labeling or capturing flows in a controlled and\nisolated environment. We show that with a large amount of easily obtainable\ndata samples for bandwidth and duration prediction tasks, and only a few data\nsamples for the traffic classification task, one can achieve high accuracy. We\nconduct two experiment with ISCX and QUIC public datasets and show the efficacy\nof our approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:11:58 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 22:38:20 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "1906.05264", "submitter": "Michael Bohlke-Schneider", "authors": "Alexander Alexandrov, Konstantinos Benidis, Michael Bohlke-Schneider,\n  Valentin Flunkert, Jan Gasthaus, Tim Januschowski, Danielle C. Maddix, Syama\n  Rangapuram, David Salinas, Jasper Schulz, Lorenzo Stella, Ali Caner\n  T\\\"urkmen, Yuyang Wang", "title": "GluonTS: Probabilistic Time Series Models in Python", "comments": "ICML Time Series Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Gluon Time Series (GluonTS, available at\nhttps://gluon-ts.mxnet.io), a library for deep-learning-based time series\nmodeling. GluonTS simplifies the development of and experimentation with time\nseries models for common tasks such as forecasting or anomaly detection. It\nprovides all necessary components and tools that scientists need for quickly\nbuilding new models, for efficiently running and analyzing experiments and for\nevaluating model accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:44:53 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:26:38 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Alexandrov", "Alexander", ""], ["Benidis", "Konstantinos", ""], ["Bohlke-Schneider", "Michael", ""], ["Flunkert", "Valentin", ""], ["Gasthaus", "Jan", ""], ["Januschowski", "Tim", ""], ["Maddix", "Danielle C.", ""], ["Rangapuram", "Syama", ""], ["Salinas", "David", ""], ["Schulz", "Jasper", ""], ["Stella", "Lorenzo", ""], ["T\u00fcrkmen", "Ali Caner", ""], ["Wang", "Yuyang", ""]]}, {"id": "1906.05271", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman", "title": "Does Learning Require Memorization? A Short Tale about a Long Tail", "comments": "Significant revision: revised introduction/overview; added formal\n  treatment of noise in the labels and explanation for the disparate effects of\n  limiting memorization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art results on image recognition tasks are achieved using\nover-parameterized learning algorithms that (nearly) perfectly fit the training\nset and are known to fit well even random labels. This tendency to memorize the\nlabels of the training data is not explained by existing theoretical analyses.\nMemorization of the training data also presents significant privacy risks when\nthe training data contains sensitive personal information and thus it is\nimportant to understand whether such memorization is necessary for accurate\nlearning.\n  We provide the first conceptual explanation and a theoretical model for this\nphenomenon. Specifically, we demonstrate that for natural data distributions\nmemorization of labels is necessary for achieving close-to-optimal\ngeneralization error. Crucially, even labels of outliers and noisy labels need\nto be memorized. The model is motivated and supported by the results of several\nrecent empirical works. In our model, data is sampled from a mixture of\nsubpopulations and our results show that memorization is necessary whenever the\ndistribution of subpopulation frequencies is long-tailed. Image and text data\nis known to be long-tailed and therefore our results establish a formal link\nbetween these empirical phenomena. Our results allow to quantify the cost of\nlimiting memorization in learning and explain the disparate effects that\nprivacy and model compression have on different subgroups.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:53:25 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 06:06:39 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 08:38:53 GMT"}, {"version": "v4", "created": "Sun, 10 Jan 2021 07:19:48 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Feldman", "Vitaly", ""]]}, {"id": "1906.05274", "submitter": "Benjamin Eysenbach", "authors": "Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Eric Xing, Sergey\n  Levine, Ruslan Salakhutdinov", "title": "Efficient Exploration via State Marginal Matching", "comments": "Videos and code:\n  https://sites.google.com/view/state-marginal-matching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is critical to a reinforcement learning agent's performance in\nits given environment. Prior exploration methods are often based on using\nheuristic auxiliary predictions to guide policy behavior, lacking a\nmathematically-grounded objective with clear properties. In contrast, we recast\nexploration as a problem of State Marginal Matching (SMM), where we aim to\nlearn a policy for which the state marginal distribution matches a given target\nstate distribution. The target distribution is a uniform distribution in most\ncases, but can incorporate prior knowledge if available. In effect, SMM\namortizes the cost of learning to explore in a given environment. The SMM\nobjective can be viewed as a two-player, zero-sum game between a state density\nmodel and a parametric policy, an idea that we use to build an algorithm for\noptimizing the SMM objective. Using this formalism, we further demonstrate that\nprior work approximately maximizes the SMM objective, offering an explanation\nfor the success of these methods. On both simulated and real-world tasks, we\ndemonstrate that agents that directly optimize the SMM objective explore faster\nand adapt more quickly to new tasks as compared to prior exploration methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:57:02 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 13:17:24 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 16:02:59 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lee", "Lisa", ""], ["Eysenbach", "Benjamin", ""], ["Parisotto", "Emilio", ""], ["Xing", "Eric", ""], ["Levine", "Sergey", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1906.05301", "submitter": "Zohar Ringel", "authors": "Omry Cohen, Or Malka, and Zohar Ringel", "title": "Learning Curves for Deep Neural Networks: A Gaussian Field Theory\n  Perspective", "comments": null, "journal-ref": "Phys. Rev. Research 3, 023034 (2021)", "doi": "10.1103/PhysRevResearch.3.023034", "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, deep neural networks (DNNs) came to the fore as the\nleading machine learning algorithms for a variety of tasks. Their raise was\nfounded on market needs and engineering craftsmanship, the latter based more on\ntrial and error than on theory. While still far behind the application\nforefront, the theoretical study of DNNs has recently made important\nadvancements in analyzing the highly over-parameterized regime where some exact\nresults have been obtained. Leveraging these ideas and adopting a more\nphysics-like approach, here we construct a versatile field-theory formalism for\nsupervised deep learning, involving renormalization group, Feynman diagrams and\nreplicas. In particular we show that our approach leads to highly accurate\npredictions of learning curves of truly deep DNNs trained on polynomial\nregression tasks and that these predictions can be used for efficient\nhyper-parameter optimization. In addition, they explain how DNNs generalize\nwell despite being highly over-parameterized, this due to an entropic bias to\nsimple functions which, for the case of fully-connected DNNs with data sampled\non the hypersphere, are low order polynomials in the input vector. Being a\ncomplex interacting system of artificial neurons, we believe that such tools\nand methodologies borrowed from condensed matter physics would prove essential\nfor obtaining an accurate quantitative understanding of deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:00:10 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 07:25:52 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 14:22:48 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 12:02:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Cohen", "Omry", ""], ["Malka", "Or", ""], ["Ringel", "Zohar", ""]]}, {"id": "1906.05323", "submitter": "Mahesh Subedar", "authors": "Ranganath Krishnan and Mahesh Subedar and Omesh Tickoo", "title": "Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical\n  Bayes", "comments": "To be published at AAAI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference for Bayesian deep neural network (DNN)\nrequires specifying priors and approximate posterior distributions over neural\nnetwork weights. Specifying meaningful weight priors is a challenging problem,\nparticularly for scaling variational inference to deeper architectures\ninvolving high dimensional weight space. We propose MOdel Priors with Empirical\nBayes using DNN (MOPED) method to choose informed weight priors in Bayesian\nneural networks. We formulate a two-stage hierarchical modeling, first find the\nmaximum likelihood estimates of weights with DNN, and then set the weight\npriors using empirical Bayes approach to infer the posterior with variational\ninference. We empirically evaluate the proposed approach on real-world tasks\nincluding image classification, video activity recognition and audio\nclassification with varying complex neural network architectures. We also\nevaluate our proposed approach on diabetic retinopathy diagnosis task and\nbenchmark with the state-of-the-art Bayesian deep learning techniques. We\ndemonstrate MOPED method enables scalable variational inference and provides\nreliable uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:26:52 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:50:23 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 15:09:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Krishnan", "Ranganath", ""], ["Subedar", "Mahesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1906.05329", "submitter": "Tom Jurgenson", "authors": "Tom Jurgenson, Edward Groshev, Aviv Tamar", "title": "Sub-Goal Trees -- a Framework for Goal-Directed Trajectory Prediction\n  and Optimization", "comments": "15 pages (8 main), 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI problems, in robotics and other domains, are goal-directed,\nessentially seeking a trajectory leading to some goal state. In such problems,\nthe way we choose to represent a trajectory underlies algorithms for trajectory\nprediction and optimization. Interestingly, most all prior work in imitation\nand reinforcement learning builds on a sequential trajectory representation --\ncalculating the next state in the trajectory given its predecessors. We propose\na different perspective: a goal-conditioned trajectory can be represented by\nfirst selecting an intermediate state between start and goal, partitioning the\ntrajectory into two. Then, recursively, predicting intermediate points on each\nsub-segment, until a complete trajectory is obtained. We call this\nrepresentation a sub-goal tree, and building on it, we develop new methods for\ntrajectory prediction, learning, and optimization. We show that in a supervised\nlearning setting, sub-goal trees better account for trajectory variability, and\ncan predict trajectories exponentially faster at test time by leveraging a\nconcurrent computation. Then, for optimization, we derive a new dynamic\nprogramming equation for sub-goal trees, and use it to develop new planning and\nreinforcement learning algorithms. These algorithms, which are not based on the\nstandard Bellman equation, naturally account for hierarchical sub-goal\nstructure in a task. Empirical results on motion planning domains show that the\nsub-goal tree framework significantly improves both accuracy and prediction\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 19:06:51 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Jurgenson", "Tom", ""], ["Groshev", "Edward", ""], ["Tamar", "Aviv", ""]]}, {"id": "1906.05330", "submitter": "Harikrishna Narasimhan", "authors": "Harikrishna Narasimhan, Andrew Cotter, Maya Gupta, Serena Wang", "title": "Pairwise Fairness for Ranking and Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present pairwise fairness metrics for ranking models and regression models\nthat form analogues of statistical fairness notions such as equal opportunity,\nequal accuracy, and statistical parity. Our pairwise formulation supports both\ndiscrete protected groups, and continuous protected attributes. We show that\nthe resulting training problems can be efficiently and effectively solved using\nexisting constrained optimization and robust optimization techniques developed\nfor fair classification. Experiments illustrate the broad applicability and\ntrade-offs of these methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 19:09:48 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 21:56:17 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 17:04:06 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""], ["Gupta", "Maya", ""], ["Wang", "Serena", ""]]}, {"id": "1906.05346", "submitter": "Yin Xian", "authors": "Jian-Feng Cai, Lizhang Miao, Yang Wang and Yin Xian", "title": "Optimal low rank tensor recovery", "comments": "There is an error in the paper and need to be correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sample size requirement for exact recovery of a high order\ntensor of low rank from a subset of its entries. In the Tucker decomposition\nframework, we show that the Riemannian optimization algorithm with initial\nvalue obtained from a spectral method can reconstruct a tensor of size $n\\times\nn \\times\\cdots \\times n$ tensor of ranks $(r,\\cdots,r)$ with high probability\nfrom as few as $O((r^d+dnr)\\log(d))$ entries. In the case of order 3 tensor,\nthe entries can be asymptotically as few as $O(nr)$ for a low rank large\ntensor. We show the theoretical guarantee condition for the recovery. The\nanalysis relies on the tensor restricted isometry property (tensor RIP) and the\ncurvature of the low rank tensor manifold. Our algorithm is computationally\nefficient and easy to implement. Numerical results verify that the algorithms\nare able to recover a low rank tensor from minimum number of measurements. The\nexperiments on hyperspectral images recovery also show that our algorithm is\ncapable of real world signal processing problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 19:37:40 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 22:48:22 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 19:41:23 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cai", "Jian-Feng", ""], ["Miao", "Lizhang", ""], ["Wang", "Yang", ""], ["Xian", "Yin", ""]]}, {"id": "1906.05358", "submitter": "You-Lin Chen", "authors": "You-Lin Chen and Mladen Kolar and Ruey S. Tsay", "title": "Tensor Canonical Correlation Analysis with Convergence and Statistical\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, such as classification of images or videos, it is of\ninterest to develop a framework for tensor data instead of an ad-hoc way of\ntransforming data to vectors due to the computational and under-sampling\nissues. In this paper, we study convergence and statistical properties of\ntwo-dimensional canonical correlation analysis \\citep{Lee2007Two} under an\nassumption that data come from a probabilistic model. We show that carefully\ninitialized the power method converges to the optimum and provide a finite\nsample bound. Then we extend this framework to tensor-valued data and propose\nthe higher-order power method, which is commonly used in tensor decomposition,\nto extract the canonical directions. Our method can be used effectively in a\nlarge-scale data setting by solving the inner least squares problem with a\nstochastic gradient descent, and we justify convergence via the theory of\nLojasiewicz's inequalities without any assumption on data generating process\nand initialization. For practical applications, we further develop (a) an\ninexact updating scheme which allows us to use the state-of-the-art stochastic\ngradient descent algorithm, (b) an effective initialization scheme which\nalleviates the problem of local optimum in non-convex optimization, and (c) a\ndeflation procedure for extracting several canonical components. Empirical\nanalyses on challenging data including gene expression and air pollution\nindexes in Taiwan, show the effectiveness and efficiency of the proposed\nmethodology. Our results fill a missing, but crucial, part in the literature on\ntensor data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 19:54:34 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 20:20:57 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 23:02:56 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 23:00:39 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Chen", "You-Lin", ""], ["Kolar", "Mladen", ""], ["Tsay", "Ruey S.", ""]]}, {"id": "1906.05360", "submitter": "Mason Chen", "authors": "Mason T. Chen, Faisal Mahmood, Jordan A. Sweer, and Nicholas J. Durr", "title": "GANPOP: Generative Adversarial Network Prediction of Optical Properties\n  from Single Snapshot Wide-field Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning framework for wide-field, content-aware estimation\nof absorption and scattering coefficients of tissues, called Generative\nAdversarial Network Prediction of Optical Properties (GANPOP). Spatial\nfrequency domain imaging is used to obtain ground-truth optical properties from\nin vivo human hands, freshly resected human esophagectomy samples and\nhomogeneous tissue phantoms. Images of objects with either flat-field or\nstructured illumination are paired with registered optical property maps and\nare used to train conditional generative adversarial networks that estimate\noptical properties from a single input image. We benchmark this approach by\ncomparing GANPOP to a single-snapshot optical property (SSOP) technique, using\na normalized mean absolute error (NMAE) metric. In human gastrointestinal\nspecimens, GANPOP estimates both reduced scattering and absorption coefficients\nat 660 nm from a single 0.2/mm spatial frequency illumination image with 58%\nhigher accuracy than SSOP. When applied to both in vivo and ex vivo swine\ntissues, a GANPOP model trained solely on human specimens and phantoms\nestimates optical properties with approximately 43% improvement over SSOP,\nindicating adaptability to sample variety. Moreover, we demonstrate that GANPOP\nestimates optical properties from flat-field illumination images with similar\nerror to SSOP, which requires structured-illumination. Given a training set\nthat appropriately spans the target domain, GANPOP has the potential to enable\nrapid and accurate wide-field measurements of optical properties, even from\nconventional imaging systems with flat-field illumination.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 19:55:49 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 18:04:02 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Chen", "Mason T.", ""], ["Mahmood", "Faisal", ""], ["Sweer", "Jordan A.", ""], ["Durr", "Nicholas J.", ""]]}, {"id": "1906.05363", "submitter": "Lydia T. Liu", "authors": "Lydia T. Liu, Horia Mania, Michael I. Jordan", "title": "Competing Bandits in Matching Markets", "comments": "15 pages, 3 figures. A version appears in the Proceedings of The 23nd\n  International Conference on Artificial Intelligence and Statistics (AISTATS),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stable matching, a classical model for two-sided markets, has long been\nstudied with little consideration for how each side's preferences are learned.\nWith the advent of massive online markets powered by data-driven matching\nplatforms, it has become necessary to better understand the interplay between\nlearning and market objectives. We propose a statistical learning model in\nwhich one side of the market does not have a priori knowledge about its\npreferences for the other side and is required to learn these from stochastic\nrewards. Our model extends the standard multi-armed bandits framework to\nmultiple players, with the added feature that arms have preferences over\nplayers. We study both centralized and decentralized approaches to this problem\nand show surprising exploration-exploitation trade-offs compared to the single\nplayer multi-armed bandits setting.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:04:25 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 21:48:30 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Liu", "Lydia T.", ""], ["Mania", "Horia", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.05370", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Yuhao Zhou, Sanja Fidler, Jimmy Ba", "title": "Neural Graph Evolution: Towards Efficient Automatic Robot Design", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the recent successes in robotic locomotion control, the design of\nrobot relies heavily on human engineering. Automatic robot design has been a\nlong studied subject, but the recent progress has been slowed due to the large\ncombinatorial search space and the difficulty in evaluating the found\ncandidates. To address the two challenges, we formulate automatic robot design\nas a graph search problem and perform evolution search in graph space. We\npropose Neural Graph Evolution (NGE), which performs selection on current\ncandidates and evolves new ones iteratively. Different from previous\napproaches, NGE uses graph neural networks to parameterize the control\npolicies, which reduces evaluation cost on new candidates with the help of\nskill transfer from previously evaluated designs. In addition, NGE applies\nGraph Mutation with Uncertainty (GM-UC) by incorporating model uncertainty,\nwhich reduces the search space by balancing exploration and exploitation. We\nshow that NGE significantly outperforms previous methods by an order of\nmagnitude. As shown in experiments, NGE is the first algorithm that can\nautomatically discover kinematically preferred robotic graph structures, such\nas a fish with two symmetrical flat side-fins and a tail, or a cheetah with\nathletic front and back legs. Instead of using thousands of cores for weeks,\nNGE efficiently solves searching problem within a day on a single 64 CPU-core\nAmazon EC2 machine.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:41:18 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Wang", "Tingwu", ""], ["Zhou", "Yuhao", ""], ["Fidler", "Sanja", ""], ["Ba", "Jimmy", ""]]}, {"id": "1906.05374", "submitter": "Sarah Bechtle", "authors": "Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette,\n  Ludovic Righetti, Gaurav Sukhatme, Franziska Meier", "title": "Meta-Learning via Learned Loss", "comments": "Project website with code and video at\n  https://sites.google.com/view/mlthree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, loss functions, regularization mechanisms and other important\naspects of training parametric models are chosen heuristically from a limited\nset of options. In this paper, we take the first step towards automating this\nprocess, with the view of producing models which train faster and more\nrobustly. Concretely, we present a meta-learning method for learning parametric\nloss functions that can generalize across different tasks and model\narchitectures. We develop a pipeline for meta-training such loss functions,\ntargeted at maximizing the performance of the model trained under them. The\nloss landscape produced by our learned losses significantly improves upon the\noriginal task-specific losses in both supervised and reinforcement learning\ntasks. Furthermore, we show that our meta-learning framework is flexible enough\nto incorporate additional information at meta-train time. This information\nshapes the learned loss function such that the environment does not need to\nprovide this information during meta-test time. We make our code available at\nhttps://sites.google.com/view/mlthree.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:55:18 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 01:44:23 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 22:48:48 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 17:00:54 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Bechtle", "Sarah", ""], ["Molchanov", "Artem", ""], ["Chebotar", "Yevgen", ""], ["Grefenstette", "Edward", ""], ["Righetti", "Ludovic", ""], ["Sukhatme", "Gaurav", ""], ["Meier", "Franziska", ""]]}, {"id": "1906.05392", "submitter": "Samet Oymak", "authors": "Samet Oymak, Zalan Fabian, Mingchen Li, Mahdi Soltanolkotabi", "title": "Generalization Guarantees for Neural Networks via Harnessing the\n  Low-rank Structure of the Jacobian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural network architectures often generalize well despite containing\nmany more parameters than the size of the training dataset. This paper explores\nthe generalization capabilities of neural networks trained via gradient\ndescent. We develop a data-dependent optimization and generalization theory\nwhich leverages the low-rank structure of the Jacobian matrix associated with\nthe network. Our results help demystify why training and generalization is\neasier on clean and structured datasets and harder on noisy and unstructured\ndatasets as well as how the network size affects the evolution of the train and\ntest errors during training. Specifically, we use a control knob to split the\nJacobian spectum into \"information\" and \"nuisance\" spaces associated with the\nlarge and small singular values. We show that over the information space\nlearning is fast and one can quickly train a model with zero training loss that\ncan also generalize well. Over the nuisance space training is slower and early\nstopping can help with generalization at the expense of some bias. We also show\nthat the overall generalization capability of the network is controlled by how\nwell the label vector is aligned with the information space. A key feature of\nour results is that even constant width neural nets can provably generalize for\nsufficiently nice datasets. We conduct various numerical experiments on deep\nnetworks that corroborate our theoretical findings and demonstrate that: (i)\nthe Jacobian of typical neural networks exhibit low-rank structure with a few\nlarge singular values and many small ones leading to a low-dimensional\ninformation space, (ii) over the information space learning is fast and most of\nthe label vector falls on this space, and (iii) label noise falls on the\nnuisance space and impedes optimization/generalization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:39:06 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 00:17:07 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Oymak", "Samet", ""], ["Fabian", "Zalan", ""], ["Li", "Mingchen", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1906.05413", "submitter": "Joshua Robinson", "authors": "Joshua Robinson, Suvrit Sra, Stefanie Jegelka", "title": "Flexible Modeling of Diversity with Strongly Log-Concave Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strongly log-concave (SLC) distributions are a rich class of discrete\nprobability distributions over subsets of some ground set. They are strictly\nmore general than strongly Rayleigh (SR) distributions such as the well-known\ndeterminantal point process. While SR distributions offer elegant models of\ndiversity, they lack an easy control over how they express diversity. We\npropose SLC as the right extension of SR that enables easier, more intuitive\ncontrol over diversity, illustrating this via examples of practical importance.\nWe develop two fundamental tools needed to apply SLC distributions to learning\nand inference: sampling and mode finding. For sampling we develop an MCMC\nsampler and give theoretical mixing time bounds. For mode finding, we establish\na weak log-submodularity property for SLC functions and derive optimization\nguarantees for a distorted greedy algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 22:44:17 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Robinson", "Joshua", ""], ["Sra", "Suvrit", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1906.05419", "submitter": "Erik Englesson", "authors": "Erik Englesson, Hossein Azizpour", "title": "Efficient Evaluation-Time Uncertainty Estimation by Improved\n  Distillation", "comments": "Submitted at the ICML 2019 Workshop on Uncertainty & Robustness in\n  Deep Learning(poster & spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we aim to obtain computationally-efficient uncertainty estimates\nwith deep networks. For this, we propose a modified knowledge distillation\nprocedure that achieves state-of-the-art uncertainty estimates both for in and\nout-of-distribution samples. Our contributions include a) demonstrating and\nadapting to distillation's regularization effect b) proposing a novel target\nteacher distribution c) a simple augmentation procedure to improve\nout-of-distribution uncertainty estimates d) shedding light on the distillation\nprocedure through comprehensive set of experiments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 23:09:59 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Englesson", "Erik", ""], ["Azizpour", "Hossein", ""]]}, {"id": "1906.05423", "submitter": "Natasa Tagasovska", "authors": "Natasa Tagasovska, Damien Ackerer, Thibault Vatter", "title": "Copulas as High-Dimensional Generative Models: Vine Copula Autoencoders", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32, pages:\n  6525--6537, year: 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the vine copula autoencoder (VCAE), a flexible generative model\nfor high-dimensional distributions built in a straightforward three-step\nprocedure.\n  First, an autoencoder (AE) compresses the data into a lower dimensional\nrepresentation. Second, the multivariate distribution of the encoded data is\nestimated with vine copulas. Third, a generative model is obtained by combining\nthe estimated distribution with the decoder part of the AE. As such, the\nproposed approach can transform any already trained AE into a flexible\ngenerative model at a low computational cost. This is an advantage over\nexisting generative models such as adversarial networks and variational AEs\nwhich can be difficult to train and can impose strong assumptions on the latent\nspace. Experiments on MNIST, Street View House Numbers and Large-Scale\nCelebFaces Attributes datasets show that VCAEs can achieve competitive results\nto standard baselines.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 23:29:17 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:12:33 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tagasovska", "Natasa", ""], ["Ackerer", "Damien", ""], ["Vatter", "Thibault", ""]]}, {"id": "1906.05431", "submitter": "Arip Asadulaev", "authors": "Arip Asadulaev, Igor Kuznetsov, Andrey Filchenkov", "title": "Interpretable Few-Shot Learning via Linear Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to develop mathematically tractable models than can interpret\nknowledge extracted from the data and provide reasonable predictions. In this\npaper, we present a Linear Distillation Learning, a simple remedy to improve\nthe performance of linear neural networks. Our approach is based on using a\nlinear function for each class in a dataset, which is trained to simulate the\noutput of a teacher linear network for each class separately. We tested our\nmodel on MNIST and Omniglot datasets in the Few-Shot learning manner. It showed\nbetter results than other interpretable models such as classical Logistic\nRegression.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 00:20:30 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 20:56:12 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Asadulaev", "Arip", ""], ["Kuznetsov", "Igor", ""], ["Filchenkov", "Andrey", ""]]}, {"id": "1906.05433", "submitter": "David Rolnick", "authors": "David Rolnick, Priya L. Donti, Lynn H. Kaack, Kelly Kochanski,\n  Alexandre Lacoste, Kris Sankaran, Andrew Slavin Ross, Nikola\n  Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, Alexandra Luccioni,\n  Tegan Maharaj, Evan D. Sherwin, S. Karthik Mukkavilli, Konrad P. Kording,\n  Carla Gomes, Andrew Y. Ng, Demis Hassabis, John C. Platt, Felix Creutzig,\n  Jennifer Chayes, Yoshua Bengio", "title": "Tackling Climate Change with Machine Learning", "comments": "For additional resources, please visit the website that accompanies\n  this paper: https://www.climatechange.ai/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change is one of the greatest challenges facing humanity, and we, as\nmachine learning experts, may wonder how we can help. Here we describe how\nmachine learning can be a powerful tool in reducing greenhouse gas emissions\nand helping society adapt to a changing climate. From smart grids to disaster\nmanagement, we identify high impact problems where existing gaps can be filled\nby machine learning, in collaboration with other fields. Our recommendations\nencompass exciting research questions as well as promising business\nopportunities. We call on the machine learning community to join the global\neffort against climate change.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:51:47 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 17:37:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Rolnick", "David", ""], ["Donti", "Priya L.", ""], ["Kaack", "Lynn H.", ""], ["Kochanski", "Kelly", ""], ["Lacoste", "Alexandre", ""], ["Sankaran", "Kris", ""], ["Ross", "Andrew Slavin", ""], ["Milojevic-Dupont", "Nikola", ""], ["Jaques", "Natasha", ""], ["Waldman-Brown", "Anna", ""], ["Luccioni", "Alexandra", ""], ["Maharaj", "Tegan", ""], ["Sherwin", "Evan D.", ""], ["Mukkavilli", "S. Karthik", ""], ["Kording", "Konrad P.", ""], ["Gomes", "Carla", ""], ["Ng", "Andrew Y.", ""], ["Hassabis", "Demis", ""], ["Platt", "John C.", ""], ["Creutzig", "Felix", ""], ["Chayes", "Jennifer", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.05437", "submitter": "Arip Asadulaev", "authors": "Arip Asadulaev, Igor Kuznetsov, Gideon Stein, Andrey Filchenkov", "title": "Conditioning of Reinforcement Learning Agents and its Policy\n  Regularization Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outcome of Jacobian singular values regularization was studied for\nsupervised learning problems. It also was shown that Jacobian conditioning\nregularization can help to avoid the ``mode-collapse'' problem in Generative\nAdversarial Networks. In this paper, we try to answer the following question:\nCan information about policy conditioning help to shape a more stable and\ngeneral policy of reinforcement learning agents? To answer this question, we\nconduct a study of Jacobian conditioning behavior during policy optimization.\nTo the best of our knowledge, this is the first work that research condition\nnumber in reinforcement learning agents. We propose a conditioning\nregularization algorithm and test its performance on the range of continuous\ncontrol tasks. Finally, we compare algorithms on the CoinRun environment with\nseparated train end test levels to analyze how conditioning regularization\ncontributes to agents' generalization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 00:52:56 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 20:30:12 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Asadulaev", "Arip", ""], ["Kuznetsov", "Igor", ""], ["Stein", "Gideon", ""], ["Filchenkov", "Andrey", ""]]}, {"id": "1906.05440", "submitter": "Shufei Ge", "authors": "Shufei Ge, Shijia Wang, Yee Whye Teh, Liangliang Wang, Lloyd T.\n  Elliott", "title": "Random Tessellation Forests", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space partitioning methods such as random forests and the Mondrian process\nare powerful machine learning methods for multi-dimensional and relational\ndata, and are based on recursively cutting a domain. The flexibility of these\nmethods is often limited by the requirement that the cuts be axis aligned. The\nOstomachion process and the self-consistent binary space partitioning-tree\nprocess were recently introduced as generalizations of the Mondrian process for\nspace partitioning with non-axis aligned cuts in the two dimensional plane.\nMotivated by the need for a multi-dimensional partitioning tree with non-axis\naligned cuts, we propose the Random Tessellation Process (RTP), a framework\nthat includes the Mondrian process and the binary space partitioning-tree\nprocess as special cases. We derive a sequential Monte Carlo algorithm for\ninference, and provide random forest methods. Our process is self-consistent\nand can relax axis-aligned constraints, allowing complex inter-dimensional\ndependence to be captured. We present a simulation study, and analyse gene\nexpression data of brain tissue, showing improved accuracies over other\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 01:07:08 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 22:32:34 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 04:50:05 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 19:17:09 GMT"}, {"version": "v5", "created": "Mon, 2 Dec 2019 02:47:48 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ge", "Shufei", ""], ["Wang", "Shijia", ""], ["Teh", "Yee Whye", ""], ["Wang", "Liangliang", ""], ["Elliott", "Lloyd T.", ""]]}, {"id": "1906.05449", "submitter": "Radha Kopparti", "authors": "Radha Kopparti and Tillman Weyde", "title": "Factors for the Generalisation of Identity Relations by Neural Networks", "comments": "ICML 2019 Workshop on Understanding and Improving Generalization in\n  Deep Learning}, Long Beach, California, 2019", "journal-ref": "ICML 2019 Workshop on Understanding and Improving Generalization\n  in Deep Learning}, Long Beach, California, 201", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many researchers implicitly assume that neural networks learn relations and\ngeneralise them to new unseen data. It has been shown recently, however, that\nthe generalisation of feed-forward networks fails for identity relations.The\nproposed solution for this problem is to create an inductive bias with\nDifferential Rectifier (DR) units. In this work we explore various factors in\nthe neural network architecture and learning process whether they make a\ndifference to the generalisation on equality detection of Neural Networks\nwithout and and with DR units in early and mid fusion architectures.\n  We find in experiments with synthetic data effects of the number of hidden\nlayers, the activation function and the data representation. The training set\nsize in relation to the total possible set of vectors also makes a difference.\nHowever, the accuracy never exceeds 61% without DR units at 50% chance level.\nDR units improve generalisation in all tasks and lead to almost perfect test\naccuracy in the Mid Fusion setting. Thus, DR units seem to be a promising\napproach for creating generalisation abilities that standard networks lack.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 01:36:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Kopparti", "Radha", ""], ["Weyde", "Tillman", ""]]}, {"id": "1906.05462", "submitter": "William Harvey", "authors": "William Harvey, Michael Teng, Frank Wood", "title": "Near-Optimal Glimpse Sequences for Improved Hard Attention Neural\n  Network Training", "comments": "11 pages, 6 figures + appendix with 9 pages, 7 figures.Submitted to\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard visual attention is a promising approach to reduce the computational\nburden of modern computer vision methodologies. Hard attention mechanisms are\ntypically non-differentiable. They can be trained with reinforcement learning\nbut the high-variance training this entails hinders more widespread\napplication. We show how hard attention for image classification can be framed\nas a Bayesian optimal experimental design (BOED) problem. From this\nperspective, the optimal locations to attend to are those which provide the\ngreatest expected reduction in the entropy of the classification distribution.\nWe introduce methodology from the BOED literature to approximate this optimal\nbehaviour, and use it to generate `near-optimal' sequences of attention\nlocations. We then show how to use such sequences to partially supervise, and\ntherefore speed up, the training of a hard attention mechanism. Although\ngenerating these sequences is computationally expensive, they can be reused by\nany other networks later trained on the same task.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 03:01:04 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 18:49:31 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Harvey", "William", ""], ["Teng", "Michael", ""], ["Wood", "Frank", ""]]}, {"id": "1906.05467", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Shuang Li, Zhigang Peng, Yao Xie", "title": "Imitation Learning of Neural Spatio-Temporal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel Neural Embedding Spatio-Temporal (NEST) point process\nmodel for spatio-temporal discrete event data and develop an efficient\nimitation learning (a type of reinforcement learning) based approach for model\nfitting. Despite the rapid development of one-dimensional temporal point\nprocesses for discrete event data, the study of spatial-temporal aspects of\nsuch data is relatively scarce. Our model captures complex spatio-temporal\ndependence between discrete events by carefully design a mixture of\nheterogeneous Gaussian diffusion kernels, whose parameters are parameterized by\nneural networks. This new kernel is the key that our model can capture\nintricate spatial dependence patterns and yet still lead to interpretable\nresults as we examine maps of Gaussian diffusion kernel parameters. The\nimitation learning model fitting for the NEST is more robust than the maximum\nlikelihood estimate. It directly measures the divergence between the empirical\ndistributions between the training data and the model-generated data. Moreover,\nour imitation learning-based approach enjoys computational efficiency due to\nthe explicit characterization of the reward function related to the likelihood\nfunction; furthermore, the likelihood function under our model enjoys tractable\nexpression due to Gaussian kernel parameterization. Experiments based on real\ndata show our method's good performance relative to the state-of-the-art and\nthe good interpretability of NEST's result.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 03:48:19 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:53:00 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 03:06:41 GMT"}, {"version": "v4", "created": "Fri, 22 Jan 2021 18:43:16 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Zhu", "Shixiang", ""], ["Li", "Shuang", ""], ["Peng", "Zhigang", ""], ["Xie", "Yao", ""]]}, {"id": "1906.05473", "submitter": "Jean Feng", "authors": "Jean Feng, Arjun Sondhi, Jessica Perry, Noah Simon", "title": "Selective prediction-set models with coverage guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though black-box predictors are state-of-the-art for many complex tasks, they\noften fail to properly quantify predictive uncertainty and may provide\ninappropriate predictions for unfamiliar data. Instead, we can learn more\nreliable models by letting them either output a prediction set or abstain when\nthe uncertainty is high. We propose training these selective prediction-set\nmodels using an uncertainty-aware loss minimization framework, which unifies\nideas from decision theory and robust maximum likelihood. Moreover, since\nblack-box methods are not guaranteed to output well-calibrated prediction sets,\nwe show how to calculate point estimates and confidence intervals for the true\ncoverage of any selective prediction-set model, as well as a uniform mixture of\nK set models obtained from K-fold sample-splitting. When applied to predicting\nin-hospital mortality and length-of-stay for ICU patients, our model\noutperforms existing approaches on both in-sample and out-of-sample age groups,\nand our recalibration method provides accurate inference for prediction set\ncoverage.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 04:05:27 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Feng", "Jean", ""], ["Sondhi", "Arjun", ""], ["Perry", "Jessica", ""], ["Simon", "Noah", ""]]}, {"id": "1906.05478", "submitter": "Sreyas Mohan", "authors": "Sreyas Mohan, Zahra Kadkhodaie, Eero P. Simoncelli and Carlos\n  Fernandez-Granda", "title": "Robust and interpretable blind image denoising via bias-free\n  convolutional neural networks", "comments": "Published as conference paper in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional networks often append additive constant (\"bias\") terms to\ntheir convolution operations, enabling a richer repertoire of functional\nmappings. Biases are also used to facilitate training, by subtracting mean\nresponse over batches of training images (a component of \"batch\nnormalization\"). Recent state-of-the-art blind denoising methods (e.g., DnCNN)\nseem to require these terms for their success. Here, however, we show that\nthese networks systematically overfit the noise levels for which they are\ntrained: when deployed at noise levels outside the training range, performance\ndegrades dramatically. In contrast, a bias-free architecture -- obtained by\nremoving the constant terms in every layer of the network, including those used\nfor batch normalization-- generalizes robustly across noise levels, while\npreserving state-of-the-art performance within the training range. Locally, the\nbias-free network acts linearly on the noisy image, enabling direct analysis of\nnetwork behavior via standard linear-algebraic tools. These analyses provide\ninterpretations of network functionality in terms of nonlinear adaptive\nfiltering, and projection onto a union of low-dimensional subspaces, connecting\nthe learning-based method to more traditional denoising methodology.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 04:48:21 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 03:18:09 GMT"}, {"version": "v3", "created": "Sat, 8 Feb 2020 05:55:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mohan", "Sreyas", ""], ["Kadkhodaie", "Zahra", ""], ["Simoncelli", "Eero P.", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "1906.05488", "submitter": "Pengfei Chen", "authors": "Pengfei Chen, Weiwen Liu, Chang-Yu Hsieh, Guangyong Chen, Shengyu\n  Zhang", "title": "Utilizing Edge Features in Graph Neural Networks via Variational\n  Information Maximization", "comments": "1. Pengfei Chen and Weiwen Liu have equal contribution. 2.\n  Correspondence to: Guangyong Chen <gycchen@tencent.com>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) achieve an impressive performance on structured\ngraphs by recursively updating the representation vector of each node based on\nits neighbors, during which parameterized transformation matrices should be\nlearned for the node feature updating. However, existing propagation schemes\nare far from being optimal since they do not fully utilize the relational\ninformation between nodes. We propose the information maximizing graph neural\nnetworks (IGNN), which maximizes the mutual information between edge states and\ntransform parameters. We reformulate the mutual information as a differentiable\nobjective via a variational approach. We compare our model against several\nrecent variants of GNNs and show that our model achieves the state-of-the-art\nperformance on multiple tasks including quantum chemistry regression on QM9\ndataset, generalization capability from QM9 to larger molecular graphs, and\nprediction of molecular bioactivities relevant for drug discovery. The IGNN\nmodel is based on an elegant and fundamental idea in information theory as\nexplained in the main text, and it could be easily generalized beyond the\ncontexts of molecular graphs considered in this work. To encourage more future\nwork in this area, all datasets and codes used in this paper will be released\nfor public access.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:36:56 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Chen", "Pengfei", ""], ["Liu", "Weiwen", ""], ["Hsieh", "Chang-Yu", ""], ["Chen", "Guangyong", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1906.05489", "submitter": "Zhengxiao Du", "authors": "Zhengxiao Du, Chang Zhou, Ming Ding, Hongxia Yang, Jie Tang", "title": "Cognitive Knowledge Graph Reasoning for One-shot Relational Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring new facts from existing knowledge graphs (KG) with explainable\nreasoning processes is a significant problem and has received much attention\nrecently. However, few studies have focused on relation types unseen in the\noriginal KG, given only one or a few instances for training. To bridge this\ngap, we propose CogKR for one-shot KG reasoning. The one-shot relational\nlearning problem is tackled through two modules: the summary module summarizes\nthe underlying relationship of the given instances, based on which the\nreasoning module infers the correct answers. Motivated by the dual process\ntheory in cognitive science, in the reasoning module, a cognitive graph is\nbuilt by iteratively coordinating retrieval (System 1, collecting relevant\nevidence intuitively) and reasoning (System 2, conducting relational reasoning\nover collected information). The structural information offered by the\ncognitive graph enables our model to aggregate pieces of evidence from multiple\nreasoning paths and explain the reasoning process graphically. Experiments show\nthat CogKR substantially outperforms previous state-of-the-art models on\none-shot KG reasoning benchmarks, with relative improvements of 24.3%-29.7% on\nMRR. The source code is available at https://github.com/THUDM/CogKR.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:39:42 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Du", "Zhengxiao", ""], ["Zhou", "Chang", ""], ["Ding", "Ming", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1906.05509", "submitter": "Pengfei Chen", "authors": "Pengfei Chen, Benben Liao, Guangyong Chen, Shengyu Zhang", "title": "A Meta Approach to Defend Noisy Labels by the Manifold Regularizer PSDR", "comments": "Correspondence to: Guangyong Chen <gycchen@tencent.com>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labels are ubiquitous in real-world datasets, which poses a challenge\nfor robustly training deep neural networks (DNNs) since DNNs can easily overfit\nto the noisy labels. Most recent efforts have been devoted to defending noisy\nlabels by discarding noisy samples from the training set or assigning weights\nto training samples, where the weight associated with a noisy sample is\nexpected to be small. Thereby, these previous efforts result in a waste of\nsamples, especially those assigned with small weights. The input $x$ is always\nuseful regardless of whether its observed label $y$ is clean. To make full use\nof all samples, we introduce a manifold regularizer, named as Paired Softmax\nDivergence Regularization (PSDR), to penalize the Kullback-Leibler (KL)\ndivergence between softmax outputs of similar inputs. In particular, similar\ninputs can be effectively generated by data augmentation. PSDR can be easily\nimplemented on any type of DNNs to improve the robustness against noisy labels.\nAs empirically demonstrated on benchmark datasets, our PSDR impressively\nimprove state-of-the-art results by a significant margin.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 06:56:00 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Chen", "Pengfei", ""], ["Liao", "Benben", ""], ["Chen", "Guangyong", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1906.05560", "submitter": "Hung-Hsuan Chen", "authors": "Yu-Wei Kao and Hung-Hsuan Chen", "title": "Associated Learning: Decomposing End-to-end Backpropagation based on\n  Auto-encoders and Target Propagation", "comments": "34 pages, 6 figures, 7 tables", "journal-ref": "MIT Neural Computation 33(1), 2021", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation (BP) is the cornerstone of today's deep learning algorithms,\nbut it is inefficient partially because of backward locking, which means\nupdating the weights of one layer locks the weight updates in the other layers.\nConsequently, it is challenging to apply parallel computing or a pipeline\nstructure to update the weights in different layers simultaneously. In this\npaper, we introduce a novel learning structure called associated learning (AL),\nwhich modularizes the network into smaller components, each of which has a\nlocal objective. Because the objectives are mutually independent, AL can learn\nthe parameters in different layers independently and simultaneously, so it is\nfeasible to apply a pipeline structure to improve the training throughput.\nSpecifically, this pipeline structure improves the complexity of the training\ntime from O(nl), which is the time complexity when using BP and stochastic\ngradient descent (SGD) for training, to O(n + l), where n is the number of\ntraining instances and l is the number of hidden layers. Surprisingly, even\nthough most of the parameters in AL do not directly interact with the target\nvariable, training deep models by this method yields accuracies comparable to\nthose from models trained using typical BP methods, in which all parameters are\nused to predict the target variable. Consequently, because of the scalability\nand the predictive power demonstrated in the experiments, AL deserves further\nstudy to determine the better hyperparameter settings, such as activation\nfunction selection, learning rate scheduling, and weight initialization, to\naccumulate experience, as we have done over the years with the typical BP\nmethod. Additionally, perhaps our design can also inspire new network designs\nfor deep learning. Our implementation is available at\nhttps://github.com/SamYWK/Associated_Learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:21:10 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 12:18:47 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 15:37:02 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 07:40:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kao", "Yu-Wei", ""], ["Chen", "Hung-Hsuan", ""]]}, {"id": "1906.05582", "submitter": "Nikos Pitsianis", "authors": "Nikos Pitsianis and Alexandros-Stavros Iliopoulos and Dimitris Floros\n  and Xiaobai Sun", "title": "Spaceland Embedding of Sparse Stochastic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nonlinear method for directly embedding large, sparse,\nstochastic graphs into low-dimensional spaces, without requiring vertex\nfeatures to reside in, or be transformed into, a metric space. Graph data and\nmodels are prevalent in real-world applications. Direct graph embedding is\nfundamental to many graph analysis tasks, in addition to graph visualization.\nWe name the novel approach SG-t-SNE, as it is inspired by and builds upon the\ncore principle of t-SNE, a widely used method for nonlinear dimensionality\nreduction and data visualization. We also introduce t-SNE-$\\Pi$, a\nhigh-performance software for 2D, 3D embedding of large sparse graphs on\npersonal computers with superior efficiency. It empowers SG-t-SNE with modern\ncomputing techniques for exploiting in tandem both matrix structures and memory\narchitectures. We present elucidating embedding results on one synthetic graph\nand four real-world networks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:55:17 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Pitsianis", "Nikos", ""], ["Iliopoulos", "Alexandros-Stavros", ""], ["Floros", "Dimitris", ""], ["Sun", "Xiaobai", ""]]}, {"id": "1906.05591", "submitter": "Mark Kozdoba", "authors": "Mark Kozdoba and Edward Moroshko and Shie Mannor and Koby Crammer", "title": "Variance Estimation For Dynamic Regression via Spectrum Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dynamic linear regression problem, where the predictor vector\nmay vary with time. This problem can be modeled as a linear dynamical system,\nwhere the parameters that need to be learned are the variance of both the\nprocess noise and the observation noise. While variance estimation for dynamic\nregression is a natural problem, with a variety of applications, existing\napproaches to this problem either lack guarantees or only have asymptotic\nguarantees without explicit rates. In addition, all existing approaches rely\nstrongly on Guassianity of the noises. In this paper we study the global system\noperator: the operator that maps the noise vectors to the output. In\nparticular, we obtain estimates on its spectrum, and as a result derive the\nfirst known variance estimators with finite sample complexity guarantees.\nMoreover, our results hold for arbitrary sub Gaussian distributions of noise\nterms. We evaluate the approach on synthetic and real-world benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 10:36:43 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 15:32:07 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 15:00:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kozdoba", "Mark", ""], ["Moroshko", "Edward", ""], ["Mannor", "Shie", ""], ["Crammer", "Koby", ""]]}, {"id": "1906.05599", "submitter": "Aly El Gamal", "authors": "Rajeev Sahay, Rehana Mahfuz, Aly El Gamal", "title": "A Computationally Efficient Method for Defending Adversarial Deep\n  Learning Attacks", "comments": "6 pages, 6 figures, submitted to IEEE Signal Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliance on deep learning algorithms has grown significantly in recent\nyears. Yet, these models are highly vulnerable to adversarial attacks, which\nintroduce visually imperceptible perturbations into testing data to induce\nmisclassifications. The literature has proposed several methods to combat such\nadversarial attacks, but each method either fails at high perturbation values,\nrequires excessive computing power, or both. This letter proposes a\ncomputationally efficient method for defending the Fast Gradient Sign (FGS)\nadversarial attack by simultaneously denoising and compressing data.\nSpecifically, our proposed defense relies on training a fully connected\nmulti-layer Denoising Autoencoder (DAE) and using its encoder as a defense\nagainst the adversarial attack. Our results show that using this dimensionality\nreduction scheme is not only highly effective in mitigating the effect of the\nFGS attack in multiple threat models, but it also provides a 2.43x speedup in\ncomparison to defense strategies providing similar robustness against the same\nattack.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 10:56:47 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Sahay", "Rajeev", ""], ["Mahfuz", "Rehana", ""], ["Gamal", "Aly El", ""]]}, {"id": "1906.05651", "submitter": "Pushpendre Rastogi", "authors": "Pushpendre Rastogi", "title": "Representation Learning for Words and Entities", "comments": "phd thesis, Machine Learning, Natural Language Processing,\n  Representation Learning, Knowledge Graphs, Entities, Word Embeddings, Entity\n  Embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents new methods for unsupervised learning of distributed\nrepresentations of words and entities from text and knowledge bases. The first\nalgorithm presented in the thesis is a multi-view algorithm for learning\nrepresentations of words called Multiview Latent Semantic Analysis (MVLSA). By\nincorporating up to 46 different types of co-occurrence statistics for the same\nvocabulary of english words, I show that MVLSA outperforms other\nstate-of-the-art word embedding models. Next, I focus on learning entity\nrepresentations for search and recommendation and present the second method of\nthis thesis, Neural Variational Set Expansion (NVSE). NVSE is also an\nunsupervised learning method, but it is based on the Variational Autoencoder\nframework. Evaluations with human annotators show that NVSE can facilitate\nbetter search and recommendation of information gathered from noisy, automatic\nannotation of unstructured natural language corpora. Finally, I move from\nunstructured data and focus on structured knowledge graphs. I present novel\napproaches for learning embeddings of vertices and edges in a knowledge graph\nthat obey logical constraints.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:29:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Rastogi", "Pushpendre", ""]]}, {"id": "1906.05657", "submitter": "Tian Bao", "authors": "Tian Bao, Brooke N. Klatt, Susan L. Whitney, Kathleen H. Sienko, Jenna\n  Wiens", "title": "Automatically Evaluating Balance: A Machine Learning Approach", "comments": "8 pages, 4 figures, 5 tables", "journal-ref": "IEEE Transactions on Neural Systems and Rehabilitation Engineering\n  2019", "doi": "10.1109/TNSRE.2019.2891000", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compared to in-clinic balance training, in-home training is not as effective.\nThis is, in part, due to the lack of feedback from physical therapists (PTs).\nHere, we analyze the feasibility of using trunk sway data and machine learning\n(ML) techniques to automatically evaluate balance, providing accurate\nassessments outside of the clinic. We recruited sixteen participants to perform\nstanding balance exercises. For each exercise, we recorded trunk sway data and\nhad a PT rate balance performance on a scale of 1 to 5. The rating scale was\nadapted from the Functional Independence Measure. From the trunk sway data, we\nextracted a 61-dimensional feature vector representing performance of each\nexercise. Given these labeled data, we trained a multi-class support vector\nmachine (SVM) to map trunk sway features to PT ratings. Evaluated in a\nleave-one-participant-out scheme, the model achieved a classification accuracy\nof 82%. Compared to participant self-assessment ratings, the SVM outputs were\nsignificantly closer to PT ratings. The results of this pilot study suggest\nthat in the absence of PTs, ML techniques can provide accurate assessments\nduring standing balance exercises. Such automated assessments could reduce PT\nconsultation time and increase user compliance outside of the clinic.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:51:17 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Bao", "Tian", ""], ["Klatt", "Brooke N.", ""], ["Whitney", "Susan L.", ""], ["Sienko", "Kathleen H.", ""], ["Wiens", "Jenna", ""]]}, {"id": "1906.05661", "submitter": "Leonard Berrada", "authors": "Leonard Berrada, Andrew Zisserman, M. Pawan Kumar", "title": "Training Neural Networks for and by Interpolation", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern supervised learning, many deep neural networks are able to\ninterpolate the data: the empirical loss can be driven to near zero on all\nsamples simultaneously. In this work, we explicitly exploit this interpolation\nproperty for the design of a new optimization algorithm for deep learning,\nwhich we term Adaptive Learning-rates for Interpolation with Gradients (ALI-G).\nALI-G retains the two main advantages of Stochastic Gradient Descent (SGD),\nwhich are (i) a low computational cost per iteration and (ii) good\ngeneralization performance in practice. At each iteration, ALI-G exploits the\ninterpolation property to compute an adaptive learning-rate in closed form. In\naddition, ALI-G clips the learning-rate to a maximal value, which we prove to\nbe helpful for non-convex problems. Crucially, in contrast to the learning-rate\nof SGD, the maximal learning-rate of ALI-G does not require a decay schedule,\nwhich makes it considerably easier to tune. We provide convergence guarantees\nof ALI-G in various stochastic settings. Notably, we tackle the realistic case\nwhere the interpolation property is satisfied up to some tolerance. We provide\nexperiments on a variety of architectures and tasks: (i) learning a\ndifferentiable neural computer; (ii) training a wide residual network on the\nSVHN data set; (iii) training a Bi-LSTM on the SNLI data set; and (iv) training\nwide residual networks and densely connected networks on the CIFAR data sets.\nALI-G produces state-of-the-art results among adaptive methods, and even yields\ncomparable performance with SGD, which requires manually tuned learning-rate\nschedules. Furthermore, ALI-G is simple to implement in any standard deep\nlearning framework and can be used as a drop-in replacement in existing code.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 13:23:34 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 09:22:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Berrada", "Leonard", ""], ["Zisserman", "Andrew", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1906.05664", "submitter": "Yi Zhang", "authors": "Mark Braverman, Xinyi Chen, Sham M. Kakade, Karthik Narasimhan, Cyril\n  Zhang, Yi Zhang", "title": "Calibration, Entropy Rates, and Memory in Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building accurate language models that capture meaningful long-term\ndependencies is a core challenge in natural language processing. Towards this\nend, we present a calibration-based approach to measure long-term discrepancies\nbetween a generative sequence model and the true distribution, and use these\ndiscrepancies to improve the model. Empirically, we show that state-of-the-art\nlanguage models, including LSTMs and Transformers, are \\emph{miscalibrated}:\nthe entropy rates of their generations drift dramatically upward over time. We\nthen provide provable methods to mitigate this phenomenon. Furthermore, we show\nhow this calibration-based approach can also be used to measure the amount of\nmemory that language models use for prediction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:00:49 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Braverman", "Mark", ""], ["Chen", "Xinyi", ""], ["Kakade", "Sham M.", ""], ["Narasimhan", "Karthik", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "1906.05678", "submitter": "Chris Larson", "authors": "Chris Larson, Tarek Lahlou, Diana Mingels, Zachary Kulis, Erik Mueller", "title": "Telephonetic: Making Neural Language Models Robust to ASR and Semantic\n  Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech processing systems rely on robust feature extraction to handle\nphonetic and semantic variations found in natural language. While techniques\nexist for desensitizing features to common noise patterns produced by\nSpeech-to-Text (STT) and Text-to-Speech (TTS) systems, the question remains how\nto best leverage state-of-the-art language models (which capture rich semantic\nfeatures, but are trained on only written text) on inputs with ASR errors. In\nthis paper, we present Telephonetic, a data augmentation framework that helps\nrobustify language model features to ASR corrupted inputs. To capture phonetic\nalterations, we employ a character-level language model trained using\nprobabilistic masking. Phonetic augmentations are generated in two stages: a\nTTS encoder (Tacotron 2, WaveGlow) and a STT decoder (DeepSpeech). Similarly,\nsemantic perturbations are produced by sampling from nearby words in an\nembedding space, which is computed using the BERT language model. Words are\nselected for augmentation according to a hierarchical grammar sampling\nstrategy. Telephonetic is evaluated on the Penn Treebank (PTB) corpus, and\ndemonstrates its effectiveness as a bootstrapping technique for transferring\nneural language models to the speech domain. Notably, our language model\nachieves a test perplexity of 37.49 on PTB, which to our knowledge is\nstate-of-the-art among models trained only on PTB.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:04:46 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Larson", "Chris", ""], ["Lahlou", "Tarek", ""], ["Mingels", "Diana", ""], ["Kulis", "Zachary", ""], ["Mueller", "Erik", ""]]}, {"id": "1906.05681", "submitter": "Suraj Tripathi", "authors": "Suraj Tripathi, Abhay Kumar, Abhiram Ramesh, Chirag Singh, Promod\n  Yenigalla", "title": "Deep Learning based Emotion Recognition System Using Speech Features and\n  Transcriptions", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a speech emotion recognition method based on speech\nfeatures and speech transcriptions (text). Speech features such as Spectrogram\nand Mel-frequency Cepstral Coefficients (MFCC) help retain emotion-related\nlow-level characteristics in speech whereas text helps capture semantic\nmeaning, both of which help in different aspects of emotion detection. We\nexperimented with several Deep Neural Network (DNN) architectures, which take\nin different combinations of speech features and text as inputs. The proposed\nnetwork architectures achieve higher accuracies when compared to\nstate-of-the-art methods on a benchmark dataset. The combined MFCC-Text\nConvolutional Neural Network (CNN) model proved to be the most accurate in\nrecognizing emotions in IEMOCAP data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:35:02 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Tripathi", "Suraj", ""], ["Kumar", "Abhay", ""], ["Ramesh", "Abhiram", ""], ["Singh", "Chirag", ""], ["Yenigalla", "Promod", ""]]}, {"id": "1906.05682", "submitter": "Suraj Tripathi", "authors": "Suraj Tripathi, Abhay Kumar, Abhiram Ramesh, Chirag Singh, Promod\n  Yenigalla", "title": "Focal Loss based Residual Convolutional Neural Network for Speech\n  Emotion Recognition", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Residual Convolutional Neural Network (ResNet) based on\nspeech features and trained under Focal Loss to recognize emotion in speech.\nSpeech features such as Spectrogram and Mel-frequency Cepstral Coefficients\n(MFCCs) have shown the ability to characterize emotion better than just plain\ntext. Further Focal Loss, first used in One-Stage Object Detectors, has shown\nthe ability to focus the training process more towards hard-examples and\ndown-weight the loss assigned to well-classified examples, thus preventing the\nmodel from being overwhelmed by easily classifiable examples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:31:23 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Tripathi", "Suraj", ""], ["Kumar", "Abhay", ""], ["Ramesh", "Abhiram", ""], ["Singh", "Chirag", ""], ["Yenigalla", "Promod", ""]]}, {"id": "1906.05685", "submitter": "Laura Martinus", "authors": "Laura Martinus and Jade Z. Abbott", "title": "A Focus on Neural Machine Translation for African Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  African languages are numerous, complex and low-resourced. The datasets\nrequired for machine translation are difficult to discover, and existing\nresearch is hard to reproduce. Minimal attention has been given to machine\ntranslation for African languages so there is scant research regarding the\nproblems that arise when using machine translation techniques. To begin\naddressing these problems, we trained models to translate English to five of\nthe official South African languages (Afrikaans, isiZulu, Northern Sotho,\nSetswana, Xitsonga), making use of modern neural machine translation\ntechniques. The results obtained show the promise of using neural machine\ntranslation techniques for African languages. By providing reproducible\npublicly-available data, code and results, this research aims to provide a\nstarting point for other researchers in African machine translation to compare\nto and build upon.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:38:34 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 12:48:25 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Martinus", "Laura", ""], ["Abbott", "Jade Z.", ""]]}, {"id": "1906.05718", "submitter": "Paul Glaysher", "authors": "Paul Glaysher, Judith M. Katzy, Sitong An", "title": "Iterative subtraction method for Feature Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG hep-ex stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training features used to analyse physical processes are often highly\ncorrelated and determining which ones are most important for the classification\nis a non-trivial tasks. For the use case of a search for a top-quark pair\nproduced in association with a Higgs boson decaying to bottom-quarks at the\nLHC, we compare feature ranking methods for a classification BDT. Ranking\nmethods, such as the BDT Selection Frequency commonly used in High Energy\nPhysics and the Permutational Performance, are compared with the\ncomputationally expense Iterative Addition and Iterative Removal procedures,\nwhile the latter was found to be the most performant.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:24:51 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Glaysher", "Paul", ""], ["Katzy", "Judith M.", ""], ["An", "Sitong", ""]]}, {"id": "1906.05741", "submitter": "Zhuoyi Yang", "authors": "Xi Chen, Weidong Liu, Xiaojun Mao and Zhuoyi Yang", "title": "Distributed High-dimensional Regression Under a Quantile Loss Function", "comments": "42 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies distributed estimation and support recovery for\nhigh-dimensional linear regression model with heavy-tailed noise. To deal with\nheavy-tailed noise whose variance can be infinite, we adopt the quantile\nregression loss function instead of the commonly used squared loss. However,\nthe non-smooth quantile loss poses new challenges to high-dimensional\ndistributed estimation in both computation and theoretical development. To\naddress the challenge, we transform the response variable and establish a new\nconnection between quantile regression and ordinary linear regression. Then, we\nprovide a distributed estimator that is both computationally and\ncommunicationally efficient, where only the gradient information is\ncommunicated at each iteration. Theoretically, we show that, after a constant\nnumber of iterations, the proposed estimator achieves a near-oracle convergence\nrate without any restriction on the number of machines. Moreover, we establish\nthe theoretical guarantee for the support recovery. The simulation analysis is\nprovided to demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:00:31 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:35:12 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Chen", "Xi", ""], ["Liu", "Weidong", ""], ["Mao", "Xiaojun", ""], ["Yang", "Zhuoyi", ""]]}, {"id": "1906.05743", "submitter": "Chen Sun", "authors": "Chen Sun, Fabien Baradel, Kevin Murphy, Cordelia Schmid", "title": "Learning Video Representations using Contrastive Bidirectional\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a self-supervised learning approach for video features\nthat results in significantly improved performance on downstream tasks (such as\nvideo classification, captioning and segmentation) compared to existing\nmethods. Our method extends the BERT model for text sequences to the case of\nsequences of real-valued feature vectors, by replacing the softmax loss with\nnoise contrastive estimation (NCE). We also show how to learn representations\nfrom sequences of visual features and sequences of words derived from ASR\n(automatic speech recognition), and show that such cross-modal training (when\npossible) helps even more.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:03:52 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 21:59:59 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sun", "Chen", ""], ["Baradel", "Fabien", ""], ["Murphy", "Kevin", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1906.05746", "submitter": "Nikos Kargas", "authors": "Nikos Kargas, Nicholas D. Sidiropoulos", "title": "Nonlinear System Identification via Tensor Completion", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function approximation from input and output data pairs constitutes a\nfundamental problem in supervised learning. Deep neural networks are currently\nthe most popular method for learning to mimic the input-output relationship of\na general nonlinear system, as they have proven to be very effective in\napproximating complex highly nonlinear functions. In this work, we show that\nidentifying a general nonlinear function $y = f(x_1,\\ldots,x_N)$ from\ninput-output examples can be formulated as a tensor completion problem and\nunder certain conditions provably correct nonlinear system identification is\npossible. Specifically, we model the interactions between the $N$ input\nvariables and the scalar output of a system by a single $N$-way tensor, and\nsetup a weighted low-rank tensor completion problem with smoothness\nregularization which we tackle using a block coordinate descent algorithm. We\nextend our method to the multi-output setting and the case of partially\nobserved data, which cannot be readily handled by neural networks. Finally, we\ndemonstrate the effectiveness of the approach using several regression tasks\nincluding some standard benchmarks and a challenging student grade prediction\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:15:21 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 21:53:12 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 16:14:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1906.05747", "submitter": "Nicholas Geneva", "authors": "Nicholas Geneva, Nicholas Zabaras", "title": "Modeling the Dynamics of PDE Systems with Physics-Constrained Deep\n  Auto-Regressive Networks", "comments": "48 pages, 30 figures, Accepted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2019.109056", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has proven to be a viable methodology for\nsurrogate modeling and uncertainty quantification for a vast number of physical\nsystems. However, in their traditional form, such models can require a large\namount of training data. This is of particular importance for various\nengineering and scientific applications where data may be extremely expensive\nto obtain. To overcome this shortcoming, physics-constrained deep learning\nprovides a promising methodology as it only utilizes the governing equations.\nIn this work, we propose a novel auto-regressive dense encoder-decoder\nconvolutional neural network to solve and model non-linear dynamical systems\nwithout training data at a computational cost that is potentially magnitudes\nlower than standard numerical solvers. This model includes a Bayesian framework\nthat allows for uncertainty quantification of the predicted quantities of\ninterest at each time-step. We rigorously test this model on several non-linear\ntransient partial differential equation systems including the turbulence of the\nKuramoto-Sivashinsky equation, multi-shock formation and interaction with 1D\nBurgers' equation and 2D wave dynamics with coupled Burgers' equations. For\neach system, the predictive results and uncertainty are presented and discussed\ntogether with comparisons to the results obtained from traditional numerical\nanalysis methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:15:52 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 16:16:38 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 17:57:10 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Geneva", "Nicholas", ""], ["Zabaras", "Nicholas", ""]]}, {"id": "1906.05767", "submitter": "Chanachok Chokwitthaya", "authors": "Chanachok Chokwitthaya, Edward Collier, Yimin Zhu, Supratik\n  Mukhopadhyay", "title": "Improving Prediction Accuracy in Building Performance Models Using\n  Generative Adversarial Networks (GANs)", "comments": "9 pages, 4 figures, The 2019 International Joint Conference on Neural\n  Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building performance discrepancies between building design and operation are\none of the causes that lead many new designs fail to achieve their goals and\nobjectives. One of main factors contributing to the discrepancy is occupant\nbehaviors. Occupants responding to a new design are influenced by several\nfactors. Existing building performance models (BPMs) ignore or partially\naddress those factors (called contextual factors) while developing BPMs. To\npotentially reduce the discrepancies and improve the prediction accuracy of\nBPMs, this paper proposes a computational framework for learning mixture models\nby using Generative Adversarial Networks (GANs) that appropriately combining\nexisting BPMs with knowledge on occupant behaviors to contextual factors in new\ndesigns. Immersive virtual environments (IVEs) experiments are used to acquire\ndata on such behaviors. Performance targets are used to guide appropriate\ncombination of existing BPMs with knowledge on occupant behaviors. The\nresulting model obtained is called an augmented BPM. Two different experiments\nrelated to occupant lighting behaviors are shown as case study. The results\nreveal that augmented BPMs significantly outperformed existing BPMs with\nrespect to achieving specified performance targets. The case study confirms the\npotential of the computational framework for improving prediction accuracy of\nBPMs during design.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:51:32 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 04:19:04 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Chokwitthaya", "Chanachok", ""], ["Collier", "Edward", ""], ["Zhu", "Yimin", ""], ["Mukhopadhyay", "Supratik", ""]]}, {"id": "1906.05777", "submitter": "Maolin Shi", "authors": "Maolin Shi, Wei Sun, Xueguan Song, Hongyou Li", "title": "High-low level support vector regression prediction approach (HL-SVR)\n  for data modeling with input parameters of unequal sample sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector regression (SVR) has been widely used to reduce the high\ncomputational cost of computer simulation. SVR assumes the input parameters\nhave equal sample sizes, but unequal sample sizes are often encountered in\nengineering practices. To solve this issue, a new prediction approach based on\nSVR, namely as high-low-level SVR approach (HL-SVR) is proposed for data\nmodeling of input parameters of unequal sample sizes in this paper. The\nproposed approach is consisted of low-level SVR models for the input parameters\nof larger sample sizes and high-level SVR model for the input parameters of\nsmaller sample sizes. For each training point of the input parameters of\nsmaller sample sizes, one low-level SVR model is built based on its\ncorresponding input parameters of larger sample sizes and their responses of\ninterest. The high-level SVR model is built based on the obtained responses\nfrom the low-level SVR models and the input parameters of smaller sample sizes.\nSeveral numerical examples are used to validate the performance of HL-SVR. The\nexperimental results indicate that HL-SVR can produce more accurate prediction\nresults than conventional SVR. The proposed approach is applied on the stress\nanalysis of dental implant, which the structural parameters have massive\nsamples but the material of implant can only be selected from several Ti and\nits alloys. The prediction performance of the proposed approach is much better\nthan the conventional SVR. The proposed approach can be used for the design,\noptimization and analysis of engineering systems with input parameters of\nunequal sample sizes.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 00:55:43 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Shi", "Maolin", ""], ["Sun", "Wei", ""], ["Song", "Xueguan", ""], ["Li", "Hongyou", ""]]}, {"id": "1906.05795", "submitter": "Meryll Dindin", "authors": "Meryll Dindin, Yuhei Umeda, Frederic Chazal", "title": "Topological Data Analysis for Arrhythmia Detection through Modular\n  Neural Networks", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an innovative and generic deep learning approach to\nmonitor heart conditions from ECG signals.We focus our attention on both the\ndetection and classification of abnormal heartbeats, known as arrhythmia. We\nstrongly insist on generalization throughout the construction of a\ndeep-learning model that turns out to be effective for new unseen patient. The\nnovelty of our approach relies on the use of topological data analysis as basis\nof our multichannel architecture, to diminish the bias due to individual\ndifferences. We show that our structure reaches the performances of the\nstate-of-the-art methods regarding arrhythmia detection and classification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:29:30 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Dindin", "Meryll", ""], ["Umeda", "Yuhei", ""], ["Chazal", "Frederic", ""]]}, {"id": "1906.05799", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen and Vijay Janapa Reddi", "title": "Deep Reinforcement Learning for Cyber Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of Internet-connected systems has increased considerably, and these\nsystems are being exposed to cyber attacks more than ever. The complexity and\ndynamics of cyber attacks require protecting mechanisms to be responsive,\nadaptive, and scalable. Machine learning, or more specifically deep\nreinforcement learning (DRL), methods have been proposed widely to address\nthese issues. By incorporating deep learning into traditional RL, DRL is highly\ncapable of solving complex, dynamic, and especially high-dimensional cyber\ndefense problems. This paper presents a survey of DRL approaches developed for\ncyber security. We touch on different vital aspects, including DRL-based\nsecurity methods for cyber-physical systems, autonomous intrusion detection\ntechniques, and multi-agent DRL-based game theory simulations for defense\nstrategies against cyber attacks. Extensive discussions and future research\ndirections on DRL-based cyber security are also given. We expect that this\ncomprehensive review provides the foundations for and facilitates future\nstudies on exploring the potential of emerging DRL to cope with increasingly\ncomplex cyber security problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:34:12 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:55:14 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 10:06:00 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1906.05803", "submitter": "Anqi Liu", "authors": "Quanying Liu, Haiyan Wu, Anqi Liu", "title": "Modeling and Interpreting Real-world Human Risk Decision Making with\n  Inverse Reinforcement Learning", "comments": "Real-world Sequential Decision Making Workshop at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model human decision-making behaviors in a risk-taking task using inverse\nreinforcement learning (IRL) for the purposes of understanding real human\ndecision making under risk. To the best of our knowledge, this is the first\nwork applying IRL to reveal the implicit reward function in human risk-taking\ndecision making and to interpret risk-prone and risk-averse decision-making\npolicies. We hypothesize that the state history (e.g. rewards and decisions in\nprevious trials) are related to the human reward function, which leads to\nrisk-averse and risk-prone decisions. We design features that reflect these\nfactors in the reward function of IRL and learn the corresponding weight that\nis interpretable as the importance of features. The results confirm the\nsub-optimal risk-related decisions of human-driven by the personalized reward\nfunction. In particular, the risk-prone person tends to decide based on the\ncurrent pump number, while the risk-averse person relies on burst information\nfrom the previous trial and the average end status. Our results demonstrate\nthat IRL is an effective tool to model human decision-making behavior, as well\nas to help interpret the human psychological process in risk decision-making.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:35:32 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Liu", "Quanying", ""], ["Wu", "Haiyan", ""], ["Liu", "Anqi", ""]]}, {"id": "1906.05815", "submitter": "Mohammad Mahmoody", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Lower Bounds for Adversarially Robust PAC Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we initiate a formal study of probably approximately correct\n(PAC) learning under evasion attacks, where the adversary's goal is to\n\\emph{misclassify} the adversarially perturbed sample point $\\widetilde{x}$,\ni.e., $h(\\widetilde{x})\\neq c(\\widetilde{x})$, where $c$ is the ground truth\nconcept and $h$ is the learned hypothesis. Previous work on PAC learning of\nadversarial examples have all modeled adversarial examples as corrupted inputs\nin which the goal of the adversary is to achieve $h(\\widetilde{x}) \\neq c(x)$,\nwhere $x$ is the original untampered instance. These two definitions of\nadversarial risk coincide for many natural distributions, such as images, but\nare incomparable in general.\n  We first prove that for many theoretically natural input spaces of high\ndimension $n$ (e.g., isotropic Gaussian in dimension $n$ under $\\ell_2$\nperturbations), if the adversary is allowed to apply up to a sublinear\n$o(||x||)$ amount of perturbations on the test instances, PAC learning requires\nsample complexity that is exponential in $n$. This is in contrast with results\nproved using the corrupted-input framework, in which the sample complexity of\nrobust learning is only polynomially more.\n  We then formalize hybrid attacks in which the evasion attack is preceded by a\npoisoning attack. This is perhaps reminiscent of \"trapdoor attacks\" in which a\npoisoning phase is involved as well, but the evasion phase here uses the\nerror-region definition of risk that aims at misclassifying the perturbed\ninstances. In this case, we show PAC learning is sometimes impossible all\ntogether, even when it is possible without the attack (e.g., due to the bounded\nVC dimension).\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:01:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1906.05819", "submitter": "Anqi Liu", "authors": "Anqi Liu, Guanya Shi, Soon-Jo Chung, Anima Anandkumar, Yisong Yue", "title": "Robust Regression for Safe Exploration in Control", "comments": "2nd Annual Conference on Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of safe learning and exploration in sequential control\nproblems. The goal is to safely collect data samples from operating in an\nenvironment, in order to learn to achieve a challenging control goal (e.g., an\nagile maneuver close to a boundary). A central challenge in this setting is how\nto quantify uncertainty in order to choose provably-safe actions that allow us\nto collect informative data and reduce uncertainty, thereby achieving both\nimproved controller safety and optimality. To address this challenge, we\npresent a deep robust regression model that is trained to directly predict the\nuncertainty bounds for safe exploration. We derive generalization bounds for\nlearning, and connect them with safety and stability bounds in control. We\ndemonstrate empirically that our robust regression approach can outperform the\nconventional Gaussian process (GP) based safe exploration in settings where it\nis difficult to specify a good GP prior.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:03:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 21:00:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Liu", "Anqi", ""], ["Shi", "Guanya", ""], ["Chung", "Soon-Jo", ""], ["Anandkumar", "Anima", ""], ["Yue", "Yisong", ""]]}, {"id": "1906.05827", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Suriya Gunasekar, Pedro Savarese, Edward Moroshko,\n  Itay Golan, Jason Lee, Daniel Soudry, Nathan Srebro", "title": "Kernel and Rich Regimes in Overparametrized Models", "comments": "This paper has been substantially modified, updated, and expanded\n  with additional content (arXiv:2002.09277). To avoid confusion with already\n  existing citations, we are withdrawing the old version of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work studies overparametrized neural networks in the \"kernel\nregime,\" i.e. when the network behaves during training as a kernelized linear\npredictor, and thus training with gradient descent has the effect of finding\nthe minimum RKHS norm solution. This stands in contrast to other studies which\ndemonstrate how gradient descent on overparametrized multilayer networks can\ninduce rich implicit biases that are not RKHS norms. Building on an observation\nby Chizat and Bach, we show how the scale of the initialization controls the\ntransition between the \"kernel\" (aka lazy) and \"rich\" (aka active) regimes and\naffects generalization properties in multilayer homogeneous models. We provide\na complete and detailed analysis for a simple two-layer model that already\nexhibits an interesting and meaningful transition between the kernel and rich\nregimes, and we demonstrate the transition for more complex matrix\nfactorization models and multilayer non-linear networks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:16:12 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 17:07:19 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 17:33:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Woodworth", "Blake", ""], ["Gunasekar", "Suriya", ""], ["Savarese", "Pedro", ""], ["Moroshko", "Edward", ""], ["Golan", "Itay", ""], ["Lee", "Jason", ""], ["Soudry", "Daniel", ""], ["Srebro", "Nathan", ""]]}, {"id": "1906.05828", "submitter": "Alessandro Davide Ialongo", "authors": "Alessandro Davide Ialongo, Mark van der Wilk, James Hensman, Carl\n  Edward Rasmussen", "title": "Overcoming Mean-Field Approximations in Recurrent Gaussian Process\n  Models", "comments": "10 pages, 4 figures, 3 tables. Published in the proceedings of the\n  Thirty-sixth International Conference on Machine Learning (ICML), 2019", "journal-ref": "PMLR 97:2931-2940 (2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a new variational inference scheme for dynamical systems whose\ntransition function is modelled by a Gaussian process. Inference in this\nsetting has either employed computationally intensive MCMC methods, or relied\non factorisations of the variational posterior. As we demonstrate in our\nexperiments, the factorisation between latent system states and transition\nfunction can lead to a miscalibrated posterior and to learning unnecessarily\nlarge noise terms. We eliminate this factorisation by explicitly modelling the\ndependence between state trajectories and the Gaussian process posterior.\nSamples of the latent states can then be tractably generated by conditioning on\nthis representation. The method we obtain (VCDT: variationally coupled dynamics\nand trajectories) gives better predictive performance and more calibrated\nestimates of the transition function, yet maintains the same time and space\ncomplexities as mean-field methods. Code is available at:\ngithub.com/ialong/GPt.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:19:04 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ialongo", "Alessandro Davide", ""], ["van der Wilk", "Mark", ""], ["Hensman", "James", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "1906.05838", "submitter": "Carlos Florensa", "authors": "Yiming Ding, Carlos Florensa, Mariano Phielipp, Pieter Abbeel", "title": "Goal-conditioned Imitation Learning", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing rewards for Reinforcement Learning (RL) is challenging because it\nneeds to convey the desired task, be efficient to optimize, and be easy to\ncompute. The latter is particularly problematic when applying RL to robotics,\nwhere detecting whether the desired configuration is reached might require\nconsiderable supervision and instrumentation. Furthermore, we are often\ninterested in being able to reach a wide range of configurations, hence setting\nup a different reward every time might be unpractical. Methods like Hindsight\nExperience Replay (HER) have recently shown promise to learn policies able to\nreach many goals, without the need of a reward. Unfortunately, without tricks\nlike resetting to points along the trajectory, HER might require many samples\nto discover how to reach certain areas of the state-space. In this work we\ninvestigate different approaches to incorporate demonstrations to drastically\nspeed up the convergence to a policy able to reach any goal, also surpassing\nthe performance of an agent trained with other Imitation Learning algorithms.\nFurthermore, we show our method can also be used when the available expert\ntrajectories do not contain the actions, which can leverage kinesthetic or\nthird person demonstration. The code is available at\nhttps://sites.google.com/view/goalconditioned-il/.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:39:52 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:37:00 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 06:47:07 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ding", "Yiming", ""], ["Florensa", "Carlos", ""], ["Phielipp", "Mariano", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1906.05850", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng and John Paisley", "title": "Reweighted Expectation Maximization", "comments": "Code can be found at https://github.com/adjidieng/REM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep generative models with maximum likelihood remains a challenge.\nThe typical workaround is to use variational inference (VI) and maximize a\nlower bound to the log marginal likelihood of the data. Variational\nauto-encoders (VAEs) adopt this approach. They further amortize the cost of\ninference by using a recognition network to parameterize the variational\nfamily. Amortized VI scales approximate posterior inference in deep generative\nmodels to large datasets. However it introduces an amortization gap and leads\nto approximate posteriors of reduced expressivity due to the problem known as\nposterior collapse. In this paper, we consider expectation maximization (EM) as\na paradigm for fitting deep generative models. Unlike VI, EM directly maximizes\nthe log marginal likelihood of the data. We rediscover the importance weighted\nauto-encoder (IWAE) as an instance of EM and propose a new EM-based algorithm\nfor fitting deep generative models called reweighted expectation maximization\n(REM). REM learns better generative models than the IWAE by decoupling the\nlearning dynamics of the generative model and the recognition network using a\nseparate expressive proposal found by moment matching. We compared REM to the\nVAE and the IWAE on several density estimation benchmarks and found it leads to\nsignificantly better performance as measured by log-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:49:54 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 19:46:56 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dieng", "Adji B.", ""], ["Paisley", "John", ""]]}, {"id": "1906.05862", "submitter": "Alexander Li", "authors": "Alexander C. Li, Carlos Florensa, Ignasi Clavera, Pieter Abbeel", "title": "Sub-policy Adaptation for Hierarchical Reinforcement Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning is a promising approach to tackle\nlong-horizon decision-making problems with sparse rewards. Unfortunately, most\nmethods still decouple the lower-level skill acquisition process and the\ntraining of a higher level that controls the skills in a new task. Leaving the\nskills fixed can lead to significant sub-optimality in the transfer setting. In\nthis work, we propose a novel algorithm to discover a set of skills, and\ncontinuously adapt them along with the higher level even when training on a new\ntask. Our main contributions are two-fold. First, we derive a new hierarchical\npolicy gradient with an unbiased latent-dependent baseline, and we introduce\nHierarchical Proximal Policy Optimization (HiPPO), an on-policy method to\nefficiently train all levels of the hierarchy jointly. Second, we propose a\nmethod for training time-abstractions that improves the robustness of the\nobtained skills to environment changes. Code and results are available at\nsites.google.com/view/hippo-rl\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:59:48 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:18:29 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 17:59:41 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 23:32:41 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Li", "Alexander C.", ""], ["Florensa", "Carlos", ""], ["Clavera", "Ignasi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1906.05890", "submitter": "Kaifeng Lyu", "authors": "Kaifeng Lyu, Jian Li", "title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks", "comments": "52 pages, 9 figures; Published in ICLR 2020; Corrected typos and\n  added a few references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the implicit regularization of the gradient descent\nalgorithm in homogeneous neural networks, including fully-connected and\nconvolutional neural networks with ReLU or LeakyReLU activations. In\nparticular, we study the gradient descent or gradient flow (i.e., gradient\ndescent with infinitesimal step size) optimizing the logistic loss or\ncross-entropy loss of any homogeneous model (possibly non-smooth), and show\nthat if the training loss decreases below a certain threshold, then we can\ndefine a smoothed version of the normalized margin which increases over time.\nWe also formulate a natural constrained optimization problem related to margin\nmaximization, and prove that both the normalized margin and its smoothed\nversion converge to the objective value at a KKT point of the optimization\nproblem. Our results generalize the previous results for logistic regression\nwith one-layer or multi-layer linear networks, and provide more quantitative\nconvergence results with weaker assumptions than previous results for\nhomogeneous smooth neural networks. We conduct several experiments to justify\nour theoretical finding on MNIST and CIFAR-10 datasets. Finally, as margin is\nclosely related to robustness, we discuss potential benefits of training longer\nfor improving the robustness of the model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 18:52:00 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 05:24:48 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 17:18:19 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 05:33:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lyu", "Kaifeng", ""], ["Li", "Jian", ""]]}, {"id": "1906.05895", "submitter": "Sungyong Baik", "authors": "Sungyong Baik, Seokil Hong, Kyoung Mu Lee", "title": "Learning to Forget for Meta-Learning", "comments": "CVPR 2020. Code at https://github.com/baiksung/L2F", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning is a challenging problem where the goal is to achieve\ngeneralization from only few examples. Model-agnostic meta-learning (MAML)\ntackles the problem by formulating prior knowledge as a common initialization\nacross tasks, which is then used to quickly adapt to unseen tasks. However,\nforcibly sharing an initialization can lead to conflicts among tasks and the\ncompromised (undesired by tasks) location on optimization landscape, thereby\nhindering the task adaptation. Further, we observe that the degree of conflict\ndiffers among not only tasks but also layers of a neural network. Thus, we\npropose task-and-layer-wise attenuation on the compromised initialization to\nreduce its influence. As the attenuation dynamically controls (or selectively\nforgets) the influence of prior knowledge for a given task and each layer, we\nname our method as L2F (Learn to Forget). The experimental results demonstrate\nthat the proposed method provides faster adaptation and greatly improves the\nperformance. Furthermore, L2F can be easily applied and improve other\nstate-of-the-art MAML-based frameworks, illustrating its simplicity and\ngeneralizability.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 19:03:27 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:24:44 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Baik", "Sungyong", ""], ["Hong", "Seokil", ""], ["Lee", "Kyoung Mu", ""]]}, {"id": "1906.05912", "submitter": "Steven Squires", "authors": "Steven Squires, Adam Pr\\\"ugel Bennett, Mahesan Niranjan", "title": "A Variational Autoencoder for Probabilistic Non-Negative Matrix\n  Factorisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and demonstrate the variational autoencoder (VAE) for\nprobabilistic non-negative matrix factorisation (PAE-NMF). We design a network\nwhich can perform non-negative matrix factorisation (NMF) and add in aspects of\na VAE to make the coefficients of the latent space probabilistic. By\nrestricting the weights in the final layer of the network to be non-negative\nand using the non-negative Weibull distribution we produce a probabilistic form\nof NMF which allows us to generate new data and find a probability distribution\nthat effectively links the latent and input variables. We demonstrate the\neffectiveness of PAE-NMF on three heterogeneous datasets: images, financial\ntime series and genomic.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:05:15 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Squires", "Steven", ""], ["Bennett", "Adam Pr\u00fcgel", ""], ["Niranjan", "Mahesan", ""]]}, {"id": "1906.05915", "submitter": "Timon Willi", "authors": "Timon Willi, Jonathan Masci, J\\\"urgen Schmidhuber, Christian\n  Osendorfer", "title": "Recurrent Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend Neural Processes (NPs) to sequential data through Recurrent NPs or\nRNPs, a family of conditional state space models. RNPs model the state space\nwith Neural Processes. Given time series observed on fast real-world time\nscales but containing slow long-term variabilities, RNPs may derive appropriate\nslow latent time scales. They do so in an efficient manner by establishing\nconditional independence among subsequences of the time series. Our\ntheoretically grounded framework for stochastic processes expands the\napplicability of NPs while retaining their benefits of flexibility, uncertainty\nestimation, and favorable runtime with respect to Gaussian Processes (GPs). We\ndemonstrate that state spaces learned by RNPs benefit predictive performance on\nreal-world time-series data and nonlinear system identification, even in the\ncase of limited data availability.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:12:55 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 20:37:37 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Willi", "Timon", ""], ["Masci", "Jonathan", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Osendorfer", "Christian", ""]]}, {"id": "1906.05925", "submitter": "Kevin VanHorn", "authors": "Kevin C. VanHorn, Meyer Zinn, Murat Can Cobanoglu", "title": "Deep Learning Development Environment in Virtual Reality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual reality (VR) offers immersive visualization and intuitive\ninteraction. We leverage VR to enable any biomedical professional to deploy a\ndeep learning (DL) model for image classification. While DL models can be\npowerful tools for data analysis, they are also challenging to understand and\ndevelop. To make deep learning more accessible and intuitive, we have built a\nvirtual reality-based DL development environment. Within our environment, the\nuser can move tangible objects to construct a neural network only using their\nhands. Our software automatically translates these configurations into a\ntrainable model and then reports its resulting accuracy on a test dataset in\nreal-time. Furthermore, we have enriched the virtual objects with\nvisualizations of the model's components such that users can achieve insight\nabout the DL models that they are developing. With this approach, we bridge the\ngap between professionals in different fields of expertise while offering a\nnovel perspective for model analysis and data interaction. We further suggest\nthat techniques of development and visualization in deep learning can benefit\nby integrating virtual reality.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:53:33 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["VanHorn", "Kevin C.", ""], ["Zinn", "Meyer", ""], ["Cobanoglu", "Murat Can", ""]]}, {"id": "1906.05929", "submitter": "Noseong Park", "authors": "Duanshun Li, Jing Liu, Noseong Park, Dongeun Lee, Giridhar\n  Ramachandran, Ali Seyedmazloom, Kookjin Lee, Chen Feng, Vadim Sokolov, Rajesh\n  Ganesan", "title": "Solving Large-Scale 0-1 Knapsack Problems and its Application to Point\n  Cloud Resampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  0-1 knapsack is of fundamental importance in computer science, business,\noperations research, etc. In this paper, we present a deep learning\ntechnique-based method to solve large-scale 0-1 knapsack problems where the\nnumber of products (items) is large and/or the values of products are not\nnecessarily predetermined but decided by an external value assignment function\nduring the optimization process. Our solution is greatly inspired by the method\nof Lagrange multiplier and some recent adoptions of game theory to deep\nlearning. After formally defining our proposed method based on them, we develop\nan adaptive gradient ascent method to stabilize its optimization process. In\nour experiments, the presented method solves all the large-scale benchmark KP\ninstances in a minute whereas existing methods show fluctuating runtime. We\nalso show that our method can be used for other applications, including but not\nlimited to the point cloud resampling.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:56:18 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Li", "Duanshun", ""], ["Liu", "Jing", ""], ["Park", "Noseong", ""], ["Lee", "Dongeun", ""], ["Ramachandran", "Giridhar", ""], ["Seyedmazloom", "Ali", ""], ["Lee", "Kookjin", ""], ["Feng", "Chen", ""], ["Sokolov", "Vadim", ""], ["Ganesan", "Rajesh", ""]]}, {"id": "1906.05936", "submitter": "Kwangmin Yu", "authors": "Kwangmin Yu and Thomas Flynn and Shinjae Yoo and Nicholas D'Imperio", "title": "Layered SGD: A Decentralized and Synchronous SGD Algorithm for Scalable\n  Deep Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is the most popular algorithm for training\ndeep neural networks (DNNs). As larger networks and datasets cause longer\ntraining times, training on distributed systems is common and distributed SGD\nvariants, mainly asynchronous and synchronous SGD, are widely used.\nAsynchronous SGD is communication efficient but suffers from accuracy\ndegradation due to delayed parameter updating. Synchronous SGD becomes\ncommunication intensive when the number of nodes increases regardless of its\nadvantage. To address these issues, we introduce Layered SGD (LSGD), a new\ndecentralized synchronous SGD algorithm. LSGD partitions computing resources\ninto subgroups that each contain a communication layer (communicator) and a\ncomputation layer (worker). Each subgroup has centralized communication for\nparameter updates while communication between subgroups is handled by\ncommunicators. As a result, communication time is overlapped with I/O latency\nof workers. The efficiency of the algorithm is tested by training a deep\nnetwork on the ImageNet classification task.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 21:31:55 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Yu", "Kwangmin", ""], ["Flynn", "Thomas", ""], ["Yoo", "Shinjae", ""], ["D'Imperio", "Nicholas", ""]]}, {"id": "1906.05944", "submitter": "Francois-Xavier Briol", "authors": "Francois-Xavier Briol, Alessandro Barp, Andrew B. Duncan, Mark\n  Girolami", "title": "Statistical Inference for Generative Models with Maximum Mean\n  Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While likelihood-based inference and its variants provide a statistically\nefficient and widely applicable approach to parametric inference, their\napplication to models involving intractable likelihoods poses challenges. In\nthis work, we study a class of minimum distance estimators for intractable\ngenerative models, that is, statistical models for which the likelihood is\nintractable, but simulation is cheap. The distance considered, maximum mean\ndiscrepancy (MMD), is defined through the embedding of probability measures\ninto a reproducing kernel Hilbert space. We study the theoretical properties of\nthese estimators, showing that they are consistent, asymptotically normal and\nrobust to model misspecification. A main advantage of these estimators is the\nflexibility offered by the choice of kernel, which can be used to trade-off\nstatistical efficiency and robustness. On the algorithmic side, we study the\ngeometry induced by MMD on the parameter space and use this to introduce a\nnovel natural gradient descent-like algorithm for efficient implementation of\nthese estimators. We illustrate the relevance of our theoretical results on\nseveral classes of models including a discrete-time latent Markov process and\ntwo multivariate stochastic differential equation models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 21:53:55 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Briol", "Francois-Xavier", ""], ["Barp", "Alessandro", ""], ["Duncan", "Andrew B.", ""], ["Girolami", "Mark", ""]]}, {"id": "1906.05945", "submitter": "Wa\\\"iss Azizian", "authors": "Wa\\\"iss Azizian, Ioannis Mitliagkas, Simon Lacoste-Julien, Gauthier\n  Gidel", "title": "A Tight and Unified Analysis of Gradient-Based Methods for a Whole\n  Spectrum of Games", "comments": "Appears in: Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020). 39 pages. Minor\n  modification regarding prior work in comparison to the AISTATS Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider differentiable games where the goal is to find a Nash\nequilibrium. The machine learning community has recently started using variants\nof the gradient method (GD). Prime examples are extragradient (EG), the\noptimistic gradient method (OG) and consensus optimization (CO), which enjoy\nlinear convergence in cases like bilinear games, where the standard GD fails.\nThe full benefits of theses relatively new methods are not known as there is no\nunified analysis for both strongly monotone and bilinear games. We provide new\nanalyses of the EG's local and global convergence properties and use is to get\na tighter global convergence rate for OG and CO. Our analysis covers the whole\nrange of settings between bilinear and strongly monotone games. It reveals that\nthese methods converge via different mechanisms at these extremes; in between,\nit exploits the most favorable mechanism for the given problem. We then prove\nthat EG achieves the optimal rate for a wide class of algorithms with any\nnumber of extrapolations. Our tight analysis of EG's convergence rate in games\nshows that, unlike in convex minimization, EG may be much faster than GD.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 21:55:41 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 22:34:10 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 12:20:03 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 14:51:34 GMT"}, {"version": "v5", "created": "Tue, 7 Jul 2020 16:28:47 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Azizian", "Wa\u00efss", ""], ["Mitliagkas", "Ioannis", ""], ["Lacoste-Julien", "Simon", ""], ["Gidel", "Gauthier", ""]]}, {"id": "1906.05956", "submitter": "Sungbin Lim", "authors": "Sungwoong Kim, Ildoo Kim, Sungbin Lim, Woonhyuk Baek, Chiheon Kim,\n  Hyungjoo Cho, Boogeon Yoon, Taesup Kim", "title": "Scalable Neural Architecture Search for 3D Medical Image Segmentation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a neural architecture search (NAS) framework is proposed for\n3D medical image segmentation, to automatically optimize a neural architecture\nfrom a large design space. Our NAS framework searches the structure of each\nlayer including neural connectivities and operation types in both of the\nencoder and decoder. Since optimizing over a large discrete architecture space\nis difficult due to high-resolution 3D medical images, a novel stochastic\nsampling algorithm based on a continuous relaxation is also proposed for\nscalable gradient based optimization. On the 3D medical image segmentation\ntasks with a benchmark dataset, an automatically designed architecture by the\nproposed NAS framework outperforms the human-designed 3D U-Net, and moreover\nthis optimized architecture is well suited to be transferred for different\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 22:39:42 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kim", "Sungwoong", ""], ["Kim", "Ildoo", ""], ["Lim", "Sungbin", ""], ["Baek", "Woonhyuk", ""], ["Kim", "Chiheon", ""], ["Cho", "Hyungjoo", ""], ["Yoon", "Boogeon", ""], ["Kim", "Taesup", ""]]}, {"id": "1906.05967", "submitter": "Yuling Jiao", "authors": "Jianfeng Cai and Yuling Jiao and Xiliang Lu and Juntao You", "title": "A stochastic alternating minimizing method for sparse phase retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse phase retrieval plays an important role in many fields of applied\nscience and thus attracts lots of attention. In this paper, we propose a\n\\underline{sto}chastic alte\\underline{r}nating \\underline{m}inimizing method\nfor \\underline{sp}arse ph\\underline{a}se \\underline{r}etrieval\n(\\textit{StormSpar}) algorithm which {emprically} is able to recover\n$n$-dimensional $s$-sparse signals from only $O(s\\,\\mathrm{log}\\, n)$ number of\nmeasurements without a desired initial value required by many existing methods.\nIn \\textit{StormSpar}, the hard-thresholding pursuit (HTP) algorithm is\nemployed to solve the sparse constraint least square sub-problems. The main\ncompetitive feature of \\textit{StormSpar} is that it converges globally\nrequiring optimal order of number of samples with random initialization.\nExtensive numerical experiments are given to validate the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 00:24:34 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Cai", "Jianfeng", ""], ["Jiao", "Yuling", ""], ["Lu", "Xiliang", ""], ["You", "Juntao", ""]]}, {"id": "1906.06002", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Tomoyuki Obuchi", "title": "Empirical Bayes Method for Boltzmann Machines", "comments": null, "journal-ref": "Journal of Physics A: Mathematical and Theoretical, vol.53,\n  014004, 2019", "doi": "10.1088/1751-8121/ab57a7", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we consider an empirical Bayes method for Boltzmann machines\nand propose an algorithm for it. The empirical Bayes method allows estimation\nof the values of the hyperparameters of the Boltzmann machine by maximizing a\nspecific likelihood function referred to as the empirical Bayes likelihood\nfunction in this study. However, the maximization is computationally hard\nbecause the empirical Bayes likelihood function involves intractable\nintegrations of the partition function. The proposed algorithm avoids this\ncomputational problem by using the replica method and the Plefka expansion. Our\nmethod does not require any iterative procedures and is quite simple and fast,\nthough it introduces a bias to the estimate, which exhibits an unnatural\nbehavior with respect to the size of the dataset. This peculiar behavior is\nsupposed to be due to the approximate treatment by the Plefka expansion. A\npossible extension to overcome this behavior is also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 03:24:32 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 15:14:36 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Yasuda", "Muneki", ""], ["Obuchi", "Tomoyuki", ""]]}, {"id": "1906.06026", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan, Danilo Vasconcellos Vargas", "title": "Adversarial Robustness Assessment: Why both $L_0$ and $L_\\infty$ Attacks\n  Are Necessary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a vast number of adversarial attacks and defences for machine\nlearning algorithms of various types which makes assessing the robustness of\nalgorithms a daunting task. To make matters worse, there is an intrinsic bias\nin these adversarial algorithms. Here, we organise the problems faced: a) Model\nDependence, b) Insufficient Evaluation, c) False Adversarial Samples, and d)\nPerturbation Dependent Results). Based on this, we propose a model agnostic\ndual quality assessment method, together with the concept of robustness levels\nto tackle them. We validate the dual quality assessment on state-of-the-art\nneural networks (WideResNet, ResNet, AllConv, DenseNet, NIN, LeNet and CapsNet)\nas well as adversarial defences for image classification problem. We further\nshow that current networks and defences are vulnerable at all levels of\nrobustness. The proposed robustness assessment reveals that depending on the\nmetric used (i.e., $L_0$ or $L_\\infty$), the robustness may vary significantly.\nHence, the duality should be taken into account for a correct evaluation.\nMoreover, a mathematical derivation, as well as a counter-example, suggest that\n$L_1$ and $L_2$ metrics alone are not sufficient to avoid spurious adversarial\nsamples. Interestingly, the threshold attack of the proposed assessment is a\nnovel $L_\\infty$ black-box adversarial method which requires even less\nperturbation than the One-Pixel Attack (only $12\\%$ of One-Pixel Attack's\namount of perturbation) to achieve similar results.\n  Code is available at http://bit.ly/DualQualityAssessment.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 05:11:12 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 08:30:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:44:38 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "1906.06032", "submitter": "Sang Michael Xie", "authors": "Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John C. Duchi, Percy\n  Liang", "title": "Adversarial Training Can Hurt Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While adversarial training can improve robust accuracy (against an\nadversary), it sometimes hurts standard accuracy (when there is no adversary).\nPrevious work has studied this tradeoff between standard and robust accuracy,\nbut only in the setting where no predictor performs well on both objectives in\nthe infinite data limit. In this paper, we show that even when the optimal\npredictor with infinite data performs well on both objectives, a tradeoff can\nstill manifest itself with finite data. Furthermore, since our construction is\nbased on a convex learning problem, we rule out optimization concerns, thus\nlaying bare a fundamental tension between robustness and generalization.\nFinally, we show that robust self-training mostly eliminates this tradeoff by\nleveraging unlabeled data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 05:46:10 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 22:36:02 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Raghunathan", "Aditi", ""], ["Xie", "Sang Michael", ""], ["Yang", "Fanny", ""], ["Duchi", "John C.", ""], ["Liang", "Percy", ""]]}, {"id": "1906.06033", "submitter": "Ahmed Taha Elthakeb", "authors": "Ahmed T. Elthakeb, Prannoy Pilligundla, Alex Cloninger, Hadi\n  Esmaeilzadeh", "title": "Divide and Conquer: Leveraging Intermediate Feature Representations for\n  Quantized Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep layers of modern neural networks extract a rather rich set of\nfeatures as an input propagates through the network. This paper sets out to\nharvest these rich intermediate representations for quantization with minimal\naccuracy loss while significantly reducing the memory footprint and compute\nintensity of the DNN. This paper utilizes knowledge distillation through\nteacher-student paradigm (Hinton et al., 2015) in a novel setting that exploits\nthe feature extraction capability of DNNs for higher-accuracy quantization. As\nsuch, our algorithm logically divides a pretrained full-precision DNN to\nmultiple sections, each of which exposes intermediate features to train a team\nof students independently in the quantized domain. This divide and conquer\nstrategy, in fact, makes the training of each student section possible in\nisolation while all these independently trained sections are later stitched\ntogether to form the equivalent fully quantized network. Our algorithm is a\nsectional approach towards knowledge distillation and is not treating the\nintermediate representation as a hint for pretraining before one knowledge\ndistillation pass over the entire network (Romero et al., 2015). Experiments on\nvarious DNNs (AlexNet, LeNet, MobileNet, ResNet-18, ResNet-20, SVHN and VGG-11)\nshow that, this approach -- called DCQ (Divide and Conquer Quantization) -- on\naverage, improves the performance of a state-of-the-art quantized training\ntechnique, DoReFa-Net (Zhou et al., 2016) by 21.6% and 9.3% for binary and\nternary quantization, respectively. Additionally, we show that incorporating\nDCQ to existing quantized training methods leads to improved accuracies as\ncompared to previously reported by multiple state-of-the-art quantized training\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 05:53:30 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 19:20:57 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 19:20:52 GMT"}, {"version": "v4", "created": "Mon, 2 Mar 2020 20:06:26 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Elthakeb", "Ahmed T.", ""], ["Pilligundla", "Prannoy", ""], ["Cloninger", "Alex", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1906.06034", "submitter": "Zinan Lin", "authors": "Zinan Lin, Kiran Koshy Thekumparampil, Giulia Fanti, Sewoong Oh", "title": "InfoGAN-CR and ModelCentrality: Self-supervised Model Training and\n  Selection for Disentangling GANs", "comments": "Published in ICML 2020. 45 pages, 52 figures, a new unsupervised\n  model selection scheme (ModelCentrality) is introduced in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled generative models map a latent code vector to a target space,\nwhile enforcing that a subset of the learned latent codes are interpretable and\nassociated with distinct properties of the target distribution. Recent advances\nhave been dominated by Variational AutoEncoder (VAE)-based methods, while\ntraining disentangled generative adversarial networks (GANs) remains\nchallenging. In this work, we show that the dominant challenges facing\ndisentangled GANs can be mitigated through the use of self-supervision. We make\ntwo main contributions: first, we design a novel approach for training\ndisentangled GANs with self-supervision. We propose contrastive regularizer,\nwhich is inspired by a natural notion of disentanglement: latent traversal.\nThis achieves higher disentanglement scores than state-of-the-art VAE- and\nGAN-based approaches. Second, we propose an unsupervised model selection scheme\ncalled ModelCentrality, which uses generated synthetic samples to compute the\nmedoid (multi-dimensional generalization of median) of a collection of models.\nThe current common practice of hyper-parameter tuning requires using\nground-truths samples, each labelled with known perfect disentangled latent\ncodes. As real datasets are not equipped with such labels, we propose an\nunsupervised model selection scheme and show that it finds a model close to the\nbest one, for both VAEs and GANs. Combining contrastive regularization with\nModelCentrality, we improve upon the state-of-the-art disentanglement scores\nsignificantly, without accessing the supervised data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 05:56:20 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:12:29 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 17:28:18 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Lin", "Zinan", ""], ["Thekumparampil", "Kiran Koshy", ""], ["Fanti", "Giulia", ""], ["Oh", "Sewoong", ""]]}, {"id": "1906.06053", "submitter": "Yunwen Lei", "authors": "Yunwen Lei and Yiming Ying", "title": "Stochastic Proximal AUC Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of maximizing the Area under the ROC\ncurve (AUC) which is a widely used performance metric in imbalanced\nclassification and anomaly detection. Due to the pairwise nonlinearity of the\nobjective function, classical SGD algorithms do not apply to the task of AUC\nmaximization. We propose a novel stochastic proximal algorithm for AUC\nmaximization which is scalable to large scale streaming data. Our algorithm can\naccommodate general penalty terms and is easy to implement with favorable\n$O(d)$ space and per-iteration time complexities. We establish a\nhigh-probability convergence rate $O(1/\\sqrt{T})$ for the general convex\nsetting, and improve it to a fast convergence rate $O(1/T)$ for the cases of\nstrongly convex regularizers and no regularization term (without strong\nconvexity). Our proof does not need the uniform boundedness assumption on the\nloss function or the iterates which is more fidelity to the practice. Finally,\nwe perform extensive experiments over various benchmark data sets from\nreal-world application domains which show the superior performance of our\nalgorithm over the existing AUC maximization algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 07:16:26 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Lei", "Yunwen", ""], ["Ying", "Yiming", ""]]}, {"id": "1906.06057", "submitter": "Jessica Hoffmann", "authors": "Jessica Hoffmann, Soumya Basu, Surbhi Goel, Constantine Caramanis", "title": "Learning Mixtures of Graphs from Epidemic Cascades", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the weighted edges of a balanced mixture\nof two undirected graphs from epidemic cascades. While mixture models are\npopular modeling tools, algorithmic development with rigorous guarantees has\nlagged. Graph mixtures are apparently no exception: until now, very little is\nknown about whether this problem is solvable.\n  To the best of our knowledge, we establish the first necessary and sufficient\nconditions for this problem to be solvable in polynomial time on edge-separated\ngraphs. When the conditions are met, i.e., when the graphs are connected with\nat least three edges, we give an efficient algorithm for learning the weights\nof both graphs with optimal sample complexity (up to log factors).\n  We give complimentary results and provide sample-optimal (up to log factors)\nalgorithms for mixtures of directed graphs of out-degree at least three, for\nmixture of undirected graphs of unbalanced and/or unknown priors.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 07:33:05 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 08:26:33 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Hoffmann", "Jessica", ""], ["Basu", "Soumya", ""], ["Goel", "Surbhi", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1906.06062", "submitter": "Guy Lorberbom", "authors": "Guy Lorberbom, Chris J. Maddison, Nicolas Heess, Tamir Hazan, Daniel\n  Tarlow", "title": "Direct Policy Gradients: Direct Optimization of Policies in Discrete\n  Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct optimization is an appealing framework that replaces integration with\noptimization of a random objective for approximating gradients in models with\ndiscrete random variables. A$^\\star$ sampling is a framework for optimizing\nsuch random objectives over large spaces. We show how to combine these\ntechniques to yield a reinforcement learning algorithm that approximates a\npolicy gradient by finding trajectories that optimize a random objective. We\ncall the resulting algorithms \"direct policy gradient\" (DirPG) algorithms. A\nmain benefit of DirPG algorithms is that they allow the insertion of domain\nknowledge in the form of upper bounds on return-to-go at training time, like is\nused in heuristic search, while still directly computing a policy gradient. We\nfurther analyze their properties, showing there are cases where DirPG has an\nexponentially larger probability of sampling informative gradients compared to\nREINFORCE. We also show that there is a built-in variance reduction technique\nand that a parameter that was previously viewed as a numerical approximation\ncan be interpreted as controlling risk sensitivity. Empirically, we evaluate\nthe effect of key degrees of freedom and show that the algorithm performs well\nin illustrative domains compared to baselines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 07:50:36 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 08:52:59 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lorberbom", "Guy", ""], ["Maddison", "Chris J.", ""], ["Heess", "Nicolas", ""], ["Hazan", "Tamir", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1906.06080", "submitter": "Jiuyong Li", "authors": "Jiuyong Li, Saisai Ma, Lin Liu, Thuc Duy Le, Jixue Liu, and Yizhao Han", "title": "Identify treatment effect patterns for personalised decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In personalised decision making, evidence is required to determine suitable\nactions for individuals. Such evidence can be obtained by identifying treatment\neffect heterogeneity in different subgroups of the population. In this paper,\nwe design a new type of pattern, treatment effect pattern to represent and\ndiscover treatment effect heterogeneity from data for determining whether a\ntreatment will work for an individual or not. Our purpose is to use the\ncomputational power to find the most specific and relevant conditions for\nindividuals with respect to a treatment or an action to assist with\npersonalised decision making. Most existing work on identifying treatment\neffect heterogeneity takes a top-down or partitioning based approach to search\nfor subgroups with heterogeneous treatment effects. We propose a bottom-up\ngeneralisation algorithm to obtain the most specific patterns that fit\nindividual circumstances the best for personalised decision making. For the\ngeneralisation, we follow a consistency driven strategy to maintain inner-group\nhomogeneity and inter-group heterogeneity of treatment effects. We also employ\ngraphical causal modelling technique to identify adjustment variables for\nreliable treatment effect pattern discovery. Our method can find the treatment\neffect patterns reliably as validated by the experiments. The method is faster\nthan the two existing machine learning methods for heterogeneous treatment\neffect identification and it produces subgroups with higher inner-group\ntreatment effect homogeneity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 08:42:21 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Li", "Jiuyong", ""], ["Ma", "Saisai", ""], ["Liu", "Lin", ""], ["Le", "Thuc Duy", ""], ["Liu", "Jixue", ""], ["Han", "Yizhao", ""]]}, {"id": "1906.06086", "submitter": "Thomas Brunner", "authors": "Thomas Brunner, Frederik Diehl, Alois Knoll", "title": "Copy and Paste: A Simple But Effective Initialization Method for\n  Black-Box Adversarial Attacks", "comments": "Presented at CVPR 2019 Workshop on Adversarial Machine Learning in\n  Real-World Computer Vision Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization methods for generating black-box adversarial examples have\nbeen proposed, but the aspect of initializing said optimizers has not been\nconsidered in much detail. We show that the choice of starting points is indeed\ncrucial, and that the performance of state-of-the-art attacks depends on it.\nFirst, we discuss desirable properties of starting points for attacking image\nclassifiers, and how they can be chosen to increase query efficiency. Notably,\nwe find that simply copying small patches from other images is a valid\nstrategy. We then present an evaluation on ImageNet that clearly demonstrates\nthe effectiveness of this method: Our initialization scheme reduces the number\nof queries required for a state-of-the-art Boundary Attack by 81%,\nsignificantly outperforming previous results reported for targeted black-box\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 09:17:19 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 16:58:39 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Brunner", "Thomas", ""], ["Diehl", "Frederik", ""], ["Knoll", "Alois", ""]]}, {"id": "1906.06090", "submitter": "Alessandro Calefati", "authors": "Riccardo La Grassa, Ignazio Gallo, Alessandro Calefati and Dimitri\n  Ognibene", "title": "Binary Classification using Pairs of Minimum Spanning Trees or N-ary\n  Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One-class classifiers are trained with target class only samples.\nIntuitively, their conservative modelling of the class description may benefit\nclassical classification tasks where classes are difficult to separate due to\noverlapping and data imbalance. In this work, three methods are proposed which\nleverage on the combination of one-class classifiers based on non-parametric\nmodels, N-ary Trees and Minimum Spanning Trees class descriptors (MST-CD), to\ntackle binary classification problems. The methods deal with the\ninconsistencies arising from combining multiple classifiers and with spurious\nconnections that MST-CD creates in multi-modal class distributions. As shown by\nour tests on several datasets, the proposed approach is feasible and comparable\nwith state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 09:28:10 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 07:57:55 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Calefati", "Alessandro", ""], ["Ognibene", "Dimitri", ""]]}, {"id": "1906.06096", "submitter": "Maxim Borisyak", "authors": "Maxim Borisyak, Artem Ryzhikov, Andrey Ustyuzhanin, Denis Derkach,\n  Fedor Ratnikov and Olga Mineeva", "title": "$(1 + \\varepsilon)$-class Classification: an Anomaly Detection Method\n  for Highly Imbalanced or Incomplete Data Sets", "comments": null, "journal-ref": "Journal of Machine Learning Research. 2020;21(72):1-22", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is not an easy problem since distribution of anomalous\nsamples is unknown a priori. We explore a novel method that gives a trade-off\npossibility between one-class and two-class approaches, and leads to a better\nperformance on anomaly detection problems with small or non-representative\nanomalous samples. The method is evaluated using several data sets and compared\nto a set of conventional one-class and two-class approaches.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 09:41:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Borisyak", "Maxim", ""], ["Ryzhikov", "Artem", ""], ["Ustyuzhanin", "Andrey", ""], ["Derkach", "Denis", ""], ["Ratnikov", "Fedor", ""], ["Mineeva", "Olga", ""]]}, {"id": "1906.06100", "submitter": "Alexander Mey", "authors": "Alexander Mey, Tom Viering, Marco Loog", "title": "A Distribution Dependent and Independent Complexity Analysis of Manifold\n  Regularization", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-44584-3_26", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold regularization is a commonly used technique in semi-supervised\nlearning. It enforces the classification rule to be smooth with respect to the\ndata-manifold. Here, we derive sample complexity bounds based on\npseudo-dimension for models that add a convex data dependent regularization\nterm to a supervised learning process, as is in particular done in Manifold\nregularization. We then compare the bound for those semi-supervised methods to\npurely supervised methods, and discuss a setting in which the semi-supervised\nmethod can only have a constant improvement, ignoring logarithmic terms. By\nviewing Manifold regularization as a kernel method we then derive Rademacher\nbounds which allow for a distribution dependent analysis. Finally we illustrate\nthat these bounds may be useful for choosing an appropriate manifold\nregularization parameter in situations with very sparsely labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 09:55:12 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 10:24:24 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Mey", "Alexander", ""], ["Viering", "Tom", ""], ["Loog", "Marco", ""]]}, {"id": "1906.06110", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana", "title": "Towards Compact and Robust Deep Neural Networks", "comments": "14 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive performance in many\napplications but their large number of parameters lead to significant\ncomputational and storage overheads. Several recent works attempt to mitigate\nthese overheads by designing compact networks using pruning of connections.\nHowever, we observe that most of the existing strategies to design compact\nnetworks fail to preserve network robustness against adversarial examples. In\nthis work, we rigorously study the extension of network pruning strategies to\npreserve both benign accuracy and robustness of a network. Starting with a\nformal definition of the pruning procedure, including pre-training, weights\npruning, and fine-tuning, we propose a new pruning method that can create\ncompact networks while preserving both benign accuracy and robustness. Our\nmethod is based on two main insights: (1) we ensure that the training\nobjectives of the pre-training and fine-tuning steps match the training\nobjective of the desired robust model (e.g., adversarial robustness/verifiable\nrobustness), and (2) we keep the pruning strategy agnostic to pre-training and\nfine-tuning objectives. We evaluate our method on four different networks on\nthe CIFAR-10 dataset and measure benign accuracy, empirical robust accuracy,\nand verifiable robust accuracy. We demonstrate that our pruning method can\npreserve on average 93\\% benign accuracy, 92.5\\% empirical robust accuracy, and\n85.0\\% verifiable robust accuracy while compressing the tested network by\n10$\\times$.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 10:12:02 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Sehwag", "Vikash", ""], ["Wang", "Shiqi", ""], ["Mittal", "Prateek", ""], ["Jana", "Suman", ""]]}, {"id": "1906.06134", "submitter": "Boris Lorbeer", "authors": "Boris Lorbeer, Tanja Deutsch, Peter Ruppel, Axel K\\\"upper", "title": "Anomaly Detection with HMM Gauge Likelihood Analysis", "comments": "published in proceedings: 2019 IEEE Fifth International Conference on\n  Big Data Computing Service and Applications (BigDataService)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper describes a new method, HMM gauge likelihood analysis, or GLA, of\ndetecting anomalies in discrete time series using Hidden Markov Models and\nclustering. At the center of the method lies the comparison of subsequences. To\nachieve this, they first get assigned to their Hidden Markov Models using the\nBaum-Welch algorithm. Next, those models are described by an approximating\nrepresentation of the probability distributions they define. Finally, this\nrepresentation is then analyzed with the help of some clustering technique or\nother outlier detection tool and anomalies are detected. Clearly, HMMs could be\nsubstituted by some other appropriate model, e.g. some other dynamic Bayesian\nnetwork. Our learning algorithm is unsupervised, so it does not require the\nlabeling of large amounts of data. The usability of this method is demonstrated\nby applying it to synthetic and real-world syslog data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 11:34:29 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 15:07:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lorbeer", "Boris", ""], ["Deutsch", "Tanja", ""], ["Ruppel", "Peter", ""], ["K\u00fcpper", "Axel", ""]]}, {"id": "1906.06151", "submitter": "Silvia Liberata Ullo", "authors": "Silvia L. Ullo and Maximillian S. Langenkamp and Tuomas P. Oikarinen\n  and Maria P. Del Rosso and Alessandro Sebastianelli and Federica Piccirillo\n  and Stefania Sica", "title": "Landslide Geohazard Assessment With Convolutional Neural Networks Using\n  Sentinel-2 Imagery Data", "comments": "4 pages, 3 figures, 1 table, accepted to 2019 IEEE IGARSS Conference\n  that will be held in Japan next July", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the authors aim to combine the latest state of the art models\nin image recognition with the best publicly available satellite images to\ncreate a system for landslide risk mitigation. We focus first on landslide\ndetection and further propose a similar system to be used for prediction. Such\nmodels are valuable as they could easily be scaled up to provide data for\nhazard evaluation, as satellite imagery becomes increasingly available. The\ngoal is to use satellite images and correlated data to enrich the public\nrepository of data and guide disaster relief efforts for locating precise areas\nwhere landslides have occurred. Different image augmentation methods are used\nto increase diversity in the chosen dataset and create more robust\nclassification. The resulting outputs are then fed into variants of 3-D\nconvolutional neural networks. A review of the current literature indicates\nthere is no research using CNNs (Convolutional Neural Networks) and freely\navailable satellite imagery for classifying landslide risk. The model has shown\nto be ultimately able to achieve a significantly better than baseline accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:22:54 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Ullo", "Silvia L.", ""], ["Langenkamp", "Maximillian S.", ""], ["Oikarinen", "Tuomas P.", ""], ["Del Rosso", "Maria P.", ""], ["Sebastianelli", "Alessandro", ""], ["Piccirillo", "Federica", ""], ["Sica", "Stefania", ""]]}, {"id": "1906.06166", "submitter": "Naresh Manwani", "authors": "Kulin Shah, Naresh Manwani", "title": "Online Active Learning of Reject Option Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is an important technique to reduce the number of labeled\nexamples in supervised learning. Active learning for binary classification has\nbeen well addressed in machine learning. However, active learning of the reject\noption classifier remains unaddressed. In this paper, we propose novel\nalgorithms for active learning of reject option classifiers. We develop an\nactive learning algorithm using double ramp loss function. We provide mistake\nbounds for this algorithm. We also propose a new loss function called double\nsigmoid loss function for reject option and corresponding active learning\nalgorithm. We offer a convergence guarantee for this algorithm. We provide\nextensive experimental results to show the effectiveness of the proposed\nalgorithms. The proposed algorithms efficiently reduce the number of label\nexamples required.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 12:36:52 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 12:06:57 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Shah", "Kulin", ""], ["Manwani", "Naresh", ""]]}, {"id": "1906.06178", "submitter": "Francesco Foglino", "authors": "Francesco Foglino, Christiano Coletto Christakou, Ricardo Luna\n  Gutierrez, Matteo Leonetti", "title": "Curriculum Learning for Cumulative Return Maximization", "comments": "Proceedings of the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI-19). arXiv admin note: text overlap with arXiv:1901.11478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning has been successfully used in reinforcement learning to\naccelerate the learning process, through knowledge transfer between tasks of\nincreasing complexity. Critical tasks, in which suboptimal exploratory actions\nmust be minimized, can benefit from curriculum learning, and its ability to\nshape exploration through transfer. We propose a task sequencing algorithm\nmaximizing the cumulative return, that is, the return obtained by the agent\nacross all the learning episodes. By maximizing the cumulative return, the\nagent not only aims at achieving high rewards as fast as possible, but also at\ndoing so while limiting suboptimal actions. We experimentally compare our task\nsequencing algorithm to several popular metaheuristic algorithms for\ncombinatorial optimization, and show that it achieves significantly better\nperformance on the problem of cumulative return maximization. Furthermore, we\nvalidate our algorithm on a critical task, optimizing a home controller for a\nmicro energy grid.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:38:56 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Foglino", "Francesco", ""], ["Christakou", "Christiano Coletto", ""], ["Gutierrez", "Ricardo Luna", ""], ["Leonetti", "Matteo", ""]]}, {"id": "1906.06180", "submitter": "Abdullah Nazib", "authors": "Abdullah Nazib, Clinton Fookes, Dimitri Perrin", "title": "Dense Deformation Network for High Resolution Tissue Cleared Image\n  Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent application of deep learning in various areas of medical image\nanalysis has brought excellent performance gains. In particular, technologies\nbased on deep learning in medical image registration can outperform traditional\noptimisation-based registration algorithms both in registration time and\naccuracy. However, the U-net based architectures used in most of the image\nregistration frameworks downscale the data, which removes global information\nand affects the deformation. In this paper, we present a densely connected\nconvolutional architecture for deformable image registration. Our proposed\ndense network downsizes data only in one stage and have dense connections\ninstead of the skip connections in U-net architecture. The training of the\nnetwork is unsupervised and does not require ground-truth deformation or any\nsynthetic deformation as a label. The proposed architecture is trained and\ntested on two different versions of tissue-cleared data, at 10\\% and 25\\%\nresolution of the original single-cell-resolution dataset. We demonstrate\ncomparable registration performance to state-of-the-art registration methods\nand superior performance to the deep-learning based VoxelMorph method in terms\nof accuracy and increased resolution handling ability. In both resolutions, the\nproposed DenseDeformation network outperforms VoxelMorph in registration\naccuracy. Importantly, it can register brains in one minute where conventional\nmethods can take hours at 25\\% resolution.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 11:54:19 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 00:56:27 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Nazib", "Abdullah", ""], ["Fookes", "Clinton", ""], ["Perrin", "Dimitri", ""]]}, {"id": "1906.06181", "submitter": "Mark Kozdoba", "authors": "Dan Fisher, Mark Kozdoba, Shie Mannor", "title": "Topic Modeling via Full Dependence Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new approach to topic modelling that scales to\nlarge datasets by using a compact representation of the data and by leveraging\nthe GPU architecture. In this approach, topics are learned directly from the\nco-occurrence data of the corpus. In particular, we introduce a novel mixture\nmodel which we term the Full Dependence Mixture (FDM) model. FDMs model second\nmoment under general generative assumptions on the data. While there is\nprevious work on topic modeling using second moments, we develop a direct\nstochastic optimization procedure for fitting an FDM with a single Kullback\nLeibler objective. Moment methods in general have the benefit that an iteration\nno longer needs to scale with the size of the corpus. Our approach allows us to\nleverage standard optimizers and GPUs for the problem of topic modeling. In\nparticular, we evaluate the approach on two large datasets, NeurIPS papers and\na Twitter corpus, with a large number of topics, and show that the approach\nperforms comparably or better than the the standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 10:47:41 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 10:14:17 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 15:40:08 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Fisher", "Dan", ""], ["Kozdoba", "Mark", ""], ["Mannor", "Shie", ""]]}, {"id": "1906.06196", "submitter": "Jean Kossaifi", "authors": "Jean Kossaifi, Antoine Toisoul, Adrian Bulat, Yannis Panagakis,\n  Timothy Hospedales and Maja Pantic", "title": "Factorized Higher-Order CNNs with an Application to Spatio-Temporal\n  Emotion Estimation", "comments": "IEEE CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks with spatio-temporal (i.e., 3D) or\nmultidimensional convolutions of higher-order is computationally challenging\ndue to millions of unknown parameters across dozens of layers. To alleviate\nthis, one approach is to apply low-rank tensor decompositions to convolution\nkernels in order to compress the network and reduce its number of parameters.\nAlternatively, new convolutional blocks, such as MobileNet, can be directly\ndesigned for efficiency. In this paper, we unify these two approaches by\nproposing a tensor factorization framework for efficient multidimensional\n(separable) convolutions of higher-order. Interestingly, the proposed framework\nenables a novel higher-order transduction, allowing to train a network on a\ngiven domain (e.g., 2D images or N-dimensional data in general) and using\ntransduction to generalize to higher-order data such as videos (or\n(N+K)-dimensional data in general), capturing for instance temporal dynamics\nwhile preserving the learnt spatial information.\n  We apply the proposed methodology, coined CP-Higher-Order Convolution\n(HO-CPConv), to spatio-temporal facial emotion analysis. Most existing facial\naffect models focus on static imagery and discard all temporal information.\nThis is due to the above-mentioned burden of training 3D convolutional nets and\nthe lack of large bodies of video data annotated by experts. We address both\nissues with our proposed framework. Initial training is first done on static\nimagery before using transduction to generalize to the temporal domain. We\ndemonstrate superior performance on three challenging large scale affect\nestimation datasets, AffectNet, SEWA, and AFEW-VA.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:30:57 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 23:57:47 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kossaifi", "Jean", ""], ["Toisoul", "Antoine", ""], ["Bulat", "Adrian", ""], ["Panagakis", "Yannis", ""], ["Hospedales", "Timothy", ""], ["Pantic", "Maja", ""]]}, {"id": "1906.06203", "submitter": "Leo Gautheron", "authors": "L\\'eo Gautheron (LHC), Pascal Germain (MODAL), Amaury Habrard (LHC),\n  Emilie Morvant (LHC), Marc Sebban (LHC), Valentina Zantedeschi (LHC)", "title": "Learning Landmark-Based Ensembles with Random Fourier Features and\n  Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Gradient Boosting algorithm for learning an ensemble of kernel\nfunctions adapted to the task at hand. Unlike state-of-the-art Multiple Kernel\nLearning techniques that make use of a pre-computed dictionary of kernel\nfunctions to select from, at each iteration we fit a kernel by approximating it\nas a weighted sum of Random Fourier Features (RFF) and by optimizing their\nbarycenter. This allows us to obtain a more versatile method, easier to setup\nand likely to have better performance. Our study builds on a recent result\nshowing one can learn a kernel from RFF by computing the minimum of a\nPAC-Bayesian bound on the kernel alignment generalization loss, which is\nobtained efficiently from a closed-form solution. We conduct an experimental\nanalysis to highlight the advantages of our method w.r.t. both Boosting-based\nand kernel-learning state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:48:19 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Gautheron", "L\u00e9o", "", "LHC"], ["Germain", "Pascal", "", "MODAL"], ["Habrard", "Amaury", "", "LHC"], ["Morvant", "Emilie", "", "LHC"], ["Sebban", "Marc", "", "LHC"], ["Zantedeschi", "Valentina", "", "LHC"]]}, {"id": "1906.06205", "submitter": "Chi Zhang", "authors": "Chi Zhang, Qianxiao Li", "title": "Distributed Optimization for Over-Parameterized Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization often consists of two updating phases: local\noptimization and inter-node communication. Conventional approaches require\nworking nodes to communicate with the server every one or few iterations to\nguarantee convergence. In this paper, we establish a completely different\nconclusion that each node can perform an arbitrary number of local optimization\nsteps before communication. Moreover, we show that the more local updating can\nreduce the overall communication, even for an infinity number of steps where\neach node is free to update its local model to near-optimality before\nexchanging information. The extra assumption we make is that the optimal sets\nof local loss functions have a non-empty intersection, which is inspired by the\nover-paramterization phenomenon in large-scale optimization and deep learning.\nOur theoretical findings are confirmed by both distributed convex optimization\nand deep learning experiments.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:52:26 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Zhang", "Chi", ""], ["Li", "Qianxiao", ""]]}, {"id": "1906.06207", "submitter": "Markus Kitza", "authors": "Markus Kitza, Pavel Golik, Ralf Schl\\\"uter, Hermann Ney", "title": "Cumulative Adaptation for BLSTM Acoustic Models", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the robust speech recognition problem as an adaptation\ntask. Specifically, we investigate the cumulative application of adaptation\nmethods. A bidirectional Long Short-Term Memory (BLSTM) based neural network,\ncapable of learning temporal relationships and translation invariant\nrepresentations, is used for robust acoustic modelling. Further, i-vectors were\nused as an input to the neural network to perform instantaneous speaker and\nenvironment adaptation, providing 8\\% relative improvement in word error rate\non the NIST Hub5 2000 evaluation test set. By enhancing the first-pass i-vector\nbased adaptation with a second-pass adaptation using speaker and environment\ndependent transformations within the network, a further relative improvement of\n5\\% in word error rate was achieved. We have reevaluated the features used to\nestimate i-vectors and their normalization to achieve the best performance in a\nmodern large scale automatic speech recognition system.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:55:12 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kitza", "Markus", ""], ["Golik", "Pavel", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1906.06211", "submitter": "Louis Faury", "authors": "Louis Faury, Ugo Tanielian, Flavian Vasile, Elena Smirnova, Elvis\n  Dohmatob", "title": "Distributionally Robust Counterfactual Risk Minimization", "comments": "Accepted at AAAI20", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript introduces the idea of using Distributionally Robust\nOptimization (DRO) for the Counterfactual Risk Minimization (CRM) problem.\nTapping into a rich existing literature, we show that DRO is a principled tool\nfor counterfactual decision making. We also show that well-established\nsolutions to the CRM problem like sample variance penalization schemes are\nspecial instances of a more general DRO problem. In this unifying framework, a\nvariety of distributionally robust counterfactual risk estimators can be\nconstructed using various probability distances and divergences as uncertainty\nmeasures. We propose the use of Kullback-Leibler divergence as an alternative\nway to model uncertainty in CRM and derive a new robust counterfactual\nobjective. In our experiments, we show that this approach outperforms the\nstate-of-the-art on four benchmark datasets, validating the relevance of using\nother uncertainty measures in practical applications.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 14:04:09 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 22:47:06 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Faury", "Louis", ""], ["Tanielian", "Ugo", ""], ["Vasile", "Flavian", ""], ["Smirnova", "Elena", ""], ["Dohmatob", "Elvis", ""]]}, {"id": "1906.06247", "submitter": "Rohith Kuditipudi", "authors": "Rohith Kuditipudi, Xiang Wang, Holden Lee, Yi Zhang, Zhiyuan Li, Wei\n  Hu, Sanjeev Arora, Rong Ge", "title": "Explaining Landscape Connectivity of Low-cost Solutions for Multilayer\n  Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode connectivity is a surprising phenomenon in the loss landscape of deep\nnets. Optima -- at least those discovered by gradient-based optimization --\nturn out to be connected by simple paths on which the loss function is almost\nconstant. Often, these paths can be chosen to be piece-wise linear, with as few\nas two segments. We give mathematical explanations for this phenomenon,\nassuming generic properties (such as dropout stability and noise stability) of\nwell-trained deep nets, which have previously been identified as part of\nunderstanding the generalization properties of deep nets. Our explanation holds\nfor realistic multilayer nets, and experiments are presented to verify the\ntheory.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 15:21:54 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 17:02:16 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kuditipudi", "Rohith", ""], ["Wang", "Xiang", ""], ["Lee", "Holden", ""], ["Zhang", "Yi", ""], ["Li", "Zhiyuan", ""], ["Hu", "Wei", ""], ["Arora", "Sanjeev", ""], ["Ge", "Rong", ""]]}, {"id": "1906.06248", "submitter": "Simon Schn\\\"urch", "authors": "Simon Schn\\\"urch and Andreas Wagner", "title": "Machine Learning on EPEX Order Books: Insights and Forecasts", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper employs machine learning algorithms to forecast German electricity\nspot market prices. The forecasts utilize in particular bid and ask order book\ndata from the spot market but also fundamental market data like renewable\ninfeed and expected demand. Appropriate feature extraction for the order book\ndata is developed. Using cross-validation to optimise hyperparameters, neural\nnetworks and random forests are proposed and compared to statistical reference\nmodels. The machine learning models outperform traditional approaches.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 15:21:58 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 08:43:38 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 08:00:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Schn\u00fcrch", "Simon", ""], ["Wagner", "Andreas", ""]]}, {"id": "1906.06250", "submitter": "Sabber Ahamed", "authors": "Sabber Ahamed and Eric G. Daub", "title": "Machine Learning Approach to Earthquake Rupture Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulating dynamic rupture propagation is challenging due to the\nuncertainties involved in the underlying physics of fault slip, stress\nconditions, and frictional properties of the fault. A trial and error approach\nis often used to determine the unknown parameters describing rupture, but\nrunning many simulations usually requires human review to determine how to\nadjust parameter values and is thus not very efficient. To reduce the\ncomputational cost and improve our ability to determine reasonable stress and\nfriction parameters, we take advantage of the machine learning approach. We\ndevelop two models for earthquake rupture propagation using the artificial\nneural network (ANN) and the random forest (RF) algorithms to predict if a\nrupture can break a geometric heterogeneity on a fault. We train the models\nusing a database of 1600 dynamic rupture simulations computed numerically.\nFault geometry, stress conditions, and friction parameters vary in each\nsimulation. We cross-validate and test the predictive power of the models using\nan additional 400 simulated ruptures, respectively. Both RF and ANN models\npredict rupture propagation with more than 81% accuracy, and model parameters\ncan be used to infer the underlying factors most important for rupture\npropagation. Both of the models are computationally efficient such that the 400\ntestings require a fraction of a second, leading to potential applications of\ndynamic rupture that have previously not been possible due to the computational\ndemands of physics-based rupture simulations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 15:31:59 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Ahamed", "Sabber", ""], ["Daub", "Eric G.", ""]]}, {"id": "1906.06268", "submitter": "Luca Corinzia", "authors": "Luca Corinzia and Ami Beuret and Joachim M. Buhmann", "title": "Variational Federated Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In federated learning, a central server coordinates the training of a single\nmodel on a massively distributed network of devices. This setting can be\nnaturally extended to a multi-task learning framework, to handle real-world\nfederated datasets that typically show strong statistical heterogeneity among\ndevices. Despite federated multi-task learning being shown to be an effective\nparadigm for real-world datasets, it has been applied only on convex models. In\nthis work, we introduce VIRTUAL, an algorithm for federated multi-task learning\nfor general non-convex models. In VIRTUAL the federated network of the server\nand the clients is treated as a star-shaped Bayesian network, and learning is\nperformed on the network using approximated variational inference. We show that\nthis method is effective on real-world federated datasets, outperforming the\ncurrent state-of-the-art for federated learning, and concurrently allowing\nsparser gradient updates.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:09:56 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 14:38:06 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Corinzia", "Luca", ""], ["Beuret", "Ami", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1906.06273", "submitter": "Hannes Eriksson", "authors": "Hannes Eriksson, Christos Dimitrakakis", "title": "Epistemic Risk-Sensitive Reinforcement Learning", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the 28th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2020)\n  339-344", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for interacting with uncertain environments in\nreinforcement learning (RL) by leveraging preferences in the form of utility\nfunctions. We claim that there is value in considering different risk measures\nduring learning. In this framework, the preference for risk can be tuned by\nvariation of the parameter $\\beta$ and the resulting behavior can be\nrisk-averse, risk-neutral or risk-taking depending on the parameter choice. We\nevaluate our framework for learning problems with model uncertainty. We measure\nand control for \\emph{epistemic} risk using dynamic programming (DP) and policy\ngradient-based algorithms. The risk-averse behavior is then compared with the\nbehavior of the optimal risk-neutral policy in environments with epistemic\nrisk.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:25:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Eriksson", "Hannes", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1906.06276", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini", "title": "Spectrally-truncated kernel ridge regression and its free lunch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel ridge regression (KRR) is a well-known and popular nonparametric\nregression approach with many desirable properties, including minimax\nrate-optimality in estimating functions that belong to common reproducing\nkernel Hilbert spaces (RKHS). The approach, however, is computationally\nintensive for large data sets, due to the need to operate on a dense $n \\times\nn$ kernel matrix, where $n$ is the sample size. Recently, various approximation\nschemes for solving KRR have been considered, and some analyzed. Some\napproaches such as Nystr\\\"{o}m approximation and sketching have been shown to\npreserve the rate optimality of KRR. In this paper, we consider the simplest\napproximation, namely, spectrally truncating the kernel matrix to its largest\n$r < n$ eigenvalues. We derive an exact expression for the maximum risk of this\ntruncated KRR, over the unit ball of the RKHS. This result can be used to study\nthe exact trade-off between the level of spectral truncation and the\nregularization parameter. We show that, as long as the RKHS is\ninfinite-dimensional, there is a threshold on $r$, above which, the\nspectrally-truncated KRR surprisingly outperforms the full KRR in terms of the\nminimax risk, where the minimum is taken over the regularization parameter.\nThis strengthens the existing results on approximation schemes, by showing that\nnot only one does not lose in terms of the rates, truncation can in fact\nimprove the performance, for all finite samples (above the threshold).\nMoreover, we show that the implicit regularization achieved by spectral\ntruncation is not a substitute for Hilbert norm regularization. Both are needed\nto achieve the best performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:29:25 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 18:11:38 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Amini", "Arash A.", ""]]}, {"id": "1906.06283", "submitter": "Dennis Willsch", "authors": "Dennis Willsch, Madita Willsch, Hans De Raedt, Kristel Michielsen", "title": "Support vector machines on the D-Wave quantum annealer", "comments": "corrected typo in Eq. (11) and relation to SVM variant on p. 4; open\n  source code available at\n  https://gitlab.version.fz-juelich.de/cavallaro1/svm_quantum-annealer", "journal-ref": "Comput. Phys. Commun. 248, 107006 (2020)", "doi": "10.1016/j.cpc.2019.107006", "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based support vector machines (SVMs) are supervised machine learning\nalgorithms for classification and regression problems. We introduce a method to\ntrain SVMs on a D-Wave 2000Q quantum annealer and study its performance in\ncomparison to SVMs trained on conventional computers. The method is applied to\nboth synthetic data and real data obtained from biology experiments. We find\nthat the quantum annealer produces an ensemble of different solutions that\noften generalizes better to unseen data than the single global minimum of an\nSVM trained on a conventional computer, especially in cases where only limited\ntraining data is available. For cases with more training data than currently\nfits on the quantum annealer, we show that a combination of classifiers for\nsubsets of the data almost always produces stronger joint classifiers than the\nconventional SVM for the same parameters.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:45:01 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 10:47:46 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 10:23:30 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Willsch", "Dennis", ""], ["Willsch", "Madita", ""], ["De Raedt", "Hans", ""], ["Michielsen", "Kristel", ""]]}, {"id": "1906.06285", "submitter": "Bo Lin", "authors": "Qianxiao Li, Bo Lin, and Weiqing Ren", "title": "Computing Committor Functions for the Study of Rare Events Using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1063/1.5110439", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The committor function is a central object of study in understanding\ntransitions between metastable states in complex systems. However, computing\nthe committor function for realistic systems at low temperatures is a\nchallenging task, due to the curse of dimensionality and the scarcity of\ntransition data. In this paper, we introduce a computational approach that\novercomes these issues and achieves good performance on complex benchmark\nproblems with rough energy landscapes. The new approach combines deep learning,\ndata sampling and feature engineering techniques. This establishes an\nalternative practical method for studying rare transition events between\nmetastable states in complex, high dimensional systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:48:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Qianxiao", ""], ["Lin", "Bo", ""], ["Ren", "Weiqing", ""]]}, {"id": "1906.06295", "submitter": "Daniil Merkulov", "authors": "Daniil Merkulov, Ivan Oseledets", "title": "Empirical study of extreme overfitting points of neural networks", "comments": null, "journal-ref": "J. Commun. Technol. Electron. 64, 1527-1534 (2019)", "doi": "10.1134/S1064226919120118", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a method of obtaining points of extreme overfitting\n- parameters of modern neural networks, at which they demonstrate close to 100\n% training accuracy, simultaneously with almost zero accuracy on the test\nsample. Despite the widespread opinion that the overwhelming majority of\ncritical points of the loss function of a neural network have equally good\ngeneralizing ability, such points have a huge generalization error. The paper\nstudies the properties of such points and their location on the surface of the\nloss function of modern neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:06:21 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 10:57:33 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Merkulov", "Daniil", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1906.06298", "submitter": "Tao Li", "authors": "Tao Li, Vivek Srikumar", "title": "Augmenting Neural Networks with First-order Logic", "comments": "Accepted in ACL 2019. Minor fixes in Fig 4; extra citation in related\n  works; Typo fix in constraint N3 and its description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the dominant paradigm for training neural networks involves minimizing\ntask loss on a large dataset. Using world knowledge to inform a model, and yet\nretain the ability to perform end-to-end training remains an open question. In\nthis paper, we present a novel framework for introducing declarative knowledge\nto neural network architectures in order to guide training and prediction. Our\nframework systematically compiles logical statements into computation graphs\nthat augment a neural network without extra learnable parameters or manual\nredesign. We evaluate our modeling strategy on three tasks: machine\ncomprehension, natural language inference, and text chunking. Our experiments\nshow that knowledge-augmented networks can strongly improve over baselines,\nespecially in low-data regimes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:10:42 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 16:14:28 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 19:08:51 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Li", "Tao", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1906.06307", "submitter": "Namhoon Lee", "authors": "Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, Philip H. S. Torr", "title": "A Signal Propagation Perspective for Pruning Neural Networks at\n  Initialization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is a promising avenue for compressing deep neural networks. A\ntypical approach to pruning starts by training a model and then removing\nredundant parameters while minimizing the impact on what is learned.\nAlternatively, a recent approach shows that pruning can be done at\ninitialization prior to training, based on a saliency criterion called\nconnection sensitivity. However, it remains unclear exactly why pruning an\nuntrained, randomly initialized neural network is effective. In this work, by\nnoting connection sensitivity as a form of gradient, we formally characterize\ninitialization conditions to ensure reliable connection sensitivity\nmeasurements, which in turn yields effective pruning results. Moreover, we\nanalyze the signal propagation properties of the resulting pruned networks and\nintroduce a simple, data-free method to improve their trainability. Our\nmodifications to the existing pruning at initialization method lead to improved\nresults on all tested network models for image classification tasks.\nFurthermore, we empirically study the effect of supervision for pruning and\ndemonstrate that our signal propagation perspective, combined with unsupervised\npruning, can be useful in various scenarios where pruning is applied to\nnon-standard arbitrarily-designed architectures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:26:29 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 18:23:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lee", "Namhoon", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Gould", "Stephen", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1906.06316", "submitter": "Huan Zhang", "authors": "Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth,\n  Bo Li, Duane Boning, Cho-Jui Hsieh", "title": "Towards Stable and Efficient Training of Verifiably Robust Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks with verifiable robustness guarantees is\nchallenging. Several existing approaches utilize linear relaxation based neural\nnetwork output bounds under perturbation, but they can slow down training by a\nfactor of hundreds depending on the underlying network architectures.\nMeanwhile, interval bound propagation (IBP) based training is efficient and\nsignificantly outperforms linear relaxation based methods on many tasks, yet it\nmay suffer from stability issues since the bounds are much looser especially at\nthe beginning of training. In this paper, we propose a new certified\nadversarial training method, CROWN-IBP, by combining the fast IBP bounds in a\nforward bounding pass and a tight linear relaxation based bound, CROWN, in a\nbackward bounding pass. CROWN-IBP is computationally efficient and consistently\noutperforms IBP baselines on training verifiably robust neural networks. We\nconduct large scale experiments on MNIST and CIFAR datasets, and outperform all\nprevious linear relaxation and bound propagation based certified defenses in\n$\\ell_\\infty$ robustness. Notably, we achieve 7.02% verified test error on\nMNIST at $\\epsilon=0.3$, and 66.94% on CIFAR-10 with $\\epsilon=8/255$. Code is\navailable at https://github.com/deepmind/interval-bound-propagation\n(TensorFlow) and https://github.com/huanzhang12/CROWN-IBP (PyTorch).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:44:40 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:03:27 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Xiao", "Chaowei", ""], ["Gowal", "Sven", ""], ["Stanforth", "Robert", ""], ["Li", "Bo", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.06321", "submitter": "Simon Du", "authors": "Simon S. Du, Yuping Luo, Ruosong Wang, Hanrui Zhang", "title": "Provably Efficient $Q$-learning with Function Approximation via\n  Distribution Shift Error Checking Oracle", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $Q$-learning with function approximation is one of the most popular methods\nin reinforcement learning. Though the idea of using function approximation was\nproposed at least 60 years ago, even in the simplest setup, i.e, approximating\n$Q$-functions with linear functions, it is still an open problem on how to\ndesign a provably efficient algorithm that learns a near-optimal policy. The\nkey challenges are how to efficiently explore the state space and how to decide\nwhen to stop exploring in conjunction with the function approximation scheme.\n  The current paper presents a provably efficient algorithm for $Q$-learning\nwith linear function approximation. Under certain regularity assumptions, our\nalgorithm, Difference Maximization $Q$-learning (DMQ), combined with linear\nfunction approximation, returns a near-optimal policy using a polynomial number\nof trajectories. Our algorithm introduces a new notion, the Distribution Shift\nError Checking (DSEC) oracle. This oracle tests whether there exists a function\nin the function class that predicts well on a distribution $\\mathcal{D}_1$, but\npredicts poorly on another distribution $\\mathcal{D}_2$, where $\\mathcal{D}_1$\nand $\\mathcal{D}_2$ are distributions over states induced by two different\nexploration policies. For the linear function class, this oracle is equivalent\nto solving a top eigenvalue problem. We believe our algorithmic insights,\nespecially the DSEC oracle, are also useful in designing and analyzing\nreinforcement learning algorithms with general function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:55:05 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 16:11:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Du", "Simon S.", ""], ["Luo", "Yuping", ""], ["Wang", "Ruosong", ""], ["Zhang", "Hanrui", ""]]}, {"id": "1906.06329", "submitter": "Stefan Leichenauer", "authors": "Stavros Efthymiou, Jack Hidary, Stefan Leichenauer", "title": "TensorNetwork for Machine Learning", "comments": "9 pages, 8 figures. All code can be found at\n  https://github.com/google/tensornetwork", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.str-el cs.CV physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the use of tensor networks for image classification with the\nTensorNetwork open source library. We explain in detail the encoding of image\ndata into a matrix product state form, and describe how to contract the network\nin a way that is parallelizable and well-suited to automatic gradients for\noptimization. Applying the technique to the MNIST and Fashion-MNIST datasets we\nfind out-of-the-box performance of 98% and 88% accuracy, respectively, using\nthe same tensor network architecture. The TensorNetwork library allows us to\nseamlessly move from CPU to GPU hardware, and we see a factor of more than 10\nimprovement in computational speed using a GPU.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:58:31 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Efthymiou", "Stavros", ""], ["Hidary", "Jack", ""], ["Leichenauer", "Stefan", ""]]}, {"id": "1906.06357", "submitter": "Ekram Hossain", "authors": "Tao Zhang, Kun Zhu, and Ekram Hossain", "title": "Data-Driven Machine Learning Techniques for Self-healing in Cellular\n  Wireless Networks: Challenges and Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For enabling automatic deployment and management of cellular networks, the\nconcept of self-organizing network (SON) was introduced. SON capabilities can\nenhance network performance, improve service quality, and reduce operational\nand capital expenditure (OPEX/CAPEX). As an important component in SON,\nself-healing is defined as a network paradigm where the faults of target\nnetworks are mitigated or recovered by automatically triggering a series of\nactions such as detection, diagnosis and compensation. Data-driven machine\nlearning has been recognized as a powerful tool to bring intelligence into\nnetwork and to realize self-healing. However, there are major challenges for\npractical applications of machine learning techniques for self-healing. In this\narticle, we first classify these challenges into five categories: 1) data\nimbalance, 2) data insufficiency, 3) cost insensitivity, 4) non-real-time\nresponse, and 5) multi-source data fusion. Then we provide potential technical\nsolutions to address these challenges. Furthermore, a case study of\ncost-sensitive fault detection with imbalanced data is provided to illustrate\nthe feasibility and effectiveness of the suggested solutions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:16:21 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Kun", ""], ["Hossain", "Ekram", ""]]}, {"id": "1906.06365", "submitter": "Nir Rosenfeld", "authors": "Nir Rosenfeld, Kojin Oshiba, Yaron Singer", "title": "Predicting Choice with Set-Dependent Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing users with alternatives to choose from is an essential component in\nmany online platforms, making the accurate prediction of choice vital to their\nsuccess. A renewed interest in learning choice models has led to significant\nprogress in modeling power, but most current methods are either limited in the\ntypes of choice behavior they capture, cannot be applied to large-scale data,\nor both.\n  Here we propose a learning framework for predicting choice that is accurate,\nversatile, theoretically grounded, and scales well. Our key modeling point is\nthat to account for how humans choose, predictive models must capture certain\nset-related invariances. Building on recent results in economics, we derive a\nclass of models that can express any behavioral choice pattern, enjoy favorable\nsample complexity guarantees, and can be efficiently trained end-to-end.\nExperiments on three large choice datasets demonstrate the utility of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:43:10 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 14:26:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rosenfeld", "Nir", ""], ["Oshiba", "Kojin", ""], ["Singer", "Yaron", ""]]}, {"id": "1906.06382", "submitter": "Rendani Mbuvha", "authors": "Rendani Mbuvha, Illyes Boulkaibet, Tshilidzi Marwala", "title": "Automatic Relevance Determination Bayesian Neural Networks for Credit\n  Card Default Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit risk modelling is an integral part of the global financial system.\nWhile there has been great attention paid to neural network models for credit\ndefault prediction, such models often lack the required interpretation\nmechanisms and measures of the uncertainty around their predictions. This work\ndevelops and compares Bayesian Neural Networks(BNNs) for credit card default\nmodelling. This includes a BNNs trained by Gaussian approximation and the first\nimplementation of BNNs trained by Hybrid Monte Carlo(HMC) in credit risk\nmodelling. The results on the Taiwan Credit Dataset show that BNNs with\nAutomatic Relevance Determination(ARD) outperform normal BNNs without ARD. The\nresults also show that BNNs trained by Gaussian approximation display similar\npredictive performance to those trained by the HMC. The results further show\nthat BNN with ARD can be used to draw inferences about the relative importance\nof different features thus critically aiding decision makers in explaining\nmodel output to consumers. The robustness of this result is reinforced by high\nlevels of congruence between the features identified as important using the two\ndifferent approaches for training BNNs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:00:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mbuvha", "Rendani", ""], ["Boulkaibet", "Illyes", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "1906.06393", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer", "title": "A Unified Framework of Constrained Robust Submodular Optimization with\n  Applications", "comments": "V2, Match 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust optimization is becoming increasingly important in machine learning\napplications. In this paper, we study a unified framework of robust submodular\noptimization. We study this problem both from a minimization and maximization\nperspective (previous work has only focused on variants of robust submodular\nmaximization). We do this under a broad range of combinatorial constraints\nincluding cardinality, knapsack, matroid as well as graph-based constraints\nsuch as cuts, paths, matchings and trees. Furthermore, we also study robust\nsubmodular minimization and maximization under multiple submodular upper and\nlower bound constraints. We show that all these problems are motivated by\nimportant machine learning applications including robust data subset selection,\nrobust co-operative cuts and robust co-operative matchings. In each case, we\nprovide scalable approximation algorithms and also study hardness bounds.\nFinally, we empirically demonstrate the utility of our algorithms on synthetic\ndata, and real-world applications of robust cooperative matchings for image\ncorrespondence, robust data subset selection for speech recognition, and image\ncollection summarization with multiple queries.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:33:41 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 23:26:09 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Iyer", "Rishabh", ""]]}, {"id": "1906.06397", "submitter": "Rohan Paleja", "authors": "Rohan Paleja, Andrew Silva, Letian Chen, Matthew Gombolay", "title": "Interpretable and Personalized Apprenticeship Scheduling: Learning\n  Interpretable Scheduling Policies from Heterogeneous User Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource scheduling and coordination is an NP-hard optimization requiring an\nefficient allocation of agents to a set of tasks with upper- and lower bound\ntemporal and resource constraints. Due to the large-scale and dynamic nature of\nresource coordination in hospitals and factories, human domain experts manually\nplan and adjust schedules on the fly. To perform this job, domain experts\nleverage heterogeneous strategies and rules-of-thumb honed over years of\napprenticeship. What is critically needed is the ability to extract this domain\nknowledge in a heterogeneous and interpretable apprenticeship learning\nframework to scale beyond the power of a single human expert, a necessity in\nsafety-critical domains. We propose a personalized and interpretable\napprenticeship scheduling algorithm that infers an interpretable representation\nof all human task demonstrators by extracting decision-making criteria via an\ninferred, personalized embedding non-parametric in the number of demonstrator\ntypes. We achieve near-perfect LfD accuracy in synthetic domains and 88.22\\%\naccuracy on a planning domain with real-world, outperforming baselines.\nFinally, our user study showed our methodology produces more interpretable and\neasier-to-use models than neural networks ($p < 0.05$).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:51:01 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 02:37:36 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 17:44:43 GMT"}, {"version": "v4", "created": "Thu, 5 Nov 2020 03:10:53 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Paleja", "Rohan", ""], ["Silva", "Andrew", ""], ["Chen", "Letian", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1906.06399", "submitter": "Sam Wiseman", "authors": "Sam Wiseman, Yoon Kim", "title": "Amortized Bethe Free Energy Minimization for Learning MRFs", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to learn deep undirected graphical models (i.e., MRFs) with a\nnon-ELBO objective for which we can calculate exact gradients. In particular,\nwe optimize a saddle-point objective deriving from the Bethe free energy\napproximation to the partition function. Unlike much recent work in approximate\ninference, the derived objective requires no sampling, and can be efficiently\ncomputed even for very expressive MRFs. We furthermore amortize this\noptimization with trained inference networks. Experimentally, we find that the\nproposed approach compares favorably with loopy belief propagation, but is\nfaster, and it allows for attaining better held out log likelihood than other\nrecent approximate inference schemes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:53:40 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 23:13:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wiseman", "Sam", ""], ["Kim", "Yoon", ""]]}, {"id": "1906.06406", "submitter": "Nikolas Tapia", "authors": "Elena Celledoni, P{\\aa}l Erik Lystad and Nikolas Tapia", "title": "Signatures in Shape Analysis: an Efficient Approach to Motion\n  Identification", "comments": "7 pages, 3 figures. Conference paper for Geometric Science of\n  Information 2019", "journal-ref": null, "doi": "10.1007/978-3-030-26980-7_3", "report-no": "Geometric Science of Information. GSI 2019. Lecture Notes in\n  Computer Science, vol 11712", "categories": "math.DG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signatures provide a succinct description of certain features of paths in a\nreparametrization invariant way. We propose a method for classifying shapes\nbased on signatures, and compare it to current approaches based on the SRV\ntransform and dynamic programming.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 21:14:34 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Celledoni", "Elena", ""], ["Lystad", "P\u00e5l Erik", ""], ["Tapia", "Nikolas", ""]]}, {"id": "1906.06419", "submitter": "Da Tang", "authors": "Da Tang, Dawen Liang, Nicholas Ruozzi, Tony Jebara", "title": "Learning Correlated Latent Representations with Adaptive Priors", "comments": "16 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoders (VAEs) have been widely applied for learning\ncompact, low-dimensional latent representations of high-dimensional data. When\nthe correlation structure among data points is available, previous work\nproposed Correlated Variational Auto-Encoders (CVAEs), which employ a\nstructured mixture model as prior and a structured variational posterior for\neach mixture component to enforce that the learned latent representations\nfollow the same correlation structure. However, as we demonstrate in this work,\nsuch a choice cannot guarantee that CVAEs capture all the correlations.\nFurthermore, it prevents us from obtaining a tractable joint and marginal\nvariational distribution. To address these issues, we propose Adaptive\nCorrelated Variational Auto-Encoders (ACVAEs), which apply an adaptive prior\ndistribution that can be adjusted during training and can learn a tractable\njoint variational distribution. Its tractable form also enables further\nrefinement with belief propagation. Experimental results on link prediction and\nhierarchical clustering show that ACVAEs significantly outperform CVAEs among\nother benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 21:58:58 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:29:20 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 20:08:17 GMT"}, {"version": "v4", "created": "Wed, 16 Oct 2019 18:58:59 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 23:27:14 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Tang", "Da", ""], ["Liang", "Dawen", ""], ["Ruozzi", "Nicholas", ""], ["Jebara", "Tony", ""]]}, {"id": "1906.06421", "submitter": "Wenying Ji", "authors": "Yitong Li, Wenying Ji", "title": "Enhanced Input Modeling for Construction Simulation using Bayesian Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/WSC40007.2019.9004934", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to propose a novel deep learning-integrated framework for\nderiving reliable simulation input models through incorporating multi-source\ninformation. The framework sources and extracts multisource data generated from\nconstruction operations, which provides rich information for input modeling.\nThe framework implements Bayesian deep neural networks to facilitate the\npurpose of incorporating richer information in input modeling. A case study on\nroad paving operation is performed to test the feasibility and applicability of\nthe proposed framework. Overall, this research enhances input modeling by\nderiving detailed input models, thereby, augmenting the decision-making\nprocesses in construction operations. This research also sheds lights on\nprompting data-driven simulation through incorporating machine learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 22:15:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Li", "Yitong", ""], ["Ji", "Wenying", ""]]}, {"id": "1906.06427", "submitter": "Francisco Messina", "authors": "Mohammadhadi Shateri, Francisco Messina, Pablo Piantanida, Fabrice\n  Labeau", "title": "Real-Time Privacy-Preserving Data Release for Smart Meters", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart Meters (SMs) are a fundamental component of smart grids, but they carry\nsensitive information about users such as occupancy status of houses and\ntherefore, they have raised serious concerns about leakage of consumers'\nprivate information. In particular, we focus on real-time privacy threats,\ni.e., potential attackers that try to infer sensitive data from SMs reported\ndata in an online fashion. We adopt an information-theoretic privacy measure\nand show that it effectively limits the performance of any real-time attacker.\nUsing this privacy measure, we propose a general formulation to design a\nprivatization mechanism that can provide a target level of privacy by adding a\nminimal amount of distortion to the SMs measurements. On the other hand, to\ncope with different applications, a flexible distortion measure is considered.\nThis formulation leads to a general loss function, which is optimized using a\ndeep learning adversarial framework, where two neural networks $-$ referred to\nas the releaser and the adversary $-$ are trained with opposite goals. An\nexhaustive empirical study is then performed to validate the performances of\nthe proposed approach for the occupancy detection privacy problem, assuming the\nattacker disposes of either limited or full access to the training dataset.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 22:57:20 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 23:51:57 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shateri", "Mohammadhadi", ""], ["Messina", "Francisco", ""], ["Piantanida", "Pablo", ""], ["Labeau", "Fabrice", ""]]}, {"id": "1906.06430", "submitter": "Abdullah-Al-Zubaer Imran", "authors": "Abdullah-Al-Zubaer Imran and Demetri Terzopoulos", "title": "Multi-Adversarial Variational Autoencoder Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unsupervised training of GANs and VAEs has enabled them to generate\nrealistic images mimicking real-world distributions and perform image-based\nunsupervised clustering or semi-supervised classification. Combining the power\nof these two generative models, we introduce Multi-Adversarial Variational\nautoEncoder Networks (MAVENs), a novel network architecture that incorporates\nan ensemble of discriminators in a VAE-GAN network, with simultaneous\nadversarial learning and variational inference. We apply MAVENs to the\ngeneration of synthetic images and propose a new distribution measure to\nquantify the quality of the generated images. Our experimental results using\ndatasets from the computer vision and medical imaging domains---Street View\nHouse Numbers, CIFAR-10, and Chest X-Ray datasets---demonstrate competitive\nperformance against state-of-the-art semi-supervised models both in image\ngeneration and classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:04:44 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Imran", "Abdullah-Al-Zubaer", ""], ["Terzopoulos", "Demetri", ""]]}, {"id": "1906.06439", "submitter": "Emily Denton", "authors": "Emily Denton, Ben Hutchinson, Margaret Mitchell, Timnit Gebru, Andrew\n  Zaldivar", "title": "Image Counterfactual Sensitivity Analysis for Detecting Unintended Bias", "comments": "Presented at CVPR 2019 Workshop on Fairness Accountability\n  Transparency and Ethics in Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial analysis models are increasingly used in applications that have\nserious impacts on people's lives, ranging from authentication to surveillance\ntracking. It is therefore critical to develop techniques that can reveal\nunintended biases in facial classifiers to help guide the ethical use of facial\nanalysis technology. This work proposes a framework called \\textit{image\ncounterfactual sensitivity analysis}, which we explore as a proof-of-concept in\nanalyzing a smiling attribute classifier trained on faces of celebrities. The\nframework utilizes counterfactuals to examine how a classifier's prediction\nchanges if a face characteristic slightly changes. We leverage recent advances\nin generative adversarial networks to build a realistic generative model of\nface images that affords controlled manipulation of specific image\ncharacteristics. We then introduce a set of metrics that measure the effect of\nmanipulating a specific property on the output of the trained classifier.\nEmpirically, we find several different factors of variation that affect the\npredictions of the smiling classifier. This proof-of-concept demonstrates\npotential ways generative models can be leveraged for fine-grained analysis of\nbias and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:50:04 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:45:47 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 21:33:55 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Denton", "Emily", ""], ["Hutchinson", "Ben", ""], ["Mitchell", "Margaret", ""], ["Gebru", "Timnit", ""], ["Zaldivar", "Andrew", ""]]}, {"id": "1906.06440", "submitter": "Evangelos Georganas", "authors": "Evangelos Georganas, Kunal Banerjee, Dhiraj Kalamkar, Sasikanth\n  Avancha, Anand Venkat, Michael Anderson, Greg Henry, Hans Pabst, Alexander\n  Heinecke", "title": "High-Performance Deep Learning via a Single Building Block", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is one of the most prominent branches of machine learning.\nDue to the immense computational cost of DL workloads, industry and academia\nhave developed DL libraries with highly-specialized kernels for each\nworkload/architecture, leading to numerous, complex code-bases that strive for\nperformance, yet they are hard to maintain and do not generalize. In this work,\nwe introduce the batch-reduce GEMM kernel and show how the most popular DL\nalgorithms can be formulated with this kernel as the basic building-block.\nConsequently, the DL library-development degenerates to mere (potentially\nautomatic) tuning of loops around this sole optimized kernel. By exploiting our\nnew kernel we implement Recurrent Neural Networks, Convolution Neural Networks\nand Multilayer Perceptron training and inference primitives in just 3K lines of\nhigh-level code. Our primitives outperform vendor-optimized libraries on\nmulti-node CPU clusters, and we also provide proof-of-concept CNN kernels\ntargeting GPUs. Finally, we demonstrate that the batch-reduce GEMM kernel\nwithin a tensor compiler yields high-performance CNN primitives, further\namplifying the viability of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 00:02:36 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 03:56:02 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Georganas", "Evangelos", ""], ["Banerjee", "Kunal", ""], ["Kalamkar", "Dhiraj", ""], ["Avancha", "Sasikanth", ""], ["Venkat", "Anand", ""], ["Anderson", "Michael", ""], ["Henry", "Greg", ""], ["Pabst", "Hans", ""], ["Heinecke", "Alexander", ""]]}, {"id": "1906.06449", "submitter": "Felipe Mejia", "authors": "Felipe A. Mejia, Paul Gamble, Zigfried Hampel-Arias, Michael Lomnitz,\n  Nina Lopatina, Lucas Tindall, Maria Alejandra Barrios", "title": "Robust or Private? Adversarial Training Makes Models More Vulnerable to\n  Privacy Attacks", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training was introduced as a way to improve the robustness of\ndeep learning models to adversarial attacks. This training method improves\nrobustness against adversarial attacks, but increases the models vulnerability\nto privacy attacks. In this work we demonstrate how model inversion attacks,\nextracting training data directly from the model, previously thought to be\nintractable become feasible when attacking a robustly trained model. The input\nspace for a traditionally trained model is dominated by adversarial examples -\ndata points that strongly activate a certain class but lack semantic meaning -\nthis makes it difficult to successfully conduct model inversion attacks. We\ndemonstrate this effect using the CIFAR-10 dataset under three different model\ninversion attacks, a vanilla gradient descent method, gradient based method at\ndifferent scales, and a generative adversarial network base attacks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 01:26:56 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mejia", "Felipe A.", ""], ["Gamble", "Paul", ""], ["Hampel-Arias", "Zigfried", ""], ["Lomnitz", "Michael", ""], ["Lopatina", "Nina", ""], ["Tindall", "Lucas", ""], ["Barrios", "Maria Alejandra", ""]]}, {"id": "1906.06465", "submitter": "Martin Jaggi", "authors": "Arno Schneuwly and Ralf Grubenmann and S\\'everine Rion Logean and Mark\n  Cieliebak and Martin Jaggi", "title": "Correlating Twitter Language with Community-Level Health Outcomes", "comments": "ACL SMM4H Workshop (Social Media Mining for Health Applications)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how language on social media is linked to diseases such as\natherosclerotic heart disease (AHD), diabetes and various types of cancer. Our\nproposed model leverages state-of-the-art sentence embeddings, followed by a\nregression model and clustering, without the need of additional labelled data.\nIt allows to predict community-level medical outcomes from language, and\nthereby potentially translate these to the individual level. The method is\napplicable to a wide range of target variables and allows us to discover known\nand potentially novel correlations of medical outcomes with life-style aspects\nand other socioeconomic risk factors.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 01:42:23 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 16:57:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Schneuwly", "Arno", ""], ["Grubenmann", "Ralf", ""], ["Logean", "S\u00e9verine Rion", ""], ["Cieliebak", "Mark", ""], ["Jaggi", "Martin", ""]]}, {"id": "1906.06498", "submitter": "Alberto Bemporad Prof.", "authors": "Alberto Bemporad", "title": "Global optimization via inverse distance weighting and radial basis\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global optimization problems whose objective function is expensive to\nevaluate can be solved effectively by recursively fitting a surrogate function\nto function samples and minimizing an acquisition function to generate new\nsamples. The acquisition step trades off between seeking for a new optimization\nvector where the surrogate is minimum (exploitation of the surrogate) and\nlooking for regions of the feasible space that have not yet been visited and\nthat may potentially contain better values of the objective function\n(exploration of the feasible space). This paper proposes a new global\noptimization algorithm that uses a combination of inverse distance weighting\n(IDW) and radial basis functions (RBF) to construct the acquisition function.\nRather arbitrary constraints that are simple to evaluate can be easily taken\ninto account. Compared to Bayesian optimization, the proposed algorithm, that\nwe call GLIS (GLobal minimum using Inverse distance weighting and Surrogate\nradial basis functions), is competitive and computationally lighter, as we show\nin a set of benchmark global optimization and hyperparameter tuning problems.\nMATLAB and Python implementations of GLIS are available at\n\\url{http://cse.lab.imtlucca.it/~bemporad/glis}.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 08:45:47 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 07:32:43 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Bemporad", "Alberto", ""]]}, {"id": "1906.06513", "submitter": "Marco Scutari", "authors": "Marco Scutari", "title": "Bayesian Network Models for Incomplete and Dynamic Data", "comments": "24 pages, 4 figures", "journal-ref": "Statistica Neerlandica (2020), 74(3), 397-419", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are a versatile and powerful tool to model complex\nphenomena and the interplay of their components in a probabilistically\nprincipled way. Moving beyond the comparatively simple case of completely\nobserved, static data, which has received the most attention in the literature,\nin this paper we will review how Bayesian networks can model dynamic data and\ndata with incomplete observations. Such data are the norm at the forefront of\nresearch and in practical applications, and Bayesian networks are uniquely\npositioned to model them due to their explainability and interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 09:59:04 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 12:17:33 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Scutari", "Marco", ""]]}, {"id": "1906.06532", "submitter": "Chun Wang", "authors": "Chun Wang, Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang and Chengqi\n  Zhang", "title": "Attributed Graph Clustering: A Deep Attentional Embedding Approach", "comments": "Accepted to IJCAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is a fundamental task which discovers communities or groups\nin networks. Recent studies have mostly focused on developing deep learning\napproaches to learn a compact graph embedding, upon which classic clustering\nmethods like k-means or spectral clustering algorithms are applied. These\ntwo-step frameworks are difficult to manipulate and usually lead to suboptimal\nperformance, mainly because the graph embedding is not goal-directed, i.e.,\ndesigned for the specific clustering task. In this paper, we propose a\ngoal-directed deep learning approach, Deep Attentional Embedded Graph\nClustering (DAEGC for short). Our method focuses on attributed graphs to\nsufficiently explore the two sides of information in graphs. By employing an\nattention network to capture the importance of the neighboring nodes to a\ntarget node, our DAEGC algorithm encodes the topological structure and node\ncontent in a graph to a compact representation, on which an inner product\ndecoder is trained to reconstruct the graph structure. Furthermore, soft labels\nfrom the graph embedding itself are generated to supervise a self-training\ngraph clustering process, which iteratively refines the clustering results. The\nself-training process is jointly learned and optimized with the graph embedding\nin a unified framework, to mutually benefit both components. Experimental\nresults compared with state-of-the-art algorithms demonstrate the superiority\nof our method.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 11:44:42 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Wang", "Chun", ""], ["Pan", "Shirui", ""], ["Hu", "Ruiqi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1906.06565", "submitter": "Yan Zhang", "authors": "Yan Zhang and Jonathon Hare and Adam Pr\\\"ugel-Bennett", "title": "Deep Set Prediction Networks", "comments": "Appendix C contains an erratum", "journal-ref": "Advances in Neural Information Processing Systems 32 (NeurIPS\n  2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current approaches for predicting sets from feature vectors ignore the\nunordered nature of sets and suffer from discontinuity issues as a result. We\npropose a general model for predicting sets that properly respects the\nstructure of sets and avoids this problem. With a single feature vector as\ninput, we show that our model is able to auto-encode point sets, predict the\nset of bounding boxes of objects in an image, and predict the set of attributes\nof these objects.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 13:48:32 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 11:02:57 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 10:09:18 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 09:33:25 GMT"}, {"version": "v5", "created": "Wed, 11 Mar 2020 14:10:03 GMT"}, {"version": "v6", "created": "Fri, 24 Apr 2020 20:49:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Yan", ""], ["Hare", "Jonathon", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1906.06566", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nikolaos Bassiliades and Grigorios Tsoumakas", "title": "LioNets: Local Interpretation of Neural Networks through Penultimate\n  Layer Decoding", "comments": "Submitted and accepted to AIMLAI-XKDD-ECMLPKDD19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological breakthroughs on smart homes, self-driving cars, health care\nand robotic assistants, in addition to reinforced law regulations, have\ncritically influenced academic research on explainable machine learning. A\nsufficient number of researchers have implemented ways to explain indifferently\nany black box model for classification tasks. A drawback of building agnostic\nexplanators is that the neighbourhood generation process is universal and\nconsequently does not guarantee true adjacency between the generated neighbours\nand the instance. This paper explores a methodology on providing explanations\nfor a neural network's decisions, in a local scope, through a process that\nactively takes into consideration the neural network's architecture on creating\nan instance's neighbourhood, that assures the adjacency among the generated\nneighbours and the instance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 13:56:09 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 06:25:14 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 10:17:43 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nikolaos", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1906.06576", "submitter": "Samy Badreddine", "authors": "Samy Badreddine, Michael Spranger", "title": "Injecting Prior Knowledge for Transfer Learning into Reinforcement\n  Learning Algorithms using Logic Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human ability at solving complex tasks is helped by priors on object and\nevent semantics of their environment. This paper investigates the use of\nsimilar prior knowledge for transfer learning in Reinforcement Learning agents.\nIn particular, the paper proposes to use a first-order-logic language grounded\nin deep neural networks to represent facts about objects and their semantics in\nthe real world. Facts are provided as background knowledge a priori to learning\na policy for how to act in the world. The priors are injected with the\nconventional input in a single agent architecture. As proof-of-concept, the\npaper tests the system in simple experiments that show the importance of\nsymbolic abstraction and flexible fact derivation. The paper shows that the\nproposed system can learn to take advantage of both the symbolic layer and the\nimage layer in a single decision selection module.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 15:26:26 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Badreddine", "Samy", ""], ["Spranger", "Michael", ""]]}, {"id": "1906.06589", "submitter": "Virat Shejwalkar", "authors": "Virat Shejwalkar and Amir Houmansadr", "title": "Membership Privacy for Machine Learning Models Through Knowledge\n  Transfer", "comments": "To Appear in the 35th AAAI Conference on Artificial Intelligence,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large capacity machine learning (ML) models are prone to membership inference\nattacks (MIAs), which aim to infer whether the target sample is a member of the\ntarget model's training dataset. The serious privacy concerns due to the\nmembership inference have motivated multiple defenses against MIAs, e.g.,\ndifferential privacy and adversarial regularization. Unfortunately, these\ndefenses produce ML models with unacceptably low classification performances.\nOur work proposes a new defense, called distillation for membership privacy\n(DMP), against MIAs that preserves the utility of the resulting models\nsignificantly better than prior defenses. DMP leverages knowledge distillation\nto train ML models with membership privacy. We provide a novel criterion to\ntune the data used for knowledge transfer in order to amplify the membership\nprivacy of DMP. Our extensive evaluation shows that DMP provides significantly\nbetter tradeoffs between membership privacy and classification accuracies\ncompared to state-of-the-art MIA defenses. For instance, DMP achieves ~100%\naccuracy improvement over adversarial regularization for DenseNet trained on\nCIFAR100, for similar membership privacy (measured using MIA risk): when the\nMIA risk is 53.7%, adversarially regularized DenseNet is 33.6% accurate, while\nDMP-trained DenseNet is 65.3% accurate.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 16:37:17 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 13:47:59 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 07:01:02 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Shejwalkar", "Virat", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1906.06594", "submitter": "Julian Katz-Samuels", "authors": "Julian Katz-Samuels, Kevin Jamieson", "title": "The True Sample Complexity of Identifying Good Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two multi-armed bandit problems with $n$ arms: (i) given an\n$\\epsilon > 0$, identify an arm with mean that is within $\\epsilon$ of the\nlargest mean and (ii) given a threshold $\\mu_0$ and integer $k$, identify $k$\narms with means larger than $\\mu_0$. Existing lower bounds and algorithms for\nthe PAC framework suggest that both of these problems require $\\Omega(n)$\nsamples. However, we argue that these definitions not only conflict with how\nthese algorithms are used in practice, but also that these results disagree\nwith intuition that says (i) requires only $\\Theta(\\frac{n}{m})$ samples where\n$m = |\\{ i : \\mu_i > \\max_{i \\in [n]} \\mu_i - \\epsilon\\}|$ and (ii) requires\n$\\Theta(\\frac{n}{m}k)$ samples where $m = |\\{ i : \\mu_i > \\mu_0 \\}|$. We\nprovide definitions that formalize these intuitions, obtain lower bounds that\nmatch the above sample complexities, and develop explicit, practical algorithms\nthat achieve nearly matching upper bounds.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 17:39:18 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Katz-Samuels", "Julian", ""], ["Jamieson", "Kevin", ""]]}, {"id": "1906.06595", "submitter": "Surbhi Goel", "authors": "Surbhi Goel", "title": "Learning Restricted Boltzmann Machines with Arbitrary External Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning graphical models with latent variables. We\ngive the first algorithm for learning locally consistent (ferromagnetic or\nantiferromagnetic) Restricted Boltzmann Machines (or RBMs) with {\\em arbitrary}\nexternal fields. Our algorithm has optimal dependence on dimension in the\nsample complexity and run time however it suffers from a sub-optimal dependency\non the underlying parameters of the RBM.\n  Prior results have been established only for {\\em ferromagnetic} RBMs with\n{\\em consistent} external fields (signs must be\nsame)\\cite{bresler2018learning}. The proposed algorithm strongly relies on the\nconcavity of magnetization which does not hold in our setting. We show the\nfollowing key structural property: even in the presence of arbitrary external\nfield, for any two observed nodes that share a common latent neighbor, the\ncovariance is high. This enables us to design a simple greedy algorithm that\nmaximizes covariance to iteratively build the neighborhood of each vertex.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 17:46:19 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Goel", "Surbhi", ""]]}, {"id": "1906.06613", "submitter": "Vitalii Emelianov", "authors": "Vitalii Emelianov, George Arvanitakis, Nicolas Gast, Krishna Gummadi,\n  Patrick Loiseau", "title": "The Price of Local Fairness in Multistage Selection", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of algorithmic decision making led to active researches on how to\ndefine and guarantee fairness, mostly focusing on one-shot decision making. In\nseveral important applications such as hiring, however, decisions are made in\nmultiple stage with additional information at each stage. In such cases,\nfairness issues remain poorly understood.\n  In this paper we study fairness in $k$-stage selection problems where\nadditional features are observed at every stage. We first introduce two\nfairness notions, local (per stage) and global (final stage) fairness, that\nextend the classical fairness notions to the $k$-stage setting. We propose a\nsimple model based on a probabilistic formulation and show that the locally and\nglobally fair selections that maximize precision can be computed via a linear\nprogram. We then define the price of local fairness to measure the loss of\nprecision induced by local constraints; and investigate theoretically and\nempirically this quantity. In particular, our experiments show that the price\nof local fairness is generally smaller when the sensitive attribute is observed\nat the first stage; but globally fair selections are more locally fair when the\nsensitive attribute is observed at the second stage---hence in both cases it is\noften possible to have a selection that has a small price of local fairness and\nis close to locally fair.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 21:00:53 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Emelianov", "Vitalii", ""], ["Arvanitakis", "George", ""], ["Gast", "Nicolas", ""], ["Gummadi", "Krishna", ""], ["Loiseau", "Patrick", ""]]}, {"id": "1906.06619", "submitter": "Gil Sadeh", "authors": "Gil Sadeh, Lior Fritz, Gabi Shalev and Eduard Oks", "title": "Generating Diverse and Informative Natural Language Fashion Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in multi-modal vision and language tasks enable a new set of\napplications. In this paper, we consider the task of generating natural\nlanguage fashion feedback on outfit images. We collect a unique dataset, which\ncontains outfit images and corresponding positive and constructive fashion\nfeedback. We treat each feedback type separately, and train deep generative\nencoder-decoder models with visual attention, similar to the standard image\ncaptioning pipeline. Following this approach, the generated sentences tend to\nbe too general and non-informative. We propose an alternative decoding\ntechnique based on the Maximum Mutual Information objective function, which\nleads to more diverse and detailed responses. We evaluate our model with common\nlanguage metrics, and also show human evaluation results. This technology is\napplied within the ``Alexa, how do I look?'' feature, publicly available in\nEcho Look devices.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 21:39:34 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sadeh", "Gil", ""], ["Fritz", "Lior", ""], ["Shalev", "Gabi", ""], ["Oks", "Eduard", ""]]}, {"id": "1906.06620", "submitter": "Gil Sadeh", "authors": "Gil Sadeh, Lior Fritz, Gabi Shalev and Eduard Oks", "title": "Joint Visual-Textual Embedding for Multimodal Style Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a multimodal visual-textual search refinement method for fashion\ngarments. Existing search engines do not enable intuitive, interactive,\nrefinement of retrieved results based on the properties of a particular\nproduct. We propose a method to retrieve similar items, based on a query item\nimage and textual refinement properties. We believe this method can be\nleveraged to solve many real-life customer scenarios, in which a similar item\nin a different color, pattern, length or style is desired. We employ a joint\nembedding training scheme in which product images and their catalog textual\nmetadata are mapped closely in a shared space. This joint visual-textual\nembedding space enables manipulating catalog images semantically, based on\ntextual refinement requirements. We propose a new training objective function,\nMini-Batch Match Retrieval, and demonstrate its superiority over the commonly\nused triplet loss. Additionally, we demonstrate the feasibility of adding an\nattribute extraction module, trained on the same catalog data, and demonstrate\nhow to integrate it within the multimodal search to boost its performance. We\nintroduce an evaluation protocol with an associated benchmark, and compare\nseveral approaches.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 21:50:31 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sadeh", "Gil", ""], ["Fritz", "Lior", ""], ["Shalev", "Gabi", ""], ["Oks", "Eduard", ""]]}, {"id": "1906.06624", "submitter": "Deniz Oktay", "authors": "Deniz Oktay, Johannes Ball\\'e, Saurabh Singh, Abhinav Shrivastava", "title": "Scalable Model Compression by Entropy Penalized Reparameterization", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple and general neural network weight compression approach,\nin which the network parameters (weights and biases) are represented in a\n\"latent\" space, amounting to a reparameterization. This space is equipped with\na learned probability model, which is used to impose an entropy penalty on the\nparameter representation during training, and to compress the representation\nusing a simple arithmetic coder after training. Classification accuracy and\nmodel compressibility is maximized jointly, with the bitrate--accuracy\ntrade-off specified by a hyperparameter. We evaluate the method on the MNIST,\nCIFAR-10 and ImageNet classification benchmarks using six distinct model\narchitectures. Our results show that state-of-the-art model compression can be\nachieved in a scalable and general way without requiring complex procedures\nsuch as multi-stage training.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 22:46:33 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 19:52:15 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 17:51:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Oktay", "Deniz", ""], ["Ball\u00e9", "Johannes", ""], ["Singh", "Saurabh", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "1906.06629", "submitter": "Dong Yin", "authors": "Avishek Ghosh, Justin Hong, Dong Yin and Kannan Ramchandran", "title": "Robust Federated Learning in a Heterogeneous Environment", "comments": "Fixing technical issues. Please discard any previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a recently proposed large-scale distributed learning paradigm,\nnamely Federated Learning, where the worker machines are end users' own\ndevices. Statistical and computational challenges arise in Federated Learning\nparticularly in the presence of heterogeneous data distribution (i.e., data\npoints on different devices belong to different distributions signifying\ndifferent clusters) and Byzantine machines (i.e., machines that may behave\nabnormally, or even exhibit arbitrary and potentially adversarial behavior). To\naddress the aforementioned challenges, first we propose a general statistical\nmodel for this problem which takes both the cluster structure of the users and\nthe Byzantine machines into account. Then, leveraging the statistical model, we\nsolve the robust heterogeneous Federated Learning problem \\emph{optimally}; in\nparticular our algorithm matches the lower bound on the estimation error in\ndimension and the number of data points. Furthermore, as a by-product, we prove\nstatistical guarantees for an outlier-robust clustering algorithm, which can be\nconsidered as the Lloyd algorithm with robust estimation. Finally, we show via\nsynthetic as well as real data experiments that the estimation error obtained\nby our proposed algorithm is significantly better than the non-Byzantine-robust\nalgorithms; in particular, we gain at least by 53\\% and 33\\% for synthetic and\nreal data experiments, respectively, in typical settings.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 00:14:53 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 22:53:13 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Ghosh", "Avishek", ""], ["Hong", "Justin", ""], ["Yin", "Dong", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1906.06635", "submitter": "Min Lin", "authors": "Min Lin, Jie Fu, Yoshua Bengio", "title": "Conditional Computation for Continual Learning", "comments": "NeurIPS 2018 Continual Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting of connectionist neural networks is caused by the\nglobal sharing of parameters among all training examples. In this study, we\nanalyze parameter sharing under the conditional computation framework where the\nparameters of a neural network are conditioned on each input example. At one\nextreme, if each input example uses a disjoint set of parameters, there is no\nsharing of parameters thus no catastrophic forgetting. At the other extreme, if\nthe parameters are the same for every example, it reduces to the conventional\nneural network. We then introduce a clipped version of maxout networks which\nlies in the middle, i.e. parameters are shared partially among examples. Based\non the parameter sharing analysis, we can locate a limited set of examples that\nare interfered when learning a new example. We propose to perform rehearsal on\nthis set to prevent forgetting, which is termed as conditional rehearsal.\nFinally, we demonstrate the effectiveness of the proposed method in an online\nnon-stationary setup, where updates are made after each new example and the\ndistribution of the received example shifts over time.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 02:11:39 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lin", "Min", ""], ["Fu", "Jie", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.06637", "submitter": "Christian Etmann", "authors": "Christian Etmann", "title": "A Closer Look at Double Backpropagation", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, an increasing number of neural network models have included\nderivatives with respect to inputs in their loss functions, resulting in\nso-called double backpropagation for first-order optimization. However, so far\nno general description of the involved derivatives exists. Here, we cover a\nwide array of special cases in a very general Hilbert space framework, which\nallows us to provide optimized backpropagation rules for many real-world\nscenarios. This includes the reduction of calculations for\nFrobenius-norm-penalties on Jacobians by roughly a third for locally linear\nactivation functions. Furthermore, we provide a description of the\ndiscontinuous loss surface of ReLU networks both in the inputs and the\nparameters and demonstrate why the discontinuities do not pose a big problem in\nreality.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 03:11:08 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Etmann", "Christian", ""]]}, {"id": "1906.06639", "submitter": "Qingpeng Cai", "authors": "Qingpeng Cai, Will Hang, Azalia Mirhoseini, George Tucker, Jingtao\n  Wang, Wei Wei", "title": "Reinforcement Learning Driven Heuristic Optimization", "comments": "DRL4KDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristic algorithms such as simulated annealing, Concorde, and METIS are\neffective and widely used approaches to find solutions to combinatorial\noptimization problems. However, they are limited by the high sample complexity\nrequired to reach a reasonable solution from a cold-start. In this paper, we\nintroduce a novel framework to generate better initial solutions for heuristic\nalgorithms using reinforcement learning (RL), named RLHO. We augment the\nability of heuristic algorithms to greedily improve upon an existing initial\nsolution generated by RL, and demonstrate novel results where RL is able to\nleverage the performance of heuristics as a learning signal to generate better\ninitialization.\n  We apply this framework to Proximal Policy Optimization (PPO) and Simulated\nAnnealing (SA). We conduct a series of experiments on the well-known\nNP-complete bin packing problem, and show that the RLHO method outperforms our\nbaselines. We show that on the bin packing problem, RL can learn to help\nheuristics perform even better, allowing us to combine the best parts of both\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 03:28:24 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Cai", "Qingpeng", ""], ["Hang", "Will", ""], ["Mirhoseini", "Azalia", ""], ["Tucker", "George", ""], ["Wang", "Jingtao", ""], ["Wei", "Wei", ""]]}, {"id": "1906.06659", "submitter": "Kamanchi Chandramouli", "authors": "Raghuram Bharadwaj Diddigi, Chandramouli Kamanchi, Shalabh Bhatnagar", "title": "A Generalized Minimax Q-learning Algorithm for Two-Player Zero-Sum\n  Stochastic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of two-player zero-sum games. This problem is\nformulated as a min-max Markov game in the literature. The solution of this\ngame, which is the min-max payoff, starting from a given state is called the\nmin-max value of the state. In this work, we compute the solution of the\ntwo-player zero-sum game utilizing the technique of successive relaxation.\nSuccessive relaxation has been successfully applied in the literature to\ncompute a faster value iteration algorithm in the context of Markov Decision\nProcesses. We extend the concept of successive relaxation to the two-player\nzero-sum games. We show that, under a special structure on the game, this\ntechnique facilitates faster computation of the min-max value of the states. We\nthen derive a generalized minimax Q-learning algorithm that computes the\noptimal policy when the model information is not known. Finally, we prove the\nconvergence of the proposed generalized minimax Q-learning algorithm utilizing\nstochastic approximation techniques. Through experiments, we demonstrate the\neffectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 07:26:21 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 17:09:14 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 18:09:26 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 06:21:20 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Diddigi", "Raghuram Bharadwaj", ""], ["Kamanchi", "Chandramouli", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1906.06663", "submitter": "Yachiko Obara", "authors": "Yachiko Obara, Tetsuro Morimura, Hiroki Yanagisawa", "title": "Sampler for Composition Ratio by Markov Chain Monte Carlo", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invention involves combination, or more precisely, ratios of composition.\nAccording to Thomas Edison, \"Genius is one percent inspiration and 99 percent\nperspiration\" is an example. In many situations, researchers and inventors\nalready have a variety of data and manage to create something new by using it,\nbut the key problem is how to select and combine knowledge. In this paper, we\npropose a new Markov chain Monte Carlo (MCMC) algorithm to generate composition\nratios, nonnegative-integer-valued vectors with two properties: (i) the sum of\nthe elements of each vector is constant, and (ii) only a small number of\nelements is nonzero. These constraints make it difficult for existing MCMC\nalgorithms to sample composition ratios. The key points of our approach are (1)\ndesigning an appropriate target distribution by using a condition on the number\nof nonzero elements, and (2) changing values only between a certain pair of\nelements in each iteration. Through an experiment on creating a new cocktail,\nwe show that the combination of the proposed method with supervised learning\ncan solve a creative problem.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 07:52:38 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 06:33:02 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Obara", "Yachiko", ""], ["Morimura", "Tetsuro", ""], ["Yanagisawa", "Hiroki", ""]]}, {"id": "1906.06666", "submitter": "Diego Alvarez-Estevez", "authors": "Diego Alvarez-Estevez, Isaac Fern\\'andez-Varela", "title": "Addressing database variability in learning from medical data: an\n  ensemble-based approach using convolutional neural networks and a case of\n  study applied to automatic sleep scoring", "comments": "Pre-print version accepted for publication; 26 pages, 1 figure, 6\n  tables, 4 supplementary tables", "journal-ref": "Computers in Biology and Medicine 119 (2020) 103697", "doi": "10.1016/j.compbiomed.2020.103697", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we examine some of the problems associated with the development\nof machine learning models with the objective to achieve robust generalization\ncapabilities on common-task multiple-database scenarios. Referred to as the\n\"database variability problem\", we focus on a specific medical domain (sleep\nstaging in sleep medicine) to show the non-triviality of translating the\nestimated model's local generalization capabilities into independent external\ndatabases. We analyze some of the scalability problems when multiple-database\ndata are used as inputs to train a single learning model. Then, we introduce a\nnovel approach based on an ensemble of local models, and we show its advantages\nin terms of inter-database generalization performance and data scalability. In\naddition, we analyze different model configurations and data pre-processing\ntechniques to determine their effects on the overall generalization\nperformance. For this purpose, we carry out experimentation that involves\nseveral sleep databases and evaluates different machine learning models based\non convolutional neural networks\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 12:29:51 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 08:38:27 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 07:43:25 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Alvarez-Estevez", "Diego", ""], ["Fern\u00e1ndez-Varela", "Isaac", ""]]}, {"id": "1906.06669", "submitter": "Aran Komatsuzaki", "authors": "Aran Komatsuzaki", "title": "One Epoch Is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised learning, collecting more data is not always a costly process\nunlike the training. For example, it is not hard to enlarge the 40GB WebText\nused for training GPT-2 by modifying its sampling methodology considering how\nmany webpages there are in the Internet. On the other hand, given that training\non this dataset already costs tens of thousands of dollars, training on a\nlarger dataset naively is not cost-wise feasible. In this paper, we suggest to\ntrain on a larger dataset for only one epoch unlike the current practice, in\nwhich the unsupervised models are trained for from tens to hundreds of epochs.\nFurthermore, we suggest to adjust the model size and the number of iterations\nto be performed appropriately. We show that the performance of Transformer\nlanguage model becomes dramatically improved in this way, especially if the\noriginal number of epochs is greater. For example, by replacing the training\nfor 10 epochs with the one epoch training, this translates to 1.9-3.3x speedup\nin wall-clock time in our settings and more if the original number of epochs is\ngreater. Under one epoch training, no overfitting occurs, and regularization\nmethod does nothing but slows down the training. Also, the curve of test loss\nover iterations follows power-law extensively. We compare the wall-clock time\nof the training of models with different parameter budget under one epoch\ntraining, and we show that size/iteration adjustment based on our proposed\nheuristics leads to 1-2.7x speedup in our cases. With the two methods combined,\nwe achieve 3.3-5.1x speedup. Finally, we speculate various implications of one\nepoch training and size/iteration adjustment. In particular, based on our\nanalysis we believe that we can reduce the cost to train the state-of-the-art\nmodels as BERT and GPT-2 dramatically, maybe even by the factor of 10.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 12:42:04 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Komatsuzaki", "Aran", ""]]}, {"id": "1906.06706", "submitter": "Changcun Huang", "authors": "Changcun Huang", "title": "Interpretations of Deep Learning by Forests and Haar Wavelets", "comments": "v2:Lemma 4 rectified; v3-v6:details refined and typos corrected;\n  v7:descriptions revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a basic property of region dividing of ReLU (rectified\nlinear unit) deep learning when new layers are successively added, by which two\nnew perspectives of interpreting deep learning are given. The first is related\nto decision trees and forests; we construct a deep learning structure\nequivalent to a forest in classification abilities, which means that certain\nkinds of ReLU deep learning can be considered as forests. The second\nperspective is that Haar wavelet represented functions can be approximated by\nReLU deep learning with arbitrary precision; and then a general conclusion of\nfunction approximation abilities of ReLU deep learning is given. Finally,\ngeneralize some of the conclusions of ReLU deep learning to the case of\nsigmoid-unit deep learning.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 14:38:41 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 13:33:10 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 12:54:43 GMT"}, {"version": "v4", "created": "Thu, 4 Jul 2019 01:12:17 GMT"}, {"version": "v5", "created": "Fri, 20 Sep 2019 08:12:38 GMT"}, {"version": "v6", "created": "Tue, 24 Sep 2019 14:43:03 GMT"}, {"version": "v7", "created": "Fri, 6 Dec 2019 15:03:06 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Huang", "Changcun", ""]]}, {"id": "1906.06717", "submitter": "Marko Vasic", "authors": "Marko Vasic, Andrija Petrovic, Kaiyuan Wang, Mladen Nikolic, Rishabh\n  Singh, Sarfraz Khurshid", "title": "MoET: Mixture of Expert Trees and its Application to Verifiable\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adaption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to analyze the inner workings of the model. We present\nMoET, a novel model based on Mixture of Experts, consisting of decision tree\nexperts and a generalized linear model gating function. While decision\nboundaries of decision trees (used in an existing verifiable approach), are\naxis-perpendicular hyperplanes, MoET supports hyperplanes of arbitrary\norientation as the boundaries. To support non-differentiable decision trees as\nexperts we formulate a novel training procedure. In addition, we introduce a\nhard thresholding version, MoET_h, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, MoET_h\nallows each prediction to be easily decomposed into a set of logical rules.\nSuch rules can be translated into a manageable SMT formula providing rich means\nfor verification. While MoET is a general use model, we illustrate its power in\nthe reinforcement learning setting. By training MoET models using an imitation\nlearning procedure on deep RL agents we outperform the previous\nstate-of-the-art technique based on decision trees while preserving the\nverifiability of the models.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 15:28:35 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 02:51:48 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 09:24:03 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Vasic", "Marko", ""], ["Petrovic", "Andrija", ""], ["Wang", "Kaiyuan", ""], ["Nikolic", "Mladen", ""], ["Singh", "Rishabh", ""], ["Khurshid", "Sarfraz", ""]]}, {"id": "1906.06719", "submitter": "Wenxian Shi", "authors": "Wenxian Shi, Hao Zhou, Ning Miao, Lei Li", "title": "Dispersed Exponential Family Mixture VAEs for Interpretable Text\n  Generation", "comments": "Camera ready version for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are commonly used for generating images and text.\nInterpretability of these models is one important pursuit, other than the\ngeneration quality. Variational auto-encoder (VAE) with Gaussian distribution\nas prior has been successfully applied in text generation, but it is hard to\ninterpret the meaning of the latent variable. To enhance the controllability\nand interpretability, one can replace the Gaussian prior with a mixture of\nGaussian distributions (GM-VAE), whose mixture components could be related to\nhidden semantic aspects of data. In this paper, we generalize the practice and\nintroduce DEM-VAE, a class of models for text generation using VAEs with a\nmixture distribution of exponential family. Unfortunately, a standard\nvariational training algorithm fails due to the mode-collapse problem. We\ntheoretically identify the root cause of the problem and propose an effective\nalgorithm to train DEM-VAE. Our method penalizes the training with an extra\ndispersion term to induce a well-structured latent space. Experimental results\nshow that our approach does obtain a meaningful space, and it outperforms\nstrong baselines in text generation benchmarks. The code is available at\nhttps://github.com/wenxianxian/demvae.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 15:41:07 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 09:50:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 09:53:34 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 09:52:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shi", "Wenxian", ""], ["Zhou", "Hao", ""], ["Miao", "Ning", ""], ["Li", "Lei", ""]]}, {"id": "1906.06766", "submitter": "Levent Sagun", "authors": "St\\'ephane d'Ascoli, Levent Sagun, Joan Bruna, Giulio Biroli", "title": "Finding the Needle in the Haystack with Convolutions: on the benefits of\n  architectural bias", "comments": "Update for the camera ready version - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the phenomenal success of deep neural networks in a broad range of\nlearning tasks, there is a lack of theory to understand the way they work. In\nparticular, Convolutional Neural Networks (CNNs) are known to perform much\nbetter than Fully-Connected Networks (FCNs) on spatially structured data: the\narchitectural structure of CNNs benefits from prior knowledge on the features\nof the data, for instance their translation invariance. The aim of this work is\nto understand this fact through the lens of dynamics in the loss landscape.\n  We introduce a method that maps a CNN to its equivalent FCN (denoted as\neFCN). Such an embedding enables the comparison of CNN and FCN training\ndynamics directly in the FCN space. We use this method to test a new training\nprotocol, which consists in training a CNN, embedding it to FCN space at a\ncertain ``relax time'', then resuming the training in FCN space. We observe\nthat for all relax times, the deviation from the CNN subspace is small, and the\nfinal performance reached by the eFCN is higher than that reachable by a\nstandard FCN of same architecture. More surprisingly, for some intermediate\nrelax times, the eFCN outperforms the CNN it stemmed, by combining the prior\ninformation of the CNN and the expressivity of the FCN in a complementary way.\nThe practical interest of our protocol is limited by the very large size of the\nhighly sparse eFCN. However, it offers interesting insights into the\npersistence of architectural bias under stochastic gradient dynamics. It shows\nthe existence of some rare basins in the FCN loss landscape associated with\nvery good generalization. These can only be accessed thanks to the CNN prior,\nwhich helps navigate the landscape during the early stages of optimization.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 20:53:21 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 18:55:07 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Sagun", "Levent", ""], ["Bruna", "Joan", ""], ["Biroli", "Giulio", ""]]}, {"id": "1906.06776", "submitter": "Yudong Chen", "authors": "Wei Qian, Yuqian Zhang, Yudong Chen", "title": "Global Convergence of Least Squares EM for Demixing Two Log-Concave\n  Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the location estimation problem for a mixture of two\nrotation invariant log-concave densities. We demonstrate that Least Squares EM,\na variant of the EM algorithm, converges to the true location parameter from a\nrandomly initialized point. We establish the explicit convergence rates and\nsample complexity bounds, revealing their dependence on the signal-to-noise\nratio and the tail property of the log-concave distribution. Moreover, we show\nthat this global convergence property is robust under model mis-specification.\n  Our analysis generalizes previous techniques for proving the convergence\nresults for Gaussian mixtures. In particular, we make use of an\nangle-decreasing property for establishing global convergence of Least Squares\nEM beyond Gaussian settings, as $\\ell_2$ distance contraction no longer holds\nglobally for general log-concave mixtures.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 21:26:17 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 21:43:46 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Qian", "Wei", ""], ["Zhang", "Yuqian", ""], ["Chen", "Yudong", ""]]}, {"id": "1906.06781", "submitter": "Bin Hu", "authors": "Bin Hu, Usman Ahmed Syed", "title": "Characterizing the Exact Behaviors of Temporal Difference Learning\n  Algorithms Using Markov Jump Linear System Theory", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a unified analysis of temporal difference learning\nalgorithms with linear function approximators by exploiting their connections\nto Markov jump linear systems (MJLS). We tailor the MJLS theory developed in\nthe control community to characterize the exact behaviors of the first and\nsecond order moments of a large family of temporal difference learning\nalgorithms. For both the IID and Markov noise cases, we show that the evolution\nof some augmented versions of the mean and covariance matrix of the TD\nestimation error exactly follows the trajectory of a deterministic linear\ntime-invariant (LTI) dynamical system. Applying the well-known LTI system\ntheory, we obtain closed-form expressions for the mean and covariance matrix of\nthe TD estimation error at any time step. We provide a tight matrix spectral\nradius condition to guarantee the convergence of the covariance matrix of the\nTD estimation error, and perform a perturbation analysis to characterize the\ndependence of the TD behaviors on learning rate. For the IID case, we provide\nan exact formula characterizing how the mean and covariance matrix of the TD\nestimation error converge to the steady state values. For the Markov case, we\nuse our formulas to explain how the behaviors of TD learning algorithms are\naffected by learning rate and the underlying Markov chain. For both cases,\nupper and lower bounds for the mean square TD error are provided. The mean\nsquare TD error is shown to converge linearly to an exact limit.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 21:56:10 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 21:07:25 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 22:48:48 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Hu", "Bin", ""], ["Syed", "Usman Ahmed", ""]]}, {"id": "1906.06784", "submitter": "Vikas Verma", "authors": "Alex Lamb, Vikas Verma, Kenji Kawaguchi, Juho Kannala, Yoshua Bengio", "title": "Interpolated Adversarial Training: Achieving Robust Neural Networks\n  without Sacrificing Too Much Accuracy", "comments": "Extended version of paper published in ACM AISec 2019; first two\n  authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has become a central goal in deep learning, both in\nthe theory and the practice. However, successful methods to improve the\nadversarial robustness (such as adversarial training) greatly hurt\ngeneralization performance on the unperturbed data. This could have a major\nimpact on how the adversarial robustness affects real world systems (i.e. many\nmay opt to forego robustness if it can improve accuracy on the unperturbed\ndata). We propose Interpolated Adversarial Training, which employs recently\nproposed interpolation based training methods in the framework of adversarial\ntraining. On CIFAR-10,adversarial training increases the standard test error\n(when there is no adversary) from 4.43% to 12.32%, whereas with our\nInterpolated adversarial training we retain the adversarial robustness while\nachieving a standard test error of only 6.45%. With our technique, the relative\nincrease in the standard error for the robust model is reduced from 178.1% to\njust 45.5%. Moreover, we provide mathematical analysis of Interpolated\nAdversarial Training to confirm its efficiencies and demonstrate its advantages\nin terms of robustness and generalization.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 22:01:51 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 15:00:24 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 20:06:18 GMT"}, {"version": "v4", "created": "Fri, 27 Sep 2019 00:34:50 GMT"}, {"version": "v5", "created": "Sat, 24 Apr 2021 12:35:43 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Lamb", "Alex", ""], ["Verma", "Vikas", ""], ["Kawaguchi", "Kenji", ""], ["Kannala", "Juho", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.06786", "submitter": "Soukayna Mouatadid", "authors": "Soukayna Mouatadid, Pierre Gentine, Wei Yu, Steve Easterbrook", "title": "Recovering the parameters underlying the Lorenz-96 chaotic dynamics", "comments": "ICML 2019 workshop on climate change", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate projections suffer from uncertain equilibrium climate sensitivity.\nThe reason behind this uncertainty is the resolution of global climate models,\nwhich is too coarse to resolve key processes such as clouds and convection.\nThese processes are approximated using heuristics in a process called\nparameterization. The selection of these parameters can be subjective, leading\nto significant uncertainties in the way clouds are represented in global\nclimate models. Here, we explore three deep network algorithms to infer these\nparameters in an objective and data-driven way. We compare the performance of a\nfully-connected network, a one-dimensional and, a two-dimensional convolutional\nnetworks to recover the underlying parameters of the Lorenz-96 model, a\nnon-linear dynamical system that has similar behavior to the climate system.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 22:20:05 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mouatadid", "Soukayna", ""], ["Gentine", "Pierre", ""], ["Yu", "Wei", ""], ["Easterbrook", "Steve", ""]]}, {"id": "1906.06796", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, James Jordon, Mihaela van der Schaar", "title": "ASAC: Active Sensing using Actor-Critic models", "comments": "Accepted in 2019 Machine Learning for Healthcare Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding what and when to observe is critical when making observations is\ncostly. In a medical setting where observations can be made sequentially,\nmaking these observations (or not) should be an active choice. We refer to this\nas the active sensing problem. In this paper, we propose a novel deep learning\nframework, which we call ASAC (Active Sensing using Actor-Critic models) to\naddress this problem. ASAC consists of two networks: a selector network and a\npredictor network. The selector network uses previously selected observations\nto determine what should be observed in the future. The predictor network uses\nthe observations selected by the selector network to predict a label, providing\nfeedback to the selector network (well-selected variables should be predictive\nof the label). The goal of the selector network is then to select variables\nthat balance the cost of observing the selected variables with their predictive\npower; we wish to preserve the conditional label distribution. During training,\nwe use the actor-critic models to allow the loss of the selector to be\n\"back-propagated\" through the sampling process. The selector network \"acts\" by\nselecting future observations to make. The predictor network acts as a \"critic\"\nby feeding predictive errors for the selected variables back to the selector\nnetwork. In our experiments, we show that ASAC significantly outperforms\nstate-of-the-arts in two real-world medical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 23:38:30 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Yoon", "Jinsung", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1906.06805", "submitter": "Michiel De Jong", "authors": "Michiel de Jong and Fei Sha", "title": "Neural Theorem Provers Do Not Learn Rules Without Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural symbolic processing aims to combine the generalization of logical\nlearning approaches and the performance of neural networks. The Neural Theorem\nProving (NTP) model by Rocktaschel et al (2017) learns embeddings for concepts\nand performs logical unification. While NTP is promising and effective in\npredicting facts accurately, we have little knowledge how well it can extract\ntrue relationship among data. To this end, we create synthetic logical datasets\nwith injected relationships, which can be generated on-the-fly, to test\nneural-based relation learning algorithms including NTP. We show that it has\ndifficulty recovering relationships in all but the simplest settings. Critical\nanalysis and diagnostic experiments suggest that the optimization algorithm\nsuffers from poor local minima due to its greedy winner-takes-all strategy in\nidentifying the most informative structure (proof path) to pursue. We alter the\nNTP algorithm to increase exploration, which sharply improves performance. We\nargue and demonstate that it is insightful to benchmark with synthetic data\nwith ground-truth relationships, for both evaluating models and revealing\nalgorithmic issues.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 00:58:29 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["de Jong", "Michiel", ""], ["Sha", "Fei", ""]]}, {"id": "1906.06818", "submitter": "Adam Kosiorek", "authors": "Adam R. Kosiorek, Sara Sabour, Yee Whye Teh, Geoffrey E. Hinton", "title": "Stacked Capsule Autoencoders", "comments": "NeurIPS 2019; 14 pages, 7 figures, 4 tables, code is available at\n  https://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objects are composed of a set of geometrically organized parts. We introduce\nan unsupervised capsule autoencoder (SCAE), which explicitly uses geometric\nrelationships between parts to reason about objects. Since these relationships\ndo not depend on the viewpoint, our model is robust to viewpoint changes. SCAE\nconsists of two stages. In the first stage, the model predicts presences and\nposes of part templates directly from the image and tries to reconstruct the\nimage by appropriately arranging the templates. In the second stage, SCAE\npredicts parameters of a few object capsules, which are then used to\nreconstruct part poses. Inference in this model is amortized and performed by\noff-the-shelf neural encoders, unlike in previous capsule networks. We find\nthat object capsule presences are highly informative of the object class, which\nleads to state-of-the-art results for unsupervised classification on SVHN (55%)\nand MNIST (98.7%). The code is available at\nhttps://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 02:31:37 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:29:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kosiorek", "Adam R.", ""], ["Sabour", "Sara", ""], ["Teh", "Yee Whye", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1906.06821", "submitter": "Shiliang Sun", "authors": "Shiliang Sun, Zehui Cao, Han Zhu, and Jing Zhao", "title": "A Survey of Optimization Methods from a Machine Learning Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning develops rapidly, which has made many theoretical\nbreakthroughs and is widely applied in various fields. Optimization, as an\nimportant part of machine learning, has attracted much attention of\nresearchers. With the exponential growth of data amount and the increase of\nmodel complexity, optimization methods in machine learning face more and more\nchallenges. A lot of work on solving optimization problems or improving\noptimization methods in machine learning has been proposed successively. The\nsystematic retrospect and summary of the optimization methods from the\nperspective of machine learning are of great significance, which can offer\nguidance for both developments of optimization and machine learning research.\nIn this paper, we first describe the optimization problems in machine learning.\nThen, we introduce the principles and progresses of commonly used optimization\nmethods. Next, we summarize the applications and developments of optimization\nmethods in some popular machine learning fields. Finally, we explore and give\nsome challenges and open problems for the optimization in machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 02:54:51 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 08:26:31 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Sun", "Shiliang", ""], ["Cao", "Zehui", ""], ["Zhu", "Han", ""], ["Zhao", "Jing", ""]]}, {"id": "1906.06832", "submitter": "Linnan Wang", "authors": "Linnan Wang, Saining Xie, Teng Li, Rodrigo Fonseca, Yuandong Tian", "title": "Sample-Efficient Neural Architecture Search by Learning Action Space", "comments": "Accepted at TPAMI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has emerged as a promising technique for\nautomatic neural network design. However, existing MCTS based NAS approaches\noften utilize manually designed action space, which is not directly related to\nthe performance metric to be optimized (e.g., accuracy), leading to\nsample-inefficient explorations of architectures. To improve the sample\nefficiency, this paper proposes Latent Action Neural Architecture Search\n(LaNAS), which learns actions to recursively partition the search space into\ngood or bad regions that contain networks with similar performance metrics.\nDuring the search phase, as different action sequences lead to regions with\ndifferent performance, the search efficiency can be significantly improved by\nbiasing towards the good regions. On three NAS tasks, empirical results\ndemonstrate that LaNAS is at least an order more sample efficient than baseline\nmethods including evolutionary algorithms, Bayesian optimizations, and random\nsearch. When applied in practice, both one-shot and regular LaNAS consistently\noutperform existing results. Particularly, LaNAS achieves 99.0% accuracy on\nCIFAR-10 and 80.8% top1 accuracy at 600 MFLOPS on ImageNet in only 800 samples,\nsignificantly outperforming AmoebaNet with 33x fewer samples. Our code is\npublicly available at https://github.com/facebookresearch/LaMCTS.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 03:50:25 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 19:13:16 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Linnan", ""], ["Xie", "Saining", ""], ["Li", "Teng", ""], ["Fonseca", "Rodrigo", ""], ["Tian", "Yuandong", ""]]}, {"id": "1906.06847", "submitter": "Liangjian Wen PhD.", "authors": "Liangjian Wen, Xuanyang Zhang, Haoli Bai, Zenglin Xu", "title": "Structured Pruning of Recurrent Neural Networks through Neuron Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have recently achieved remarkable successes\nin a number of applications. However, the huge sizes and computational burden\nof these models make it difficult for their deployment on edge devices. A\npractically effective approach is to reduce the overall storage and computation\ncosts of RNNs by network pruning techniques. Despite their successful\napplications, those pruning methods based on Lasso either produce irregular\nsparse patterns in weight matrices, which is not helpful in practical speedup.\nTo address these issues, we propose structured pruning method through neuron\nselection which can reduce the sizes of basic structures of RNNs. More\nspecifically, we introduce two sets of binary random variables, which can be\ninterpreted as gates or switches to the input neurons and the hidden neurons,\nrespectively. We demonstrate that the corresponding optimization problem can be\naddressed by minimizing the L0 norm of the weight matrix. Finally, experimental\nresults on language modeling and machine reading comprehension tasks have\nindicated the advantages of the proposed method in comparison with\nstate-of-the-art pruning competitors. In particular, nearly 20 x practical\nspeedup during inference was achieved without losing performance for language\nmodel on the Penn TreeBank dataset, indicating the promising performance of the\nproposed method\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 05:23:36 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 04:37:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Wen", "Liangjian", ""], ["Zhang", "Xuanyang", ""], ["Bai", "Haoli", ""], ["Xu", "Zenglin", ""]]}, {"id": "1906.06852", "submitter": "Abhishek Ghose", "authors": "Abhishek Ghose, Balaraman Ravindran", "title": "Learning Interpretable Models Using an Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Machine Learning (ML) becomes pervasive in various real world systems, the\nneed for models to be understandable has increased. We focus on\ninterpretability, noting that models often need to be constrained in size for\nthem to be considered interpretable, e.g., a decision tree of depth 5 is easier\nto interpret than one of depth 50. But smaller models also tend to have high\nbias. This suggests a trade-off between interpretability and accuracy. We\npropose a model agnostic technique to minimize this trade-off. Our strategy is\nto first learn a powerful, possibly black-box, probabilistic model - referred\nto as the oracle - on the training data. Uncertainty in the oracle's\npredictions are used to learn a sampling distribution for the training data.\nThe interpretable model is trained on a sample obtained using this\ndistribution. We demonstrate that such a model often is significantly more\naccurate than one trained on the original data.\n  Determining the sampling strategy is formulated as an optimization problem.\nOur solution to this problem possesses the following key favorable properties:\n(1) the number of optimization variables is independent of the dimensionality\nof the data: a fixed number of seven variables are used (2) our technique is\nmodel agnostic - in that both the interpretable model and the oracle may belong\nto arbitrary model families.\n  Results using multiple real world datasets, using Linear Probability Models\nand Decision Trees as interpretable models, with Gradient Boosted Model and\nRandom Forest as oracles, are presented. We observe significant relative\nimprovements in the F1-score in most cases, occasionally seeing improvements\ngreater than 100%. Additionally, we discuss an interesting application of our\ntechnique where a Gated Recurrent Unit network is used to improve the sequence\nclassification accuracy of a Decision Tree that uses character n-grams as\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 05:53:52 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 20:25:55 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ghose", "Abhishek", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1906.06854", "submitter": "Jong Chul Ye", "authors": "Yoseob Han, Junyoung Kim, and Jong Chul Ye", "title": "Differentiated Backprojection Domain Deep Learning for Conebeam Artifact\n  Removal", "comments": "This paper is accepted for IEEE Trans. Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conebeam CT using a circular trajectory is quite often used for various\napplications due to its relative simple geometry. For conebeam geometry,\nFeldkamp, Davis and Kress algorithm is regarded as the standard reconstruction\nmethod, but this algorithm suffers from so-called conebeam artifacts as the\ncone angle increases. Various model-based iterative reconstruction methods have\nbeen developed to reduce the cone-beam artifacts, but these algorithms usually\nrequire multiple applications of computational expensive forward and\nbackprojections. In this paper, we develop a novel deep learning approach for\naccurate conebeam artifact removal. In particular, our deep network, designed\non the differentiated backprojection domain, performs a data-driven inversion\nof an ill-posed deconvolution problem associated with the Hilbert transform.\nThe reconstruction results along the coronal and sagittal directions are then\ncombined using a spectral blending technique to minimize the spectral leakage.\nExperimental results show that our method outperforms the existing iterative\nmethods despite significantly reduced runtime complexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 05:59:33 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:05:48 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Han", "Yoseob", ""], ["Kim", "Junyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1906.06857", "submitter": "Zicun Cong", "authors": "Zicun Cong, Lingyang Chu, Lanjun Wang, Xia Hu, Jian Pei", "title": "Exact and Consistent Interpretation of Piecewise Linear Models Hidden\n  behind APIs: A Closed Form Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more AI services are provided through APIs on cloud where predictive\nmodels are hidden behind APIs. To build trust with users and reduce potential\napplication risk, it is important to interpret how such predictive models\nhidden behind APIs make their decisions. The biggest challenge of interpreting\nsuch predictions is that no access to model parameters or training data is\navailable. Existing works interpret the predictions of a model hidden behind an\nAPI by heuristically probing the response of the API with perturbed input\ninstances. However, these methods do not provide any guarantee on the exactness\nand consistency of their interpretations. In this paper, we propose an elegant\nclosed form solution named OpenAPI to compute exact and consistent\ninterpretations for the family of Piecewise Linear Models (PLM), which includes\nmany popular classification models. The major idea is to first construct a set\nof overdetermined linear equation systems with a small set of perturbed\ninstances and the predictions made by the model on those instances. Then, we\nsolve the equation systems to identify the decision features that are\nresponsible for the prediction on an input instance. Our extensive experiments\nclearly demonstrate the exactness and consistency of our method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 06:24:20 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 20:18:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cong", "Zicun", ""], ["Chu", "Lingyang", ""], ["Wang", "Lanjun", ""], ["Hu", "Xia", ""], ["Pei", "Jian", ""]]}, {"id": "1906.06875", "submitter": "Yongyi Mao Dr", "authors": "Guillaume P. Archambault, Yongyi Mao, Hongyu Guo, Richong Zhang", "title": "MixUp as Directional Adversarial Training", "comments": "12 pages, 1 figure, submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explain the working mechanism of MixUp in terms of\nadversarial training. We introduce a new class of adversarial training schemes,\nwhich we refer to as directional adversarial training, or DAT. In a nutshell, a\nDAT scheme perturbs a training example in the direction of another example but\nkeeps its original label as the training target. We prove that MixUp is\nequivalent to a special subclass of DAT, in that it has the same expected loss\nfunction and corresponds to the same optimization problem asymptotically. This\nunderstanding not only serves to explain the effectiveness of MixUp, but also\nreveals a more general family of MixUp schemes, which we call Untied MixUp. We\nprove that the family of Untied MixUp schemes is equivalent to the entire class\nof DAT schemes. We establish empirically the existence of Untied Mixup schemes\nwhich improve upon MixUp.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 07:26:14 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Archambault", "Guillaume P.", ""], ["Mao", "Yongyi", ""], ["Guo", "Hongyu", ""], ["Zhang", "Richong", ""]]}, {"id": "1906.06890", "submitter": "Usama Muhammad Mr.", "authors": "Muhammad Usama and Dong Eui Chang", "title": "Learning-Driven Exploration for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective and intelligent exploration has been an unresolved problem for\nreinforcement learning. Most contemporary reinforcement learning relies on\nsimple heuristic strategies such as $\\epsilon$-greedy exploration or adding\nGaussian noise to actions. These heuristics, however, are unable to\nintelligently distinguish the well explored and the unexplored regions of state\nspace, which can lead to inefficient use of training time. We introduce\nentropy-based exploration (EBE) that enables an agent to explore efficiently\nthe unexplored regions of state space. EBE quantifies the agent's learning in a\nstate using merely state-dependent action values and adaptively explores the\nstate space, i.e. more exploration for the unexplored region of the state\nspace. We perform experiments on a diverse set of environments and demonstrate\nthat EBE enables efficient exploration that ultimately results in faster\nlearning without having to tune any hyperparameter.\n  The code to reproduce the experiments is given at\n\\url{https://github.com/Usama1002/EBE-Exploration} and the supplementary video\nis given at \\url{https://youtu.be/nJggIjjzKic}.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:22:19 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 06:32:42 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Usama", "Muhammad", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1906.06899", "submitter": "Anthony Degleris", "authors": "Anthony Degleris and Nicolas Gillis", "title": "A Provably Correct and Robust Algorithm for Convolutive Nonnegative\n  Matrix Factorization", "comments": "24 pages, 4 figures, references updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a provably correct algorithm for convolutive\nnonnegative matrix factorization (CNMF) under separability assumptions. CNMF is\na convolutive variant of nonnegative matrix factorization (NMF), which\nfunctions as an NMF with additional sequential structure. This model is useful\nin a number of applications, such as audio source separation and neural\nsequence identification. While a number of heuristic algorithms have been\nproposed to solve CNMF, to the best of our knowledge no provably correct\nalgorithms have been developed. We present an algorithm that takes advantage of\nthe NMF model underlying CNMF and exploits existing algorithms for separable\nNMF to provably find a solution under certain conditions. Our approach\nguarantees the solution in low noise settings, and runs in polynomial time. We\nillustrate its effectiveness on synthetic datasets, and on a singing bird audio\nsequence.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:40:23 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 05:41:44 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 14:11:28 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 21:33:45 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Degleris", "Anthony", ""], ["Gillis", "Nicolas", ""]]}, {"id": "1906.06903", "submitter": "Ilsang Ohn", "authors": "Ilsang Ohn and Yongdai Kim", "title": "Smooth function approximation by deep neural networks with general\n  activation functions", "comments": "24 pages", "journal-ref": "Entropy 2019, 21(7), 627", "doi": "10.3390/e21070627", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing interest in expressivity of deep neural networks.\nHowever, most of the existing work about this topic focuses only on the\nspecific activation function such as ReLU or sigmoid. In this paper, we\ninvestigate the approximation ability of deep neural networks with a broad\nclass of activation functions. This class of activation functions includes most\nof frequently used activation functions. We derive the required depth, width\nand sparsity of a deep neural network to approximate any H\\\"older smooth\nfunction upto a given approximation error for the large class of activation\nfunctions. Based on our approximation error analysis, we derive the minimax\noptimality of the deep neural network estimators with the general activation\nfunctions in both regression and classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:49:21 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 23:32:29 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ohn", "Ilsang", ""], ["Kim", "Yongdai", ""]]}, {"id": "1906.06904", "submitter": "Maximilian Schmidt", "authors": "Maximilian Schmidt, Marko Simic", "title": "Normalizing flows for novelty detection in industrial time series data", "comments": "Presented at \"First workshop on Invertible Neural Networks and\n  Normalizing Flows(ICML 2019), Long Beach, CA, USA\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based deep generative models learn data distributions by transforming a\nsimple base distribution into a complex distribution via a set of invertible\ntransformations. Due to the invertibility, such models can score unseen data\nsamples by computing their exact likelihood under the learned distribution.\nThis makes flow-based models a perfect tool for novelty detection, an anomaly\ndetection technique where unseen data samples are classified as normal or\nabnormal by scoring them against a learned model of normal data. We show that\nnormalizing flows can be used as novelty detectors in time series. Two\nflow-based models, Masked Autoregressive Flows and Free-form Jacobian of\nReversible Dynamics restricted by autoregressive MADE networks, are tested on\nsynthetic data and motor current data from an industrial machine and achieve\ngood results, outperforming a conventional novelty detection method, the Local\nOutlier Factor.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:52:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Schmidt", "Maximilian", ""], ["Simic", "Marko", ""]]}, {"id": "1906.06914", "submitter": "Guillaume Dehaene P.", "authors": "Alexander Immer and Guillaume P. Dehaene", "title": "Variational Inference with Numerical Derivatives: variance reduction\n  through coupling", "comments": "Under review (NEURIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Black Box Variational Inference (Ranganath et al. (2014)) algorithm\nprovides a universal method for Variational Inference, but taking advantage of\nspecial properties of the approximation family or of the target can improve the\nconvergence speed significantly. For example, if the approximation family is a\ntransformation family, such as a Gaussian, then switching to the\nreparameterization gradient (Kingma and Welling (2014)) often yields a major\nreduction in gradient variance. Ultimately, reducing the variance can reduce\nthe computational cost and yield better approximations.\n  We present a new method to extend the reparameterization trick to more\ngeneral exponential families including the Wishart, Gamma, and Student\ndistributions. Variational Inference with Numerical Derivatives (VIND)\napproximates the gradient with numerical derivatives and reduces its variance\nusing a tight coupling of the approximation family. The resulting algorithm is\nsimple to implement and can profit from widely known couplings. Our experiments\nconfirm that VIND effectively decreases the gradient variance and therefore\nimproves the posterior approximation in relevant cases. It thus provides an\nefficient yet simple Variational Inference method for computing non-Gaussian\napproximations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:30:29 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Immer", "Alexander", ""], ["Dehaene", "Guillaume P.", ""]]}, {"id": "1906.06919", "submitter": "Shuyu Cheng", "authors": "Shuyu Cheng, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu", "title": "Improving Black-box Adversarial Attacks with a Transfer-based Prior", "comments": "NeurIPS 2019; Code available at\n  https://github.com/thu-ml/Prior-Guided-RGF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the black-box adversarial setting, where the adversary has to\ngenerate adversarial perturbations without access to the target models to\ncompute gradients. Previous methods tried to approximate the gradient either by\nusing a transfer gradient of a surrogate white-box model, or based on the query\nfeedback. However, these methods often suffer from low attack success rates or\npoor query efficiency since it is non-trivial to estimate the gradient in a\nhigh-dimensional space with limited information. To address these problems, we\npropose a prior-guided random gradient-free (P-RGF) method to improve black-box\nadversarial attacks, which takes the advantage of a transfer-based prior and\nthe query information simultaneously. The transfer-based prior given by the\ngradient of a surrogate model is appropriately integrated into our algorithm by\nan optimal coefficient derived by a theoretical analysis. Extensive experiments\ndemonstrate that our method requires much fewer queries to attack black-box\nmodels with higher success rates compared with the alternative state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:40:32 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 07:56:53 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 14:00:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cheng", "Shuyu", ""], ["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1906.06924", "submitter": "Ken Kobayashi", "authors": "Akinori Tanaka, Akiyoshi Sannai, Ken Kobayashi, Naoki Hamada", "title": "Asymptotic Risk of Bezier Simplex Fitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bezier simplex fitting is a novel data modeling technique which exploits\ngeometric structures of data to approximate the Pareto front of multi-objective\noptimization problems. There are two fitting methods based on different\nsampling strategies. The inductive skeleton fitting employs a stratified\nsubsampling from each skeleton of a simplex, whereas the all-at-once fitting\nuses a non-stratified sampling which treats a simplex as a whole. In this\npaper, we analyze the asymptotic risks of those B\\'ezier simplex fitting\nmethods and derive the optimal subsample ratio for the inductive skeleton\nfitting. It is shown that the inductive skeleton fitting with the optimal ratio\nhas a smaller risk when the degree of a Bezier simplex is less than three.\nThose results are verified numerically under small to moderate sample sizes. In\naddition, we provide two complementary applications of our theory: a\ngeneralized location problem and a multi-objective hyper-parameter tuning of\nthe group lasso. The former can be represented by a Bezier simplex of degree\ntwo where the inductive skeleton fitting outperforms. The latter can be\nrepresented by a Bezier simplex of degree three where the all-at-once fitting\ngets an advantage.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:56:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Tanaka", "Akinori", ""], ["Sannai", "Akiyoshi", ""], ["Kobayashi", "Ken", ""], ["Hamada", "Naoki", ""]]}, {"id": "1906.06925", "submitter": "Johannes Sappl", "authors": "Johannes Sappl, Laurent Seiler, Matthias Harders, Wolfgang Rauch", "title": "Deep Learning of Preconditioners for Conjugate Gradient Solvers in Urban\n  Water Related Problems", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving systems of linear equations is a problem occuring frequently in water\nengineering applications. Usually the size of the problem is too large to be\nsolved via direct factorization. One can resort to iterative approaches, in\nparticular the conjugate gradients method if the matrix is symmetric positive\ndefinite. Preconditioners further enhance the rate of convergence but hitherto\nonly handcrafted ones requiring expert knowledge have been used. We propose an\ninnovative approach employing Machine Learning, in particular a Convolutional\nNeural Network, to unassistedly design preconditioning matrices specifically\nfor the problem at hand. Based on an in-depth case study in fluid simulation we\nare able to show that our learned preconditioner is able to improve the\nconvergence rate even beyond well established methods like incomplete Cholesky\nfactorization or Algebraic MultiGrid.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:57:06 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sappl", "Johannes", ""], ["Seiler", "Laurent", ""], ["Harders", "Matthias", ""], ["Rauch", "Wolfgang", ""]]}, {"id": "1906.06957", "submitter": "Isao Ishikawa", "authors": "Isao Ishikawa and Akinori Tanaka and Masahiro Ikeda and Yoshinobu\n  Kawahara", "title": "Metric on random dynamical systems with vector-valued reproducing kernel\n  Hilbert spaces", "comments": "We improved the readability, and added emperical experiments with\n  real data", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of metrics for structural data-generating mechanisms is\nfundamental in machine learning and the related fields. In this paper, we give\na general framework to construct metrics on random nonlinear dynamical systems,\ndefined with the Perron-Frobenius operators in vector-valued reproducing kernel\nHilbert spaces (vvRKHSs). We employ vvRKHSs to design mathematically manageable\nmetrics and also to introduce operator-valued kernels, which enables us to\nhandle randomness in systems. Our metric provides an extension of the existing\nmetrics for deterministic systems, and gives a specification of the kernel\nmaximal mean discrepancy of random processes. Moreover, by considering the\ntime-wise independence of random processes, we clarify a connection between our\nmetric and the independence criteria with kernels such as Hilbert-Schmidt\nindependence criteria. We empirically illustrate our metric with synthetic\ndata, and evaluate it in the context of the independence test for random\nprocesses. We also evaluate the performance with real time seris datas via\nclusering tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 11:17:22 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 02:54:30 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 05:34:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ishikawa", "Isao", ""], ["Tanaka", "Akinori", ""], ["Ikeda", "Masahiro", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1906.06968", "submitter": "Vijayalakshmi Janakiraman", "authors": "Rashmi Jain, Dinah Samuel Anand, Vijayalakshmi Janakiraman", "title": "Scrubbing Sensitive PHI Data from Medical Records made Easy by SpaCy --\n  A Scalable Model Implementation Comparisons", "comments": "9 Pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De-identification of clinical records is an extremely important process which\nenables the use of the wealth of information present in them. There are a lot\nof techniques available for this but none of the method implementation has\nevaluated the scalability, which is an important benchmark. We evaluated\nnumerous deep learning techniques such as BiLSTM-CNN, IDCNN, CRF, BiLSTM-CRF,\nSpaCy, etc. on both the performance and efficiency. We propose that the SpaCy\nmodel implementation for scrubbing sensitive PHI data from medical records is\nboth well performing and extremely efficient compared to other published\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 11:42:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jain", "Rashmi", ""], ["Anand", "Dinah Samuel", ""], ["Janakiraman", "Vijayalakshmi", ""]]}, {"id": "1906.06977", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Sylvie Calabretto,\n  Liyun He-Guelton, Frederic Obl\\'e, Michael Granitzer", "title": "Dataset shift quantification for credit card fraud detection", "comments": "Presented at IEEE Artificial Intelligence and Knowledge Engineering\n  (AIKE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However purchase behaviour and fraudster\nstrategies may change over time. This phenomenon is named dataset shift or\nconcept drift in the domain of fraud detection. In this paper, we present a\nmethod to quantify day-by-day the dataset shift in our face-to-face credit card\ntransactions dataset (card holder located in the shop) . In practice, we\nclassify the days against each other and measure the efficiency of the\nclassification. The more efficient the classification, the more different the\nbuying behaviour between two days, and vice versa. Therefore, we obtain a\ndistance matrix characterizing the dataset shift. After an agglomerative\nclustering of the distance matrix, we observe that the dataset shift pattern\nmatches the calendar events for this time period (holidays, week-ends, etc). We\nthen incorporate this dataset shift knowledge in the credit card fraud\ndetection task as a new feature. This leads to a small improvement of the\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 12:03:42 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["Calabretto", "Sylvie", ""], ["He-Guelton", "Liyun", ""], ["Obl\u00e9", "Frederic", ""], ["Granitzer", "Michael", ""]]}, {"id": "1906.06994", "submitter": "Verner Vla\\v{c}i\\'c", "authors": "Verner Vla\\v{c}i\\'c and Helmut B\\\"olcskei", "title": "Neural network identifiability for a family of sigmoidal nonlinearities", "comments": "43 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.AI cs.IT math.CV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the following question of neural network\nidentifiability: Does the input-output map realized by a feed-forward neural\nnetwork with respect to a given nonlinearity uniquely specify the network\narchitecture, weights, and biases? Existing literature on the subject Sussman\n1992, Albertini, Sontag et al. 1993, Fefferman 1994 suggests that the answer\nshould be yes, up to certain symmetries induced by the nonlinearity, and\nprovided the networks under consideration satisfy certain \"genericity\nconditions\". The results in Sussman 1992 and Albertini, Sontag et al. 1993\napply to networks with a single hidden layer and in Fefferman 1994 the networks\nneed to be fully connected. In an effort to answer the identifiability question\nin greater generality, we derive necessary genericity conditions for the\nidentifiability of neural networks of arbitrary depth and connectivity with an\narbitrary nonlinearity. Moreover, we construct a family of nonlinearities for\nwhich these genericity conditions are minimal, i.e., both necessary and\nsufficient. This family is large enough to approximate many commonly\nencountered nonlinearities to within arbitrary precision in the uniform norm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:48:11 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 13:13:26 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 08:15:05 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Vla\u010di\u0107", "Verner", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1906.07046", "submitter": "Bert Huang", "authors": "Alyssa Herbst and Bert Huang", "title": "Bounded Expectation of Label Assignment: Dataset Annotation by\n  Supervised Splitting with Bias-Reduction Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating large unlabeled datasets can be a major bottleneck for machine\nlearning applications. We introduce a scheme for inferring labels of unlabeled\ndata at a fraction of the cost of labeling the entire dataset. Our scheme,\nbounded expectation of label assignment (BELA), greedily queries an oracle (or\nhuman labeler) and partitions a dataset to find data subsets that have mostly\nthe same label. BELA can then infer labels by majority vote of the known labels\nin each subset. BELA determines whether to split or label from a subset by\nmaximizing a lower bound on the expected number of correctly labeled examples.\nOur approach differs from existing hierarchical labeling schemes by using\nsupervised models to partition the data, therefore avoiding reliance on\nunsupervised clustering methods that may not accurately group data by label. We\ndesign BELA with strategies to avoid bias that could be introduced through this\nadaptive partitioning. We evaluate BELA on three datasets and find that it\noutperforms existing strategies for adaptive labeling.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 14:13:42 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:45:54 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Herbst", "Alyssa", ""], ["Huang", "Bert", ""]]}, {"id": "1906.07073", "submitter": "Chris Nota", "authors": "Chris Nota and Philip S. Thomas", "title": "Is the Policy Gradient a Gradient?", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradient theorem describes the gradient of the expected discounted\nreturn with respect to an agent's policy parameters. However, most policy\ngradient methods drop the discount factor from the state distribution and\ntherefore do not optimize the discounted objective. What do they optimize\ninstead? This has been an open question for several years, and this lack of\ntheoretical clarity has lead to an abundance of misstatements in the\nliterature. We answer this question by proving that the update direction\napproximated by most methods is not the gradient of any function. Further, we\nargue that algorithms that follow this direction are not guaranteed to converge\nto a \"reasonable\" fixed point by constructing a counterexample wherein the\nfixed point is globally pessimal with respect to both the discounted and\nundiscounted objectives. We motivate this work by surveying the literature and\nshowing that there remains a widespread misunderstanding regarding discounted\npolicy gradient methods, with errors present even in highly-cited papers\npublished at top conferences.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:00:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 23:25:35 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Nota", "Chris", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1906.07077", "submitter": "Felix Assion", "authors": "Felix Assion, Peter Schlicht, Florens Gre{\\ss}ner, Wiebke G\\\"unther,\n  Fabian H\\\"uger, Nico Schmidt, Umair Rasheed", "title": "The Attack Generator: A Systematic Approach Towards Constructing\n  Adversarial Attacks", "comments": "CVPR SAIAD - Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art machine learning (ML) classification systems are\nvulnerable to adversarial perturbations. As a consequence, adversarial\nrobustness poses a significant challenge for the deployment of ML-based systems\nin safety- and security-critical environments like autonomous driving, disease\ndetection or unmanned aerial vehicles. In the past years we have seen an\nimpressive amount of publications presenting more and more new adversarial\nattacks. However, the attack research seems to be rather unstructured and new\nattacks often appear to be random selections from the unlimited set of possible\nadversarial attacks. With this publication, we present a structured analysis of\nthe adversarial attack creation process. By detecting different building blocks\nof adversarial attacks, we outline the road to new sets of adversarial attacks.\nWe call this the \"attack generator\". In the pursuit of this objective, we\nsummarize and extend existing adversarial perturbation taxonomies. The\nresulting taxonomy is then linked to the application context of computer vision\nsystems for autonomous vehicles, i.e. semantic segmentation and object\ndetection. Finally, in order to prove the usefulness of the attack generator,\nwe investigate existing semantic segmentation attacks with respect to the\ndetected defining components of adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:06:47 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Assion", "Felix", ""], ["Schlicht", "Peter", ""], ["Gre\u00dfner", "Florens", ""], ["G\u00fcnther", "Wiebke", ""], ["H\u00fcger", "Fabian", ""], ["Schmidt", "Nico", ""], ["Rasheed", "Umair", ""]]}, {"id": "1906.07079", "submitter": "Jong-Chyi Su", "authors": "Jong-Chyi Su, Subhransu Maji, Bharath Hariharan", "title": "Boosting Supervision with Self-Supervision for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique to improve the transferability of deep representations\nlearned on small labeled datasets by introducing self-supervised tasks as\nauxiliary loss functions. While recent approaches for self-supervised learning\nhave shown the benefits of training on large unlabeled datasets, we find\nimprovements in generalization even on small datasets and when combined with\nstrong supervision. Learning representations with self-supervised losses\nreduces the relative error rate of a state-of-the-art meta-learner by 5-25% on\nseveral few-shot learning benchmarks, as well as off-the-shelf deep networks on\nstandard classification tasks when training from scratch. We find the benefits\nof self-supervision increase with the difficulty of the task. Our approach\nutilizes the images within the dataset to construct self-supervised losses and\nhence is an effective way of learning transferable representations without\nrelying on any external training data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:17:40 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Su", "Jong-Chyi", ""], ["Maji", "Subhransu", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1906.07095", "submitter": "Sukhpreet Kaur Khangura", "authors": "Sukhpreet Kaur Khangura and Sami Ak{\\i}n", "title": "Measurement-based Online Available Bandwidth Estimation employing\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate and fast estimation of the available bandwidth in a network with\nvarying cross-traffic is a challenging task. The accepted probing tools, based\non the fluid-flow model of a bottleneck link with first-in, first-out\nmultiplexing, estimate the available bandwidth by measuring packet dispersions.\nThe estimation becomes more difficult if packet dispersions deviate from the\nassumptions of the fluid-flow model in the presence of non-fluid bursty\ncross-traffic, multiple bottleneck links, and inaccurate time-stamping. This\nmotivates us to explore the use of machine learning tools for available\nbandwidth estimation. Hence, we consider reinforcement learning and implement\nthe single-state multi-armed bandit technique, which follows the\n$\\epsilon$-greedy algorithm to find the available bandwidth. Our measurements\nand tests reveal that our proposed method identifies the available bandwidth\nwith high precision. Furthermore, our method converges to the available\nbandwidth under a variety of notoriously difficult conditions, such as heavy\ntraffic burstiness, different cross-traffic intensities, multiple bottleneck\nlinks, and in networks where the tight link and the bottleneck link are not\nsame. Compared to the piece-wise linear network a model-based direct probing\ntechnique that employs a Kalman filter, our method shows more accurate\nestimates and faster convergence in certain network scenarios and does not\nrequire measurement noise statistics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:02:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Khangura", "Sukhpreet Kaur", ""], ["Ak\u0131n", "Sami", ""]]}, {"id": "1906.07098", "submitter": "Gaetano Manzo", "authors": "Gaetano Manzo, Sebastian Otalora, Marco Ajmone Marsan, Torsten Braun,\n  Hung Nguyen, Gianluca Rizzo", "title": "DeepFloat: Resource-Efficient Dynamic Management of Vehicular Floating\n  Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opportunistic communications are expected to playa crucial role in enabling\ncontext-aware vehicular services. A widely investigated opportunistic\ncommunication paradigm for storing a piece of content probabilistically in a\ngeographica larea is Floating Content (FC). A key issue in the practical\ndeployment of FC is how to tune content replication and caching in a way which\nachieves a target performance (in terms of the mean fraction of users\npossessing the content in a given region of space) while minimizing the use of\nbandwidth and host memory. Fully distributed, distance-based approaches prove\nhighly inefficient, and may not meet the performance target,while centralized,\nmodel-based approaches do not perform well in realistic, inhomogeneous\nsettings. In this work, we present a data-driven centralized approach to\nresource-efficient, QoS-aware dynamic management of FC.We propose a Deep\nLearning strategy, which employs a Convolutional Neural Network (CNN) to\ncapture the relationships between patterns of users mobility, of content\ndiffusion and replication, and FC performance in terms of resource utilization\nand of content availability within a given area. Numerical evaluations show the\neffectiveness of our approach in deriving strategies which efficiently modulate\nthe FC operation in space and effectively adapt to mobility pattern changes\nover time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 07:49:55 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Manzo", "Gaetano", ""], ["Otalora", "Sebastian", ""], ["Marsan", "Marco Ajmone", ""], ["Braun", "Torsten", ""], ["Nguyen", "Hung", ""], ["Rizzo", "Gianluca", ""]]}, {"id": "1906.07122", "submitter": "Ari Azarafrooz", "authors": "Ari Azarafrooz and John Brock", "title": "Hierarchical Soft Actor-Critic: Adversarial Exploration via Mutual\n  Information Optimization", "comments": "Presented at the ICML 2019 workshop on Imitation, Intent, and\n  Interaction, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel extension of soft actor-critics for hierarchical Deep\nQ-Networks (HDQN) architectures using mutual information metric. The proposed\nextension provides a suitable framework for encouraging explorations in such\nhierarchical networks. A natural utilization of this framework is an\nadversarial setting, where meta-controller and controller play minimax over the\nmutual information objective but cooperate on maximizing expected rewards.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:43:09 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Azarafrooz", "Ari", ""], ["Brock", "John", ""]]}, {"id": "1906.07125", "submitter": "David Rohde", "authors": "Finnian Lattimore and David Rohde", "title": "Replacing the do-calculus with Bayes rule", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of causality has a controversial history. The question of whether\nit is possible to represent and address causal problems with probability\ntheory, or if fundamentally new mathematics such as the do calculus is required\nhas been hotly debated, e.g. Pearl (2001) states \"the building blocks of our\nscientific and everyday knowledge are elementary facts such as \"mud does not\ncause rain\" and \"symptoms do not cause disease\" and those facts, strangely\nenough, cannot be expressed in the vocabulary of probability calculus\". This\nhas lead to a dichotomy between advocates of causal graphical modeling and the\ndo calculus, and researchers applying Bayesian methods. In this paper we\ndemonstrate that, while it is critical to explicitly model our assumptions on\nthe impact of intervening in a system, provided we do so, estimating causal\neffects can be done entirely within the standard Bayesian paradigm. The\ninvariance assumptions underlying causal graphical models can be encoded in\nordinary Probabilistic graphical models, allowing causal estimation with\nBayesian statistics, equivalent to the do calculus. Elucidating the connections\nbetween these approaches is a key step toward enabling the insights provided by\neach to be combined to solve real problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:50:55 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 13:51:39 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lattimore", "Finnian", ""], ["Rohde", "David", ""]]}, {"id": "1906.07133", "submitter": "Quan Kong", "authors": "Quan Kong, Bin Tong, Martin Klinkigt, Yuki Watanabe, Naoto Akira,\n  Tomokazu Murakami", "title": "Active Generative Adversarial Network for Image Classification", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sufficient supervised information is crucial for any machine learning models\nto boost performance. However, labeling data is expensive and sometimes\ndifficult to obtain. Active learning is an approach to acquire annotations for\ndata from a human oracle by selecting informative samples with a high\nprobability to enhance performance. In recent emerging studies, a generative\nadversarial network (GAN) has been integrated with active learning to generate\ngood candidates to be presented to the oracle. In this paper, we propose a\nnovel model that is able to obtain labels for data in a cheaper manner without\nthe need to query an oracle. In the model, a novel reward for each sample is\ndevised to measure the degree of uncertainty, which is obtained from a\nclassifier trained with existing labeled data. This reward is used to guide a\nconditional GAN to generate informative samples with a higher probability for a\ncertain label. With extensive evaluations, we have confirmed the effectiveness\nof the model, showing that the generated samples are capable of improving the\nclassification performance in popular image classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:11:07 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kong", "Quan", ""], ["Tong", "Bin", ""], ["Klinkigt", "Martin", ""], ["Watanabe", "Yuki", ""], ["Akira", "Naoto", ""], ["Murakami", "Tomokazu", ""]]}, {"id": "1906.07136", "submitter": "David Rohde", "authors": "David Rohde", "title": "A Bayesian Solution to the M-Bias Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice in using regression type models for inferring causal\neffects, that inferring the correct causal relationship requires extra\ncovariates are included or ``adjusted for''. Without performing this adjustment\nerroneous causal effects can be inferred. Given this phenomenon it is common\npractice to include as many covariates as possible, however such advice comes\nunstuck in the presence of M-bias. M-Bias is a problem in causal inference\nwhere the correct estimation of treatment effects requires that certain\nvariables are not adjusted for i.e. are simply neglected from inclusion in the\nmodel. This issue caused a storm of controversy in 2009 when Rubin, Pearl and\nothers disagreed about if it could be problematic to include additional\nvariables in models when inferring causal effects. This paper makes two\ncontributions to this issue. Firstly we provide a Bayesian solution to the\nM-Bias problem. The solution replicates Pearl's solution, but consistent with\nRubin's advice we condition on all variables. Secondly the fact that we are\nable to offer a solution to this problem in Bayesian terms shows that it is\nindeed possible to represent causal relationships within the Bayesian paradigm,\nalbeit in an extended space. We make several remarks on the similarities and\ndifferences between causal graphical models which implement the do-calculus and\nprobabilistic graphical models which enable Bayesian statistics. We hope this\nwork will stimulate more research on unifying Pearl's causal calculus using\ncausal graphical models with traditional Bayesian statistics and probabilistic\ngraphical models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:18:17 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Rohde", "David", ""]]}, {"id": "1906.07148", "submitter": "Marcus Comiter", "authors": "Marcus Comiter, Surat Teerapittayanon, H.T. Kung", "title": "CheckNet: Secure Inference on Untrusted Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CheckNet, a method for secure inference with deep neural\nnetworks on untrusted devices. CheckNet is like a checksum for neural network\ninference: it verifies the integrity of the inference computation performed by\nuntrusted devices to 1) ensure the inference has actually been performed, and\n2) ensure the inference has not been manipulated by an attacker. CheckNet is\ncompletely transparent to the third party running the computation, applicable\nto all types of neural networks, does not require specialized hardware, adds\nlittle overhead, and has negligible impact on model performance. CheckNet can\nbe configured to provide different levels of security depending on application\nneeds and compute/communication budgets. We present both empirical and\ntheoretical validation of CheckNet on multiple popular deep neural network\nmodels, showing excellent attack detection (0.88-0.99 AUC) and attack success\nbounds.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:45:25 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Comiter", "Marcus", ""], ["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1906.07153", "submitter": "Tom Goldstein", "authors": "Parsa Saadatpanah, Ali Shafahi, Tom Goldstein", "title": "Adversarial attacks on Copyright Detection Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that many machine learning models are susceptible to\nadversarial attacks, in which an attacker evades a classifier by making small\nperturbations to inputs. This paper discusses how industrial copyright\ndetection tools, which serve a central role on the web, are susceptible to\nadversarial attacks. We discuss a range of copyright detection systems, and why\nthey are particularly vulnerable to attacks. These vulnerabilities are\nespecially apparent for neural network based systems. As a proof of concept, we\ndescribe a well-known music identification method, and implement this system in\nthe form of a neural net. We then attack this system using simple gradient\nmethods. Adversarial music created this way successfully fools industrial\nsystems, including the AudioTag copyright detector and YouTube's Content ID\nsystem. Our goal is to raise awareness of the threats posed by adversarial\nexamples in this space, and to highlight the importance of hardening copyright\ndetection systems to attacks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:57:04 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:44:20 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Saadatpanah", "Parsa", ""], ["Shafahi", "Ali", ""], ["Goldstein", "Tom", ""]]}, {"id": "1906.07159", "submitter": "Fan-Yun Sun", "authors": "Fan-Yun Sun, Meng Qu, Jordan Hoffmann, Chin-Wei Huang, Jian Tang", "title": "vGraph: A Generative Model for Joint Community Detection and Node\n  Representation Learning", "comments": "Accepted Paper at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on two fundamental tasks of graph analysis: community\ndetection and node representation learning, which capture the global and local\nstructures of graphs, respectively. In the current literature, these two tasks\nare usually independently studied while they are actually highly correlated. We\npropose a probabilistic generative model called vGraph to learn community\nmembership and node representation collaboratively. Specifically, we assume\nthat each node can be represented as a mixture of communities, and each\ncommunity is defined as a multinomial distribution over nodes. Both the mixing\ncoefficients and the community distribution are parameterized by the\nlow-dimensional representations of the nodes and communities. We designed an\neffective variational inference algorithm which regularizes the community\nmembership of neighboring nodes to be similar in the latent space. Experimental\nresults on multiple real-world graphs show that vGraph is very effective in\nboth community detection and node representation learning, outperforming many\ncompetitive baselines in both tasks. We show that the framework of vGraph is\nquite flexible and can be easily extended to detect hierarchical communities.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 05:19:04 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 05:09:09 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sun", "Fan-Yun", ""], ["Qu", "Meng", ""], ["Hoffmann", "Jordan", ""], ["Huang", "Chin-Wei", ""], ["Tang", "Jian", ""]]}, {"id": "1906.07172", "submitter": "Erkao Bao", "authors": "Erkao Bao and Linqi Song", "title": "Equivariant neural networks and equivarification", "comments": "More explanations added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a process to modify a neural network to an equivariant one, which\nwe call equivarification. As an illustration, we build an equivariant neural\nnetwork for image classification by equivarifying a convolutional neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 23:26:03 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 03:40:06 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 06:51:29 GMT"}, {"version": "v4", "created": "Sun, 22 Mar 2020 04:28:55 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Bao", "Erkao", ""], ["Song", "Linqi", ""]]}, {"id": "1906.07181", "submitter": "Zhan Shi", "authors": "Zhan Shi, Kevin Swersky, Daniel Tarlow, Parthasarathy Ranganathan,\n  Milad Hashemi", "title": "Learning Execution through Neural Code Fusion", "comments": "14 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the performance of computer systems stagnates due to the end of Moore's\nLaw, there is a need for new models that can understand and optimize the\nexecution of general purpose code. While there is a growing body of work on\nusing Graph Neural Networks (GNNs) to learn representations of source code,\nthese representations do not understand how code dynamically executes. In this\nwork, we propose a new approach to use GNNs to learn fused representations of\ngeneral source code and its execution. Our approach defines a multi-task GNN\nover low-level representations of source code and program state (i.e., assembly\ncode and dynamic memory states), converting complex source code constructs and\ncomplex data structures into a simpler, more uniform format. We show that this\nleads to improved performance over similar methods that do not use execution\nand it opens the door to applying GNN models to new tasks that would not be\nfeasible from static code alone. As an illustration of this, we apply the new\nmodel to challenging dynamic tasks (branch prediction and prefetching) from the\nSPEC CPU benchmark suite, outperforming the state-of-the-art by 26% and 45%\nrespectively. Moreover, we use the learned fused graph embeddings to\ndemonstrate transfer learning with high performance on an indirectly related\ntask (algorithm classification).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:05:48 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:11:50 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shi", "Zhan", ""], ["Swersky", "Kevin", ""], ["Tarlow", "Daniel", ""], ["Ranganathan", "Parthasarathy", ""], ["Hashemi", "Milad", ""]]}, {"id": "1906.07183", "submitter": "Gavindya Jayawardena", "authors": "Gavindya Jayawardena, Anne Michalek, Sampath Jayarathna", "title": "Eye Gaze Metrics and Analysis of AOI for Indexing Working Memory towards\n  Predicting ADHD", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ADHD is being recognized as a diagnosis which persists into adulthood\nimpacting economic, occupational, and educational outcomes. There is an\nincreased need to accurately diagnose and recommend interventions for this\npopulation. One consideration is the development and implementation of reliable\nand valid outcome measures which reflect core diagnostic criteria. For example,\nadults with ADHD have reduced working memory capacity when compared to their\npeers (Michalek et al., 2014). A reduction in working memory capacity indicates\nattentional control deficits which align with many symptoms outlined on\nbehavioral checklists used to diagnose ADHD. Using computational methods, such\nas eye tracking technology, to generate a relationship between ADHD and\nmeasures of working memory capacity would be useful to advancing our\nunderstanding and treatment of the diagnosis in adults. This chapter will\noutline a feasibility study in which eye tracking was used to measure eye gaze\nmetrics during a working memory capacity task for adults with and without ADHD\nand machine learning algorithms were applied to generate a feature set unique\nto the ADHD diagnosis. The chapter will summarize the purpose, methods,\nresults, and impact of this study.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:24:28 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Jayawardena", "Gavindya", ""], ["Michalek", "Anne", ""], ["Jayarathna", "Sampath", ""]]}, {"id": "1906.07214", "submitter": "Sai Vineeth Kalluru Srinivas", "authors": "Sai Vineeth Kalluru Srinivas, Harideep Nair, Vinay Vidyasagar", "title": "Hardware Aware Neural Network Architectures using FbNet", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a differentiable Neural Architecture Search (NAS) method\ninspired by FBNet for discovering neural networks that are heavily optimized\nfor a particular target device. The FBNet NAS method discovers a neural network\nfrom a given search space by optimizing over a loss function which accounts for\naccuracy and target device latency. We extend this loss function by adding an\nenergy term. This will potentially enhance the ``hardware awareness\" and help\nus find a neural network architecture that is optimal in terms of accuracy,\nlatency and energy consumption, given a target device (Raspberry Pi in our\ncase). We name our trained child architecture obtained at the end of search\nprocess as Hardware Aware Neural Network Architecture (HANNA). We prove the\nefficacy of our approach by benchmarking HANNA against two other\nstate-of-the-art neural networks designed for mobile/embedded applications,\nnamely MobileNetv2 and CondenseNet for CIFAR-10 dataset. Our results show that\nHANNA provides a speedup of about 2.5x and 1.7x, and reduces energy consumption\nby 3.8x and 2x compared to MobileNetv2 and CondenseNet respectively. HANNA is\nable to provide such significant speedup and energy efficiency benefits over\nthe state-of-the-art baselines at the cost of a tolerable 4-5% drop in\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:34:01 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Srinivas", "Sai Vineeth Kalluru", ""], ["Nair", "Harideep", ""], ["Vidyasagar", "Vinay", ""]]}, {"id": "1906.07247", "submitter": "Ashwin Geet D'Sa", "authors": "Ashwin Geet D'Sa and B. G. Prasad", "title": "An IoT Based Framework For Activity Recognition Using Deep Learning\n  Technique", "comments": "Intended to submit to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition is the ability to identify and recognize the action or\ngoals of the agent. The agent can be any object or entity that performs action\nthat has end goals. The agents can be a single agent performing the action or\ngroup of agents performing the actions or having some interaction. Human\nactivity recognition has gained popularity due to its demands in many practical\napplications such as entertainment, healthcare, simulations and surveillance\nsystems. Vision based activity recognition is gaining advantage as it does not\nrequire any human intervention or physical contact with humans. Moreover, there\nare set of cameras that are networked with the intention to track and recognize\nthe activities of the agent. Traditional applications that were required to\ntrack or recognize human activities made use of wearable devices. However, such\napplications require physical contact of the person. To overcome such\nchallenges, vision based activity recognition system can be used, which uses a\ncamera to record the video and a processor that performs the task of\nrecognition. The work is implemented in two stages. In the first stage, an\napproach for the Implementation of Activity recognition is proposed using\nbackground subtraction of images, followed by 3D- Convolutional Neural\nNetworks. The impact of using Background subtraction prior to 3D-Convolutional\nNeural Networks has been reported. In the second stage, the work is further\nextended and implemented on Raspberry Pi, that can be used to record a stream\nof video, followed by recognizing the activity that was involved in the video.\nThus, a proof-of-concept for activity recognition using small, IoT based\ndevice, is provided, which can enhance the system and extend its applications\nin various forms like, increase in portability, networking, and other\ncapabilities of the device.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:09:41 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["D'Sa", "Ashwin Geet", ""], ["Prasad", "B. G.", ""]]}, {"id": "1906.07248", "submitter": "Adeel Mufti", "authors": "Adeel Mufti, Svetlin Penkov, Subramanian Ramamoorthy", "title": "Iterative Model-Based Reinforcement Learning Using Simulations in the\n  Differentiable Neural Computer", "comments": "Accepted at the Workshop on Multi-Task and Lifelong Reinforcement\n  Learning, 36th International Conference on Machine Learning, Long Beach,\n  California, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a lifelong learning architecture, the Neural Computer Agent (NCA),\nwhere a Reinforcement Learning agent is paired with a predictive model of the\nenvironment learned by a Differentiable Neural Computer (DNC). The agent and\nDNC model are trained in conjunction iteratively. The agent improves its policy\nin simulations generated by the DNC model and rolls out the policy to the live\nenvironment, collecting experiences in new portions or tasks of the environment\nfor further learning. Experiments in two synthetic environments show that DNC\nmodels can continually learn from pixels alone to simulate new tasks as they\nare encountered by the agent, while the agents can be successfully trained to\nsolve the tasks using Proximal Policy Optimization entirely in simulations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:15:02 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Mufti", "Adeel", ""], ["Penkov", "Svetlin", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1906.07255", "submitter": "Lisa Tse", "authors": "Mark Herbster, Stephen Pasteris, Lisa Tse", "title": "Online Matrix Completion with Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an online algorithm and prove novel mistake and regret bounds for\nonline binary matrix completion with side information. The mistake bounds we\nprove are of the form $\\tilde{O}(D/\\gamma^2)$. The term $1/\\gamma^2$ is\nanalogous to the usual margin term in SVM (perceptron) bounds. More\nspecifically, if we assume that there is some factorization of the underlying\n$m \\times n$ matrix into $P Q^\\intercal$ where the rows of $P$ are interpreted\nas \"classifiers\" in $\\mathcal{R}^d$ and the rows of $Q$ as \"instances\" in\n$\\mathcal{R}^d$, then $\\gamma$ is the maximum (normalized) margin over all\nfactorizations $P Q^\\intercal$ consistent with the observed matrix. The\nquasi-dimension term $D$ measures the quality of side information. In the\npresence of vacuous side information, $D= m+n$. However, if the side\ninformation is predictive of the underlying factorization of the matrix, then\nin an ideal case, $D \\in O(k + \\ell)$ where $k$ is the number of distinct row\nfactors and $\\ell$ is the number of distinct column factors. We additionally\nprovide a generalization of our algorithm to the inductive setting. In this\nsetting, we provide an example where the side information is not directly\nspecified in advance. For this example, the quasi-dimension $D$ is now bounded\nby $O(k^2 + \\ell^2)$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:37:18 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 16:39:30 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 12:00:48 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Herbster", "Mark", ""], ["Pasteris", "Stephen", ""], ["Tse", "Lisa", ""]]}, {"id": "1906.07265", "submitter": "Keith Levin", "authors": "Keith Levin and Asad Lodhia and Elizaveta Levina", "title": "Recovering shared structure from multiple networks with unknown edge\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In increasingly many settings, data sets consist of multiple samples from a\npopulation of networks, with vertices aligned across these networks. For\nexample, brain connectivity networks in neuroscience consist of measures of\ninteraction between brain regions that have been aligned to a common template.\nWe consider the setting where the observed networks have a shared expectation,\nbut may differ in the noise structure on their edges. Our approach exploits the\nshared mean structure to denoise edge-level measurements of the observed\nnetworks and estimate the underlying population-level parameters. We also\nexplore the extent to which edge-level errors influence estimation and\ndownstream inference. We establish a finite-sample concentration inequality for\nthe low-rank eigenvalue truncation of a random weighted adjacency matrix that\nmay be of independent interest. The proposed approach is illustrated on\nsynthetic networks and on data from an fMRI study of schizophrenia.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 01:30:27 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 20:46:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Levin", "Keith", ""], ["Lodhia", "Asad", ""], ["Levina", "Elizaveta", ""]]}, {"id": "1906.07277", "submitter": "Kian Hsiang Low", "authors": "Yehong Zhang, Zhongxiang Dai, Kian Hsiang Low", "title": "Bayesian Optimization with Binary Auxiliary Information", "comments": "35th Conference on Uncertainty in Artificial Intelligence (UAI 2019),\n  Extended version with derivations and more experimental results, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents novel mixed-type Bayesian optimization (BO) algorithms to\naccelerate the optimization of a target objective function by exploiting\ncorrelated auxiliary information of binary type that can be more cheaply\nobtained, such as in policy search for reinforcement learning and\nhyperparameter tuning of machine learning models with early stopping. To\nachieve this, we first propose a mixed-type multi-output Gaussian process\n(MOGP) to jointly model the continuous target function and binary auxiliary\nfunctions. Then, we propose information-based acquisition functions such as\nmixed-type entropy search (MT-ES) and mixed-type predictive ES (MT-PES) for\nmixed-type BO based on the MOGP predictive belief of the target and auxiliary\nfunctions. The exact acquisition functions of MT-ES and MT-PES cannot be\ncomputed in closed form and need to be approximated. We derive an efficient\napproximation of MT-PES via a novel mixed-type random features approximation of\nthe MOGP model whose cross-correlation structure between the target and\nauxiliary functions can be exploited for improving the belief of the global\ntarget maximizer using observations from evaluating these functions. We propose\nnew practical constraints to relate the global target maximizer to the binary\nauxiliary functions. We empirically evaluate the performance of MT-ES and\nMT-PES with synthetic and real-world experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 21:20:21 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Zhang", "Yehong", ""], ["Dai", "Zhongxiang", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1906.07282", "submitter": "Alex Lu", "authors": "Alex X. Lu, Amy X. Lu, Wiebke Schormann, Marzyeh Ghassemi, David W.\n  Andrews, Alan M. Moses", "title": "The Cells Out of Sample (COOS) dataset and benchmarks for measuring\n  out-of-sample generalization of image classifiers", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems 32, pages\n  1852-1860. NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding if classifiers generalize to out-of-sample datasets is a\ncentral problem in machine learning. Microscopy images provide a standardized\nway to measure the generalization capacity of image classifiers, as we can\nimage the same classes of objects under increasingly divergent, but controlled\nfactors of variation. We created a public dataset of 132,209 images of mouse\ncells, COOS-7 (Cells Out Of Sample 7-Class). COOS-7 provides a classification\nsetting where four test datasets have increasing degrees of covariate shift:\nsome images are random subsets of the training data, while others are from\nexperiments reproduced months later and imaged by different instruments. We\nbenchmarked a range of classification models using different representations,\nincluding transferred neural network features, end-to-end classification with a\nsupervised deep CNN, and features from a self-supervised CNN. While most\nclassifiers perform well on test datasets similar to the training dataset, all\nclassifiers failed to generalize their performance to datasets with greater\ncovariate shifts. These baselines highlight the challenges of covariate shifts\nin image data, and establish metrics for improving the generalization capacity\nof image classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 21:35:00 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 15:05:54 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 15:46:56 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Lu", "Alex X.", ""], ["Lu", "Amy X.", ""], ["Schormann", "Wiebke", ""], ["Ghassemi", "Marzyeh", ""], ["Andrews", "David W.", ""], ["Moses", "Alan M.", ""]]}, {"id": "1906.07291", "submitter": "Andr\\'es Corrada-Emmanuel", "authors": "Andr\\'es Corrada-Emmanuel and Edward Zahrebelski and Edward Pantridge", "title": "Error Correcting Algorithms for Sparsely Correlated Regressors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomy and adaptation of machines requires that they be able to measure\ntheir own errors. We consider the advantages and limitations of such an\napproach when a machine has to measure the error in a regression task. How can\na machine measure the error of regression sub-components when it does not have\nthe ground truth for the correct predictions? A compressed sensing approach\napplied to the error signal of the regressors can recover their precision error\nwithout any ground truth. It allows for some regressors to be \\emph{strongly\ncorrelated} as long as not too many are so related. Its solutions, however, are\nnot unique - a property of ground truth inference solutions. Adding\n$\\ell_1$--minimization as a condition can recover the correct solution in\nsettings where error correction is possible. We briefly discuss the similarity\nof the mathematics of ground truth inference for regressors to that for\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 22:34:17 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Corrada-Emmanuel", "Andr\u00e9s", ""], ["Zahrebelski", "Edward", ""], ["Pantridge", "Edward", ""]]}, {"id": "1906.07300", "submitter": "Adam Ibrahim", "authors": "Adam Ibrahim, Wa\\\"iss Azizian, Gauthier Gidel, Ioannis Mitliagkas", "title": "Linear Lower Bounds and Conditioning of Differentiable Games", "comments": "ICML 2020 final version", "journal-ref": "Proceedings of the 37 th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes of game-theoretic formulations in ML have caused a\nresurgence of research interest in differentiable games. Overwhelmingly, that\nresearch focuses on methods and upper bounds on their speed of convergence. In\nthis work, we approach the question of fundamental iteration complexity by\nproviding lower bounds to complement the linear (i.e. geometric) upper bounds\nobserved in the literature on a wide class of problems. We cast saddle-point\nand min-max problems as 2-player games. We leverage tools from single-objective\nconvex optimisation to propose new linear lower bounds for convex-concave\ngames. Notably, we give a linear lower bound for $n$-player differentiable\ngames, by using the spectral properties of the update operator. We then propose\na new definition of the condition number arising from our lower bound analysis.\nUnlike past definitions, our condition number captures the fact that linear\nrates are possible in games, even in the absence of strong convexity or strong\nconcavity in the variables.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:08:26 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:59:50 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 13:55:09 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ibrahim", "Adam", ""], ["Azizian", "Wa\u00efss", ""], ["Gidel", "Gauthier", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1906.07304", "submitter": "Jiayuan Mao", "authors": "Sidi Lu and Jiayuan Mao and Joshua B. Tenenbaum and Jiajun Wu", "title": "Neurally-Guided Structure Inference", "comments": "Proceedings of the 36th International Conference on Machine Learning\n  (ICML 2019). First two authors contributed equally. Project page:\n  http://ngsi.csail.mit.edu", "journal-ref": "PMLR(2019)97: 4144--4153", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most structure inference methods either rely on exhaustive search or are\npurely data-driven. Exhaustive search robustly infers the structure of\narbitrarily complex data, but it is slow. Data-driven methods allow efficient\ninference, but do not generalize when test data have more complex structures\nthan training data. In this paper, we propose a hybrid inference algorithm, the\nNeurally-Guided Structure Inference (NG-SI), keeping the advantages of both\nsearch-based and data-driven methods. The key idea of NG-SI is to use a neural\nnetwork to guide the hierarchical, layer-wise search over the compositional\nspace of structures. We evaluate our algorithm on two representative structure\ninference tasks: probabilistic matrix decomposition and symbolic program\nparsing. It outperforms data-driven and search-based alternatives on both\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:22:28 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 08:38:29 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Lu", "Sidi", ""], ["Mao", "Jiayuan", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1906.07315", "submitter": "Somdeb Majumdar", "authors": "Shauharda Khadka and Somdeb Majumdar and Santiago Miret and Stephen\n  McAleer and Kagan Tumer", "title": "Evolutionary Reinforcement Learning for Sample-Efficient Multiagent\n  Coordination", "comments": "Proceedings of the 37th International Conference on Machine Learning,\n  Vienna, Austria, PMLR 108, 2020", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cooperative multiagent reinforcement learning environments provide\nagents with a sparse team-based reward, as well as a dense agent-specific\nreward that incentivizes learning basic skills. Training policies solely on the\nteam-based reward is often difficult due to its sparsity. Furthermore, relying\nsolely on the agent-specific reward is sub-optimal because it usually does not\ncapture the team coordination objective. A common approach is to use reward\nshaping to construct a proxy reward by combining the individual rewards.\nHowever, this requires manual tuning for each environment. We introduce\nMultiagent Evolutionary Reinforcement Learning (MERL), a split-level training\nplatform that handles the two objectives separately through two optimization\nprocesses. An evolutionary algorithm maximizes the sparse team-based objective\nthrough neuroevolution on a population of teams. Concurrently, a gradient-based\noptimizer trains policies to only maximize the dense agent-specific rewards.\nThe gradient-based policies are periodically added to the evolutionary\npopulation as a way of information transfer between the two optimization\nprocesses. This enables the evolutionary algorithm to use skills learned via\nthe agent-specific rewards toward optimizing the global objective. Results\ndemonstrate that MERL significantly outperforms state-of-the-art methods, such\nas MADDPG, on a number of difficult coordination benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 00:25:27 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:24:50 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 17:03:43 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Khadka", "Shauharda", ""], ["Majumdar", "Somdeb", ""], ["Miret", "Santiago", ""], ["McAleer", "Stephen", ""], ["Tumer", "Kagan", ""]]}, {"id": "1906.07341", "submitter": "Zhiyong Yang", "authors": "Zhiyong Yang, Qianqian Xu, Xiaochun Cao, Qingming Huang", "title": "Learning Personalized Attribute Preference via Multi-task AUC\n  Optimization", "comments": "AAAI2019 oral", "journal-ref": "AAAI2019 oral", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, most of the existing attribute learning methods are trained\nbased on the consensus of annotations aggregated from a limited number of\nannotators. However, the consensus might fail in settings, especially when a\nwide spectrum of annotators with different interests and comprehension about\nthe attribute words are involved. In this paper, we develop a novel multi-task\nmethod to understand and predict personalized attribute annotations. Regarding\nthe attribute preference learning for each annotator as a specific task, we\nfirst propose a multi-level task parameter decomposition to capture the\nevolution from a highly popular opinion of the mass to highly personalized\nchoices that are special for each person. Meanwhile, for personalized learning\nmethods, ranking prediction is much more important than accurate\nclassification. This motivates us to employ an Area Under ROC Curve (AUC) based\nloss function to improve our model. On top of the AUC-based loss, we propose an\nefficient method to evaluate the loss and gradients. Theoretically, we propose\na novel closed-form solution for one of our non-convex subproblem, which leads\nto provable convergence behaviors. Furthermore, we also provide a\ngeneralization bound to guarantee a reasonable performance. Finally, empirical\nanalysis consistently speaks to the efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 02:14:36 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Yang", "Zhiyong", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "1906.07343", "submitter": "YiDing Jiang", "authors": "Yiding Jiang, Shixiang Gu, Kevin Murphy, Chelsea Finn", "title": "Language as an Abstraction for Hierarchical Deep Reinforcement Learning", "comments": "Published in Neural Information Processing Systems (NeurIPS) 2019;\n  Supplementary materials: https://sites.google.com/view/hal-demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving complex, temporally-extended tasks is a long-standing problem in\nreinforcement learning (RL). We hypothesize that one critical element of\nsolving such problems is the notion of compositionality. With the ability to\nlearn concepts and sub-skills that can be composed to solve longer tasks, i.e.\nhierarchical RL, we can acquire temporally-extended behaviors. However,\nacquiring effective yet general abstractions for hierarchical RL is remarkably\nchallenging. In this paper, we propose to use language as the abstraction, as\nit provides unique compositional structure, enabling fast learning and\ncombinatorial generalization, while retaining tremendous flexibility, making it\nsuitable for a variety of problems. Our approach learns an\ninstruction-following low-level policy and a high-level policy that can reuse\nabstractions across tasks, in essence, permitting agents to reason using\nstructured language. To study compositional task learning, we introduce an\nopen-source object interaction environment built using the MuJoCo physics\nengine and the CLEVR engine. We find that, using our approach, agents can learn\nto solve to diverse, temporally-extended tasks such as object sorting and\nmulti-object rearrangement, including from raw pixel observations. Our analysis\nreveals that the compositional nature of language is critical for learning\ndiverse sub-skills and systematically generalizing to new sub-skills in\ncomparison to non-compositional abstractions that use the same supervision.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 02:27:45 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 21:51:49 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jiang", "Yiding", ""], ["Gu", "Shixiang", ""], ["Murphy", "Kevin", ""], ["Finn", "Chelsea", ""]]}, {"id": "1906.07355", "submitter": "Yue Sun", "authors": "Yue Sun, Nicolas Flammarion and Maryam Fazel", "title": "Escaping from saddle points on Riemannian manifolds", "comments": "submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider minimizing a nonconvex, smooth function $f$ on a Riemannian\nmanifold $\\mathcal{M}$. We show that a perturbed version of Riemannian gradient\ndescent algorithm converges to a second-order stationary point (and hence is\nable to escape saddle points on the manifold). The rate of convergence depends\nas $1/\\epsilon^2$ on the accuracy $\\epsilon$, which matches a rate known only\nfor unconstrained smooth minimization. The convergence rate depends\npolylogarithmically on the manifold dimension $d$, hence is almost\ndimension-free. The rate also has a polynomial dependence on the parameters\ndescribing the curvature of the manifold and the smoothness of the function.\nWhile the unconstrained problem (Euclidean setting) is well-studied, our result\nis the first to prove such a rate for nonconvex, manifold-constrained problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 03:02:56 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Sun", "Yue", ""], ["Flammarion", "Nicolas", ""], ["Fazel", "Maryam", ""]]}, {"id": "1906.07372", "submitter": "Faraz Torabi", "authors": "Brahma S. Pavse, Faraz Torabi, Josiah P. Hanna, Garrett Warnell, Peter\n  Stone", "title": "RIDM: Reinforced Inverse Dynamics Modeling for Learning from a Single\n  Observed Demonstration", "comments": "IEEE Robotics and Automation Letters, presented at International\n  Conference on Intelligent Robots and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmenting reinforcement learning with imitation learning is often hailed as\na method by which to improve upon learning from scratch. However, most existing\nmethods for integrating these two techniques are subject to several strong\nassumptions---chief among them that information about demonstrator actions is\navailable. In this paper, we investigate the extent to which this assumption is\nnecessary by introducing and evaluating reinforced inverse dynamics modeling\n(RIDM), a novel paradigm for combining imitation from observation (IfO) and\nreinforcement learning with no dependence on demonstrator action information.\nMoreover, RIDM requires only a single demonstration trajectory and is able to\noperate directly on raw (unaugmented) state features. We find experimentally\nthat RIDM performs favorably compared to a baseline approach for several tasks\nin simulation as well as for tasks on a real UR5 robot arm. Experiment videos\ncan be found at https://sites.google.com/view/ridm-reinforced-inverse-dynami.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 04:33:51 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 18:48:07 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 21:34:14 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 18:35:49 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Pavse", "Brahma S.", ""], ["Torabi", "Faraz", ""], ["Hanna", "Josiah P.", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1906.07374", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Sean Geiger, Garrett Warnell, Peter Stone", "title": "Sample-efficient Adversarial Imitation Learning from Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation from observation is the framework of learning tasks by observing\ndemonstrated state-only trajectories. Recently, adversarial approaches have\nachieved significant performance improvements over other methods for imitating\ncomplex behaviors. However, these adversarial imitation algorithms often\nrequire many demonstration examples and learning iterations to produce a policy\nthat is successful at imitating a demonstrator's behavior. This high sample\ncomplexity often prohibits these algorithms from being deployed on physical\nrobots. In this paper, we propose an algorithm that addresses the sample\ninefficiency problem by utilizing ideas from trajectory centric reinforcement\nlearning algorithms. We test our algorithm and conduct experiments using an\nimitation task on a physical robot arm and its simulated version in Gazebo and\nwill show the improvement in learning rate and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 04:39:45 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Torabi", "Faraz", ""], ["Geiger", "Sean", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1906.07380", "submitter": "Siddhartha Jain", "authors": "Siddhartha Jain, Ge Liu, Jonas Mueller, David Gifford", "title": "Maximizing Overall Diversity for Improved Uncertainty Estimates in Deep\n  Ensembles", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inaccuracy of neural network models on inputs that do not stem from the\ntraining data distribution is both problematic and at times unrecognized. Model\nuncertainty estimation can address this issue, where uncertainty estimates are\noften based on the variation in predictions produced by a diverse ensemble of\nmodels applied to the same input. Here we describe Maximize Overall Diversity\n(MOD), a straightforward approach to improve ensemble-based uncertainty\nestimates by encouraging larger overall diversity in ensemble predictions\nacross all possible inputs that might be encountered in the future. When\napplied to various neural network ensembles, MOD significantly improves\npredictive performance for out-of-distribution test examples without\nsacrificing in-distribution performance on 38 Protein-DNA binding regression\ndatasets, 9 UCI datasets, and the IMDB-Wiki image dataset. Across many Bayesian\noptimization tasks, the performance of UCB acquisition is also greatly improved\nby leveraging MOD uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 05:03:45 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:03:14 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Jain", "Siddhartha", ""], ["Liu", "Ge", ""], ["Mueller", "Jonas", ""], ["Gifford", "David", ""]]}, {"id": "1906.07389", "submitter": "Isabelle Augenstein", "authors": "Johannes Bjerva, Yova Kementchedjhieva, Ryan Cotterell, Isabelle\n  Augenstein", "title": "Uncovering Probabilistic Implications in Typological Knowledge Bases", "comments": "To appear in Proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of linguistic typology is rooted in the implications we find\nbetween linguistic features, such as the fact that languages with object-verb\nword ordering tend to have post-positions. Uncovering such implications\ntypically amounts to time-consuming manual processing by trained and\nexperienced linguists, which potentially leaves key linguistic universals\nunexplored. In this paper, we present a computational model which successfully\nidentifies known universals, including Greenberg universals, but also uncovers\nnew ones, worthy of further linguistic investigation. Our approach outperforms\nbaselines previously used for this problem, as well as a strong baseline from\nknowledge base population.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 05:51:13 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kementchedjhieva", "Yova", ""], ["Cotterell", "Ryan", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1906.07395", "submitter": "Ching-Kang Ing", "authors": "Ching-Kang Ing", "title": "Model selection for high-dimensional linear regression with dependent\n  observations", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the prediction capability of the orthogonal greedy algorithm\n(OGA) in high-dimensional regression models with dependent observations. The\nrates of convergence of the prediction error of OGA are obtained under a\nvariety of sparsity conditions. To prevent OGA from overfitting, we introduce a\nhigh-dimensional Akaike's information criterion (HDAIC) to determine the number\nof OGA iterations. A key contribution of this work is to show that OGA, used in\nconjunction with HDAIC, can achieve the optimal convergence rate without\nknowledge of how sparse the underlying high-dimensional model is.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 06:17:30 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Ing", "Ching-Kang", ""]]}, {"id": "1906.07405", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Wenqing Hu, Haoyi Xiong, Jun Huan, Vladimir Braverman,\n  Zhanxing Zhu", "title": "On the Noisy Gradient Descent that Generalizes as SGD", "comments": "ICML 2020 near camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradient noise of SGD is considered to play a central role in the\nobserved strong generalization abilities of deep learning. While past studies\nconfirm that the magnitude and the covariance structure of gradient noise are\ncritical for regularization, it remains unclear whether or not the class of\nnoise distributions is important. In this work we provide negative results by\nshowing that noises in classes different from the SGD noise can also\neffectively regularize gradient descent. Our finding is based on a novel\nobservation on the structure of the SGD noise: it is the multiplication of the\ngradient matrix and a sampling noise that arises from the mini-batch sampling\nprocedure. Moreover, the sampling noises unify two kinds of gradient\nregularizing noises that belong to the Gaussian class: the one using (scaled)\nFisher as covariance and the one using the gradient covariance of SGD as\ncovariance. Finally, thanks to the flexibility of choosing noise class, an\nalgorithm is proposed to perform noisy gradient descent that generalizes well,\nthe variant of which even benefits large batch SGD training without hurting\ngeneralization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 06:54:56 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 17:18:19 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 14:46:39 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wu", "Jingfeng", ""], ["Hu", "Wenqing", ""], ["Xiong", "Haoyi", ""], ["Huan", "Jun", ""], ["Braverman", "Vladimir", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1906.07407", "submitter": "Shaosheng Cao", "authors": "Shaosheng Cao, Xinxing Yang, Cen Chen, Jun Zhou, Xiaolong Li, and Yuan\n  Qi", "title": "TitAnt: Online Real-time Transaction Fraud Detection in Ant Financial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of e-commerce and the booming of e-payment,\ndetecting online transaction fraud in real time has become increasingly\nimportant to Fintech business. To tackle this problem, we introduce the TitAnt,\na transaction fraud detection system deployed in Ant Financial, one of the\nlargest Fintech companies in the world. The system is able to predict online\nreal-time transaction fraud in mere milliseconds. We present the problem\ndefinition, feature extraction, detection methods, implementation and\ndeployment of the system, as well as empirical effectiveness. Extensive\nexperiments have been conducted on large real-world transaction data to show\nthe effectiveness and the efficiency of the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 07:05:25 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Cao", "Shaosheng", ""], ["Yang", "Xinxing", ""], ["Chen", "Cen", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Qi", "Yuan", ""]]}, {"id": "1906.07413", "submitter": "Kaidi Cao", "authors": "Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, Tengyu Ma", "title": "Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss", "comments": "to appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms can fare poorly when the training dataset suffers\nfrom heavy class-imbalance but the testing criterion requires good\ngeneralization on less frequent classes. We design two novel methods to improve\nperformance in such scenarios. First, we propose a theoretically-principled\nlabel-distribution-aware margin (LDAM) loss motivated by minimizing a\nmargin-based generalization bound. This loss replaces the standard\ncross-entropy objective during training and can be applied with prior\nstrategies for training with class-imbalance such as re-weighting or\nre-sampling. Second, we propose a simple, yet effective, training schedule that\ndefers re-weighting until after the initial stage, allowing the model to learn\nan initial representation while avoiding some of the complications associated\nwith re-weighting or re-sampling. We test our methods on several benchmark\nvision tasks including the real-world imbalanced dataset iNaturalist 2018. Our\nexperiments show that either of these methods alone can already improve over\nexisting techniques and their combination achieves even better performance\ngains.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 07:21:18 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 23:31:52 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cao", "Kaidi", ""], ["Wei", "Colin", ""], ["Gaidon", "Adrien", ""], ["Arechiga", "Nikos", ""], ["Ma", "Tengyu", ""]]}, {"id": "1906.07437", "submitter": "Qi Lei", "authors": "Qi Lei, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis", "title": "Inverting Deep Generative models, One layer at a time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inverting a deep generative model with ReLU\nactivations. Inversion corresponds to finding a latent code vector that\nexplains observed measurements as much as possible. In most prior works this is\nperformed by attempting to solve a non-convex optimization problem involving\nthe generator. In this paper we obtain several novel theoretical results for\nthe inversion problem.\n  We show that for the realizable case, single layer inversion can be performed\nexactly in polynomial time, by solving a linear program. Further, we show that\nfor multiple layers, inversion is NP-hard and the pre-image set can be\nnon-convex.\n  For generative models of arbitrary depth, we show that exact recovery is\npossible in polynomial time with high probability, if the layers are expanding\nand the weights are randomly selected. Very recent work analyzed the same\nproblem for gradient descent inversion. Their analysis requires significantly\nhigher expansion (logarithmic in the latent dimension) while our proposed\nalgorithm can provably reconstruct even with constant factor expansion. We also\nprovide provable error bounds for different norms for reconstructing noisy\nobservations. Our empirical validation demonstrates that we obtain better\nreconstructions when the latent dimension is large.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 08:20:34 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 06:19:19 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Lei", "Qi", ""], ["Jalal", "Ajil", ""], ["Dhillon", "Inderjit S.", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1906.07502", "submitter": "Delmiro Fernandez-Reyes Dr", "authors": "Biobele J. Brown, Alexander A. Przybylski, Petru Manescu, Fabio\n  Caccioli, Gbeminiyi Oyinloye, Muna Elmi, Michael J. Shaw, Vijay Pawar, Remy\n  Claveau, John Shawe-Taylor, Mandayam A. Srinivasan, Nathaniel K. Afolabi,\n  Adebola E. Orimadegun, Wasiu A. Ajetunmobi, Francis Akinkunmi, Olayinka\n  Kowobari, Kikelomo Osinusi, Felix O. Akinbami, Samuel Omokhodion, Wuraola A.\n  Shokunbi, Ikeoluwa Lagunju, Olugbemiro Sodeinde, and Delmiro Fernandez-Reyes", "title": "Data-Driven Malaria Prevalence Prediction in Large Densely-Populated\n  Urban Holoendemic sub-Saharan West Africa: Harnessing Machine Learning\n  Approaches and 22-years of Prospectively Collected Data", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plasmodium falciparum malaria still poses one of the greatest threats to\nhuman life with over 200 million cases globally leading to half-million deaths\nannually. Of these, 90% of cases and of the mortality occurs in sub-Saharan\nAfrica, mostly among children. Although malaria prediction systems are central\nto the 2016-2030 malaria Global Technical Strategy, currently these are\ninadequate at capturing and estimating the burden of disease in highly endemic\ncountries. We developed and validated a computational system that exploits the\npredictive power of current Machine Learning approaches on 22-years of\nprospective data from the high-transmission holoendemic malaria\nurban-densely-populated sub-Saharan West-Africa metropolis of Ibadan. Our\ndataset of >9x104 screened study participants attending our clinical and\ncommunity services from 1996 to 2017 contains monthly prevalence, temporal,\nenvironmental and host features. Our Locality-specific Elastic-Net based\nMalaria Prediction System (LEMPS) achieves good generalization performance,\nboth in magnitude and direction of the prediction, when tasked to predict\nmonthly prevalence on previously unseen validation data (MAE<=6x10-2,\nMSE<=7x10-3) within a range of (+0.1 to -0.05) error-tolerance which is\nrelevant and usable for aiding decision-support in a holoendemic setting. LEMPS\nis well-suited for malaria prediction, where there are multiple features which\nare correlated with one another, and trading-off between\nregularization-strength L1-norm and L2-norm allows the system to retain\nstability. Data-driven systems are critical for regionally-adaptable\nsurveillance, management of control strategies and resource allocation across\nstretched healthcare systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 11:25:35 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Brown", "Biobele J.", ""], ["Przybylski", "Alexander A.", ""], ["Manescu", "Petru", ""], ["Caccioli", "Fabio", ""], ["Oyinloye", "Gbeminiyi", ""], ["Elmi", "Muna", ""], ["Shaw", "Michael J.", ""], ["Pawar", "Vijay", ""], ["Claveau", "Remy", ""], ["Shawe-Taylor", "John", ""], ["Srinivasan", "Mandayam A.", ""], ["Afolabi", "Nathaniel K.", ""], ["Orimadegun", "Adebola E.", ""], ["Ajetunmobi", "Wasiu A.", ""], ["Akinkunmi", "Francis", ""], ["Kowobari", "Olayinka", ""], ["Osinusi", "Kikelomo", ""], ["Akinbami", "Felix O.", ""], ["Omokhodion", "Samuel", ""], ["Shokunbi", "Wuraola A.", ""], ["Lagunju", "Ikeoluwa", ""], ["Sodeinde", "Olugbemiro", ""], ["Fernandez-Reyes", "Delmiro", ""]]}, {"id": "1906.07516", "submitter": "Daniel J. Mankowitz", "authors": "Daniel J. Mankowitz and Nir Levine and Rae Jeong and Yuanyuan Shi and\n  Jackie Kay and Abbas Abdolmaleki and Jost Tobias Springenberg and Timothy\n  Mann and Todd Hester and Martin Riedmiller", "title": "Robust Reinforcement Learning for Continuous Control with Model\n  Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a framework for incorporating robustness -- to perturbations in\nthe transition dynamics which we refer to as model misspecification -- into\ncontinuous control Reinforcement Learning (RL) algorithms. We specifically\nfocus on incorporating robustness into a state-of-the-art continuous control RL\nalgorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve\nthis by learning a policy that optimizes for a worst case expected return\nobjective and derive a corresponding robust entropy-regularized Bellman\ncontraction operator. In addition, we introduce a less conservative,\nsoft-robust, entropy-regularized objective with a corresponding Bellman\noperator. We show that both, robust and soft-robust policies, outperform their\nnon-robust counterparts in nine Mujoco domains with environment perturbations.\nIn addition, we show improved robust performance on a high-dimensional,\nsimulated, dexterous robotic hand. Finally, we present multiple investigative\nexperiments that provide a deeper insight into the robustness framework. This\nincludes an adaptation to another continuous control RL algorithm as well as\nlearning the uncertainty set from offline data. Performance videos can be found\nonline at https://sites.google.com/view/robust-rl.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:08:42 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:23:02 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Levine", "Nir", ""], ["Jeong", "Rae", ""], ["Shi", "Yuanyuan", ""], ["Kay", "Jackie", ""], ["Abdolmaleki", "Abbas", ""], ["Springenberg", "Jost Tobias", ""], ["Mann", "Timothy", ""], ["Hester", "Todd", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1906.07528", "submitter": "Kevin Alexander Laube", "authors": "Kevin Alexander Laube and Andreas Zell", "title": "Prune and Replace NAS", "comments": "9 pages, 3 figures, 3 tables reworked, accepted at the ICMLA 2019", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00158", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent NAS algorithms are thousands of times faster than the pioneering\nworks, it is often overlooked that they use fewer candidate operations,\nresulting in a significantly smaller search space. We present PR-DARTS, a NAS\nalgorithm that discovers strong network configurations in a much larger search\nspace and a single day. A small candidate operation pool is used, from which\ncandidates are progressively pruned and replaced with better performing ones.\nExperiments on CIFAR-10 and CIFAR-100 achieve 2.51% and 15.53% test error,\nrespectively, despite searching in a space where each cell has 150 times as\nmany possible configurations than in the DARTS baseline. Code is available at\nhttps://github.com/cogsys-tuebingen/prdarts\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:32:30 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 06:59:00 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Laube", "Kevin Alexander", ""], ["Zell", "Andreas", ""]]}, {"id": "1906.07529", "submitter": "Simon Tamayo Giraldo", "authors": "Simon Tamayo (CAOR), Fran\\c{c}ois Combes (IFSTTAR/AME/SPLOTT), Gaudron\n  Arthur (CAOR)", "title": "Unsupervised machine learning to analyse city logistics through Twitter", "comments": null, "journal-ref": "11th International Conference on City Logistics, Jun 2019,\n  Dubrovnik, Croatia", "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  City Logistics is characterized by multiple stakeholders that often have\ndifferent views of such a complex system. From a public policy perspective,\nidentifying stakeholders, issues and trends is a daunting challenge, only\npartially addressed by traditional observation systems. Nowadays, social media\nis one of the biggest channels of public expression and is often used to\ncommunicate opinions and content related to City Logistics. The idea of this\nresearch is that analysing social media content could help in understanding the\npublic perception of City logistics. This paper offers a methodology for\ncollecting content from Twitter and implementing Machine Learning techniques\n(Unsupervised Learning and Natural Language Processing), to perform content and\nsentiment analysis. The proposed methodology is applied to more than 110 000\ntweets containing City Logistics key-terms. Results allowed the building of an\nInterest Map of concepts and a Sentiment Analysis to determine if City\nLogistics entries are positive, negative or neutral.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:34:13 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Tamayo", "Simon", "", "CAOR"], ["Combes", "Fran\u00e7ois", "", "IFSTTAR/AME/SPLOTT"], ["Arthur", "Gaudron", "", "CAOR"]]}, {"id": "1906.07537", "submitter": "Arielle Moro", "authors": "Arielle Moro, Beno\\^it Garbinato and Val\\'erie Chavez-Demoulin", "title": "Analyzing privacy-aware mobility behavior using the evolution of\n  spatio-temporal entropy", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing mobility behavior of users is extremely useful to create or improve\nexisting services. Several research works have been done in order to study\nmobility behavior of users that mainly use users' significant locations.\nHowever, these existing analysis are extremely intrusive because they require\nthe knowledge of the frequently visited places of users, which thus makes it\nfairly easy to identify them. Consequently, in this paper, we present a\nprivacy-aware methodology to analyze mobility behavior of users. We firstly\npropose a new metric based on the well-known Shannon entropy, called\nspatio-temporal entropy, to quantify the mobility level of a user during a time\nwindow. Then, we compute a sequence of spatio-temporal entropy from the\nlocation history of the user that expresses user's movements as rhythms. We\nsecondly present how to study the effects of several groups of additional\nvariables on the evolution of the spatio-temporal entropy of a user, such as\nspatio-temporal, demographic and mean of transportation variables. For this, we\nuse Generalized Additive Models (GAMs). The results firstly show that the\nspatio-temporal entropy and GAMs are an ideal combination to understand\nmobility behavior of an individual user or a group of users. We also evaluate\nthe prediction accuracy of a global GAM compared to individual GAMs and\nindividual AutoRegressive Integrated Moving Average (ARIMA) models. These last\nresults highlighted that the global GAM gives more accurate predictions of\nspatio-temporal entropy by checking the Mean Absolute Error (MAE). In addition,\nthis research work opens various threads, such as the prediction of demographic\ndata of users or the creation of personalized mobility prediction models by\nusing movement rhythm characteristics of a user.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:56:26 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 11:30:19 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Moro", "Arielle", ""], ["Garbinato", "Beno\u00eet", ""], ["Chavez-Demoulin", "Val\u00e9rie", ""]]}, {"id": "1906.07549", "submitter": "Zhusi Zhong", "authors": "Zhusi Zhong, Jie Li, Zhenxi Zhang, Zhicheng Jiao, Xinbo Gao", "title": "An Attention-Guided Deep Regression Model for Landmark Detection in\n  Cephalograms", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32226-7_60", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cephalometric tracing method is usually used in orthodontic diagnosis and\ntreatment planning. In this paper, we propose a deep learning based framework\nto automatically detect anatomical landmarks in cephalometric X-ray images. We\ntrain the deep encoder-decoder for landmark detection, and combine global\nlandmark configuration with local high-resolution feature responses. The\nproposed frame-work is based on 2-stage u-net, regressing the multi-channel\nheatmaps for land-mark detection. In this framework, we embed attention\nmechanism with global stage heatmaps, guiding the local stage inferring, to\nregress the local heatmap patches in a high resolution. Besides, the Expansive\nExploration strategy improves robustness while inferring, expanding the\nsearching scope without increasing model complexity. We have evaluated our\nframework in the most widely-used public dataset of landmark detection in\ncephalometric X-ray images. With less computation and manually tuning, our\nframework achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:11:31 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 03:24:20 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 07:44:02 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zhong", "Zhusi", ""], ["Li", "Jie", ""], ["Zhang", "Zhenxi", ""], ["Jiao", "Zhicheng", ""], ["Gao", "Xinbo", ""]]}, {"id": "1906.07552", "submitter": "Qiuqiang Kong", "authors": "Qiuqiang Kong, Yong Xu, Wenwu Wang, Philip J. B. Jackson, Mark D.\n  Plumbley", "title": "Single-Channel Signal Separation and Deconvolution with Generative\n  Adversarial Networks", "comments": "7 pages. Accepted by IJCAI 2019", "journal-ref": "International Joint Conference on Artificial Intelligence (IJCAI),\n  2019, pp. 2747-2753", "doi": "10.24963/ijcai.2019/381", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-channel signal separation and deconvolution aims to separate and\ndeconvolve individual sources from a single-channel mixture and is a\nchallenging problem in which no prior knowledge of the mixing filters is\navailable. Both individual sources and mixing filters need to be estimated. In\naddition, a mixture may contain non-stationary noise which is unseen in the\ntraining set. We propose a synthesizing-decomposition (S-D) approach to solve\nthe single-channel separation and deconvolution problem. In synthesizing, a\ngenerative model for sources is built using a generative adversarial network\n(GAN). In decomposition, both mixing filters and sources are optimized to\nminimize the reconstruction error of the mixture. The proposed S-D approach\nachieves a peak-to-noise-ratio (PSNR) of 18.9 dB and 15.4 dB in image\ninpainting and completion, outperforming a baseline convolutional neural\nnetwork PSNR of 15.3 dB and 12.2 dB, respectively and achieves a PSNR of 13.2\ndB in source separation together with deconvolution, outperforming a\nconvolutive non-negative matrix factorization (NMF) baseline of 10.1 dB.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 22:00:26 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Kong", "Qiuqiang", ""], ["Xu", "Yong", ""], ["Wang", "Wenwu", ""], ["Jackson", "Philip J. B.", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1906.07573", "submitter": "Mithun Das Gupta", "authors": "Gautam Prasad and Upendra Reddy Vuyyuru and Mithun Das Gupta", "title": "Agriculture Commodity Arrival Prediction using Remote Sensing Data:\n  Insights and Beyond", "comments": "KDD'18 Fragile Earth Workshop (FEED)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In developing countries like India agriculture plays an extremely important\nrole in the lives of the population. In India, around 80\\% of the population\ndepend on agriculture or its by-products as the primary means for employment.\nGiven large population dependency on agriculture, it becomes extremely\nimportant for the government to estimate market factors in advance and prepare\nfor any deviation from those estimates. Commodity arrivals to market is an\nextremely important factor which is captured at district level throughout the\ncountry. Historical data and short-term prediction of important variables such\nas arrivals, prices, crop quality etc. for commodities are used by the\ngovernment to take proactive steps and decide various policy measures.\n  In this paper, we present a framework to work with short timeseries in\nconjunction with remote sensing data to predict future commodity arrivals. We\ndeal with extremely high dimensional data which exceed the observation sizes by\nmultiple orders of magnitude. We use cascaded layers of dimensionality\nreduction techniques combined with regularized regression models for\nprediction. We present results to predict arrivals to major markets and state\nwide prices for `Tur' (red gram) crop in Karnataka, India. Our model\nconsistently beats popular ML techniques on many instances. Our model is\nscalable, time efficient and can be generalized to many other crops and\nregions. We draw multiple insights from the regression parameters, some of\nwhich are important aspects to consider when predicting more complex quantities\nsuch as prices in the future. We also combine the insights to generate\nimportant recommendations for different government organizations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 07:54:20 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Prasad", "Gautam", ""], ["Vuyyuru", "Upendra Reddy", ""], ["Gupta", "Mithun Das", ""]]}, {"id": "1906.07575", "submitter": "Ali AbdelAziz", "authors": "Ali AbdelAziz, Amin Shoukry, Walid Gomaa, Moustafa Youssef", "title": "Trans-Sense: Real Time Transportation Schedule Estimation Using Smart\n  Phones", "comments": "8 pages, 11 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing countries suffer from traffic congestion, poorly planned road/rail\nnetworks, and lack of access to public transportation facilities. This context\nresults in an increase in fuel consumption, pollution level, monetary losses,\nmassive delays, and less productivity. On the other hand, it has a negative\nimpact on the commuters feelings and moods. Availability of real-time transit\ninformation - by providing public transportation vehicles locations using GPS\ndevices - helps in estimating a passenger's waiting time and addressing the\nabove issues. However, such solution is expensive for developing countries.\nThis paper aims at designing and implementing a crowd-sourced mobile\nphones-based solution to estimate the expected waiting time of a passenger in\npublic transit systems, the prediction of the remaining time to get on/off a\nvehicle, and to construct a real time public transit schedule. Trans-Sense has\nbeen evaluated using real data collected for over 800 hours, on a daily basis,\nby different Android phones, and using different light rail transit lines at\ndifferent time spans. The results show that Trans-Sense can achieve an average\nrecall and precision of 95.35% and 90.1%, respectively, in discriminating\nlightrail stations. Moreover, the empirical distributions governing the\ndifferent time delays affecting a passenger's total trip time enable predicting\nthe right time of arrival of a passenger to her destination with an accuracy of\n91.81%.In addition, the system estimates the stations dimensions with an\naccuracy of 95.71%.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 01:11:15 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["AbdelAziz", "Ali", ""], ["Shoukry", "Amin", ""], ["Gomaa", "Walid", ""], ["Youssef", "Moustafa", ""]]}, {"id": "1906.07576", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Thibault Asselborn, Caroline Jolly, Laurence Casteran,\n  Marie-Ange~Nguyen-Morel, Wafa Johal, Pierre Dillenbourg", "title": "The Dynamics of Handwriting Improves the Automated Diagnosis of\n  Dysgraphia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting disorder (termed dysgraphia) is a far from a singular problem as\nnearly 8.6% of the population in France is considered dysgraphic. Moreover,\nresearch highlights the fundamental importance to detect and remediate these\nhandwriting difficulties as soon as possible as they may affect a child's\nentire life, undermining performance and self-confidence in a wide variety of\nschool activities. At the moment, the detection of handwriting difficulties is\nperformed through a standard test called BHK. This detection, performed by\ntherapists, is laborious because of its high cost and subjectivity. We present\na digital approach to identify and characterize handwriting difficulties via a\nRecurrent Neural Network model (RNN). The child under investigation is asked to\nwrite on a graphics tablet all the letters of the alphabet as well as the ten\ndigits. Once complete, the RNN delivers a diagnosis in a few milliseconds and\ndemonstrates remarkable efficiency as it correctly identifies more than 90% of\nchildren diagnosed as dysgraphic using the BHK test. The main advantage of our\ntablet-based system is that it captures the dynamic features of writing --\nsomething a human expert, such as a teacher, is unable to do. We show that\nincorporating the dynamic information available by the use of tablet is highly\nbeneficial to our digital test to discriminate between typically-developing and\ndysgraphic children.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:47:02 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Zolna", "Konrad", ""], ["Asselborn", "Thibault", ""], ["Jolly", "Caroline", ""], ["Casteran", "Laurence", ""], ["Marie-Ange~Nguyen-Morel", "", ""], ["Johal", "Wafa", ""], ["Dillenbourg", "Pierre", ""]]}, {"id": "1906.07582", "submitter": "Karen Ullrich", "authors": "Karen Ullrich, Rianne van den Berg, Marcus Brubaker, David Fleet, Max\n  Welling", "title": "Differentiable probabilistic models of scientific imaging with the\n  Fourier slice theorem", "comments": "accepted to UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scientific imaging techniques such as optical and electron microscopy and\ncomputed tomography (CT) scanning are used to study the 3D structure of an\nobject through 2D observations. These observations are related to the original\n3D object through orthogonal integral projections. For common 3D reconstruction\nalgorithms, computational efficiency requires the modeling of the 3D structures\nto take place in Fourier space by applying the Fourier slice theorem. At\npresent, it is unclear how to differentiate through the projection operator,\nand hence current learning algorithms can not rely on gradient based methods to\noptimize 3D structure models. In this paper we show how back-propagation\nthrough the projection operator in Fourier space can be achieved. We\ndemonstrate the validity of the approach with experiments on 3D reconstruction\nof proteins. We further extend our approach to learning probabilistic models of\n3D objects. This allows us to predict regions of low sampling rates or estimate\nnoise. A higher sample efficiency can be reached by utilizing the learned\nuncertainties of the 3D structure as an unsupervised estimate of the model fit.\nFinally, we demonstrate how the reconstruction algorithm can be extended with\nan amortized inference scheme on unknown attributes such as object pose.\nThrough empirical studies we show that joint inference of the 3D structure and\nthe object pose becomes more difficult when the ground truth object contains\nmore symmetries. Due to the presence of for instance (approximate) rotational\nsymmetries, the pose estimation can easily get stuck in local optima,\ninhibiting a fine-grained high-quality estimate of the 3D structure.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:49:06 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 15:20:54 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Ullrich", "Karen", ""], ["Berg", "Rianne van den", ""], ["Brubaker", "Marcus", ""], ["Fleet", "David", ""], ["Welling", "Max", ""]]}, {"id": "1906.07586", "submitter": "Dongqi Han", "authors": "Tadashi Kozuno, Dongqi Han, Kenji Doya", "title": "Gap-Increasing Policy Evaluation for Efficient and Noise-Tolerant\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications of reinforcement learning (RL), noise from\ninherent stochasticity of environments is inevitable. However, current policy\nevaluation algorithms, which plays a key role in many RL algorithms, are either\nprone to noise or inefficient. To solve this issue, we introduce a novel policy\nevaluation algorithm, which we call Gap-increasing RetrAce Policy Evaluation\n(GRAPE). It leverages two recent ideas: (1) gap-increasing value update\noperators in advantage learning for noise-tolerance and (2) off-policy\neligibility trace in Retrace algorithm for efficient learning. We provide\ndetailed theoretical analysis of the new algorithm that shows its efficiency\nand noise-tolerance inherited from Retrace and advantage learning. Furthermore,\nour analysis shows that GRAPE's learning is significantly efficient than that\nof a simple learning-rate-based approach while keeping the same level of\nnoise-tolerance. We applied GRAPE to control problems and obtained experimental\nresults supporting our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:54:54 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kozuno", "Tadashi", ""], ["Han", "Dongqi", ""], ["Doya", "Kenji", ""]]}, {"id": "1906.07590", "submitter": "Tobias Jacobs", "authors": "Prabhant Singh and Tobias Jacobs and Sebastien Nicolas and Mischa\n  Schmidt", "title": "A Study of the Learning Progress in Neural Architecture Search\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural architecture search, the structure of the neural network to best\nmodel a given dataset is determined by an automated search process. Efficient\nNeural Architecture Search (ENAS), proposed by Pham et al. (2018), has recently\nreceived considerable attention due to its ability to find excellent\narchitectures within a comparably short search time. In this work, which is\nmotivated by the quest to further improve the learning speed of architecture\nsearch, we evaluate the learning progress of the controller which generates the\narchitectures in ENAS. We measure the progress by comparing the architectures\ngenerated by it at different controller training epochs, where architectures\nare evaluated after having re-trained them from scratch. As a surprising\nresult, we find that the learning curves are completely flat, i.e., there is no\nobservable progress of the controller in terms of the performance of its\ngenerated architectures. This observation is consistent across the CIFAR-10 and\nCIFAR-100 datasets and two different search spaces. We conclude that the high\nquality of the models generated by ENAS is a result of the search space design\nrather than the controller training, and our results indicate that one-shot\narchitecture design is an efficient alternative to architecture search by ENAS.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:00:19 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Singh", "Prabhant", ""], ["Jacobs", "Tobias", ""], ["Nicolas", "Sebastien", ""], ["Schmidt", "Mischa", ""]]}, {"id": "1906.07611", "submitter": "Tyler Lekang", "authors": "Tyler Lekang, Andrew Lamperski", "title": "Simple Algorithms for Dueling Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present simple algorithms for Dueling Bandits. We prove\nthat the algorithms have regret bounds for time horizon T of order O(T^rho )\nwith 1/2 <= rho <= 3/4, which importantly do not depend on any preference gap\nbetween actions, Delta. Dueling Bandits is an important extension of the\nMulti-Armed Bandit problem, in which the algorithm must select two actions at a\ntime and only receives binary feedback for the duel outcome. This is analogous\nto comparisons in which the rater can only provide yes/no or better/worse type\nresponses. We compare our simple algorithms to the current state-of-the-art for\nDueling Bandits, ISS and DTS, discussing complexity and regret upper bounds,\nand conducting experiments on synthetic data that demonstrate their regret\nperformance, which in some cases exceeds state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:35:10 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Lekang", "Tyler", ""], ["Lamperski", "Andrew", ""]]}, {"id": "1906.07633", "submitter": "Gr\\'egoire Montavon", "authors": "Jacob Kauffmann, Malte Esders, Gr\\'egoire Montavon, Wojciech Samek,\n  Klaus-Robert M\\\"uller", "title": "From Clustering to Cluster Explanations via Neural Networks", "comments": "12 pages + supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wealth of algorithms have been developed to extract natural cluster\nstructure in data. Identifying this structure is desirable but not always\nsufficient: We may also want to understand why the data points have been\nassigned to a given cluster. Clustering algorithms do not offer a systematic\nanswer to this simple question. Hence we propose a new framework that can, for\nthe first time, explain cluster assignments in terms of input features in a\ncomprehensive manner. It is based on the novel theoretical insight that\nclustering models can be rewritten as neural networks, or 'neuralized'.\nPredictions of the obtained networks can then be quickly and accurately\nattributed to the input features. Several showcases demonstrate the ability of\nour method to assess the quality of learned clusters and to extract novel\ninsights from the analyzed data and representations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:08:17 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kauffmann", "Jacob", ""], ["Esders", "Malte", ""], ["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1906.07644", "submitter": "Andr\\'e Biedenkapp", "authors": "Andr\\'e Biedenkapp, H. Furkan Bozkurt, Frank Hutter, Marius Lindauer", "title": "Towards White-box Benchmarks for Algorithm Control", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many algorithms in the fields of hard combinatorial\nproblem solving, machine learning or AI in general depends on tuned\nhyperparameter configurations. Automated methods have been proposed to\nalleviate users from the tedious and error-prone task of manually searching for\nperformance-optimized configurations across a set of problem instances. However\nthere is still a lot of untapped potential through adjusting an algorithm's\nhyperparameters online since different hyperparameters are potentially optimal\nat different stages of the algorithm. We formulate the problem of adjusting an\nalgorithm's hyperparameters for a given instance on the fly as a contextual\nMDP, making reinforcement learning (RL) the prime candidate to solve the\nresulting algorithm control problem in a data-driven way. Furthermore, inspired\nby applications of algorithm configuration, we introduce new white-box\nbenchmarks suitable to study algorithm control. We show that on short\nsequences, algorithm configuration is a valid choice, but that with increasing\nsequence length a black-box view on the problem quickly becomes infeasible and\nRL performs better.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:40:43 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 13:43:34 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Biedenkapp", "Andr\u00e9", ""], ["Bozkurt", "H. Furkan", ""], ["Hutter", "Frank", ""], ["Lindauer", "Marius", ""]]}, {"id": "1906.07658", "submitter": "Bamdad Hosseini Dr.", "authors": "Franca Hoffmann, Bamdad Hosseini, Zhi Ren, Andrew M. Stuart", "title": "Consistency of semi-supervised learning algorithms on graphs: Probit and\n  one-hot methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based semi-supervised learning is the problem of propagating labels\nfrom a small number of labelled data points to a larger set of unlabelled data.\nThis paper is concerned with the consistency of optimization-based techniques\nfor such problems, in the limit where the labels have small noise and the\nunderlying unlabelled data is well clustered. We study graph-based probit for\nbinary classification, and a natural generalization of this method to\nmulti-class classification using one-hot encoding. The resulting objective\nfunction to be optimized comprises the sum of a quadratic form defined through\na rational function of the graph Laplacian, involving only the unlabelled data,\nand a fidelity term involving only the labelled data. The consistency analysis\nsheds light on the choice of the rational function defining the optimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:52:33 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 19:38:25 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Hoffmann", "Franca", ""], ["Hosseini", "Bamdad", ""], ["Ren", "Zhi", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1906.07661", "submitter": "Bharathkumar Ramachandra", "authors": "Bharathkumar Ramachandra, Benjamin Dutton and Ranga Raju Vatsavai", "title": "Estimating a Manifold from a Tangent Bundle Learner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold hypotheses are typically used for tasks such as dimensionality\nreduction, interpolation, or improving classification performance. In the less\ncommon problem of manifold estimation, the task is to characterize the\ngeometric structure of the manifold in the original ambient space from a\nsample. We focus on the role that tangent bundle learners (TBL) can play in\nestimating the underlying manifold from which data is assumed to be sampled.\nSince the unbounded tangent spaces natively represent a poor manifold estimate,\nthe problem reduces to one of estimating regions in the tangent space where it\nacts as a relatively faithful linear approximator to the surface of the\nmanifold. Local PCA methods, such as the Mixtures of Probabilistic Principal\nComponent Analyzers method of Tipping and Bishop produce a subset of the\ntangent bundle of the manifold along with an assignment function that assigns\npoints in the training data used by the TBL to elements of the estimated\ntangent bundle. We formulate three methods that use the data assigned to each\ntangent space to estimate the underlying bounded subspaces for which the\ntangent space is a faithful estimate of the manifold and offer thoughts on how\nthis perspective is theoretically grounded in the manifold assumption. We seek\nto explore the conceptual and technical challenges that arise in trying to\nutilize simple TBL methods to arrive at reliable estimates of the underlying\nmanifold.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:59:27 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Ramachandra", "Bharathkumar", ""], ["Dutton", "Benjamin", ""], ["Vatsavai", "Ranga Raju", ""]]}, {"id": "1906.07663", "submitter": "Tamas Madarasz", "authors": "Tamas J. Madarasz", "title": "Better transfer learning with inferred successor maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals show remarkable flexibility in adjusting their behaviour\nwhen their goals, or rewards in the environment change. While such flexibility\nis a hallmark of intelligent behaviour, these multi-task scenarios remain an\nimportant challenge for machine learning algorithms and neurobiological models\nalike. We investigated two approaches that could enable this flexibility:\nfactorized representations, which abstract away general aspects of a task from\nthose prone to change, and nonparametric, memory-based approaches, which can\nprovide a principled way of using similarity to past experiences to guide\ncurrent behaviour. In particular, we combine the successor representation (SR)\nthat factors the value of actions into expected outcomes and corresponding\nrewards with evaluating task similarity through clustering the space of reward\nfunctions. The proposed algorithm inverts a generative model over tasks, and\ndynamically samples from a flexible number of distinct SR maps while\naccumulating evidence about the current task context through amortized\ninference. It improves SR's transfer capabilities and outperforms competing\nalgorithms and baselines in settings with both known and unsignalled rewards\nchanges. Further, as a neurobiological model of spatial coding in the\nhippocampus, it explains important signatures of this representation, such as\nthe \"flickering\" behaviour of hippocampal maps, and trajectory-dependent place\ncells (so-called splitter cells) and their dynamics. We thus provide a novel\nalgorithmic approach for multi-task learning, as well as a common normative\nframework that links together these different characteristics of the brain's\nspatial representation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 16:03:25 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 17:11:46 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 15:45:21 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 16:31:08 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 15:27:22 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Madarasz", "Tamas J.", ""]]}, {"id": "1906.07670", "submitter": "Vittorio Erba", "authors": "Vittorio Erba, Marco Gherardi, Pietro Rotondo", "title": "Intrinsic dimension estimation for locally undersampled data", "comments": null, "journal-ref": "Scientific Reports volume 9, Article number: 17133 (2019)", "doi": "10.1038/s41598-019-53549-9", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data are ubiquitous in contemporary science and finding\nmethods to compress them is one of the primary goals of machine learning. Given\na dataset lying in a high-dimensional space (in principle hundreds to several\nthousands of dimensions), it is often useful to project it onto a\nlower-dimensional manifold, without loss of information. Identifying the\nminimal dimension of such manifold is a challenging problem known in the\nliterature as intrinsic dimension estimation (IDE). Traditionally, most IDE\nalgorithms are either based on multiscale principal component analysis (PCA) or\non the notion of correlation dimension (and more in general on\nk-nearest-neighbors distances). These methods are affected, in different ways,\nby a severe curse of dimensionality. In particular, none of the existing\nalgorithms can provide accurate ID estimates in the extreme locally\nundersampled regime, i.e. in the limit where the number of samples in any local\npatch of the manifold is less than (or of the same order of) the ID of the\ndataset. Here we introduce a new ID estimator that leverages on simple\nproperties of the tangent space of a manifold to overcome these shortcomings.\nThe method is based on the full correlation integral, going beyond the limit of\nsmall radius used for the estimation of the correlation dimension. Our\nestimator alleviates the extreme undersampling problem, intractable with other\nmethods. Based on this insight, we explore a multiscale generalization of the\nalgorithm. We show that it is capable of (i) identifying multiple\ndimensionalities in a dataset, and (ii) providing accurate estimates of the ID\nof extremely curved manifolds. In particular, we test the method on manifolds\ngenerated from global transformations of high-contrast images, relevant for\ninvariant object recognition and considered a challenge for state-of-the-art ID\nestimators.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 16:15:16 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 15:47:22 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Erba", "Vittorio", ""], ["Gherardi", "Marco", ""], ["Rotondo", "Pietro", ""]]}, {"id": "1906.07690", "submitter": "S\\'ebastien Lugan PhD", "authors": "Sebastien Lugan, Paul Desbordes, Luis Xavier Ramos Tormo, Axel Legay\n  and Benoit Macq", "title": "Secure Architectures Implementing Trusted Coalitions for Blockchained\n  Distributed Learning (TCLearn)", "comments": null, "journal-ref": "IEEE Access, vol. 7, pp. 181789-181799, 2019", "doi": "10.1109/ACCESS.2019.2959220", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning across a coalition of organizations allows the members\nof the coalition to train and share a model without sharing the data used to\noptimize this model. In this paper, we propose new secure architectures that\nguarantee preservation of data privacy, trustworthy sequence of iterative\nlearning and equitable sharing of the learned model among each member of the\ncoalition by using adequate encryption and blockchain mechanisms. We exemplify\nits deployment in the case of the distributed optimization of a deep learning\nconvolutional neural network trained on medical images.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 17:03:28 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lugan", "Sebastien", ""], ["Desbordes", "Paul", ""], ["Tormo", "Luis Xavier Ramos", ""], ["Legay", "Axel", ""], ["Macq", "Benoit", ""]]}, {"id": "1906.07697", "submitter": "Jonathan Gordon", "authors": "James Requeima, Jonathan Gordon, John Bronskill, Sebastian Nowozin,\n  Richard E. Turner", "title": "Fast and Flexible Multi-Task Classification Using Conditional Neural\n  Adaptive Processes", "comments": "Published in NeurIPS 2019", "journal-ref": "Advances in Neural Information Processing Systems 32 (2019)\n  7957-7968", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to design image classification systems that, after\nan initial multi-task training phase, can automatically adapt to new tasks\nencountered at test time. We introduce a conditional neural process based\napproach to the multi-task classification setting for this purpose, and\nestablish connections to the meta-learning and few-shot learning literature.\nThe resulting approach, called CNAPs, comprises a classifier whose parameters\nare modulated by an adaptation network that takes the current task's dataset as\ninput. We demonstrate that CNAPs achieves state-of-the-art results on the\nchallenging Meta-Dataset benchmark indicating high-quality transfer-learning.\nWe show that the approach is robust, avoiding both over-fitting in low-shot\nregimes and under-fitting in high-shot regimes. Timing experiments reveal that\nCNAPs is computationally efficient at test-time as it does not involve gradient\nbased adaptation. Finally, we show that trained models are immediately\ndeployable to continual learning and active learning where they can outperform\nexisting approaches that do not leverage transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 17:16:49 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 13:41:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Requeima", "James", ""], ["Gordon", "Jonathan", ""], ["Bronskill", "John", ""], ["Nowozin", "Sebastian", ""], ["Turner", "Richard E.", ""]]}, {"id": "1906.07709", "submitter": "Matus Telgarsky", "authors": "Bolton Bailey, Ziwei Ji, Matus Telgarsky, Ruicheng Xian", "title": "Approximation power of random neural networks", "comments": "This submission constitutes a poor approach to the problem, and has\n  no scientific purpose. A superior (different) approach (and stronger final\n  result, also treating the NTK) has appeared in arXiv:1910.06956 ; please see\n  that work instead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the approximation power of three types of random\nneural networks: (a) infinite width networks, with weights following an\narbitrary distribution; (b) finite width networks obtained by subsampling the\npreceding infinite width networks; (c) finite width networks obtained by\nstarting with standard Gaussian initialization, and then adding a vanishingly\nsmall correction to the weights. The primary result is a fully quantified bound\non the rate of approximation of general general continuous functions: in all\nthree cases, a function $f$ can be approximated with complexity $\\|f\\|_1\n(d/\\delta)^{\\mathcal{O}(d)}$, where $\\delta$ depends on continuity properties\nof $f$ and the complexity measure depends on the weight magnitudes and/or\ncardinalities. Along the way, a variety of ancillary results are developed: an\nexact construction of Gaussian densities with infinite width networks, an\nelementary stand-alone proof scheme for approximation via convolutions of\nradial basis functions, subsampling rates for infinite width networks, and\ndepth separation for corrected networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 17:46:12 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 03:19:11 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Bailey", "Bolton", ""], ["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""], ["Xian", "Ruicheng", ""]]}, {"id": "1906.07745", "submitter": "Masoumeh Shafieinejad", "authors": "Masoumeh Shafieinejad, Jiaqi Wang, Nils Lukas, Xinda Li, Florian\n  Kerschbaum", "title": "On the Robustness of the Backdoor-based Watermarking in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining the state of the art performance of deep learning models imposes a\nhigh cost to model generators, due to the tedious data preparation and the\nsubstantial processing requirements. To protect the model from unauthorized\nre-distribution, watermarking approaches have been introduced in the past\ncouple of years. We investigate the robustness and reliability of\nstate-of-the-art deep neural network watermarking schemes. We focus on\nbackdoor-based watermarking and propose two -- a black-box and a white-box --\nattacks that remove the watermark. Our black-box attack steals the model and\nremoves the watermark with minimum requirements; it just relies on public\nunlabeled data and a black-box access to the classification label. It does not\nneed classification confidences or access to the model's sensitive information\nsuch as the training data set, the trigger set or the model parameters. The\nwhite-box attack, proposes an efficient watermark removal when the parameters\nof the marked model are available; our white-box attack does not require access\nto the labeled data or the trigger set and improves the runtime of the\nblack-box attack up to seventeen times. We as well prove the security\ninadequacy of the backdoor-based watermarking in keeping the watermark\nundetectable by proposing an attack that detects whether a model contains a\nwatermark. Our attacks show that a recipient of a marked model can remove a\nbackdoor-based watermark with significantly less effort than training a new\nmodel and some other techniques are needed to protect against re-distribution\nby a motivated attacker.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 18:05:35 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 00:56:00 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shafieinejad", "Masoumeh", ""], ["Wang", "Jiaqi", ""], ["Lukas", "Nils", ""], ["Li", "Xinda", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1906.07748", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Maximilian Stark and Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "Joint Learning of Geometric and Probabilistic Constellation Shaping", "comments": "Accepted for presentation at the IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of constellations largely affects the performance of communication\nsystems. When designing constellations, both the locations and probability of\noccurrence of the points can be optimized. These approaches are referred to as\ngeometric and probabilistic shaping, respectively. Usually, the geometry of the\nconstellation is fixed, e.g., quadrature amplitude modulation (QAM) is used. In\nsuch cases, the achievable information rate can still be improved by\nprobabilistic shaping. In this work, we show how autoencoders can be leveraged\nto perform probabilistic shaping of constellations. We devise an\ninformation-theoretical description of autoencoders, which allows learning of\ncapacity-achieving symbol distributions and constellations. Recently, machine\nlearning techniques to perform geometric shaping were proposed. However,\nprobabilistic shaping is more challenging as it requires the optimization of\ndiscrete distributions. Furthermore, the proposed method enables joint\nprobabilistic and geometric shaping of constellations over any channel model.\nSimulation results show that the learned constellations achieve information\nrates very close to capacity on an additive white Gaussian noise (AWGN) channel\nand outperform existing approaches on both AWGN and fading channels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 18:15:11 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 07:19:18 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 05:54:06 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Stark", "Maximilian", ""], ["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1906.07773", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Bjarne Pfitzner, Matteo Russo, Javier\n  Carnerero-Cano, Emil C. Lupu", "title": "Poisoning Attacks with Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are vulnerable to poisoning attacks: An adversary\ncan inject malicious points in the training dataset to influence the learning\nprocess and degrade the algorithm's performance. Optimal poisoning attacks have\nalready been proposed to evaluate worst-case scenarios, modelling attacks as a\nbi-level optimization problem. Solving these problems is computationally\ndemanding and has limited applicability for some models such as deep networks.\nIn this paper we introduce a novel generative model to craft systematic\npoisoning attacks against machine learning classifiers generating adversarial\ntraining examples, i.e. samples that look like genuine data points but that\ndegrade the classifier's accuracy when used for training. We propose a\nGenerative Adversarial Net with three components: generator, discriminator, and\nthe target classifier. This approach allows us to model naturally the\ndetectability constrains that can be expected in realistic attacks and to\nidentify the regions of the underlying data distribution that can be more\nvulnerable to data poisoning. Our experimental evaluation shows the\neffectiveness of our attack to compromise machine learning classifiers,\nincluding deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 19:14:09 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:23:27 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Pfitzner", "Bjarne", ""], ["Russo", "Matteo", ""], ["Carnerero-Cano", "Javier", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1906.07774", "submitter": "Valentin Thomas", "authors": "Valentin Thomas, Fabian Pedregosa, Bart van Merri\\\"enboer,\n  Pierre-Antoine Mangazol, Yoshua Bengio, Nicolas Le Roux", "title": "On the interplay between noise and curvature and its effect on\n  optimization and generalization", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speed at which one can minimize an expected loss using stochastic methods\ndepends on two properties: the curvature of the loss and the variance of the\ngradients. While most previous works focus on one or the other of these\nproperties, we explore how their interaction affects optimization speed.\nFurther, as the ultimate goal is good generalization performance, we clarify\nhow both curvature and noise are relevant to properly estimate the\ngeneralization gap. Realizing that the limitations of some existing works stems\nfrom a confusion between these matrices, we also clarify the distinction\nbetween the Fisher matrix, the Hessian, and the covariance matrix of the\ngradients.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 19:19:11 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 23:28:33 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Thomas", "Valentin", ""], ["Pedregosa", "Fabian", ""], ["van Merri\u00ebnboer", "Bart", ""], ["Mangazol", "Pierre-Antoine", ""], ["Bengio", "Yoshua", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "1906.07791", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Hengshuai Yao, Amir-massoud Farahmand, Martha White", "title": "Hill Climbing on Value Estimates for Search-control in Dyna", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyna is an architecture for model-based reinforcement learning (RL), where\nsimulated experience from a model is used to update policies or value\nfunctions. A key component of Dyna is search-control, the mechanism to generate\nthe state and action from which the agent queries the model, which remains\nlargely unexplored. In this work, we propose to generate such states by using\nthe trajectory obtained from Hill Climbing (HC) the current estimate of the\nvalue function. This has the effect of propagating value from high-value\nregions and of preemptively updating value estimates of the regions that the\nagent is likely to visit next. We derive a noisy projected natural gradient\nalgorithm for hill climbing, and highlight a connection to Langevin dynamics.\nWe provide an empirical demonstration on four classical domains that our\nalgorithm, HC-Dyna, can obtain significant sample efficiency improvements. We\nstudy the properties of different sampling distributions for search-control,\nand find that there appears to be a benefit specifically from using the samples\ngenerated by climbing on current value estimates from low-value to high-value\nregion.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:24:45 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 04:03:47 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 08:26:53 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Pan", "Yangchen", ""], ["Yao", "Hengshuai", ""], ["Farahmand", "Amir-massoud", ""], ["White", "Martha", ""]]}, {"id": "1906.07800", "submitter": "Tianwei Yu", "authors": "Tianwei Yu", "title": "Autoencoder-based integrative multi-omics data embedding that allows for\n  confounder adjustments", "comments": "20 pages, 5 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the integrative analyses of omics data, it is often of interest to extract\ndata representation from one data type that best reflect its relations with\nanother data type. This task is traditionally fulfilled by linear methods such\nas canonical correlation analysis (CCA) and partial least squares (PLS).\nHowever, information contained in one data type pertaining to the other data\ntype may be complex and in nonlinear form. Deep learning provides a convenient\nalternative to extract low-dimensional nonlinear data embedding. In addition,\nthe deep learning setup can naturally incorporate the effects of clinical\nconfounding factors into the integrative analysis. Here we report a deep\nlearning setup, named Autoencoder-based Integrative Multi-omics data Embedding\n(AIME), to extract data representation for omics data integrative analysis. The\nmethod can adjust for confounder variables, achieve informative data embedding,\nrank features in terms of their contributions, and find pairs of features from\nthe two data types that are related to each other through the data embedding.\nIn simulation studies, the method was highly effective in the extraction of\nmajor contributing features between data types. Using a real microRNA-gene\nexpression dataset, and a real DNA methylation-gene expression dataset, we show\nthat AIME excluded the influence of confounders including batch effects, and\nextracted biologically plausible novel information. The R package based on\nKeras and the TensorFlow backend is available at\nhttps://github.com/tianwei-yu/AIME.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:38:38 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 10:11:14 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Yu", "Tianwei", ""]]}, {"id": "1906.07805", "submitter": "Zhaohan Guo", "authors": "Zhaohan Daniel Guo, Emma Brunskill", "title": "Directed Exploration for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is necessary to achieve good sample efficiency for\nreinforcement learning in general. From small, tabular settings such as\ngridworlds to large, continuous and sparse reward settings such as robotic\nobject manipulation tasks, exploration through adding an uncertainty bonus to\nthe reward function has been shown to be effective when the uncertainty is able\nto accurately drive exploration towards promising states. However reward\nbonuses can still be inefficient since they are non-stationary, which means\nthat we must wait for function approximators to catch up and converge again\nwhen uncertainties change. We propose the idea of directed exploration, that is\nlearning a goal-conditioned policy where goals are simply other states, and\nusing that to directly try to reach states with large uncertainty. The\ngoal-conditioned policy is independent of uncertainty and is thus stationary.\nWe show in our experiments how directed exploration is more efficient at\nexploration and more robust to how the uncertainty is computed than adding\nbonuses to rewards.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:44:07 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Brunskill", "Emma", ""]]}, {"id": "1906.07832", "submitter": "Ayoub Belhadji", "authors": "Ayoub Belhadji, R\\'emi Bardenet, Pierre Chainais", "title": "Kernel quadrature with DPPs", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Dec\n  2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study quadrature rules for functions from an RKHS, using nodes sampled\nfrom a determinantal point process (DPP). DPPs are parametrized by a kernel,\nand we use a truncated and saturated version of the RKHS kernel. This link\nbetween the two kernels, along with DPP machinery, leads to relatively tight\nbounds on the quadrature error, that depends on the spectrum of the RKHS\nkernel. Finally, we experimentally compare DPPs to existing kernel-based\nquadratures such as herding, Bayesian quadrature, or leverage score sampling.\nNumerical results confirm the interest of DPPs, and even suggest faster rates\nthan our bounds in particular cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 22:34:37 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 21:03:22 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 21:38:11 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Belhadji", "Ayoub", ""], ["Bardenet", "R\u00e9mi", ""], ["Chainais", "Pierre", ""]]}, {"id": "1906.07838", "submitter": "Paul Budnarain", "authors": "Paul Budnarain, Renato Ferreira Pinto Junior, Ilan Kogan", "title": "RadGrad: Active learning with loss gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving sequential decision prediction problems, including those in imitation\nlearning settings, requires mitigating the problem of covariate shift. The\nstandard approach, DAgger, relies on capturing expert behaviour in all states\nthat the agent reaches. In real-world settings, querying an expert is costly.\nWe propose a new active learning algorithm that selectively queries the expert,\nbased on both a prediction of agent error and a proxy for agent risk, that\nmaintains the performance of unrestrained expert querying systems while\nsubstantially reducing the number of expert queries made. We show that our\napproach, RadGrad, has the potential to improve upon existing safety-aware\nalgorithms, and matches or exceeds the performance of DAgger and variants\n(i.e., SafeDAgger) in one simulated environment. However, we also find that a\nmore complex environment poses challenges not only to our proposed method, but\nalso to existing safety-aware algorithms, which do not match the performance of\nDAgger in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:02:48 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Budnarain", "Paul", ""], ["Junior", "Renato Ferreira Pinto", ""], ["Kogan", "Ilan", ""]]}, {"id": "1906.07842", "submitter": "Joan Bruna", "authors": "Francis Williams, Matthew Trager, Claudio Silva, Daniele Panozzo,\n  Denis Zorin, Joan Bruna", "title": "Gradient Dynamics of Shallow Univariate ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical and empirical study of the gradient dynamics of\noverparameterized shallow ReLU networks with one-dimensional input, solving\nleast-squares interpolation. We show that the gradient dynamics of such\nnetworks are determined by the gradient flow in a non-redundant\nparameterization of the network function. We examine the principal qualitative\nfeatures of this gradient flow. In particular, we determine conditions for two\nlearning regimes:kernel and adaptive, which depend both on the relative\nmagnitude of initialization of weights in different layers and the asymptotic\nbehavior of initialization coefficients in the limit of large network widths.\nWe show that learning in the kernel regime yields smooth interpolants,\nminimizing curvature, and reduces to cubic splines for uniform initializations.\nLearning in the adaptive regime favors instead linear splines, where knots\ncluster adaptively at the sample points.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:21:56 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Williams", "Francis", ""], ["Trager", "Matthew", ""], ["Silva", "Claudio", ""], ["Panozzo", "Daniele", ""], ["Zorin", "Denis", ""], ["Bruna", "Joan", ""]]}, {"id": "1906.07849", "submitter": "Marius Arvinte", "authors": "Marius Arvinte and Sriram Vishwanath and Ahmed H. Tewfik", "title": "Deep Learning-Based Quantization of L-Values for Gray-Coded Modulation", "comments": "Submitted to IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, a deep learning-based quantization scheme for log-likelihood\nratio (L-value) storage is introduced. We analyze the dependency between the\naverage magnitude of different L-values from the same quadrature amplitude\nmodulation (QAM) symbol and show they follow a consistent ordering. Based on\nthis we design a deep autoencoder that jointly compresses and separately\nreconstructs each L-value, allowing the use of a weighted loss function that\naims to more accurately reconstructs low magnitude inputs. Our method is shown\nto be competitive with state-of-the-art maximum mutual information quantization\nschemes, reducing the required memory footprint by a ratio of up to two and a\nloss of performance smaller than 0.1 dB with less than two effective bits per\nL-value or smaller than 0.04 dB with 2.25 effective bits. We experimentally\nshow that our proposed method is a universal compression scheme in the sense\nthat after training on an LDPC-coded Rayleigh fading scenario we can reuse the\nsame network without further training on other channel models and codes while\npreserving the same performance benefits.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:43:38 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 23:31:07 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Arvinte", "Marius", ""], ["Vishwanath", "Sriram", ""], ["Tewfik", "Ahmed H.", ""]]}, {"id": "1906.07858", "submitter": "Rosin Ngueveu", "authors": "Ulrich A\\\"ivodji, Fran\\c{c}ois Bidet, S\\'ebastien Gambs, Rosin Claude\n  Ngueveu, Alain Tapp", "title": "Adversarial training approach for local data debiasing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of automated decision processes in many areas of our\nsociety raises serious ethical issues concerning the fairness of the process\nand the possible resulting discriminations. In this work, we propose a novel\napproach called GANsan whose objective is to prevent the possibility of any\ndiscrimination i.e., direct and indirect) based on a sensitive attribute by\nremoving the attribute itself as well as the existing correlations with the\nremaining attributes. Our sanitization algorithm GANsan is partially inspired\nby the powerful framework of generative adversarial networks (in particular the\nCycle-GANs), which offers a flexible way to learn a distribution empirically or\nto translate between two different distributions.\n  In contrast to prior work, one of the strengths of our approach is that the\nsanitization is performed in the same space as the original data by only\nmodifying the other attributes as little as possible and thus preserving the\ninterpretability of the sanitized data. As a consequence, once the sanitizer is\ntrained, it can be applied to new data, such as for instance, locally by an\nindividual on his profile before releasing it. Finally, experiments on a real\ndataset demonstrate the effectiveness of the proposed approach as well as the\nachievable trade-off between fairness and utility.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:20:58 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 20:29:19 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 17:54:53 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Bidet", "Fran\u00e7ois", ""], ["Gambs", "S\u00e9bastien", ""], ["Ngueveu", "Rosin Claude", ""], ["Tapp", "Alain", ""]]}, {"id": "1906.07859", "submitter": "Nishant Yadav", "authors": "Nishant Yadav, Ari Kobren, Nicholas Monath, Andrew McCallum", "title": "Supervised Hierarchical Clustering with Exponential Linkage", "comments": "Appears in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised clustering, standard techniques for learning a pairwise\ndissimilarity function often suffer from a discrepancy between the training and\nclustering objectives, leading to poor cluster quality. Rectifying this\ndiscrepancy necessitates matching the procedure for training the dissimilarity\nfunction to the clustering algorithm. In this paper, we introduce a method for\ntraining the dissimilarity function in a way that is tightly coupled with\nhierarchical clustering, in particular single linkage. However, the appropriate\nclustering algorithm for a given dataset is often unknown. Thus we introduce an\napproach to supervised hierarchical clustering that smoothly interpolates\nbetween single, average, and complete linkage, and we give a training procedure\nthat simultaneously learns a linkage function and a dissimilarity function. We\naccomplish this with a novel Exponential Linkage function that has a learnable\nparameter that controls the interpolation. In experiments on four datasets, our\njoint training procedure consistently matches or outperforms the next best\ntraining procedure/linkage function pair and gives up to 8 points improvement\nin dendrogram purity over discrepant pairs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:27:50 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Yadav", "Nishant", ""], ["Kobren", "Ari", ""], ["Monath", "Nicholas", ""], ["McCallum", "Andrew", ""]]}, {"id": "1906.07860", "submitter": "Lei Lei", "authors": "Lei Lei, Huijuan Xu, Xiong Xiong, Kan Zheng, Wei Xiang, and Xianbin\n  Wang", "title": "Multi-user Resource Control with Deep Reinforcement Learning in IoT Edge\n  Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By leveraging the concept of mobile edge computing (MEC), massive amount of\ndata generated by a large number of Internet of Things (IoT) devices could be\noffloaded to MEC server at the edge of wireless network for further\ncomputational intensive processing. However, due to the resource constraint of\nIoT devices and wireless network, both the communications and computation\nresources need to be allocated and scheduled efficiently for better system\nperformance. In this paper, we propose a joint computation offloading and\nmulti-user scheduling algorithm for IoT edge computing system to minimize the\nlong-term average weighted sum of delay and power consumption under stochastic\ntraffic arrival. We formulate the dynamic optimization problem as an\ninfinite-horizon average-reward continuous-time Markov decision process (CTMDP)\nmodel. One critical challenge in solving this MDP problem for the multi-user\nresource control is the curse-of-dimensionality problem, where the state space\nof the MDP model and the computation complexity increase exponentially with the\ngrowing number of users or IoT devices. In order to overcome this challenge, we\nuse the deep reinforcement learning (RL) techniques and propose a neural\nnetwork architecture to approximate the value functions for the post-decision\nsystem states. The designed algorithm to solve the CTMDP problem supports\nsemi-distributed auction-based implementation, where the IoT devices submit\nbids to the BS to make the resource control decisions centrally. Simulation\nresults show that the proposed algorithm provides significant performance\nimprovement over the baseline algorithms, and also outperforms the RL\nalgorithms based on other neural network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:29:06 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Lei", "Lei", ""], ["Xu", "Huijuan", ""], ["Xiong", "Xiong", ""], ["Zheng", "Kan", ""], ["Xiang", "Wei", ""], ["Wang", "Xianbin", ""]]}, {"id": "1906.07865", "submitter": "Cameron Linke", "authors": "Cam Linke, Nadia M. Ady, Martha White, Thomas Degris, Adam White", "title": "Adapting Behaviour via Intrinsic Reward: A Survey and Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning about many things can provide numerous benefits to a reinforcement\nlearning system. For example, learning many auxiliary value functions, in\naddition to optimizing the environmental reward, appears to improve both\nexploration and representation learning. The question we tackle in this paper\nis how to sculpt the stream of experience---how to adapt the learning system's\nbehavior---to optimize the learning of a collection of value functions. A\nsimple answer is to compute an intrinsic reward based on the statistics of each\nauxiliary learner, and use reinforcement learning to maximize that intrinsic\nreward. Unfortunately, implementing this simple idea has proven difficult, and\nthus has been the focus of decades of study. It remains unclear which of the\nmany possible measures of learning would work well in a parallel learning\nsetting where environmental reward is extremely sparse or absent. In this\npaper, we investigate and compare different intrinsic reward mechanisms in a\nnew bandit-like parallel-learning testbed. We discuss the interaction between\nreward and prediction learners and highlight the importance of introspective\nprediction learners: those that increase their rate of learning when progress\nis possible, and decrease when it is not. We provide a comprehensive empirical\ncomparison of 14 different rewards, including well-known ideas from\nreinforcement learning and active learning. Our results highlight a simple but\nseemingly powerful principle: intrinsic rewards based on the amount of learning\ncan generate useful behavior, if each individual learner is introspective.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:07:12 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 23:39:27 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 15:59:09 GMT"}, {"version": "v4", "created": "Sat, 22 Aug 2020 03:33:39 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Linke", "Cam", ""], ["Ady", "Nadia M.", ""], ["White", "Martha", ""], ["Degris", "Thomas", ""], ["White", "Adam", ""]]}, {"id": "1906.07867", "submitter": "Alejandro Carderera", "authors": "Jelena Diakonikolas, Alejandro Carderera, Sebastian Pokutta", "title": "Locally Accelerated Conditional Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional gradients constitute a class of projection-free first-order\nalgorithms for smooth convex optimization. As such, they are frequently used in\nsolving smooth convex optimization problems over polytopes, for which the\ncomputational cost of orthogonal projections would be prohibitive. However,\nthey do not enjoy the optimal convergence rates achieved by projection-based\naccelerated methods; moreover, achieving such globally-accelerated rates is\ninformation-theoretically impossible for these methods. To address this issue,\nwe present Locally Accelerated Conditional Gradients -- an algorithmic\nframework that couples accelerated steps with conditional gradient steps to\nachieve local acceleration on smooth strongly convex problems. Our approach\ndoes not require projections onto the feasible set, but only on (typically\nlow-dimensional) simplices, thus keeping the computational cost of projections\nat bay. Further, it achieves the optimal accelerated local convergence. Our\ntheoretical results are supported by numerical experiments, which demonstrate\nsignificant speedups of our framework over state of the art methods in both\nper-iteration progress and wall-clock time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:23:03 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 14:41:24 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Carderera", "Alejandro", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1906.07868", "submitter": "Xuechen Li", "authors": "Xuechen Li, Denny Wu, Lester Mackey, Murat A. Erdogdu", "title": "Stochastic Runge-Kutta Accelerates Langevin Monte Carlo and Beyond", "comments": "56 pages; update acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling with Markov chain Monte Carlo methods often amounts to discretizing\nsome continuous-time dynamics with numerical integration. In this paper, we\nestablish the convergence rate of sampling algorithms obtained by discretizing\nsmooth It\\^o diffusions exhibiting fast Wasserstein-$2$ contraction, based on\nlocal deviation properties of the integration scheme. In particular, we study a\nsampling algorithm constructed by discretizing the overdamped Langevin\ndiffusion with the method of stochastic Runge-Kutta. For strongly convex\npotentials that are smooth up to a certain order, its iterates converge to the\ntarget distribution in $2$-Wasserstein distance in\n$\\tilde{\\mathcal{O}}(d\\epsilon^{-2/3})$ iterations. This improves upon the\nbest-known rate for strongly log-concave sampling based on the overdamped\nLangevin equation using only the gradient oracle without adjustment. In\naddition, we extend our analysis of stochastic Runge-Kutta methods to uniformly\ndissipative diffusions with possibly non-convex potentials and show they\nachieve better rates compared to the Euler-Maruyama scheme in terms of the\ndependence on tolerance $\\epsilon$. Numerical studies show that these\nalgorithms lead to better stability and lower asymptotic errors.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:24:59 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 19:54:02 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 23:57:24 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Xuechen", ""], ["Wu", "Denny", ""], ["Mackey", "Lester", ""], ["Erdogdu", "Murat A.", ""]]}, {"id": "1906.07869", "submitter": "Yuqi Gu", "authors": "Yuqi Gu and Gongjun Xu", "title": "Identifiability of Hierarchical Latent Attribute Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Latent Attribute Models (HLAMs) are a family of discrete latent\nvariable models that are attracting increasing attention in educational,\npsychological, and behavioral sciences. The key ingredients of an HLAM include\na binary structural matrix and a directed acyclic graph specifying hierarchical\nconstraints on the configurations of latent attributes. These components encode\npractitioners' design information and carry important scientific meanings.\nDespite the popularity of HLAMs, the fundamental identifiability issue remains\nunaddressed. The existence of the attribute hierarchy graph leads to degenerate\nparameter space, and the potentially unknown structural matrix further\ncomplicates the identifiability problem. This paper addresses this issue of\nidentifying the latent structure and model parameters underlying an HLAM. We\ndevelop sufficient and necessary identifiability conditions. These results\ndirectly and sharply characterize the different impacts on identifiability cast\nby different attribute types in the graph. The proposed conditions not only\nprovide insights into diagnostic test designs under the attribute hierarchy,\nbut also serve as tools to assess the validity of an estimated HLAM.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:27:10 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 22:50:23 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 21:46:24 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Gu", "Yuqi", ""], ["Xu", "Gongjun", ""]]}, {"id": "1906.07875", "submitter": "Qing Yang", "authors": "Qing Yang, Wei Wen, Zuoguan Wang, Hai Li", "title": "Joint Regularization on Activations and Weights for Efficient Neural\n  Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid scaling up of deep neural networks (DNNs), extensive research\nstudies on network model compression such as weight pruning have been performed\nfor improving deployment efficiency. This work aims to advance the compression\nbeyond the weights to neuron activations. We propose the joint regularization\ntechnique which simultaneously regulates the distribution of weights and\nactivations. By distinguishing and leveraging the significance difference among\nneuron responses and connections during learning, the jointly pruned network,\nnamely \\textit{JPnet}, optimizes the sparsity of activations and weights for\nimproving execution efficiency. The derived deep sparsification of JPnet\nreveals more optimization space for the existing DNN accelerators dedicated for\nsparse matrix operations. We thoroughly evaluate the effectiveness of joint\nregularization through various network models with different activation\nfunctions and on different datasets. With $0.4\\%$ degradation constraint on\ninference accuracy, a JPnet can save $72.3\\% \\sim 98.8\\%$ of computation cost\ncompared to the original dense models, with up to $5.2\\times$ and $12.3\\times$\nreductions in activation and weight numbers, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:45:42 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 03:48:06 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Yang", "Qing", ""], ["Wen", "Wei", ""], ["Wang", "Zuoguan", ""], ["Li", "Hai", ""]]}, {"id": "1906.07882", "submitter": "Zhiqiang Tan", "authors": "Xinwei Zhang, Zhiqiang Tan", "title": "Semi-supervised Logistic Learning Based on Exponential Tilt Mixture\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider semi-supervised learning for classification, where both labeled and\nunlabeled data are available for training. The goal is to exploit both datasets\nto achieve higher prediction accuracy than just using labeled data alone. We\ndevelop a semi-supervised logistic learning method based on exponential tilt\nmixture models, by extending a statistical equivalence between logistic\nregression and exponential tilt modeling. We study maximum nonparametric\nlikelihood estimation and derive novel objective functions which are shown to\nbe Fisher consistent. We also propose regularized estimation and construct\nsimple and highly interpretable EM algorithms. Finally, we present numerical\nresults which demonstrate the advantage of the proposed methods compared with\nexisting methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 02:30:25 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Zhang", "Xinwei", ""], ["Tan", "Zhiqiang", ""]]}, {"id": "1906.07902", "submitter": "Han Zhao", "authors": "Han Zhao, Jianfeng Chi, Yuan Tian, Geoffrey J. Gordon", "title": "Trade-offs and Guarantees of Adversarial Representation Learning for\n  Information Obfuscation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourced data used in machine learning services might carry sensitive\ninformation about attributes that users do not want to share. Various methods\nhave been proposed to minimize the potential information leakage of sensitive\nattributes while maximizing the task accuracy. However, little is known about\nthe theory behind these methods. In light of this gap, we develop a novel\ntheoretical framework for attribute obfuscation. Under our framework, we\npropose a minimax optimization formulation to protect the given attribute and\nanalyze its inference guarantees against worst-case adversaries. Meanwhile, it\nis clear that in general there is a tension between minimizing information\nleakage and maximizing task accuracy. To understand this, we prove an\ninformation-theoretic lower bound to precisely characterize the fundamental\ntrade-off between accuracy and information leakage. We conduct experiments on\ntwo real-world datasets to corroborate the inference guarantees and validate\nthis trade-off. Our results indicate that, among several alternatives, the\nadversarial learning approach achieves the best trade-off in terms of attribute\nobfuscation and accuracy maximization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 04:00:38 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 05:08:11 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 05:23:04 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhao", "Han", ""], ["Chi", "Jianfeng", ""], ["Tian", "Yuan", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1906.07906", "submitter": "Brian de Silva", "authors": "Brian M. de Silva (1), David M. Higdon (2), Steven L. Brunton (3), J.\n  Nathan Kutz (1) ((1) University of Washington Applied Mathematics, (2)\n  Virginia Polytechnic Institute and State University Statistics, (3)\n  University of Washington Mechanical Engineering)", "title": "Discovery of Physics from Data: Universal Laws and Discrepancies", "comments": null, "journal-ref": null, "doi": "10.3389/frai.2020.00025", "report-no": null, "categories": "cs.LG physics.class-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) and artificial intelligence (AI) algorithms are now\nbeing used to automate the discovery of physics principles and governing\nequations from measurement data alone. However, positing a universal physical\nlaw from data is challenging without simultaneously proposing an accompanying\ndiscrepancy model to account for the inevitable mismatch between theory and\nmeasurements. By revisiting the classic problem of modeling falling objects of\ndifferent size and mass, we highlight a number of nuanced issues that must be\naddressed by modern data-driven methods for automated physics discovery.\nSpecifically, we show that measurement noise and complex secondary physical\nmechanisms, like unsteady fluid drag forces, can obscure the underlying law of\ngravitation, leading to an erroneous model. We use the sparse identification of\nnonlinear dynamics (SINDy) method to identify governing equations for\nreal-world measurement data and simulated trajectories. Incorporating into\nSINDy the assumption that each falling object is governed by a similar physical\nlaw is shown to improve the robustness of the learned models, but discrepancies\nbetween the predictions and observations persist due to subtleties in drag\ndynamics. This work highlights the fact that the naive application of ML/AI\nwill generally be insufficient to infer universal physical laws without further\nmodification.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 04:09:20 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 18:21:32 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 19:56:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["de Silva", "Brian M.", ""], ["Higdon", "David M.", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1906.07916", "submitter": "Ruiqi Gao", "authors": "Ruiqi Gao, Tianle Cai, Haochuan Li, Liwei Wang, Cho-Jui Hsieh, Jason\n  D. Lee", "title": "Convergence of Adversarial Training in Overparametrized Neural Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial examples, i.e. inputs that are\nimperceptibly perturbed from natural data and yet incorrectly classified by the\nnetwork. Adversarial training, a heuristic form of robust optimization that\nalternates between minimization and maximization steps, has proven to be among\nthe most successful methods to train networks to be robust against a\npre-defined family of perturbations. This paper provides a partial answer to\nthe success of adversarial training, by showing that it converges to a network\nwhere the surrogate loss with respect to the the attack algorithm is within\n$\\epsilon$ of the optimal robust loss. Then we show that the optimal robust\nloss is also close to zero, hence adversarial training finds a robust\nclassifier. The analysis technique leverages recent work on the analysis of\nneural networks via Neural Tangent Kernel (NTK), combined with motivation from\nonline-learning when the maximization is solved by a heuristic, and the\nexpressiveness of the NTK kernel in the $\\ell_\\infty$-norm. In addition, we\nalso prove that robust interpolation requires more model capacity, supporting\nthe evidence that adversarial training requires wider networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 04:53:25 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 17:35:57 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gao", "Ruiqi", ""], ["Cai", "Tianle", ""], ["Li", "Haochuan", ""], ["Wang", "Liwei", ""], ["Hsieh", "Cho-Jui", ""], ["Lee", "Jason D.", ""]]}, {"id": "1906.07920", "submitter": "Hanbin Hu", "authors": "Hanbin Hu and Mit Shah and Jianhua Z. Huang and Peng Li", "title": "Global Adversarial Attacks for Assessing Deep Learning Robustness", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that deep neural networks (DNNs) may be vulnerable to\nadversarial attacks, raising the concern on their robustness particularly for\nsafety-critical applications. Recognizing the local nature and limitations of\nexisting adversarial attacks, we present a new type of global adversarial\nattacks for assessing global DNN robustness. More specifically, we propose a\nnovel concept of global adversarial example pairs in which each pair of two\nexamples are close to each other but have different class labels predicted by\nthe DNN. We further propose two families of global attack methods and show that\nour methods are able to generate diverse and intriguing adversarial example\npairs at locations far from the training or testing data. Moreover, we\ndemonstrate that DNNs hardened using the strong projected gradient descent\n(PGD) based (local) adversarial training are vulnerable to the proposed global\nadversarial example pairs, suggesting that global robustness must be considered\nwhile training robust deep learning networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 05:16:57 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Hu", "Hanbin", ""], ["Shah", "Mit", ""], ["Huang", "Jianhua Z.", ""], ["Li", "Peng", ""]]}, {"id": "1906.07975", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Kenneth Wang, Nima Anari, Dorsa Sadigh", "title": "Batch Active Learning Using Determinantal Point Processes", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection and labeling is one of the main challenges in employing\nmachine learning algorithms in a variety of real-world applications with\nlimited data. While active learning methods attempt to tackle this issue by\nlabeling only the data samples that give high information, they generally\nsuffer from large computational costs and are impractical in settings where\ndata can be collected in parallel. Batch active learning methods attempt to\novercome this computational burden by querying batches of samples at a time. To\navoid redundancy between samples, previous works rely on some ad hoc\ncombination of sample quality and diversity. In this paper, we present a new\nprincipled batch active learning method using Determinantal Point Processes, a\nrepulsive point process that enables generating diverse batches of samples. We\ndevelop tractable algorithms to approximate the mode of a DPP distribution, and\nprovide theoretical guarantees on the degree of approximation. We further\ndemonstrate that an iterative greedy method for DPP maximization, which has\nlower computational costs but worse theoretical guarantees, still gives\ncompetitive results for batch active learning. Our experiments show the value\nof our methods on several datasets against state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 08:45:59 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Wang", "Kenneth", ""], ["Anari", "Nima", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1906.07982", "submitter": "Rafa\\\"el Pinot", "authors": "Rafael Pinot and Florian Yger and C\\'edric Gouy-Pailler and Jamal Atif", "title": "A unified view on differential privacy and robustness to adversarial\n  examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note highlights some links between two lines of research within\nthe emerging topic of trustworthy machine learning: differential privacy and\nrobustness to adversarial examples. By abstracting the definitions of both\nnotions, we show that they build upon the same theoretical ground and hence\nresults obtained so far in one domain can be transferred to the other. More\nprecisely, our analysis is based on two key elements: probabilistic mappings\n(also called randomized algorithms in the differential privacy community), and\nthe Renyi divergence which subsumes a large family of divergences. We first\ngeneralize the definition of robustness against adversarial examples to\nencompass probabilistic mappings. Then we observe that Renyi-differential\nprivacy (a generalization of differential privacy recently proposed\nin~\\cite{Mironov2017RenyiDP}) and our definition of robustness share several\nsimilarities. We finally discuss how can both communities benefit from this\nconnection to transfer technical tools from one research field to the other.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:12:31 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Pinot", "Rafael", ""], ["Yger", "Florian", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Atif", "Jamal", ""]]}, {"id": "1906.07983", "submitter": "Pan Kessel", "authors": "Ann-Kathrin Dombrowski, Maximilian Alber, Christopher J. Anders,\n  Marcel Ackermann, Klaus-Robert M\\\"uller, Pan Kessel", "title": "Explanations can be manipulated and geometry is to blame", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanation methods aim to make neural networks more trustworthy and\ninterpretable. In this paper, we demonstrate a property of explanation methods\nwhich is disconcerting for both of these purposes. Namely, we show that\nexplanations can be manipulated arbitrarily by applying visually hardly\nperceptible perturbations to the input that keep the network's output\napproximately constant. We establish theoretically that this phenomenon can be\nrelated to certain geometrical properties of neural networks. This allows us to\nderive an upper bound on the susceptibility of explanations to manipulations.\nBased on this result, we propose effective mechanisms to enhance the robustness\nof explanations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:13:23 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:12:12 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Dombrowski", "Ann-Kathrin", ""], ["Alber", "Maximilian", ""], ["Anders", "Christopher J.", ""], ["Ackermann", "Marcel", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Kessel", "Pan", ""]]}, {"id": "1906.07987", "submitter": "Hugo Penedones", "authors": "Hugo Penedones, Carlos Riquelme, Damien Vincent, Hartmut Maennel,\n  Timothy Mann, Andre Barreto, Sylvain Gelly, Gergely Neu", "title": "Adaptive Temporal-Difference Learning for Policy Evaluation with\n  Per-State Uncertainty Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the core reinforcement-learning problem of on-policy value\nfunction approximation from a batch of trajectory data, and focus on various\nissues of Temporal Difference (TD) learning and Monte Carlo (MC) policy\nevaluation. The two methods are known to achieve complementary bias-variance\ntrade-off properties, with TD tending to achieve lower variance but potentially\nhigher bias. In this paper, we argue that the larger bias of TD can be a result\nof the amplification of local approximation errors. We address this by\nproposing an algorithm that adaptively switches between TD and MC in each\nstate, thus mitigating the propagation of errors. Our method is based on\nlearned confidence intervals that detect biases of TD estimates. We demonstrate\nin a variety of policy evaluation tasks that this simple adaptive algorithm\nperforms competitively with the best approach in hindsight, suggesting that\nlearned confidence intervals are a powerful technique for adapting policy\nevaluation to use TD or MC returns in a data-driven way.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:22:22 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Penedones", "Hugo", ""], ["Riquelme", "Carlos", ""], ["Vincent", "Damien", ""], ["Maennel", "Hartmut", ""], ["Mann", "Timothy", ""], ["Barreto", "Andre", ""], ["Gelly", "Sylvain", ""], ["Neu", "Gergely", ""]]}, {"id": "1906.08018", "submitter": "JInglai Li", "authors": "Xin Cai, Guang Lin, Jinglai Li", "title": "Bayesian inverse regression for dimension reduction with small datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider supervised dimension reduction problems, namely to identify a low\ndimensional projection of the predictors $\\-x$ which can retain the statistical\nrelationship between $\\-x$ and the response variable $y$. We follow the idea of\nthe sliced inverse regression (SIR) and the sliced average variance estimation\n(SAVE) type of methods, which is to use the statistical information of the\nconditional distribution $\\pi(\\-x|y)$ to identify the dimension reduction (DR)\nspace. In particular we focus on the task of computing this conditional\ndistribution without slicing the data. We propose a Bayesian framework to\ncompute the conditional distribution where the likelihood function is obtained\nusing the Gaussian process regression model. The conditional distribution\n$\\pi(\\-x|y)$ can then be computed directly via Monte Carlo sampling. We then\ncan perform DR by considering certain moment functions (e.g. the first or the\nsecond moment) of the samples of the posterior distribution. With numerical\nexamples, we demonstrate that the proposed method is especially effective for\nsmall data problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 10:49:56 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 20:50:25 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 20:20:16 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Cai", "Xin", ""], ["Lin", "Guang", ""], ["Li", "Jinglai", ""]]}, {"id": "1906.08031", "submitter": "Niv Nayman", "authors": "Niv Nayman, Asaf Noy, Tal Ridnik, Itamar Friedman, Rong Jin, Lihi\n  Zelnik-Manor", "title": "XNAS: Neural Architecture Search with Expert Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel optimization method for differential neural\narchitecture search, based on the theory of prediction with expert advice. Its\noptimization criterion is well fitted for an architecture-selection, i.e., it\nminimizes the regret incurred by a sub-optimal selection of operations. Unlike\nprevious search relaxations, that require hard pruning of architectures, our\nmethod is designed to dynamically wipe out inferior architectures and enhance\nsuperior ones. It achieves an optimal worst-case regret bound and suggests the\nuse of multiple learning-rates, based on the amount of information carried by\nthe backward gradients. Experiments show that our algorithm achieves a strong\nperformance over several image classification datasets. Specifically, it\nobtains an error rate of 1.6% for CIFAR-10, 24% for ImageNet under mobile\nsettings, and achieves state-of-the-art results on three additional datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 12:00:00 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Nayman", "Niv", ""], ["Noy", "Asaf", ""], ["Ridnik", "Tal", ""], ["Friedman", "Itamar", ""], ["Jin", "Rong", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "1906.08034", "submitter": "Mario Geiger", "authors": "Mario Geiger, Stefano Spigler, Arthur Jacot and Matthieu Wyart", "title": "Disentangling feature and lazy training in deep neural networks", "comments": "minor revisions", "journal-ref": null, "doi": "10.1088/1742-5468/abc4de", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two distinct limits for deep learning have been derived as the network width\n$h\\rightarrow \\infty$, depending on how the weights of the last layer scale\nwith $h$. In the Neural Tangent Kernel (NTK) limit, the dynamics becomes linear\nin the weights and is described by a frozen kernel $\\Theta$. By contrast, in\nthe Mean-Field limit, the dynamics can be expressed in terms of the\ndistribution of the parameters associated with a neuron, that follows a partial\ndifferential equation. In this work we consider deep networks where the weights\nin the last layer scale as $\\alpha h^{-1/2}$ at initialization. By varying\n$\\alpha$ and $h$, we probe the crossover between the two limits. We observe the\npreviously identified regimes of lazy training and feature training. In the\nlazy-training regime, the dynamics is almost linear and the NTK barely changes\nafter initialization. The feature-training regime includes the mean-field\nformulation as a limiting case and is characterized by a kernel that evolves in\ntime, and learns some features. We perform numerical experiments on MNIST,\nFashion-MNIST, EMNIST and CIFAR10 and consider various architectures. We find\nthat (i) The two regimes are separated by an $\\alpha^*$ that scales as\n$h^{-1/2}$. (ii) Network architecture and data structure play an important role\nin determining which regime is better: in our tests, fully-connected networks\nperform generally better in the lazy-training regime, unlike convolutional\nnetworks. (iii) In both regimes, the fluctuations $\\delta F$ induced on the\nlearned function by initial conditions decay as $\\delta F\\sim 1/\\sqrt{h}$,\nleading to a performance that increases with $h$. The same improvement can also\nbe obtained at an intermediate width by ensemble-averaging several networks.\n(iv) In the feature-training regime we identify a time scale\n$t_1\\sim\\sqrt{h}\\alpha$, such that for $t\\ll t_1$ the dynamics is linear.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 12:08:13 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 14:25:37 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 10:05:27 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 19:22:13 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Geiger", "Mario", ""], ["Spigler", "Stefano", ""], ["Jacot", "Arthur", ""], ["Wyart", "Matthieu", ""]]}, {"id": "1906.08039", "submitter": "Chao Ma", "authors": "Weinan E, Chao Ma, Lei Wu", "title": "The Barron Space and the Flow-induced Function Spaces for Neural Network\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key issues in the analysis of machine learning models is to\nidentify the appropriate function space and norm for the model. This is the set\nof functions endowed with a quantity which can control the approximation and\nestimation errors by a particular machine learning model. In this paper, we\naddress this issue for two representative neural network models: the two-layer\nnetworks and the residual neural networks. We define the Barron space and show\nthat it is the right space for two-layer neural network models in the sense\nthat optimal direct and inverse approximation theorems hold for functions in\nthe Barron space. For residual neural network models, we construct the\nso-called flow-induced function space, and prove direct and inverse\napproximation theorems for this space. In addition, we show that the Rademacher\ncomplexity for bounded sets under these norms has the optimal upper bounds.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:07:01 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 22:57:52 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "1906.08044", "submitter": "Yan Han", "authors": "Yan Han, Gautam Krishna, Co Tran, Mason Carnahan, Ahmed H Tewfik", "title": "Robust End-to-End Speaker Verification Using EEG", "comments": "Accepted for EUSIPCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate that performance of a speaker verification\nsystem can be improved by concatenating electroencephalography (EEG) signal\nfeatures with speech signal features or only using EEG signal features. We use\nstate-of-the-art end-to-end deep learning model for performing speaker\nverification and we demonstrate our results for noisy speech. Our results\nindicate that EEG signals can improve the robustness of speaker verification\nsystems, especially in noiser environment.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:11:24 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 22:42:33 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 05:01:58 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 01:48:23 GMT"}, {"version": "v5", "created": "Wed, 10 Jun 2020 00:42:49 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Han", "Yan", ""], ["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1906.08045", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Yan Han, Mason Carnahan, Ahmed H Tewfik", "title": "Speech Recognition With No Speech Or With Noisy Speech Beyond English", "comments": "arXiv admin note: text overlap with arXiv:1906.08871", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate continuous noisy speech recognition using\nconnectionist temporal classification (CTC) model on limited Chinese vocabulary\nusing electroencephalography (EEG) features with no speech signal as input and\nwe further demonstrate single CTC model based continuous noisy speech\nrecognition on limited joint English and Chinese vocabulary using EEG features\nwith no speech signal as input. We demonstrate our results using various EEG\nfeature sets recently introduced in [1] as well as we propose a new deep\nlearning architecture in this paper which can perform continuous speech\nrecognition using raw EEG signals on limited joint English and Chinese\nvocabulary.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:25:59 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 04:08:27 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 19:29:58 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 05:00:55 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2020 03:11:06 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Han", "Yan", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1906.08050", "submitter": "Katherine Fitch", "authors": "Katherine Fitch", "title": "Learning Directed Graphical Models from Gaussian Data", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new directed graphical model from Gaussian\ndata: the Gaussian graphical interaction model (GGIM). The development of this\nmodel comes from considering stationary Gaussian processes on graphs, and\nleveraging the equations between the resulting steady-state covariance matrix\nand the Laplacian matrix representing the interaction graph. Through the\npresentation of conceptually straightforward theory, we develop the new model\nand provide interpretations of the edges in the graphical model in terms of\nstatistical measures. We show that when restricted to undirected graphs, the\nLaplacian matrix representing a GGIM is equivalent to the standard inverse\ncovariance matrix that encodes conditional dependence relationships.\nFurthermore, our approach leads to a natural definition of directed conditional\nindependence of two elements in a stationary Gaussian process. We demonstrate\nthat the problem of learning sparse GGIMs for a given observation set can be\nframed as a LASSO problem. By comparison with the problem of inverse covariance\nestimation, we prove a bound on the difference between the covariance matrix\ncorresponding to a sparse GGIM and the covariance matrix corresponding to the\n$l_1$-norm penalized maximum log-likelihood estimate. Finally, we consider the\nproblem of learning GGIMs associated with sparse directed conditional\ndependence relationships. In all, the new model presents a novel perspective on\ndirected relationships between variables and significantly expands on the state\nof the art in Gaussian graphical modeling.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 12:16:48 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 13:29:40 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 15:52:53 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fitch", "Katherine", ""]]}, {"id": "1906.08059", "submitter": "Jia You", "authors": "Jia You, Philip L.H. Yu, Anderson C.O. Tsang, Eva L.H. Tsui, Pauline\n  P.S. Woo, and Gilberto K.K. Leung", "title": "Automated Computer Evaluation of Acute Ischemic Stroke and Large Vessel\n  Occlusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large vessel occlusion (LVO) plays an important role in the diagnosis of\nacute ischemic stroke. Identifying LVO of patients in the early stage on\nadmission would significantly lower the probabilities of suffering from severe\neffects due to stroke or even save their lives. In this paper, we utilized both\nstructural and imaging data from all recorded acute ischemic stroke patients in\nHong Kong. Total 300 patients (200 training and 100 testing) are used in this\nstudy. We established three hierarchical models based on demographic data,\nclinical data and features obtained from computerized tomography (CT) scans.\nThe first two stages of modeling are merely based on demographic and clinical\ndata. Besides, the third model utilized extra CT imaging features obtained from\ndeep learning model. The optimal cutoff is determined at the maximal Youden\nindex based on 10-fold cross-validation. With both clinical and imaging\nfeatures, the Level-3 model achieved the best performance on testing data. The\nsensitivity, specificity, Youden index, accuracy and area under the curve (AUC)\nare 0.930, 0.684, 0.614, 0.790 and 0.850 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 09:30:30 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["You", "Jia", ""], ["Yu", "Philip L. H.", ""], ["Tsang", "Anderson C. O.", ""], ["Tsui", "Eva L. H.", ""], ["Woo", "Pauline P. S.", ""], ["Leung", "Gilberto K. K.", ""]]}, {"id": "1906.08068", "submitter": "Kazuki Seshimo", "authors": "Kazuki Seshimo, Ota Akira, Nishio Daichi, Yamane Satoshi", "title": "Online Heterogeneous Mixture Learning for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the online machine learning for big data analysis with\nheterogeneity. We performed an experiment to compare the accuracy of each\niteration between batch one and online one. It is possible to converge quickly\nwith the same accuracy as the batch one.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 06:48:59 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Seshimo", "Kazuki", ""], ["Akira", "Ota", ""], ["Daichi", "Nishio", ""], ["Satoshi", "Yamane", ""]]}, {"id": "1906.08090", "submitter": "Jiapeng Zhu", "authors": "Jiapeng Zhu, Deli Zhao, Bo Zhang, Bolei Zhou", "title": "Disentangled Inference for GANs with Latently Invertible Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) play an increasingly important role in\nmachine learning. However, there is one fundamental issue hindering their\npractical applications: the absence of capability for encoding real-world\nsamples. The conventional way of addressing this issue is to learn an encoder\nfor GAN via Variational Auto-Encoder (VAE). In this paper, we show that the\nentanglement of the latent space for the VAE/GAN framework poses the main\nchallenge for encoder learning. To address the entanglement issue and enable\ninference in GAN we propose a novel algorithm named Latently Invertible\nAutoencoder (LIA). The framework of LIA is that an invertible network and its\ninverse mapping are symmetrically embedded in the latent space of VAE. The\ndecoder of LIA is first trained as a standard GAN with the invertible network\nand then the partial encoder is learned from a disentangled autoencoder by\ndetaching the invertible network from LIA, thus avoiding the entanglement\nproblem caused by the random latent space. Experiments conducted on the FFHQ\nface dataset and three LSUN datasets validate the effectiveness of LIA/GAN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:24:39 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 08:51:37 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 15:27:35 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Zhu", "Jiapeng", ""], ["Zhao", "Deli", ""], ["Zhang", "Bo", ""], ["Zhou", "Bolei", ""]]}, {"id": "1906.08094", "submitter": "Yasuaki Kobayashi", "authors": "Yusuke Shido, Yasuaki Kobayashi, Akihiro Yamamoto, Atsushi Miyamoto,\n  Tadayuki Matsumura", "title": "Automatic Source Code Summarization with Extended Tree-LSTM", "comments": "IJCNN 2019, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation models are used to automatically generate a\ndocument from given source code since this can be regarded as a machine\ntranslation task. Source code summarization is one of the components for\nautomatic document generation, which generates a summary in natural language\nfrom given source code. This suggests that techniques used in neural machine\ntranslation, such as Long Short-Term Memory (LSTM), can be used for source code\nsummarization. However, there is a considerable difference between source code\nand natural language: Source code is essentially {\\em structured}, having loops\nand conditional branching, etc. Therefore, there is some obstacle to apply\nknown machine translation models to source code.\n  Abstract syntax trees (ASTs) capture these structural properties and play an\nimportant role in recent machine learning studies on source code. Tree-LSTM is\nproposed as a generalization of LSTMs for tree-structured data. However, there\nis a critical issue when applying it to ASTs: It cannot handle a tree that\ncontains nodes having an arbitrary number of children and their order\nsimultaneously, which ASTs generally have such nodes. To address this issue, we\npropose an extension of Tree-LSTM, which we call \\emph{Multi-way Tree-LSTM} and\napply it for source code summarization. As a result of computational\nexperiments, our proposal achieved better results when compared with several\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:42:24 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 20:33:05 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Shido", "Yusuke", ""], ["Kobayashi", "Yasuaki", ""], ["Yamamoto", "Akihiro", ""], ["Miyamoto", "Atsushi", ""], ["Matsumura", "Tadayuki", ""]]}, {"id": "1906.08102", "submitter": "Zal\\'an Borsos", "authors": "Zal\\'an Borsos, Andrey Khorlin, Andrea Gesmundo", "title": "Transfer NAS: Knowledge Transfer between Search Spaces with Transformer\n  Agents", "comments": "6th ICML Workshop on Automated Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Neural Architecture Search (NAS) have produced\nstate-of-the-art architectures on several tasks. NAS shifts the efforts of\nhuman experts from developing novel architectures directly to designing\narchitecture search spaces and methods to explore them efficiently. The search\nspace definition captures prior knowledge about the properties of the\narchitectures and it is crucial for the complexity and the performance of the\nsearch algorithm. However, different search space definitions require\nrestarting the learning process from scratch. We propose a novel agent based on\nthe Transformer that supports joint training and efficient transfer of prior\nknowledge between multiple search spaces and tasks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:57:33 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Borsos", "Zal\u00e1n", ""], ["Khorlin", "Andrey", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1906.08107", "submitter": "Qinghai Zheng", "authors": "Qinghai Zheng, Jihua Zhu, Zhiqiang Tian, Zhongyu Li, Shanmin Pang,\n  Xiuyi Jia", "title": "Constrained Bilinear Factorization Multi-view Subspace Clustering", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2020.105514", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering is an important and fundamental problem. Many\nmulti-view subspace clustering methods have been proposed, and most of them\nassume that all views share a same coefficient matrix. However, the underlying\ninformation of multi-view data are not fully exploited under this assumption,\nsince the coefficient matrices of different views should have the same\nclustering properties rather than be uniform among multiple views. To this end,\nthis paper proposes a novel Constrained Bilinear Factorization Multi-view\nSubspace Clustering (CBF-MSC) method. Specifically, the bilinear factorization\nwith an orthonormality constraint and a low-rank constraint is imposed for all\ncoefficient matrices to make them have the same trace-norm instead of being\nequivalent, so as to explore the consensus information of multi-view data more\nfully. Finally, an Augmented Lagrangian Multiplier (ALM) based algorithm is\ndesigned to optimize the objective function. Comprehensive experiments tested\non nine benchmark datasets validate the effectiveness and competitiveness of\nthe proposed approach compared with several state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 14:07:59 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 13:08:51 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Zheng", "Qinghai", ""], ["Zhu", "Jihua", ""], ["Tian", "Zhiqiang", ""], ["Li", "Zhongyu", ""], ["Pang", "Shanmin", ""], ["Jia", "Xiuyi", ""]]}, {"id": "1906.08113", "submitter": "Huang Xiao", "authors": "Huang Xiao, Michael Herman, Joerg Wagner, Sebastian Ziesche, Jalal\n  Etesami, Thai Hong Linh", "title": "Wasserstein Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning describes the problem of recovering an expert policy from\ndemonstrations. While inverse reinforcement learning approaches are known to be\nvery sample-efficient in terms of expert demonstrations, they usually require\nproblem-dependent reward functions or a (task-)specific reward-function\nregularization. In this paper, we show a natural connection between inverse\nreinforcement learning approaches and Optimal Transport, that enables more\ngeneral reward functions with desirable properties (e.g., smoothness). Based on\nour observation, we propose a novel approach called Wasserstein Adversarial\nImitation Learning. Our approach considers the Kantorovich potentials as a\nreward function and further leverages regularized optimal transport to enable\nlarge-scale applications. In several robotic experiments, our approach\noutperforms the baselines in terms of average cumulative rewards and shows a\nsignificant improvement in sample-efficiency, by requiring just one expert\ndemonstration.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 14:20:58 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Xiao", "Huang", ""], ["Herman", "Michael", ""], ["Wagner", "Joerg", ""], ["Ziesche", "Sebastian", ""], ["Etesami", "Jalal", ""], ["Linh", "Thai Hong", ""]]}, {"id": "1906.08120", "submitter": "Kobi Cohen", "authors": "Tomer Gafni and Kobi Cohen", "title": "Learning in Restless Multi-Armed Bandits via Adaptive Arm Sequencing\n  Rules", "comments": "A short version of this paper was presented at IEEE International\n  Symposium on Information Theory (ISIT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of restless multi-armed bandit (RMAB) problems with\nunknown arm dynamics. At each time, a player chooses an arm out of N arms to\nplay, referred to as an active arm, and receives a random reward from a finite\nset of reward states. The reward state of the active arm transits according to\nan unknown Markovian dynamics. The reward state of passive arms (which are not\nchosen to play at time t) evolves according to an arbitrary unknown random\nprocess. The objective is an arm-selection policy that minimizes the regret,\ndefined as the reward loss with respect to a player that always plays the most\nrewarding arm. This class of RMAB problems has been studied recently in the\ncontext of communication networks and financial investment applications. We\ndevelop a strategy that selects arms to be played in a consecutive manner,\ndubbed Adaptive Sequencing Rules (ASR) algorithm. The sequencing rules for\nselecting arms under the ASR algorithm are adaptively updated and controlled by\nthe current sample reward means. By designing judiciously the adaptive\nsequencing rules, we show that the ASR algorithm achieves a logarithmic regret\norder with time, and a finite-sample bound on the regret is established.\nAlthough existing methods have shown a logarithmic regret order with time in\nthis RMAB setting, the theoretical analysis shows a significant improvement in\nthe regret scaling with respect to the system parameters under ASR. Extensive\nsimulation results support the theoretical study and demonstrate strong\nperformance of the algorithm as compared to existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 14:43:39 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Gafni", "Tomer", ""], ["Cohen", "Kobi", ""]]}, {"id": "1906.08129", "submitter": "Thomas Mortier", "authors": "Thomas Mortier and Marek Wydmuch and Krzysztof Dembczy\\'nski and Eyke\n  H\\\"ullermeier and Willem Waegeman", "title": "Efficient Set-Valued Prediction in Multi-Class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cases of uncertainty, a multi-class classifier preferably returns a set of\ncandidate classes instead of predicting a single class label with little\nguarantee. More precisely, the classifier should strive for an optimal balance\nbetween the correctness (the true class is among the candidates) and the\nprecision (the candidates are not too many) of its prediction. We formalize\nthis problem within a general decision-theoretic framework that unifies most of\nthe existing work in this area. In this framework, uncertainty is quantified in\nterms of conditional class probabilities, and the quality of a predicted set is\nmeasured in terms of a utility function. We then address the problem of finding\nthe Bayes-optimal prediction, i.e., the subset of class labels with highest\nexpected utility. For this problem, which is computationally challenging as\nthere are exponentially (in the number of classes) many predictions to choose\nfrom, we propose efficient algorithms that can be applied to a broad family of\nutility functions. Our theoretical results are complemented by experimental\nstudies, in which we analyze the proposed algorithms in terms of predictive\naccuracy and runtime efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 14:55:34 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 09:02:56 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Mortier", "Thomas", ""], ["Wydmuch", "Marek", ""], ["Dembczy\u0144ski", "Krzysztof", ""], ["H\u00fcllermeier", "Eyke", ""], ["Waegeman", "Willem", ""]]}, {"id": "1906.08143", "submitter": "Jing Cheng", "authors": "Jing Cheng, Haifeng Wang, Yanjie Zhu, Qiegen Liu, Qiyang Zhang, Ting\n  Su, Jianwei Chen, Yongshuai Ge, Zhanli Hu, Xin Liu, Hairong Zheng, Leslie\n  Ying, Dong Liang", "title": "Model-based Deep Medical Imaging: the roadmap of generalizing iterative\n  reconstruction model using deep learning", "comments": "part of the preliminary work will be presented at MICCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.SP math.OC physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical imaging is playing a more and more important role in clinics.\nHowever, there are several issues in different imaging modalities such as slow\nimaging speed in MRI, radiation injury in CT and PET. Therefore, accelerating\nMRI, reducing radiation dose in CT and PET have been ongoing research topics\nsince their invention. Usually, acquiring less data is a direct but important\nstrategy to address these issues. However, less acquisition usually results in\naliasing artifacts in reconstructions. Recently, deep learning (DL) has been\nintroduced in medical image reconstruction and shown potential on significantly\nspeeding up MR reconstruction and reducing radiation dose. In this paper, we\npropose a general framework on combining the reconstruction model with deep\nlearning to maximize the potential of deep learning and model-based\nreconstruction, and give the examples to demonstrate the performance and\nrequirements of unrolling different algorithms using deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:10:59 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 01:33:27 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2019 08:56:26 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 15:42:47 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Cheng", "Jing", ""], ["Wang", "Haifeng", ""], ["Zhu", "Yanjie", ""], ["Liu", "Qiegen", ""], ["Zhang", "Qiyang", ""], ["Su", "Ting", ""], ["Chen", "Jianwei", ""], ["Ge", "Yongshuai", ""], ["Hu", "Zhanli", ""], ["Liu", "Xin", ""], ["Zheng", "Hairong", ""], ["Ying", "Leslie", ""], ["Liang", "Dong", ""]]}, {"id": "1906.08144", "submitter": "Arun Pandey", "authors": "Arun Pandey, Joachim Schreurs, Johan A. K. Suykens", "title": "Generative Restricted Kernel Machines: A Framework for Multi-view\n  Generation and Disentangled Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel framework for generative models based on\nRestricted Kernel Machines (RKMs) with joint multi-view generation and\nuncorrelated feature learning, called Gen-RKM. To enable joint multi-view\ngeneration, this mechanism uses a shared representation of data from various\nviews. Furthermore, the model has a primal and dual formulation to incorporate\nboth kernel-based and (deep convolutional) neural network based models within\nthe same setting. When using neural networks as explicit feature-maps, a novel\ntraining procedure is proposed, which jointly learns the features and shared\nsubspace representation. The latent variables are given by the\neigen-decomposition of the kernel matrix, where the mutual orthogonality of\neigenvectors represents the learned uncorrelated features. Experiments\ndemonstrate the potential of the framework through qualitative and quantitative\nevaluation of generated samples on various standard datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:12:00 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 11:50:33 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 21:03:59 GMT"}, {"version": "v4", "created": "Tue, 4 Feb 2020 09:55:54 GMT"}, {"version": "v5", "created": "Thu, 6 Feb 2020 18:08:27 GMT"}, {"version": "v6", "created": "Wed, 14 Oct 2020 15:37:53 GMT"}, {"version": "v7", "created": "Thu, 17 Dec 2020 10:34:20 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Pandey", "Arun", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1906.08152", "submitter": "Yin-Jyun Luo", "authors": "Yin-Jyun Luo, Kat Agres, Dorien Herremans", "title": "Learning Disentangled Representations of Timbre and Pitch for Musical\n  Instrument Sounds Using Gaussian Mixture Variational Autoencoders", "comments": "20th Conference of the International Society for Music Information\n  Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we learn disentangled representations of timbre and pitch for\nmusical instrument sounds. We adapt a framework based on variational\nautoencoders with Gaussian mixture latent distributions. Specifically, we use\ntwo separate encoders to learn distinct latent spaces for timbre and pitch,\nwhich form Gaussian mixture components representing instrument identity and\npitch, respectively. For reconstruction, latent variables of timbre and pitch\nare sampled from corresponding mixture components, and are concatenated as the\ninput to a decoder. We show the model efficacy by latent space visualization,\nand a quantitative analysis indicates the discriminability of these spaces,\neven with a limited number of instrument labels for training. The model allows\nfor controllable synthesis of selected instrument sounds by sampling from the\nlatent spaces. To evaluate this, we trained instrument and pitch classifiers\nusing original labeled data. These classifiers achieve high accuracy when\ntested on our synthesized sounds, which verifies the model performance of\ncontrollable realistic timbre and pitch synthesis. Our model also enables\ntimbre transfer between multiple instruments, with a single autoencoder\narchitecture, which is evaluated by measuring the shift in posterior of\ninstrument classification. Our in depth evaluation confirms the model ability\nto successfully disentangle timbre and pitch.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:25:29 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 04:29:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Luo", "Yin-Jyun", ""], ["Agres", "Kat", ""], ["Herremans", "Dorien", ""]]}, {"id": "1906.08158", "submitter": "Joost van Amersfoort", "authors": "Andreas Kirsch, Joost van Amersfoort, Yarin Gal", "title": "BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian\n  Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop BatchBALD, a tractable approximation to the mutual information\nbetween a batch of points and model parameters, which we use as an acquisition\nfunction to select multiple informative points jointly for the task of deep\nBayesian active learning. BatchBALD is a greedy linear-time $1 -\n\\frac{1}{e}$-approximate algorithm amenable to dynamic programming and\nefficient caching. We compare BatchBALD to the commonly used approach for batch\ndata acquisition and find that the current approach acquires similar and\nredundant points, sometimes performing worse than randomly acquiring data. We\nfinish by showing that, using BatchBALD to consider dependencies within an\nacquisition batch, we achieve new state of the art performance on standard\nbenchmarks, providing substantial data efficiency improvements in batch\nacquisition.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:35:07 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 16:38:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kirsch", "Andreas", ""], ["van Amersfoort", "Joost", ""], ["Gal", "Yarin", ""]]}, {"id": "1906.08167", "submitter": "Maryam Parsa", "authors": "Maryam Parsa, Aayush Ankit, Amirkoushyar Ziabari, Kaushik Roy", "title": "PABO: Pseudo Agent-Based Multi-Objective Bayesian Hyperparameter\n  Optimization for Efficient Neural Accelerator Design", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever increasing computational cost of Deep Neural Networks (DNN) and the\ndemand for energy efficient hardware for DNN acceleration has made accuracy and\nhardware cost co-optimization for DNNs tremendously important, especially for\nedge devices. Owing to the large parameter space and cost of evaluating each\nparameter in the search space, manually tuning of DNN hyperparameters is\nimpractical. Automatic joint DNN and hardware hyperparameter optimization is\nindispensable for such problems. Bayesian optimization-based approaches have\nshown promising results for hyperparameter optimization of DNNs. However, most\nof these techniques have been developed without considering the underlying\nhardware, thereby leading to inefficient designs. Further, the few works that\nperform joint optimization are not generalizable and mainly focus on CMOS-based\narchitectures. In this work, we present a novel pseudo agent-based\nmulti-objective hyperparameter optimization (PABO) for maximizing the DNN\nperformance while obtaining low hardware cost. Compared to the existing\nmethods, our work poses a theoretically different approach for joint\noptimization of accuracy and hardware cost and focuses on memristive\ncrossbar-based accelerators. PABO uses a supervisor agent to establish\nconnections between the posterior Gaussian distribution models of network\naccuracy and hardware cost requirements. The agent reduces the mathematical\ncomplexity of the co-optimization problem by removing unnecessary computations\nand updates of acquisition functions, thereby achieving significant speed-ups\nfor the optimization procedure. PABO outputs a Pareto frontier that underscores\nthe trade-offs between designing high-accuracy and hardware efficiency. Our\nresults demonstrate a superior performance compared to the state-of-the-art\nmethods both in terms of accuracy and computational speed (~100x speed up).\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:57:54 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Parsa", "Maryam", ""], ["Ankit", "Aayush", ""], ["Ziabari", "Amirkoushyar", ""], ["Roy", "Kaushik", ""]]}, {"id": "1906.08189", "submitter": "Riley Simmons-Edler", "authors": "Riley Simmons-Edler, Ben Eisner, Daniel Yang, Anthony Bisulco, Eric\n  Mitchell, Sebastian Seung, Daniel Lee", "title": "Reward Prediction Error as an Exploration Objective in Deep RL", "comments": "Published at IJCAI 2020, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in reinforcement learning is exploration, when local\ndithering methods such as epsilon-greedy sampling are insufficient to solve a\ngiven task. Many recent methods have proposed to intrinsically motivate an\nagent to seek novel states, driving the agent to discover improved reward.\nHowever, while state-novelty exploration methods are suitable for tasks where\nnovel observations correlate well with improved reward, they may not explore\nmore efficiently than epsilon-greedy approaches in environments where the two\nare not well-correlated. In this paper, we distinguish between exploration\ntasks in which seeking novel states aids in finding new reward, and those where\nit does not, such as goal-conditioned tasks and escaping local reward maxima.\nWe propose a new exploration objective, maximizing the reward prediction error\n(RPE) of a value function trained to predict extrinsic reward. We then propose\na deep reinforcement learning method, QXplore, which exploits the temporal\ndifference error of a Q-function to solve hard exploration tasks in\nhigh-dimensional MDPs. We demonstrate the exploration behavior of QXplore on\nseveral OpenAI Gym MuJoCo tasks and Atari games and observe that QXplore is\ncomparable to or better than a baseline state-novelty method in all cases,\noutperforming the baseline on tasks where state novelty is not well-correlated\nwith improved reward.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 16:06:36 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 21:11:45 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 18:51:51 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 00:30:52 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 01:26:18 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Simmons-Edler", "Riley", ""], ["Eisner", "Ben", ""], ["Yang", "Daniel", ""], ["Bisulco", "Anthony", ""], ["Mitchell", "Eric", ""], ["Seung", "Sebastian", ""], ["Lee", "Daniel", ""]]}, {"id": "1906.08207", "submitter": "Imtiaz Ziko", "authors": "Imtiaz Masud Ziko, Eric Granger, Jing Yuan, Ismail Ben Ayed", "title": "Variational Fair Clustering", "comments": "Accepted to be published in AAAI 2021. The Code is available at:\n  https://github.com/imtiazziko/Variational-Fair-Clustering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general variational framework of fair clustering, which\nintegrates an original Kullback-Leibler (KL) fairness term with a large class\nof clustering objectives, including prototype or graph based. Fundamentally\ndifferent from the existing combinatorial and spectral solutions, our\nvariational multi-term approach enables to control the trade-off levels between\nthe fairness and clustering objectives. We derive a general tight upper bound\nbased on a concave-convex decomposition of our fairness term, its\nLipschitz-gradient property and the Pinsker's inequality. Our tight upper bound\ncan be jointly optimized with various clustering objectives, while yielding a\nscalable solution, with convergence guarantee. Interestingly, at each\niteration, it performs an independent update for each assignment variable.\nTherefore, it can be easily distributed for large-scale datasets. This\nscalability is important as it enables to explore different trade-off levels\nbetween the fairness and clustering objectives. Unlike spectral relaxation, our\nformulation does not require computing its eigenvalue decomposition. We report\ncomprehensive evaluations and comparisons with state-of-the-art methods over\nvarious fair-clustering benchmarks, which show that our variational formulation\ncan yield highly competitive solutions in terms of fairness and clustering\nobjectives.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 16:29:56 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 16:47:44 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 16:40:43 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 15:24:18 GMT"}, {"version": "v5", "created": "Fri, 4 Dec 2020 15:58:15 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ziko", "Imtiaz Masud", ""], ["Granger", "Eric", ""], ["Yuan", "Jing", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "1906.08215", "submitter": "Csaba Toth", "authors": "Csaba Toth, Harald Oberhauser", "title": "Bayesian Learning from Sequential Data using Gaussian Processes with\n  Signature Covariances", "comments": "Near camera ready version for ICML 2020. Previous title: \"Variational\n  Gaussian Processes with Signature Covariances\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian approach to learning from sequential data by using\nGaussian processes (GPs) with so-called signature kernels as covariance\nfunctions. This allows to make sequences of different length comparable and to\nrely on strong theoretical results from stochastic analysis. Signatures capture\nsequential structure with tensors that can scale unfavourably in sequence\nlength and state space dimension. To deal with this, we introduce a sparse\nvariational approach with inducing tensors. We then combine the resulting GP\nwith LSTMs and GRUs to build larger models that leverage the strengths of each\nof these approaches and benchmark the resulting GPs on multivariate time series\n(TS) classification datasets. Code available at\nhttps://github.com/tgcsaba/GPSig.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 16:46:22 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 16:54:31 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Toth", "Csaba", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1906.08226", "submitter": "Ankesh Anand", "authors": "Ankesh Anand, Evan Racah, Sherjil Ozair, Yoshua Bengio, Marc-Alexandre\n  C\\^ot\\'e, R Devon Hjelm", "title": "Unsupervised State Representation Learning in Atari", "comments": "NeurIPS 2019; v6 fixes a broken figure reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State representation learning, or the ability to capture latent generative\nfactors of an environment, is crucial for building intelligent agents that can\nperform a wide variety of tasks. Learning such representations without\nsupervision from rewards is a challenging open problem. We introduce a method\nthat learns state representations by maximizing mutual information across\nspatially and temporally distinct features of a neural encoder of the\nobservations. We also introduce a new benchmark based on Atari 2600 games where\nwe evaluate representations based on how well they capture the ground truth\nstate variables. We believe this new framework for evaluating representation\nlearning models will be crucial for future representation learning research.\nFinally, we compare our technique with other state-of-the-art generative and\ncontrastive representation learning methods. The code associated with this work\nis available at https://github.com/mila-iqia/atari-representation-learning\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:16:46 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 19:34:15 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 01:17:20 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 00:28:02 GMT"}, {"version": "v5", "created": "Sun, 19 Jan 2020 20:54:03 GMT"}, {"version": "v6", "created": "Thu, 5 Nov 2020 23:10:28 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Anand", "Ankesh", ""], ["Racah", "Evan", ""], ["Ozair", "Sherjil", ""], ["Bengio", "Yoshua", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1906.08227", "submitter": "Andr\\'es Hoyos-Idrobo", "authors": "Andr\\'es Hoyos-Idrobo", "title": "Local Bures-Wasserstein Transport: A Practical and Fast Mapping\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT)-based methods have a wide range of applications and\nhave attracted a tremendous amount of attention in recent years. However, most\nof the computational approaches of OT do not learn the underlying transport\nmap. Although some algorithms have been proposed to learn this map, they rely\non kernel-based methods, which makes them prohibitively slow when the number of\nsamples increases. Here, we propose a way to learn an approximate transport map\nand a parametric approximation of the Wasserstein barycenter. We build an\napproximated transport mapping by leveraging the closed-form of Gaussian\n(Bures-Wasserstein) transport; we compute local transport plans between matched\npairs of the Gaussian components of each density. The learned map generalizes\nto out-of-sample examples. We provide experimental results on simulated and\nreal data, comparing our proposed method with other mapping estimation\nalgorithms. Preliminary experiments suggest that our proposed method is not\nonly faster, with a factor 80 overall running time, but it also requires fewer\ncomponents than state-of-the-art methods to recover the support of the\nbarycenter. From a practical standpoint, it is straightforward to implement and\ncan be used with a conventional machine learning pipeline.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:16:54 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Hoyos-Idrobo", "Andr\u00e9s", ""]]}, {"id": "1906.08230", "submitter": "Roshan Rao", "authors": "Roshan Rao, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi Chen,\n  John Canny, Pieter Abbeel, and Yun S. Song", "title": "Evaluating Protein Transfer Learning with TAPE", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein modeling is an increasingly popular area of machine learning\nresearch. Semi-supervised learning has emerged as an important paradigm in\nprotein modeling due to the high cost of acquiring supervised protein labels,\nbut the current literature is fragmented when it comes to datasets and\nstandardized evaluation techniques. To facilitate progress in this field, we\nintroduce the Tasks Assessing Protein Embeddings (TAPE), a set of five\nbiologically relevant semi-supervised learning tasks spread across different\ndomains of protein biology. We curate tasks into specific training, validation,\nand test splits to ensure that each task tests biologically relevant\ngeneralization that transfers to real-life scenarios. We benchmark a range of\napproaches to semi-supervised protein representation learning, which span\nrecent work as well as canonical sequence learning techniques. We find that\nself-supervised pretraining is helpful for almost all models on all tasks, more\nthan doubling performance in some cases. Despite this increase, in several\ncases features learned by self-supervised pretraining still lag behind features\nextracted by state-of-the-art non-neural techniques. This gap in performance\nsuggests a huge opportunity for innovative architecture design and improved\nmodeling paradigms that better capture the signal in biological sequences. TAPE\nwill help the machine learning community focus effort on scientifically\nrelevant problems. Toward this end, all data and code used to run these\nexperiments are available at https://github.com/songlab-cal/tape.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:19:31 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Rao", "Roshan", ""], ["Bhattacharya", "Nicholas", ""], ["Thomas", "Neil", ""], ["Duan", "Yan", ""], ["Chen", "Xi", ""], ["Canny", "John", ""], ["Abbeel", "Pieter", ""], ["Song", "Yun S.", ""]]}, {"id": "1906.08241", "submitter": "Justin Domke", "authors": "Justin Domke", "title": "Provable Gradient Variance Guarantees for Black-Box Variational\n  Inference", "comments": "Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent variational inference methods use stochastic gradient estimators whose\nvariance is not well understood. Theoretical guarantees for these estimators\nare important to understand when these methods will or will not work. This\npaper gives bounds for the common \"reparameterization\" estimators when the\ntarget is smooth and the variational family is a location-scale distribution.\nThese bounds are unimprovable and thus provide the best possible guarantees\nunder the stated assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:41:45 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 01:11:23 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Domke", "Justin", ""]]}, {"id": "1906.08253", "submitter": "Michael Janner", "authors": "Michael Janner, Justin Fu, Marvin Zhang, Sergey Levine", "title": "When to Trust Your Model: Model-Based Policy Optimization", "comments": "NeurIPS 2019. Code at https://github.com/JannerM/mbpo, project page\n  at: https://people.eecs.berkeley.edu/~janner/mbpo/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing effective model-based reinforcement learning algorithms is\ndifficult because the ease of data generation must be weighed against the bias\nof model-generated data. In this paper, we study the role of model usage in\npolicy optimization both theoretically and empirically. We first formulate and\nanalyze a model-based reinforcement learning algorithm with a guarantee of\nmonotonic improvement at each step. In practice, this analysis is overly\npessimistic and suggests that real off-policy data is always preferable to\nmodel-generated on-policy data, but we show that an empirical estimate of model\ngeneralization can be incorporated into such analysis to justify model usage.\nMotivated by this analysis, we then demonstrate that a simple procedure of\nusing short model-generated rollouts branched from real data has the benefits\nof more complicated model-based algorithms without the usual pitfalls. In\nparticular, this approach surpasses the sample efficiency of prior model-based\nmethods, matches the asymptotic performance of the best model-free algorithms,\nand scales to horizons that cause other model-based methods to fail entirely.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:54:53 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 01:22:47 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Janner", "Michael", ""], ["Fu", "Justin", ""], ["Zhang", "Marvin", ""], ["Levine", "Sergey", ""]]}, {"id": "1906.08255", "submitter": "Christopher Geier", "authors": "Christopher Geier", "title": "Training on test data: Removing near duplicates in Fashion-MNIST", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MNIST and Fashion MNIST are extremely popular for testing in the machine\nlearning space. Fashion MNIST improves on MNIST by introducing a harder\nproblem, increasing the diversity of testing sets, and more accurately\nrepresenting a modern computer vision task. In order to increase the data\nquality of FashionMNIST, this paper investigates near duplicate images between\ntraining and testing sets. Near-duplicates between testing and training sets\nartificially increase the testing accuracy of machine learning models. This\npaper identifies near-duplicate images in Fashion MNIST and proposes a dataset\nwith near-duplicates removed.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:09:47 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Geier", "Christopher", ""]]}, {"id": "1906.08257", "submitter": "Monimoy Bujarbaruah", "authors": "Xiaojing Zhang, Monimoy Bujarbaruah, Francesco Borrelli", "title": "Safe and Near-Optimal Policy Learning for Model Predictive Control using\n  Primal-Dual Neural Networks", "comments": "IEEE American Control Conference (ACC) 2019, July 9-12, Philadelphia,\n  PA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework for approximating the explicit\nMPC law for linear parameter-varying systems using supervised learning. In\ncontrast to most existing approaches, we not only learn the control policy, but\nalso a \"certificate policy\", that allows us to estimate the sub-optimality of\nthe learned control policy online, during execution-time. We learn both these\npolicies from data using supervised learning techniques, and also provide a\nrandomized method that allows us to guarantee the quality of each learned\npolicy, measured in terms of feasibility and optimality. This in turn allows us\nto bound the probability of the learned control policy of being infeasible or\nsuboptimal, where the check is performed by the certificate policy. Since our\nalgorithm does not require the solution of an optimization problem during\nrun-time, it can be deployed even on resource-constrained systems. We\nillustrate the efficacy of the proposed framework on a vehicle dynamics control\nproblem where we demonstrate a speedup of up to two orders of magnitude\ncompared to online optimization with minimal performance degradation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 06:08:06 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zhang", "Xiaojing", ""], ["Bujarbaruah", "Monimoy", ""], ["Borrelli", "Francesco", ""]]}, {"id": "1906.08259", "submitter": "Japan Patel", "authors": "Jinzhao Chen, Japan K. Patel, and Richard Vasques", "title": "Solver Recommendation For Transport Problems in Slabs Using Machine\n  Learning", "comments": "Accepted -- The International Conference on Mathematics and\n  Computational Methods applied to Nuclear Science and Engineering (M&C 2019),\n  Portland, OR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nucl-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning algorithms to address classification problems is\non the rise in many research areas. The current study is aimed at testing the\npotential of using such algorithms to auto-select the best solvers for\ntransport problems in uniform slabs. Three solvers are used in this work:\nRichardson, diffusion synthetic acceleration, and nonlinear diffusion\nacceleration. Three parameters are manipulated to create different transport\nproblem scenarios. Five machine learning algorithms are applied: linear\ndiscriminant analysis, K-nearest neighbors, support vector machine, random\nforest, and neural networks. We present and analyze the results of these\nalgorithms for the test problems, showing that random forest and K-nearest\nneighbors are potentially the best suited candidates for this type of\nclassification problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 16:21:20 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Chen", "Jinzhao", ""], ["Patel", "Japan K.", ""], ["Vasques", "Richard", ""]]}, {"id": "1906.08283", "submitter": "Francois-Xavier Briol", "authors": "Alessandro Barp, Francois-Xavier Briol, Andrew B. Duncan, Mark\n  Girolami, Lester Mackey", "title": "Minimum Stein Discrepancy Estimators", "comments": "Accepted for publication at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When maximum likelihood estimation is infeasible, one often turns to score\nmatching, contrastive divergence, or minimum probability flow to obtain\ntractable parameter estimates. We provide a unifying perspective of these\ntechniques as minimum Stein discrepancy estimators, and use this lens to design\nnew diffusion kernel Stein discrepancy (DKSD) and diffusion score matching\n(DSM) estimators with complementary strengths. We establish the consistency,\nasymptotic normality, and robustness of DKSD and DSM estimators, then derive\nstochastic Riemannian gradient descent algorithms for their efficient\noptimisation. The main strength of our methodology is its flexibility, which\nallows us to design estimators with desirable properties for specific models at\nhand by carefully selecting a Stein discrepancy. We illustrate this advantage\nfor several challenging problems for score matching, such as non-smooth,\nheavy-tailed or light-tailed densities.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 18:04:28 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 10:11:43 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Barp", "Alessandro", ""], ["Briol", "Francois-Xavier", ""], ["Duncan", "Andrew B.", ""], ["Girolami", "Mark", ""], ["Mackey", "Lester", ""]]}, {"id": "1906.08312", "submitter": "Ali Malik", "authors": "Ali Malik, Volodymyr Kuleshov, Jiaming Song, Danny Nemer, Harlan\n  Seymour, Stefano Ermon", "title": "Calibrated Model-Based Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:4314-4323, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimates of predictive uncertainty are important for accurate model-based\nplanning and reinforcement learning. However, predictive\nuncertainties---especially ones derived from modern deep learning systems---can\nbe inaccurate and impose a bottleneck on performance. This paper explores which\nuncertainties are needed for model-based reinforcement learning and argues that\ngood uncertainties must be calibrated, i.e. their probabilities should match\nempirical frequencies of predicted events. We describe a simple way to augment\nany model-based reinforcement learning agent with a calibrated model and show\nthat doing so consistently improves planning, sample complexity, and\nexploration. On the \\textsc{HalfCheetah} MuJoCo task, our system achieves\nstate-of-the-art performance using 50\\% fewer samples than the current leading\napproach. Our findings suggest that calibration can improve the performance of\nmodel-based reinforcement learning with minimal computational and\nimplementation overhead.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:10:26 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Malik", "Ali", ""], ["Kuleshov", "Volodymyr", ""], ["Song", "Jiaming", ""], ["Nemer", "Danny", ""], ["Seymour", "Harlan", ""], ["Ermon", "Stefano", ""]]}, {"id": "1906.08320", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Rasmus Pagh, Ameya Velingker", "title": "Scalable and Differentially Private Distributed Aggregation in the\n  Shuffled Model", "comments": "17 pages, 1 figure, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning promises to make machine learning feasible on distributed,\nprivate datasets by implementing gradient descent using secure aggregation\nmethods. The idea is to compute a global weight update without revealing the\ncontributions of individual users. Current practical protocols for secure\naggregation work in an \"honest but curious\" setting where a curious adversary\nobserving all communication to and from the server cannot learn any private\ninformation assuming the server is honest and follows the protocol. A more\nscalable and robust primitive for privacy-preserving protocols is shuffling of\nuser data, so as to hide the origin of each data item. Highly scalable and\nsecure protocols for shuffling, so-called mixnets, have been proposed as a\nprimitive for privacy-preserving analytics in the Encode-Shuffle-Analyze\nframework by Bittau et al., which was later analytically studied by Erlingsson\net al. and Cheu et al.. The recent papers by Cheu et al., and Balle et al. have\ngiven protocols for secure aggregation that achieve differential privacy\nguarantees in this \"shuffled model\". Their protocols come at a cost, though:\nEither the expected aggregation error or the amount of communication per user\nscales as a polynomial $n^{\\Omega(1)}$ in the number of users $n$. In this\npaper we propose simple and more efficient protocol for aggregation in the\nshuffled model, where communication as well as error increases only\npolylogarithmically in $n$. Our new technique is a conceptual \"invisibility\ncloak\" that makes users' data almost indistinguishable from random noise while\nintroducing zero distortion on the sum.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:30:05 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 17:21:17 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:53:21 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ghazi", "Badih", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "1906.08324", "submitter": "Christos Louizos", "authors": "Christos Louizos, Xiahan Shi, Klamer Schutte and Max Welling", "title": "The Functional Neural Process", "comments": "Published as a conference paper at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new family of exchangeable stochastic processes, the Functional\nNeural Processes (FNPs). FNPs model distributions over functions by learning a\ngraph of dependencies on top of latent representations of the points in the\ngiven dataset. In doing so, they define a Bayesian model without explicitly\npositing a prior distribution over latent global parameters; they instead adopt\npriors over the relational structure of the given dataset, a task that is much\nsimpler. We show how we can learn such models from data, demonstrate that they\nare scalable to large datasets through mini-batch optimization and describe how\nwe can make predictions for new points via their posterior predictive\ndistribution. We experimentally evaluate FNPs on the tasks of toy regression\nand image classification and show that, when compared to baselines that employ\nglobal latent parameters, they offer both competitive predictions as well as\nmore robust uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:39:59 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 11:46:02 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Louizos", "Christos", ""], ["Shi", "Xiahan", ""], ["Schutte", "Klamer", ""], ["Welling", "Max", ""]]}, {"id": "1906.08325", "submitter": "Jose Daniel Gallego Posada", "authors": "Jose Gallego, Ankit Vani, Max Schwarzer and Simon Lacoste-Julien", "title": "GAIT: A Geometric Approach to Information Theory", "comments": "Appears in: Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2020. 19 pages", "journal-ref": "PMLR (2020) 108:2601-2611", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate the use of a notion of entropy that reflects the relative\nabundances of the symbols in an alphabet, as well as the similarities between\nthem. This concept was originally introduced in theoretical ecology to study\nthe diversity of ecosystems. Based on this notion of entropy, we introduce\ngeometry-aware counterparts for several concepts and theorems in information\ntheory. Notably, our proposed divergence exhibits performance on par with\nstate-of-the-art methods based on the Wasserstein distance, but enjoys a\nclosed-form expression that can be computed efficiently. We demonstrate the\nversatility of our method via experiments on a broad range of domains: training\ngenerative models, computing image barycenters, approximating empirical\nmeasures and counting modes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:46:28 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 18:45:31 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 22:27:51 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Gallego", "Jose", ""], ["Vani", "Ankit", ""], ["Schwarzer", "Max", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1906.08333", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Younggwan Kim, Hyungjun Lim, Yeunju Choi, Hoirin Kim", "title": "Spatial Pyramid Encoding with Convex Length Normalization for\n  Text-Independent Speaker Verification", "comments": "5 pages, 2 figures, Interspeech 2019", "journal-ref": "Proc. of Interspeech 2019, 2019, pp. 4030-4034", "doi": "10.21437/Interspeech.2019-2177", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new pooling method called spatial pyramid\nencoding (SPE) to generate speaker embeddings for text-independent speaker\nverification. We first partition the output feature maps from a deep residual\nnetwork (ResNet) into increasingly fine sub-regions and extract speaker\nembeddings from each sub-region through a learnable dictionary encoding layer.\nThese embeddings are concatenated to obtain the final speaker representation.\nThe SPE layer not only generates a fixed-dimensional speaker embedding for a\nvariable-length speech segment, but also aggregates the information of feature\ndistribution from multi-level temporal bins. Furthermore, we apply deep length\nnormalization by augmenting the loss function with ring loss. By applying ring\nloss, the network gradually learns to normalize the speaker embeddings using\nmodel weights themselves while preserving convexity, leading to more robust\nspeaker embeddings. Experiments on the VoxCeleb1 dataset show that the proposed\nsystem using the SPE layer and ring loss-based deep length normalization\noutperforms both i-vector and d-vector baselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 20:13:27 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Jung", "Youngmoon", ""], ["Kim", "Younggwan", ""], ["Lim", "Hyungjun", ""], ["Choi", "Yeunju", ""], ["Kim", "Hoirin", ""]]}, {"id": "1906.08339", "submitter": "Subhro Das", "authors": "Subhro Das, Chandramouli Maduri, Ching-Hua Chen, Pei-Yun S. Hsueh", "title": "Learning Patient Engagement in Care Management: Performance vs.\n  Interpretability", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The health outcomes of high-need patients can be substantially influenced by\nthe degree of patient engagement in their own care. The role of care managers\nincludes that of enrolling patients into care programs and keeping them\nsufficiently engaged in the program, so that patients can attain various goals.\nThe attainment of these goals is expected to improve the patients' health\noutcomes. In this paper, we present a real world data-driven method and the\nbehavioral engagement scoring pipeline for scoring the engagement level of a\npatient in two regards: (1) Their interest in enrolling into a relevant care\nprogram, and (2) their interest and commitment to program goals. We use this\nscore to predict a patient's propensity to respond (i.e., to a call for\nenrollment into a program, or to an assigned program goal). Using real-world\ncare management data, we show that our scoring method successfully predicts\npatient engagement. We also show that we are able to provide interpretable\ninsights to care managers, using prototypical patients as a point of reference,\nwithout sacrificing prediction performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 20:26:07 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Das", "Subhro", ""], ["Maduri", "Chandramouli", ""], ["Chen", "Ching-Hua", ""], ["Hsueh", "Pei-Yun S.", ""]]}, {"id": "1906.08344", "submitter": "Oliver Hamelijnck", "authors": "Oliver Hamelijnck, Theodoros Damoulas, Kangrui Wang, Mark Girolami", "title": "Multi-resolution Multi-task Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider evidence integration from potentially dependent observation\nprocesses under varying spatio-temporal sampling resolutions and noise levels.\nWe develop a multi-resolution multi-task (MRGP) framework while allowing for\nboth inter-task and intra-task multi-resolution and multi-fidelity. We develop\nshallow Gaussian Process (GP) mixtures that approximate the difficult to\nestimate joint likelihood with a composite one and deep GP constructions that\nnaturally handle biases in the mean. By doing so, we generalize and outperform\nstate of the art GP compositions and offer information-theoretic corrections\nand efficient variational approximations. We demonstrate the competitiveness of\nMRGPs on synthetic settings and on the challenging problem of hyper-local\nestimation of air pollution levels across London from multiple sensing\nmodalities operating at disparate spatio-temporal resolutions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 20:33:09 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 11:44:04 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Hamelijnck", "Oliver", ""], ["Damoulas", "Theodoros", ""], ["Wang", "Kangrui", ""], ["Girolami", "Mark", ""]]}, {"id": "1906.08365", "submitter": "Dushyant Sahoo", "authors": "Dushyant Sahoo, Theodore D. Satterthwaite and Christos Davatzikos", "title": "Extraction of hierarchical functional connectivity components in human\n  brain using resting-state fMRI", "comments": null, "journal-ref": null, "doi": "10.1109/TMI.2020.3042873", "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of hierarchy in networks of the human brain has been of significant\ninterest among the researchers as numerous studies have pointed out towards a\nfunctional hierarchical organization of the human brain. This paper provides a\nnovel method for the extraction of hierarchical connectivity components in the\nhuman brain using resting-state fMRI. The method builds upon prior work of\nSparse Connectivity Patterns (SCPs) by introducing a hierarchy of sparse\noverlapping patterns. The components are estimated by deep factorization of\ncorrelation matrices generated from fMRI. The goal of the paper is to extract\ninterpretable hierarchical patterns using correlation matrices where a low rank\ndecomposition is formed by a linear combination of a high rank decomposition.\nWe formulate the decomposition as a non-convex optimization problem and solve\nit using gradient descent algorithms with adaptive step size. We also provide a\nmethod for the warm start of the gradient descent using singular value\ndecomposition. We demonstrate the effectiveness of the developed method on two\ndifferent real-world datasets by showing that multi-scale hierarchical SCPs are\nreproducible between sub-samples and are more reproducible as compared to\nsingle scale patterns. We also compare our method with existing hierarchical\ncommunity detection approaches. Our method also provides novel insight into the\nfunctional organization of the human brain.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 21:29:40 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 18:27:57 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 17:24:32 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sahoo", "Dushyant", ""], ["Satterthwaite", "Theodore D.", ""], ["Davatzikos", "Christos", ""]]}, {"id": "1906.08386", "submitter": "Han Zhao", "authors": "Han Zhao, Geoffrey J. Gordon", "title": "Inherent Tradeoffs in Learning Fair Representations", "comments": "Appeared in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of machine learning in high-stakes applications,\nespecially the ones regulated by anti-discrimination laws or societal norms, it\nis crucial to ensure that the predictive models do not propagate any existing\nbias or discrimination. Due to the ability of deep neural nets to learn rich\nrepresentations, recent advances in algorithmic fairness have focused on\nlearning fair representations with adversarial techniques to reduce bias in\ndata while preserving utility simultaneously. In this paper, through the lens\nof information theory, we provide the first result that quantitatively\ncharacterizes the tradeoff between demographic parity and the joint utility\nacross different population groups. Specifically, when the base rates differ\nbetween groups, we show that any method aiming to learn fair representations\nadmits an information-theoretic lower bound on the joint error across these\ngroups. To complement our negative results, we also prove that if the optimal\ndecision functions across different groups are close, then learning fair\nrepresentations leads to an alternative notion of fairness, known as the\naccuracy parity, which states that the error rates are close between groups.\nFinally, our theoretical findings are also confirmed empirically on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:44:14 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 18:49:45 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:54:23 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 07:28:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhao", "Han", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1906.08387", "submitter": "Daochen Zha", "authors": "Daochen Zha, Kwei-Herng Lai, Kaixiong Zhou and Xia Hu", "title": "Experience Replay Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay enables reinforcement learning agents to memorize and reuse\npast experiences, just as humans replay memories for the situation at hand.\nContemporary off-policy algorithms either replay past experiences uniformly or\nutilize a rule-based replay strategy, which may be sub-optimal. In this work,\nwe consider learning a replay policy to optimize the cumulative reward. Replay\nlearning is challenging because the replay memory is noisy and large, and the\ncumulative reward is unstable. To address these issues, we propose a novel\nexperience replay optimization (ERO) framework which alternately updates two\npolicies: the agent policy, and the replay policy. The agent is updated to\nmaximize the cumulative reward based on the replayed data, while the replay\npolicy is updated to provide the agent with the most useful experiences. The\nconducted experiments on various continuous control tasks demonstrate the\neffectiveness of ERO, empirically showing promise in experience replay learning\nto improve the performance of off-policy reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:46:39 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zha", "Daochen", ""], ["Lai", "Kwei-Herng", ""], ["Zhou", "Kaixiong", ""], ["Hu", "Xia", ""]]}, {"id": "1906.08397", "submitter": "Dixin Luo", "authors": "Dixin Luo, Hongteng Xu and Lawrence Carin", "title": "Adversarial Self-Paced Learning for Mixture Models of Hawkes Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adversarial learning strategy for mixture models of Hawkes\nprocesses, leveraging data augmentation techniques of Hawkes process in the\nframework of self-paced learning. Instead of learning a mixture model directly\nfrom a set of event sequences drawn from different Hawkes processes, the\nproposed method learns the target model iteratively, which generates \"easy\"\nsequences and uses them in an adversarial and self-paced manner. In each\niteration, we first generate a set of augmented sequences from original\nobserved sequences. Based on the fact that an easy sample of the target model\ncan be an adversarial sample of a misspecified model, we apply a maximum\nlikelihood estimation with an adversarial self-paced mechanism. In this manner\nthe target model is updated, and the augmented sequences that obey it are\nemployed for the next learning iteration. Experimental results show that the\nproposed method outperforms traditional methods consistently.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 00:24:02 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Luo", "Dixin", ""], ["Xu", "Hongteng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.08399", "submitter": "Lalit Jain", "authors": "Tanner Fiez, Lalit Jain, Kevin Jamieson, Lillian Ratliff", "title": "Sequential Experimental Design for Transductive Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the transductive linear bandit problem: given a\nset of measurement vectors $\\mathcal{X}\\subset \\mathbb{R}^d$, a set of items\n$\\mathcal{Z}\\subset \\mathbb{R}^d$, a fixed confidence $\\delta$, and an unknown\nvector $\\theta^{\\ast}\\in \\mathbb{R}^d$, the goal is to infer\n$\\text{argmax}_{z\\in \\mathcal{Z}} z^\\top\\theta^\\ast$ with probability\n$1-\\delta$ by making as few sequentially chosen noisy measurements of the form\n$x^\\top\\theta^{\\ast}$ as possible. When $\\mathcal{X}=\\mathcal{Z}$, this setting\ngeneralizes linear bandits, and when $\\mathcal{X}$ is the standard basis\nvectors and $\\mathcal{Z}\\subset \\{0,1\\}^d$, combinatorial bandits. Such a\ntransductive setting naturally arises when the set of measurement vectors is\nlimited due to factors such as availability or cost. As an example, in drug\ndiscovery the compounds and dosages $\\mathcal{X}$ a practitioner may be willing\nto evaluate in the lab in vitro due to cost or safety reasons may differ vastly\nfrom those compounds and dosages $\\mathcal{Z}$ that can be safely administered\nto patients in vivo. Alternatively, in recommender systems for books, the set\nof books $\\mathcal{X}$ a user is queried about may be restricted to well known\nbest-sellers even though the goal might be to recommend more esoteric titles\n$\\mathcal{Z}$. In this paper, we provide instance-dependent lower bounds for\nthe transductive setting, an algorithm that matches these up to logarithmic\nfactors, and an evaluation. In particular, we provide the first non-asymptotic\nalgorithm for linear bandits that nearly achieves the information theoretic\nlower bound.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 00:38:06 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Fiez", "Tanner", ""], ["Jain", "Lalit", ""], ["Jamieson", "Kevin", ""], ["Ratliff", "Lillian", ""]]}, {"id": "1906.08412", "submitter": "Takuya Shimada", "authors": "Takuya Shimada, Shoichiro Yamaguchi, Kohei Hayashi, Sosuke Kobayashi", "title": "Data Interpolating Prediction: Alternative Interpretation of Mixup", "comments": "Presented at the 2nd Learning from Limited Labeled Data (LLD)\n  Workshop at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation by mixing samples, such as Mixup, has widely been used\ntypically for classification tasks. However, this strategy is not always\neffective due to the gap between augmented samples for training and original\nsamples for testing. This gap may prevent a classifier from learning the\noptimal decision boundary and increase the generalization error. To overcome\nthis problem, we propose an alternative framework called Data Interpolating\nPrediction (DIP). Unlike common data augmentations, we encapsulate the\nsample-mixing process in the hypothesis class of a classifier so that train and\ntest samples are treated equally. We derive the generalization bound and show\nthat DIP helps to reduce the original Rademacher complexity. Also, we\nempirically demonstrate that DIP can outperform existing Mixup.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 01:53:24 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shimada", "Takuya", ""], ["Yamaguchi", "Shoichiro", ""], ["Hayashi", "Kohei", ""], ["Kobayashi", "Sosuke", ""]]}, {"id": "1906.08416", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Brenden M. Lake", "title": "Improving the robustness of ImageNet classifiers using elements of human\n  visual cognition", "comments": "v2 involves reformating and stylistic changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the robustness properties of image recognition models equipped\nwith two features inspired by human vision, an explicit episodic memory and a\nshape bias, at the ImageNet scale. As reported in previous work, we show that\nan explicit episodic memory improves the robustness of image recognition models\nagainst small-norm adversarial perturbations under some threat models. It does\nnot, however, improve the robustness against more natural, and typically\nlarger, perturbations. Learning more robust features during training appears to\nbe necessary for robustness in this second sense. We show that features derived\nfrom a model that was encouraged to learn global, shape-based representations\n(Geirhos et al., 2019) do not only improve the robustness against natural\nperturbations, but when used in conjunction with an episodic memory, they also\nprovide additional robustness against adversarial perturbations. Finally, we\naddress three important design choices for the episodic memory: memory size,\ndimensionality of the memories and the retrieval method. We show that to make\nthe episodic memory more compact, it is preferable to reduce the number of\nmemories by clustering them, instead of reducing their dimensionality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 02:28:19 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:29:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Orhan", "A. Emin", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1906.08430", "submitter": "Gabriel Grand", "authors": "Gabriel Grand and Yonatan Belinkov", "title": "Adversarial Regularization for Visual Question Answering: Strengths,\n  Shortcomings, and Side Effects", "comments": "In Proceedings of the 2nd Workshop on Shortcomings in Vision and\n  Language (SiVL) at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) models have been shown to over-rely on\nlinguistic biases in VQA datasets, answering questions \"blindly\" without\nconsidering visual context. Adversarial regularization (AdvReg) aims to address\nthis issue via an adversary sub-network that encourages the main model to learn\na bias-free representation of the question. In this work, we investigate the\nstrengths and shortcomings of AdvReg with the goal of better understanding how\nit affects inference in VQA models. Despite achieving a new state-of-the-art on\nVQA-CP, we find that AdvReg yields several undesirable side-effects, including\nunstable gradients and sharply reduced performance on in-domain examples. We\ndemonstrate that gradual introduction of regularization during training helps\nto alleviate, but not completely solve, these issues. Through error analyses,\nwe observe that AdvReg improves generalization to binary questions, but impairs\nperformance on questions with heterogeneous answer distributions.\nQualitatively, we also find that regularized models tend to over-rely on visual\nfeatures, while ignoring important linguistic cues in the question. Our results\nsuggest that AdvReg requires further refinement before it can be considered a\nviable bias mitigation technique for VQA.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 03:28:09 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Grand", "Gabriel", ""], ["Belinkov", "Yonatan", ""]]}, {"id": "1906.08473", "submitter": "Satoshi Hara", "authors": "Satoshi Hara, Atsushi Nitanda, Takanori Maehara", "title": "Data Cleansing for Models Trained with SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data cleansing is a typical approach used to improve the accuracy of machine\nlearning models, which, however, requires extensive domain knowledge to\nidentify the influential instances that affect the models. In this paper, we\npropose an algorithm that can suggest influential instances without using any\ndomain knowledge. With the proposed method, users only need to inspect the\ninstances suggested by the algorithm, implying that users do not need extensive\nknowledge for this procedure, which enables even non-experts to conduct data\ncleansing and improve the model. The existing methods require the loss function\nto be convex and an optimal model to be obtained, which is not always the case\nin modern machine learning. To overcome these limitations, we propose a novel\napproach specifically designed for the models trained with stochastic gradient\ndescent (SGD). The proposed method infers the influential instances by\nretracing the steps of the SGD while incorporating intermediate models computed\nin each step. Through experiments, we demonstrate that the proposed method can\naccurately infer the influential instances. Moreover, we used MNIST and CIFAR10\nto show that the models can be effectively improved by removing the influential\ninstances suggested by the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 07:28:25 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Hara", "Satoshi", ""], ["Nitanda", "Atsushi", ""], ["Maehara", "Takanori", ""]]}, {"id": "1906.08482", "submitter": "Antonio H. Ribeiro", "authors": "Ant\\^onio H. Ribeiro and Koen Tiels and Luis A. Aguirre and Thomas B.\n  Sch\\\"on", "title": "Beyond exploding and vanishing gradients: analysing RNN training using\n  attractors and smoothness", "comments": "To appear in the Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS), 2020. PMLR: Volume 108.\n  This paper was previously titled \"The trade-off between long-term memory and\n  smoothness for recurrent networks\". The current version subsumes all previous\n  versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploding and vanishing gradient problem has been the major conceptual\nprinciple behind most architecture and training improvements in recurrent\nneural networks (RNNs) during the last decade. In this paper, we argue that\nthis principle, while powerful, might need some refinement to explain recent\ndevelopments. We refine the concept of exploding gradients by reformulating the\nproblem in terms of the cost function smoothness, which gives insight into\nhigher-order derivatives and the existence of regions with many close local\nminima. We also clarify the distinction between vanishing gradients and the\nneed for the RNN to learn attractors to fully use its expressive power. Through\nthe lens of these refinements, we shed new light on recent developments in the\nRNN field, namely stable RNN and unitary (or orthogonal) RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 07:53:31 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 17:10:26 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 13:55:39 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ribeiro", "Ant\u00f4nio H.", ""], ["Tiels", "Koen", ""], ["Aguirre", "Luis A.", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1906.08484", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang, Shaofeng H.-C. Jiang, Nisheeth K. Vishnoi", "title": "Coresets for Clustering with Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent work, [19] studied the following \"fair\" variants of classical\nclustering problems such as $k$-means and $k$-median: given a set of $n$ data\npoints in $\\mathbb{R}^d$ and a binary type associated to each data point, the\ngoal is to cluster the points while ensuring that the proportion of each type\nin each cluster is roughly the same as its underlying proportion. Subsequent\nwork has focused on either extending this setting to when each data point has\nmultiple, non-disjoint sensitive types such as race and gender [6], or to\naddress the problem that the clustering algorithms in the above work do not\nscale well. The main contribution of this paper is an approach to clustering\nwith fairness constraints that involve multiple, non-disjoint types, that is\nalso scalable. Our approach is based on novel constructions of coresets: for\nthe $k$-median objective, we construct an $\\varepsilon$-coreset of size\n$O(\\Gamma k^2 \\varepsilon^{-d})$ where $\\Gamma$ is the number of distinct\ncollections of groups that a point may belong to, and for the $k$-means\nobjective, we show how to construct an $\\varepsilon$-coreset of size $O(\\Gamma\nk^3\\varepsilon^{-d-1})$. The former result is the first known coreset\nconstruction for the fair clustering problem with the $k$-median objective, and\nthe latter result removes the dependence on the size of the full dataset as in\n[39] and generalizes it to multiple, non-disjoint types. Plugging our coresets\ninto existing algorithms for fair clustering such as [5] results in the fastest\nalgorithms for several cases. Empirically, we assess our approach over the\n\\textbf{Adult}, \\textbf{Bank}, \\textbf{Diabetes} and \\textbf{Athlete} dataset,\nand show that the coreset sizes are much smaller than the full dataset. We also\nachieve a speed-up to recent fair clustering algorithms [5,6] by incorporating\nour coreset construction.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:00:39 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 08:22:18 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 14:02:48 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2019 16:52:07 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Huang", "Lingxiao", ""], ["Jiang", "Shaofeng H. -C.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1906.08495", "submitter": "Meng Qu", "authors": "Meng Qu, Jian Tang", "title": "Probabilistic Logic Neural Networks for Reasoning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph reasoning, which aims at predicting the missing facts through\nreasoning with the observed facts, is critical to many applications. Such a\nproblem has been widely explored by traditional logic rule-based approaches and\nrecent knowledge graph embedding methods. A principled logic rule-based\napproach is the Markov Logic Network (MLN), which is able to leverage domain\nknowledge with first-order logic and meanwhile handle their uncertainty.\nHowever, the inference of MLNs is usually very difficult due to the complicated\ngraph structures. Different from MLNs, knowledge graph embedding methods (e.g.\nTransE, DistMult) learn effective entity and relation embeddings for reasoning,\nwhich are much more effective and efficient. However, they are unable to\nleverage domain knowledge. In this paper, we propose the probabilistic Logic\nNeural Network (pLogicNet), which combines the advantages of both methods. A\npLogicNet defines the joint distribution of all possible triplets by using a\nMarkov logic network with first-order logic, which can be efficiently optimized\nwith the variational EM algorithm. In the E-step, a knowledge graph embedding\nmodel is used for inferring the missing triplets, while in the M-step, the\nweights of logic rules are updated based on both the observed and predicted\ntriplets. Experiments on multiple knowledge graphs prove the effectiveness of\npLogicNet over many competitive baselines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:22:26 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 17:07:14 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Qu", "Meng", ""], ["Tang", "Jian", ""]]}, {"id": "1906.08496", "submitter": "Zhuang Yang", "authors": "Zhuang Yang, Zengping Chen, and Cheng Wang", "title": "Accelerating Mini-batch SARAH by Step Size Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StochAstic Recursive grAdient algoritHm (SARAH), originally proposed for\nconvex optimization and also proven to be effective for general nonconvex\noptimization, has received great attention due to its simple recursive\nframework for updating stochastic gradient estimates. The performance of SARAH\nsignificantly depends on the choice of step size sequence. However, SARAH and\nits variants often employ a best-tuned step size by mentor, which is time\nconsuming in practice. Motivated by this gap, we proposed a variant of the\nBarzilai-Borwein (BB) method, referred to as the Random Barzilai-Borwein (RBB)\nmethod, to calculate step size for SARAH in the mini-batch setting, thereby\nleading to a new SARAH method: MB-SARAH-RBB. We prove that MB-SARAH-RBB\nconverges linearly in expectation for strongly convex objective functions. We\nanalyze the complexity of MB-SARAH-RBB and show that it is better than the\noriginal method. Numerical experiments on standard data sets indicate that\nMB-SARAH-RBB outperforms or matches state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:22:48 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Yang", "Zhuang", ""], ["Chen", "Zengping", ""], ["Wang", "Cheng", ""]]}, {"id": "1906.08502", "submitter": "Simone Scardapane", "authors": "Indro Spinelli, Simone Scardapane, Michele Scarpiniti, Aurelio Uncini", "title": "Efficient data augmentation using graph imputation neural networks", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, data augmentation in the semi-supervised regime, where unlabeled\ndata vastly outnumbers labeled data, has received a considerable attention. In\nthis paper, we describe an efficient technique for this task, exploiting a\nrecent framework we proposed for missing data imputation called graph\nimputation neural network (GINN). The key idea is to leverage both supervised\nand unsupervised data to build a graph of similarities between points in the\ndataset. Then, we augment the dataset by severely damaging a few of the nodes\n(up to 80\\% of their features), and reconstructing them using a variation of\nGINN. On several benchmark datasets, we show that our method can obtain\nsignificant improvements compared to a fully-supervised model, and we are able\nto augment the datasets up to a factor of 10x. This points to the power of\ngraph-based neural networks to represent structural affinities in the samples\nfor tasks of data reconstruction and augmentation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:44:03 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Spinelli", "Indro", ""], ["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1906.08506", "submitter": "Johannes Hendriks", "authors": "J.N. Hendriks, A.W.T. Gregg, R.R. Jackson, C.M. Wensrich, A. Wills,\n  A.S. Tremsin, T. Shinohara, V. Luzin and O. Kirstein", "title": "Tomographic Reconstruction of Triaxial Strain Fields from Bragg-Edge\n  Neutron Imaging", "comments": null, "journal-ref": "Phys. Rev. Materials 3, 113803 (2019)", "doi": "10.1103/PhysRevMaterials.3.113803", "report-no": null, "categories": "physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a proof-of-concept demonstration of triaxial strain\ntomography from Bragg-edge neutron imaging within a three-dimensional sample.\nBragg-edge neutron transmission can provide high-resolution images of the\naverage through thickness strain within a polycrystalline material. This poses\nan associated rich tomography problem which seeks to reconstruct the full\ntriaxial strain field from these images. The presented demonstration is an\nimportant step towards solving this problem, and towards a technique capable of\nstudying the residual strain and stress within engineering components. A\nGaussian process based approach is used that ensures the reconstruction\nsatisfies equilibrium and known boundary conditions. This approach is\ndemonstrated experimentally on a non-trivial steel sample with use of the RADEN\ninstrument at the Japan Proton Accelerator Research Complex. Validation of the\nreconstruction is provided by comparison with conventional strain scans from\nthe KOWARI constant-wavelength strain diffractometer at the Australian Nuclear\nScience and Technology Organisation and simulations via finite element\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:56:21 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 09:49:50 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 14:15:56 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 22:01:21 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Hendriks", "J. N.", ""], ["Gregg", "A. W. T.", ""], ["Jackson", "R. R.", ""], ["Wensrich", "C. M.", ""], ["Wills", "A.", ""], ["Tremsin", "A. S.", ""], ["Shinohara", "T.", ""], ["Luzin", "V.", ""], ["Kirstein", "O.", ""]]}, {"id": "1906.08509", "submitter": "Xavier Fontaine", "authors": "Xavier Fontaine and Pierre Perrault and Michal Valko and Vianney\n  Perchet", "title": "Online A-Optimal Design and Active Linear Regression", "comments": "29 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in this paper the problem of optimal experiment design where a\ndecision maker can choose which points to sample to obtain an estimate\n$\\hat{\\beta}$ of the hidden parameter $\\beta^{\\star}$ of an underlying linear\nmodel. The key challenge of this work lies in the heteroscedasticity assumption\nthat we make, meaning that each covariate has a different and unknown variance.\nThe goal of the decision maker is then to figure out on the fly the optimal way\nto allocate the total budget of $T$ samples between covariates, as sampling\nseveral times a specific one will reduce the variance of the estimated model\naround it (but at the cost of a possible higher variance elsewhere). By trying\nto minimize the $\\ell^2$-loss $\\mathbb{E}\n[\\lVert\\hat{\\beta}-\\beta^{\\star}\\rVert^2]$ the decision maker is actually\nminimizing the trace of the covariance matrix of the problem, which corresponds\nthen to online A-optimal design. Combining techniques from bandit and convex\noptimization we propose a new active sampling algorithm and we compare it with\nexisting ones. We provide theoretical guarantees of this algorithm in different\nsettings, including a $\\mathcal{O}(T^{-2})$ regret bound in the case where the\ncovariates form a basis of the feature space, generalizing and improving\nexisting results. Numerical experiments validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:04:36 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 20:48:20 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fontaine", "Xavier", ""], ["Perrault", "Pierre", ""], ["Valko", "Michal", ""], ["Perchet", "Vianney", ""]]}, {"id": "1906.08510", "submitter": "Canchen Li", "authors": "Canchen Li", "title": "Preprocessing Methods and Pipelines of Data Mining: An Overview", "comments": "7 pages, 3 figures, IEEE conference format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining is about obtaining new knowledge from existing datasets. However,\nthe data in the existing datasets can be scattered, noisy, and even incomplete.\nAlthough lots of effort is spent on developing or fine-tuning data mining\nmodels to make them more robust to the noise of the input data, their qualities\nstill strongly depend on the quality of it. The article starts with an overview\nof the data mining pipeline, where the procedures in a data mining task are\nbriefly introduced. Then an overview of the data preprocessing techniques which\nare categorized as the data cleaning, data transformation and data\npreprocessing is given. Detailed preprocessing methods, as well as their\ninfluenced on the data mining models, are covered in this article.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:11:04 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Li", "Canchen", ""]]}, {"id": "1906.08512", "submitter": "Jong Wook Kim", "authors": "Jong Wook Kim, Juan Pablo Bello", "title": "Adversarial Learning for Improved Onsets and Frames Music Transcription", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic music transcription is considered to be one of the hardest problems\nin music information retrieval, yet recent deep learning approaches have\nachieved substantial improvements on transcription performance. These\napproaches commonly employ supervised learning models that predict various\ntime-frequency representations, by minimizing element-wise losses such as the\ncross entropy function. However, applying the loss in this manner assumes\nconditional independence of each label given the input, and thus cannot\naccurately express inter-label dependencies. To address this issue, we\nintroduce an adversarial training scheme that operates directly on the\ntime-frequency representations and makes the output distribution closer to the\nground-truth. Through adversarial learning, we achieve a consistent improvement\nin both frame-level and note-level metrics over Onsets and Frames, a\nstate-of-the-art music transcription model. Our results show that adversarial\nlearning can significantly reduce the error rate while increasing the\nconfidence of the model estimations. Our approach is generic and applicable to\nany transcription model based on multi-label predictions, which are very common\nin music signal analysis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:17:36 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Kim", "Jong Wook", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1906.08524", "submitter": "Francis Bach", "authors": "Francis Bach (SIERRA)", "title": "Max-Plus Matching Pursuit for Deterministic Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deterministic Markov decision processes (MDPs) and apply max-plus\nalgebra tools to approximate the value iteration algorithm by a\nsmaller-dimensional iteration based on a representation on dictionaries of\nvalue functions. The setup naturally leads to novel theoretical results which\nare simply formulated due to the max-plus algebra structure. For example, when\nconsidering a fixed (non adaptive) finite basis, the computational complexity\nof approximating the optimal value function is not directly related to the\nnumber of states, but to notions of covering numbers of the state space. In\norder to break the curse of dimensionality in factored state-spaces, we\nconsider adaptive basis that can adapt to particular problems leading to an\nalgorithm similar to matching pursuit from signal processing. They currently\ncome with no theoretical guarantees but work empirically well on simple\ndeterministic MDPs derived from low-dimensional continuous control problems. We\nfocus primarily on deterministic MDPs but note that the framework can be\napplied to all MDPs by considering measure-based formulations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:44:48 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Bach", "Francis", "", "SIERRA"]]}, {"id": "1906.08528", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro", "title": "Analyzing and Storing Network Intrusion Detection Data using Bayesian\n  Coresets: A Preliminary Study in Offline and Streaming Settings", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we offer a preliminary study of the application of Bayesian\ncoresets to network security data. Network intrusion detection is a field that\ncould take advantage of Bayesian machine learning in modelling uncertainty and\nmanaging streaming data; however, the large size of the data sets often hinders\nthe use of Bayesian learning methods based on MCMC. Limiting the amount of\nuseful data is a central problem in a field like network traffic analysis,\nwhere large amount of redundant data can be generated very quickly via packet\ncollection. Reducing the number of samples would not only make learning more\nfeasible, but would also contribute to reduce the need for memory and storage.\nWe explore here the use of Bayesian coresets, a technique that reduces the\namount of data samples while guaranteeing the learning of an accurate posterior\ndistribution using Bayesian learning. We analyze how Bayesian coresets affect\nthe accuracy of learned models, and how time-space requirements are traded-off,\nboth in a static scenario and in a streaming scenario.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:53:46 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zennaro", "Fabio Massimo", ""]]}, {"id": "1906.08540", "submitter": "Mokhtar Z. Alaya", "authors": "Mokhtar Z. Alaya, Maxime B\\'erar, Gilles Gasso, Alain Rakotomamonjy", "title": "Screening Sinkhorn Algorithm for Regularized Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce in this paper a novel strategy for efficiently approximating the\nSinkhorn distance between two discrete measures. After identifying neglectable\ncomponents of the dual solution of the regularized Sinkhorn problem, we propose\nto screen those components by directly setting them at that value before\nentering the Sinkhorn problem. This allows us to solve a smaller Sinkhorn\nproblem while ensuring approximation with provable guarantees. More formally,\nthe approach is based on a new formulation of dual of Sinkhorn divergence\nproblem and on the KKT optimality conditions of this problem, which enable\nidentification of dual components to be screened. This new analysis leads to\nthe Screenkhorn algorithm. We illustrate the efficiency of Screenkhorn on\ncomplex tasks such as dimensionality reduction and domain adaptation involving\nregularized optimal transport.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:25:36 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:32:09 GMT"}, {"version": "v3", "created": "Sat, 18 Jan 2020 07:15:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Alaya", "Mokhtar Z.", ""], ["B\u00e9rar", "Maxime", ""], ["Gasso", "Gilles", ""], ["Rakotomamonjy", "Alain", ""]]}, {"id": "1906.08541", "submitter": "Roy Abel", "authors": "Roy Abel, Yoram Louzoun", "title": "Regional based query in graph active learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution networks (GCN) have emerged as the leading method to\nclassify node classes in networks, and have reached the highest accuracy in\nmultiple node classification tasks. In the absence of available tagged samples,\nactive learning methods have been developed to obtain the highest accuracy\nusing the minimal number of queries to an oracle. The current best active\nlearning methods use the sample class uncertainty as selection criteria.\nHowever, in graph based classification, the class of each node is often related\nto the class of its neighbors. As such, the uncertainty in the class of a\nnode's neighbor may be a more appropriate selection criterion. We here propose\ntwo such criteria, one extending the classical uncertainty measure, and the\nother extending the page-rank algorithm. We show that the latter is optimal\nwhen the fraction of tagged nodes is low, and when this fraction grows to one\nover the average degree, the regional uncertainty performs better than all\nexisting methods. While we have tested this methods on graphs, such methods can\nbe extended to any classification problem, where a distance metrics can be\ndefined between the input samples.\n  All the code used can be accessed at : https://github.com/louzounlab/graph-al\n  All the datasets used can be accessed at :\nhttps://github.com/louzounlab/DataSets\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:28:11 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Abel", "Roy", ""], ["Louzoun", "Yoram", ""]]}, {"id": "1906.08556", "submitter": "Ville Vestman", "authors": "Ville Vestman, Kong Aik Lee, Tomi H. Kinnunen, Takafumi Koshinaka", "title": "Unleashing the Unused Potential of I-Vectors Enabled by GPU Acceleration", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker embeddings are continuous-value vector representations that allow\neasy comparison between voices of speakers with simple geometric operations.\nAmong others, i-vector and x-vector have emerged as the mainstream methods for\nspeaker embedding. In this paper, we illustrate the use of modern computation\nplatform to harness the benefit of GPU acceleration for i-vector extraction. In\nparticular, we achieve an acceleration of 3000 times in frame posterior\ncomputation compared to real time and 25 times in training the i-vector\nextractor compared to the CPU baseline from Kaldi toolkit. This significant\nspeed-up allows the exploration of ideas that were hitherto impossible. In\nparticular, we show that it is beneficial to update the universal background\nmodel (UBM) and re-compute frame alignments while training the i-vector\nextractor. Additionally, we are able to study different variations of i-vector\nextractors more rigorously than before. In this process, we reveal some\nundocumented details of Kaldi's i-vector extractor and show that it outperforms\nthe standard formulation by a margin of 1 to 2% when tested with VoxCeleb\nspeaker verification protocol. All of our findings are asserted by ensemble\naveraging the results from multiple runs with random start.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:09:39 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Vestman", "Ville", ""], ["Lee", "Kong Aik", ""], ["Kinnunen", "Tomi H.", ""], ["Koshinaka", "Takafumi", ""]]}, {"id": "1906.08587", "submitter": "Nikolay Nikitin", "authors": "Pavel Vychuzhanin, Nikolay O. Nikitin, Anna V. Kalyuzhnaya", "title": "REBEC: Robust Evolutionary-based Calibration Approach for the Numerical\n  Wind Wave Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptation of numerical wind wave models to the local time-spatial\nconditions is a problem that can be solved by using various calibration\ntechniques. However, the obtained sets of physical parameters become over-tuned\nto specific events if there is a lack of observations. In this paper, we\npropose a robust evolutionary calibration approach that allows to build the\nstochastic ensemble of perturbed models and use it to achieve the trade-off\nbetween quality and robustness of the target model. The implemented robust\nensemble-based evolutionary calibration (REBEC) approach was compared to the\nbaseline SPEA2 algorithm in a set of experiments with the SWAN wind wave model\nconfiguration for the Kara Sea domain. Provided metrics for the set of\nscenarios confirm the effectiveness of the REBEC approach for the majority of\ncalibration scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:25:19 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Vychuzhanin", "Pavel", ""], ["Nikitin", "Nikolay O.", ""], ["Kalyuzhnaya", "Anna V.", ""]]}, {"id": "1906.08591", "submitter": "Chong Liu", "authors": "Chong Liu and Yu-Xiang Wang", "title": "Doubly Robust Crowdsourcing", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale labeled datasets are the indispensable fuel that ignites the AI\nrevolution as we see today. Most such datasets are constructed using\ncrowdsourcing services such as Amazon Mechanical Turk which provides noisy\nlabels from non-experts at a fair price. The sheer size of such datasets\nmandates that it is only feasible to collect a few labels per data point. We\nformulate the problem of test-time label aggregation as a statistical\nestimation problem of inferring the expected voting score in an ideal world\nwhere all workers label all items. By imitating workers with supervised\nlearners and using them in a doubly robust estimation framework, we prove that\nthe variance of estimation can be substantially reduced, even if the learner is\na poor approximation. Synthetic and real-world experiments show that by\ncombining the doubly robust approach with adaptive worker/item selection, we\noften need as low as 0.1 labels per data point to achieve nearly the same\naccuracy as in the ideal world where all workers label all data points.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 18:12:40 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Liu", "Chong", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1906.08611", "submitter": "Nathan Kallus", "authors": "Nathan Kallus", "title": "More Efficient Policy Learning via Optimal Retargeting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy learning can be used to extract individualized treatment regimes from\nobservational data in healthcare, civics, e-commerce, and beyond. One big\nhurdle to policy learning is a commonplace lack of overlap in the data for\ndifferent actions, which can lead to unwieldy policy evaluation and poorly\nperforming learned policies. We study a solution to this problem based on\nretargeting, that is, changing the population on which policies are optimized.\nWe first argue that at the population level, retargeting may induce little to\nno bias. We then characterize the optimal reference policy and retargeting\nweights in both binary-action and multi-action settings. We do this in terms of\nthe asymptotic efficient estimation variance of the new learning objective.\nExtensive empirical results in a simulation study and a case study of\npersonalized job counseling demonstrate that retargeting is a fairly easy way\nto significantly improve any policy learning procedure applied to observational\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:40:59 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 00:30:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Kallus", "Nathan", ""]]}, {"id": "1906.08619", "submitter": "David Ruhe", "authors": "David Ruhe, Giovanni Cin\\`a, Michele Tonutti, Daan de Bruin, Paul\n  Elbers", "title": "Bayesian Modelling in Practice: Using Uncertainty to Improve\n  Trustworthiness in Medical Applications", "comments": "Presented at AISG @ ICML2019:\n  https://aiforsocialgood.github.io/icml2019/index.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Intensive Care Unit (ICU) is a hospital department where machine learning\nhas the potential to provide valuable assistance in clinical decision making.\nClassical machine learning models usually only provide point-estimates and no\nuncertainty of predictions. In practice, uncertain predictions should be\npresented to doctors with extra care in order to prevent potentially\ncatastrophic treatment decisions. In this work we show how Bayesian modelling\nand the predictive uncertainty that it provides can be used to mitigate risk of\nmisguided prediction and to detect out-of-domain examples in a medical setting.\nWe derive analytically a bound on the prediction loss with respect to\npredictive uncertainty. The bound shows that uncertainty can mitigate loss.\nFurthermore, we apply a Bayesian Neural Network to the MIMIC-III dataset,\npredicting risk of mortality of ICU patients. Our empirical results show that\nuncertainty can indeed prevent potential errors and reliably identifies\nout-of-domain patients. These results suggest that Bayesian predictive\nuncertainty can greatly improve trustworthiness of machine learning models in\nhigh-risk settings such as the ICU.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:51:07 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Ruhe", "David", ""], ["Cin\u00e0", "Giovanni", ""], ["Tonutti", "Michele", ""], ["de Bruin", "Daan", ""], ["Elbers", "Paul", ""]]}, {"id": "1906.08628", "submitter": "Guo-Jun Qi", "authors": "Guo-Jun Qi, Liheng Zhang, Xiao Wang", "title": "Learning Generalized Transformation Equivariant Representations via\n  Autoencoding Transformations", "comments": "arXiv admin note: text overlap with arXiv:1903.10863", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformation Equivariant Representations (TERs) aim to capture the\nintrinsic visual structures that equivary to various transformations by\nexpanding the notion of {\\em translation} equivariance underlying the success\nof Convolutional Neural Networks (CNNs). For this purpose, we present both\ndeterministic AutoEncoding Transformations (AET) and probabilistic AutoEncoding\nVariational Transformations (AVT) models to learn visual representations from\ngeneric groups of transformations. While the AET is trained by directly\ndecoding the transformations from the learned representations, the AVT is\ntrained by maximizing the joint mutual information between the learned\nrepresentation and transformations. This results in Generalized TERs (GTERs)\nequivariant against transformations in a more general fashion by capturing\ncomplex patterns of visual structures beyond the conventional linear\nequivariance under a transformation group. The presented approach can be\nextended to (semi-)supervised models by jointly maximizing the mutual\ninformation of the learned representation with both labels and transformations.\nExperiments demonstrate the proposed models outperform the state-of-the-art\nmodels in both unsupervised and (semi-)supervised tasks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 06:17:56 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 04:50:28 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 16:27:59 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Qi", "Guo-Jun", ""], ["Zhang", "Liheng", ""], ["Wang", "Xiao", ""]]}, {"id": "1906.08632", "submitter": "Sebastian Goldt", "authors": "Sebastian Goldt, Madhu S. Advani, Andrew M. Saxe, Florent Krzakala,\n  Lenka Zdeborov\\'a", "title": "Dynamics of stochastic gradient descent for two-layer neural networks in\n  the teacher-student setup", "comments": "9 pages + references + supplemental material. Oral presentation at\n  NeurIPS 2019. arXiv admin note: substantial text overlap with\n  arXiv:1901.09085", "journal-ref": "Advances in Neural Information Processing Systems, 6979-6989\n  (2019)", "doi": "10.1088/1742-5468/abc61e", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve stellar generalisation even when they have\nenough parameters to easily fit all their training data. We study this\nphenomenon by analysing the dynamics and the performance of over-parameterised\ntwo-layer neural networks in the teacher-student setup, where one network, the\nstudent, is trained on data generated by another network, called the teacher.\nWe show how the dynamics of stochastic gradient descent (SGD) is captured by a\nset of differential equations and prove that this description is asymptotically\nexact in the limit of large inputs. Using this framework, we calculate the\nfinal generalisation error of student networks that have more parameters than\ntheir teachers. We find that the final generalisation error of the student\nincreases with network size when training only the first layer, but stays\nconstant or even decreases with size when training both layers. We show that\nthese different behaviours have their root in the different solutions SGD finds\nfor different activation functions. Our results indicate that achieving good\ngeneralisation in neural networks goes beyond the properties of SGD alone and\ndepends on the interplay of at least the algorithm, the model architecture, and\nthe data set.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 21:02:06 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 14:37:05 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Goldt", "Sebastian", ""], ["Advani", "Madhu S.", ""], ["Saxe", "Andrew M.", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1906.08635", "submitter": "Angelica I. Aviles-Rivero", "authors": "Angelica I. Aviles-Rivero, Nicolas Papadakis, Ruoteng Li, Samar M\n  Alsaleh, Robby T Tan, Carola-Bibiane Schonlieb", "title": "When Labelled Data Hurts: Deep Semi-Supervised Classification with the\n  Graph 1-Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of classifying when a significantly reduced amount of\nlabelled data is available. This problem is of a great interest, in several\nreal-world problems, as obtaining large amounts of labelled data is expensive\nand time consuming. We present a novel semi-supervised framework for\nmulti-class classification that is based on the non-smooth $\\ell_1$ norm of the\nnormalised graph 1-Laplacian. Our transductive framework is framed under a\nnovel functional with carefully selected class priors - that enforces a\nsufficiently smooth solution and strengthens the intrinsic relation between the\nlabelled and unlabelled data. We provide theoretical results of our new\noptimisation model and show its connections with deep learning for handling\nlarge-scale datasets. We demonstrate through extensive experimental results on\nlarge datasets - CIFAR-10, CIFAR-100 and ChestX-Ray14 - that our method\noutperforms classic methods and readily competes with recent deep-learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:04:39 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 20:27:11 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 20:29:18 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Aviles-Rivero", "Angelica I.", ""], ["Papadakis", "Nicolas", ""], ["Li", "Ruoteng", ""], ["Alsaleh", "Samar M", ""], ["Tan", "Robby T", ""], ["Schonlieb", "Carola-Bibiane", ""]]}, {"id": "1906.08637", "submitter": "Joseph Bethge", "authors": "Joseph Bethge, Haojin Yang, Marvin Bornstein, Christoph Meinel", "title": "Back to Simplicity: How to Train Accurate BNNs from Scratch?", "comments": "Supplementary Material can be found\n  https://owncloud.hpi.de/s/1jrAUnqRAfg0TXH. arXiv admin note: substantial text\n  overlap with arXiv:1812.01965", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) show promising progress in reducing\ncomputational and memory costs but suffer from substantial accuracy degradation\ncompared to their real-valued counterparts on large-scale datasets, e.g.,\nImageNet. Previous work mainly focused on reducing quantization errors of\nweights and activations, whereby a series of approximation methods and\nsophisticated training tricks have been proposed. In this work, we make several\nobservations that challenge conventional wisdom. We revisit some commonly used\ntechniques, such as scaling factors and custom gradients, and show that these\nmethods are not crucial in training well-performing BNNs. On the contrary, we\nsuggest several design principles for BNNs based on the insights learned and\ndemonstrate that highly accurate BNNs can be trained from scratch with a simple\ntraining strategy. We propose a new BNN architecture BinaryDenseNet, which\nsignificantly surpasses all existing 1-bit CNNs on ImageNet without tricks. In\nour experiments, BinaryDenseNet achieves 18.6% and 7.6% relative improvement\nover the well-known XNOR-Network and the current state-of-the-art Bi-Real Net\nin terms of top-1 accuracy on ImageNet, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 10:32:45 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Bethge", "Joseph", ""], ["Yang", "Haojin", ""], ["Bornstein", "Marvin", ""], ["Meinel", "Christoph", ""]]}, {"id": "1906.08649", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Jimmy Ba", "title": "Exploring Model-based Planning with Policy Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) with model-predictive control or\nonline planning has shown great potential for locomotion control tasks in terms\nof both sample efficiency and asymptotic performance. Despite their initial\nsuccesses, the existing planning methods search from candidate sequences\nrandomly generated in the action space, which is inefficient in complex\nhigh-dimensional environments. In this paper, we propose a novel MBRL\nalgorithm, model-based policy planning (POPLIN), that combines policy networks\nwith online planning. More specifically, we formulate action planning at each\ntime-step as an optimization problem using neural networks. We experiment with\nboth optimization w.r.t. the action sequences initialized from the policy\nnetwork, and also online optimization directly w.r.t. the parameters of the\npolicy network. We show that POPLIN obtains state-of-the-art performance in the\nMuJoCo benchmarking environments, being about 3x more sample efficient than the\nstate-of-the-art algorithms, such as PETS, TD3 and SAC. To explain the\neffectiveness of our algorithm, we show that the optimization surface in\nparameter space is smoother than in action space. Further more, we found the\ndistilled policy network can be effectively applied without the expansive model\npredictive control during test time for some environments such as Cheetah. Code\nis released in https://github.com/WilsonWangTHU/POPLIN.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:13:12 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Wang", "Tingwu", ""], ["Ba", "Jimmy", ""]]}, {"id": "1906.08652", "submitter": "Charles Marx", "authors": "Charles T. Marx, Richard Lanas Phillips, Sorelle A. Friedler, Carlos\n  Scheidegger, Suresh Venkatasubramanian", "title": "Disentangling Influence: Using Disentangled Representations to Audit\n  Model Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to audit complex and black box models, there has been\nextensive research on quantifying how data features influence model\npredictions. Feature influence can be direct (a direct influence on model\noutcomes) and indirect (model outcomes are influenced via proxy features).\nFeature influence can also be expressed in aggregate over the training or test\ndata or locally with respect to a single point. Current research has typically\nfocused on one of each of these dimensions. In this paper, we develop\ndisentangled influence audits, a procedure to audit the indirect influence of\nfeatures. Specifically, we show that disentangled representations provide a\nmechanism to identify proxy features in the dataset, while allowing an explicit\ncomputation of feature influence on either individual outcomes or\naggregate-level outcomes. We show through both theory and experiments that\ndisentangled influence audits can both detect proxy features and show, for each\nindividual or in aggregate, which of these proxy features affects the\nclassifier being audited the most. In this respect, our method is more powerful\nthan existing methods for ascertaining feature influence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:15:38 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Marx", "Charles T.", ""], ["Phillips", "Richard Lanas", ""], ["Friedler", "Sorelle A.", ""], ["Scheidegger", "Carlos", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1906.08654", "submitter": "Eran Malach", "authors": "Alon Brutzkus, Amit Daniely, Eran Malach", "title": "ID3 Learns Juntas for Smoothed Product Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there are many attempts to understand popular heuristics. An\nexample of such a heuristic algorithm is the ID3 algorithm for learning\ndecision trees. This algorithm is commonly used in practice, but there are very\nfew theoretical works studying its behavior. In this paper, we analyze the ID3\nalgorithm, when the target function is a $k$-Junta, a function that depends on\n$k$ out of $n$ variables of the input. We prove that when $k = \\log n$, the ID3\nalgorithm learns in polynomial time $k$-Juntas, in the smoothed analysis model\nof Kalai & Teng. That is, we show a learnability result when the observed\ndistribution is a \"noisy\" variant of the original distribution.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:17:33 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Brutzkus", "Alon", ""], ["Daniely", "Amit", ""], ["Malach", "Eran", ""]]}, {"id": "1906.08656", "submitter": "Haoyu Zhao", "authors": "Haoyu Zhao, Wei Chen", "title": "Stochastic One-Sided Full-Information Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the stochastic version of the one-sided full\ninformation bandit problem, where we have $K$ arms $[K] = \\{1, 2, \\ldots, K\\}$,\nand playing arm $i$ would gain reward from an unknown distribution for arm $i$\nwhile obtaining reward feedback for all arms $j \\ge i$. One-sided full\ninformation bandit can model the online repeated second-price auctions, where\nthe auctioneer could select the reserved price in each round and the bidders\nonly reveal their bids when their bids are higher than the reserved price. In\nthis paper, we present an elimination-based algorithm to solve the problem. Our\nelimination based algorithm achieves distribution independent regret upper\nbound $O(\\sqrt{T\\cdot\\log (TK)})$, and distribution dependent bound $O((\\log T\n+ \\log K)f(\\Delta))$, where $T$ is the time horizon, $\\Delta$ is a vector of\ngaps between the mean reward of arms and the mean reward of the best arm, and\n$f(\\Delta)$ is a formula depending on the gap vector that we will specify in\ndetail. Our algorithm has the best theoretical regret upper bound so far. We\nalso validate our algorithm empirically against other possible alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:19:28 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zhao", "Haoyu", ""], ["Chen", "Wei", ""]]}, {"id": "1906.08707", "submitter": "Brandon Amos", "authors": "Brandon Amos, Vladlen Koltun, J. Zico Kolter", "title": "The Limited Multi-Label Projection Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Limited Multi-Label (LML) projection layer as a new primitive\noperation for end-to-end learning systems. The LML layer provides a\nprobabilistic way of modeling multi-label predictions limited to having exactly\nk labels. We derive efficient forward and backward passes for this layer and\nshow how the layer can be used to optimize the top-k recall for multi-label\ntasks with incomplete label information. We evaluate LML layers on top-k\nCIFAR-100 classification and scene graph generation. We show that LML layers\nadd a negligible amount of computational overhead, strictly improve the model's\nrepresentational capacity, and improve accuracy. We also revisit the truncated\ntop-k entropy method as a competitive baseline for top-k classification.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:51:24 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 18:24:49 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 17:53:34 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Amos", "Brandon", ""], ["Koltun", "Vladlen", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1906.08714", "submitter": "Jin-mo Choi", "authors": "Jin-mo Choi", "title": "Clustering and Classification Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will describe a network architecture that demonstrates high\nperformance on various sizes of datasets. To do this, we will perform an\narchitecture search by dividing the fully connected layer into three levels in\nthe existing network architecture. The first step is to learn existing CNN\nlayer and existing fully connected layer for 1 epoch. The second step is\nclustering similar classes by applying L1 distance to the result of Softmax.\nThe third step is to reclassify using clustering class masks. We accomplished\nthe result of state-of-the-art by performing the above three steps sequentially\nor recursively. The technology recorded an error of 11.56% on Cifar-100.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:59:22 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Choi", "Jin-mo", ""]]}, {"id": "1906.08720", "submitter": "Nataly Brukhim", "authors": "Naman Agarwal, Nataly Brukhim, Elad Hazan, Zhou Lu", "title": "Boosting for Control of Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of how to aggregate controllers for dynamical systems\nin order to improve their performance. To this end, we propose a framework of\nboosting for online control. Our main result is an efficient boosting algorithm\nthat combines weak controllers into a provably more accurate one. Empirical\nevaluation on a host of control settings supports our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:05:23 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 18:32:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Agarwal", "Naman", ""], ["Brukhim", "Nataly", ""], ["Hazan", "Elad", ""], ["Lu", "Zhou", ""]]}, {"id": "1906.08743", "submitter": "David G\\\"uera", "authors": "David G\\\"uera and Sriram Baireddy and Paolo Bestagini and Stefano\n  Tubaro and Edward J. Delp", "title": "We Need No Pixels: Video Manipulation Detection Using Stream Descriptors", "comments": "7 pages, 6 figures, presented at the ICML 2019 Worksop on Synthetic\n  Realities: Deep Learning for Detecting AudioVisual Fakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating video content is easier than ever. Due to the misuse potential\nof manipulated content, multiple detection techniques that analyze the pixel\ndata from the videos have been proposed. However, clever manipulators should\nalso carefully forge the metadata and auxiliary header information, which is\nharder to do for videos than images. In this paper, we propose to identify\nforged videos by analyzing their multimedia stream descriptors with simple\nbinary classifiers, completely avoiding the pixel space. Using well-known\ndatasets, our results show that this scalable approach can achieve a high\nmanipulation detection score if the manipulators have not done a careful data\nsanitization of the multimedia stream descriptors.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:42:06 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["G\u00fcera", "David", ""], ["Baireddy", "Sriram", ""], ["Bestagini", "Paolo", ""], ["Tubaro", "Stefano", ""], ["Delp", "Edward J.", ""]]}, {"id": "1906.08746", "submitter": "Le Thanh Nguyen-Meidine", "authors": "Le Thanh Nguyen-Meidine, Eric Granger, Madhu Kiran, Louis-Antoine\n  Blais-Morin, Marco Pedersoli", "title": "Progressive Gradient Pruning for Classification, Detection and\n  DomainAdaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks (NNs) have achievedstate-of-the-art accuracy in\nmany visual recognition tasks,the growing computational complexity and energy\ncon-sumption of networks remains an issue, especially for ap-plications on\nplatforms with limited resources and requir-ing real-time processing. Filter\npruning techniques haverecently shown promising results for the compression\nandacceleration of convolutional NNs (CNNs). However, thesetechniques involve\nnumerous steps and complex optimisa-tions because some only prune after\ntraining CNNs, whileothers prune from scratch during training by\nintegratingsparsity constraints or modifying the loss function.In this paper we\npropose a new Progressive GradientPruning (PGP) technique for iterative filter\npruning dur-ing training. In contrast to previous progressive\npruningtechniques, it relies on a novel filter selection criterion thatmeasures\nthe change in filter weights, uses a new hard andsoft pruning strategy and\neffectively adapts momentum ten-sors during the backward propagation pass.\nExperimentalresults obtained after training various CNNs on image datafor\nclassification, object detection and domain adaptationbenchmarks indicate that\nthe PGP technique can achievea better trade-off between classification accuracy\nand net-work (time and memory) complexity than PSFP and otherstate-of-the-art\nfilter pruning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:46:16 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 13:46:47 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 15:27:16 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 18:42:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Nguyen-Meidine", "Le Thanh", ""], ["Granger", "Eric", ""], ["Kiran", "Madhu", ""], ["Blais-Morin", "Louis-Antoine", ""], ["Pedersoli", "Marco", ""]]}, {"id": "1906.08763", "submitter": "Gauri Jagatap", "authors": "Gauri Jagatap, Chinmay Hegde", "title": "Algorithmic Guarantees for Inverse Imaging with Untrained Network Priors", "comments": "NeurIPS 2019 version with few modifications", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks as image priors have been recently introduced for\nproblems such as denoising, super-resolution and inpainting with promising\nperformance gains over hand-crafted image priors such as sparsity and low-rank.\nUnlike learned generative priors they do not require any training over large\ndatasets. However, few theoretical guarantees exist in the scope of using\nuntrained neural network priors for inverse imaging problems. We explore new\napplications and theory for untrained neural network priors. Specifically, we\nconsider the problem of solving linear inverse problems, such as compressive\nsensing, as well as non-linear problems, such as compressive phase retrieval.\nWe model images to lie in the range of an untrained deep generative network\nwith a fixed seed. We further present a projected gradient descent scheme that\ncan be used for both compressive sensing and phase retrieval and provide\nrigorous theoretical guarantees for its convergence. We also show both\ntheoretically as well as empirically that with deep network priors, one can\nachieve better compression rates for the same image quality compared to hand\ncrafted priors.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 17:34:49 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 18:29:58 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jagatap", "Gauri", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1906.08770", "submitter": "Pere Gim\\'enez-Febrer", "authors": "Pere Gim\\'enez-Febrer, Alba Pag\\`es-Zamora, and Georgios B. Giannakis", "title": "Generalization error bounds for kernel matrix completion and\n  extrapolation", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.2970306", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior information can be incorporated in matrix completion to improve\nestimation accuracy and extrapolate the missing entries. Reproducing kernel\nHilbert spaces provide tools to leverage the said prior information, and derive\nmore reliable algorithms. This paper analyzes the generalization error of such\napproaches, and presents numerical tests confirming the theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 17:53:06 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Gim\u00e9nez-Febrer", "Pere", ""], ["Pag\u00e8s-Zamora", "Alba", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1906.08771", "submitter": "Joseph K J", "authors": "K J Joseph, Vamshi Teja R, Krishnakant Singh, Vineeth N\n  Balasubramanian", "title": "Submodular Batch Selection for Training Deep Neural Networks", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mini-batch gradient descent based methods are the de facto algorithms for\ntraining neural network architectures today. We introduce a mini-batch\nselection strategy based on submodular function maximization. Our novel\nsubmodular formulation captures the informativeness of each sample and\ndiversity of the whole subset. We design an efficient, greedy algorithm which\ncan give high-quality solutions to this NP-hard combinatorial optimization\nproblem. Our extensive experiments on standard datasets show that the deep\nmodels trained using the proposed batch selection strategy provide better\ngeneralization than Stochastic Gradient Descent as well as a popular baseline\nsampling strategy across different learning rates, batch sizes, and distance\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 17:53:15 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Joseph", "K J", ""], ["R", "Vamshi Teja", ""], ["Singh", "Krishnakant", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1906.08776", "submitter": "Valentina Fedorova", "authors": "Valentina Fedorova, Gleb Gusev, Pavel Serdyukov", "title": "Latent Distribution Assumption for Unbiased and Consistent Consensus\n  Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of aggregation noisy labels. Usually, it is solved by\nproposing a stochastic model for the process of generating noisy labels and\nthen estimating the model parameters using the observed noisy labels. A\ntraditional assumption underlying previously introduced generative models is\nthat each object has one latent true label. In contrast, we introduce a novel\nlatent distribution assumption, implying that a unique true label for an object\nmight not exist, but rather each object might have a specific distribution\ngenerating a latent subjective label each time the object is observed. Our\nexperiments showed that the novel assumption is more suitable for difficult\ntasks, when there is an ambiguity in choosing a \"true\" label for certain\nobjects.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:14:03 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Fedorova", "Valentina", ""], ["Gusev", "Gleb", ""], ["Serdyukov", "Pavel", ""]]}, {"id": "1906.08792", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh, Jaroslaw Sydir, Meryem Simsek, Hosein Nikopour,\n  Shilpa Talwar", "title": "When Multiple Agents Learn to Schedule: A Distributed Radio Resource\n  Management Framework", "comments": "Submitted to IEEE Wireless Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference among concurrent transmissions in a wireless network is a key\nfactor limiting the system performance. One way to alleviate this problem is to\nmanage the radio resources in order to maximize either the average or the\nworst-case performance. However, joint consideration of both metrics is often\nneglected as they are competing in nature. In this article, a mechanism for\nradio resource management using multi-agent deep reinforcement learning (RL) is\nproposed, which strikes the right trade-off between maximizing the average and\nthe $5^{th}$ percentile user throughput. Each transmitter in the network is\nequipped with a deep RL agent, receiving partial observations from the network\n(e.g., channel quality, interference level, etc.) and deciding whether to be\nactive or inactive at each scheduling interval for given radio resources, a\nprocess referred to as link scheduling. Based on the actions of all agents, the\nnetwork emits a reward to the agents, indicating how good their joint decisions\nwere. The proposed framework enables the agents to make decisions in a\ndistributed manner, and the reward is designed in such a way that the agents\nstrive to guarantee a minimum performance, leading to a fair resource\nallocation among all users across the network. Simulation results demonstrate\nthe superiority of our approach compared to decentralized baselines in terms of\naverage and $5^{th}$ percentile user throughput, while achieving performance\nclose to that of a centralized exhaustive search approach. Moreover, the\nproposed framework is robust to mismatches between training and testing\nscenarios. In particular, it is shown that an agent trained on a network with\nlow transmitter density maintains its performance and outperforms the baselines\nwhen deployed in a network with a higher transmitter density.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 18:06:58 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Sydir", "Jaroslaw", ""], ["Simsek", "Meryem", ""], ["Nikopour", "Hosein", ""], ["Talwar", "Shilpa", ""]]}, {"id": "1906.08809", "submitter": "Wentai Zhang", "authors": "Haiguang Liao, Wentai Zhang, Xuliang Dong, Barnabas Poczos, Kenji\n  Shimada, Levent Burak Kara", "title": "A Deep Reinforcement Learning Approach for Global Routing", "comments": "Preprint submitted to ASME JMD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global routing has been a historically challenging problem in electronic\ncircuit design, where the challenge is to connect a large and arbitrary number\nof circuit components with wires without violating the design rules for the\nprinted circuit boards or integrated circuits. Similar routing problems also\nexist in the design of complex hydraulic systems, pipe systems and logistic\nnetworks. Existing solutions typically consist of greedy algorithms and\nhard-coded heuristics. As such, existing approaches suffer from a lack of model\nflexibility and non-optimum solutions. As an alternative approach, this work\npresents a deep reinforcement learning method for solving the global routing\nproblem in a simulated environment. At the heart of the proposed method is deep\nreinforcement learning that enables an agent to produce an optimal policy for\nrouting based on the variety of problems it is presented with leveraging the\nconjoint optimization mechanism of deep reinforcement learning. Conjoint\noptimization mechanism is explained and demonstrated in details; the best\nnetwork structure and the parameters of the learned model are explored. Based\non the fine-tuned model, routing solutions and rewards are presented and\nanalyzed. The results indicate that the approach can outperform the benchmark\nmethod of a sequential A* method, suggesting a promising potential for deep\nreinforcement learning for global routing and other routing or path planning\nproblems in general. Another major contribution of this work is the development\nof a global routing problem sets generator with the ability to generate\nparameterized global routing problem sets with different size and constraints,\nenabling evaluation of different routing algorithms and the generation of\ntraining datasets for future data-driven routing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 19:07:01 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Liao", "Haiguang", ""], ["Zhang", "Wentai", ""], ["Dong", "Xuliang", ""], ["Poczos", "Barnabas", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1906.08823", "submitter": "Isabela Maria Carneiro de Albuquerque", "authors": "Isabela Albuquerque, Jo\\~ao Monteiro, Olivier Rosanne, Abhishek\n  Tiwari, Jean-Fran\\c{c}ois Gagnon, and Tiago H. Falk", "title": "Cross-Subject Statistical Shift Estimation for Generalized\n  Electroencephalography-based Mental Workload Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessment of mental workload in real world conditions is key to ensure the\nperformance of workers executing tasks which demand sustained attention.\nPrevious literature has employed electroencephalography (EEG) to this end.\nHowever, EEG correlates of mental workload vary across subjects and physical\nstrain, thus making it difficult to devise models capable of simultaneously\npresenting reliable performance across users. The field of domain adaptation\n(DA) aims at developing methods that allow for generalization across different\ndomains by learning domain-invariant representations. Such DA methods, however,\nrely on the so-called covariate shift assumption, which typically does not hold\nfor EEG-based applications. As such, in this paper we propose a way to measure\nthe statistical (marginal and conditional) shift observed on data obtained from\ndifferent users and use this measure to quantitatively assess the effectiveness\nof different adaptation strategies. In particular, we use EEG data collected\nfrom individuals performing a mental task while running in a treadmill and\nexplore the effects of different normalization strategies commonly used to\nmitigate cross-subject variability. We show the effects that different\nnormalization schemes have on statistical shifts and their relationship with\nthe accuracy of mental workload prediction as assessed on unseen participants\nat train time.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 19:50:02 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Albuquerque", "Isabela", ""], ["Monteiro", "Jo\u00e3o", ""], ["Rosanne", "Olivier", ""], ["Tiwari", "Abhishek", ""], ["Gagnon", "Jean-Fran\u00e7ois", ""], ["Falk", "Tiago H.", ""]]}, {"id": "1906.08829", "submitter": "Ashesh Chattopadhyay", "authors": "Ashesh Chattopadhyay, Pedram Hassanzadeh, Devika Subramanian", "title": "Data-driven prediction of a multi-scale Lorenz 96 chaotic system using\n  deep learning methods: Reservoir computing, ANN, and RNN-LSTM", "comments": "Some changes, in Figures, addition of an appendix etc has been done", "journal-ref": "Nonlin. Processes Geophys. 2020", "doi": "10.5194/npg-27-373-2020", "report-no": null, "categories": "cs.LG math.DS nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the performance of three deep learning methods for predicting\nshort-term evolution and for reproducing the long-term statistics of a\nmulti-scale spatio-temporal Lorenz 96 system is examined. The methods are: echo\nstate network (a type of reservoir computing, RC-ESN), deep feed-forward\nartificial neural network (ANN), and recurrent neural network with long\nshort-term memory (RNN-LSTM). This Lorenz 96 system has three tiers of\nnonlinearly interacting variables representing slow/large-scale ($X$),\nintermediate ($Y$), and fast/small-scale ($Z$) processes. For training or\ntesting, only $X$ is available; $Y$ and $Z$ are never known or used. We show\nthat RC-ESN substantially outperforms ANN and RNN-LSTM for short-term\nprediction, e.g., accurately forecasting the chaotic trajectories for hundreds\nof numerical solver's time steps, equivalent to several Lyapunov timescales.\nThe RNN-LSTM and ANN show some prediction skills as well; RNN-LSTM bests ANN.\nFurthermore, even after losing the trajectory, data predicted by RC-ESN and\nRNN-LSTM have probability density functions (PDFs) that closely match the true\nPDF, even at the tails. The PDF of the data predicted using ANN, however,\ndeviates from the true PDF. Implications, caveats, and applications to\ndata-driven and data-assisted surrogate modeling of complex nonlinear dynamical\nsystems such as weather/climate are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 20:16:53 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 00:51:09 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 03:48:47 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Chattopadhyay", "Ashesh", ""], ["Hassanzadeh", "Pedram", ""], ["Subramanian", "Devika", ""]]}, {"id": "1906.08834", "submitter": "Kanwar Bharat Singh", "authors": "Kanwar Bharat Singh and Mustafa Ali Arat", "title": "Deep Learning in the Automotive Industry: Recent Advances and\n  Application Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most exciting technology breakthroughs in the last few years has\nbeen the rise of deep learning. State-of-the-art deep learning models are being\nwidely deployed in academia and industry, across a variety of areas, from image\nanalysis to natural language processing. These models have grown from fledgling\nresearch subjects to mature techniques in real-world use. The increasing scale\nof data, computational power and the associated algorithmic innovations are the\nmain drivers for the progress we see in this field. These developments also\nhave a huge potential for the automotive industry and therefore the interest in\ndeep learning-based technology is growing. A lot of the product innovations,\nsuch as self-driving cars, parking and lane-change assist or safety functions,\nsuch as autonomous emergency braking, are powered by deep learning algorithms.\nDeep learning is poised to offer gains in performance and functionality for\nmost ADAS (Advanced Driver Assistance System) solutions. Virtual sensing for\nvehicle dynamics application, vehicle inspection/heath monitoring, automated\ndriving and data-driven product development are key areas that are expected to\nget the most attention. This article provides an overview of the recent\nadvances and some associated challenges in deep learning techniques in the\ncontext of automotive applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 20:30:39 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 07:57:58 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Singh", "Kanwar Bharat", ""], ["Arat", "Mustafa Ali", ""]]}, {"id": "1906.08850", "submitter": "Topi Paananen", "authors": "Topi Paananen, Juho Piironen, Paul-Christian B\\\"urkner, Aki Vehtari", "title": "Implicitly Adaptive Importance Sampling", "comments": "Major revision: More comparisons to adaptive importance sampling with\n  parametric distributions", "journal-ref": "Stat Comput 31, 16 (2021)", "doi": "10.1007/s11222-020-09982-2", "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive importance sampling is a class of techniques for finding good\nproposal distributions for importance sampling. Often the proposal\ndistributions are standard probability distributions whose parameters are\nadapted based on the mismatch between the current proposal and a target\ndistribution. In this work, we present an implicit adaptive importance sampling\nmethod that applies to complicated distributions which are not available in\nclosed form. The method iteratively matches the moments of a set of Monte Carlo\ndraws to weighted moments based on importance weights. We apply the method to\nBayesian leave-one-out cross-validation and show that it performs better than\nmany existing parametric adaptive importance sampling methods while being\ncomputationally inexpensive.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 21:16:35 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 12:16:20 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Paananen", "Topi", ""], ["Piironen", "Juho", ""], ["B\u00fcrkner", "Paul-Christian", ""], ["Vehtari", "Aki", ""]]}, {"id": "1906.08856", "submitter": "Wei Luo", "authors": "Wei Luo and Feng Yu", "title": "Learning Longer-term Dependencies via Grouped Distributor Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term dependencies still remains difficult for recurrent neural\nnetworks (RNNs) despite their success in sequence modeling recently. In this\npaper, we propose a novel gated RNN structure, which contains only one gate.\nHidden states in the proposed grouped distributor unit (GDU) are partitioned\ninto groups. For each group, the proportion of memory to be overwritten in each\nstate transition is limited to a constant and is adaptively distributed to each\ngroup member. In other word, every separate group has a fixed overall update\nrate, yet all units are allowed to have different paces. Information is\ntherefore forced to be latched in a flexible way, which helps the model to\ncapture long-term dependencies in data. Besides having a simpler structure, GDU\nis demonstrated experimentally to outperform LSTM and GRU on tasks including\nboth pathological problems and natural data set.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 02:08:27 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Luo", "Wei", ""], ["Yu", "Feng", ""]]}, {"id": "1906.08858", "submitter": "Rahul Gupta", "authors": "Rahul Gupta, Aman Alok, Shankar Ananthakrishnan", "title": "One-vs-All Models for Asynchronous Training: An Empirical Analysis", "comments": "5 pages, Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any given classification problem can be modeled using multi-class or\nOne-vs-All (OVA) architecture. An OVA system consists of as many OVA models as\nthe number of classes, providing the advantage of asynchrony, where each OVA\nmodel can be re-trained independent of other models. This is particularly\nadvantageous in settings where scalable model training is a consideration (for\ninstance in an industrial environment where multiple and frequent updates need\nto be made to the classification system). In this paper, we conduct empirical\nanalysis on realizing independent updates to OVA models and its impact on the\naccuracy of the overall OVA system. Given that asynchronous updates lead to\ndifferences in training datasets for OVA models, we first define a metric to\nquantify the differences in datasets. Thereafter, using Natural Language\nUnderstanding as a task of interest, we estimate the impact of three factors:\n(i) number of classes, (ii) number of data points and, (iii) divergences in\ntraining datasets across OVA models; on the OVA system accuracy. Finally, we\nobserve the accuracy impact of increased asynchrony in a Spoken Language\nUnderstanding system. We analyze the results and establish that the proposed\nmetric correlates strongly with the model performances in both the experimental\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 21:23:30 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Gupta", "Rahul", ""], ["Alok", "Aman", ""], ["Ananthakrishnan", "Shankar", ""]]}, {"id": "1906.08861", "submitter": "Deboleena Roy", "authors": "Deboleena Roy, Priyadarshini Panda, and Kaushik Roy", "title": "Synthesizing Images from Spatio-Temporal Representations using\n  Spike-based Backpropagation", "comments": "17 pages, 10 Figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) offer a promising alternative to current\nartificial neural networks to enable low-power event-driven neuromorphic\nhardware. Spike-based neuromorphic applications require processing and\nextracting meaningful information from spatio-temporal data, represented as\nseries of spike trains over time. In this paper, we propose a method to\nsynthesize images from multiple modalities in a spike-based environment. We use\nspiking auto-encoders to convert image and audio inputs into compact\nspatio-temporal representations that is then decoded for image synthesis. For\nthis, we use a direct training algorithm that computes loss on the membrane\npotential of the output layer and back-propagates it by using a sigmoid\napproximation of the neuron's activation function to enable differentiability.\nThe spiking autoencoders are benchmarked on MNIST and Fashion-MNIST and achieve\nvery low reconstruction loss, comparable to ANNs. Then, spiking autoencoders\nare trained to learn meaningful spatio-temporal representations of the data,\nacross the two modalities - audio and visual. We synthesize images from audio\nin a spike-based environment by first generating, and then utilizing such\nshared multi-modal spatio-temporal representations. Our audio to image\nsynthesis model is tested on the task of converting TI-46 digits audio samples\nto MNIST images. We are able to synthesize images with high fidelity and the\nmodel achieves competitive performance against ANNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:33:15 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Roy", "Deboleena", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1906.08862", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran and Svetha Venkatesh", "title": "Neural Stored-program Memory", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks powered with external memory simulate computer behaviors.\nThese models, which use the memory to store data for a neural controller, can\nlearn algorithms and other complex tasks. In this paper, we introduce a new\nmemory to store weights for the controller, analogous to the stored-program\nmemory in modern computer architectures. The proposed model, dubbed Neural\nStored-program Memory, augments current memory-augmented neural networks,\ncreating differentiable machines that can switch programs through time, adapt\nto variable contexts and thus resemble the Universal Turing Machine. A wide\nrange of experiments demonstrate that the resulting machines not only excel in\nclassical algorithmic problems, but also have potential for compositional,\ncontinual, few-shot learning and question-answering tasks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 06:30:11 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 00:44:44 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1906.08864", "submitter": "Erol Gelenbe", "authors": "Khaled F. Hussain, Mohamed Yousef Bassyouni, and Erol Gelenbe", "title": "Accurate and Energy-Efficient Classification with Spiking Random Neural\n  Network: Corrected and Expanded Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial Neural Network (ANN) based techniques have dominated\nstate-of-the-art results in most problems related to computer vision, audio\nrecognition, and natural language processing in the past few years, resulting\nin strong industrial adoption from all leading technology companies worldwide.\nOne of the major obstacles that have historically delayed large scale adoption\nof ANNs is the huge computational and power costs associated with training and\ntesting (deploying) them. In the mean-time, Neuromorphic Computing platforms\nhave recently achieved remarkable performance running more bio-realistic\nSpiking Neural Networks at high throughput and very low power consumption\nmaking them a natural alternative to ANNs. Here, we propose using the Random\nNeural Network (RNN), a spiking neural network with both theoretical and\npractical appealing properties, as a general purpose classifier that can match\nthe classification power of ANNs on a number of tasks while enjoying all the\nfeatures of a spiking neural network. This is demonstrated on a number of\nreal-world classification datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 18:49:57 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hussain", "Khaled F.", ""], ["Bassyouni", "Mohamed Yousef", ""], ["Gelenbe", "Erol", ""]]}, {"id": "1906.08868", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Krzysztof Choromanski, Alp Kucukelbir", "title": "Variance Reduction for Evolution Strategies via Structured Control\n  Variates", "comments": "Accepted to AISTATS (International Conference on Artificial\n  Intelligence and Statistics), 2020 in Palermo, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution Strategies (ES) are a powerful class of blackbox optimization\ntechniques that recently became a competitive alternative to state-of-the-art\npolicy gradient (PG) algorithms for reinforcement learning (RL). We propose a\nnew method for improving accuracy of the ES algorithms, that as opposed to\nrecent approaches utilizing only Monte Carlo structure of the gradient\nestimator, takes advantage of the underlying MDP structure to reduce the\nvariance. We observe that the gradient estimator of the ES objective can be\nalternatively computed using reparametrization and PG estimators, which leads\nto new control variate techniques for gradient estimation in ES optimization.\nWe provide theoretical insights and show through extensive experiments that\nthis RL-specific variance reduction approach outperforms general purpose\nvariance reduction methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:48:28 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 13:20:01 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Tang", "Yunhao", ""], ["Choromanski", "Krzysztof", ""], ["Kucukelbir", "Alp", ""]]}, {"id": "1906.08871", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed H Tewfik", "title": "Advancing Speech Recognition With No Speech Or With Noisy Speech", "comments": "Extended version of our accepted IEEE EUSIPCO 2019 paper with\n  additional results for CTC model based recognition. arXiv admin note:\n  substantial text overlap with arXiv:1906.08045, arXiv:1906.08044", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate end-to-end continuous speech recognition (CSR)\nusing electroencephalography (EEG) signals with no speech signal as input. An\nattention model based automatic speech recognition (ASR) and connectionist\ntemporal classification (CTC) based ASR systems were implemented for performing\nrecognition. We further demonstrate CSR for noisy speech by fusing with EEG\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:06:51 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 03:13:24 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 03:46:44 GMT"}, {"version": "v4", "created": "Sat, 17 Aug 2019 02:44:48 GMT"}, {"version": "v5", "created": "Wed, 21 Aug 2019 19:00:45 GMT"}, {"version": "v6", "created": "Sun, 10 Nov 2019 02:47:45 GMT"}, {"version": "v7", "created": "Wed, 13 Nov 2019 03:53:06 GMT"}, {"version": "v8", "created": "Wed, 4 Mar 2020 22:28:26 GMT"}, {"version": "v9", "created": "Sun, 15 Mar 2020 02:51:46 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1906.08873", "submitter": "Suraj Tripathi", "authors": "Suraj Tripathi, Abhiram Ramesh, Abhay Kumar, Chirag Singh, Promod\n  Yenigalla", "title": "Learning Discriminative features using Center Loss and Reconstruction as\n  Regularizer for Speech Emotion Recognition", "comments": "10 pages, Accepted in IJCAI Affective Computing Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Convolutional Neural Network (CNN) inspired by\nMultitask Learning (MTL) and based on speech features trained under the joint\nsupervision of softmax loss and center loss, a powerful metric learning\nstrategy, for the recognition of emotion in speech. Speech features such as\nSpectrograms and Mel-frequency Cepstral Coefficient s (MFCCs) help retain\nemotion-related low-level characteristics in speech. We experimented with\nseveral Deep Neural Network (DNN) architectures that take in speech features as\ninput and trained them under both softmax and center loss, which resulted in\nhighly discriminative features ideal for Speech Emotion Recognition (SER). Our\nnetworks also employ a regularizing effect by simultaneously performing the\nauxiliary task of reconstructing the input speech features. This sharing of\nrepresentations among related tasks enables our network to better generalize\nthe original task of SER. Some of our proposed networks contain far fewer\nparameters when compared to state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 02:50:59 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 05:19:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tripathi", "Suraj", ""], ["Ramesh", "Abhiram", ""], ["Kumar", "Abhay", ""], ["Singh", "Chirag", ""], ["Yenigalla", "Promod", ""]]}, {"id": "1906.08878", "submitter": "Ahsan Alvi", "authors": "Binxin Ru, Ahsan S. Alvi, Vu Nguyen, Michael A. Osborne, Stephen J\n  Roberts", "title": "Bayesian Optimisation over Multiple Continuous and Categorical Inputs", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient optimisation of black-box problems that comprise both continuous\nand categorical inputs is important, yet poses significant challenges. We\npropose a new approach, Continuous and Categorical Bayesian Optimisation\n(CoCaBO), which combines the strengths of multi-armed bandits and Bayesian\noptimisation to select values for both categorical and continuous inputs. We\nmodel this mixed-type space using a Gaussian Process kernel, designed to allow\nsharing of information across multiple categorical variables, each with\nmultiple possible values; this allows CoCaBO to leverage all available data\nefficiently. We extend our method to the batch setting and propose an efficient\nselection procedure that dynamically balances exploration and exploitation\nwhilst encouraging batch diversity. We demonstrate empirically that our method\noutperforms existing approaches on both synthetic and real-world optimisation\ntasks with continuous and categorical inputs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 22:05:22 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 17:16:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ru", "Binxin", ""], ["Alvi", "Ahsan S.", ""], ["Nguyen", "Vu", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J", ""]]}, {"id": "1906.08879", "submitter": "Ravichandra Addanki", "authors": "Ravichandra Addanki, Shaileshh Bojja Venkatakrishnan, Shreyan Gupta,\n  Hongzi Mao and Mohammad Alizadeh", "title": "Placeto: Learning Generalizable Device Placement Algorithms for\n  Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Placeto, a reinforcement learning (RL) approach to efficiently\nfind device placements for distributed neural network training. Unlike prior\napproaches that only find a device placement for a specific computation graph,\nPlaceto can learn generalizable device placement policies that can be applied\nto any graph. We propose two key ideas in our approach: (1) we represent the\npolicy as performing iterative placement improvements, rather than outputting a\nplacement in one shot; (2) we use graph embeddings to capture relevant\ninformation about the structure of the computation graph, without relying on\nnode labels for indexing. These ideas allow Placeto to train efficiently and\ngeneralize to unseen graphs. Our experiments show that Placeto requires up to\n6.1x fewer training steps to find placements that are on par with or better\nthan the best placements found by prior approaches. Moreover, Placeto is able\nto learn a generalizable placement policy for any given family of graphs, which\ncan then be used without any retraining to predict optimized placements for\nunseen graphs from the same family. This eliminates the large overhead incurred\nby prior RL approaches whose lack of generalizability necessitates re-training\nfrom scratch every time a new graph is to be placed.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 22:08:51 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Addanki", "Ravichandra", ""], ["Venkatakrishnan", "Shaileshh Bojja", ""], ["Gupta", "Shreyan", ""], ["Mao", "Hongzi", ""], ["Alizadeh", "Mohammad", ""]]}, {"id": "1906.08898", "submitter": "Ang Yang", "authors": "Ang Yang, Cheng Li, Santu Rana, Sunil Gupta, Svetha Venkatesh", "title": "Sparse Spectrum Gaussian Process for Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel sparse spectrum approximation of Gaussian process (GP)\ntailored for Bayesian optimization. Whilst the current sparse spectrum methods\nprovide desired approximations for regression problems, it is observed that\nthis particular form of sparse approximations generates an overconfident GP,\ni.e. it produces less epistemic uncertainty than the original GP. Since the\nbalance between predictive mean and the predictive variance is the key\ndeterminant to the success of Bayesian optimization, the current sparse\nspectrum methods are less suitable for it. We derive a new regularized marginal\nlikelihood for finding the optimal frequencies to fix this over-confidence\nissue, particularly for Bayesian optimization. The regularizer trades off the\naccuracy in the model fitting with a targeted increase in the predictive\nvariance of the resultant GP. Specifically, we use the entropy of the global\nmaximum distribution from the posterior GP as the regularizer that needs to be\nmaximized. Since this distribution cannot be calculated analytically, we first\npropose a Thompson sampling based approach and then a more efficient sequential\nMonte Carlo based approach to estimate it. Later, we also show that the\nExpected Improvement acquisition function can be used as a proxy for the\nmaximum distribution, thus making the whole process further efficient.\nExperiments show considerable improvement to Bayesian optimization convergence\nrate over the vanilla sparse spectrum method and over a full GP when its\ncovariance matrix is ill-conditioned due to the presence of a large number of\nobservations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 00:27:09 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 06:51:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Yang", "Ang", ""], ["Li", "Cheng", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1906.08899", "submitter": "Andrea Montanari", "authors": "Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari", "title": "Limitations of Lazy Training of Two-layers Neural Networks", "comments": "39 pages; 2 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the supervised learning problem under either of the following two\nmodels: (1) Feature vectors ${\\boldsymbol x}_i$ are $d$-dimensional Gaussians\nand responses are $y_i = f_*({\\boldsymbol x}_i)$ for $f_*$ an unknown quadratic\nfunction; (2) Feature vectors ${\\boldsymbol x}_i$ are distributed as a mixture\nof two $d$-dimensional centered Gaussians, and $y_i$'s are the corresponding\nclass labels. We use two-layers neural networks with quadratic activations, and\ncompare three different learning regimes: the random features (RF) regime in\nwhich we only train the second-layer weights; the neural tangent (NT) regime in\nwhich we train a linearization of the neural network around its initialization;\nthe fully trained neural network (NN) regime in which we train all the weights\nin the network. We prove that, even for the simple quadratic model of point\n(1), there is a potentially unbounded gap between the prediction risk achieved\nin these three training regimes, when the number of neurons is smaller than the\nambient dimension. When the number of neurons is larger than the number of\ndimensions, the problem is significantly easier and both NT and NN learning\nachieve zero risk.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 00:29:54 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ghorbani", "Behrooz", ""], ["Mei", "Song", ""], ["Misiakiewicz", "Theodor", ""], ["Montanari", "Andrea", ""]]}, {"id": "1906.08901", "submitter": "Eli Sennesh", "authors": "Eli Sennesh, Zulqarnain Khan, Yiyu Wang, Jennifer Dy, Ajay B. Satpute,\n  J. Benjamin Hutchinson, Jan-Willem van de Meent", "title": "Neural Topographic Factor Analysis for fMRI Data", "comments": "15 pages, 9 figures, associated source code available at\n  https://github.com/neu-spiral/HTFATorch", "journal-ref": "Advances in Neural Information Processing Systems 34 (2020)", "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging studies produce gigabytes of spatio-temporal data for a small\nnumber of participants and stimuli. Rarely do researchers attempt to model and\nexamine how individual participants vary from each other -- a question that\nshould be addressable even in small samples given the right statistical tools.\nWe propose Neural Topographic Factor Analysis (NTFA), a probabilistic factor\nanalysis model that infers embeddings for participants and stimuli. These\nembeddings allow us to reason about differences between participants and\nstimuli as signal rather than noise. We evaluate NTFA on data from an in-house\npilot experiment, as well as two publicly available datasets. We demonstrate\nthat inferring representations for participants and stimuli improves predictive\ngeneralization to unseen data when compared to previous topographic methods. We\nalso demonstrate that the inferred latent factor representations are useful for\ndownstream tasks such as multivoxel pattern analysis and functional\nconnectivity.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 00:56:07 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 18:41:49 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 17:07:31 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 17:04:06 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sennesh", "Eli", ""], ["Khan", "Zulqarnain", ""], ["Wang", "Yiyu", ""], ["Dy", "Jennifer", ""], ["Satpute", "Ajay B.", ""], ["Hutchinson", "J. Benjamin", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1906.08902", "submitter": "Heliang Huang", "authors": "Chen Ding, Tian-Yi Bao, He-Liang Huang", "title": "Quantum-Inspired Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine (SVM) is a particularly powerful and flexible\nsupervised learning model that analyzes data for both classification and\nregression, whose usual algorithm complexity scales polynomially with the\ndimension of data space and the number of data points. To tackle the big data\nchallenge, a quantum SVM algorithm was proposed, which is claimed to achieve\nexponential speedup for least squares SVM (LS-SVM). Here, inspired by the\nquantum SVM algorithm, we present a quantum-inspired classical algorithm for\nLS-SVM. In our approach, a improved fast sampling technique, namely indirect\nsampling, is proposed for sampling the kernel matrix and classifying. We first\nconsider the LS-SVM with a linear kernel, and then discuss the generalization\nof our method to non-linear kernels. Theoretical analysis shows our algorithm\ncan make classification with arbitrary success probability in logarithmic\nruntime of both the dimension of data space and the number of data points for\nlow rank, low condition number and high dimensional data matrix, matching the\nruntime of the quantum SVM.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:00:07 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 15:41:56 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 11:07:10 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 02:35:34 GMT"}, {"version": "v5", "created": "Tue, 16 Mar 2021 01:54:20 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ding", "Chen", ""], ["Bao", "Tian-Yi", ""], ["Huang", "He-Liang", ""]]}, {"id": "1906.08905", "submitter": "Jing Li", "authors": "Feiping Nie, Jing Li, and Xuelong Li", "title": "Intrinsic Weight Learning Approach for Multi-view Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting different representations, or views, of the same object for better\nclustering has become very popular these days, which is conventionally called\nmulti-view clustering. Generally, it is essential to measure the importance of\neach individual view, due to some noises, or inherent capacities in\ndescription. Many previous works model the view importance as weight, which is\nsimple but effective empirically. In this paper, instead of following the\ntraditional thoughts, we propose a new weight learning paradigm in context of\nmulti-view clustering in virtue of the idea of re-weighted approach, and we\ntheoretically analyze its working mechanism. Meanwhile, as a carefully achieved\nexample, all of the views are connected by exploring a unified Laplacian rank\nconstrained graph, which will be a representative method to compare with other\nweight learning approaches in experiments. Furthermore, the proposed weight\nlearning strategy is much suitable for multi-view data, and it can be naturally\nintegrated with many existing clustering learners. According to the numerical\nexperiments, the proposed intrinsic weight learning approach is proved\neffective and practical to use in multi-view clustering.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:07:55 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Nie", "Feiping", ""], ["Li", "Jing", ""], ["Li", "Xuelong", ""]]}, {"id": "1906.08934", "submitter": "Jorge Gustavo Madrid Perez", "authors": "Jorge Madrid, Hugo Jair Escalante, Eduardo Morales", "title": "Meta-learning of textual representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in AutoML has lead to state-of-the-art methods (e.g.,\nAutoSKLearn) that can be readily used by non-experts to approach any supervised\nlearning problem. Whereas these methods are quite effective, they are still\nlimited in the sense that they work for tabular (matrix formatted) data only.\nThis paper describes one step forward in trying to automate the design of\nsupervised learning methods in the context of text mining. We introduce a meta\nlearning methodology for automatically obtaining a representation for text\nmining tasks starting from raw text. We report experiments considering 60\ndifferent textual representations and more than 80 text mining datasets\nassociated to a wide variety of tasks. Experimental results show the proposed\nmethodology is a promising solution to obtain highly effective off the shell\ntext classification pipelines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:39:46 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 21:19:49 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Madrid", "Jorge", ""], ["Escalante", "Hugo Jair", ""], ["Morales", "Eduardo", ""]]}, {"id": "1906.08935", "submitter": "Ligeng Zhu", "authors": "Ligeng Zhu and Zhijian Liu and Song Han", "title": "Deep Leakage from Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchanging gradients is a widely used method in modern multi-node machine\nlearning system (e.g., distributed training, collaborative learning). For a\nlong time, people believed that gradients are safe to share: i.e., the training\ndata will not be leaked by gradient exchange. However, we show that it is\npossible to obtain the private training data from the publicly shared\ngradients. We name this leakage as Deep Leakage from Gradient and empirically\nvalidate the effectiveness on both computer vision and natural language\nprocessing tasks. Experimental results show that our attack is much stronger\nthan previous approaches: the recovery is pixel-wise accurate for images and\ntoken-wise matching for texts. We want to raise people's awareness to rethink\nthe gradient's safety. Finally, we discuss several possible strategies to\nprevent such deep leakage. The most effective defense method is gradient\npruning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:46:43 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 05:09:29 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhu", "Ligeng", ""], ["Liu", "Zhijian", ""], ["Han", "Song", ""]]}, {"id": "1906.08947", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Manzil Zaheer, Csaba Szepesvari, Lihong Li, Mohammad\n  Ghavamzadeh, and Craig Boutilier", "title": "Randomized Exploration in Generalized Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two randomized algorithms for generalized linear bandits, GLM-TSL\nand GLM-FPL. GLM-TSL samples a generalized linear model (GLM) from the Laplace\napproximation to the posterior distribution. GLM-FPL fits a GLM to a randomly\nperturbed history of past rewards. We prove $\\tilde{O}(d \\sqrt{n \\log K})$\nbounds on the $n$-round regret of GLM-TSL and GLM-FPL, where $d$ is the number\nof features and $K$ is the number of arms. The regret bound of GLM-TSL improves\nupon prior work and the regret bound of GLM-FPL is the first of its kind. We\napply both GLM-TSL and GLM-FPL to logistic and neural network bandits, and show\nthat they perform well empirically. In more complex models, GLM-FPL is\nsignificantly faster. Our results showcase the role of randomization, beyond\nsampling from the posterior, in exploration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 04:57:54 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 06:31:52 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Szepesvari", "Csaba", ""], ["Li", "Lihong", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "1906.08952", "submitter": "Maya Okawa", "authors": "Maya Okawa, Tomoharu Iwata, Takeshi Kurashima, Yusuke Tanaka, Hiroyuki\n  Toda, Naonori Ueda", "title": "Deep Mixture Point Processes: Spatio-temporal Event Prediction with Rich\n  Contextual Information", "comments": "KDD 19", "journal-ref": null, "doi": "10.1145/3292500.3330937", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predicting when and where events will occur in cities, like taxi pick-ups,\ncrimes, and vehicle collisions, is a challenging and important problem with\nmany applications in fields such as urban planning, transportation optimization\nand location-based marketing. Though many point processes have been proposed to\nmodel events in a continuous spatio-temporal space, none of them allow for the\nconsideration of the rich contextual factors that affect event occurrence, such\nas weather, social activities, geographical characteristics, and traffic. In\nthis paper, we propose \\textsf{DMPP} (Deep Mixture Point Processes), a point\nprocess model for predicting spatio-temporal events with the use of rich\ncontextual information; a key advance is its incorporation of the heterogeneous\nand high-dimensional context available in image and text data. Specifically, we\ndesign the intensity of our point process model as a mixture of kernels, where\nthe mixture weights are modeled by a deep neural network. This formulation\nallows us to automatically learn the complex nonlinear effects of the\ncontextual factors on event occurrence. At the same time, this formulation\nmakes analytical integration over the intensity, which is required for point\nprocess estimation, tractable. We use real-world data sets from different\ndomains to demonstrate that DMPP has better predictive performance than\nexisting methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 05:29:40 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Okawa", "Maya", ""], ["Iwata", "Tomoharu", ""], ["Kurashima", "Takeshi", ""], ["Tanaka", "Yusuke", ""], ["Toda", "Hiroyuki", ""], ["Ueda", "Naonori", ""]]}, {"id": "1906.08988", "submitter": "Dong Yin", "authors": "Dong Yin, Raphael Gontijo Lopes, Jonathon Shlens, Ekin D. Cubuk,\n  Justin Gilmer", "title": "A Fourier Perspective on Model Robustness in Computer Vision", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving robustness to distributional shift is a longstanding and\nchallenging goal of computer vision. Data augmentation is a commonly used\napproach for improving robustness, however robustness gains are typically not\nuniform across corruption types. Indeed increasing performance in the presence\nof random noise is often met with reduced performance on other corruptions such\nas contrast change. Understanding when and why these sorts of trade-offs occur\nis a crucial step towards mitigating them. Towards this end, we investigate\nrecently observed trade-offs caused by Gaussian data augmentation and\nadversarial training. We find that both methods improve robustness to\ncorruptions that are concentrated in the high frequency domain while reducing\nrobustness to corruptions that are concentrated in the low frequency domain.\nThis suggests that one way to mitigate these trade-offs via data augmentation\nis to use a more diverse set of augmentations. Towards this end we observe that\nAutoAugment, a recently proposed data augmentation policy optimized for clean\naccuracy, achieves state-of-the-art robustness on the CIFAR-10-C benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 07:31:26 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 04:55:48 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 01:30:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Yin", "Dong", ""], ["Lopes", "Raphael Gontijo", ""], ["Shlens", "Jonathon", ""], ["Cubuk", "Ekin D.", ""], ["Gilmer", "Justin", ""]]}, {"id": "1906.09003", "submitter": "Christoph David Hofer M.Sc.", "authors": "Christoph Hofer, Roland Kwitt, Mandar Dixit, Marc Niethammer", "title": "Connectivity-Optimized Representation Learning via Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning representations with controllable\nconnectivity properties. This is beneficial in situations when the imposed\nstructure can be leveraged upstream. In particular, we control the connectivity\nof an autoencoder's latent space via a novel type of loss, operating on\ninformation from persistent homology. Under mild conditions, this loss is\ndifferentiable and we present a theoretical analysis of the properties induced\nby the loss. We choose one-class learning as our upstream task and demonstrate\nthat the imposed structure enables informed parameter selection for modeling\nthe in-class distribution via kernel density estimators. Evaluated on computer\nvision data, these one-class models exhibit competitive performance and, in a\nlow sample size regime, outperform other methods by a large margin. Notably,\nour results indicate that a single autoencoder, trained on auxiliary\n(unlabeled) data, yields a mapping into latent space that can be reused across\ndatasets for one-class learning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 08:23:57 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hofer", "Christoph", ""], ["Kwitt", "Roland", ""], ["Dixit", "Mandar", ""], ["Niethammer", "Marc", ""]]}, {"id": "1906.09012", "submitter": "Brett Roads", "authors": "Brett D. Roads, Bradley C. Love", "title": "Learning as the Unsupervised Alignment of Conceptual Systems", "comments": "This is a post-peer-review, pre-copyedit version of an article\n  published in Nature Machine Intelligence. The final authenticated version is\n  available online at: https://doi.org/10.1038/s42256-019-0132-2", "journal-ref": null, "doi": "10.1038/s42256-019-0132-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept induction requires the extraction and naming of concepts from noisy\nperceptual experience. For supervised approaches, as the number of concepts\ngrows, so does the number of required training examples. Philosophers,\npsychologists, and computer scientists, have long recognized that children can\nlearn to label objects without being explicitly taught. In a series of\ncomputational experiments, we highlight how information in the environment can\nbe used to build and align conceptual systems. Unlike supervised learning, the\nlearning problem becomes easier the more concepts and systems there are to\nmaster. The key insight is that each concept has a unique signature within one\nconceptual system (e.g., images) that is recapitulated in other systems (e.g.,\ntext or audio). As predicted, children's early concepts form readily aligned\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 08:54:19 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 09:20:25 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 17:04:48 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Roads", "Brett D.", ""], ["Love", "Bradley C.", ""]]}, {"id": "1906.09023", "submitter": "Wei Wang", "authors": "Wei Wang, Zheng Dang, Yinlin Hu, Pascal Fua and Mathieu Salzmann", "title": "Backpropagation-Friendly Eigendecomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigendecomposition (ED) is widely used in deep networks. However, the\nbackpropagation of its results tends to be numerically unstable, whether using\nED directly or approximating it with the Power Iteration method, particularly\nwhen dealing with large matrices. While this can be mitigated by partitioning\nthe data in small and arbitrary groups, doing so has no theoretical basis and\nmakes its impossible to exploit the power of ED to the full. In this paper, we\nintroduce a numerically stable and differentiable approach to leveraging\neigenvectors in deep networks. It can handle large matrices without requiring\nto split them. We demonstrate the better robustness of our approach over\nstandard ED and PI for ZCA whitening, an alternative to batch normalization,\nand for PCA denoising, which we introduce as a new normalization strategy for\ndeep networks, aiming to further denoise the network's features.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 09:17:14 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 07:42:43 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wang", "Wei", ""], ["Dang", "Zheng", ""], ["Hu", "Yinlin", ""], ["Fua", "Pascal", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "1906.09059", "submitter": "Yuval Lewi", "authors": "Yuval Lewi, Haim Kaplan and Yishay Mansour", "title": "Thompson Sampling for Adversarial Bit Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Thompson sampling algorithm in an adversarial setting,\nspecifically, for adversarial bit prediction. We characterize the bit sequences\nwith the smallest and largest expected regret. Among sequences of length $T$\nwith $k < \\frac{T}{2}$ zeros, the sequences of largest regret consist of\nalternating zeros and ones followed by the remaining ones, and the sequence of\nsmallest regret consists of ones followed by zeros. We also bound the regret of\nthose sequences, the worse case sequences have regret $O(\\sqrt{T})$ and the\nbest case sequence have regret $O(1)$.\n  We extend our results to a model where false positive and false negative\nerrors have different weights. We characterize the sequences with largest\nexpected regret in this generalized setting, and derive their regret bounds. We\nalso show that there are sequences with $O(1)$ regret.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 10:54:15 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 15:01:16 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 11:24:08 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Lewi", "Yuval", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1906.09060", "submitter": "Jeffrey Ede BSc MPhys", "authors": "Jeffrey M. Ede and Richard Beanland", "title": "Adaptive Learning Rate Clipping Stabilizes Learning", "comments": "7 pages, 6 figures, 1 table", "journal-ref": "Mach. Learn.: Sci. Technol. 1 015011 (2020)", "doi": "10.1088/2632-2153/ab81e2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial neural network training with stochastic gradient descent can be\ndestabilized by \"bad batches\" with high losses. This is often problematic for\ntraining with small batch sizes, high order loss functions or unstably high\nlearning rates. To stabilize learning, we have developed adaptive learning rate\nclipping (ALRC) to limit backpropagated losses to a number of standard\ndeviations above their running means. ALRC is designed to complement existing\nlearning algorithms: Our algorithm is computationally inexpensive, can be\napplied to any loss function or batch size, is robust to hyperparameter choices\nand does not affect backpropagated gradient distributions. Experiments with\nCIFAR-10 supersampling show that ALCR decreases errors for unstable mean\nquartic error training while stable mean squared error training is unaffected.\nWe also show that ALRC decreases unstable mean squared errors for partial\nscanning transmission electron micrograph completion. Our source code is\npublicly available at https://github.com/Jeffrey-Ede/ALRC\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 11:00:17 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 08:20:05 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ede", "Jeffrey M.", ""], ["Beanland", "Richard", ""]]}, {"id": "1906.09069", "submitter": "Thanh Huy Nguyen", "authors": "Thanh Huy Nguyen, Umut \\c{S}im\\c{s}ekli, Mert G\\\"urb\\\"uzbalaban,\n  Ga\\\"el Richard", "title": "First Exit Time Analysis of Stochastic Gradient Descent Under\n  Heavy-Tailed Gradient Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been widely used in machine learning\ndue to its computational efficiency and favorable generalization properties.\nRecently, it has been empirically demonstrated that the gradient noise in\nseveral deep learning settings admits a non-Gaussian, heavy-tailed behavior.\nThis suggests that the gradient noise can be modeled by using $\\alpha$-stable\ndistributions, a family of heavy-tailed distributions that appear in the\ngeneralized central limit theorem. In this context, SGD can be viewed as a\ndiscretization of a stochastic differential equation (SDE) driven by a L\\'{e}vy\nmotion, and the metastability results for this SDE can then be used for\nilluminating the behavior of SGD, especially in terms of `preferring wide\nminima'. While this approach brings a new perspective for analyzing SGD, it is\nlimited in the sense that, due to the time discretization, SGD might admit a\nsignificantly different behavior than its continuous-time limit. Intuitively,\nthe behaviors of these two systems are expected to be similar to each other\nonly when the discretization step is sufficiently small; however, to the best\nof our knowledge, there is no theoretical understanding on how small the\nstep-size should be chosen in order to guarantee that the discretized system\ninherits the properties of the continuous-time system. In this study, we\nprovide formal theoretical analysis where we derive explicit conditions for the\nstep-size such that the metastability behavior of the discrete-time system is\nsimilar to its continuous-time limit. We show that the behaviors of the two\nsystems are indeed similar for small step-sizes and we identify how the error\ndepends on the algorithm and problem parameters. We illustrate our results with\nsimulations on a synthetic model and neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 11:14:59 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Nguyen", "Thanh Huy", ""], ["\u015eim\u015fekli", "Umut", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "1906.09084", "submitter": "Paul Prasse", "authors": "Paul Prasse and Rene Knaebel and Lukas Machlica and Tomas Pevny and\n  Tobias Scheffer", "title": "Joint Detection of Malicious Domains and Infected Clients", "comments": "Mach Learn (2019)", "journal-ref": null, "doi": "10.1007/s10994-019-05789-z", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detection of malware-infected computers and detection of malicious web\ndomains based on their encrypted HTTPS traffic are challenging problems,\nbecause only addresses, timestamps, and data volumes are observable. The\ndetection problems are coupled, because infected clients tend to interact with\nmalicious domains. Traffic data can be collected at a large scale, and\nantivirus tools can be used to identify infected clients in retrospect.\nDomains, by contrast, have to be labeled individually after forensic analysis.\nWe explore transfer learning based on sluice networks; this allows the\ndetection models to bootstrap each other. In a large-scale experimental study,\nwe find that the model outperforms known reference models and detects\npreviously unknown malware, previously unknown malware families, and previously\nunknown malicious domains.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 11:50:29 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Prasse", "Paul", ""], ["Knaebel", "Rene", ""], ["Machlica", "Lukas", ""], ["Pevny", "Tomas", ""], ["Scheffer", "Tobias", ""]]}, {"id": "1906.09086", "submitter": "Fatima Haouari", "authors": "Fatima Haouari, Emna Baccour, Aiman Erbad, Amr Mohamed, and Mohsen\n  Guizani", "title": "QoE-Aware Resource Allocation for Crowdsourced Live Streaming: A Machine\n  Learning Approach", "comments": "This paper was accepted in the Proceedings of ICC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.HC cs.LG cs.MM cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the tremendous technological advancement of personal devices and\nthe prevalence of wireless mobile network accesses, the world has witnessed an\nexplosion in crowdsourced live streaming. Ensuring a better viewers quality of\nexperience (QoE) is the key to maximize the audiences number and increase\nstreaming providers' profits. This can be achieved by advocating a\ngeo-distributed cloud infrastructure to allocate the multimedia resources as\nclose as possible to viewers, in order to minimize the access delay and video\nstalls. Moreover, allocating the exact needed resources beforehand avoids\nover-provisioning, which may lead to significant costs by the service\nproviders. In the contrary, under-provisioning might cause significant delays\nto the viewers. In this paper, we introduce a prediction driven resource\nallocation framework, to maximize the QoE of viewers and minimize the resource\nallocation cost. First, by exploiting the viewers locations available in our\nunique dataset, we implement a machine learning model to predict the viewers\nnumber near each geo-distributed cloud site. Second, based on the predicted\nresults that showed to be close to the actual values, we formulate an\noptimization problem to proactively allocate resources at the viewers\nproximity. Additionally, we will present a trade-off between the video access\ndelay and the cost of resource allocation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:57:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Haouari", "Fatima", ""], ["Baccour", "Emna", ""], ["Erbad", "Aiman", ""], ["Mohamed", "Amr", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1906.09088", "submitter": "Jovan Tanevski", "authors": "\\v{Z}iga Luk\\v{s}i\\v{c} and Jovan Tanevski and Sa\\v{s}o D\\v{z}eroski\n  and Ljup\\v{c}o Todorovski", "title": "Meta-Model Framework for Surrogate-Based Parameter Estimation in\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2959846", "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The central task in modeling complex dynamical systems is parameter\nestimation. This task involves numerous evaluations of a computationally\nexpensive objective function. Surrogate-based optimization introduces a\ncomputationally efficient predictive model that approximates the value of the\nobjective function. The standard approach involves learning a surrogate from\ntraining examples that correspond to past evaluations of the objective\nfunction. Current surrogate-based optimization methods use static, predefined\nsubstitution strategies that decide when to use the surrogate and when the true\nobjective. We introduce a meta-model framework where the substitution strategy\nis dynamically adapted to the solution space of the given optimization problem.\nThe meta model encapsulates the objective function, the surrogate model and the\nmodel of the substitution strategy, as well as components for learning them.\nThe framework can be seamlessly coupled with an arbitrary optimization\nalgorithm without any modification: it replaces the objective function and\nautonomously decides how to evaluate a given candidate solution. We test the\nutility of the framework on three tasks of estimating parameters of real-world\nmodels of dynamical systems. The results show that the meta model significantly\nimproves the efficiency of optimization, reducing the total number of\nevaluations of the objective function up to an average of 77%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 12:12:38 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 09:15:10 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Luk\u0161i\u010d", "\u017diga", ""], ["Tanevski", "Jovan", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Todorovski", "Ljup\u010do", ""]]}, {"id": "1906.09114", "submitter": "Aristide Charles Yedia Tossou", "authors": "Aristide Tossou, Christos Dimitrakakis, Debabrota Basu", "title": "Near-optimal Bayesian Solution For Unknown Discrete Markov Decision\n  Process", "comments": "Improved the text and added detailed proofs of claims Change title to\n  better express the solution proposed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of acting in an unknown finite and discrete Markov\nDecision Process (MDP) for which the expected shortest path from any state to\nany other state is bounded by a finite number $D$. An MDP consists of $S$\nstates and $A$ possible actions per state. Upon choosing an action $a_t$ at\nstate $s_t$, one receives a real value reward $r_t$, then one transits to a\nnext state $s_{t+1}$. The reward $r_t$ is generated from a fixed reward\ndistribution depending only on $(s_t, a_t)$ and similarly, the next state\n$s_{t+1}$ is generated from a fixed transition distribution depending only on\n$(s_t, a_t)$. The objective is to maximize the accumulated rewards after $T$\ninteractions. In this paper, we consider the case where the reward\ndistributions, the transitions, $T$ and $D$ are all unknown. We derive the\nfirst polynomial time Bayesian algorithm, BUCRL{} that achieves up to logarithm\nfactors, a regret (i.e the difference between the accumulated rewards of the\noptimal policy and our algorithm) of the optimal order\n$\\tilde{\\mathcal{O}}(\\sqrt{DSAT})$. Importantly, our result holds with high\nprobability for the worst-case (frequentist) regret and not the weaker notion\nof Bayesian regret. We perform experiments in a variety of environments that\ndemonstrate the superiority of our algorithm over previous techniques.\n  Our work also illustrates several results that will be of independent\ninterest. In particular, we derive a sharper upper bound for the KL-divergence\nof Bernoulli random variables. We also derive sharper upper and lower bounds\nfor Beta and Binomial quantiles. All the bound are very simple and only use\nelementary functions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 06:32:36 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 21:47:50 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Tossou", "Aristide", ""], ["Dimitrakakis", "Christos", ""], ["Basu", "Debabrota", ""]]}, {"id": "1906.09116", "submitter": "Adria Gascon", "authors": "Borja Balle, James Bell, Adria Gascon, Kobbi Nissim", "title": "Differentially Private Summation with Multi-Message Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, Cheu et al. (Eurocrypt 2019) proposed a protocol for\n$n$-party real summation in the shuffle model of differential privacy with\n$O_{\\epsilon, \\delta}(1)$ error and $\\Theta(\\epsilon\\sqrt{n})$ one-bit messages\nper party. In contrast, every local model protocol for real summation must\nincur error $\\Omega(1/\\sqrt{n})$, and there exist protocols matching this lower\nbound which require just one bit of communication per party. Whether this gap\nin number of messages is necessary was left open by Cheu et al.\n  In this note we show a protocol with $O(1/\\epsilon)$ error and\n$O(\\log(n/\\delta))$ messages of size $O(\\log(n))$ per party. This protocol is\nbased on the work of Ishai et al.\\ (FOCS 2006) showing how to implement\ndistributed summation from secure shuffling, and the observation that this\nallows simulating the Laplace mechanism in the shuffle model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:45:21 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 14:32:33 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 18:36:00 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Balle", "Borja", ""], ["Bell", "James", ""], ["Gascon", "Adria", ""], ["Nissim", "Kobbi", ""]]}, {"id": "1906.09155", "submitter": "Shlomo Dubnov", "authors": "Shlomo Dubnov", "title": "Query-based Deep Improvisation", "comments": null, "journal-ref": "7th International Workshop on Musical Metacreation, International\n  Conference on Computational Creativity 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we explore techniques for generating new music using a\nVariational Autoencoder (VAE) neural network that was trained on a corpus of\nspecific style. Instead of randomly sampling the latent states of the network\nto produce free improvisation, we generate new music by querying the network\nwith musical input in a style different from the training corpus. This allows\nus to produce new musical output with longer-term structure that blends aspects\nof the query to the style of the network. In order to control the level of this\nblending we add a noisy channel between the VAE encoder and decoder using\nbit-allocation algorithm from communication rate-distortion theory. Our\nexperiments provide new insight into relations between the representational and\nstructural information of latent states and the query signal, suggesting their\npossible use for composition purposes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 14:09:22 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Dubnov", "Shlomo", ""]]}, {"id": "1906.09199", "submitter": "Wil Ward", "authors": "Wil O. C. Ward, Tom Ryder, Dennis Prangle, Mauricio A. \\'Alvarez", "title": "Black-Box Inference for Non-Linear Latent Force Models", "comments": "13 pages plus references and supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent force models are systems whereby there is a mechanistic model\ndescribing the dynamics of the system state, with some unknown forcing term\nthat is approximated with a Gaussian process. If such dynamics are non-linear,\nit can be difficult to estimate the posterior state and forcing term jointly,\nparticularly when there are system parameters that also need estimating. This\npaper uses black-box variational inference to jointly estimate the posterior,\ndesigning a multivariate extension to local inverse autoregressive flows as a\nflexible approximater of the system. We compare estimates on systems where the\nposterior is known, demonstrating the effectiveness of the approximation, and\napply to problems with non-linear dynamics, multi-output systems and models\nwith non-Gaussian likelihoods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:35:08 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 10:24:28 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ward", "Wil O. C.", ""], ["Ryder", "Tom", ""], ["Prangle", "Dennis", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1906.09205", "submitter": "Fengda Zhu", "authors": "Fengda Zhu, Xiaojun Chang, Runhao Zeng, Mingkui Tan", "title": "Continual Reinforcement Learning with Diversity Exploration and\n  Adversarial Self-Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has made significant progress in the field of\ncontinuous control, such as physical control and autonomous driving. However,\nit is challenging for a reinforcement model to learn a policy for each task\nsequentially due to catastrophic forgetting. Specifically, the model would\nforget knowledge it learned in the past when trained on a new task. We consider\nthis challenge from two perspectives: i) acquiring task-specific skills is\ndifficult since task information and rewards are not highly related; ii)\nlearning knowledge from previous experience is difficult in continuous control\ndomains. In this paper, we introduce an end-to-end framework namely Continual\nDiversity Adversarial Network (CDAN). We first develop an unsupervised\ndiversity exploration method to learn task-specific skills using an\nunsupervised objective. Then, we propose an adversarial self-correction\nmechanism to learn knowledge by exploiting past experience. The two learning\nprocedures are presumably reciprocal. To evaluate the proposed method, we\npropose a new continuous reinforcement learning environment named Continual Ant\nMaze (CAM) and a new metric termed Normalized Shorten Distance (NSD). The\nexperimental results confirm the effectiveness of diversity exploration and\nself-correction. It is worthwhile noting that our final result outperforms\nbaseline by 18.35% in terms of NSD, and 0.61 according to the average reward.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:44:41 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhu", "Fengda", ""], ["Chang", "Xiaojun", ""], ["Zeng", "Runhao", ""], ["Tan", "Mingkui", ""]]}, {"id": "1906.09211", "submitter": "Maxim Raginsky", "authors": "Joshua Hanson and Maxim Raginsky", "title": "Universal Approximation of Input-Output Maps by Temporal Convolutional\n  Nets", "comments": "final version to appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent shift in sequence-to-sequence modeling from recurrent\nnetwork architectures to convolutional network architectures due to\ncomputational advantages in training and operation while still achieving\ncompetitive performance. For systems having limited long-term temporal\ndependencies, the approximation capability of recurrent networks is essentially\nequivalent to that of temporal convolutional nets (TCNs). We prove that TCNs\ncan approximate a large class of input-output maps having approximately finite\nmemory to arbitrary error tolerance. Furthermore, we derive quantitative\napproximation rates for deep ReLU TCNs in terms of the width and depth of the\nnetwork and modulus of continuity of the original input-output map, and apply\nthese results to input-output maps of systems that admit finite-dimensional\nstate-space realizations (i.e., recurrent models).\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:55:43 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 14:41:36 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hanson", "Joshua", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1906.09218", "submitter": "Samuel Yeom", "authors": "Emily Black, Samuel Yeom, Matt Fredrikson", "title": "FlipTest: Fairness Testing via Optimal Transport", "comments": "Accepted to ACM FAT* 2020; The first two authors contributed equally", "journal-ref": null, "doi": "10.1145/3351095.3372845", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FlipTest, a black-box technique for uncovering discrimination in\nclassifiers. FlipTest is motivated by the intuitive question: had an individual\nbeen of a different protected status, would the model have treated them\ndifferently? Rather than relying on causal information to answer this question,\nFlipTest leverages optimal transport to match individuals in different\nprotected groups, creating similar pairs of in-distribution samples. We show\nhow to use these instances to detect discrimination by constructing a\n\"flipset\": the set of individuals whose classifier output changes\npost-translation, which corresponds to the set of people who may be harmed\nbecause of their group membership. To shed light on why the model treats a\ngiven subgroup differently, FlipTest produces a \"transparency report\": a\nranking of features that are most associated with the model's behavior on the\nflipset. Evaluating the approach on three case studies, we show that this\nprovides a computationally inexpensive way to identify subgroups that may be\nharmed by model discrimination, including in cases where the model satisfies\ngroup fairness criteria.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:05:56 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 15:12:43 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 19:39:38 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 22:25:30 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Black", "Emily", ""], ["Yeom", "Samuel", ""], ["Fredrikson", "Matt", ""]]}, {"id": "1906.09222", "submitter": "Sergio G\\'omez", "authors": "Alberto Fern\\'andez, Sergio G\\'omez", "title": "Versatile linkage: a family of space-conserving strategies for\n  agglomerative hierarchical clustering", "comments": "To appear in Journal of Classification. Software for Versatile\n  linkage available at http://deim.urv.cat/~sergio.gomez/multidendrograms.php", "journal-ref": "Journal of Classification 37 (2020) 584-597", "doi": "10.1007/s00357-019-09339-z", "report-no": null, "categories": "stat.ME cs.IR physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agglomerative hierarchical clustering can be implemented with several\nstrategies that differ in the way elements of a collection are grouped together\nto build a hierarchy of clusters. Here we introduce versatile linkage, a new\ninfinite system of agglomerative hierarchical clustering strategies based on\ngeneralized means, which go from single linkage to complete linkage, passing\nthrough arithmetic average linkage and other clustering methods yet unexplored\nsuch as geometric linkage and harmonic linkage. We compare the different\nclustering strategies in terms of cophenetic correlation, mean absolute error,\nand also tree balance and space distortion, two new measures proposed to\ndescribe hierarchical trees. Unlike the $\\beta$-flexible clustering system, we\nshow that the versatile linkage family is space-conserving.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:10:24 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Fern\u00e1ndez", "Alberto", ""], ["G\u00f3mez", "Sergio", ""]]}, {"id": "1906.09223", "submitter": "Janith C. Petangoda", "authors": "Janith C. Petangoda, Sergio Pascual-Diaz, Vincent Adam, Peter Vrancx,\n  Jordi Grau-Moya", "title": "Disentangled Skill Embeddings for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for multi-task reinforcement learning (MTRL).\nUsing a variational inference formulation, we learn policies that generalize\nacross both changing dynamics and goals. The resulting policies are\nparametrized by shared parameters that allow for transfer between different\ndynamics and goal conditions, and by task-specific latent-space embeddings that\nallow for specialization to particular tasks. We show how the latent-spaces\nenable generalization to unseen dynamics and goals conditions. Additionally,\npolicies equipped with such embeddings serve as a space of skills (or options)\nfor hierarchical reinforcement learning. Since we can change task dynamics and\ngoals independently, we name our framework Disentangled Skill Embeddings (DSE).\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:12:15 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Petangoda", "Janith C.", ""], ["Pascual-Diaz", "Sergio", ""], ["Adam", "Vincent", ""], ["Vrancx", "Peter", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1906.09230", "submitter": "Mohammad Malekzadeh", "authors": "Edoardo Lisi, Mohammad Malekzadeh, Hamed Haddadi, F. Din-Houn Lau,\n  Seth Flaxman", "title": "Modeling and Forecasting Art Movements with CGANs", "comments": "15 pages, 6 figures", "journal-ref": "Royal Society Open Science, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Generative Adversarial Networks~(CGAN) are a recent and popular\nmethod for generating samples from a probability distribution conditioned on\nlatent information. The latent information often comes in the form of a\ndiscrete label from a small set. We propose a novel method for training CGANs\nwhich allows us to condition on a sequence of continuous latent distributions\n$f^{(1)}, \\ldots, f^{(K)}$. This training allows CGANs to generate samples from\na sequence of distributions. We apply our method to paintings from a sequence\nof artistic movements, where each movement is considered to be its own\ndistribution. Exploiting the temporal aspect of the data, a vector\nautoregressive (VAR) model is fitted to the means of the latent distributions\nthat we learn, and used for one-step-ahead forecasting, to predict the latent\ndistribution of a future art movement $f^{{(K+1)}}$. Realisations from this\ndistribution can be used by the CGAN to generate \"future\" paintings. In\nexperiments, this novel methodology generates accurate predictions of the\nevolution of art. The training set consists of a large dataset of past\npaintings. While there is no agreement on exactly what current art period we\nfind ourselves in, we test on plausible candidate sets of present art, and show\nthat the mean distance to our predictions is small.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:32:06 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 17:40:34 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Lisi", "Edoardo", ""], ["Malekzadeh", "Mohammad", ""], ["Haddadi", "Hamed", ""], ["Lau", "F. Din-Houn", ""], ["Flaxman", "Seth", ""]]}, {"id": "1906.09231", "submitter": "Om Thakkar", "authors": "Ryan Rogers, Aaron Roth, Adam Smith, Nathan Srebro, Om Thakkar, Blake\n  Woodworth", "title": "Guaranteed Validity for Empirical Approaches to Adaptive Data Analysis", "comments": "Accepted to appear in the proceedings of the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a general framework for answering adaptive statistical queries that\nfocuses on providing explicit confidence intervals along with point estimates.\nPrior work in this area has either focused on providing tight confidence\nintervals for specific analyses, or providing general worst-case bounds for\npoint estimates. Unfortunately, as we observe, these worst-case bounds are\nloose in many settings --- often not even beating simple baselines like sample\nsplitting. Our main contribution is to design a framework for providing valid,\ninstance-specific confidence intervals for point estimates that can be\ngenerated by heuristics. When paired with good heuristics, this method gives\nguarantees that are orders of magnitude better than the best worst-case bounds.\nWe provide a Python library implementing our method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:33:02 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 05:30:40 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Rogers", "Ryan", ""], ["Roth", "Aaron", ""], ["Smith", "Adam", ""], ["Srebro", "Nathan", ""], ["Thakkar", "Om", ""], ["Woodworth", "Blake", ""]]}, {"id": "1906.09234", "submitter": "Robin Vogel", "authors": "Robin Vogel, Aur\\'elien Bellet, Stephan Cl\\'emen\\c{c}on, Ons Jelassi,\n  Guillaume Papa", "title": "Trade-offs in Large-Scale Distributed Tuplewise Estimation and Learning", "comments": "23 pages, 6 figures, ECML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of cluster computing frameworks has allowed practitioners to\nscale out various statistical estimation and machine learning algorithms with\nminimal programming effort. This is especially true for machine learning\nproblems whose objective function is nicely separable across individual data\npoints, such as classification and regression. In contrast, statistical\nlearning tasks involving pairs (or more generally tuples) of data points - such\nas metric learning, clustering or ranking do not lend themselves as easily to\ndata-parallelism and in-memory computing. In this paper, we investigate how to\nbalance between statistical performance and computational efficiency in such\ndistributed tuplewise statistical problems. We first propose a simple strategy\nbased on occasionally repartitioning data across workers between parallel\ncomputation stages, where the number of repartitioning steps rules the\ntrade-off between accuracy and runtime. We then present some theoretical\nresults highlighting the benefits brought by the proposed method in terms of\nvariance reduction, and extend our results to design distributed stochastic\ngradient descent algorithms for tuplewise empirical risk minimization. Our\nresults are supported by numerical experiments in pairwise statistical\nestimation and learning on synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:45:05 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Vogel", "Robin", ""], ["Bellet", "Aur\u00e9lien", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""], ["Jelassi", "Ons", ""], ["Papa", "Guillaume", ""]]}, {"id": "1906.09235", "submitter": "Zhiqin Xu", "authors": "Tao Luo, Zheng Ma, Zhi-Qin John Xu, Yaoyu Zhang", "title": "Theory of the Frequency Principle for General Deep Neural Networks", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with fruitful applications of Deep Neural Networks (DNNs) to realistic\nproblems, recently, some empirical studies of DNNs reported a universal\nphenomenon of Frequency Principle (F-Principle): a DNN tends to learn a target\nfunction from low to high frequencies during the training. The F-Principle has\nbeen very useful in providing both qualitative and quantitative understandings\nof DNNs. In this paper, we rigorously investigate the F-Principle for the\ntraining dynamics of a general DNN at three stages: initial stage, intermediate\nstage, and final stage. For each stage, a theorem is provided in terms of\nproper quantities characterizing the F-Principle. Our results are general in\nthe sense that they work for multilayer networks with general activation\nfunctions, population densities of data, and a large class of loss functions.\nOur work lays a theoretical foundation of the F-Principle for a better\nunderstanding of the training process of DNNs.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:46:04 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 03:28:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Luo", "Tao", ""], ["Ma", "Zheng", ""], ["Xu", "Zhi-Qin John", ""], ["Zhang", "Yaoyu", ""]]}, {"id": "1906.09237", "submitter": "Danilo Jimenez Rezende", "authors": "Karol Gregor and Danilo Jimenez Rezende and Frederic Besse and Yan Wu\n  and Hamza Merzic and Aaron van den Oord", "title": "Shaping Belief States with Generative Environment Models for RL", "comments": "pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents interact with a complex environment, they must form and maintain\nbeliefs about the relevant aspects of that environment. We propose a way to\nefficiently train expressive generative models in complex environments. We show\nthat a predictive algorithm with an expressive generative model can form stable\nbelief-states in visually rich and dynamic 3D environments. More precisely, we\nshow that the learned representation captures the layout of the environment as\nwell as the position and orientation of the agent. Our experiments show that\nthe model substantially improves data-efficiency on a number of reinforcement\nlearning (RL) tasks compared with strong model-free baseline agents. We find\nthat predicting multiple steps into the future (overshooting), in combination\nwith an expressive generative model, is critical for stable representations to\nemerge. In practice, using expressive generative models in RL is\ncomputationally expensive and we propose a scheme to reduce this computational\nburden, allowing us to build agents that are competitive with model-free\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:54:42 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 15:36:55 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gregor", "Karol", ""], ["Rezende", "Danilo Jimenez", ""], ["Besse", "Frederic", ""], ["Wu", "Yan", ""], ["Merzic", "Hamza", ""], ["Oord", "Aaron van den", ""]]}, {"id": "1906.09243", "submitter": "Robin Vogel", "authors": "St\\'ephan Cl\\'emen\\c{c}on, Robin Vogel", "title": "On Tree-based Methods for Similarity Learning", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": "10.1007/978-3-030-37599-7_56", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many situations, the choice of an adequate similarity measure or metric on\nthe feature space dramatically determines the performance of machine learning\nmethods. Building automatically such measures is the specific purpose of\nmetric/similarity learning. In Vogel et al. (2018), similarity learning is\nformulated as a pairwise bipartite ranking problem: ideally, the larger the\nprobability that two observations in the feature space belong to the same class\n(or share the same label), the higher the similarity measure between them. From\nthis perspective, the ROC curve is an appropriate performance criterion and it\nis the goal of this article to extend recursive tree-based ROC optimization\ntechniques in order to propose efficient similarity learning algorithms. The\nvalidity of such iterative partitioning procedures in the pairwise setting is\nestablished by means of results pertaining to the theory of U-processes and\nfrom a practical angle, it is discussed at length how to implement them by\nmeans of splitting rules specifically tailored to the similarity learning task.\nBeyond these theoretical/methodological contributions, numerical experiments\nare displayed and provide strong empirical evidence of the performance of the\nalgorithmic approaches we propose.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:03:51 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Cl\u00e9men\u00e7on", "St\u00e9phan", ""], ["Vogel", "Robin", ""]]}, {"id": "1906.09247", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, Siddhartha\n  Jayanti", "title": "Learning from weakly dependent data under Dobrushin's condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical learning theory has largely focused on learning and\ngeneralization given independent and identically distributed (i.i.d.) samples.\nMotivated by applications involving time-series data, there has been a growing\nliterature on learning and generalization in settings where data is sampled\nfrom an ergodic process. This work has also developed complexity measures,\nwhich appropriately extend the notion of Rademacher complexity to bound the\ngeneralization error and learning rates of hypothesis classes in this setting.\nRather than time-series data, our work is motivated by settings where data is\nsampled on a network or a spatial domain, and thus do not fit well within the\nframework of prior work. We provide learning and generalization bounds for data\nthat are complexly dependent, yet their distribution satisfies the standard\nDobrushin's condition. Indeed, we show that the standard complexity measures of\nGaussian and Rademacher complexities and VC dimension are sufficient measures\nof complexity for the purposes of bounding the generalization error and\nlearning rates of hypothesis classes in our setting. Moreover, our\ngeneralization bounds only degrade by constant factors compared to their i.i.d.\nanalogs, and our learnability bounds degrade by log factors in the size of the\ntraining set.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:14:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Jayanti", "Siddhartha", ""]]}, {"id": "1906.09248", "submitter": "Selim Ickin", "authors": "Selim Ickin, Konstantinos Vandikas, Markus Fiedler", "title": "Privacy Preserving QoE Modeling using Collaborative Learning", "comments": "6 pages, 4 figures, 7 tables, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning based Quality of Experience (QoE) models potentially suffer\nfrom over-fitting due to limitations including low data volume, and limited\nparticipant profiles. This prevents models from becoming generic. Consequently,\nthese trained models may under-perform when tested outside the experimented\npopulation. One reason for the limited datasets, which we refer in this paper\nas small QoE data lakes, is due to the fact that often these datasets\npotentially contain user sensitive information and are only collected\nthroughout expensive user studies with special user consent. Thus, sharing of\ndatasets amongst researchers is often not allowed. In recent years, privacy\npreserving machine learning models have become important and so have techniques\nthat enable model training without sharing datasets but instead relying on\nsecure communication protocols. Following this trend, in this paper, we present\nRound-Robin based Collaborative Machine Learning model training, where the\nmodel is trained in a sequential manner amongst the collaborated partner nodes.\nWe benchmark this work using our customized Federated Learning mechanism as\nwell as conventional Centralized and Isolated Learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:14:53 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 13:25:59 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Ickin", "Selim", ""], ["Vandikas", "Konstantinos", ""], ["Fiedler", "Markus", ""]]}, {"id": "1906.09255", "submitter": "Ashwin Pananjady", "authors": "Avishek Ghosh, Ashwin Pananjady, Adityanand Guntuboyina, Kannan\n  Ramchandran", "title": "Max-Affine Regression: Provable, Tractable, and Near-Optimal Statistical\n  Estimation", "comments": "The first two authors contributed equally to this work and are\n  ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-affine regression refers to a model where the unknown regression function\nis modeled as a maximum of $k$ unknown affine functions for a fixed $k \\geq 1$.\nThis generalizes linear regression and (real) phase retrieval, and is closely\nrelated to convex regression. Working within a non-asymptotic framework, we\nstudy this problem in the high-dimensional setting assuming that $k$ is a fixed\nconstant, and focus on estimation of the unknown coefficients of the affine\nfunctions underlying the model. We analyze a natural alternating minimization\n(AM) algorithm for the non-convex least squares objective when the design is\nrandom. We show that the AM algorithm, when initialized suitably, converges\nwith high probability and at a geometric rate to a small ball around the\noptimal coefficients. In order to initialize the algorithm, we propose and\nanalyze a combination of a spectral method and a random search scheme in a\nlow-dimensional space, which may be of independent interest. The final rate\nthat we obtain is near-parametric and minimax optimal (up to a poly-logarithmic\nfactor) as a function of the dimension, sample size, and noise variance. In\nthat sense, our approach should be viewed as a direct and implementable method\nof enforcing regularization to alleviate the curse of dimensionality in\nproblems of the convex regression type. As a by-product of our analysis, we\nalso obtain guarantees on a classical algorithm for the phase retrieval problem\nunder considerably weaker assumptions on the design distribution than was\npreviously known. Numerical experiments illustrate the sharpness of our bounds\nin the various problem parameters.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:47:18 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ghosh", "Avishek", ""], ["Pananjady", "Ashwin", ""], ["Guntuboyina", "Adityanand", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1906.09256", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Testing randomness", "comments": "34 pages, 1 table, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis of randomness is fundamental in statistical machine learning\nand in many areas of nonparametric statistics; it says that the observations\nare assumed to be independent and coming from the same unknown probability\ndistribution. This hypothesis is close, in certain respects, to the hypothesis\nof exchangeability, which postulates that the distribution of the observations\nis invariant with respect to their permutations. This paper reviews known\nmethods of testing the two hypotheses concentrating on the online mode of\ntesting, when the observations arrive sequentially. All known online methods\nfor testing these hypotheses are based on conformal martingales, which are\ndefined and studied in detail. The paper emphasizes conceptual and practical\naspects and states two kinds of results. Validity results limit the probability\nof a false alarm or the frequency of false alarms for various procedures based\non conformal martingales, including conformal versions of the CUSUM and\nShiryaev-Roberts procedures. Efficiency results establish connections between\nrandomness, exchangeability, and conformal martingales.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:49:42 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 15:07:52 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 12:49:21 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "1906.09264", "submitter": "Baihan Lin", "authors": "Baihan Lin, Marieke Mur, Tim Kietzmann, Nikolaus Kriegeskorte", "title": "Visualizing Representational Dynamics with Multidimensional Scaling\n  Alignment", "comments": "CCN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational similarity analysis (RSA) has been shown to be an effective\nframework to characterize brain-activity profiles and deep neural network\nactivations as representational geometry by computing the pairwise distances of\nthe response patterns as a representational dissimilarity matrix (RDM).\nHowever, how to properly analyze and visualize the representational geometry as\ndynamics over the time course from stimulus onset to offset is not well\nunderstood. In this work, we formulated the pipeline to understand\nrepresentational dynamics with RDM movies and Procrustes-aligned\nMultidimensional Scaling (pMDS), and applied it to neural recording of monkey\nIT cortex. Our results suggest that the the multidimensional scaling alignment\ncan genuinely capture the dynamics of the category-specific representation\nspaces with multiple visualization possibilities, and that object\ncategorization may be hierarchical, multi-staged, and oscillatory (or\nrecurrent).\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:46:18 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 12:07:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lin", "Baihan", ""], ["Mur", "Marieke", ""], ["Kietzmann", "Tim", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1906.09293", "submitter": "Shubham Rathi", "authors": "Shubham Rathi", "title": "Generating Counterfactual and Contrastive Explanations using SHAP", "comments": "This work was presented at 2nd Workshop on Humanizing AI (HAI) at\n  IJCAI'19 in Macao, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of GDPR, the domain of explainable AI and model\ninterpretability has gained added impetus. Methods to extract and communicate\nvisibility into decision-making models have become legal requirement. Two\nspecific types of explanations, contrastive and counterfactual have been\nidentified as suitable for human understanding. In this paper, we propose a\nmodel agnostic method and its systemic implementation to generate these\nexplanations using shapely additive explanations (SHAP). We discuss a\ngenerative pipeline to create contrastive explanations and use it to further to\ngenerate counterfactual datapoints. This pipeline is tested and discussed on\nthe IRIS, Wine Quality & Mobile Features dataset. Analysis of the results\nobtained follows.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:13:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Rathi", "Shubham", ""]]}, {"id": "1906.09300", "submitter": "Sobhan Soleymani", "authors": "Sobhan Soleymani, Ali Dabouei, Jeremy Dawson, and Nasser M. Nasrabadi", "title": "Adversarial Examples to Fool Iris Recognition Systems", "comments": "2019 International Conference on Biometrics (ICB 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have recently proven to be able to fool deep learning\nmethods by adding carefully crafted small perturbation to the input space\nimage. In this paper, we study the possibility of generating adversarial\nexamples for code-based iris recognition systems. Since generating adversarial\nexamples requires back-propagation of the adversarial loss, conventional filter\nbank-based iris-code generation frameworks cannot be employed in such a setup.\nTherefore, to compensate for this shortcoming, we propose to train a deep\nauto-encoder surrogate network to mimic the conventional iris code generation\nprocedure. This trained surrogate network is then deployed to generate the\nadversarial examples using the iterative gradient sign method algorithm. We\nconsider non-targeted and targeted attacks through three attack scenarios.\nConsidering these attacks, we study the possibility of fooling an iris\nrecognition system in white-box and black-box frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:30:41 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 21:09:35 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Soleymani", "Sobhan", ""], ["Dabouei", "Ali", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1906.09308", "submitter": "Asma Ghandeharioun", "authors": "Asma Ghandeharioun, Judy Hanwen Shen, Natasha Jaques, Craig Ferguson,\n  Noah Jones, Agata Lapedriza, Rosalind Picard", "title": "Approximating Interactive Human Evaluation with Self-Play for\n  Open-Domain Dialog Systems", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building an open-domain conversational agent is a challenging problem.\nCurrent evaluation methods, mostly post-hoc judgments of static conversation,\ndo not capture conversation quality in a realistic interactive context. In this\npaper, we investigate interactive human evaluation and provide evidence for its\nnecessity; we then introduce a novel, model-agnostic, and dataset-agnostic\nmethod to approximate it. In particular, we propose a self-play scenario where\nthe dialog system talks to itself and we calculate a combination of proxies\nsuch as sentiment and semantic coherence on the conversation trajectory. We\nshow that this metric is capable of capturing the human-rated quality of a\ndialog model better than any automated metric known to-date, achieving a\nsignificant Pearson correlation (r>.7, p<.05). To investigate the strengths of\nthis novel metric and interactive evaluation in comparison to state-of-the-art\nmetrics and human evaluation of static conversations, we perform extended\nexperiments with a set of models, including several that make novel\nimprovements to recent hierarchical dialog generation architectures through\nsentiment and semantic knowledge distillation on the utterance level. Finally,\nwe open-source the interactive evaluation platform we built and the dataset we\ncollected to allow researchers to efficiently deploy and evaluate dialog\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:08:18 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 01:47:34 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Jaques", "Natasha", ""], ["Ferguson", "Craig", ""], ["Jones", "Noah", ""], ["Lapedriza", "Agata", ""], ["Picard", "Rosalind", ""]]}, {"id": "1906.09323", "submitter": "Sobhan Miryoosefi", "authors": "Sobhan Miryoosefi, Kiant\\'e Brantley, Hal Daum\\'e III, Miroslav Dudik,\n  Robert Schapire", "title": "Reinforcement Learning with Convex Constraints", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (2019),\n  14093-14102", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard reinforcement learning (RL), a learning agent seeks to optimize\nthe overall reward. However, many key aspects of a desired behavior are more\nnaturally expressed as constraints. For instance, the designer may want to\nlimit the use of unsafe actions, increase the diversity of trajectories to\nenable exploration, or approximate expert trajectories when rewards are sparse.\nIn this paper, we propose an algorithmic scheme that can handle a wide class of\nconstraints in RL tasks: specifically, any constraints that require expected\nvalues of some vector measurements (such as the use of an action) to lie in a\nconvex set. This captures previously studied constraints (such as safety and\nproximity to an expert), but also enables new classes of constraints (such as\ndiversity). Our approach comes with rigorous theoretical guarantees and only\nrelies on the ability to approximately solve standard RL tasks. As a result, it\ncan be easily adapted to work with any model-free or model-based RL. In our\nexperiments, we show that it matches previous algorithms that enforce safety\nvia constraints, but can also enforce new properties that these algorithms do\nnot incorporate, such as diversity.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:04:27 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 20:00:43 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Miryoosefi", "Sobhan", ""], ["Brantley", "Kiant\u00e9", ""], ["Daum\u00e9", "Hal", "III"], ["Dudik", "Miroslav", ""], ["Schapire", "Robert", ""]]}, {"id": "1906.09325", "submitter": "Tomek Korbak", "authors": "Renard Korzeniowski and Rafa{\\l} Rolczy\\'nski and Przemys{\\l}aw\n  Sadownik and Tomasz Korbak and Marcin Mo\\.zejko", "title": "Exploiting Unsupervised Pre-training and Automated Feature Engineering\n  for Low-resource Hate Speech Detection in Polish", "comments": "http://poleval.pl/publication", "journal-ref": "Proceedings of the PolEval 2019 Workshop", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our contribution to PolEval 2019 Task 6: Hate speech and\nbullying detection. We describe three parallel approaches that we followed:\nfine-tuning a pre-trained ULMFiT model to our classification task, fine-tuning\na pre-trained BERT model to our classification task, and using the TPOT library\nto find the optimal pipeline. We present results achieved by these three tools\nand review their advantages and disadvantages in terms of user experience. Our\nteam placed second in subtask 2 with a shallow model found by TPOT: a~logistic\nregression classifier with non-trivial feature engineering.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 13:11:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Korzeniowski", "Renard", ""], ["Rolczy\u0144ski", "Rafa\u0142", ""], ["Sadownik", "Przemys\u0142aw", ""], ["Korbak", "Tomasz", ""], ["Mo\u017cejko", "Marcin", ""]]}, {"id": "1906.09331", "submitter": "Alexey Drutsa", "authors": "Alexey Drutsa", "title": "Reserve Pricing in Repeated Second-Price Auctions with Strategic Bidders", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study revenue optimization learning algorithms for repeated second-price\nauctions with reserve where a seller interacts with multiple strategic bidders\neach of which holds a fixed private valuation for a good and seeks to maximize\nhis expected future cumulative discounted surplus. We propose a novel algorithm\nthat has strategic regret upper bound of $O(\\log\\log T)$ for worst-case\nvaluations. This pricing is based on our novel transformation that upgrades an\nalgorithm designed for the setup with a single buyer to the multi-buyer case.\nWe provide theoretical guarantees on the ability of a transformed algorithm to\nlearn the valuation of a strategic buyer, which has uncertainty about the\nfuture due to the presence of rivals.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:16:22 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Drutsa", "Alexey", ""]]}, {"id": "1906.09338", "submitter": "Yunhui Long", "authors": "Yunhui Long, Suxin Lin, Zhuolin Yang, Carl A. Gunter, and Bo Li", "title": "Scalable Differentially Private Generative Student Model via PATE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent rapid development of machine learning is largely due to algorithmic\nbreakthroughs, computation resource development, and especially the access to a\nlarge amount of training data. However, though data sharing has the great\npotential of improving machine learning models and enabling new applications,\nthere have been increasing concerns about the privacy implications of data\ncollection. In this work, we present a novel approach for training\ndifferentially private data generator G-PATE. The generator can be used to\nproduce synthetic datasets with strong privacy guarantee while preserving high\ndata utility. Our approach leverages generative adversarial nets (GAN) to\ngenerate data and protect data privacy based on the Private Aggregation of\nTeacher Ensembles (PATE) framework. Our approach improves the use of privacy\nbudget by only ensuring differential privacy for the generator, which is the\npart of the model that actually needs to be published for private data\ngeneration. To achieve this, we connect a student generator with an ensemble of\nteacher discriminators. We also propose a private gradient aggregation\nmechanism to ensure differential privacy on all the information that flows from\nthe teacher discriminators to the student generator. We empirically show that\nthe G-PATE significantly outperforms prior work on both image and non-image\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:42:23 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Long", "Yunhui", ""], ["Lin", "Suxin", ""], ["Yang", "Zhuolin", ""], ["Gunter", "Carl A.", ""], ["Li", "Bo", ""]]}, {"id": "1906.09356", "submitter": "Panagiotis Traganitis", "authors": "Panagiotis A. Traganitis and Georgios B. Giannakis", "title": "Unsupervised Ensemble Classification with Sequential and Networked Data", "comments": "Accepted at IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning, the machine learning paradigm where multiple algorithms\nare combined, has exhibited promising perfomance in a variety of tasks. The\npresent work focuses on unsupervised ensemble classification. The term\nunsupervised refers to the ensemble combiner who has no knowledge of the\nground-truth labels that each classifier has been trained on. While most prior\nworks on unsupervised ensemble classification are designed for independent and\nidentically distributed (i.i.d.) data, the present work introduces an\nunsupervised scheme for learning from ensembles of classifiers in the presence\nof data dependencies. Two types of data dependencies are considered: sequential\ndata and networked data whose dependencies are captured by a graph. Moment\nmatching and Expectation Maximization algorithms are developed for the\naforementioned cases, and their performance is evaluated on synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 00:01:45 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 13:57:49 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2020 21:39:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Traganitis", "Panagiotis A.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1906.09358", "submitter": "Mohamed Hammad Dr.", "authors": "Ahmed Alghamdi, Mohamed Hammad, Hassan Ugail, Asmaa Abdel-Raheem, Khan\n  Muhammad, Hany S. Khalifa, Ahmed A. Abd El-Latif", "title": "Detection of Myocardial Infarction Based on Novel Deep Transfer Learning\n  Methods for Urban Healthcare in Smart Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  . In this paper, an effective computer-aided diagnosis (CAD) system is\npresented to detect MI signals using the convolution neural network (CNN) for\nurban healthcare in smart cities. Two types of transfer learning techniques are\nemployed to retrain the pre-trained VGG-Net (Fine-tuning and VGG-Net as fixed\nfeature extractor) and obtained two new networks VGG-MI1 and VGG-MI2. In the\nVGG-MI1 model, the last layer of the VGG-Net model is replaced with a specific\nlayer according to our requirements and various functions are optimized to\nreduce overfitting. In the VGG-MI2 model, one layer of the VGG-Net model is\nselected as a feature descriptor of the ECG images to describe it with\ninformative features. Considering the limited availability of dataset, ECG data\nis augmented which has increased the classification performance.\nPhysikalisch-technische bundesanstalt (PTB) Diagnostic ECG database is used for\nexperimentation, which has been widely employed in MI detection studies. In\ncase of using VGG-MI1, we achieved an accuracy, sensitivity, and specificity of\n99.02%, 98.76%, and 99.17%, respectively and we achieved an accuracy of 99.22%,\na sensitivity of 99.15%, and a specificity of 99.49% with VGG-MI2 model.\nExperimental results validate the efficiency of the proposed system in terms of\naccuracy sensitivity, and specificity.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 00:13:03 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 17:11:20 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Alghamdi", "Ahmed", ""], ["Hammad", "Mohamed", ""], ["Ugail", "Hassan", ""], ["Abdel-Raheem", "Asmaa", ""], ["Muhammad", "Khan", ""], ["Khalifa", "Hany S.", ""], ["El-Latif", "Ahmed A. Abd", ""]]}, {"id": "1906.09360", "submitter": "Creighton Heaukulani", "authors": "Creighton Heaukulani and Mark van der Wilk", "title": "Scalable Bayesian dynamic covariance modeling with variational Wishart\n  and inverse Wishart processes", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement gradient-based variational inference routines for Wishart and\ninverse Wishart processes, which we apply as Bayesian models for the dynamic,\nheteroskedastic covariance matrix of a multivariate time series. The Wishart\nand inverse Wishart processes are constructed from i.i.d. Gaussian processes,\nexisting variational inference algorithms for which form the basis of our\napproach. These methods are easy to implement as a black-box and scale\nfavorably with the length of the time series, however, they fail in the case of\nthe Wishart process, an issue we resolve with a simple modification into an\nadditive white noise parameterization of the model. This modification is also\nkey to implementing a factored variant of the construction, allowing inference\nto additionally scale to high-dimensional covariance matrices. Through\nexperimentation, we demonstrate that some (but not all) model variants\noutperform multivariate GARCH when forecasting the covariances of returns on\nfinancial instruments.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 00:56:13 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 08:15:06 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Heaukulani", "Creighton", ""], ["van der Wilk", "Mark", ""]]}, {"id": "1906.09381", "submitter": "Michael Matheny", "authors": "Mingxuan Han, Michael Matheny, and Jeff M. Phillips", "title": "The Kernel Spatial Scan Statistic", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kulldorff's (1997) seminal paper on spatial scan statistics (SSS) has led to\nmany methods considering different regions of interest, different statistical\nmodels, and different approximations while also having numerous applications in\nepidemiology, environmental monitoring, and homeland security. SSS provides a\nway to rigorously test for the existence of an anomaly and provide statistical\nguarantees as to how \"anomalous\" that anomaly is. However, these methods rely\non defining specific regions where the spatial information a point contributes\nis limited to binary 0 or 1, of either inside or outside the region, while in\nreality anomalies will tend to follow smooth distributions with decaying\ndensity further from an epicenter. In this work, we propose a method that\naddresses this shortcoming through a continuous scan statistic that generalizes\nSSS by allowing the point contribution to be defined by a kernel. We provide\nextensive experimental and theoretical results that shows our methods can be\ncomputed efficiently while providing high statistical power for detecting\nanomalous regions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:45:45 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 21:14:19 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Han", "Mingxuan", ""], ["Matheny", "Michael", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "1906.09382", "submitter": "Sandra Robles", "authors": "Sandra Robles, Jonathan S. G\\'omez, Ad\\'in Ram\\'irez Rivera, Jenny A.\n  Gonz\\'alez, Nelson D. Padilla, Diego Dujovne", "title": "A Halo Merger Tree Generation and Evaluation Framework", "comments": "11 pages, 7 figures, 2 tables, 3 appendices. Presented at the ICML\n  2019 Workshop on Theoretical Physics for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-analytic models are best suited to compare galaxy formation and\nevolution theories with observations. These models rely heavily on halo merger\ntrees, and their realistic features (i.e., no drastic changes on halo mass or\njumps on physical locations). Our aim is to provide a new framework for halo\nmerger tree generation that takes advantage of the results of large volume\nsimulations, with a modest computational cost. We treat halo merger tree\nconstruction as a matrix generation problem, and propose a Generative\nAdversarial Network that learns to generate realistic halo merger trees. We\nevaluate our proposal on merger trees from the EAGLE simulation suite, and show\nthe quality of the generated trees.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 03:42:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Robles", "Sandra", ""], ["G\u00f3mez", "Jonathan S.", ""], ["Rivera", "Ad\u00edn Ram\u00edrez", ""], ["Gonz\u00e1lez", "Jenny A.", ""], ["Padilla", "Nelson D.", ""], ["Dujovne", "Diego", ""]]}, {"id": "1906.09391", "submitter": "Keiichi Kisamori", "authors": "Keiichi Kisamori, Keisuke Yamazaki, Yuto Komori, Hiroshi Tokieda", "title": "Model Bridging: Connection between Simulation Model and Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretability of machine learning, particularly for deep neural\nnetworks, is crucial for decision making in real-world applications. One\napproach is replacing the un-interpretable machine learning model with a\nsurrogate model, which has a simple structure for interpretation. Another\napproach is understanding the target system by using a simulation modeled by\nhuman knowledge with interpretable simulation parameters. Recently, simulator\ncalibration has been developed based on kernel mean embedding to estimate the\nsimulation parameters as posterior distributions. Our idea is to use a\nsimulation model as an interpretable surrogate model. However, the\ncomputational cost of simulator calibration is high owing to the complexity of\nthe simulation model. Thus, we propose a ''model-bridging'' framework to bridge\nmachine learning models with simulation models by a series of kernel mean\nembeddings to address these difficulties. The proposed framework enables us to\nobtain predictions and interpretable simulation parameters simultaneously\nwithout the computationally expensive calculations of the simulations. In this\nstudy, we apply the proposed framework to essential simulations in the\nmanufacturing industry, such as production simulation and fluid dynamics\nsimulation.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 05:45:40 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 13:06:18 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 12:45:56 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Kisamori", "Keiichi", ""], ["Yamazaki", "Keisuke", ""], ["Komori", "Yuto", ""], ["Tokieda", "Hiroshi", ""]]}, {"id": "1906.09400", "submitter": "Roland Vollgraf", "authors": "Roland Vollgraf", "title": "Learning Set-equivariant Functions with SWARM Mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a new neural network architecture that efficiently\nimplements and learns general purpose set-equivariant functions. Such a\nfunction f maps a set of entities x = {x1, . . . , xn} from one domain to a set\nof same cardinality y = f (x) = {y1, . . . , yn} in another domain regardless\nof the ordering of the entities. The architecture is based on a gated recurrent\nnetwork which is iteratively applied to all entities individually and at the\nsame time syncs with the progression of the whole population. In reminiscence\nto this pattern, which can be frequently observed in nature, we call our\napproach SWARM mapping. Set-equivariant and generally permutation invariant\nfunctions are important building blocks for many state of the art machine\nlearning approaches. Even in applications where the permutation invariance is\nnot of primary interest, as to be seen in the recent success of attention based\ntransformer models (Vaswani et. al. 2017). Accordingly, we demonstrate the\npower and usefulness of SWARM mappings in different applications. We compare\nthe performance of our approach with another recently proposed set-equivariant\nfunction, the Set Transformer (Lee et.al. 2018) and we demonstrate that models\nsolely based on SWARM layers gives state of the art results.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 06:54:33 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 09:53:30 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Vollgraf", "Roland", ""]]}, {"id": "1906.09412", "submitter": "Fariba Yousefi", "authors": "Fariba Yousefi, Michael Thomas Smith, Mauricio A. \\'Alvarez", "title": "Multi-task Learning for Aggregated Data using Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregated data is commonplace in areas such as epidemiology and demography.\nFor example, census data for a population is usually given as averages defined\nover time periods or spatial resolutions (cities, regions or countries). In\nthis paper, we present a novel multi-task learning model based on Gaussian\nprocesses for joint learning of variables that have been aggregated at\ndifferent input scales. Our model represents each task as the linear\ncombination of the realizations of latent processes that are integrated at a\ndifferent scale per task. We are then able to compute the cross-covariance\nbetween the different tasks either analytically or numerically. We also allow\neach task to have a potentially different likelihood model and provide a\nvariational lower bound that can be optimised in a stochastic fashion making\nour model suitable for larger datasets. We show examples of the model in a\nsynthetic example, a fertility dataset, and an air pollution prediction\napplication.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 09:10:29 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 23:08:01 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 15:26:49 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 14:43:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Yousefi", "Fariba", ""], ["Smith", "Michael Thomas", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1906.09427", "submitter": "Pengfei Chen", "authors": "Guangyong Chen, Pengfei Chen, Chang-Yu Hsieh, Chee-Kong Lee, Benben\n  Liao, Renjie Liao, Weiwen Liu, Jiezhong Qiu, Qiming Sun, Jie Tang, Richard\n  Zemel, Shengyu Zhang", "title": "Alchemy: A Quantum Chemistry Dataset for Benchmarking AI Models", "comments": "Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new molecular dataset, named Alchemy, for developing machine\nlearning models useful in chemistry and material science. As of June 20th 2019,\nthe dataset comprises of 12 quantum mechanical properties of 119,487 organic\nmolecules with up to 14 heavy atoms, sampled from the GDB MedChem database. The\nAlchemy dataset expands the volume and diversity of existing molecular\ndatasets. Our extensive benchmarks of the state-of-the-art graph neural network\nmodels on Alchemy clearly manifest the usefulness of new data in validating and\ndeveloping machine learning models for chemistry and material science. We\nfurther launch a contest to attract attentions from researchers in the related\nfields. More details can be found on the contest website\n\\footnote{https://alchemy.tencent.com}. At the time of benchamrking experiment,\nwe have generated 119,487 molecules in our Alchemy dataset. More molecular\nsamples are generated since then. Hence, we provide a list of molecules used in\nthe reported benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 10:27:00 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Chen", "Guangyong", ""], ["Chen", "Pengfei", ""], ["Hsieh", "Chang-Yu", ""], ["Lee", "Chee-Kong", ""], ["Liao", "Benben", ""], ["Liao", "Renjie", ""], ["Liu", "Weiwen", ""], ["Qiu", "Jiezhong", ""], ["Sun", "Qiming", ""], ["Tang", "Jie", ""], ["Zemel", "Richard", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1906.09436", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Fisher and Kernel Fisher Discriminant Analysis: Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a detailed tutorial paper which explains the Fisher discriminant\nAnalysis (FDA) and kernel FDA. We start with projection and reconstruction.\nThen, one- and multi-dimensional FDA subspaces are covered. Scatters in two-\nand then multi-classes are explained in FDA. Then, we discuss on the rank of\nthe scatters and the dimensionality of the subspace. A real-life example is\nalso provided for interpreting FDA. Then, possible singularity of the scatter\nis discussed to introduce robust FDA. PCA and FDA directions are also compared.\nWe also prove that FDA and linear discriminant analysis are equivalent. Fisher\nforest is also introduced as an ensemble of fisher subspaces useful for\nhandling data with different features and dimensionality. Afterwards, kernel\nFDA is explained for both one- and multi-dimensional subspaces with both two-\nand multi-classes. Finally, some simulations are performed on AT&T face dataset\nto illustrate FDA and compare it with PCA.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 11:55:50 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1906.09437", "submitter": "Xun Zhang", "authors": "Xun Zhang, William B. Haskell, and Zhisheng Ye", "title": "A Unifying Framework for Variance Reduction Algorithms for Finding\n  Zeroes of Monotone Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to encounter large-scale monotone inclusion problems where the\nobjective has a finite sum structure. We develop a general framework for\nvariance-reduced forward-backward splitting algorithms for this problem. This\nframework includes a number of existing deterministic and variance-reduced\nalgorithms for function minimization as special cases, and it is also\napplicable to more general problems such as saddle-point problems and\nvariational inequalities. With a carefully constructed Lyapunov function, we\nshow that the algorithms covered by our framework enjoy a linear convergence\nrate in expectation under mild assumptions. We further consider Catalyst\nacceleration and asynchronous implementation to reduce the algorithmic\ncomplexity and computation time. We apply our proposed framework to a policy\nevaluation problem and a strongly monotone two-player game, both of which fall\noutside of function minimization.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 11:56:18 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 04:36:03 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhang", "Xun", ""], ["Haskell", "William B.", ""], ["Ye", "Zhisheng", ""]]}, {"id": "1906.09439", "submitter": "Maolin Shi", "authors": "Maolin Shi, Shuo Wang, Wei Sun, Liye Lv, Xueguan Song", "title": "A support vector regression-based multi-fidelity surrogate model", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational simulations with different fidelity have been widely used in\nengineering design. A high-fidelity (HF) model is generally more accurate but\nalso more time-consuming than an low-fidelity (LF) model. To take advantages of\nboth HF and LF models, multi-fidelity surrogate models that aim to integrate\ninformation from both HF and LF models have gained increasing popularity. In\nthis paper, a multi-fidelity surrogate model based on support vector regression\nnamed as Co_SVR is developed by combining HF and LF models. In Co_SVR, a kernel\nfunction is used to map the map the difference between the HF and LF models.\nBesides, a heuristic algorithm is used to obtain the optimal parameters of\nCo_SVR. The proposed Co_SVR is compared with two popular multi-fidelity\nsurrogate models Co_Kriging model, Co_RBF model, and their single-fidelity\nsurrogates through several numerical cases and a pressure vessel design\nproblem. The results show that Co_SVR provides competitive prediction accuracy\nfor numerical cases, and presents a better performance compared with the\nCo_Kriging and Co_RBF models and single-fidelity surrogate models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 12:12:46 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Shi", "Maolin", ""], ["Wang", "Shuo", ""], ["Sun", "Wei", ""], ["Lv", "Liye", ""], ["Song", "Xueguan", ""]]}, {"id": "1906.09443", "submitter": "Amir M. Mir", "authors": "A. Mir, Jalal A. Nasiri", "title": "An enhanced KNN-based twin support vector machine with stable learning\n  rules", "comments": "This paper was written in the summer of 2018. It is a part of Mir's\n  MSc thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the extensions of twin support vector machine (TSVM), some scholars\nhave utilized K-nearest neighbor (KNN) graph to enhance TSVM's classification\naccuracy. However, these KNN-based TSVM classifiers have two major issues such\nas high computational cost and overfitting. In order to address these issues,\nthis paper presents an enhanced regularized K-nearest neighbor based twin\nsupport vector machine (RKNN-TSVM). It has three additional advantages: (1)\nWeight is given to each sample by considering the distance from its nearest\nneighbors. This further reduces the effect of noise and outliers on the output\nmodel. (2) An extra stabilizer term was added to each objective function. As a\nresult, the learning rules of the proposed method are stable. (3) To reduce the\ncomputational cost of finding KNNs for all the samples, location difference of\nmultiple distances based k-nearest neighbors algorithm (LDMDBA) was embedded\ninto the learning process of the proposed method. The extensive experimental\nresults on several synthetic and benchmark datasets show the effectiveness of\nour proposed RKNN-TSVM in both classification accuracy and computational time.\nMoreover, the largest speedup in the proposed method reaches to 14 times.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:03:01 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Mir", "A.", ""], ["Nasiri", "Jalal A.", ""]]}, {"id": "1906.09453", "submitter": "Dimitris Tsipras", "authors": "Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Andrew Ilyas, Logan\n  Engstrom, Aleksander Madry", "title": "Image Synthesis with a Single (Robust) Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the basic classification framework alone can be used to tackle\nsome of the most challenging tasks in image synthesis. In contrast to other\nstate-of-the-art approaches, the toolkit we develop is rather minimal: it uses\na single, off-the-shelf classifier for all these tasks. The crux of our\napproach is that we train this classifier to be adversarially robust. It turns\nout that adversarial robustness is precisely what we need to directly\nmanipulate salient features of the input. Overall, our findings demonstrate the\nutility of robustness in the broader machine learning context. Code and models\nfor our experiments can be found at https://git.io/robust-apps.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:12:08 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 15:47:42 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Tran", "Brandon", ""], ["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Madry", "Aleksander", ""]]}, {"id": "1906.09458", "submitter": "Fabio Vitale", "authors": "Fabio Vitale, Anand Rajagopalan, Claudio Gentile", "title": "Flattening a Hierarchical Clustering through Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate active learning by pairwise similarity over the leaves of\ntrees originating from hierarchical clustering procedures. In the realizable\nsetting, we provide a full characterization of the number of queries needed to\nachieve perfect reconstruction of the tree cut. In the non-realizable setting,\nwe rely on known important-sampling procedures to obtain regret and query\ncomplexity bounds. Our algorithms come with theoretical guarantees on the\nstatistical error and, more importantly, lend themselves to linear-time\nimplementations in the relevant parameters of the problem. We discuss such\nimplementations, prove running time guarantees for them, and present\npreliminary experiments on real-world datasets showing the compelling practical\nperformance of our algorithms as compared to both passive learning and simple\nactive learning baselines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 15:03:11 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 15:41:39 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Vitale", "Fabio", ""], ["Rajagopalan", "Anand", ""], ["Gentile", "Claudio", ""]]}, {"id": "1906.09459", "submitter": "Yang Li", "authors": "Yang Li and Yaqiang Yao", "title": "Bayesian Optimization with Directionally Constrained Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization offers a flexible framework to optimize an objective\nfunction that is expensive to be evaluated. A Bayesian optimizer iteratively\nqueries the function values on its carefully selected points. Subsequently, it\nmakes a sensible recommendation about where the optimum locates based on its\naccumulated knowledge. This procedure usually demands a long execution time. In\npractice, however, there often exists a computational budget or an evaluation\nlimitation allocated to an optimizer, due to the resource scarcity. This\nconstraint demands an optimizer to be aware of its remaining budget and able to\nspend it wisely, in order to return as better a point as possible. In this\npaper, we propose a Bayesian optimization approach in this evaluation-limited\nscenario. Our approach is based on constraining searching directions so as to\ndedicate the model capability to the most promising area. It could be viewed as\na combination of local and global searching policies, which aims at reducing\ninefficient exploration in the local searching areas, thus making a searching\npolicy more efficient. Experimental studies are conducted on both synthetic and\nreal-world applications. The results demonstrate the superior performance of\nour newly proposed approach in searching for the optimum within a prescribed\nevaluation budget.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 15:04:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Yang", ""], ["Yao", "Yaqiang", ""]]}, {"id": "1906.09479", "submitter": "Ning Ning", "authors": "Wenjian Liu and Ning Ning", "title": "The non-tightness of the reconstruction threshold of a 4 states\n  symmetric model with different in-block and out-block mutations", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tree reconstruction problem is to collect and analyze massive data at the\n$n$th level of the tree, to identify whether there is non-vanishing information\nof the root, as $n$ goes to infinity. Its connection to the clustering problem\nin the setting of the stochastic block model, which has wide applications in\nmachine learning and data mining, has been well established. For the stochastic\nblock model, an \"information-theoretically-solvable-but-computationally-hard\"\nregion, or say \"hybrid-hard phase\", appears whenever the reconstruction bound\nis not tight of the corresponding reconstruction on the tree problem. Although\nit has been studied in numerous contexts, the existing literature with rigorous\nreconstruction thresholds established are very limited, and it becomes\nextremely challenging when the model under investigation has $4$ states (the\nstochastic block model with $4$ communities). In this paper, inspired by the\nnewly proposed $q_1+q_2$ stochastic block model, we study a $4$ states\nsymmetric model with different in-block and out-block transition probabilities,\nand rigorously give the conditions for the non-tightness of the reconstruction\nthreshold.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 17:57:27 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Liu", "Wenjian", ""], ["Ning", "Ning", ""]]}, {"id": "1906.09480", "submitter": "Eszter V\\'ertes", "authors": "Eszter Vertes and Maneesh Sahani", "title": "A neurally plausible model learns successor representations in partially\n  observable environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals need to devise strategies to maximize returns while interacting with\ntheir environment based on incoming noisy sensory observations. Task-relevant\nstates, such as the agent's location within an environment or the presence of a\npredator, are often not directly observable but must be inferred using\navailable sensory information. Successor representations (SR) have been\nproposed as a middle-ground between model-based and model-free reinforcement\nlearning strategies, allowing for fast value computation and rapid adaptation\nto changes in the reward function or goal locations. Indeed, recent studies\nsuggest that features of neural responses are consistent with the SR framework.\nHowever, it is not clear how such representations might be learned and computed\nin partially observed, noisy environments. Here, we introduce a neurally\nplausible model using distributional successor features, which builds on the\ndistributed distributional code for the representation and computation of\nuncertainty, and which allows for efficient value function computation in\npartially observed environments via the successor representation. We show that\ndistributional successor features can support reinforcement learning in noisy\nenvironments in which direct learning of successful policies is infeasible.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 18:05:07 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Vertes", "Eszter", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1906.09489", "submitter": "Nick Ryder", "authors": "Nick Ryder, Zohar Karnin, Edo Liberty", "title": "Asymmetric Random Projections", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projections (RP) are a popular tool for reducing dimensionality while\npreserving local geometry. In many applications the data set to be projected is\ngiven to us in advance, yet the current RP techniques do not make use of\ninformation about the data. In this paper, we provide a computationally light\nway to extract statistics from the data that allows designing a data dependent\nRP with superior performance compared to data-oblivious RP. We tackle scenarios\nsuch as matrix multiplication and linear regression/classification in which we\nwish to estimate inner products between pairs of vectors from two possibly\ndifferent sources. Our technique takes advantage of the difference between the\nsources and is provably superior to oblivious RPs. Additionally, we provide\nextensive experiments comparing RPs with our approach showing significant\nperformance lifts in fast matrix multiplication, regression and classification\nproblems.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 19:27:02 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ryder", "Nick", ""], ["Karnin", "Zohar", ""], ["Liberty", "Edo", ""]]}, {"id": "1906.09501", "submitter": "Vasiliki Velona", "authors": "G\\'abor Lugosi, Jakub Truszkowski, Vasiliki Velona, Piotr Zwiernik", "title": "Structure learning in graphical models by covariance queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering the structure underlying large Gaussian\ngraphical models or, more generally, partial correlation graphs. In\nhigh-dimensional problems it is often too costly to store the entire sample\ncovariance matrix. We propose a new input model in which one can query single\nentries of the covariance matrix. We prove that it is possible to recover the\nsupport of the inverse covariance matrix with low query and computational\ncomplexity. Our algorithms work in a regime when this support is represented by\ntree-like graphs and, more generally, for graphs of small treewidth. Our\nresults demonstrate that for large classes of graphs, the structure of the\ncorresponding partial correlation graphs can be determined much faster than\neven computing the empirical covariance matrix.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 20:44:52 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 11:05:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Truszkowski", "Jakub", ""], ["Velona", "Vasiliki", ""], ["Zwiernik", "Piotr", ""]]}, {"id": "1906.09510", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Joel Lehman, Qiang Liu, Jian Peng", "title": "Learning Belief Representations for Imitation Learning in POMDPs", "comments": "Conference on Uncertainty in Artificial Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of imitation learning from expert demonstrations in\npartially observable Markov decision processes (POMDPs). Belief\nrepresentations, which characterize the distribution over the latent states in\na POMDP, have been modeled using recurrent neural networks and probabilistic\nlatent variable models, and shown to be effective for reinforcement learning in\nPOMDPs. In this work, we investigate the belief representation learning problem\nfor generative adversarial imitation learning in POMDPs. Instead of training\nthe belief module and the policy separately as suggested in prior work, we\nlearn the belief module jointly with the policy, using a task-aware imitation\nloss to ensure that the representation is more aligned with the policy's\nobjective. To improve robustness of representation, we introduce several\ninformative belief regularization techniques, including multi-step prediction\nof dynamics and action-sequences. Evaluated on various partially observable\ncontinuous-control locomotion tasks, our belief-module imitation learning\napproach (BMIL) substantially outperforms several baselines, including the\noriginal GAIL algorithm and the task-agnostic belief learning algorithm.\nExtensive ablation analysis indicates the effectiveness of task-aware belief\nlearning and belief regularization.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 21:40:03 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Lehman", "Joel", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1906.09521", "submitter": "Dejan Slep\\v{c}ev", "authors": "Marco Caroccia, Antonin Chambolle, Dejan Slep\\v{c}ev", "title": "Mumford-Shah functionals on graphs and their asymptotics", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6544/ab81ee", "report-no": null, "categories": "math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider adaptations of the Mumford-Shah functional to graphs. These are\nbased on discretizations of nonlocal approximations to the Mumford-Shah\nfunctional. Motivated by applications in machine learning we study the random\ngeometric graphs associated to random samples of a measure. We establish the\nconditions on the graph constructions under which the minimizers of graph\nMumford-Shah functionals converge to a minimizer of a continuum Mumford-Shah\nfunctional. Furthermore we explicitly identify the limiting functional.\nMoreover we describe an efficient algorithm for computing the approximate\nminimizers of the graph Mumford-Shah functional.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 23:54:28 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 15:43:03 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Caroccia", "Marco", ""], ["Chambolle", "Antonin", ""], ["Slep\u010dev", "Dejan", ""]]}, {"id": "1906.09525", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, David Wagner", "title": "Defending Against Adversarial Examples with K-Nearest Neighbor", "comments": "Inadequate experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness is an increasingly important property of machine learning models\nas they become more and more prevalent. We propose a defense against\nadversarial examples based on a k-nearest neighbor (kNN) on the intermediate\nactivation of neural networks. Our scheme surpasses state-of-the-art defenses\non MNIST and CIFAR-10 against l2-perturbation by a significant margin. With our\nmodels, the mean perturbation norm required to fool our MNIST model is 3.07 and\n2.30 on CIFAR-10. Additionally, we propose a simple certifiable lower bound on\nthe l2-norm of the adversarial perturbation using a more specific version of\nour scheme, a 1-NN on representations learned by a Lipschitz network. Our model\nprovides a nontrivial average lower bound of the perturbation norm, comparable\nto other schemes on MNIST with similar clean accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 00:38:07 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 20:14:50 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Wagner", "David", ""]]}, {"id": "1906.09526", "submitter": "Dino Oglic", "authors": "Dino Oglic and Zoran Cvetkovic and Peter Sollich", "title": "A Deep Variational Convolutional Neural Network for Robust Speech\n  Recognition in the Waveform Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the potential of probabilistic neural networks for learning of\nrobust waveform-based acoustic models. To that end, we consider a deep\nconvolutional network that first decomposes speech into frequency sub-bands via\nan adaptive parametric convolutional block where filters are specified by\ncosine modulations of compactly supported windows. The network then employs\nstandard non-parametric wide-pass filters, i.e., 1D convolutions, to extract\nthe most relevant spectro-temporal patterns while gradually compressing the\nstructured high dimensional representation generated by the parametric block.\nWe rely on a probabilistic parametrization of the proposed architecture and\nlearn the model using stochastic variational inference. This requires\nevaluation of an analytically intractable integral defining the\nKullback-Leibler divergence term responsible for regularization, for which we\npropose an effective approximation based on the Gauss-Hermite quadrature. Our\nempirical results demonstrate a superior performance of the proposed approach\nover relevant waveform-based baselines and indicate that it could lead to\nrobustness. Moreover, the approach outperforms a recently proposed deep\nconvolutional network for learning of robust acoustic models with standard\nfilterbank features.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 00:42:27 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 18:51:55 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 10:09:05 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Oglic", "Dino", ""], ["Cvetkovic", "Zoran", ""], ["Sollich", "Peter", ""]]}, {"id": "1906.09529", "submitter": "Mohit Goyal", "authors": "Mohit Goyal, Rajan Goyal, Brejesh Lall", "title": "Learning Activation Functions: A new paradigm for understanding Neural\n  Networks", "comments": "A modified version of the article has been published in IEEE WCCI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scope of research in the domain of activation functions remains limited\nand centered around improving the ease of optimization or generalization\nquality of neural networks (NNs). However, to develop a deeper understanding of\ndeep learning, it becomes important to look at the non linear component of NNs\nmore carefully. In this paper, we aim to provide a generic form of activation\nfunction along with appropriate mathematical grounding so as to allow for\ninsights into the working of NNs in future. We propose \"Self-Learnable\nActivation Functions\" (SLAF), which are learned during training and are capable\nof approximating most of the existing activation functions. SLAF is given as a\nweighted sum of pre-defined basis elements which can serve for a good\napproximation of the optimal activation function. The coefficients for these\nbasis elements allow a search in the entire space of continuous functions\n(consisting of all the conventional activations). We propose various training\nroutines which can be used to achieve performance with SLAF equipped neural\nnetworks (SLNNs). We prove that SLNNs can approximate any neural network with\nlipschitz continuous activations, to any arbitrary error highlighting their\ncapacity and possible equivalence with standard NNs. Also, SLNNs can be\ncompletely represented as a collections of finite degree polynomial upto the\nvery last layer obviating several hyper parameters like width and depth. Since\nthe optimization of SLNNs is still a challenge, we show that using SLAF along\nwith standard activations (like ReLU) can provide performance improvements with\nonly a small increase in number of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 01:54:36 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:56:10 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 04:13:25 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Goyal", "Mohit", ""], ["Goyal", "Rajan", ""], ["Lall", "Brejesh", ""]]}, {"id": "1906.09531", "submitter": "Aditya Grover", "authors": "Aditya Grover, Jiaming Song, Alekh Agarwal, Kenneth Tran, Ashish\n  Kapoor, Eric Horvitz, Stefano Ermon", "title": "Bias Correction of Learned Generative Models using Likelihood-Free\n  Importance Weighting", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learned generative model often produces biased statistics relative to the\nunderlying data distribution. A standard technique to correct this bias is\nimportance sampling, where samples from the model are weighted by the\nlikelihood ratio under model and true distributions. When the likelihood ratio\nis unknown, it can be estimated by training a probabilistic classifier to\ndistinguish samples from the two distributions. We employ this likelihood-free\nimportance weighting method to correct for the bias in generative models. We\nfind that this technique consistently improves standard goodness-of-fit metrics\nfor evaluating the sample quality of state-of-the-art deep generative models,\nsuggesting reduced bias. Finally, we demonstrate its utility on representative\napplications in a) data augmentation for classification using generative\nadversarial networks, and b) model-based policy evaluation using off-policy\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 01:57:29 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 08:27:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Grover", "Aditya", ""], ["Song", "Jiaming", ""], ["Agarwal", "Alekh", ""], ["Tran", "Kenneth", ""], ["Kapoor", "Ashish", ""], ["Horvitz", "Eric", ""], ["Ermon", "Stefano", ""]]}, {"id": "1906.09536", "submitter": "Yang Li", "authors": "Yang Li", "title": "Inferring Latent dimension of Linear Dynamical System with Minimum\n  Description Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-invariant linear dynamical system arises in many real-world\napplications,and its usefulness is widely acknowledged. A practical limitation\nwith this model is that its latent dimension that has a large impact on the\nmodel capability needs to be manually specified. It can be demonstrated that a\nlower-order model class could be totally nested into a higher-order class, and\nthe corresponding likelihood is nondecreasing. Hence, criterion built on the\nlikelihood is not appropriate for model selection. This paper addresses the\nissue and proposes a criterion for linear dynamical system based on the\nprinciple of minimum description length. The latent structure, which is omitted\nin previous work, is explicitly considered in this newly proposed criterion.\nOur work extends the principle of minimum description length and demonstrates\nits effectiveness in the tasks of model training. The experiments on both\nunivariate and multivariate sequences confirm the good performance of our newly\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 02:22:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Yang", ""]]}, {"id": "1906.09551", "submitter": "Zhilu Zhang", "authors": "Zhilu Zhang, Adrian V. Dalca, Mert R. Sabuncu", "title": "Confidence Calibration for Convolutional Neural Networks Using\n  Structured Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification applications, we often want probabilistic predictions to\nreflect confidence or uncertainty. Dropout, a commonly used training technique,\nhas recently been linked to Bayesian inference, yielding an efficient way to\nquantify uncertainty in neural network models. However, as previously\ndemonstrated, confidence estimates computed with a naive implementation of\ndropout can be poorly calibrated, particularly when using convolutional\nnetworks. In this paper, through the lens of ensemble learning, we associate\ncalibration error with the correlation between the models sampled with dropout.\nMotivated by this, we explore the use of structured dropout to promote model\ndiversity and improve confidence calibration. We use the SVHN, CIFAR-10 and\nCIFAR-100 datasets to empirically compare model diversity and confidence errors\nobtained using various dropout techniques. We also show the merit of structured\ndropout in a Bayesian active learning application.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 04:34:14 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhang", "Zhilu", ""], ["Dalca", "Adrian V.", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1906.09557", "submitter": "Yizhou Zhou", "authors": "Yizhou Zhou, Xiaoyan Sun, Chong Luo, Zheng-Jun Zha, Wenjun Zeng", "title": "Posterior-Guided Neural Architecture Search", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of neural architecture search (NAS) has greatly advanced the\nresearch on network design. Recent proposals such as gradient-based methods or\none-shot approaches significantly boost the efficiency of NAS. In this paper,\nwe formulate the NAS problem from a Bayesian perspective. We propose explicitly\nestimating the joint posterior distribution over pairs of network architecture\nand weights. Accordingly, a hybrid network representation is presented which\nenables us to leverage the Variational Dropout so that the approximation of the\nposterior distribution becomes fully gradient-based and highly efficient. A\nposterior-guided sampling method is then presented to sample architecture\ncandidates and directly make evaluations. As a Bayesian approach, our\nposterior-guided NAS (PGNAS) avoids tuning a number of hyper-parameters and\nenables a very effective architecture sampling in posterior probability space.\nInterestingly, it also leads to a deeper insight into the weight sharing used\nin the one-shot NAS and naturally alleviates the mismatch between the sampled\narchitecture and weights caused by the weight sharing. We validate our PGNAS\nmethod on the fundamental image classification task. Results on Cifar-10,\nCifar-100 and ImageNet show that PGNAS achieves a good trade-off between\nprecision and speed of search among NAS methods. For example, it takes 11 GPU\ndays to search a very competitive architecture with 1.98% and 14.28% test\nerrors on Cifar10 and Cifar100, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 05:51:19 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 05:42:59 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Zhou", "Yizhou", ""], ["Sun", "Xiaoyan", ""], ["Luo", "Chong", ""], ["Zha", "Zheng-Jun", ""], ["Zeng", "Wenjun", ""]]}, {"id": "1906.09602", "submitter": "Ruo-Chun Tzeng", "authors": "Ruo-Chun Tzeng, Shan-Hung Wu", "title": "Ego-CNN: Distributed, Egocentric Representations of Graphs for Detecting\n  Critical Structures", "comments": "Proceedings of the 36th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting critical structures using a graph embedding\nmodel. Existing graph embedding models lack the ability to precisely detect\ncritical structures that are specific to a task at the global scale. In this\npaper, we propose a novel graph embedding model, called the Ego-CNNs, that\nemploys the ego-convolutions convolutions at each layer and stacks up layers\nusing an ego-centric way to detects precise critical structures efficiently. An\nEgo-CNN can be jointly trained with a task model and help explain/discover\nknowledge for the task. We conduct extensive experiments and the results show\nthat Ego-CNNs (1) can lead to comparable task performance as the\nstate-of-the-art graph embedding models, (2) works nicely with CNN\nvisualization techniques to illustrate the detected structures, and (3) is\nefficient and can incorporate with scale-free priors, which commonly occurs in\nsocial network datasets, to further improve the training efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 16:14:22 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Tzeng", "Ruo-Chun", ""], ["Wu", "Shan-Hung", ""]]}, {"id": "1906.09613", "submitter": "Daniel Alabi", "authors": "Daniel Alabi", "title": "The Cost of a Reductions Approach to Private Fair Optimization", "comments": "52 Pages, 4 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Through the lens of information-theoretic reductions, we examine a reductions\napproach to fair optimization and learning where a black-box optimizer is used\nto learn a fair model for classification or regression. Quantifying the\ncomplexity, both statistically and computationally, of making such models\nsatisfy the rigorous definition of differential privacy is our end goal. We\nresolve a few open questions and show applicability to fair machine learning,\nhypothesis testing, and to optimizing non-standard measures of classification\nloss. Furthermore, our sample complexity bounds are tight amongst all\nstrategies that jointly minimize a composition of functions.\n  The reductions approach to fair optimization can be abstracted as the\nconstrained group-objective optimization problem where we aim to optimize an\nobjective that is a function of losses of individual groups, subject to some\nconstraints. We give the first polynomial-time algorithms to solve the problem\nwith $(\\epsilon, 0)$ or $(\\epsilon, \\delta)$ differential privacy guarantees\nwhen defined on a convex decision set (for example, the $\\ell_P$ unit ball)\nwith convex constraints and losses. Accompanying information-theoretic lower\nbounds for the problem are presented. In addition, compared to a previous\nmethod for ensuring differential privacy subject to a relaxed form of the\nequalized odds fairness constraint, the $(\\epsilon, \\delta)$-differentially\nprivate algorithm we present provides asymptotically better sample complexity\nguarantees, resulting in an exponential improvement in certain parameter\nregimes. We introduce a class of bounded divergence linear optimizers, which\ncould be of independent interest, and specialize to pure and approximate\ndifferential privacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 17:36:26 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 23:17:07 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 21:49:26 GMT"}, {"version": "v4", "created": "Sun, 23 May 2021 13:29:42 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Alabi", "Daniel", ""]]}, {"id": "1906.09621", "submitter": "Candice Schumann", "authors": "Candice Schumann, Zhi Lang, Jeffrey S. Foster, John P. Dickerson", "title": "Making the Cut: A Bandit-based Approach to Tiered Interviewing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a huge set of applicants, how should a firm allocate sequential resume\nscreenings, phone interviews, and in-person site visits? In a tiered interview\nprocess, later stages (e.g., in-person visits) are more informative, but also\nmore expensive than earlier stages (e.g., resume screenings). Using accepted\nhiring models and the concept of structured interviews, a best practice in\nhuman resources, we cast tiered hiring as a combinatorial pure exploration\n(CPE) problem in the stochastic multi-armed bandit setting. The goal is to\nselect a subset of arms (in our case, applicants) with some combinatorial\nstructure. We present new algorithms in both the probably approximately correct\n(PAC) and fixed-budget settings that select a near-optimal cohort with provable\nguarantees. We show via simulations on real data from one of the largest\nUS-based computer science graduate programs that our algorithms make better\nhiring decisions or use less budget than the status quo.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 18:02:10 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 22:27:28 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Schumann", "Candice", ""], ["Lang", "Zhi", ""], ["Foster", "Jeffrey S.", ""], ["Dickerson", "John P.", ""]]}, {"id": "1906.09624", "submitter": "Rohin Shah", "authors": "Rohin Shah, Noah Gundotra, Pieter Abbeel, Anca D. Dragan", "title": "On the Feasibility of Learning, Rather than Assuming, Human Biases for\n  Reward Inference", "comments": "Published at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is for agents to optimize the right reward function, despite how\ndifficult it is for us to specify what that is. Inverse Reinforcement Learning\n(IRL) enables us to infer reward functions from demonstrations, but it usually\nassumes that the expert is noisily optimal. Real people, on the other hand,\noften have systematic biases: risk-aversion, myopia, etc. One option is to try\nto characterize these biases and account for them explicitly during learning.\nBut in the era of deep learning, a natural suggestion researchers make is to\navoid mathematical models of human behavior that are fraught with specific\nassumptions, and instead use a purely data-driven approach. We decided to put\nthis to the test -- rather than relying on assumptions about which specific\nbias the demonstrator has when planning, we instead learn the demonstrator's\nplanning algorithm that they use to generate demonstrations, as a\ndifferentiable planner. Our exploration yielded mixed findings: on the one\nhand, learning the planner can lead to better reward inference than relying on\nthe wrong assumption; on the other hand, this benefit is dwarfed by the loss we\nincur by going from an exact to a differentiable planner. This suggest that at\nleast for the foreseeable future, agents need a middle ground between the\nflexibility of data-driven methods and the useful bias of known human biases.\nCode is available at https://tinyurl.com/learningbiases.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 18:41:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Shah", "Rohin", ""], ["Gundotra", "Noah", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1906.09665", "submitter": "Felipe Tobar", "authors": "Gonzalo Rios, Felipe Tobar", "title": "Compositionally-Warped Gaussian Processes", "comments": "Accepted at Elsevier Neural Networks, DOI added and author order\n  corrected", "journal-ref": null, "doi": "10.1016/j.neunet.2019.06.012", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process (GP) is a nonparametric prior distribution over\nfunctions indexed by time, space, or other high-dimensional index set. The GP\nis a flexible model yet its limitation is given by its very nature: it can only\nmodel Gaussian marginal distributions. To model non-Gaussian data, a GP can be\nwarped by a nonlinear transformation (or warping) as performed by warped GPs\n(WGPs) and more computationally-demanding alternatives such as Bayesian WGPs\nand deep GPs. However, the WGP requires a numerical approximation of the\ninverse warping for prediction, which increases the computational complexity in\npractice. To sidestep this issue, we construct a novel class of warpings\nconsisting of compositions of multiple elementary functions, for which the\ninverse is known explicitly. We then propose the compositionally-warped GP\n(CWGP), a non-Gaussian generative model whose expressiveness follows from its\ndeep compositional architecture, and its computational efficiency is guaranteed\nby the analytical inverse warping. Experimental validation using synthetic and\nreal-world datasets confirms that the proposed CWGP is robust to the choice of\nwarpings and provides more accurate point predictions, better trained models\nand shorter computation times than WGP.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 22:41:32 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 16:06:17 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Rios", "Gonzalo", ""], ["Tobar", "Felipe", ""]]}, {"id": "1906.09669", "submitter": "Waleed Yousef", "authors": "Waleed A. Mustafa, Waleed A. Yousef", "title": "Nested Cavity Classifier: performance and remedy", "comments": "This manuscript was composed in 2009 as part of a research pursued\n  that time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested Cavity Classifier (NCC) is a classification rule that pursues\npartitioning the feature space, in parallel coordinates, into convex hulls to\nbuild decision regions. It is claimed in some literatures that this\ngeometric-based classifier is superior to many others, particularly in higher\ndimensions. First, we give an example on how NCC can be inefficient, then\nmotivate a remedy by combining the NCC with the Linear Discriminant Analysis\n(LDA) classifier. We coin the term Nested Cavity Discriminant Analysis (NCDA)\nfor the resulting classifier. Second, a simulation study is conducted to\ncompare both, NCC and NCDA to another two basic classifiers, Linear and\nQuadratic Discriminant Analysis. NCC alone proves to be inferior to others,\nwhile NCDA always outperforms NCC and competes with LDA and QDA.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 23:03:36 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 13:10:35 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 12:24:22 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Mustafa", "Waleed A.", ""], ["Yousef", "Waleed A.", ""]]}, {"id": "1906.09674", "submitter": "Kaixiang Lin", "authors": "Kaixiang Lin and Jiayu Zhou", "title": "Ranking Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample inefficiency is a long-lasting problem in reinforcement learning (RL).\nThe state-of-the-art estimates the optimal action values while it usually\ninvolves an extensive search over the state-action space and unstable\noptimization. Towards the sample-efficient RL, we propose ranking policy\ngradient (RPG), a policy gradient method that learns the optimal rank of a set\nof discrete actions. To accelerate the learning of policy gradient methods, we\nestablish the equivalence between maximizing the lower bound of return and\nimitating a near-optimal policy without accessing any oracles. These results\nlead to a general off-policy learning framework, which preserves the\noptimality, reduces variance, and improves the sample-efficiency. Furthermore,\nthe sample complexity of RPG does not depend on the dimension of state space,\nwhich enables RPG for large-scale problems. We conduct extensive experiments\nshowing that when consolidating with the off-policy learning framework, RPG\nsubstantially reduces the sample complexity, comparing to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:13:42 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 17:49:21 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 16:00:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lin", "Kaixiang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1906.09679", "submitter": "Farhad Farokhi", "authors": "Nan Wu, Farhad Farokhi, David Smith, Mohamed Ali Kaafar", "title": "The Value of Collaboration in Convex Machine Learning with Differential\n  Privacy", "comments": "Accepted in IEEE S&P 2020", "journal-ref": "IEEE Symposium on Security and Privacy 2020 (IEEE SP 2020)", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply machine learning to distributed private data owned by\nmultiple data owners, entities with access to non-overlapping training\ndatasets. We use noisy, differentially-private gradients to minimize the\nfitness cost of the machine learning model using stochastic gradient descent.\nWe quantify the quality of the trained model, using the fitness cost, as a\nfunction of privacy budget and size of the distributed datasets to capture the\ntrade-off between privacy and utility in machine learning. This way, we can\npredict the outcome of collaboration among privacy-aware data owners prior to\nexecuting potentially computationally-expensive machine learning algorithms.\nParticularly, we show that the difference between the fitness of the trained\nmachine learning model using differentially-private gradient queries and the\nfitness of the trained machine model in the absence of any privacy concerns is\ninversely proportional to the size of the training datasets squared and the\nprivacy budget squared. We successfully validate the performance prediction\nwith the actual performance of the proposed privacy-aware learning algorithms,\napplied to: financial datasets for determining interest rates of loans using\nregression; and detecting credit card frauds using support vector machines.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:57:15 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Wu", "Nan", ""], ["Farokhi", "Farhad", ""], ["Smith", "David", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1906.09686", "submitter": "Jiayu Yao", "authors": "Jiayu Yao, Weiwei Pan, Soumya Ghosh, Finale Doshi-Velez", "title": "Quality of Uncertainty Quantification for Bayesian Neural Network\n  Inference", "comments": "Accepted to ICML UDL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNNs) place priors over the parameters in a neural\nnetwork. Inference in BNNs, however, is difficult; all inference methods for\nBNNs are approximate. In this work, we empirically compare the quality of\npredictive uncertainty estimates for 10 common inference methods on both\nregression and classification tasks. Our experiments demonstrate that commonly\nused metrics (e.g. test log-likelihood) can be misleading. Our experiments also\nindicate that inference innovations designed to capture structure in the\nposterior do not necessarily produce high quality posterior approximations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 01:35:55 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Yao", "Jiayu", ""], ["Pan", "Weiwei", ""], ["Ghosh", "Soumya", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1906.09688", "submitter": "Candice Schumann", "authors": "Candice Schumann, Xuezhi Wang, Alex Beutel, Jilin Chen, Hai Qian, Ed\n  H. Chi", "title": "Transfer of Machine Learning Fairness across Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If our models are used in new or unexpected cases, do we know if they will\nmake fair predictions? Previously, researchers developed ways to debias a model\nfor a single problem domain. However, this is often not how models are trained\nand used in practice. For example, labels and demographics (sensitive\nattributes) are often hard to observe, resulting in auxiliary or synthetic data\nto be used for training, and proxies of the sensitive attribute to be used for\nevaluation of fairness. A model trained for one setting may be picked up and\nused in many others, particularly as is common with pre-training and cloud\nAPIs. Despite the pervasiveness of these complexities, remarkably little work\nin the fairness literature has theoretically examined these issues. We frame\nall of these settings as domain adaptation problems: how can we use what we\nhave learned in a source domain to debias in a new target domain, without\ndirectly debiasing on the target domain as if it is a completely new problem?\nWe offer new theoretical guarantees of improving fairness across domains, and\noffer a modeling approach to transfer to data-sparse target domains. We give\nempirical results validating the theory and showing that these modeling\napproaches can improve fairness metrics with less data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 01:55:09 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 05:21:15 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 21:50:20 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Schumann", "Candice", ""], ["Wang", "Xuezhi", ""], ["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Qian", "Hai", ""], ["Chi", "Ed H.", ""]]}, {"id": "1906.09691", "submitter": "Amjad Almahairi", "authors": "Jacob Leygonie, Jennifer She, Amjad Almahairi, Sai Rajeswar, Aaron\n  Courville", "title": "Adversarial Computation of Optimal Transport Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing optimal transport maps between high-dimensional and continuous\ndistributions is a challenging problem in optimal transport (OT). Generative\nadversarial networks (GANs) are powerful generative models which have been\nsuccessfully applied to learn maps across high-dimensional domains. However,\nlittle is known about the nature of the map learned with a GAN objective. To\naddress this problem, we propose a generative adversarial model in which the\ndiscriminator's objective is the $2$-Wasserstein metric. We show that during\ntraining, our generator follows the $W_2$-geodesic between the initial and the\ntarget distributions. As a consequence, it reproduces an optimal map at the end\nof training. We validate our approach empirically in both low-dimensional and\nhigh-dimensional continuous settings, and show that it outperforms prior\nmethods on image data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 02:12:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Leygonie", "Jacob", ""], ["She", "Jennifer", ""], ["Almahairi", "Amjad", ""], ["Rajeswar", "Sai", ""], ["Courville", "Aaron", ""]]}, {"id": "1906.09693", "submitter": "Jun Wen", "authors": "Jun Wen, Nenggan Zheng, Junsong Yuan, Zhefeng Gong, Changyou Chen", "title": "Bayesian Uncertainty Matching for Unsupervised Domain Adaptation", "comments": "IJCAI-2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is an important technique to alleviate performance\ndegradation caused by domain shift, e.g., when training and test data come from\ndifferent domains. Most existing deep adaptation methods focus on reducing\ndomain shift by matching marginal feature distributions through deep\ntransformations on the input features, due to the unavailability of target\ndomain labels. We show that domain shift may still exist via label distribution\nshift at the classifier, thus deteriorating model performances. To alleviate\nthis issue, we propose an approximate joint distribution matching scheme by\nexploiting prediction uncertainty. Specifically, we use a Bayesian neural\nnetwork to quantify prediction uncertainty of a classifier. By imposing\ndistribution matching on both features and labels (via uncertainty), label\ndistribution mismatching in source and target data is effectively alleviated,\nencouraging the classifier to produce consistent predictions across domains. We\nalso propose a few techniques to improve our method by adaptively reweighting\ndomain adaptation loss to achieve nontrivial distribution matching and stable\ntraining. Comparisons with state of the art unsupervised domain adaptation\nmethods on three popular benchmark datasets demonstrate the superiority of our\napproach, especially on the effectiveness of alleviating negative transfer.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 02:57:22 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wen", "Jun", ""], ["Zheng", "Nenggan", ""], ["Yuan", "Junsong", ""], ["Gong", "Zhefeng", ""], ["Chen", "Changyou", ""]]}, {"id": "1906.09712", "submitter": "Steven Howard", "authors": "Steven R. Howard, Aaditya Ramdas", "title": "Sequential estimation of quantiles with applications to A/B-testing and\n  best-arm identification", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose confidence sequences -- sequences of confidence intervals which\nare valid uniformly over time -- for quantiles of any distribution over a\ncomplete, fully-ordered set, based on a stream of i.i.d. observations. We give\nmethods both for tracking a fixed quantile and for tracking all quantiles\nsimultaneously. Specifically, we provide explicit expressions with small\nconstants for intervals whose widths shrink at the fastest possible\n$\\sqrt{t^{-1} \\log\\log t}$ rate, along with a non-asymptotic concentration\ninequality for the empirical distribution function which holds uniformly over\ntime with the same rate. The latter strengthens Smirnov's empirical process law\nof the iterated logarithm and extends the Dvoretzky-Kiefer-Wolfowitz inequality\nto hold uniformly over time. We give a new algorithm and sample complexity\nbound for selecting an arm with an approximately best quantile in a multi-armed\nbandit framework. In simulations, our method requires fewer samples than\nexisting methods by a factor of five to fifty.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 03:47:58 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:51:58 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 03:58:30 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Howard", "Steven R.", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "1906.09734", "submitter": "Matthew Aitchison", "authors": "Matthew Aitchison", "title": "Optimal Use of Experience in First Person Shooter Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although reinforcement learning has made great strides recently, a continuing\nlimitation is that it requires an extremely high number of interactions with\nthe environment. In this paper, we explore the effectiveness of reusing\nexperience from the experience replay buffer in the Deep Q-Learning algorithm.\nWe test the effectiveness of applying learning update steps multiple times per\nenvironmental step in the VizDoom environment and show first, this requires a\nchange in the learning rate, and second that it does not improve the\nperformance of the agent. Furthermore, we show that updating less frequently is\neffective up to a ratio of 4:1, after which performance degrades significantly.\nThese results quantitatively confirm the widespread practice of performing\nlearning updates every 4th environmental step.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 05:37:58 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Aitchison", "Matthew", ""]]}, {"id": "1906.09735", "submitter": "Victor Coscrato", "authors": "Victor Coscrato, Marco Henrique de Almeida In\\'acio, Rafael Izbicki", "title": "The NN-Stacking: Feature weighted linear stacking through neural\n  networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.02.073", "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stacking methods improve the prediction performance of regression models. A\nsimple way to stack base regressions estimators is by combining them linearly,\nas done by \\citet{breiman1996stacked}. Even though this approach is useful from\nan interpretative perspective, it often does not lead to high predictive power.\nWe propose the NN-Stacking method (NNS), which generalizes Breiman's method by\nallowing the linear parameters to vary with input features. This improvement\nenables NNS to take advantage of the fact that distinct base models often\nperform better at different regions of the feature space. Our method uses\nneural networks to estimate the stacking coefficients. We show that while our\napproach keeps the interpretative features of Breiman's method at a local\nlevel, it leads to better predictive power, especially in datasets with large\nsample sizes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 05:46:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Coscrato", "Victor", ""], ["In\u00e1cio", "Marco Henrique de Almeida", ""], ["Izbicki", "Rafael", ""]]}, {"id": "1906.09744", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting", "title": "Improving the Effectiveness and Efficiency of Stochastic Neighbour\n  Embedding with Isolation Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new insight into improving the performance of\nStochastic Neighbour Embedding (t-SNE) by using Isolation kernel instead of\nGaussian kernel. Isolation kernel outperforms Gaussian kernel in two aspects.\nFirst, the use of Isolation kernel in t-SNE overcomes the drawback of\nmisrepresenting some structures in the data, which often occurs when Gaussian\nkernel is applied in t-SNE. This is because Gaussian kernel determines each\nlocal bandwidth based on one local point only, while Isolation kernel is\nderived directly from the data based on space partitioning. Second, the use of\nIsolation kernel yields a more efficient similarity computation because\ndata-dependent Isolation kernel has only one parameter that needs to be tuned.\nIn contrast, the use of data-independent Gaussian kernel increases the\ncomputational cost by determining n bandwidths for a dataset of n points. As\nthe root cause of these deficiencies in t-SNE is Gaussian kernel, we show that\nsimply replacing Gaussian kernel with Isolation kernel in t-SNE significantly\nimproves the quality of the final visualisation output (without creating\nmisrepresented structures) and removes one key obstacle that prevents t-SNE\nfrom processing large datasets. Moreover, Isolation kernel enables t-SNE to\ndeal with large-scale datasets in less runtime without trading off accuracy,\nunlike existing methods in speeding up t-SNE.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 06:49:04 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 03:34:10 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 04:20:20 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""]]}, {"id": "1906.09769", "submitter": "Nimisha Ghosh", "authors": "Nimisha Ghosh, Rourab Paul, Satyabrata Maity, Krishanu Maity and\n  Sayantan Saha", "title": "Fault Matters: Sensor Data Fusion for Detection of Faults using\n  Dempster-Shafer Theory of Evidence in IoT-Based Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault detection in sensor nodes is a pertinent issue that has been an\nimportant area of research for a very long time. But it is not explored much as\nyet in the context of Internet of Things. Internet of Things work with a\nmassive amount of data so the responsibility for guaranteeing the accuracy of\nthe data also lies with it. Moreover, a lot of important and critical decisions\nare made based on these data, so ensuring its correctness and accuracy is also\nvery important. Also, the detection needs to be as precise as possible to avoid\nnegative alerts. For this purpose, this work has adopted Dempster-Shafer Theory\nof Evidence which is a popular learning method to collate the information from\nsensors to come up with a decision regarding the faulty status of a sensor\nnode. To verify the validity of the proposed method, simulations have been\nperformed on a benchmark data set and data collected through a test bed in a\nlaboratory set-up. For the different types of faults, the proposed method shows\nvery competent accuracy for both the benchmark (99.8%) and laboratory data sets\n(99.9%) when compared to the other state-of-the-art machine learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 07:58:59 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ghosh", "Nimisha", ""], ["Paul", "Rourab", ""], ["Maity", "Satyabrata", ""], ["Maity", "Krishanu", ""], ["Saha", "Sayantan", ""]]}, {"id": "1906.09781", "submitter": "Hadi Samer Jomaa", "authors": "Hadi S. Jomaa, Josif Grabocka, Lars Schmidt-Thieme", "title": "In Hindsight: A Smooth Reward for Steady Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical Q-learning, the objective is to maximize the sum of discounted\nrewards through iteratively using the Bellman equation as an update, in an\nattempt to estimate the action value function of the optimal policy.\nConventionally, the loss function is defined as the temporal difference between\nthe action value and the expected (discounted) reward, however it focuses\nsolely on the future, leading to overestimation errors. We extend the\nwell-established Q-learning techniques by introducing the hindsight factor, an\nadditional loss term that takes into account how the model progresses, by\nintegrating the historic temporal difference as part of the reward. The effect\nof this modification is examined in a deterministic continuous-state space\nfunction estimation problem, where the overestimation phenomenon is\nsignificantly reduced and results in improved stability. The underlying effect\nof the hindsight factor is modeled as an adaptive learning rate, which unlike\nexisting adaptive optimizers, takes into account the previously estimated\naction value.\n  The proposed method outperforms variations of Q-learning, with an overall\nhigher average reward and lower action values, which supports the deterministic\nevaluation, and proves that the hindsight factor contributes to lower\noverestimation errors. The mean average score of 100 episodes obtained after\ntraining for 10 million frames shows that the hindsight factor outperforms deep\nQ-networks, double deep Q-networks and dueling networks for a variety of ATARI\ngames.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:40:58 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jomaa", "Hadi S.", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1906.09784", "submitter": "Nino Vieillard", "authors": "Nino Vieillard, Olivier Pietquin, Matthieu Geist", "title": "Deep Conservative Policy Iteration", "comments": "AAAI 2020 (long version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conservative Policy Iteration (CPI) is a founding algorithm of Approximate\nDynamic Programming (ADP). Its core principle is to stabilize greediness\nthrough stochastic mixtures of consecutive policies. It comes with strong\ntheoretical guarantees, and inspired approaches in deep Reinforcement Learning\n(RL). However, CPI itself has rarely been implemented, never with neural\nnetworks, and only experimented on toy problems. In this paper, we show how CPI\ncan be practically combined with deep RL with discrete actions. We also\nintroduce adaptive mixture rates inspired by the theory. We experiment\nthoroughly the resulting algorithm on the simple Cartpole problem, and validate\nthe proposed method on a representative subset of Atari games. Overall, this\nwork suggests that revisiting classic ADP may lead to improved and more stable\ndeep RL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:44:56 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 14:05:31 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Vieillard", "Nino", ""], ["Pietquin", "Olivier", ""], ["Geist", "Matthieu", ""]]}, {"id": "1906.09807", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar, Ben Day, Pietro Li\\'o", "title": "Proximal Distilled Evolutionary Reinforcement Learning", "comments": "Camera-ready version for AAAI-20. Contains 10 pages, 11 figures", "journal-ref": "Vol 34 No 04: AAAI 2020 Technical Track on Machine Learning\n  3283-3290", "doi": "10.1609/aaai.v34i04.5728", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has achieved impressive performance in many\ncomplex environments due to the integration with Deep Neural Networks (DNNs).\nAt the same time, Genetic Algorithms (GAs), often seen as a competing approach\nto RL, had limited success in scaling up to the DNNs required to solve\nchallenging tasks. Contrary to this dichotomic view, in the physical world,\nevolution and learning are complementary processes that continuously interact.\nThe recently proposed Evolutionary Reinforcement Learning (ERL) framework has\ndemonstrated mutual benefits to performance when combining the two methods.\nHowever, ERL has not fully addressed the scalability problem of GAs. In this\npaper, we show that this problem is rooted in an unfortunate combination of a\nsimple genetic encoding for DNNs and the use of traditional\nbiologically-inspired variation operators. When applied to these encodings, the\nstandard operators are destructive and cause catastrophic forgetting of the\ntraits the networks acquired. We propose a novel algorithm called Proximal\nDistilled Evolutionary Reinforcement Learning (PDERL) that is characterised by\na hierarchical integration between evolution and learning. The main innovation\nof PDERL is the use of learning-based variation operators that compensate for\nthe simplicity of the genetic representation. Unlike traditional operators, our\nproposals meet the functional requirements of variation operators when applied\non directly-encoded DNNs. We evaluate PDERL in five robot locomotion settings\nfrom the OpenAI gym. Our method outperforms ERL, as well as two\nstate-of-the-art RL algorithms, PPO and TD3, in all tested environments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:31:09 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 23:22:47 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 21:19:53 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 10:29:57 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Bodnar", "Cristian", ""], ["Day", "Ben", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "1906.09808", "submitter": "Jannis Schuecker", "authors": "C\\'esar Ojeda, Kostadin Cvejosky, Rams\\'es J. S\\'anchez, Jannis\n  Schuecker, Bogdan Georgiev, Christian Bauckhage", "title": "Recurrent Adversarial Service Times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service system dynamics occur at the interplay between customer behaviour and\na service provider's response. This kind of dynamics can effectively be modeled\nwithin the framework of queuing theory where customers' arrivals are described\nby point process models. However, these approaches are limited by parametric\nassumptions as to, for example, inter-event time distributions. In this paper,\nwe address these limitations and propose a novel, deep neural network solution\nto the queuing problem. Our solution combines a recurrent neural network that\nmodels the arrival process with a recurrent generative adversarial network\nwhich models the service time distribution. We evaluate our methodology on\nvarious empirical datasets ranging from internet services (Blockchain, GitHub,\nStackoverflow) to mobility service systems (New York taxi cab).\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:31:43 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ojeda", "C\u00e9sar", ""], ["Cvejosky", "Kostadin", ""], ["S\u00e1nchez", "Rams\u00e9s J.", ""], ["Schuecker", "Jannis", ""], ["Georgiev", "Bogdan", ""], ["Bauckhage", "Christian", ""]]}, {"id": "1906.09838", "submitter": "Thomas Gerald", "authors": "Thomas Gerald, Aur\\'elia L\\'eon, Nicolas Baskiotis, Ludovic Denoyer", "title": "Binary Stochastic Representations for Large Multi-class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification with a large number of classes is a key problem in machine\nlearning and corresponds to many real-world applications like tagging of images\nor textual documents in social networks. If one-vs-all methods usually reach\ntop performance in this context, these approaches suffer from a high inference\ncomplexity, linear w.r.t the number of categories. Different models based on\nthe notion of binary codes have been proposed to overcome this limitation,\nachieving in a sublinear inference complexity. But they a priori need to decide\nwhich binary code to associate to which category before learning using more or\nless complex heuristics. We propose a new end-to-end model which aims at\nsimultaneously learning to associate binary codes with categories, but also\nlearning to map inputs to binary codes. This approach called Deep Stochastic\nNeural Codes (DSNC) keeps the sublinear inference complexity but do not need\nany a priori tuning. Experimental results on different datasets show the\neffectiveness of the approach w.r.t baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:20:45 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gerald", "Thomas", ""], ["L\u00e9on", "Aur\u00e9lia", ""], ["Baskiotis", "Nicolas", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1906.09852", "submitter": "Morteza Haghir Chehreghani", "authors": "Claes Stranneg{\\aa}rd, Herman Carlstr\\\"om, Niklas Engsner, Fredrik\n  M\\\"akel\\\"ainen, Filip Slottner Seholm, Morteza Haghir Chehreghani", "title": "Lifelong Learning Starting From Zero", "comments": "To appear in AGI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep neural-network model for lifelong learning inspired by\nseveral forms of neuroplasticity. The neural network develops continuously in\nresponse to signals from the environment. In the beginning, the network is a\nblank slate with no nodes at all. It develops according to four rules: (i)\nexpansion, which adds new nodes to memorize new input combinations; (ii)\ngeneralization, which adds new nodes that generalize from existing ones; (iii)\nforgetting, which removes nodes that are of relatively little use; and (iv)\nbackpropagation, which fine-tunes the network parameters. We analyze the model\nfrom the perspective of accuracy, energy efficiency, and versatility and\ncompare it to other network models, finding better performance in several\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 11:18:00 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Stranneg\u00e5rd", "Claes", ""], ["Carlstr\u00f6m", "Herman", ""], ["Engsner", "Niklas", ""], ["M\u00e4kel\u00e4inen", "Fredrik", ""], ["Seholm", "Filip Slottner", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1906.09855", "submitter": "Roi Weiss", "authors": "Steve Hanneke, Aryeh Kontorovich, Sivan Sabato, Roi Weiss", "title": "Universal Bayes consistency in metric spaces", "comments": "To appear in Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend a recently proposed 1-nearest-neighbor based multiclass learning\nalgorithm and prove that our modification is universally strongly\nBayes-consistent in all metric spaces admitting any such learner, making it an\n\"optimistically universal\" Bayes-consistent learner. This is the first learning\nalgorithm known to enjoy this property; by comparison, the $k$-NN classifier\nand its variants are not generally universally Bayes-consistent, except under\nadditional structural assumptions, such as an inner product, a norm, finite\ndimension, or a Besicovitch-type property. The metric spaces in which universal\nBayes consistency is possible are the \"essentially separable\" ones -- a notion\nthat we define, which is more general than standard separability. The existence\nof metric spaces that are not essentially separable is widely believed to be\nindependent of the ZFC axioms of set theory. We prove that essential\nseparability exactly characterizes the existence of a universal\nBayes-consistent learner for the given metric space. In particular, this yields\nthe first impossibility result for universal Bayes consistency. Taken together,\nour results completely characterize strong and weak universal Bayes consistency\nin metric spaces.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 11:29:00 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 06:50:37 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 21:16:08 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 17:20:57 GMT"}, {"version": "v5", "created": "Sun, 11 Oct 2020 16:31:23 GMT"}, {"version": "v6", "created": "Fri, 16 Oct 2020 09:55:46 GMT"}, {"version": "v7", "created": "Wed, 6 Jan 2021 22:39:49 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""], ["Sabato", "Sivan", ""], ["Weiss", "Roi", ""]]}, {"id": "1906.09882", "submitter": "Xiao Zhou", "authors": "Xiao Zhou, Danyang Liu, Jianxun Lian and Xing Xie", "title": "Collaborative Metric Learning with Memory Network for Multi-Relational\n  Recommender Systems", "comments": "7 pages, 4 figures, IJCAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of recommender systems in modern online platforms is inseparable\nfrom the accurate capture of users' personal tastes. In everyday life, large\namounts of user feedback data are created along with user-item online\ninteractions in a variety of ways, such as browsing, purchasing, and sharing.\nThese multiple types of user feedback provide us with tremendous opportunities\nto detect individuals' fine-grained preferences. Different from most existing\nrecommender systems that rely on a single type of feedback, we advocate\nincorporating multiple types of user-item interactions for better\nrecommendations. Based on the observation that the underlying spectrum of user\npreferences is reflected in various types of interactions with items and can be\nuncovered by latent relational learning in metric space, we propose a unified\nneural learning framework, named Multi-Relational Memory Network (MRMN). It can\nnot only model fine-grained user-item relations but also enable us to\ndiscriminate between feedback types in terms of the strength and diversity of\nuser preferences. Extensive experiments show that the proposed MRMN model\noutperforms competitive state-of-the-art algorithms in a wide range of\nscenarios, including e-commerce, local services, and job recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 12:29:18 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhou", "Xiao", ""], ["Liu", "Danyang", ""], ["Lian", "Jianxun", ""], ["Xie", "Xing", ""]]}, {"id": "1906.09890", "submitter": "Miquel India", "authors": "Miquel India, Pooyan Safari and Javier Hernando", "title": "Self Multi-Head Attention for Speaker Recognition", "comments": "4+1 pages. 4 Figures. Accepted for Interspeech 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most state-of-the-art Deep Learning (DL) approaches for speaker recognition\nwork on a short utterance level. Given the speech signal, these algorithms\nextract a sequence of speaker embeddings from short segments and those are\naveraged to obtain an utterance level speaker representation. In this work we\npropose the use of an attention mechanism to obtain a discriminative speaker\nembedding given non fixed length speech utterances. Our system is based on a\nConvolutional Neural Network (CNN) that encodes short-term speaker features\nfrom the spectrogram and a self multi-head attention model that maps these\nrepresentations into a long-term speaker embedding. The attention model that we\npropose produces multiple alignments from different subsegments of the CNN\nencoded states over the sequence. Hence this mechanism works as a pooling layer\nwhich decides the most discriminative features over the sequence to obtain an\nutterance level representation. We have tested this approach for the\nverification task for the VoxCeleb1 dataset. The results show that self\nmulti-head attention outperforms both temporal and statistical pooling methods\nwith a 18\\% of relative EER. Obtained results show a 58\\% relative improvement\nin EER compared to i-vector+PLDA.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 12:44:09 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 22:02:09 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["India", "Miquel", ""], ["Safari", "Pooyan", ""], ["Hernando", "Javier", ""]]}, {"id": "1906.09925", "submitter": "Charul Charul", "authors": "Charul and Pravesh Biyani", "title": "To each route its own ETA: A generative modeling framework for ETA\n  prediction", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate expected time of arrival (ETA) information is crucial in maintaining\nthe quality of service of public transit. Recent advances in artificial\nintelligence (AI) has led to more effective models for ETA estimation that rely\nheavily on a large GPS datasets. More importantly, these are mainly cabs based\ndatasets which may not be fit for bus-based public transport. Consequently, the\nlatest methods may not be applicable for ETA estimation in cities with the\nabsence of large training data set. On the other hand, the ETA estimation\nproblem in many cities needs to be solved in the absence of big datasets that\nalso contains outliers, anomalies and may be incomplete. This work presents a\nsimple but robust model for ETA estimation for a bus route that only relies on\nthe historical data of the particular route. We propose a system that generates\nETA information for a trip and updates it as the trip progresses based on the\nreal-time information. We train a deep learning based generative model that\nlearns the probability distribution of ETA data across trips and conditional on\nthe current trip information updates the ETA information on the go. Our plug\nand play model not only captures the non-linearity of the task well but that\nany transit agency can use without needing any other external data source. The\nexperiments run over three routes, data collected in the city of Delhi\nillustrates the promise of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:13:45 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Charul", "", ""], ["Biyani", "Pravesh", ""]]}, {"id": "1906.09926", "submitter": "Prathamesh Deshpande", "authors": "Prathamesh Deshpande, Sunita Sarawagi", "title": "Streaming Adaptation of Deep Forecasting Models using Adaptive Recurrent\n  Units", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": "10.1145/3292500.3330996", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ARU, an Adaptive Recurrent Unit for streaming adaptation of deep\nglobally trained time-series forecasting models. The ARU combines the\nadvantages of learning complex data transformations across multiple time series\nfrom deep global models, with per-series localization offered by closed-form\nlinear models. Unlike existing methods of adaptation that are either\nmemory-intensive or non-responsive after training, ARUs require only fixed\nsized state and adapt to streaming data via an easy RNN-like update operation.\nThe core principle driving ARU is simple --- maintain sufficient statistics of\nconditional Gaussian distributions and use them to compute local parameters in\nclosed form. Our contribution is in embedding such local linear models in\nglobally trained deep models while allowing end-to-end training on the one\nhand, and easy RNN-like updates on the other. Across several datasets we show\nthat ARU is more effective than recently proposed local adaptation methods that\ntax the global network to compute local parameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:15:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 12:08:21 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Deshpande", "Prathamesh", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1906.09936", "submitter": "Valentin Thorey", "authors": "Valentin Thorey, Albert Bou Hernandez, Pierrick J. Arnal, Emmanuel H.\n  During", "title": "AI vs Humans for the diagnosis of sleep apnea", "comments": "copyright 2019 IEEE. Accepted for publication in 41st International\n  Engineering in Medicine and Biology Conference (EMBC), July 23-27, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polysomnography (PSG) is the gold standard for diagnosing sleep obstructive\napnea (OSA). It allows monitoring of breathing events throughout the night. The\ndetection of these events is usually done by trained sleep experts. However,\nthis task is tedious, highly time-consuming and subject to important\ninter-scorer variability. In this study, we adapted our state-of-the-art deep\nlearning method for sleep event detection, DOSED, to the detection of sleep\nbreathing events in PSG for the diagnosis of OSA. We used a dataset of 52 PSG\nrecordings with apnea-hypopnea event scoring from 5 trained sleep experts. We\nassessed the performance of the automatic approach and compared it to the\ninter-scorer performance for both the diagnosis of OSA severity and, at the\nmicroscale, for the detection of single breathing events. We observed that\nhuman sleep experts reached an average accuracy of 75\\% while the automatic\napproach reached 81\\% for sleep apnea severity diagnosis. The F1 score for\nindividual event detection was 0.55 for experts and 0.57 for the automatic\napproach, on average. These results demonstrate that the automatic approach can\nperform at a sleep expert level for the diagnosis of OSA.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:26:58 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Thorey", "Valentin", ""], ["Hernandez", "Albert Bou", ""], ["Arnal", "Pierrick J.", ""], ["During", "Emmanuel H.", ""]]}, {"id": "1906.09951", "submitter": "Yan Yang", "authors": "Yan Yang, Juan Yu, Zhifang Yang, Mingxu Xiang, Ren Liu", "title": "Fast Calculation of Probabilistic Optimal Power Flow: A Deep Learning\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic optimal power flow (POPF) is an important analytical tool to\nensure the secure and economic operation of power systems. POPF needs to solve\nenormous nonlinear and nonconvex optimization problems. The huge computational\nburden has become the major bottleneck for the practical application. This\npaper presents a deep learning approach to solve the POPF problem efficiently\nand accurately. Taking advantage of the deep structure and reconstructive\nstrategy of stacked denoising auto encoders (SDAE), a SDAE-based optimal power\nflow (OPF) is developed to extract the high-level nonlinear correlations\nbetween the system operating condition and the OPF solution. A training process\nis designed to learn the feature of POPF. The trained SDAE network can be\nutilized to conveniently calculate the OPF solution of random samples generated\nby Monte-Carlo simulation (MCS) without the need of optimization. A modified\nIEEE 118-bus power system is simulated to demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:41:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Yang", "Yan", ""], ["Yu", "Juan", ""], ["Yang", "Zhifang", ""], ["Xiang", "Mingxu", ""], ["Liu", "Ren", ""]]}, {"id": "1906.09981", "submitter": "Mark Eisen", "authors": "Zhan Gao, Mark Eisen, Alejandro Ribeiro", "title": "Optimal WDM Power Allocation via Deep Learning for Radio on Free Space\n  Optics Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio on Free Space Optics (RoFSO), as a universal platform for heterogeneous\nwireless services, is able to transmit multiple radio frequency signals at high\nrates in free space optical networks. This paper investigates the optimal\ndesign of power allocation for Wavelength Division Multiplexing (WDM)\ntransmission in RoFSO systems. The proposed problem is a weighted total\ncapacity maximization problem with two constraints of total power limitation\nand eye safety concern. The model-based Stochastic Dual Gradient algorithm is\npresented first, which solves the problem exactly by exploiting the null\nduality gap. The model-free Primal-Dual Deep Learning algorithm is then\ndeveloped to learn and optimize the power allocation policy with Deep Neural\nNetwork (DNN) parametrization, which can be utilized without any knowledge of\nsystem models. Numerical simulations are performed to exhibit significant\nperformance of our algorithms compared to the average equal power allocation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 13:53:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gao", "Zhan", ""], ["Eisen", "Mark", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1906.09986", "submitter": "Suraj Tripathi", "authors": "Suraj Tripathi, Abhay Kumar, Chirag Singh", "title": "Visual Context-aware Convolution Filters for Transformation-invariant\n  Neural Network", "comments": "Under-Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel visual context-aware filter generation module which\nincorporates contextual information present in images into Convolutional Neural\nNetworks (CNNs). In contrast to traditional CNNs, we do not employ the same set\nof learned convolution filters for all input image instances. Our proposed\ninput-conditioned convolution filters when combined with techniques inspired by\nMulti-instance learning and max-pooling, results in a transformation-invariant\nneural network. We investigated the performance of our proposed framework on\nthree MNIST variations, which covers both rotation and scaling variance, and\nachieved 1.13% error on MNIST-rot-12k, 1.12% error on Half-rotated MNIST and\n0.68% error on Scaling MNIST, which is significantly better than the\nstate-of-the-art results. We make use of visualization to further prove the\neffectiveness of our visual context-aware convolution filters. Our proposed\nvisual context-aware convolution filter generation framework can also serve as\na plugin for any CNN based architecture and enhance its modeling capacity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 05:53:16 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Tripathi", "Suraj", ""], ["Kumar", "Abhay", ""], ["Singh", "Chirag", ""]]}, {"id": "1906.09988", "submitter": "Robin Sandkuehler", "authors": "Robin Sandk\\\"uhler, Simon Andermatt, Grzegorz Bauman, Sylvia Nyilas,\n  Christoph Jud, Philippe C. Cattin", "title": "Recurrent Registration Neural Networks for Deformable Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric spatial transformation models have been successfully applied to\nimage registration tasks. In such models, the transformation of interest is\nparameterized by a fixed set of basis functions as for example B-splines. Each\nbasis function is located on a fixed regular grid position among the image\ndomain, because the transformation of interest is not known in advance. As a\nconsequence, not all basis functions will necessarily contribute to the final\ntransformation which results in a non-compact representation of the\ntransformation. We reformulate the pairwise registration problem as a recursive\nsequence of successive alignments. For each element in the sequence, a local\ndeformation defined by its position, shape, and weight is computed by our\nrecurrent registration neural network. The sum of all local deformations yield\nthe final spatial alignment of both images. Formulating the registration\nproblem in this way allows the network to detect non-aligned regions in the\nimages and to learn how to locally refine the registration properly. In\ncontrast to current non-sequence-based registration methods, our approach\niteratively applies local spatial deformations to the images until the desired\nregistration accuracy is achieved. We trained our network on 2D magnetic\nresonance images of the lung and compared our method to a standard parametric\nB-spline registration. The experiments show, that our method performs on par\nfor the accuracy but yields a more compact representation of the\ntransformation. Furthermore, we achieve a speedup of around 15 compared to the\nB-spline registration.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:44:53 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Sandk\u00fchler", "Robin", ""], ["Andermatt", "Simon", ""], ["Bauman", "Grzegorz", ""], ["Nyilas", "Sylvia", ""], ["Jud", "Christoph", ""], ["Cattin", "Philippe C.", ""]]}, {"id": "1906.10019", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "A Review of Statistical Learning Machines from ATR to DNA Microarrays:\n  design, assessment, and advice for practitioners", "comments": "This manuscript was composed in 2006 as part of a the author's Ph.D.\n  dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical Learning is the process of estimating an unknown probabilistic\ninput-output relationship of a system using a limited number of observations;\nand a statistical learning machine (SLM) is the machine that learned such a\nprocess. While their roots grow deeply in Probability Theory, SLMs are\nubiquitous in the modern world. Automatic Target Recognition (ATR) in military\napplications, Computer Aided Diagnosis (CAD) in medical imaging, DNA\nmicroarrays in Genomics, Optical Character Recognition (OCR), Speech\nRecognition (SR), spam email filtering, stock market prediction, etc., are few\nexamples and applications for SLM; diverse fields but one theory.\n  The field of Statistical Learning can be decomposed to two basic subfields,\nDesign and Assessment. Three main groups of specializations-namely\nstatisticians, engineers, and computer scientists (ordered ascendingly by\nprogramming capabilities and descendingly by mathematical rigor)-exist on the\nvenue of this field and each takes its elephant bite. Exaggerated rigorous\nanalysis of statisticians sometimes deprives them from considering new ML\ntechniques and methods that, yet, have no \"complete\" mathematical theory. On\nthe other hand, immoderate add-hoc simulations of computer scientists sometimes\nderive them towards unjustified and immature results. A prudent approach is\nneeded that has the enough flexibility to utilize simulations and trials and\nerrors without sacrificing any rigor. If this prudent attitude is necessary for\nthis field it is necessary, as well, in other fields of Engineering.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:15:21 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 11:27:44 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1906.10025", "submitter": "Sergey Ivanov", "authors": "Sergey Ivanov, Alexander D'yakonov", "title": "Modern Deep Reinforcement Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent advances in Reinforcement Learning, grounded on combining classical\ntheoretical results with Deep Learning paradigm, led to breakthroughs in many\nartificial intelligence tasks and gave birth to Deep Reinforcement Learning\n(DRL) as a field of research. In this work latest DRL algorithms are reviewed\nwith a focus on their theoretical justification, practical limitations and\nobserved empirical properties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:27:51 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 18:30:45 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Ivanov", "Sergey", ""], ["D'yakonov", "Alexander", ""]]}, {"id": "1906.10033", "submitter": "Kristof Sch\\\"utt", "authors": "K. T. Sch\\\"utt, M. Gastegger, A. Tkatchenko, K.-R. M\\\"uller, R. J.\n  Maurer", "title": "Unifying machine learning and quantum chemistry -- a deep neural network\n  for molecular wavefunctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning advances chemistry and materials science by enabling\nlarge-scale exploration of chemical space based on quantum chemical\ncalculations. While these models supply fast and accurate predictions of\natomistic chemical properties, they do not explicitly capture the electronic\ndegrees of freedom of a molecule, which limits their applicability for reactive\nchemistry and chemical analysis. Here we present a deep learning framework for\nthe prediction of the quantum mechanical wavefunction in a local basis of\natomic orbitals from which all other ground-state properties can be derived.\nThis approach retains full access to the electronic structure via the\nwavefunction at force field-like efficiency and captures quantum mechanics in\nan analytically differentiable representation. On several examples, we\ndemonstrate that this opens promising avenues to perform inverse design of\nmolecular structures for target electronic property optimisation and a clear\npath towards increased synergy of machine learning and quantum chemistry.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:46:29 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Sch\u00fctt", "K. T.", ""], ["Gastegger", "M.", ""], ["Tkatchenko", "A.", ""], ["M\u00fcller", "K. -R.", ""], ["Maurer", "R. J.", ""]]}, {"id": "1906.10064", "submitter": "Yuchen Li", "authors": "Yuchen Li, Frank Rudzicz, Jekaterina Novikova", "title": "Variations on the Chebyshev-Lagrange Activation Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to improve the data efficiency of neural networks and present novel\nimplementations of parameterized piece-wise polynomial activation functions.\nThe parameters are the y-coordinates of n+1 Chebyshev nodes per hidden unit and\nLagrangian interpolation between the nodes produces the polynomial on [-1, 1].\nWe show results for different methods of handling inputs outside [-1, 1] on\nsynthetic datasets, finding significant improvements in capacity of expression\nand accuracy of interpolation in models that compute some form of linear\nextrapolation from either ends. We demonstrate competitive or state-of-the-art\nperformance on the classification of images (MNIST and CIFAR-10) and\nminimally-correlated vectors (DementiaBank) when we replace ReLU or tanh with\nlinearly extrapolated Chebyshev-Lagrange activations in deep residual\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:38:22 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Yuchen", ""], ["Rudzicz", "Frank", ""], ["Novikova", "Jekaterina", ""]]}, {"id": "1906.10075", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Christos Tzamos", "title": "Distribution-Independent PAC Learning of Halfspaces with Massart Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of {\\em distribution-independent} PAC learning of\nhalfspaces in the presence of Massart noise. Specifically, we are given a set\nof labeled examples $(\\mathbf{x}, y)$ drawn from a distribution $\\mathcal{D}$\non $\\mathbb{R}^{d+1}$ such that the marginal distribution on the unlabeled\npoints $\\mathbf{x}$ is arbitrary and the labels $y$ are generated by an unknown\nhalfspace corrupted with Massart noise at noise rate $\\eta<1/2$. The goal is to\nfind a hypothesis $h$ that minimizes the misclassification error\n$\\mathbf{Pr}_{(\\mathbf{x}, y) \\sim \\mathcal{D}} \\left[ h(\\mathbf{x}) \\neq y\n\\right]$.\n  We give a $\\mathrm{poly}\\left(d, 1/\\epsilon \\right)$ time algorithm for this\nproblem with misclassification error $\\eta+\\epsilon$. We also provide evidence\nthat improving on the error guarantee of our algorithm might be computationally\nhard. Prior to our work, no efficient weak (distribution-independent) learner\nwas known in this model, even for the class of disjunctions. The existence of\nsuch an algorithm for halfspaces (or even disjunctions) has been posed as an\nopen question in various works, starting with Sloan (1988), Cohen (1997), and\nwas most recently highlighted in Avrim Blum's FOCS 2003 tutorial.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:54:46 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:46:00 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Tzamos", "Christos", ""]]}, {"id": "1906.10086", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski", "title": "Analyzing CART", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees with binary splits are popularly constructed using\nClassification and Regression Trees (CART) methodology. For binary\nclassification and regression models, this approach recursively divides the\ndata into two near-homogenous daughter nodes according to a split point that\nmaximizes the reduction in sum of squares error (the impurity) along a\nparticular variable. This paper aims to study the bias and adaptive properties\nof regression trees constructed with CART. In doing so, we derive an\ninteresting connection between the bias and the mean decrease in impurity (MDI)\nmeasure of variable importance---a tool widely used for model\ninterpretability---defined as the sum of impurity reductions over all\nnon-terminal nodes in the tree. In particular, we show that the probability\ncontent of a terminal subnode for a variable is small when the MDI for that\nvariable is large and that this relationship is exponential---confirming\ntheoretically that decision trees with CART have small bias and are adaptive to\nsignal strength and direction. Finally, we apply these individual tree bounds\nto tree ensembles and show consistency of Breiman's random forests. The context\nis surprisingly general and applies to a wide variety of multivariable data\ngenerating distributions and regression functions. The main technical tool is\nan exact characterization of the conditional probability content of the\ndaughter nodes arising from an optimal split, in terms of the partial\ndependence function and reduction in impurity.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:06:26 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 01:30:19 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 22:21:47 GMT"}, {"version": "v4", "created": "Mon, 5 Aug 2019 16:58:37 GMT"}, {"version": "v5", "created": "Sat, 31 Aug 2019 21:24:35 GMT"}, {"version": "v6", "created": "Fri, 20 Mar 2020 00:12:23 GMT"}, {"version": "v7", "created": "Thu, 13 Aug 2020 18:13:26 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Klusowski", "Jason M.", ""]]}, {"id": "1906.10094", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang, Yuchao Cai, and Hanfang Yang", "title": "Density-based Clustering with Best-scored Random Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-level density-based approach has long been widely acknowledged to be a\nconceptually and mathematically convincing clustering method. In this paper, we\npropose an algorithm called \"best-scored clustering forest\" that can obtain the\noptimal level and determine corresponding clusters. The terminology\n\"best-scored\" means to select one random tree with the best empirical\nperformance out of a certain number of purely random tree candidates. From the\ntheoretical perspective, we first show that consistency of our proposed\nalgorithm can be guaranteed. Moreover, under certain mild restrictions on the\nunderlying density functions and target clusters, even fast convergence rates\ncan be achieved. Last but not least, comparisons with other state-of-the-art\nclustering methods in the numerical experiments demonstrate accuracy of our\nalgorithm on both synthetic data and several benchmark real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:19:22 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hang", "Hanyuan", ""], ["Cai", "Yuchao", ""], ["Yang", "Hanfang", ""]]}, {"id": "1906.10095", "submitter": "Cun Mu", "authors": "Cun Mu, Binwei Yang, Zheng Yan", "title": "An Empirical Comparison of FAISS and FENSHSES for Nearest Neighbor\n  Search in Hamming Space", "comments": "SIGIR eCom'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare the performances of FAISS and FENSHSES on nearest\nneighbor search in Hamming space--a fundamental task with ubiquitous\napplications in nowadays eCommerce. Comprehensive evaluations are made in terms\nof indexing speed, search latency and RAM consumption. This comparison is\nconducted towards a better understanding on trade-offs between nearest neighbor\nsearch systems implemented in main memory and the ones implemented in secondary\nmemory, which is largely unaddressed in literature.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:24:11 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 20:46:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mu", "Cun", ""], ["Yang", "Binwei", ""], ["Yan", "Zheng", ""]]}, {"id": "1906.10115", "submitter": "Justin Domke", "authors": "Justin Domke and Daniel Sheldon", "title": "Divide and Couple: Using Monte Carlo Variational Objectives for\n  Posterior Approximation", "comments": "Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in variational inference (VI) uses ideas from Monte Carlo\nestimation to tighten the lower bounds on the log-likelihood that are used as\nobjectives. However, there is no systematic understanding of how optimizing\ndifferent objectives relates to approximating the posterior distribution.\nDeveloping such a connection is important if the ideas are to be applied to\ninference-i.e., applications that require an approximate posterior and not just\nan approximation of the log-likelihood. Given a VI objective defined by a Monte\nCarlo estimator of the likelihood, we use a \"divide and couple\" procedure to\nidentify augmented proposal and target distributions. The divergence between\nthese is equal to the gap between the VI objective and the log-likelihood.\nThus, after maximizing the VI objective, the augmented variational distribution\nmay be used to approximate the posterior distribution.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:57:33 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 01:01:18 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 15:12:35 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Domke", "Justin", ""], ["Sheldon", "Daniel", ""]]}, {"id": "1906.10121", "submitter": "Absalom Ezugwu", "authors": "Bradley J. Pillay and Absalom E. Ezugwu", "title": "Metaheuristics optimized feedforward neural networks for efficient stock\n  price prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The prediction of stock prices is an important task in economics, investment\nand making financial decisions. This has, for decades, spurred the interest of\nmany researchers to make focused contributions to the design of accurate stock\nprice predictive models; of which some have been utilized to predict the next\nday opening and closing prices of the stock indices. This paper proposes the\ndesign and implementation of a hybrid symbiotic organisms search trained\nfeedforward neural network model for effective and accurate stock price\nprediction. The symbiotic organisms search algorithm is used as an efficient\noptimization technique to train the feedforward neural networks, while the\nresulting training process is used to build a better stock price prediction\nmodel. Furthermore, the study also presents a comparative performance\nevaluation of three different stock price forecasting models; namely, the\nparticle swarm optimization trained feedforward neural network model, the\ngenetic algorithm trained feedforward neural network model and the well-known\nARIMA model. The system developed in support of this study utilizes sixteen\nstock indices as time series datasets for training and testing purpose. Three\nstatistical evaluation measures are used to compare the results of the\nimplemented models, namely the root mean squared error, the mean absolute\npercentage error and the mean absolution deviation. The computational results\nobtained reveal that the symbiotic organisms search trained feedforward neural\nnetwork model exhibits outstanding predictive performance compared to the other\nmodels. However, the performance study shows that the three metaheuristics\ntrained feedforward neural network models have promising predictive competence\nfor solving problems of high dimensional nonlinear time series data, which are\ndifficult to capture by traditional models.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 11:31:52 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 12:19:40 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 16:13:42 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Pillay", "Bradley J.", ""], ["Ezugwu", "Absalom E.", ""]]}, {"id": "1906.10186", "submitter": "Lin Xiao", "authors": "Junyu Zhang and Lin Xiao", "title": "A Stochastic Composite Gradient Method with Incremental Variance\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing the composition of a smooth (nonconvex)\nfunction and a smooth vector mapping, where the inner mapping is in the form of\nan expectation over some random variable or a finite sum. We propose a\nstochastic composite gradient method that employs an incremental\nvariance-reduced estimator for both the inner vector mapping and its Jacobian.\nWe show that this method achieves the same orders of complexity as the best\nknown first-order methods for minimizing expected-value and finite-sum\nnonconvex functions, despite the additional outer composition which renders the\ncomposite gradient estimator biased. This finding enables a much broader range\nof applications in machine learning to benefit from the low complexity of\nincremental variance-reduction methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:21:29 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zhang", "Junyu", ""], ["Xiao", "Lin", ""]]}, {"id": "1906.10188", "submitter": "Pegah Karimi", "authors": "Pegah Karimi, Mary Lou Maher, Nicholas Davis, Kazjon Grace", "title": "Deep Learning in a Computational Model for Conceptual Shifts in a\n  Co-Creative Design System", "comments": "9 pages, 3 Figures, 1 Table, Accepted in ICCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a computational model for conceptual shifts, based on a\nnovelty metric applied to a vector representation generated through deep\nlearning. This model is integrated into a co-creative design system, which\nenables a partnership between an AI agent and a human designer interacting\nthrough a sketching canvas. The AI agent responds to the human designer's\nsketch with a new sketch that is a conceptual shift: intentionally varying the\nvisual and conceptual similarity with increasingly more novelty. The paper\npresents the results of a user study showing that increasing novelty in the AI\ncontribution is associated with higher creative outcomes, whereas low novelty\nleads to less creative outcomes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:24:09 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Karimi", "Pegah", ""], ["Maher", "Mary Lou", ""], ["Davis", "Nicholas", ""], ["Grace", "Kazjon", ""]]}, {"id": "1906.10199", "submitter": "Charles Onu", "authors": "Charles C. Onu, Jonathan Lebensold, William L. Hamilton, Doina Precup", "title": "Neural Transfer Learning for Cry-based Diagnosis of Perinatal Asphyxia", "comments": "Accepted at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite continuing medical advances, the rate of newborn morbidity and\nmortality globally remains high, with over 6 million casualties every year. The\nprediction of pathologies affecting newborns based on their cry is thus of\nsignificant clinical interest, as it would facilitate the development of\naccessible, low-cost diagnostic tools\\cut{ based on wearables and smartphones}.\nHowever, the inadequacy of clinically annotated datasets of infant cries limits\nprogress on this task. This study explores a neural transfer learning approach\nto developing accurate and robust models for identifying infants that have\nsuffered from perinatal asphyxia. In particular, we explore the hypothesis that\nrepresentations learned from adult speech could inform and improve performance\nof models developed on infant speech. Our experiments show that models based on\nsuch representation transfer are resilient to different types and degrees of\nnoise, as well as to signal loss in time and frequency domains.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:47:37 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 13:33:29 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 12:21:33 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Onu", "Charles C.", ""], ["Lebensold", "Jonathan", ""], ["Hamilton", "William L.", ""], ["Precup", "Doina", ""]]}, {"id": "1906.10225", "submitter": "Yoon Kim", "authors": "Yoon Kim, Chris Dyer, Alexander M. Rush", "title": "Compound Probabilistic Context-Free Grammars for Grammar Induction", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a formalization of the grammar induction problem that models\nsentences as being generated by a compound probabilistic context-free grammar.\nIn contrast to traditional formulations which learn a single stochastic\ngrammar, our grammar's rule probabilities are modulated by a per-sentence\ncontinuous latent variable, which induces marginal dependencies beyond the\ntraditional context-free assumptions. Inference in this grammar is performed by\ncollapsed variational inference, in which an amortized variational posterior is\nplaced on the continuous variable, and the latent trees are marginalized out\nwith dynamic programming. Experiments on English and Chinese show the\neffectiveness of our approach compared to recent state-of-the-art methods when\nevaluated on unsupervised parsing.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 20:45:50 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 01:53:59 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2019 00:47:50 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2019 03:04:52 GMT"}, {"version": "v5", "created": "Wed, 14 Aug 2019 15:02:33 GMT"}, {"version": "v6", "created": "Sun, 18 Aug 2019 05:04:18 GMT"}, {"version": "v7", "created": "Sun, 1 Sep 2019 02:06:46 GMT"}, {"version": "v8", "created": "Tue, 17 Mar 2020 23:53:34 GMT"}, {"version": "v9", "created": "Sun, 29 Mar 2020 16:27:33 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kim", "Yoon", ""], ["Dyer", "Chris", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1906.10228", "submitter": "Jad Rahme", "authors": "Jad Rahme and Ryan P. Adams", "title": "A Theoretical Connection Between Statistical Physics and Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision making in the presence of uncertainty and stochastic\ndynamics gives rise to distributions over state/action trajectories in\nreinforcement learning (RL) and optimal control problems. This observation has\nled to a variety of connections between RL and inference in probabilistic\ngraphical models (PGMs). Here we explore a different dimension to this\nrelationship, examining reinforcement learning using the tools and abstractions\nof statistical physics. The central object in the statistical physics\nabstraction is the idea of a partition function $\\mathcal{Z}$, and here we\nconstruct a partition function from the ensemble of possible trajectories that\nan agent might take in a Markov decision process. Although value functions and\n$Q$-functions can be derived from this partition function and interpreted via\naverage energies, the $\\mathcal{Z}$-function provides an object with its own\nBellman equation that can form the basis of alternative dynamic programming\napproaches. Moreover, when the MDP dynamics are deterministic, the Bellman\nequation for $\\mathcal{Z}$ is linear, allowing direct solutions that are\nunavailable for the nonlinear equations associated with traditional value\nfunctions. The policies learned via these $\\mathcal{Z}$-based Bellman updates\nare tightly linked to Boltzmann-like policy parameterizations. In addition to\nsampling actions proportionally to the exponential of the expected cumulative\nreward as Boltzmann policies would, these policies take entropy into account\nfavoring states from which many outcomes are possible.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 20:47:42 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Rahme", "Jad", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1906.10242", "submitter": "Luyun Gan", "authors": "Luyun Gan, Brosnan Yuen and Tao Lu", "title": "Multi-label Classification with Optimal Thresholding for\n  Multi-composition Spectroscopic Analysis", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we implement multi-label neural networks with optimal\nthresholding to identify gas species among a multi gas mixture in a cluttered\nenvironment. Using infrared absorption spectroscopy and tested on synthesized\nspectral datasets, our approach outperforms conventional binary relevance -\npartial least squares discriminant analysis when signal-to-noise ratio and\ntraining sample size are sufficient.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 21:36:19 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Gan", "Luyun", ""], ["Yuen", "Brosnan", ""], ["Lu", "Tao", ""]]}, {"id": "1906.10244", "submitter": "Ramya Srinivasan", "authors": "Ramya Srinivasan, Ajay Chander, Pouya Pezeshkpour", "title": "Generating User-friendly Explanations for Loan Denials using GANs", "comments": "Presented at the NeurIPS 2018 Workshop on Challenges and\n  Opportunities for AI in Financial Services: the Impact of Fairness,\n  Explainability, Accuracy, and Privacy, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial decisions impact our lives, and thus everyone from the regulator to\nthe consumer is interested in fair, sound, and explainable decisions. There is\nincreasing competitive desire and regulatory incentive to deploy AI mindfully\nwithin financial services. An important mechanism towards that end is to\nexplain AI decisions to various stakeholders. State-of-the-art explainable AI\nsystems mostly serve AI engineers and offer little to no value to business\ndecision makers, customers, and other stakeholders. Towards addressing this\ngap, in this work we consider the scenario of explaining loan denials. We build\nthe first-of-its-kind dataset that is representative of loan-applicant friendly\nexplanations. We design a novel Generative Adversarial Network (GAN) that can\naccommodate smaller datasets, to generate user-friendly textual explanations.\nWe demonstrate how our system can also generate explanations serving different\npurposes: those that help educate the loan applicants, or help them take\nappropriate action towards a future approval.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 21:41:55 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Srinivasan", "Ramya", ""], ["Chander", "Ajay", ""], ["Pezeshkpour", "Pouya", ""]]}, {"id": "1906.10258", "submitter": "Davide Viviano Mr.", "authors": "Davide Viviano", "title": "Policy Targeting under Network Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.SI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the problem of estimating treatment allocation rules\nunder network interference. I propose a method with several attractive features\nfor applications: (i) it does not rely on the correct specification of a\nparticular structural model; (ii) it exploits heterogeneity in treatment\neffects for targeting individuals; (iii) it accommodates arbitrary constraints\non the policy function; (iv) it does not necessitate network information of the\ntarget units. I introduce estimation procedures that leverage experimental or\nobservational data and derive strong guarantees on the utilitarian regret. I\nprovide a mixed-integer linear program formulation, which can be solved using\noff-the-shelf algorithms. I illustrate the advantages of the method for\ntargeting information on social networks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 22:42:32 GMT"}, {"version": "v10", "created": "Tue, 30 Mar 2021 14:53:08 GMT"}, {"version": "v11", "created": "Tue, 11 May 2021 03:43:47 GMT"}, {"version": "v12", "created": "Tue, 1 Jun 2021 16:09:04 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 04:21:07 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 16:39:58 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 05:37:55 GMT"}, {"version": "v5", "created": "Sun, 10 Nov 2019 17:46:00 GMT"}, {"version": "v6", "created": "Tue, 7 Apr 2020 14:46:03 GMT"}, {"version": "v7", "created": "Fri, 12 Jun 2020 02:23:28 GMT"}, {"version": "v8", "created": "Thu, 17 Dec 2020 02:23:59 GMT"}, {"version": "v9", "created": "Thu, 25 Mar 2021 17:35:18 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Viviano", "Davide", ""]]}, {"id": "1906.10263", "submitter": "Muhammad Rehman Zafar", "authors": "Muhammad Rehman Zafar, Naimul Mefraz Khan", "title": "DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations\n  Approach for Computer-Aided Diagnosis Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Interpretable Model-Agnostic Explanations (LIME) is a popular technique\nused to increase the interpretability and explainability of black box Machine\nLearning (ML) algorithms. LIME typically generates an explanation for a single\nprediction by any ML model by learning a simpler interpretable model (e.g.\nlinear classifier) around the prediction through generating simulated data\naround the instance by random perturbation, and obtaining feature importance\nthrough applying some form of feature selection. While LIME and similar local\nalgorithms have gained popularity due to their simplicity, the random\nperturbation and feature selection methods result in \"instability\" in the\ngenerated explanations, where for the same prediction, different explanations\ncan be generated. This is a critical issue that can prevent deployment of LIME\nin a Computer-Aided Diagnosis (CAD) system, where stability is of utmost\nimportance to earn the trust of medical professionals. In this paper, we\npropose a deterministic version of LIME. Instead of random perturbation, we\nutilize agglomerative Hierarchical Clustering (HC) to group the training data\ntogether and K-Nearest Neighbour (KNN) to select the relevant cluster of the\nnew instance that is being explained. After finding the relevant cluster, a\nlinear model is trained over the selected cluster to generate the explanations.\nExperimental results on three different medical datasets show the superiority\nfor Deterministic Local Interpretable Model-Agnostic Explanations (DLIME),\nwhere we quantitatively determine the stability of DLIME compared to LIME\nutilizing the Jaccard similarity among multiple generated explanations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 23:08:03 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zafar", "Muhammad Rehman", ""], ["Khan", "Naimul Mefraz", ""]]}, {"id": "1906.10264", "submitter": "Gautam Singh", "authors": "Gautam Singh, Jaesik Yoon, Youngsung Son, Sungjin Ahn", "title": "Sequential Neural Processes", "comments": "NeurIPS 2019 Spotlight. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Processes combine the strengths of neural networks and Gaussian\nprocesses to achieve both flexible learning and fast prediction in stochastic\nprocesses. However, a large class of problems comprises underlying temporal\ndependency structures in a sequence of stochastic processes that Neural\nProcesses (NP) do not explicitly consider. In this paper, we propose Sequential\nNeural Processes (SNP) which incorporates a temporal state-transition model of\nstochastic processes and thus extends its modeling capabilities to dynamic\nstochastic processes. In applying SNP to dynamic 3D scene modeling, we\nintroduce the Temporal Generative Query Networks. To our knowledge, this is the\nfirst 4D model that can deal with the temporal dynamics of 3D scenes. In\nexperiments, we evaluate the proposed methods in dynamic (non-stationary)\nregression and 4D scene inference and rendering.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 23:11:45 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 00:24:20 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 07:48:36 GMT"}, {"version": "v4", "created": "Sun, 27 Oct 2019 16:18:21 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Singh", "Gautam", ""], ["Yoon", "Jaesik", ""], ["Son", "Youngsung", ""], ["Ahn", "Sungjin", ""]]}, {"id": "1906.10283", "submitter": "Jean Pauphilet", "authors": "Dimitris Bertsimas, Jourdain Lamperski and Jean Pauphilet", "title": "Certifiably Optimal Sparse Inverse Covariance Estimation", "comments": null, "journal-ref": "Mathematical Programming 184 (2020) 491-530", "doi": "10.1007/s10107-019-01419-7", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the maximum likelihood estimation of sparse inverse covariance\nmatrices. We demonstrate that current heuristic approaches primarily encourage\nrobustness, instead of the desired sparsity. We give a novel approach that\nsolves the cardinality constrained likelihood problem to certifiable\noptimality. The approach uses techniques from mixed-integer optimization and\nconvex optimization, and provides a high-quality solution with a guarantee on\nits suboptimality, even if the algorithm is terminated early. Using a variety\nof synthetic and real datasets, we demonstrate that our approach can solve\nproblems where the dimension of the inverse covariance matrix is up to 1,000s.\nWe also demonstrate that our approach produces significantly sparser solutions\nthan Glasso and other popular learning procedures, makes less false\ndiscoveries, while still maintaining state-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 00:45:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Lamperski", "Jourdain", ""], ["Pauphilet", "Jean", ""]]}, {"id": "1906.10304", "submitter": "Weijie Bian", "authors": "Guorui Zhou, Kailun Wu, Weijie Bian, Zhao Yang, Xiaoqiang Zhu, Kun Gai", "title": "Res-embedding for Deep Learning Based Click-Through Rate Prediction\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, click-through rate (CTR) prediction models have evolved from\nshallow methods to deep neural networks. Most deep CTR models follow an\nEmbedding\\&MLP paradigm, that is, first mapping discrete id features, e.g. user\nvisited items, into low dimensional vectors with an embedding module, then\nlearn a multi-layer perception (MLP) to fit the target. In this way, embedding\nmodule performs as the representative learning and plays a key role in the\nmodel performance. However, in many real-world applications, deep CTR model\noften suffers from poor generalization performance, which is mostly due to the\nlearning of embedding parameters. In this paper, we model user behavior using\nan interest delay model, study carefully the embedding mechanism, and obtain\ntwo important results: (i) We theoretically prove that small aggregation radius\nof embedding vectors of items which belongs to a same user interest domain will\nresult in good generalization performance of deep CTR model. (ii) Following our\ntheoretical analysis, we design a new embedding structure named res-embedding.\nIn res-embedding module, embedding vector of each item is the sum of two\ncomponents: (i) a central embedding vector calculated from an item-based\ninterest graph (ii) a residual embedding vector with its scale to be relatively\nsmall. Empirical evaluation on several public datasets demonstrates the\neffectiveness of the proposed res-embedding structure, which brings significant\nimprovement on the model performance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 03:13:43 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zhou", "Guorui", ""], ["Wu", "Kailun", ""], ["Bian", "Weijie", ""], ["Yang", "Zhao", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1906.10306", "submitter": "Boyi Liu", "authors": "Boyi Liu, Qi Cai, Zhuoran Yang, Zhaoran Wang", "title": "Neural Proximal/Trust Region Policy Optimization Attains Globally\n  Optimal Policy", "comments": "A short version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization and trust region policy optimization (PPO and\nTRPO) with actor and critic parametrized by neural networks achieve significant\nempirical success in deep reinforcement learning. However, due to nonconvexity,\nthe global convergence of PPO and TRPO remains less understood, which separates\ntheory from practice. In this paper, we prove that a variant of PPO and TRPO\nequipped with overparametrized neural networks converges to the globally\noptimal policy at a sublinear rate. The key to our analysis is the global\nconvergence of infinite-dimensional mirror descent under a notion of one-point\nmonotonicity, where the gradient and iterate are instantiated by neural\nnetworks. In particular, the desirable representation power and optimization\ngeometry induced by the overparametrization of such neural networks allow them\nto accurately approximate the infinite-dimensional gradient and iterate.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 03:20:04 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:07:35 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Liu", "Boyi", ""], ["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1906.10307", "submitter": "Vinay Varma Kalidindi", "authors": "Yaohui Guo, Vinay Varma Kalidindi, Mansur Arief, Wenshuo Wang,\n  Jiacheng Zhu, Huei Peng, Ding Zhao", "title": "Modeling Multi-Vehicle Interaction Scenarios Using Gaussian Random Field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles are expected to navigate in complex traffic scenarios\nwith multiple surrounding vehicles. The correlations between road users vary\nover time, the degree of which, in theory, could be infinitely large, thus\nposing a great challenge in modeling and predicting the driving environment. In\nthis paper, we propose a method to model multi-vehicle interactions using a\nstochastic vector field model and apply non-parametric Bayesian learning to\nextract the underlying motion patterns from a large quantity of naturalistic\ntraffic data. We then use this model to reproduce the high-dimensional driving\nscenarios in a finitely tractable form. We use a Gaussian process to model\nmulti-vehicle motion, and a Dirichlet process to assign each observation to a\nspecific scenario. We verify the effectiveness of the proposed method on\nhighway and intersection datasets from the NGSIM project, in which complex\nmulti-vehicle interactions are prevalent. The results show that the proposed\nmethod can capture motion patterns from both settings, without imposing heroic\nprior, and hence demonstrate the potential application for a wide array of\ntraffic situations. The proposed modeling method could enable simulation\nplatforms and other testing methods designed for autonomous vehicle evaluation,\nto easily model and generate traffic scenarios emulating large scale driving\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 03:20:15 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:52:00 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Guo", "Yaohui", ""], ["Kalidindi", "Vinay Varma", ""], ["Arief", "Mansur", ""], ["Wang", "Wenshuo", ""], ["Zhu", "Jiacheng", ""], ["Peng", "Huei", ""], ["Zhao", "Ding", ""]]}, {"id": "1906.10317", "submitter": "Devashish Khulbe", "authors": "Devashish Khulbe and Soumya Sourav", "title": "Modeling Severe Traffic Accidents With Spatial And Temporal Features", "comments": "6 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to estimate the severity of traffic related accidents\nin aggregated (area-level) and disaggregated (point level) data. Exploring\nspatial features, we measure complexity of road networks using several area\nlevel variables. Also using temporal and other situational features from open\ndata for New York City, we use Gradient Boosting models for inference and\nmeasuring feature importance along with Gaussian Processes to model spatial\ndependencies in the data. The results show significant importance of complexity\nin aggregated model as well as as other features in prediction which may be\nhelpful in framing policies and targeting interventions for preventing severe\ntraffic related accidents and injuries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 04:31:19 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Khulbe", "Devashish", ""], ["Sourav", "Soumya", ""]]}, {"id": "1906.10320", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Shi Hui Tan, Ana Fern\\'andez del R\\'io, Pei Pei Chen and\n  \\'Africa Peri\\'a\\~nez", "title": "From Non-Paying to Premium: Predicting User Conversion in Video Games\n  with Ensemble Learning", "comments": "social games, conversion prediction, ensemble methods, survival\n  analysis, online games, user behavior", "journal-ref": "ACM Foundations of Digital Games (FDG'2019), 97, 9, 2019", "doi": "10.1145/3337722.3341855", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retaining premium players is key to the success of free-to-play games, but\nmost of them do not start purchasing right after joining the game. By\nexploiting the exceptionally rich datasets recorded by modern video\ngames--which provide information on the individual behavior of each and every\nplayer--survival analysis techniques can be used to predict what players are\nmore likely to become paying (or even premium) users and when, both in terms of\ntime and game level, the conversion will take place. Here we show that a\ntraditional semi-parametric model (Cox regression), a random survival forest\n(RSF) technique and a method based on conditional inference survival ensembles\nall yield very promising results. However, the last approach has the advantage\nof being able to correct the inherent bias in RSF models by dividing the\nprocedure into two steps: first selecting the best predictor to perform the\nsplitting and then the best split point for that covariate. The proposed\nconditional inference survival ensembles method could be readily used in\noperational environments for early identification of premium players and the\nparts of the game that may prompt them to become paying users. Such knowledge\nwould allow developers to induce their conversion and, more generally, to\nbetter understand the needs of their players and provide them with a\npersonalized experience, thereby increasing their engagement and paving the way\nto higher monetization.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 04:42:53 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 01:23:24 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Guitart", "Anna", ""], ["Tan", "Shi Hui", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Chen", "Pei Pei", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1906.10329", "submitter": "Ahmed Shifaz", "authors": "Ahmed Shifaz, Charlotte Pelletier, Francois Petitjean, Geoffrey I.\n  Webb", "title": "TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series\n  Classification", "comments": "37 pages, 10 figures", "journal-ref": "Data Mining and Knowledge Discovery 34 (2020) 742-775", "doi": "10.1007/s10618-020-00679-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Classification (TSC) has seen enormous progress over the last two\ndecades. HIVE-COTE (Hierarchical Vote Collective of Transformation-based\nEnsembles) is the current state of the art in terms of classification accuracy.\nHIVE-COTE recognizes that time series data are a specific data type for which\nthe traditional attribute-value representation, used predominantly in machine\nlearning, fails to provide a relevant representation. HIVE-COTE combines\nmultiple types of classifiers: each extracting information about a specific\naspect of a time series, be it in the time domain, frequency domain or\nsummarization of intervals within the series. However, HIVE-COTE (and its\npredecessor, FLAT-COTE) is often infeasible to run on even modest amounts of\ndata. For instance, training HIVE-COTE on a dataset with only 1,500 time series\ncan require 8 days of CPU time. It has polynomial runtime with respect to the\ntraining set size, so this problem compounds as data quantity increases. We\npropose a novel TSC algorithm, TS-CHIEF (Time Series Combination of\nHeterogeneous and Integrated Embedding Forest), which rivals HIVE-COTE in\naccuracy but requires only a fraction of the runtime. TS-CHIEF constructs an\nensemble classifier that integrates the most effective embeddings of time\nseries that research has developed in the last decade. It uses tree-structured\nclassifiers to do so efficiently. We assess TS-CHIEF on 85 datasets of the\nUniversity of California Riverside (UCR) archive, where it achieves\nstate-of-the-art accuracy with scalability and efficiency. We demonstrate that\nTS-CHIEF can be trained on 130k time series in 2 days, a data quantity that is\nbeyond the reach of any TSC algorithm with comparable accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 05:41:16 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 04:14:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Shifaz", "Ahmed", ""], ["Pelletier", "Charlotte", ""], ["Petitjean", "Francois", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "1906.10335", "submitter": "Zijun Zhang", "authors": "Zijun Zhang, Ruixiang Zhang, Zongpeng Li, Yoshua Bengio, Liam Paull", "title": "Perceptual Generative Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern generative models are usually designed to match target distributions\ndirectly in the data space, where the intrinsic dimension of data can be much\nlower than the ambient dimension. We argue that this discrepancy may contribute\nto the difficulties in training generative models. We therefore propose to map\nboth the generated and target distributions to a latent space using the encoder\nof a standard autoencoder, and train the generator (or decoder) to match the\ntarget distribution in the latent space. Specifically, we enforce the\nconsistency in both the data space and the latent space with theoretically\njustified data and latent reconstruction losses. The resulting generative\nmodel, which we call a perceptual generative autoencoder (PGA), is then trained\nwith a maximum likelihood or variational autoencoder (VAE) objective. With\nmaximum likelihood, PGAs generalize the idea of reversible generative models to\nunrestricted neural network architectures and arbitrary number of latent\ndimensions. When combined with VAEs, PGAs substantially improve over the\nbaseline VAEs in terms of sample quality. Compared to other autoencoder-based\ngenerative models using simple priors, PGAs achieve state-of-the-art FID scores\non CIFAR-10 and CelebA.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 06:03:14 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 04:52:04 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Zhang", "Zijun", ""], ["Zhang", "Ruixiang", ""], ["Li", "Zongpeng", ""], ["Bengio", "Yoshua", ""], ["Paull", "Liam", ""]]}, {"id": "1906.10343", "submitter": "Phi Vu Tran", "authors": "Phi Vu Tran", "title": "Exploring Self-Supervised Regularization for Supervised and\n  Semi-Supervised Learning", "comments": "NeurIPS'19 Workshop on Learning with Rich Experience: Integration of\n  Learning Paradigms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in semi-supervised learning have shown tremendous potential\nin overcoming a major barrier to the success of modern machine learning\nalgorithms: access to vast amounts of human-labeled training data. Previous\nalgorithms based on consistency regularization can harness the abundance of\nunlabeled data to produce impressive results on a number of semi-supervised\nbenchmarks, approaching the performance of strong supervised baselines using\nonly a fraction of the available labeled data. In this work, we challenge the\nlong-standing success of consistency regularization by introducing\nself-supervised regularization as the basis for combining semantic feature\nrepresentations from unlabeled data. We perform extensive comparative\nexperiments to demonstrate the effectiveness of self-supervised regularization\nfor supervised and semi-supervised image classification on SVHN, CIFAR-10, and\nCIFAR-100 benchmark datasets. We present two main results: (1) models augmented\nwith self-supervised regularization significantly improve upon traditional\nsupervised classifiers without the need for unlabeled data; (2) together with\nunlabeled data, our models yield semi-supervised performance competitive with,\nand in many cases exceeding, prior state-of-the-art consistency baselines.\nLastly, our models have the practical utility of being efficiently trained\nend-to-end and require no additional hyper-parameters to tune for optimal\nperformance beyond the standard set for training neural networks. Reference\ncode and data are available at https://github.com/vuptran/sesemi\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 06:42:05 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 08:30:43 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Tran", "Phi Vu", ""]]}, {"id": "1906.10407", "submitter": "Boyi Liu", "authors": "Boyi Liu, Xiangyan Tang, Jieren Cheng, Pengchao Shi", "title": "Traffic Flow Combination Forecasting Method Based on Improved LSTM and\n  ARIMA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow forecasting is hot spot research of intelligent traffic system\nconstruction. The existing traffic flow prediction methods have problems such\nas poor stability, high data requirements, or poor adaptability. In this paper,\nwe define the traffic data time singularity ratio in the dropout module and\npropose a combination prediction method based on the improved long short-term\nmemory neural network and time series autoregressive integrated moving average\nmodel (SDLSTM-ARIMA), which is derived from the Recurrent Neural Networks (RNN)\nmodel. It compares the traffic data time singularity with the probability value\nin the dropout module and combines them at unequal time intervals to achieve an\naccurate prediction of traffic flow data. Then, we design an adaptive traffic\nflow embedded system that can adapt to Java, Python and other languages and\nother interfaces. The experimental results demonstrate that the method based on\nthe SDLSTM - ARIMA model has higher accuracy than the similar method using only\nautoregressive integrated moving average or autoregressive. Our embedded\ntraffic prediction system integrating computer vision, machine learning and\ncloud has the advantages such as high accuracy, high reliability and low cost.\nTherefore, it has a wide application prospect.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 09:26:01 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Liu", "Boyi", ""], ["Tang", "Xiangyan", ""], ["Cheng", "Jieren", ""], ["Shi", "Pengchao", ""]]}, {"id": "1906.10431", "submitter": "R\\'emy Degenne", "authors": "R\\'emy Degenne, Wouter M. Koolen, Pierre M\\'enard", "title": "Non-Asymptotic Pure Exploration by Solving Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pure exploration (aka active testing) is the fundamental task of sequentially\ngathering information to answer a query about a stochastic environment. Good\nalgorithms make few mistakes and take few samples. Lower bounds (for\nmulti-armed bandit models with arms in an exponential family) reveal that the\nsample complexity is determined by the solution to an optimisation problem. The\nexisting state of the art algorithms achieve asymptotic optimality by solving a\nplug-in estimate of that optimisation problem at each step. We interpret the\noptimisation problem as an unknown game, and propose sampling rules based on\niterative strategies to estimate and converge to its saddle point. We apply\nno-regret learners to obtain the first finite confidence guarantees that are\nadapted to the exponential family and which apply to any pure exploration query\nand bandit structure. Moreover, our algorithms only use a best response oracle\ninstead of fully solving the optimisation problem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:09:07 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Degenne", "R\u00e9my", ""], ["Koolen", "Wouter M.", ""], ["M\u00e9nard", "Pierre", ""]]}, {"id": "1906.10437", "submitter": "Amy Zhang", "authors": "Amy Zhang, Zachary C. Lipton, Luis Pineda, Kamyar Azizzadenesheli,\n  Anima Anandkumar, Laurent Itti, Joelle Pineau, Tommaso Furlanello", "title": "Learning Causal State Representations of Partially Observable\n  Environments", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents can cope with sensory-rich environments by learning\ntask-agnostic state abstractions. In this paper, we propose an algorithm to\napproximate causal states, which are the coarsest partition of the joint\nhistory of actions and observations in partially-observable Markov decision\nprocesses (POMDP). Our method learns approximate causal state representations\nfrom RNNs trained to predict subsequent observations given the history. We\ndemonstrate that these learned state representations are useful for learning\npolicies efficiently in reinforcement learning problems with rich observation\nspaces. We connect causal states with causal feature sets from the causal\ninference literature, and also provide theoretical guarantees on the optimality\nof the continuous version of this causal state representation under Lipschitz\nassumptions by proving equivalence to bisimulation, a relation between\nbehaviorally equivalent systems. This allows for lower bounds on the optimal\nvalue function of the learned representation, which is tight given certain\nassumptions. Finally, we empirically evaluate causal state representations\nusing multiple partially observable tasks and compare with prior methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:27:57 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 18:54:23 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhang", "Amy", ""], ["Lipton", "Zachary C.", ""], ["Pineda", "Luis", ""], ["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Anima", ""], ["Itti", "Laurent", ""], ["Pineau", "Joelle", ""], ["Furlanello", "Tommaso", ""]]}, {"id": "1906.10454", "submitter": "Oleksandr Zadorozhnyi", "authors": "Oleksandr Zadorozhnyi, Gilles Blanchard, Alexandra Carpentier", "title": "Restless dependent bandits with fading memory", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic multi-armed bandit problem in the case when the arm\nsamples are dependent over time and generated from so-called weak $\\cC$-mixing\nprocesses. We establish a $\\cC-$Mix Improved UCB agorithm and provide both\nproblem-dependent and independent regret analysis in two different scenarios.\nIn the first, so-called fast-mixing scenario, we show that pseudo-regret enjoys\nthe same upper bound (up to a factor) as for i.i.d. observations; whereas in\nthe second, slow mixing scenario, we discover a surprising effect, that the\nregret upper bound is similar to the independent case, with an incremental {\\em\nadditive} term which does not depend on the number of arms. The analysis of\nslow mixing scenario is supported with a minmax lower bound, which (up to a\n$\\log(T)$ factor) matches the obtained upper bound.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 11:10:11 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zadorozhnyi", "Oleksandr", ""], ["Blanchard", "Gilles", ""], ["Carpentier", "Alexandra", ""]]}, {"id": "1906.10462", "submitter": "Long Yang", "authors": "Long Yang, Gang Zheng, Haotian Zhang, Yu Zhang, Qian Zheng, Jun Wen,\n  Gang Pan", "title": "Policy Optimization with Stochastic Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving sample efficiency has been a longstanding goal in reinforcement\nlearning. In this paper, we propose the $\\mathtt{VRMPO}$: a sample efficient\npolicy gradient method with stochastic mirror descent. A novel variance reduced\npolicy gradient estimator is the key of $\\mathtt{VRMPO}$ to improve sample\nefficiency. Our $\\mathtt{VRMPO}$ needs only $\\mathcal{O}(\\epsilon^{-3})$ sample\ntrajectories to achieve an $\\epsilon$-approximate first-order stationary point,\nwhich matches the best-known sample complexity. We conduct extensive\nexperiments to show our algorithm outperforms state-of-the-art policy gradient\nmethods in various settings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 11:36:18 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:12:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yang", "Long", ""], ["Zheng", "Gang", ""], ["Zhang", "Haotian", ""], ["Zhang", "Yu", ""], ["Zheng", "Qian", ""], ["Wen", "Jun", ""], ["Pan", "Gang", ""]]}, {"id": "1906.10470", "submitter": "Jielong Yang", "authors": "Jielong Yang and Wee Peng Tay", "title": "An Unsupervised Bayesian Neural Network for Truth Discovery in Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating event truths from conflicting agent opinions in a\nsocial network is investigated. An autoencoder learns the complex relationships\nbetween event truths, agent reliabilities and agent observations. A Bayesian\nnetwork model is proposed to guide the learning process by modeling the\nrelationship of the autoencoder's outputs with different variables. At the same\ntime, it also models the social relationships between agents in the network.\nThe proposed approach is unsupervised and is applicable when ground truth\nlabels of events are unavailable. A variational inference method is used to\njointly estimate the hidden variables in the Bayesian network and the\nparameters in the autoencoder. Experiments on three real datasets demonstrate\nthat our proposed approach is competitive with, and in most cases better than,\nseveral state-of-the-art benchmark methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 12:18:46 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 02:35:03 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yang", "Jielong", ""], ["Tay", "Wee Peng", ""]]}, {"id": "1906.10502", "submitter": "Hossein Hajipour", "authors": "Hossein Hajipour, Apratim Bhattacharya, Mario Fritz", "title": "SampleFix: Learning to Correct Programs by Sampling Diverse Fixes", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic program correction is an active topic of research, which holds the\npotential of dramatically improving productivity of programmers during the\nsoftware development process and correctness of software in general. Recent\nadvances in machine learning, deep learning and NLP have rekindled the hope to\neventually fully automate the process of repairing programs. A key challenge is\nambiguity, as multiple codes -- or fixes -- can implement the same\nfunctionality. In addition, datasets by nature fail to capture the variance\nintroduced by such ambiguities. Therefore, we propose a deep generative model\nto automatically correct programming errors by learning a distribution of\npotential fixes. Our model is formulated as a deep conditional variational\nautoencoder that samples diverse fixes for the given erroneous programs. In\norder to account for ambiguity and inherent lack of representative datasets, we\npropose a novel regularizer to encourage the model to generate diverse fixes.\nOur evaluations on common programming errors show for the first time the\ngeneration of diverse fixes and strong improvements over the state-of-the-art\napproaches by fixing up to 65% of the mistakes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:28:51 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:11:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hajipour", "Hossein", ""], ["Bhattacharya", "Apratim", ""], ["Fritz", "Mario", ""]]}, {"id": "1906.10509", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Soheil Kolouri, Zak Murez, Yuri Owekcho, Eric Eaton,\n  Kuyngnam Kim", "title": "Zero-Shot Image Classification Using Coupled Dictionary Embedding", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.03688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) is a framework to classify images belonging to\nunseen classes based on solely semantic information about these unseen classes.\nIn this paper, we propose a new ZSL algorithm using coupled dictionary\nlearning. The core idea is that the visual features and the semantic attributes\nof an image can share the same sparse representation in an intermediate space.\nWe use images from seen classes and semantic attributes from seen and unseen\nclasses to learn two dictionaries that can represent sparsely the visual and\nsemantic feature vectors of an image. In the ZSL testing stage and in the\nabsence of labeled data, images from unseen classes can be mapped into the\nattribute space by finding the joint sparse representation using solely the\nvisual data. The image is then classified in the attribute space given semantic\ndescriptions of unseen classes. We also provide an attribute-aware formulation\nto tackle domain shift and hubness problems in ZSL. Extensive experiments are\nprovided to demonstrate the superior performance of our approach against the\nstate of the art ZSL algorithms on benchmark ZSL datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:35:36 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Rostami", "Mohammad", ""], ["Kolouri", "Soheil", ""], ["Murez", "Zak", ""], ["Owekcho", "Yuri", ""], ["Eaton", "Eric", ""], ["Kim", "Kuyngnam", ""]]}, {"id": "1906.10511", "submitter": "Laura Martinus", "authors": "Laura Martinus and Jade Z. Abbott", "title": "Benchmarking Neural Machine Translation for Southern African Languages", "comments": "arXiv admin note: text overlap with arXiv:1906.05685", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unlike major Western languages, most African languages are very\nlow-resourced. Furthermore, the resources that do exist are often scattered and\ndifficult to obtain and discover. As a result, the data and code for existing\nresearch has rarely been shared. This has lead a struggle to reproduce reported\nresults, and few publicly available benchmarks for African machine translation\nmodels exist. To start to address these problems, we trained neural machine\ntranslation models for 5 Southern African languages on publicly-available\ndatasets. Code is provided for training the models and evaluate the models on a\nnewly released evaluation set, with the aim of spur future research in the\nfield for Southern African languages.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:47:28 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Martinus", "Laura", ""], ["Abbott", "Jade Z.", ""]]}, {"id": "1906.10529", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "Jaouad Mourtada and St\\'ephane Ga\\\"iffas and Erwan Scornet", "title": "AMF: Aggregated Mondrian Forests for Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forests (RF) is one of the algorithms of choice in many supervised\nlearning applications, be it classification or regression. The appeal of such\ntree-ensemble methods comes from a combination of several characteristics: a\nremarkable accuracy in a variety of tasks, a small number of parameters to\ntune, robustness with respect to features scaling, a reasonable computational\ncost for training and prediction, and their suitability in high-dimensional\nsettings. The most commonly used RF variants however are \"offline\" algorithms,\nwhich require the availability of the whole dataset at once. In this paper, we\nintroduce AMF, an online random forest algorithm based on Mondrian Forests.\nUsing a variant of the Context Tree Weighting algorithm, we show that it is\npossible to efficiently perform an exact aggregation over all prunings of the\ntrees; in particular, this enables to obtain a truly online parameter-free\nalgorithm which is competitive with the optimal pruning of the Mondrian tree,\nand thus adaptive to the unknown regularity of the regression function.\nNumerical experiments show that AMF is competitive with respect to several\nstrong baselines on a large number of datasets for multi-class classification.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 13:50:22 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:45:45 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mourtada", "Jaouad", ""], ["Ga\u00efffas", "St\u00e9phane", ""], ["Scornet", "Erwan", ""]]}, {"id": "1906.10546", "submitter": "Sihui Luo", "authors": "Sihui Luo, Xinchao Wang, Gongfan Fang, Yao Hu, Dapeng Tao and Mingli\n  Song", "title": "Knowledge Amalgamation from Heterogeneous Networks by Common Feature\n  Learning", "comments": "IJCAI 2019, 7 pages, the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of well-trained deep networks have been released online\nby researchers and developers, enabling the community to reuse them in a\nplug-and-play way without accessing the training annotations. However, due to\nthe large number of network variants, such public-available trained models are\noften of different architectures, each of which being tailored for a specific\ntask or dataset. In this paper, we study a deep-model reusing task, where we\nare given as input pre-trained networks of heterogeneous architectures\nspecializing in distinct tasks, as teacher models. We aim to learn a\nmultitalented and light-weight student model that is able to grasp the\nintegrated knowledge from all such heterogeneous-structure teachers, again\nwithout accessing any human annotation. To this end, we propose a common\nfeature learning scheme, in which the features of all teachers are transformed\ninto a common space and the student is enforced to imitate them all so as to\namalgamate the intact knowledge. We test the proposed approach on a list of\nbenchmarks and demonstrate that the learned student is able to achieve very\npromising performance, superior to those of the teachers in their specialized\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 12:33:24 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Luo", "Sihui", ""], ["Wang", "Xinchao", ""], ["Fang", "Gongfan", ""], ["Hu", "Yao", ""], ["Tao", "Dapeng", ""], ["Song", "Mingli", ""]]}, {"id": "1906.10551", "submitter": "Oren Halvani", "authors": "Oren Halvani, Christian Winter, Lukas Graner", "title": "Assessing the Applicability of Authorship Verification Methods", "comments": "Paper has been accepted for publication in: The 14th International\n  Conference on Availability, Reliability and Security (ARES 2019). arXiv admin\n  note: text overlap with arXiv:1901.00399", "journal-ref": null, "doi": "10.1145/3339252.3340508", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification (AV) is a research subject in the field of digital\ntext forensics that concerns itself with the question, whether two documents\nhave been written by the same person. During the past two decades, an\nincreasing number of proposed AV approaches can be observed. However, a closer\nlook at the respective studies reveals that the underlying characteristics of\nthese methods are rarely addressed, which raises doubts regarding their\napplicability in real forensic settings. The objective of this paper is to fill\nthis gap by proposing clear criteria and properties that aim to improve the\ncharacterization of existing and future AV approaches. Based on these\nproperties, we conduct three experiments using 12 existing AV approaches,\nincluding the current state of the art. The examined methods were trained,\noptimized and evaluated on three self-compiled corpora, where each corpus\nfocuses on a different aspect of applicability. Our results indicate that part\nof the methods are able to cope with very challenging verification cases such\nas 250 characters long informal chat conversations (72.7% accuracy) or cases in\nwhich two scientific documents were written at different times with an average\ndifference of 15.6 years (> 75% accuracy). However, we also identified that all\ninvolved methods are prone to cross-topic verification cases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:44:46 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Halvani", "Oren", ""], ["Winter", "Christian", ""], ["Graner", "Lukas", ""]]}, {"id": "1906.10583", "submitter": "David Cohen-Steiner", "authors": "David Cohen-Steiner and Alba Chiara de Vitis", "title": "Spectral Properties of Radial Kernels and Clustering in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the spectrum and the eigenvectors of radial kernels\nfor mixtures of distributions in $\\mathbb{R}^n$. Our approach focuses on high\ndimensions and relies solely on the concentration properties of the components\nin the mixture. We give several results describing of the structure of kernel\nmatrices for a sample drawn from such a mixture. Based on these results, we\nanalyze the ability of kernel PCA to cluster high dimensional mixtures. In\nparticular, we exhibit a specific kernel leading to a simple spectral algorithm\nfor clustering mixtures with possibly common means but different covariance\nmatrices. We show that the minimum angular separation between the covariance\nmatrices that is required for the algorithm to succeed tends to $0$ as $n$ goes\nto infinity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:01:55 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 15:18:02 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 13:56:06 GMT"}, {"version": "v4", "created": "Mon, 6 Jan 2020 16:31:37 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Cohen-Steiner", "David", ""], ["de Vitis", "Alba Chiara", ""]]}, {"id": "1906.10586", "submitter": "Konstantin Mishchenko", "authors": "Konstantin Mishchenko, Mallory Montgomery, Federico Vaggi", "title": "A Self-supervised Approach to Hierarchical Forecasting with Applications\n  to Groupwise Synthetic Controls", "comments": "ICML Time Series workshop 2019. 6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When forecasting time series with a hierarchical structure, the existing\nstate of the art is to forecast each time series independently, and, in a\npost-treatment step, to reconcile the time series in a way that respects the\nhierarchy (Hyndman et al., 2011; Wickramasuriya et al., 2018). We propose a new\nloss function that can be incorporated into any maximum likelihood objective\nwith hierarchical data, resulting in reconciled estimates with confidence\nintervals that correctly account for additional uncertainty due to imperfect\nreconciliation. We evaluate our method using a non-linear model and synthetic\ndata on a counterfactual forecasting problem, where we have access to the\nground truth and contemporaneous covariates, and show that we largely improve\nover the existing state-of-the-art method.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:05:25 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Mishchenko", "Konstantin", ""], ["Montgomery", "Mallory", ""], ["Vaggi", "Federico", ""]]}, {"id": "1906.10623", "submitter": "Alessandro Lameiras Koerich", "authors": "Juan D. S. Ortega, Patrick Cardinal, Alessandro L. Koerich", "title": "Emotion Recognition Using Fusion of Audio and Video Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a fusion approach to continuous emotion recognition\nthat combines visual and auditory modalities in their representation spaces to\npredict the arousal and valence levels. The proposed approach employs a\npre-trained convolution neural network and transfer learning to extract\nfeatures from video frames that capture the emotional content. For the auditory\ncontent, a minimalistic set of parameters such as prosodic, excitation, vocal\ntract, and spectral descriptors are used as features. The fusion of these two\nmodalities is carried out at a feature level, before training a single support\nvector regressor (SVR) or at a prediction level, after training one SVR for\neach modality. The proposed approach also includes preprocessing and\npost-processing techniques which contribute favorably to improving the\nconcordance correlation coefficient (CCC). Experimental results for predicting\nspontaneous and natural emotions on the RECOLA dataset have shown that the\nproposed approach takes advantage of the complementary information of visual\nand auditory modalities and provides CCCs of 0.749 and 0.565 for arousal and\nvalence, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 16:13:41 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ortega", "Juan D. S.", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "1906.10637", "submitter": "James Chin-Jen Pang", "authors": "James Chin-Jen Pang, Hessam Mahdavifar, and S. Sandeep Pradhan", "title": "Coding for Crowdsourced Classification with XOR Queries", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper models the crowdsourced labeling/classification problem as a\nsparsely encoded source coding problem, where each query answer, regarded as a\ncode bit, is the XOR of a small number of labels, as source information bits.\nIn this paper we leverage the connections between this problem and well-studied\ncodes with sparse representations for the channel coding problem to provide\nquerying schemes with almost optimal number of queries, each of which involving\nonly a constant number of labels. We also extend this scenario to the case\nwhere some workers can be unresponsive. For this case, we propose querying\nschemes where each query involves only log n items, where n is the total number\nof items to be labeled. Furthermore, we consider classification of two\ncorrelated labeling systems and provide two-stage querying schemes with almost\noptimal number of queries each involving a constant number of labels.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 16:27:21 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:28:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Pang", "James Chin-Jen", ""], ["Mahdavifar", "Hessam", ""], ["Pradhan", "S. Sandeep", ""]]}, {"id": "1906.10651", "submitter": "Peter Hase", "authors": "Peter Hase, Chaofan Chen, Oscar Li, Cynthia Rudin", "title": "Interpretable Image Recognition with Hierarchical Prototypes", "comments": "Published as a full paper at HCOMP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision models are interpretable when they classify objects on the basis of\nfeatures that a person can directly understand. Recently, methods relying on\nvisual feature prototypes have been developed for this purpose. However, in\ncontrast to how humans categorize objects, these approaches have not yet made\nuse of any taxonomical organization of class labels. With such an approach, for\ninstance, we may see why a chimpanzee is classified as a chimpanzee, but not\nwhy it was considered to be a primate or even an animal. In this work we\nintroduce a model that uses hierarchically organized prototypes to classify\nobjects at every level in a predefined taxonomy. Hence, we may find distinct\nexplanations for the prediction an image receives at each level of the\ntaxonomy. The hierarchical prototypes enable the model to perform another\nimportant task: interpretably classifying images from previously unseen classes\nat the level of the taxonomy to which they correctly relate, e.g. classifying a\nhand gun as a weapon, when the only weapons in the training data are rifles.\nWith a subset of ImageNet, we test our model against its counterpart black-box\nmodel on two tasks: 1) classification of data from familiar classes, and 2)\nclassification of data from previously unseen classes at the appropriate level\nin the taxonomy. We find that our model performs approximately as well as its\ncounterpart black-box model while allowing for each classification to be\ninterpreted.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 16:45:34 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 00:35:55 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hase", "Peter", ""], ["Chen", "Chaofan", ""], ["Li", "Oscar", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1906.10652", "submitter": "Andriy Mnih", "authors": "Shakir Mohamed and Mihaela Rosca and Michael Figurnov and Andriy Mnih", "title": "Monte Carlo Gradient Estimation in Machine Learning", "comments": "62 pages", "journal-ref": "Journal of Machine Learning Research, 21(132):1-62, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a broad and accessible survey of the methods we have at our\ndisposal for Monte Carlo gradient estimation in machine learning and across the\nstatistical sciences: the problem of computing the gradient of an expectation\nof a function with respect to parameters defining the distribution that is\nintegrated; the problem of sensitivity analysis. In machine learning research,\nthis gradient problem lies at the core of many learning problems, in\nsupervised, unsupervised and reinforcement learning. We will generally seek to\nrewrite such gradients in a form that allows for Monte Carlo estimation,\nallowing them to be easily and efficiently used and analysed. We explore three\nstrategies--the pathwise, score function, and measure-valued gradient\nestimators--exploring their historical development, derivation, and underlying\nassumptions. We describe their use in other fields, show how they are related\nand can be combined, and expand on their possible generalisations. Wherever\nMonte Carlo gradient estimators have been derived and deployed in the past,\nimportant advances have followed. A deeper and more widely-held understanding\nof this problem will lead to further advances, and it is these advances that we\nwish to support.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 16:46:04 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 15:56:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mohamed", "Shakir", ""], ["Rosca", "Mihaela", ""], ["Figurnov", "Michael", ""], ["Mnih", "Andriy", ""]]}, {"id": "1906.10667", "submitter": "Shagun Sodhani", "authors": "Anirudh Goyal, Shagun Sodhani, Jonathan Binas, Xue Bin Peng, Sergey\n  Levine, Yoshua Bengio", "title": "Reinforcement Learning with Competitive Ensembles of\n  Information-Constrained Primitives", "comments": "Preprint, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents that operate in diverse and complex\nenvironments can benefit from the structured decomposition of their behavior.\nOften, this is addressed in the context of hierarchical reinforcement learning,\nwhere the aim is to decompose a policy into lower-level primitives or options,\nand a higher-level meta-policy that triggers the appropriate behaviors for a\ngiven situation. However, the meta-policy must still produce appropriate\ndecisions in all states. In this work, we propose a policy design that\ndecomposes into primitives, similarly to hierarchical reinforcement learning,\nbut without a high-level meta-policy. Instead, each primitive can decide for\nthemselves whether they wish to act in the current state. We use an\ninformation-theoretic mechanism for enabling this decentralized decision: each\nprimitive chooses how much information it needs about the current state to make\na decision and the primitive that requests the most information about the\ncurrent state acts in the world. The primitives are regularized to use as\nlittle information as possible, which leads to natural competition and\nspecialization. We experimentally demonstrate that this policy architecture\nimproves over both flat and hierarchical policies in terms of generalization.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:04:48 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Goyal", "Anirudh", ""], ["Sodhani", "Shagun", ""], ["Binas", "Jonathan", ""], ["Peng", "Xue Bin", ""], ["Levine", "Sergey", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.10669", "submitter": "Erva Ulu", "authors": "Erva Ulu, James McCann, Levent Burak Kara", "title": "Structural Design Using Laplacian Shells", "comments": "Eurographics Symposium on Geometry Processing (SGP) 2019 / Computer\n  Graphics Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to design lightweight shell objects that are\nstructurally robust under the external forces they may experience during use.\nGiven an input 3D model and a general description of the external forces, our\nalgorithm generates a structurally-sound minimum weight shell object. Our\napproach works by altering the local shell thickness repeatedly based on the\nstresses that develop inside the object. A key issue in shell design is that\nlarge thickness values might result in self-intersections on the inner boundary\ncreating a significant computational challenge during optimization. To address\nthis, we propose a shape parametrization based on the solution to the Laplace's\nequation that guarantees smooth and intersection-free shell boundaries.\nCombined with our gradient-free optimization algorithm, our method provides a\npractical solution to the structural design of hollow objects with a single\ninner cavity. We demonstrate our method on a variety of problems with arbitrary\n3D models under complex force configurations and validate its performance with\nphysical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:06:07 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ulu", "Erva", ""], ["McCann", "James", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1906.10670", "submitter": "Gabriel Erion", "authors": "Gabriel Erion, Joseph D. Janizek, Pascal Sturmfels, Scott Lundberg,\n  Su-In Lee", "title": "Improving performance of deep learning models with axiomatic attribution\n  priors and expected gradients", "comments": "Updated after submission to Nature Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has demonstrated that feature attribution methods for deep\nnetworks can themselves be incorporated into training; these attribution priors\noptimize for a model whose attributions have certain desirable properties --\nmost frequently, that particular features are important or unimportant. These\nattribution priors are often based on attribution methods that are not\nguaranteed to satisfy desirable interpretability axioms, such as completeness\nand implementation invariance. Here, we introduce attribution priors to\noptimize for higher-level properties of explanations, such as smoothness and\nsparsity, enabled by a fast new attribution method formulation called expected\ngradients that satisfies many important interpretability axioms. This improves\nmodel performance on many real-world tasks where previous attribution priors\nfail. Our experiments show that the gains from combining higher-level\nattribution priors with expected gradients attributions are consistent across\nimage, gene expression, and health care data sets. We believe this work\nmotivates and provides the necessary tools to support the widespread adoption\nof axiomatic attribution priors in many areas of applied machine learning. The\nimplementations and our results have been made freely available to academic\ncommunities.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:09:34 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:26:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Erion", "Gabriel", ""], ["Janizek", "Joseph D.", ""], ["Sturmfels", "Pascal", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "1906.10671", "submitter": "Jonathan Moore", "authors": "Jonathan Moore, Nils Hammerla, Chris Watkins", "title": "Explaining Deep Learning Models with Constrained Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms generally suffer from a problem of\nexplainability. Given a classification result from a model, it is typically\nhard to determine what caused the decision to be made, and to give an\ninformative explanation. We explore a new method of generating counterfactual\nexplanations, which instead of explaining why a particular classification was\nmade explain how a different outcome can be achieved. This gives the recipients\nof the explanation a better way to understand the outcome, and provides an\nactionable suggestion. We show that the introduced method of Constrained\nAdversarial Examples (CADEX) can be used in real world applications, and yields\nexplanations which incorporate business or domain constraints such as handling\ncategorical attributes and range constraints.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:09:43 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Moore", "Jonathan", ""], ["Hammerla", "Nils", ""], ["Watkins", "Chris", ""]]}, {"id": "1906.10673", "submitter": "Michele Donini", "authors": "Luca Oneto, Michele Donini, Andreas Maurer, Massimiliano Pontil", "title": "Learning Fair and Transferable Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing learning methods which do not discriminate subgroups in the\npopulation is a central goal of algorithmic fairness. One way to reach this\ngoal is by modifying the data representation in order to meet certain fairness\nconstraints. In this work we measure fairness according to demographic parity.\nThis requires the probability of the possible model decisions to be independent\nof the sensitive information. We argue that the goal of imposing demographic\nparity can be substantially facilitated within a multitask learning setting. We\nleverage task similarities by encouraging a shared fair representation across\nthe tasks via low rank matrix factorization. We derive learning bounds\nestablishing that the learned representation transfers well to novel tasks both\nin terms of prediction performance and fairness metrics. We present experiments\non three real world datasets, showing that the proposed method outperforms\nstate-of-the-art approaches by a significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:18:08 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 15:57:57 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 07:49:40 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Oneto", "Luca", ""], ["Donini", "Michele", ""], ["Maurer", "Andreas", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1906.10717", "submitter": "Kenneth Tran", "authors": "Tung-Long Vuong and Kenneth Tran", "title": "Uncertainty-aware Model-based Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning has the potential to be more sample\nefficient than model-free approaches. However, existing model-based methods are\nvulnerable to model bias, which leads to poor generalization and asymptotic\nperformance compared to model-free counterparts. In addition, they are\ntypically based on the model predictive control (MPC) framework, which not only\nis computationally inefficient at decision time but also does not enable policy\ntransfer due to the lack of an explicit policy representation. In this paper,\nwe propose a novel uncertainty-aware model-based policy optimization framework\nwhich solves those issues. In this framework, the agent simultaneously learns\nan uncertainty-aware dynamics model and optimizes the policy according to these\nlearned models. In the optimization step, the policy gradient is computed by\nautomatic differentiation through the models. With respect to sample efficiency\nalone, our approach shows promising results on challenging continuous control\nbenchmarks with competitive asymptotic performance and significantly lower\nsample complexity than state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:25:20 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Vuong", "Tung-Long", ""], ["Tran", "Kenneth", ""]]}, {"id": "1906.10720", "submitter": "Niru Maheswaranathan", "authors": "Niru Maheswaranathan, Alex Williams, Matthew D. Golub, Surya Ganguli,\n  David Sussillo", "title": "Reverse engineering recurrent networks for sentiment classification\n  reveals line attractor dynamics", "comments": "Presented at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a widely used tool for modeling\nsequential data, yet they are often treated as inscrutable black boxes. Given a\ntrained recurrent network, we would like to reverse engineer it--to obtain a\nquantitative, interpretable description of how it solves a particular task.\nEven for simple tasks, a detailed understanding of how recurrent networks work,\nor a prescription for how to develop such an understanding, remains elusive. In\nthis work, we use tools from dynamical systems analysis to reverse engineer\nrecurrent networks trained to perform sentiment classification, a foundational\nnatural language processing task. Given a trained network, we find fixed points\nof the recurrent dynamics and linearize the nonlinear system around these fixed\npoints. Despite their theoretical capacity to implement complex,\nhigh-dimensional computations, we find that trained networks converge to highly\ninterpretable, low-dimensional representations. In particular, the topological\nstructure of the fixed points and corresponding linearized dynamics reveal an\napproximate line attractor within the RNN, which we can use to quantitatively\nunderstand how the RNN solves the sentiment analysis task. Finally, we find\nthis mechanism present across RNN architectures (including LSTMs, GRUs, and\nvanilla RNNs) trained on multiple datasets, suggesting that our findings are\nnot unique to a particular architecture or dataset. Overall, these results\ndemonstrate that surprisingly universal and human interpretable computations\ncan arise across a range of recurrent networks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:42:25 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 20:51:14 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Maheswaranathan", "Niru", ""], ["Williams", "Alex", ""], ["Golub", "Matthew D.", ""], ["Ganguli", "Surya", ""], ["Sussillo", "David", ""]]}, {"id": "1906.10725", "submitter": "Andres Felipe Duque Correa", "authors": "Andr\\'es F. Duque, Guy Wolf, Kevin R. Moon", "title": "Visualizing High Dimensional Dynamical Processes", "comments": "7 pages, 3 figures", "journal-ref": "IEEE International Workshop on Machine Learning for Signal\n  Processing, Oct. 2019", "doi": "10.1109/MLSP.2019.8918875", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning techniques for dynamical systems and time series have shown\ntheir utility for a broad spectrum of applications in recent years. While these\nmethods are effective at learning a low-dimensional representation, they are\noften insufficient for visualizing the global and local structure of the data.\nIn this paper, we present DIG (Dynamical Information Geometry), a visualization\nmethod for multivariate time series data that extracts an information geometry\nfrom a diffusion framework. Specifically, we implement a novel group of\ndistances in the context of diffusion operators, which may be useful to reveal\nstructure in the data that may not be accessible by the commonly used diffusion\ndistances. Finally, we present a case study applying our visualization tool to\nEEG data to visualize sleep stages.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 19:02:21 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Duque", "Andr\u00e9s F.", ""], ["Wolf", "Guy", ""], ["Moon", "Kevin R.", ""]]}, {"id": "1906.10732", "submitter": "Utku Evci", "authors": "Utku Evci, Fabian Pedregosa, Aidan Gomez, Erich Elsen", "title": "The Difficulty of Training Sparse Neural Networks", "comments": "sparse networks, pruning, energy landscape, sparsity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the difficulties of training sparse neural networks and make\nnew observations about optimization dynamics and the energy landscape within\nthe sparse regime. Recent work of \\citep{Gale2019, Liu2018} has shown that\nsparse ResNet-50 architectures trained on ImageNet-2012 dataset converge to\nsolutions that are significantly worse than those found by pruning. We show\nthat, despite the failure of optimizers, there is a linear path with a\nmonotonically decreasing objective from the initialization to the \"good\"\nsolution. Additionally, our attempts to find a decreasing objective path from\n\"bad\" solutions to the \"good\" ones in the sparse subspace fail. However, if we\nallow the path to traverse the dense subspace, then we consistently find a path\nbetween two solutions. These findings suggest traversing extra dimensions may\nbe needed to escape stationary points found in the sparse subspace.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 19:21:15 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 19:38:25 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 17:38:07 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Evci", "Utku", ""], ["Pedregosa", "Fabian", ""], ["Gomez", "Aidan", ""], ["Elsen", "Erich", ""]]}, {"id": "1906.10742", "submitter": "Jie Zhang", "authors": "Jie M. Zhang (1), Mark Harman (1 and 2), Lei Ma (3), Yang Liu (4) ((1)\n  University College London, (2) Facebook London, (3) Kyushu University, (4)\n  Nanyang Technological University)", "title": "Machine Learning Testing: Survey, Landscapes and Horizons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a comprehensive survey of Machine Learning Testing (ML\ntesting) research. It covers 144 papers on testing properties (e.g.,\ncorrectness, robustness, and fairness), testing components (e.g., the data,\nlearning program, and framework), testing workflow (e.g., test generation and\ntest evaluation), and application scenarios (e.g., autonomous driving, machine\ntranslation). The paper also analyses trends concerning datasets, research\ntrends, and research focus, concluding with research challenges and promising\nresearch directions in ML testing.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:39:19 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 23:12:23 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Zhang", "Jie M.", "", "1 and 2"], ["Harman", "Mark", "", "1 and 2"], ["Ma", "Lei", ""], ["Liu", "Yang", ""]]}, {"id": "1906.10771", "submitter": "Pavlo Molchanov", "authors": "Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, Jan Kautz", "title": "Importance Estimation for Neural Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural pruning of neural network parameters reduces computation, energy,\nand memory transfer costs during inference. We propose a novel method that\nestimates the contribution of a neuron (filter) to the final loss and\niteratively removes those with smaller scores. We describe two variations of\nour method using the first and second-order Taylor expansions to approximate a\nfilter's contribution. Both methods scale consistently across any network layer\nwithout requiring per-layer sensitivity analysis and can be applied to any kind\nof layer, including skip connections. For modern networks trained on ImageNet,\nwe measured experimentally a high (>93%) correlation between the contribution\ncomputed by our methods and a reliable estimate of the true importance. Pruning\nwith the proposed methods leads to an improvement over state-of-the-art in\nterms of accuracy, FLOPs, and parameter reduction. On ResNet-101, we achieve a\n40% FLOPS reduction by removing 30% of the parameters, with a loss of 0.02% in\nthe top-1 accuracy on ImageNet. Code is available at\nhttps://github.com/NVlabs/Taylor_pruning.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 22:20:16 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Molchanov", "Pavlo", ""], ["Mallya", "Arun", ""], ["Tyree", "Stephen", ""], ["Frosio", "Iuri", ""], ["Kautz", "Jan", ""]]}, {"id": "1906.10773", "submitter": "Kang Liu", "authors": "Kang Liu, Haoyu Yang, Yuzhe Ma, Benjamin Tan, Bei Yu, Evangeline F. Y.\n  Young, Ramesh Karri, Siddharth Garg", "title": "Are Adversarial Perturbations a Showstopper for ML-Based CAD? A Case\n  Study on CNN-Based Lithographic Hotspot Detection", "comments": null, "journal-ref": "ACM Trans. Des. Autom. Electron. Syst. 25, 5, Article 48 (August\n  2020)", "doi": "10.1145/3408288", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is substantial interest in the use of machine learning (ML) based\ntechniques throughout the electronic computer-aided design (CAD) flow,\nparticularly those based on deep learning. However, while deep learning methods\nhave surpassed state-of-the-art performance in several applications, they have\nexhibited intrinsic susceptibility to adversarial perturbations --- small but\ndeliberate alterations to the input of a neural network, precipitating\nincorrect predictions. In this paper, we seek to investigate whether\nadversarial perturbations pose risks to ML-based CAD tools, and if so, how\nthese risks can be mitigated. To this end, we use a motivating case study of\nlithographic hotspot detection, for which convolutional neural networks (CNN)\nhave shown great promise. In this context, we show the first adversarial\nperturbation attacks on state-of-the-art CNN-based hotspot detectors;\nspecifically, we show that small (on average 0.5% modified area), functionality\npreserving and design-constraint satisfying changes to a layout can nonetheless\ntrick a CNN-based hotspot detector into predicting the modified layout as\nhotspot free (with up to 99.7% success). We propose an adversarial retraining\nstrategy to improve the robustness of CNN-based hotspot detection and show that\nthis strategy significantly improves robustness (by a factor of ~3) against\nadversarial attacks without compromising classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 22:37:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Liu", "Kang", ""], ["Yang", "Haoyu", ""], ["Ma", "Yuzhe", ""], ["Tan", "Benjamin", ""], ["Yu", "Bei", ""], ["Young", "Evangeline F. Y.", ""], ["Karri", "Ramesh", ""], ["Garg", "Siddharth", ""]]}, {"id": "1906.10780", "submitter": "Khurram Javed Mr", "authors": "Samuel Sokota, Ryan D'Orazio, Khurram Javed, Humza Haider, Russell\n  Greiner", "title": "Simultaneous Prediction Intervals for Patient-Specific Survival Curves", "comments": "7 pages, 7 figures, IJCAI 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate models of patient survival probabilities provide important\ninformation to clinicians prescribing care for life-threatening and terminal\nailments. A recently developed class of models - known as individual survival\ndistributions (ISDs) - produces patient-specific survival functions that offer\ngreater descriptive power of patient outcomes than was previously possible.\nUnfortunately, at the time of writing, ISD models almost universally lack\nuncertainty quantification. In this paper, we demonstrate that an existing\nmethod for estimating simultaneous prediction intervals from samples can easily\nbe adapted for patient-specific survival curve analysis and yields accurate\nresults. Furthermore, we introduce both a modification to the existing method\nand a novel method for estimating simultaneous prediction intervals and show\nthat they offer competitive performance. It is worth emphasizing that these\nmethods are not limited to survival analysis and can be applied in any context\nin which sampling the distribution of interest is tractable. Code is available\nat https://github.com/ssokota/spie .\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 23:03:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Sokota", "Samuel", ""], ["D'Orazio", "Ryan", ""], ["Javed", "Khurram", ""], ["Haider", "Humza", ""], ["Greiner", "Russell", ""]]}, {"id": "1906.10816", "submitter": "Oleksandr Polozov", "authors": "Richard Shin, Miltiadis Allamanis, Marc Brockschmidt, Oleksandr\n  Polozov", "title": "Program Synthesis and Semantic Parsing with Learned Code Idioms", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS)\n  2019. 13 pages total, 9 pages of main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis of general-purpose source code from natural language\nspecifications is challenging due to the need to reason about high-level\npatterns in the target program and low-level implementation details at the same\ntime. In this work, we present PATOIS, a system that allows a neural program\nsynthesizer to explicitly interleave high-level and low-level reasoning at\nevery generation step. It accomplishes this by automatically mining common code\nidioms from a given corpus, incorporating them into the underlying language for\nneural synthesis, and training a tree-based neural synthesizer to use these\nidioms during code generation. We evaluate PATOIS on two complex semantic\nparsing datasets and show that using learned code idioms improves the\nsynthesizer's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:28:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 21:58:59 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 01:28:05 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 02:44:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shin", "Richard", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Polozov", "Oleksandr", ""]]}, {"id": "1906.10822", "submitter": "Kosuke Haruki", "authors": "Kosuke Haruki, Taiji Suzuki, Yohei Hamakawa, Takeshi Toda, Ryuji\n  Sakai, Masahiro Ozawa, Mitsuhiro Kimura", "title": "Gradient Noise Convolution (GNC): Smoothing Loss Function for\n  Distributed Large-Batch SGD", "comments": "19 pages, 11 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-batch stochastic gradient descent (SGD) is widely used for training in\ndistributed deep learning because of its training-time efficiency, however,\nextremely large-batch SGD leads to poor generalization and easily converges to\nsharp minima, which prevents naive large-scale data-parallel SGD (DP-SGD) from\nconverging to good minima. To overcome this difficulty, we propose gradient\nnoise convolution (GNC), which effectively smooths sharper minima of the loss\nfunction. For DP-SGD, GNC utilizes so-called gradient noise, which is induced\nby stochastic gradient variation and convolved to the loss function as a\nsmoothing effect. GNC computation can be performed by simply computing the\nstochastic gradient on each parallel worker and merging them, and is therefore\nextremely easy to implement. Due to convolving with the gradient noise, which\ntends to spread along a sharper direction of the loss function, GNC can\neffectively smooth sharp minima and achieve better generalization, whereas\nisotropic random noise cannot. We empirically show this effect by comparing GNC\nwith isotropic random noise, and show that it achieves state-of-the-art\ngeneralization performance for large-scale deep neural network optimization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:54:26 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Haruki", "Kosuke", ""], ["Suzuki", "Taiji", ""], ["Hamakawa", "Yohei", ""], ["Toda", "Takeshi", ""], ["Sakai", "Ryuji", ""], ["Ozawa", "Masahiro", ""], ["Kimura", "Mitsuhiro", ""]]}, {"id": "1906.10827", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Sebastian Claici, Edward Chien, Farzaneh Mirzazadeh\n  and Justin Solomon", "title": "Hierarchical Optimal Transport for Document Representation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to measure similarity between documents enables intelligent\nsummarization and analysis of large corpora. Past distances between documents\nsuffer from either an inability to incorporate semantic similarities between\nwords or from scalability issues. As an alternative, we introduce hierarchical\noptimal transport as a meta-distance between documents, where documents are\nmodeled as distributions over topics, which themselves are modeled as\ndistributions over words. We then solve an optimal transport problem on the\nsmaller topic space to compute a similarity score. We give conditions on the\ntopics under which this construction defines a distance, and we relate it to\nthe word mover's distance. We evaluate our technique for k-NN classification\nand show better interpretability and scalability with comparable performance to\ncurrent methods at a fraction of the cost.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 03:26:23 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 22:07:08 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Claici", "Sebastian", ""], ["Chien", "Edward", ""], ["Mirzazadeh", "Farzaneh", ""], ["Solomon", "Justin", ""]]}, {"id": "1906.10845", "submitter": "Yu Wang", "authors": "Xiao Li, Yu Wang, Sumanta Basu, Karl Kumbier, Bin Yu", "title": "A Debiased MDI Feature Importance Measure for Random Forests", "comments": "NeurIPS'19. The first two authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree ensembles such as Random Forests have achieved impressive empirical\nsuccess across a wide variety of applications. To understand how these models\nmake predictions, people routinely turn to feature importance measures\ncalculated from tree ensembles. It has long been known that Mean Decrease\nImpurity (MDI), one of the most widely used measures of feature importance,\nincorrectly assigns high importance to noisy features, leading to systematic\nbias in feature selection. In this paper, we address the feature selection bias\nof MDI from both theoretical and methodological perspectives. Based on the\noriginal definition of MDI by Breiman et al. for a single tree, we derive a\ntight non-asymptotic bound on the expected bias of MDI importance of noisy\nfeatures, showing that deep trees have higher (expected) feature selection bias\nthan shallow ones. However, it is not clear how to reduce the bias of MDI using\nits existing analytical expression. We derive a new analytical expression for\nMDI, and based on this new expression, we are able to propose a debiased MDI\nfeature importance measure using out-of-bag samples, called MDI-oob. For both\nthe simulated data and a genomic ChIP dataset, MDI-oob achieves\nstate-of-the-art performance in feature selection from Random Forests for both\ndeep and shallow trees.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 04:51:52 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 06:35:31 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Li", "Xiao", ""], ["Wang", "Yu", ""], ["Basu", "Sumanta", ""], ["Kumbier", "Karl", ""], ["Yu", "Bin", ""]]}, {"id": "1906.10851", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Guanghui Wang, Wei-Wei Tu, Zhi-Hua Zhou", "title": "Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive\n  Regret of Convex Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with changing environments, a new performance measure -- adaptive\nregret, defined as the maximum static regret over any interval, was proposed in\nonline learning. Under the setting of online convex optimization, several\nalgorithms have been successfully developed to minimize the adaptive regret.\nHowever, existing algorithms lack universality in the sense that they can only\nhandle one type of convex functions and need apriori knowledge of parameters.\nBy contrast, there exist universal algorithms, such as MetaGrad, that attain\noptimal static regret for multiple types of convex functions simultaneously.\nAlong this line of research, this paper presents the first universal algorithm\nfor minimizing the adaptive regret of convex functions. Specifically, we borrow\nthe idea of maintaining multiple learning rates in MetaGrad to handle the\nuncertainty of functions, and utilize the technique of sleeping experts to\ncapture changing environments. In this way, our algorithm automatically adapts\nto the property of functions (convex, exponentially concave, or strongly\nconvex), as well as the nature of environments (stationary or changing). As a\nby product, it also allows the type of functions to switch between rounds.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 05:23:26 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 13:13:16 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zhang", "Lijun", ""], ["Wang", "Guanghui", ""], ["Tu", "Wei-Wei", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1906.10897", "submitter": "Yao Xu", "authors": "Yao Xu, Xueshuang Xiang, Meiyu Huang", "title": "Task-Driven Common Representation Learning via Bridge Neural Network", "comments": "To appear in AAAI-19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel deep learning based method, named bridge neural\nnetwork (BNN) to dig the potential relationship between two given data sources\ntask by task. The proposed approach employs two convolutional neural networks\nthat project the two data sources into a feature space to learn the desired\ncommon representation required by the specific task. The training objective\nwith artificial negative samples is introduced with the ability of mini-batch\ntraining and it's asymptotically equivalent to maximizing the total correlation\nof the two data sources, which is verified by the theoretical analysis. The\nexperiments on the tasks, including pair matching, canonical correlation\nanalysis, transfer learning, and reconstruction demonstrate the\nstate-of-the-art performance of BNN, which may provide new insights into the\naspect of common representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:55:53 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Xu", "Yao", ""], ["Xiang", "Xueshuang", ""], ["Huang", "Meiyu", ""]]}, {"id": "1906.10908", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz", "title": "Prediction Poisoning: Towards Defenses Against DNN Model Stealing\n  Attacks", "comments": "ICLR 2020, Project page:\n  https://resources.mpi-inf.mpg.de/d2/orekondy/predpoison/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-performance Deep Neural Networks (DNNs) are increasingly deployed in\nmany real-world applications e.g., cloud prediction APIs. Recent advances in\nmodel functionality stealing attacks via black-box access (i.e., inputs in,\npredictions out) threaten the business model of such applications, which\nrequire a lot of time, money, and effort to develop. Existing defenses take a\npassive role against stealing attacks, such as by truncating predicted\ninformation. We find such passive defenses ineffective against DNN stealing\nattacks. In this paper, we propose the first defense which actively perturbs\npredictions targeted at poisoning the training objective of the attacker. We\nfind our defense effective across a wide range of challenging datasets and DNN\nmodel stealing attacks, and additionally outperforms existing defenses. Our\ndefense is the first that can withstand highly accurate model stealing attacks\nfor tens of thousands of queries, amplifying the attacker's error rate up to a\nfactor of 85$\\times$ with minimal impact on the utility for benign users.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:32:37 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 10:51:12 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1906.10910", "submitter": "Youngnam Lee", "authors": "Youngnam Lee, Youngduck Choi, Junghyun Cho, Alexander R. Fabbri,\n  Hyunbin Loh, Chanyou Hwang, Yongku Lee, Sang-Wook Kim, Dragomir Radev", "title": "Creating A Neural Pedagogical Agent by Jointly Learning to Review and\n  Assess", "comments": "9 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays an increasing role in intelligent tutoring systems as\nboth the amount of data available and specialization among students grow.\nNowadays, these systems are frequently deployed on mobile applications. Users\non such mobile education platforms are dynamic, frequently being added,\naccessing the application with varying levels of focus, and changing while\nusing the service. The education material itself, on the other hand, is often\nstatic and is an exhaustible resource whose use in tasks such as problem\nrecommendation must be optimized. The ability to update user models with\nrespect to educational material in real-time is thus essential; however,\nexisting approaches require time-consuming re-training of user features\nwhenever new data is added. In this paper, we introduce a neural pedagogical\nagent for real-time user modeling in the task of predicting user response\ncorrectness, a central task for mobile education applications. Our model,\ninspired by work in natural language processing on sequence modeling and\nmachine translation, updates user features in real-time via bidirectional\nrecurrent neural networks with an attention mechanism over embedded\nquestion-response pairs. We experiment on the mobile education application\nSantaTOEIC, which has 559k users, 66M response data points as well as a set of\n10k study problems each expert-annotated with topic tags and gathered since\n2016. Our model outperforms existing approaches over several metrics in\npredicting user response correctness, notably out-performing other methods on\nnew users without large question-response histories. Additionally, our\nattention mechanism and annotated tag set allow us to create an interpretable\neducation platform, with a smart review system that addresses the\naforementioned issue of varied user attention and problem exhaustion.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:37:44 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:03:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lee", "Youngnam", ""], ["Choi", "Youngduck", ""], ["Cho", "Junghyun", ""], ["Fabbri", "Alexander R.", ""], ["Loh", "Hyunbin", ""], ["Hwang", "Chanyou", ""], ["Lee", "Yongku", ""], ["Kim", "Sang-Wook", ""], ["Radev", "Dragomir", ""]]}, {"id": "1906.10921", "submitter": "Azadeh Khaleghi", "authors": "Azadeh Khaleghi and Daniil Ryabko", "title": "Clustering piecewise stationary processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of time-series clustering is considered in the case where each\ndata-point is a sample generated by a piecewise stationary ergodic process.\nStationary processes are perhaps the most general class of processes considered\nin non-parametric statistics and allow for arbitrary long-range dependence\nbetween variables. Piecewise stationary processes studied here for the first\ntime in the context of clustering, relax the last remaining assumption in this\nmodel: stationarity. A natural formulation is proposed for this problem and a\nnotion of consistency is introduced which requires the samples to be placed in\nthe same cluster if and only if the piecewise stationary distributions that\ngenerate them have the same set of stationary distributions. Simple,\ncomputationally efficient algorithms are proposed and are shown to be\nconsistent without any additional assumptions beyond piecewise stationarity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:01:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Khaleghi", "Azadeh", ""], ["Ryabko", "Daniil", ""]]}, {"id": "1906.10935", "submitter": "Feng Pan", "authors": "Feng Pan, Pengfei Zhou, Hai-Jun Zhou, Pan Zhang", "title": "Solving Statistical Mechanics on Sparse Graphs with Feedback Set\n  Variational Autoregressive Networks", "comments": "13 pages, 5 figures", "journal-ref": "Phys. Rev. E 103, 012103 (2021)", "doi": "10.1103/PhysRevE.103.012103", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for solving statistical mechanics problems defined on\nsparse graphs. It extracts a small Feedback Vertex Set (FVS) from the sparse\ngraph, converting the sparse system to a much smaller system with many-body and\ndense interactions with an effective energy on every configuration of the FVS,\nthen learns a variational distribution parameterized using neural networks to\napproximate the original Boltzmann distribution. The method is able to estimate\nfree energy, compute observables, and generate unbiased samples via direct\nsampling without auto-correlation. Extensive experiments show that our approach\nis more accurate than existing approaches for sparse spin glasses. On random\ngraphs and real-world networks, our approach significantly outperforms the\nstandard methods for sparse systems such as the belief-propagation algorithm;\non structured sparse systems such as two-dimensional lattices our approach is\nsignificantly faster and more accurate than recently proposed variational\nautoregressive networks using convolution neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:33:18 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 07:29:58 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Pan", "Feng", ""], ["Zhou", "Pengfei", ""], ["Zhou", "Hai-Jun", ""], ["Zhang", "Pan", ""]]}, {"id": "1906.10948", "submitter": "Pan Li", "authors": "Pan Li, Alexander Tuzhilin", "title": "Latent Multi-Criteria Ratings for Recommendations", "comments": "Accepted to RecSys19'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-criteria recommender systems have been increasingly valuable for\nhelping consumers identify the most relevant items based on different\ndimensions of user experiences. However, previously proposed multi-criteria\nmodels did not take into account latent embeddings generated from user reviews,\nwhich capture latent semantic relations between users and items. To address\nthese concerns, we utilize variational autoencoders to map user reviews into\nlatent embeddings, which are subsequently compressed into low-dimensional\ndiscrete vectors. The resulting compressed vectors constitute latent\nmulti-criteria ratings that we use for the recommendation purposes via standard\nmulti-criteria recommendation methods. We show that the proposed latent\nmulti-criteria rating approach outperforms several baselines significantly and\nconsistently across different datasets and performance evaluation measures.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 10:10:07 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Li", "Pan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "1906.10973", "submitter": "Yifeng Li", "authors": "Yifeng Li, Lingxi Xie, Ya Zhang, Rui Zhang, Yanfeng Wang, Qi Tian", "title": "Defending Adversarial Attacks by Correcting logits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating and eliminating adversarial examples has been an intriguing topic\nin the field of deep learning. While previous research verified that\nadversarial attacks are often fragile and can be defended via image-level\nprocessing, it remains unclear how high-level features are perturbed by such\nattacks. We investigate this issue from a new perspective, which purely relies\non logits, the class scores before softmax, to detect and defend adversarial\nattacks. Our defender is a two-layer network trained on a mixed set of clean\nand perturbed logits, with the goal being recovering the original prediction.\nUpon a wide range of adversarial attacks, our simple approach shows promising\nresults with relatively high accuracy in defense, and the defender can transfer\nacross attackers with similar properties. More importantly, our defender can\nwork in the scenarios that image data are unavailable, and enjoys high\ninterpretability especially at the semantic level.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:07:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Li", "Yifeng", ""], ["Xie", "Lingxi", ""], ["Zhang", "Ya", ""], ["Zhang", "Rui", ""], ["Wang", "Yanfeng", ""], ["Tian", "Qi", ""]]}, {"id": "1906.10981", "submitter": "Qiyu Kang", "authors": "Qiyu Kang and Wee Peng Tay", "title": "Learning Orthogonal Projections in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a linear stochastic bandit model, each arm is a vector in an Euclidean\nspace and the observed return at each time step is an unknown linear function\nof the chosen arm at that time step. In this paper, we investigate the problem\nof learning the best arm in a linear stochastic bandit model, where each arm's\nexpected reward is an unknown linear function of the projection of the arm onto\na subspace. We call this the projection reward. Unlike the classical linear\nbandit problem in which the observed return corresponds to the reward, the\nprojection reward at each time step is unobservable. Such a model is useful in\nrecommendation applications where the observed return includes corruption by\neach individual's biases, which we wish to exclude in the learned model. In the\ncase where there are finitely many arms, we develop a strategy to achieve\n$O(|\\bbD|\\log n)$ regret, where $n$ is the number of time steps and $|\\bbD|$ is\nthe number of arms. In the case where each arm is chosen from an infinite\ncompact set, our strategy achieves $O(n^{2/3}(\\log{n})^{1/2})$ regret.\nExperiments verify the efficiency of our strategy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:25:19 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 19:49:10 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 09:38:41 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kang", "Qiyu", ""], ["Tay", "Wee Peng", ""]]}, {"id": "1906.10991", "submitter": "Yaniv Saar", "authors": "Gil Einziger, Maayan Goldstein, Yaniv Sa'ar, Itai Segall", "title": "Verifying Robustness of Gradient Boosted Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted models are a fundamental machine learning technique.\nRobustness to small perturbations of the input is an important quality measure\nfor machine learning models, but the literature lacks a method to prove the\nrobustness of gradient boosted models. This work introduces VeriGB, a tool for\nquantifying the robustness of gradient boosted models. VeriGB encodes the model\nand the robustness property as an SMT formula, which enables state of the art\nverification tools to prove the model's robustness. We extensively evaluate\nVeriGB on publicly available datasets and demonstrate a capability for\nverifying large models. Finally, we show that some model configurations tend to\nbe inherently more robust than others.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:48:58 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Einziger", "Gil", ""], ["Goldstein", "Maayan", ""], ["Sa'ar", "Yaniv", ""], ["Segall", "Itai", ""]]}, {"id": "1906.11043", "submitter": "Anne Sabourin", "authors": "Holger Drees, Anne Sabourin (LTCI)", "title": "Principal Component Analysis for Multivariate Extremes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first order behavior of multivariate heavy-tailed random vectors above\nlarge radial thresholds is ruled by a limit measure in a regular variation\nframework. For a high dimensional vector, a reasonable assumption is that the\nsupport of this measure is concentrated on a lower dimensional subspace,\nmeaning that certain linear combinations of the components are much likelier to\nbe large than others. Identifying this subspace and thus reducing the dimension\nwill facilitate a refined statistical analysis. In this work we apply Principal\nComponent Analysis (PCA) to a re-scaled version of radially thresholded\nobservations. Within the statistical learning framework of empirical risk\nminimization, our main focus is to analyze the squared reconstruction error for\nthe exceedances over large radial thresholds. We prove that the empirical risk\nconverges to the true risk, uniformly over all projection subspaces. As a\nconsequence, the best projection subspace is shown to converge in probability\nto the optimal one, in terms of the Hausdorff distance between their\nintersections with the unit sphere. In addition, if the exceedances are\nre-scaled to the unit ball, we obtain finite sample uniform guarantees to the\nreconstruction error pertaining to the estimated projection sub-space.\nNumerical experiments illustrate the relevance of the proposed framework for\npractical purposes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:44:54 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Drees", "Holger", "", "LTCI"], ["Sabourin", "Anne", "", "LTCI"]]}, {"id": "1906.11046", "submitter": "Wenhang Bao", "authors": "Wenhang Bao, Xiao-yang Liu", "title": "Multi-Agent Deep Reinforcement Learning for Liquidation Strategy\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquidation is the process of selling a large number of shares of one stock\nsequentially within a given time frame, taking into consideration the costs\narising from market impact and a trader's risk aversion. The main challenge in\noptimizing liquidation is to find an appropriate modeling system that can\nincorporate the complexities of the stock market and generate practical trading\nstrategies. In this paper, we propose to use multi-agent deep reinforcement\nlearning model, which better captures high-level complexities comparing to\nvarious machine learning methods, such that agents can learn how to make the\nbest selling decisions. First, we theoretically analyze the Almgren and Chriss\nmodel and extend its fundamental mechanism so it can be used as the multi-agent\ntrading environment. Our work builds the foundation for future multi-agent\nenvironment trading analysis. Secondly, we analyze the cooperative and\ncompetitive behaviours between agents by adjusting the reward functions for\neach agent, which overcomes the limitation of single-agent reinforcement\nlearning algorithms. Finally, we simulate trading and develop an optimal\ntrading strategy with practical constraints by using a reinforcement learning\nmethod, which shows the capabilities of reinforcement learning methods in\nsolving realistic liquidation problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 20:22:46 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Bao", "Wenhang", ""], ["Liu", "Xiao-yang", ""]]}, {"id": "1906.11047", "submitter": "Patrick von Platen", "authors": "Patrick von Platen, Chao Zhang, Philip Woodland", "title": "Multi-Span Acoustic Modelling using Raw Waveform Signals", "comments": "To appear in INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-2454", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional automatic speech recognition (ASR) systems often use an acoustic\nmodel (AM) built on handcrafted acoustic features, such as log Mel-filter bank\n(FBANK) values. Recent studies found that AMs with convolutional neural\nnetworks (CNNs) can directly use the raw waveform signal as input. Given\nsufficient training data, these AMs can yield a competitive word error rate\n(WER) to those built on FBANK features. This paper proposes a novel multi-span\nstructure for acoustic modelling based on the raw waveform with multiple\nstreams of CNN input layers, each processing a different span of the raw\nwaveform signal. Evaluation on both the single channel CHiME4 and AMI data sets\nshow that multi-span AMs give a lower WER than FBANK AMs by an average of about\n5% (relative). Analysis of the trained multi-span model reveals that the CNNs\ncan learn filters that are rather different to the log Mel filters.\nFurthermore, the paper shows that a widely used single span raw waveform AM can\nbe improved by using a smaller CNN kernel size and increased stride to yield\nimproved WERs.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 06:06:00 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 17:13:02 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["von Platen", "Patrick", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip", ""]]}, {"id": "1906.11058", "submitter": "Long Yang", "authors": "Long Yang, Yu Zhang, Jun Wen, Qian Zheng, Pengfei Li, Gang Pan", "title": "Expected Sarsa($\\lambda$) with Control Variate for Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning is powerful for reinforcement learning. However, the high\nvariance of off-policy evaluation is a critical challenge, which causes\noff-policy learning falls into an uncontrolled instability. In this paper, for\nreducing the variance, we introduce control variate technique to\n$\\mathtt{Expected}$ $\\mathtt{Sarsa}$($\\lambda$) and propose a tabular\n$\\mathtt{ES}$($\\lambda$)-$\\mathtt{CV}$ algorithm. We prove that if a proper\nestimator of value function reaches, the proposed\n$\\mathtt{ES}$($\\lambda$)-$\\mathtt{CV}$ enjoys a lower variance than\n$\\mathtt{Expected}$ $\\mathtt{Sarsa}$($\\lambda$). Furthermore, to extend\n$\\mathtt{ES}$($\\lambda$)-$\\mathtt{CV}$ to be a convergent algorithm with linear\nfunction approximation, we propose the $\\mathtt{GES}$($\\lambda$) algorithm\nunder the convex-concave saddle-point formulation. We prove that the\nconvergence rate of $\\mathtt{GES}$($\\lambda$) achieves $\\mathcal{O}(1/T)$,\nwhich matches or outperforms lots of state-of-art gradient-based algorithms,\nbut we use a more relaxed condition. Numerical experiments show that the\nproposed algorithm performs better with lower variance than several\nstate-of-art gradient-based TD learning algorithms: $\\mathtt{GQ}$($\\lambda$),\n$\\mathtt{GTB}$($\\lambda$) and $\\mathtt{ABQ}$($\\zeta$).\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 11:35:44 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:38:02 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yang", "Long", ""], ["Zhang", "Yu", ""], ["Wen", "Jun", ""], ["Zheng", "Qian", ""], ["Li", "Pengfei", ""], ["Pan", "Gang", ""]]}, {"id": "1906.11080", "submitter": "Jun Huan", "authors": "Hanchao Wang and Jun Huan", "title": "AGAN: Towards Automated Design of Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in Generative Adversarial Networks (GANs) has shown promising\nsigns of improving GAN training via architectural change. Despite some early\nsuccess, at present the design of GAN architectures requires human expertise,\nlaborious trial-and-error testings, and often draws inspiration from its image\nclassification counterpart. In the current paper, we present the first neural\narchitecture search algorithm, automated neural architecture search for deep\ngenerative models, or AGAN for abbreviation, that is specifically suited for\nGAN training. For unsupervised image generation tasks on CIFAR-10, our\nalgorithm finds architecture that outperforms state-of-the-art models under\nsame regularization techniques. For supervised tasks, the automatically\nsearched architectures also achieve highly competitive performance,\noutperforming best human-invented architectures at resolution $32\\times32$.\nMoreover, we empirically demonstrate that the modules learned by AGAN are\ntransferable to other image generation tasks such as STL-10.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:12:32 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Wang", "Hanchao", ""], ["Huan", "Jun", ""]]}, {"id": "1906.11099", "submitter": "Hajime Seya", "authors": "Hajime Seya, Daiki Shiroi", "title": "A comparison of apartment rent price prediction using a large dataset:\n  Kriging versus DNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hedonic approach based on a regression model has been widely adopted for\nthe prediction of real estate property price and rent. In particular, a spatial\nregression technique called Kriging, a method of interpolation that was\nadvanced in the field of spatial statistics, are known to enable high accuracy\nprediction in light of the spatial dependence of real estate property data.\nMeanwhile, there has been a rapid increase in machine learning-based prediction\nusing a large (big) dataset and its effectiveness has been demonstrated in\nprevious studies. However, no studies have ever shown the extent to which\npredictive accuracy differs for Kriging and machine learning techniques using\nbig data. Thus, this study compares the predictive accuracy of apartment rent\nprice in Japan between the nearest neighbor Gaussian processes (NNGP) model,\nwhich enables application of Kriging to big data, and the deep neural network\n(DNN), a representative machine learning technique, with a particular focus on\nthe data sample size (n = 10^4, 10^5, 10^6) and differences in predictive\nperformance. Our analysis showed that, with an increase in sample size, the\nout-of-sample predictive accuracy of DNN approached that of NNGP and they were\nnearly equal on the order of n = 10^6. Furthermore, it is suggested that, for\nboth higher and lower end properties whose rent price deviates from the median,\nDNN may have a higher predictive accuracy than that of NNGP.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 14:15:31 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Seya", "Hajime", ""], ["Shiroi", "Daiki", ""]]}, {"id": "1906.11122", "submitter": "Luca Magri", "authors": "Nguyen Anh Khoa Doan, Wolfgang Polifke, Luca Magri", "title": "Physics-Informed Echo State Networks for Chaotic Systems Forecasting", "comments": "7 pages, 3 figures", "journal-ref": "Computational Science - ICCS 2019. ICCS 2019. Lecture Notes in\n  Computer Science, vol 11539. Springer, Cham", "doi": "10.1007/978-3-030-22747-0_15", "report-no": null, "categories": "physics.soc-ph cs.ET cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-informed Echo State Network (ESN) to predict the\nevolution of chaotic systems. Compared to conventional ESNs, the\nphysics-informed ESNs are trained to solve supervised learning tasks while\nensuring that their predictions do not violate physical laws. This is achieved\nby introducing an additional loss function during the training of the ESNs,\nwhich penalizes non-physical predictions without the need of any additional\ntraining data. This approach is demonstrated on a chaotic Lorenz system, where\nthe physics-informed ESNs improve the predictability horizon by about two\nLyapunov times as compared to conventional ESNs. The proposed framework shows\nthe potential of using machine learning combined with prior physical knowledge\nto improve the time-accurate prediction of chaotic dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:01:56 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Doan", "Nguyen Anh Khoa", ""], ["Polifke", "Wolfgang", ""], ["Magri", "Luca", ""]]}, {"id": "1906.11129", "submitter": "Rajeev Yasarla", "authors": "Rajeev Yasarla and Vishal M. Patel", "title": "Uncertainty Guided Multi-Scale Residual Learning-using a Cycle Spinning\n  CNN for Single Image De-Raining", "comments": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single image de-raining is an extremely challenging problem since the rainy\nimage may contain rain streaks which may vary in size, direction and density.\nPrevious approaches have attempted to address this problem by leveraging some\nprior information to remove rain streaks from a single image. One of the major\nlimitations of these approaches is that they do not consider the location\ninformation of rain drops in the image. The proposed Uncertainty guided\nMulti-scale Residual Learning (UMRL) network attempts to address this issue by\nlearning the rain content at different scales and using them to estimate the\nfinal de-rained output. In addition, we introduce a technique which guides the\nnetwork to learn the network weights based on the confidence measure about the\nestimate. Furthermore, we introduce a new training and testing procedure based\non the notion of cycle spinning to improve the final de-raining performance.\nExtensive experiments on synthetic and real datasets to demonstrate that the\nproposed method achieves significant improvements over the recent\nstate-of-the-art methods. Code is available at:\nhttps://github.com/rajeevyasarla/UMRL--using-Cycle-Spinning\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:13:50 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Yasarla", "Rajeev", ""], ["Patel", "Vishal M.", ""]]}, {"id": "1906.11133", "submitter": "Gary Saavedra", "authors": "Gary J Saavedra, Kathryn N Rodhouse, Daniel M Dunlavy, Philip W\n  Kegelmeyer", "title": "A Review of Machine Learning Applications in Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing has played an important role in improving software development and\ntesting over the course of several decades. Recent research in fuzzing has\nfocused on applications of machine learning (ML), offering useful tools to\novercome challenges in the fuzzing process. This review surveys the current\nresearch in applying ML to fuzzing. Specifically, this review discusses\nsuccessful applications of ML to fuzzing, briefly explores challenges\nencountered, and motivates future research to address fuzzing bottlenecks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:02:49 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 20:19:14 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Saavedra", "Gary J", ""], ["Rodhouse", "Kathryn N", ""], ["Dunlavy", "Daniel M", ""], ["Kegelmeyer", "Philip W", ""]]}, {"id": "1906.11148", "submitter": "Amir Asadi", "authors": "Amir R. Asadi and Emmanuel Abbe", "title": "Chaining Meets Chain Rule: Multilevel Entropic Regularization and\n  Training of Neural Nets", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive generalization and excess risk bounds for neural nets using a\nfamily of complexity measures based on a multilevel relative entropy. The\nbounds are obtained by introducing the notion of generated hierarchical\ncoverings of neural nets and by using the technique of chaining mutual\ninformation introduced in Asadi et al. NeurIPS'18. The resulting bounds are\nalgorithm-dependent and exploit the multilevel structure of neural nets. This,\nin turn, leads to an empirical risk minimization problem with a multilevel\nentropic regularization. The minimization problem is resolved by introducing a\nmulti-scale generalization of the celebrated Gibbs posterior distribution,\nproving that the derived distribution achieves the unique minimum. This leads\nto a new training procedure for neural nets with performance guarantees, which\nexploits the chain rule of relative entropy rather than the chain rule of\nderivatives (as in backpropagation). To obtain an efficient implementation of\nthe latter, we further develop a multilevel Metropolis algorithm simulating the\nmulti-scale Gibbs distribution, with an experiment for a two-layer neural net\non the MNIST data set.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 15:05:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Asadi", "Amir R.", ""], ["Abbe", "Emmanuel", ""]]}, {"id": "1906.11152", "submitter": "Erik Bodin", "authors": "Erik Bodin, Markus Kaiser, Ieva Kazlauskaite, Zhenwen Dai, Neill D. F.\n  Campbell, Carl Henrik Ek", "title": "Modulating Surrogates for Bayesian Optimization", "comments": null, "journal-ref": "37th International Conference On Machine Learning (ICML 2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) methods often rely on the assumption that the\nobjective function is well-behaved, but in practice, this is seldom true for\nreal-world objectives even if noise-free observations can be collected. Common\napproaches, which try to model the objective as precisely as possible, often\nfail to make progress by spending too many evaluations modeling irrelevant\ndetails. We address this issue by proposing surrogate models that focus on the\nwell-behaved structure in the objective function, which is informative for\nsearch, while ignoring detrimental structure that is challenging to model from\nfew observations. First, we demonstrate that surrogate models with appropriate\nnoise distributions can absorb challenging structures in the objective function\nby treating them as irreducible uncertainty. Secondly, we show that a latent\nGaussian process is an excellent surrogate for this purpose, comparing with\nGaussian processes with standard noise distributions. We perform numerous\nexperiments on a range of BO benchmarks and find that our approach improves\nreliability and performance when faced with challenging objective functions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 15:10:44 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 20:41:45 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 11:39:49 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 19:00:51 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Bodin", "Erik", ""], ["Kaiser", "Markus", ""], ["Kazlauskaite", "Ieva", ""], ["Dai", "Zhenwen", ""], ["Campbell", "Neill D. F.", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1906.11156", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Chi Wang, Kuansan Wang,\n  and Jie Tang", "title": "NetSMF: Large-Scale Network Embedding as Sparse Matrix Factorization", "comments": "11 pages, in Proceedings of the Web Conference 2019 (WWW 19)", "journal-ref": null, "doi": "10.1145/3308558.3313446", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of large-scale network embedding, which aims to learn\nlatent representations for network mining applications. Previous research shows\nthat 1) popular network embedding benchmarks, such as DeepWalk, are in essence\nimplicitly factorizing a matrix with a closed form, and 2)the explicit\nfactorization of such matrix generates more powerful embeddings than existing\nmethods. However, directly constructing and factorizing this matrix---which is\ndense---is prohibitively expensive in terms of both time and space, making it\nnot scalable for large networks.\n  In this work, we present the algorithm of large-scale network embedding as\nsparse matrix factorization (NetSMF). NetSMF leverages theories from spectral\nsparsification to efficiently sparsify the aforementioned dense matrix,\nenabling significantly improved efficiency in embedding learning. The\nsparsified matrix is spectrally close to the original dense one with a\ntheoretically bounded approximation error, which helps maintain the\nrepresentation power of the learned embeddings. We conduct experiments on\nnetworks of various scales and types. Results show that among both popular\nbenchmarks and factorization based methods, NetSMF is the only method that\nachieves both high efficiency and effectiveness. We show that NetSMF requires\nonly 24 hours to generate effective embeddings for a large-scale academic\ncollaboration network with tens of millions of nodes, while it would cost\nDeepWalk months and is computationally infeasible for the dense matrix\nfactorization solution. The source code of NetSMF is publicly available\n(https://github.com/xptree/NetSMF).\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 15:17:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Dong", "Yuxiao", ""], ["Ma", "Hao", ""], ["Li", "Jian", ""], ["Wang", "Chi", ""], ["Wang", "Kuansan", ""], ["Tang", "Jie", ""]]}, {"id": "1906.11177", "submitter": "Signe Riemer-Sorensen", "authors": "Signe Riemer-S{\\o}rensen (2) and Jie Wu (2) Halvor Lie (2) Svein\n  S{\\ae}vik (3) and Sang-Woo Kim (3) ((1) SINTEF Digital, (2) SINTEF Ocean, (3)\n  NTNU)", "title": "Data-driven prediction of vortex-induced vibration response of marine\n  risers subjected to three-dimensional current", "comments": "12 pages, presented at Norwegian AI Society Symposium 2019, accepted\n  for publication in Springer Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Slender marine structures such as deep-water marine risers are subjected to\ncurrents and will normally experience Vortex Induced Vibrations (VIV), which\ncan cause fast accumulation of fatigue damage. The ocean current is often\nthree-dimensional (3D), i.e., the direction and magnitude of the current vary\nthroughout the water column. Today, semi-empirical tools are used by the\nindustry to predict VIV induced fatigue on risers. The load model and\nhydrodynamic parameters in present VIV prediction tools are developed based on\ntwo-dimensional (2D) flow conditions, as it is challenging to consider the\neffect of 3D flow along the risers. Accordingly, the current profiles must be\npurposely made 2D during the design process, which leads to significant\nuncertainty in the prediction results. Further, due to the limitations in the\nlaboratory, VIV model tests are mostly carried out under 2D flow conditions and\nthus little experimental data exist to document VIV response of riser subjected\nto varying directions of the current. However, a few experiments have been\nconducted with 3D current. We have used results from one of these experiments\nto investigate how well 1) traditional and 2) an alternative method based on a\ndata driven prediction can describe VIV in 3D currents. Data driven modelling\nis particularly suited for complicated problems with many parameters and\nnon-linear relationships. We have applied a data clustering algorithm to the\nexperimental 3D flow data in order to identify measurable parameters that can\ninfluence responses. The riser responses are grouped based on their statistical\ncharacteristics, which relate to the direction of the flow. Furthermore we fit\na random forest regression model to the measured VIV response and compare its\nperformance with the predictions of existing VIV prediction tools (VIVANA-FD).\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 07:54:32 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Riemer-S\u00f8rensen", "Signe", ""], ["Wu", "Jie", ""], ["Lie", "Halvor", ""], ["S\u00e6vik", "Svein", ""], ["Kim", "Sang-Woo", ""]]}, {"id": "1906.11196", "submitter": "Fusong Ju", "authors": "Fusong Ju, Jianwei Zhu, Guozheng Wei, Qi Zhang, Shiwei Sun, Dongbo Bu", "title": "Seq-SetNet: Exploring Sequence Sets for Inferring Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence set is a widely-used type of data source in a large variety of\nfields. A typical example is protein structure prediction, which takes an\nmultiple sequence alignment (MSA) as input and aims to infer structural\ninformation from it. Almost all of the existing approaches exploit MSAs in an\nindirect fashion, i.e., they transform MSAs into position-specific scoring\nmatrices (PSSM) that represent the distribution of amino acid types at each\ncolumn. PSSM could capture column-wise characteristics of MSA, however, the\ncolumn-wise characteristics embedded in each individual component sequence were\nnearly totally neglected.\n  The drawback of PSSM is rooted in the fact that an MSA is essentially an\nunordered sequence set rather than a matrix. Specifically, the interchange of\nany two sequences will not affect the whole MSA. In contrast, the pixels in an\nimage essentially form a matrix since any two rows of pixels cannot be\ninterchanged. Therefore, the traditional deep neural networks designed for\nimage processing cannot be directly applied on sequence sets. Here, we proposed\na novel deep neural network framework (called Seq-SetNet) for sequence set\nprocessing. By employing a {\\it symmetric function} module to integrate\nfeatures calculated from preceding layers, Seq-SetNet are immune to the order\nof sequences in the input MSA. This advantage enables us to directly and fully\nexploit MSAs by considering each component protein individually. We evaluated\nSeq-SetNet by using it to extract structural information from MSA for protein\nsecondary structure prediction. Experimental results on popular benchmark sets\nsuggests that Seq-SetNet outperforms the state-of-the-art approaches by 3.6% in\nprecision. These results clearly suggest the advantages of Seq-SetNet in\nsequence set processing and it can be readily used in a wide range of fields,\nsay natural language processing.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 12:41:00 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Ju", "Fusong", ""], ["Zhu", "Jianwei", ""], ["Wei", "Guozheng", ""], ["Zhang", "Qi", ""], ["Sun", "Shiwei", ""], ["Bu", "Dongbo", ""]]}, {"id": "1906.11199", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Deployable probabilistic programming", "comments": "15 pages, to appear in SLPASH Onward! 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose design guidelines for a probabilistic programming facility\nsuitable for deployment as a part of a production software system. As a\nreference implementation, we introduce Infergo, a probabilistic programming\nfacility for Go, a modern programming language of choice for server-side\nsoftware development. We argue that a similar probabilistic programming\nfacility can be added to most modern general-purpose programming languages.\n  Probabilistic programming enables automatic tuning of program parameters and\nalgorithmic decision making through probabilistic inference based on the data.\nTo facilitate addition of probabilistic programming capabilities to other\nprogramming languages, we share implementation choices and techniques employed\nin development of Infergo. We illustrate applicability of Infergo to various\nuse cases on case studies, and evaluate Infergo's performance on several\nbenchmarks, comparing Infergo to dedicated inference-centric probabilistic\nprogramming frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:17:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1906.11228", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Abbas Abdolmaleki, Roland Hafner, Jost Tobias\n  Springenberg, Michael Neunert, Tim Hertweck, Thomas Lampe, Noah Siegel,\n  Nicolas Heess, Martin Riedmiller", "title": "Compositional Transfer in Hierarchical Reinforcement Learning", "comments": "Robotics Science and Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful application of general reinforcement learning algorithms to\nreal-world robotics applications is often limited by their high data\nrequirements. We introduce Regularized Hierarchical Policy Optimization (RHPO)\nto improve data-efficiency for domains with multiple dominant tasks and\nultimately reduce required platform time. To this end, we employ compositional\ninductive biases on multiple levels and corresponding mechanisms for sharing\noff-policy transition data across low-level controllers and tasks as well as\nscheduling of tasks. The presented algorithm enables stable and fast learning\nfor complex, real-world domains in the parallel multitask and sequential\ntransfer case. We show that the investigated types of hierarchy enable positive\ntransfer while partially mitigating negative interference and evaluate the\nbenefits of additional incentives for efficient, compositional task solutions\nin single task domains. Finally, we demonstrate substantial data-efficiency and\nfinal performance gains over competitive baselines in a week-long, physical\nrobot stacking experiment.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 17:42:07 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 09:44:16 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 17:29:06 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Abdolmaleki", "Abbas", ""], ["Hafner", "Roland", ""], ["Springenberg", "Jost Tobias", ""], ["Neunert", "Michael", ""], ["Hertweck", "Tim", ""], ["Lampe", "Thomas", ""], ["Siegel", "Noah", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1906.11235", "submitter": "Fanny Yang", "authors": "Fanny Yang, Zuowen Wang, Christina Heinze-Deml", "title": "Invariance-inducing regularization using worst-case transformations\n  suffices to boost accuracy and spatial robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides theoretical and empirical evidence that\ninvariance-inducing regularizers can increase predictive accuracy for\nworst-case spatial transformations (spatial robustness). Evaluated on these\nadversarially transformed examples, we demonstrate that adding regularization\non top of standard or adversarial training reduces the relative error by 20%\nfor CIFAR10 without increasing the computational cost. This outperforms\nhandcrafted networks that were explicitly designed to be spatial-equivariant.\nFurthermore, we observe for SVHN, known to have inherent variance in\norientation, that robust training also improves standard accuracy on the test\nset. We prove that this no-trade-off phenomenon holds for adversarial examples\nfrom transformation groups in the infinite data limit.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 17:57:10 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Yang", "Fanny", ""], ["Wang", "Zuowen", ""], ["Heinze-Deml", "Christina", ""]]}, {"id": "1906.11247", "submitter": "Osonde Osoba Ph.D.", "authors": "Osonde Osoba, Bart Kosko", "title": "Beyond DAGs: Modeling Causal Feedback with Fuzzy Cognitive Maps", "comments": "51 pages, 10 figures. Full details, theorems, & knowledge engineering\n  for \"Causal Modeling with Feedback Fuzzy Cognitive Maps\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy cognitive maps (FCMs) model feedback causal relations in interwoven\nwebs of causality and policy variables. FCMs are fuzzy signed directed graphs\nthat allow degrees of causal influence and event occurrence. Such causal models\ncan simulate a wide range of policy scenarios and decision processes. Their\ndirected loops or cycles directly model causal feedback. Their nonlinear\ndynamics permit forward-chaining inference from input causes and policy options\nto output effects. Users can add detailed dynamics and feedback links directly\nto the causal model or infer them with statistical learning laws. Users can\nfuse or combine FCMs from multiple experts by weighting and adding the\nunderlying fuzzy edge matrices and do so recursively if needed. The combined\nFCM tends to better represent domain knowledge as the expert sample size\nincreases if the expert sample approximates a random sample. Many causal models\nuse more restrictive directed acyclic graphs (DAGs) and Bayesian probabilities.\nDAGs do not model causal feedback because they do not contain closed loops.\nCombining DAGs also tends to produce cycles and thus tends not to produce a new\nDAG. Combining DAGs tends to produce a FCM. FCM causal influence is also\ntransitive whereas probabilistic causal influence is not transitive in general.\nOverall: FCMs trade the numerical precision of probabilistic DAGs for pattern\nprediction, faster and scalable computation, ease of combination, and richer\nfeedback representation. We show how FCMs can apply to problems of public\nsupport for insurgency and terrorism and to US-China conflict relations in\nGraham Allison's Thucydides-trap framework. The appendix gives the textual\njustification of the Thucydides-trap FCM. It also extends our earlier theorem\n[Osoba-Kosko2017] to a more general result that shows the transitive and total\ncausal influence that upstream concept nodes exert on downstream nodes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 16:27:01 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 04:18:14 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Osoba", "Osonde", ""], ["Kosko", "Bart", ""]]}, {"id": "1906.11285", "submitter": "Shameem Puthiya Parambath Mr.", "authors": "Shameem A Puthiya Parambath", "title": "Re-ranking Based Diversification: A Unifying View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze different re-ranking algorithms for diversification and show that\nmajority of them are based on maximizing submodular/modular functions from the\nclass of parameterized concave/linear over modular functions. We study the\noptimality of such algorithms in terms of the `total curvature'. We also show\nthat by adjusting the hyperparameter of the concave/linear composition to\ntrade-off relevance and diversity, if any, one is in fact tuning the `total\ncurvature' of the function for relevance-diversity trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 18:22:02 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Parambath", "Shameem A Puthiya", ""]]}, {"id": "1906.11286", "submitter": "Baihan Lin", "authors": "Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf, Jenna Reinen, Irina\n  Rish", "title": "A Story of Two Streams: Reinforcement Learning Models from Human\n  Behavior and Neuropsychiatry", "comments": "Published in AAMAS 2020 as a full paper. This article supersedes our\n  work arXiv:1706.02897 into RL setting and extends extensively into RL games,\n  cognitive modeling, and gambling tasks in lifelong learning setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing an inspiration from behavioral studies of human decision making, we\npropose here a more general and flexible parametric framework for reinforcement\nlearning that extends standard Q-learning to a two-stream model for processing\npositive and negative rewards, and allows to incorporate a wide range of\nreward-processing biases -- an important component of human decision making\nwhich can help us better understand a wide spectrum of multi-agent interactions\nin complex real-world socioeconomic systems, as well as various\nneuropsychiatric conditions associated with disruptions in normal reward\nprocessing. From the computational perspective, we observe that the proposed\nSplit-QL model and its clinically inspired variants consistently outperform\nstandard Q-Learning and SARSA methods, as well as recently proposed Double\nQ-Learning approaches, on simulated tasks with particular reward distributions,\na real-world dataset capturing human decision-making in gambling tasks, and the\nPac-Man game in a lifelong learning setting across different reward\nstationarities.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:31:37 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 06:14:11 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 04:34:06 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 19:21:21 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 18:56:09 GMT"}, {"version": "v6", "created": "Tue, 10 Mar 2020 20:52:24 GMT"}, {"version": "v7", "created": "Tue, 14 Apr 2020 17:26:49 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Lin", "Baihan", ""], ["Cecchi", "Guillermo", ""], ["Bouneffouf", "Djallel", ""], ["Reinen", "Jenna", ""], ["Rish", "Irina", ""]]}, {"id": "1906.11289", "submitter": "Tiancheng Yu", "authors": "Tiancheng Yu, Xiyu Zhai, Suvrit Sra", "title": "Near Optimal Stratified Sampling", "comments": "We have discovered a mistake in the main result. The quantity on the\n  RHS of (3) is not equal to the variance of estimator (2) when the sampling\n  rule is designed adaptively as we do. There will be further cross-product\n  terms which are now dominant terms. Therefore, although our bound is correct\n  for (3), it no longer implies bound of the variance of (2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a machine learning system is usually evaluated by using\ni.i.d.\\ observations with true labels. However, acquiring ground truth labels\nis expensive, while obtaining unlabeled samples may be cheaper. Stratified\nsampling can be beneficial in such settings and can reduce the number of true\nlabels required without compromising the evaluation accuracy. Stratified\nsampling exploits statistical properties (e.g., variance) across strata of the\nunlabeled population, though usually under the unrealistic assumption that\nthese properties are known. We propose two new algorithms that simultaneously\nestimate these properties and optimize the evaluation accuracy. We construct a\nlower bound to show the proposed algorithms (to log-factors) are rate optimal.\nExperiments on synthetic and real data show the reduction in label complexity\nthat is enabled by our algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 18:27:31 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 13:50:44 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Yu", "Tiancheng", ""], ["Zhai", "Xiyu", ""], ["Sra", "Suvrit", ""]]}, {"id": "1906.11290", "submitter": "Aurelio F. Bariviera", "authors": "Augusto Villa-Monte, Laura Lanzarini, Aurelio F. Bariviera, Jos\\'e A.\n  Olivas", "title": "User-Oriented Summaries Using a PSO Based Scoring Optimization Method", "comments": null, "journal-ref": "Entropy. 2019; 21(6):617", "doi": "10.3390/e21060617", "report-no": null, "categories": "cs.LG cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization tools have a great impact on many fields, such\nas medicine, law, and scientific research in general. As information overload\nincreases, automatic summaries allow handling the growing volume of documents,\nusually by assigning weights to the extracted phrases based on their\nsignificance in the expected summary. Obtaining the main contents of any given\ndocument in less time than it would take to do that manually is still an issue\nof interest. In~this~ article, a new method is presented that allows\nautomatically generating extractive summaries from documents by adequately\nweighting sentence scoring features using \\textit{Particle Swarm Optimization}.\nThe key feature of the proposed method is the identification of those features\nthat are closest to the criterion used by the individual when summarizing. The\nproposed method combines a binary representation and a continuous one, using an\noriginal variation of the technique developed by the authors of this paper. Our\npaper shows that using user labeled information in the training set helps to\nfind better metrics and weights. The empirical results yield an improved\naccuracy compared to previous methods used in this field\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 18:27:54 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Villa-Monte", "Augusto", ""], ["Lanzarini", "Laura", ""], ["Bariviera", "Aurelio F.", ""], ["Olivas", "Jos\u00e9 A.", ""]]}, {"id": "1906.11300", "submitter": "Phil Long", "authors": "Peter L. Bartlett, Philip M. Long, G\\'abor Lugosi and Alexander\n  Tsigler", "title": "Benign Overfitting in Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phenomenon of benign overfitting is one of the key mysteries uncovered by\ndeep learning methodology: deep neural networks seem to predict well, even with\na perfect fit to noisy training data. Motivated by this phenomenon, we consider\nwhen a perfect fit to training data in linear regression is compatible with\naccurate prediction. We give a characterization of linear regression problems\nfor which the minimum norm interpolating prediction rule has near-optimal\nprediction accuracy. The characterization is in terms of two notions of the\neffective rank of the data covariance. It shows that overparameterization is\nessential for benign overfitting in this setting: the number of directions in\nparameter space that are unimportant for prediction must significantly exceed\nthe sample size. By studying examples of data covariance properties that this\ncharacterization shows are required for benign overfitting, we find an\nimportant role for finite-dimensional data: the accuracy of the minimum norm\ninterpolating prediction rule approaches the best possible accuracy for a much\nnarrower range of properties of the data distribution when the data lies in an\ninfinite dimensional space versus when the data lies in a finite dimensional\nspace whose dimension grows faster than the sample size.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:09:56 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 00:04:53 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 21:01:57 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Long", "Philip M.", ""], ["Lugosi", "G\u00e1bor", ""], ["Tsigler", "Alexander", ""]]}, {"id": "1906.11328", "submitter": "Tian Liu", "authors": "Tian Liu and Tao Shu", "title": "Adversarial FDI Attack against AC State Estimation with ANN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural network (ANN) provides superior accuracy for nonlinear\nalternating current (AC) state estimation (SE) in smart grid over traditional\nmethods. However, research has discovered that ANN could be easily fooled by\nadversarial examples. In this paper, we initiate a new study of adversarial\nfalse data injection (FDI) attack against AC SE with ANN: by injecting a\ndeliberate attack vector into measurements, the attacker can degrade the\naccuracy of ANN SE while remaining undetected. We propose a population-based\nalgorithm and a gradient-based algorithm to generate attack vectors. The\nperformance of these algorithms is evaluated through simulations on IEEE 9-bus,\n14-bus and 30-bus systems under various attack scenarios. Simulation results\nshow that DE is more effective than SLSQP on all simulation cases. The attack\nexamples generated by DE algorithm successfully degrade the ANN SE accuracy\nwith high probability.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:16:17 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Liu", "Tian", ""], ["Shu", "Tao", ""]]}, {"id": "1906.11356", "submitter": "Abhinav Shaw", "authors": "Abhinav Shaw, Natcha Simsiri, Iman Deznaby, Madalina Fiterau, Tauhidur\n  Rahaman", "title": "Personalized Student Stress Prediction with Deep Multitask Network", "comments": "4 Pages, without references. Published in Proceedings of the 1st\n  Adaptive & Multitask Learning Workshop,Long Beach, California, 2019", "journal-ref": "Proceedings of the 1st Adaptive & Multitask Learning Workshop,Long\n  Beach, California, 2019, URL - https://openreview.net/pdf?id=HJxCE9Sjn4", "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing popularity of wearable devices, the ability to utilize\nphysiological data collected from these devices to predict the wearer's mental\nstate such as mood and stress suggests great clinical applications, yet such a\ntask is extremely challenging. In this paper, we present a general platform for\npersonalized predictive modeling of behavioural states like students' level of\nstress. Through the use of Auto-encoders and Multitask learning we extend the\nprediction of stress to both sequences of passive sensor data and high-level\ncovariates. Our model outperforms the state-of-the-art in the prediction of\nstress level from mobile sensor data, obtaining a 45.6 % improvement in F1\nscore on the StudentLife dataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 21:31:45 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Shaw", "Abhinav", ""], ["Simsiri", "Natcha", ""], ["Deznaby", "Iman", ""], ["Fiterau", "Madalina", ""], ["Rahaman", "Tauhidur", ""]]}, {"id": "1906.11366", "submitter": "Jerry Li", "authors": "Yihe Dong, Samuel B. Hopkins, Jerry Li", "title": "Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved\n  Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two problems in high-dimensional robust statistics: \\emph{robust\nmean estimation} and \\emph{outlier detection}. In robust mean estimation the\ngoal is to estimate the mean $\\mu$ of a distribution on $\\mathbb{R}^d$ given\n$n$ independent samples, an $\\varepsilon$-fraction of which have been corrupted\nby a malicious adversary. In outlier detection the goal is to assign an\n\\emph{outlier score} to each element of a data set such that elements more\nlikely to be outliers are assigned higher scores. Our algorithms for both\nproblems are based on a new outlier scoring method we call QUE-scoring based on\n\\emph{quantum entropy regularization}. For robust mean estimation, this yields\nthe first algorithm with optimal error rates and nearly-linear running time\n$\\widetilde{O}(nd)$ in all parameters, improving on the previous fastest\nrunning time $\\widetilde{O}(\\min(nd/\\varepsilon^6, nd^2))$. For outlier\ndetection, we evaluate the performance of QUE-scoring via extensive experiments\non synthetic and real data, and demonstrate that it often performs better than\npreviously proposed algorithms. Code for these experiments is available at\nhttps://github.com/twistedcubic/que-outlier-detection .\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 22:23:14 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Dong", "Yihe", ""], ["Hopkins", "Samuel B.", ""], ["Li", "Jerry", ""]]}, {"id": "1906.11367", "submitter": "Linguang Zhang", "authors": "Linguang Zhang, Maciej Halber, Szymon Rusinkiewicz", "title": "Accelerating Large-Kernel Convolution Using Summed-Area Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding the receptive field to capture large-scale context is key to\nobtaining good performance in dense prediction tasks, such as human pose\nestimation. While many state-of-the-art fully-convolutional architectures\nenlarge the receptive field by reducing resolution using strided convolution or\npooling layers, the most straightforward strategy is adopting large filters.\nThis, however, is costly because of the quadratic increase in the number of\nparameters and multiply-add operations. In this work, we explore using\nlearnable box filters to allow for convolution with arbitrarily large kernel\nsize, while keeping the number of parameters per filter constant. In addition,\nwe use precomputed summed-area tables to make the computational cost of\nconvolution independent of the filter size. We adapt and incorporate the box\nfilter as a differentiable module in a fully-convolutional neural network, and\ndemonstrate its competitive performance on popular benchmarks for the task of\nhuman pose estimation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 22:24:56 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Zhang", "Linguang", ""], ["Halber", "Maciej", ""], ["Rusinkiewicz", "Szymon", ""]]}, {"id": "1906.11389", "submitter": "Max Vladymyrov", "authors": "Max Vladymyrov", "title": "No Pressure! Addressing the Problem of Local Minima in Manifold Learning\n  Algorithms", "comments": "10 pages, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear embedding manifold learning methods provide invaluable visual\ninsights into the structure of high-dimensional data. However, due to a\ncomplicated nonconvex objective function, these methods can easily get stuck in\nlocal minima and their embedding quality can be poor. We propose a natural\nextension to several manifold learning methods aimed at identifying pressured\npoints, i.e. points stuck in poor local minima and have poor embedding quality.\nWe show that the objective function can be decreased by temporarily allowing\nthese points to make use of an extra dimension in the embedding space. Our\nmethod is able to improve the objective function value of existing methods even\nafter they get stuck in a poor local minimum.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 23:53:26 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 11:29:40 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Vladymyrov", "Max", ""]]}, {"id": "1906.11392", "submitter": "Nikolai Matni", "authors": "Nikolai Matni, Alexandre Proutiere, Anders Rantzer, Stephen Tu", "title": "From self-tuning regulators to reinforcement learning and back again", "comments": "Tutorial paper, 2019 IEEE Conference on Decision and Control, to\n  appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine and reinforcement learning (RL) are increasingly being applied to\nplan and control the behavior of autonomous systems interacting with the\nphysical world. Examples include self-driving vehicles, distributed sensor\nnetworks, and agile robots. However, when machine learning is to be applied in\nthese new settings, the algorithms had better come with the same type of\nreliability, robustness, and safety bounds that are hallmarks of control\ntheory, or failures could be catastrophic. Thus, as learning algorithms are\nincreasingly and more aggressively deployed in safety critical settings, it is\nimperative that control theorists join the conversation. The goal of this\ntutorial paper is to provide a starting point for control theorists wishing to\nwork on learning related problems, by covering recent advances bridging\nlearning and control theory, and by placing these results within an appropriate\nhistorical context of system identification and adaptive control.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 00:01:54 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 19:29:40 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Matni", "Nikolai", ""], ["Proutiere", "Alexandre", ""], ["Rantzer", "Anders", ""], ["Tu", "Stephen", ""]]}, {"id": "1906.11395", "submitter": "Nikolai Matni", "authors": "Nikolai Matni, Stephen Tu", "title": "A Tutorial on Concentration Bounds for System Identification", "comments": "Tutorial paper to appear at the 2019 IEEE Conference on Decision and\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a brief tutorial on the use of concentration inequalities as they\napply to system identification of state-space parameters of linear time\ninvariant systems, with a focus on the fully observed setting. We draw upon\ntools from the theories of large-deviations and self-normalized martingales,\nand provide both data-dependent and independent bounds on the learning rate.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 00:05:36 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 20:35:32 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Matni", "Nikolai", ""], ["Tu", "Stephen", ""]]}, {"id": "1906.11416", "submitter": "Shizhan Lu", "authors": "Shizhan Lu", "title": "Clustering by the way of atomic fission", "comments": "9 pages, 3 figures", "journal-ref": "IEEE ACCESS 2020", "doi": "10.1109/ACCESS.2020.2987345", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis which focuses on the grouping and categorization of similar\nelements is widely used in various fields of research. Inspired by the\nphenomenon of atomic fission, a novel density-based clustering algorithm is\nproposed in this paper, called fission clustering (FC). It focuses on mining\nthe dense families of a dataset and utilizes the information of the distance\nmatrix to fissure clustering dataset into subsets. When we face the dataset\nwhich has a few points surround the dense families of clusters, K-nearest\nneighbors local density indicator is applied to distinguish and remove the\npoints of sparse areas so as to obtain a dense subset that is constituted by\nthe dense families of clusters. A number of frequently-used datasets were used\nto test the performance of this clustering approach, and to compare the results\nwith those of algorithms. The proposed algorithm is found to outperform other\nalgorithms in speed and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:05:13 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Lu", "Shizhan", ""]]}, {"id": "1906.11426", "submitter": "Prashant Shekhar", "authors": "Prashant Shekhar and Abani Patra", "title": "Hierarchical Data Reduction and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a hierarchical learning strategy for generating sparse\nrepresentations of multivariate datasets. The hierarchy arises from\napproximation spaces considered at successively finer scales. A detailed\nanalysis of stability, convergence and behavior of error functionals associated\nwith the approximations are presented, along with a well chosen set of\napplications. Results show the performance of the approach as a data reduction\nmechanism for both synthetic (univariate and multivariate) and real datasets\n(geospatial and numerical model outcomes). The sparse representation generated\nis shown to efficiently reconstruct data and minimize error in prediction.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:47:37 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 11:58:52 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Shekhar", "Prashant", ""], ["Patra", "Abani", ""]]}, {"id": "1906.11471", "submitter": "Manuel Hau{\\ss}mann", "authors": "Manuel Haussmann, Fred A. Hamprecht, Melih Kandemir", "title": "Deep Active Learning with Adaptive Acquisition", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection is treated as a standard performance boosting step in many\nmachine learning applications. Once all other properties of a learning problem\nare fixed, the model is selected by grid search on a held-out validation set.\nThis is strictly inapplicable to active learning. Within the standardized\nworkflow, the acquisition function is chosen among available heuristics a\npriori, and its success is observed only after the labeling budget is already\nexhausted. More importantly, none of the earlier studies report a unique\nconsistently successful acquisition heuristic to the extent to stand out as the\nunique best choice. We present a method to break this vicious circle by\ndefining the acquisition function as a learning predictor and training it by\nreinforcement feedback collected from each labeling round. As active learning\nis a scarce data regime, we bootstrap from a well-known heuristic that filters\nthe bulk of data points on which all heuristics would agree, and learn a policy\nto warp the top portion of this ranking in the most beneficial way for the\ncharacter of a specific data distribution. Our system consists of a Bayesian\nneural net, the predictor, a bootstrap acquisition function, a probabilistic\nstate definition, and another Bayesian policy network that can effectively\nincorporate this input distribution. We observe on three benchmark data sets\nthat our method always manages to either invent a new superior acquisition\nfunction or to adapt itself to the a priori unknown best performing heuristic\nfor each specific data set.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 07:32:55 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Haussmann", "Manuel", ""], ["Hamprecht", "Fred A.", ""], ["Kandemir", "Melih", ""]]}, {"id": "1906.11527", "submitter": "Hadi Samer Jomaa", "authors": "Hadi S. Jomaa, Josif Grabocka, Lars Schmidt-Thieme", "title": "Hyp-RL : Hyperparameter Optimization by Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning is an omnipresent problem in machine learning as it is\nan integral aspect of obtaining the state-of-the-art performance for any model.\nMost often, hyperparameters are optimized just by training a model on a grid of\npossible hyperparameter values and taking the one that performs best on a\nvalidation sample (grid search). More recently, methods have been introduced\nthat build a so-called surrogate model that predicts the validation loss for a\nspecific hyperparameter setting, model and dataset and then sequentially select\nthe next hyperparameter to test, based on a heuristic function of the expected\nvalue and the uncertainty of the surrogate model called acquisition function\n(sequential model-based Bayesian optimization, SMBO).\n  In this paper we model the hyperparameter optimization problem as a\nsequential decision problem, which hyperparameter to test next, and address it\nwith reinforcement learning. This way our model does not have to rely on a\nheuristic acquisition function like SMBO, but can learn which hyperparameters\nto test next based on the subsequent reduction in validation loss they will\neventually lead to, either because they yield good models themselves or because\nthey allow the hyperparameter selection policy to build a better surrogate\nmodel that is able to choose better hyperparameters later on. Experiments on a\nlarge battery of 50 data sets demonstrate that our method outperforms the\nstate-of-the-art approaches for hyperparameter learning.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:59:44 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Jomaa", "Hadi S.", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1906.11537", "submitter": "Andrew Y. K. Foong", "authors": "Andrew Y. K. Foong, Yingzhen Li, Jos\\'e Miguel Hern\\'andez-Lobato,\n  Richard E. Turner", "title": "'In-Between' Uncertainty in Bayesian Neural Networks", "comments": "Presented at the ICML 2019 Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a limitation in the expressiveness of the predictive uncertainty\nestimate given by mean-field variational inference (MFVI), a popular\napproximate inference method for Bayesian neural networks. In particular, MFVI\nfails to give calibrated uncertainty estimates in between separated regions of\nobservations. This can lead to catastrophically overconfident predictions when\ntesting on out-of-distribution data. Avoiding such overconfidence is critical\nfor active learning, Bayesian optimisation and out-of-distribution robustness.\nWe instead find that a classical technique, the linearised Laplace\napproximation, can handle 'in-between' uncertainty much better for small\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 10:25:14 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Foong", "Andrew Y. K.", ""], ["Li", "Yingzhen", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Turner", "Richard E.", ""]]}, {"id": "1906.11567", "submitter": "Morgane Goibert", "authors": "Morgane Goibert and Elvis Dohmatob", "title": "Adversarial Robustness via Label-Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Label-Smoothing as a means for improving adversarial robustness of\nsupervised deep-learning models. After establishing a thorough and unified\nframework, we propose several variations to this general method: adversarial,\nBoltzmann and second-best Label-Smoothing methods, and we explain how to\nconstruct your own one. On various datasets (MNIST, CIFAR10, SVHN) and models\n(linear models, MLPs, LeNet, ResNet), we show that Label-Smoothing in general\nimproves adversarial robustness against a variety of attacks (FGSM, BIM,\nDeepFool, Carlini-Wagner) by better taking account of the dataset geometry. The\nproposed Label-Smoothing methods have two main advantages: they can be\nimplemented as a modified cross-entropy loss, thus do not require any\nmodifications of the network architecture nor do they lead to increased\ntraining times, and they improve both standard and adversarial accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 11:47:55 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 16:40:10 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Goibert", "Morgane", ""], ["Dohmatob", "Elvis", ""]]}, {"id": "1906.11594", "submitter": "Deli Zhao", "authors": "Deli Zhao, Jiapeng Zhu, Zhenfang Guo, Bo Zhang", "title": "Curriculum Learning for Deep Generative Models with Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative models like Generative Adversarial Network (GAN) is\nchallenging for noisy data. A novel curriculum learning algorithm pertaining to\nclustering is proposed to address this issue in this paper. The curriculum\nconstruction is based on the centrality of underlying clusters in data points.\nThe data points of high centrality takes priority of being fed into generative\nmodels during training. To make our algorithm scalable to large-scale data, the\nactive set is devised, in the sense that every round of training proceeds only\non an active subset containing a small fraction of already trained data and the\nincremental data of lower centrality. Moreover, the geometric analysis is\npresented to interpret the necessity of cluster curriculum for generative\nmodels. The experiments on cat and human-face data validate that our algorithm\nis able to learn the optimal generative models (e.g. ProGAN) with respect to\nspecified quality metrics for noisy data. An interesting finding is that the\noptimal cluster curriculum is closely related to the critical point of the\ngeometric percolation process formulated in the paper.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 12:44:09 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 03:04:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhao", "Deli", ""], ["Zhu", "Jiapeng", ""], ["Guo", "Zhenfang", ""], ["Zhang", "Bo", ""]]}, {"id": "1906.11613", "submitter": "Jean-Baptiste Gouray", "authors": "Ya\\\"el Fr\\'egier, Jean-Baptiste Gouray", "title": "Mind2Mind : transfer learning for GANs", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative adversarial networks (GANs) on high quality (HQ) images\ninvolves important computing resources. This requirement represents a\nbottleneck for the development of applications of GANs. We propose a transfer\nlearning technique for GANs that significantly reduces training time. Our\napproach consists of freezing the low-level layers of both the critic and\ngenerator of the original GAN. We assume an autoencoder constraint in order to\nensure the compatibility of the internal representations of the critic and the\ngenerator. This assumption explains the gain in training time as it enables us\nto bypass the low-level layers during the forward and backward passes. We\ncompare our method to baselines and observe a significant acceleration of the\ntraining. It can reach two orders of magnitude on HQ datasets when compared\nwith StyleGAN. We prove rigorously, within the framework of optimal transport,\na theorem ensuring the convergence of the learning of the transferred GAN. We\nmoreover provide a precise bound for the convergence of the training in terms\nof the distance between the source and target dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:19:29 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 13:15:27 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Fr\u00e9gier", "Ya\u00ebl", ""], ["Gouray", "Jean-Baptiste", ""]]}, {"id": "1906.11632", "submitter": "Paolo Galeone", "authors": "Federico Di Mattia, Paolo Galeone, Michele De Simoni, Emanuele Ghelfi", "title": "A Survey on GANs for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anomaly detection is a significant problem faced in several research areas.\nDetecting and correctly classifying something unseen as anomalous is a\nchallenging problem that has been tackled in many different manners over the\nyears.\n  Generative Adversarial Networks (GANs) and the adversarial training process\nhave been recently employed to face this task yielding remarkable results. In\nthis paper we survey the principal GAN-based anomaly detection methods,\nhighlighting their pros and cons. Our contributions are the empirical\nvalidation of the main GAN models for anomaly detection, the increase of the\nexperimental results on different datasets and the public release of a complete\nOpen Source toolbox for Anomaly Detection using GANs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:38:22 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Di Mattia", "Federico", ""], ["Galeone", "Paolo", ""], ["De Simoni", "Michele", ""], ["Ghelfi", "Emanuele", ""]]}, {"id": "1906.11633", "submitter": "Lilian Weng", "authors": "Maciek Chociej, Peter Welinder, Lilian Weng", "title": "ORRB -- OpenAI Remote Rendering Backend", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the OpenAI Remote Rendering Backend (ORRB), a system that allows\nfast and customizable rendering of robotics environments. It is based on the\nUnity3d game engine and interfaces with the MuJoCo physics simulation library.\nORRB was designed with visual domain randomization in mind. It is optimized for\ncloud deployment and high throughput operation. We are releasing it to the\npublic under a liberal MIT license: https://github.com/openai/orrb .\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 16:58:46 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Chociej", "Maciek", ""], ["Welinder", "Peter", ""], ["Weng", "Lilian", ""]]}, {"id": "1906.11641", "submitter": "Daniela De Canditiis", "authors": "Daniela De Canditiis", "title": "A global approach for learning sparse Ising models", "comments": "15 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1902.04728 by other authors", "journal-ref": "Mathematics and Computers in Simulation (2020)", "doi": "10.1016/j.matcom.2020.02.012", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the link parameters as well as the\nstructure of a binary-valued pairwise Markov model. Under sparsity assumption,\nwe propose a method based on $l_1$- regularized logistic regression, which\nestimate globally the whole set of edges and link parameters. Unlike the more\nrecent methods discussed in literature that learn the edges and the\ncorresponding link parameters one node at a time, in this work we propose a\nmethod that learns all the edges and corresponding link parameters\nsimultaneously for all nodes. The idea behind this proposal is to exploit the\nreciprocal information of the nodes between each other during the estimation\nprocess. Numerical experiments highlight the advantage of this technique and\nconfirm the intuition behind it.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:24:54 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:28:31 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["De Canditiis", "Daniela", ""]]}, {"id": "1906.11645", "submitter": "Evgenii Razinkov", "authors": "Lenar Gabdrakhmanov, Rustem Garaev, Evgenii Razinkov", "title": "RUSLAN: Russian Spoken Language Corpus for Speech Synthesis", "comments": "Accepted to SPECOM'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RUSLAN -- a new open Russian spoken language corpus for the\ntext-to-speech task. RUSLAN contains 22200 audio samples with text annotations\n-- more than 31 hours of high-quality speech of one person -- being the largest\nannotated Russian corpus in terms of speech duration for a single speaker. We\ntrained an end-to-end neural network for the text-to-speech task on our corpus\nand evaluated the quality of the synthesized speech using Mean Opinion Score\ntest. Synthesized speech achieves 4.05 score for naturalness and 3.78 score for\nintelligibility on a 5-point MOS scale.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:06:05 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Gabdrakhmanov", "Lenar", ""], ["Garaev", "Rustem", ""], ["Razinkov", "Evgenii", ""]]}, {"id": "1906.11653", "submitter": "Daniel Kowal", "authors": "Daniel R. Kowal and Antonio Canale", "title": "Simultaneous Transformation and Rounding (STAR) Models for\n  Integer-Valued Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet powerful framework for modeling integer-valued data,\nsuch as counts, scores, and rounded data. The data-generating process is\ndefined by Simultaneously Transforming and Rounding (STAR) a continuous-valued\nprocess, which produces a flexible family of integer-valued distributions\ncapable of modeling zero-inflation, bounded or censored data, and over- or\nunderdispersion. The transformation is modeled as unknown for greater\ndistributional flexibility, while the rounding operation ensures a coherent\ninteger-valued data-generating process. An efficient MCMC algorithm is\ndeveloped for posterior inference and provides a mechanism for adaptation of\nsuccessful Bayesian models and algorithms for continuous data to the\ninteger-valued data setting. Using the STAR framework, we design a new Bayesian\nAdditive Regression Tree (BART) model for integer-valued data, which\ndemonstrates impressive predictive distribution accuracy for both synthetic\ndata and a large healthcare utilization dataset. For interpretable\nregression-based inference, we develop a STAR additive model, which offers\ngreater flexibility and scalability than existing integer-valued models. The\nSTAR additive model is applied to study the recent decline in Amazon river\ndolphins.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:56:39 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 15:27:26 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kowal", "Daniel R.", ""], ["Canale", "Antonio", ""]]}, {"id": "1906.11655", "submitter": "Michael Lohaus", "authors": "Michael Lohaus, Philipp Hennig, Ulrike von Luxburg", "title": "Uncertainty Estimates for Ordinal Embeddings", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To investigate objects without a describable notion of distance, one can\ngather ordinal information by asking triplet comparisons of the form \"Is object\n$x$ closer to $y$ or is $x$ closer to $z$?\" In order to learn from such data,\nthe objects are typically embedded in a Euclidean space while satisfying as\nmany triplet comparisons as possible. In this paper, we introduce empirical\nuncertainty estimates for standard embedding algorithms when few noisy triplets\nare available, using a bootstrap and a Bayesian approach. In particular,\nsimulations show that these estimates are well calibrated and can serve to\nselect embedding parameters or to quantify uncertainty in scientific\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:58:53 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Lohaus", "Michael", ""], ["Hennig", "Philipp", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1906.11661", "submitter": "Camille Couprie", "authors": "Baptiste Rozi\\`ere, Morgane Riviere, Olivier Teytaud, J\\'er\\'emy\n  Rapin, Yann LeCun, Camille Couprie", "title": "Inspirational Adversarial Image Generation", "comments": null, "journal-ref": "TIP 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of image generation started to receive some attention from artists\nand designers to inspire them in new creations. However, exploiting the results\nof deep generative models such as Generative Adversarial Networks can be long\nand tedious given the lack of existing tools. In this work, we propose a simple\nstrategy to inspire creators with new generations learned from a dataset of\ntheir choice, while providing some control on them. We design a simple\noptimization method to find the optimal latent parameters corresponding to the\nclosest generation to any input inspirational image. Specifically, we allow the\ngeneration given an inspirational image of the user choice by performing\nseveral optimization steps to recover optimal parameters from the model's\nlatent space. We tested several exploration methods starting with classic\ngradient descents to gradient-free optimizers. Many gradient-free optimizers\njust need comparisons (better/worse than another image), so that they can even\nbe used without numerical criterion, without inspirational image, but with only\nwith human preference. Thus, by iterating on one's preferences we could make\nrobust Facial Composite or Fashion Generation algorithms. High resolution of\nthe produced design generations are obtained using progressive growing of GANs.\nOur results on four datasets of faces, fashion images, and textures show that\nsatisfactory images are effectively retrieved in most cases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 06:52:40 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 06:55:30 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Rozi\u00e8re", "Baptiste", ""], ["Riviere", "Morgane", ""], ["Teytaud", "Olivier", ""], ["Rapin", "J\u00e9r\u00e9my", ""], ["LeCun", "Yann", ""], ["Couprie", "Camille", ""]]}, {"id": "1906.11684", "submitter": "Spencer Kent", "authors": "Spencer J. Kent, E. Paxon Frady, Friedrich T. Sommer, Bruno A.\n  Olshausen", "title": "Resonator Networks outperform optimization methods at solving\n  high-dimensional vector factorization", "comments": "arXiv's LaTeX compiler contains a compatibility issue with the\n  subcaption package, screwing up the placement of Figure 6 (and subsequent\n  figures) in V3. This update simply remedies that issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop theoretical foundations of Resonator Networks, a new type of\nrecurrent neural network introduced in Frady et al. (2020) to solve a\nhigh-dimensional vector factorization problem arising in Vector Symbolic\nArchitectures. Given a composite vector formed by the Hadamard product between\na discrete set of high-dimensional vectors, a Resonator Network can efficiently\ndecompose the composite into these factors. We compare the performance of\nResonator Networks against optimization-based methods, including Alternating\nLeast Squares and several gradient-based algorithms, showing that Resonator\nNetworks are superior in several important ways. This advantage is achieved by\nleveraging a combination of nonlinear dynamics and \"searching in\nsuperposition,\" by which estimates of the correct solution are formed from a\nweighted superposition of all possible solutions. While the alternative methods\nalso search in superposition, the dynamics of Resonator Networks allow them to\nstrike a more effective balance between exploring the solution space and\nexploiting local information to drive the network toward probable solutions.\nResonator Networks are not guaranteed to converge, but within a particular\nregime they almost always do. In exchange for relaxing this guarantee of global\nconvergence, Resonator Networks are dramatically more effective at finding\nfactorizations than all alternative approaches considered.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:18:03 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 00:47:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 21:52:31 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 19:04:13 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Kent", "Spencer J.", ""], ["Frady", "E. Paxon", ""], ["Sommer", "Friedrich T.", ""], ["Olshausen", "Bruno A.", ""]]}, {"id": "1906.11729", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "Using Intuition from Empirical Properties to Simplify Adversarial\n  Training Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the surprisingly good representation power of complex distributions,\nneural network (NN) classifiers are widely used in many tasks which include\nnatural language processing, computer vision and cyber security. In recent\nworks, people noticed the existence of adversarial examples. These adversarial\nexamples break the NN classifiers' underlying assumption that the environment\nis attack free and can easily mislead fully trained NN classifier without\nnoticeable changes. Among defensive methods, adversarial training is a popular\nchoice. However, original adversarial training with single-step adversarial\nexamples (Single-Adv) can not defend against iterative adversarial examples.\nAlthough adversarial training with iterative adversarial examples (Iter-Adv)\ncan defend against iterative adversarial examples, it consumes too much\ncomputational power and hence is not scalable. In this paper, we analyze\nIter-Adv techniques and identify two of their empirical properties. Based on\nthese properties, we propose modifications which enhance Single-Adv to perform\ncompetitively as Iter-Adv. Through preliminary evaluation, we show that the\nproposed method enhances the test accuracy of state-of-the-art (SOTA)\nSingle-Adv defensive method against iterative adversarial examples by up to\n16.93% while reducing its training cost by 28.75%.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:22:56 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "1906.11732", "submitter": "Yue Bai", "authors": "Yue Bai, Leo L. Duan", "title": "Tuning-Free Disentanglement via Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In representation learning and non-linear dimension reduction, there is a\nhuge interest to learn the 'disentangled' latent variables, where each\nsub-coordinate almost uniquely controls a facet of the observed data. While\nmany regularization approaches have been proposed on variational autoencoders,\nheuristic tuning is required to balance between disentanglement and loss in\nreconstruction accuracy -- due to the unsupervised nature, there is no\nprincipled way to find an optimal weight for regularization. Motivated to\ncompletely bypass regularization, we consider a projection strategy: modifying\nthe canonical Gaussian encoder, we add a layer of scaling and rotation to the\nGaussian mean, such that the marginal correlations among latent sub-coordinates\nbecome exactly zero. This achieves a theoretically maximal disentanglement, as\nguaranteed by zero cross-correlation between one latent sub-coordinate and the\nobserved varying with the rest. Unlike regularizations, the extra projection\nlayer does not impact the flexibility of the previous encoder layers, leading\nto almost no loss in expressiveness. This approach is simple to implement in\npractice. Our numerical experiments demonstrate very good performance, with no\ntuning required.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:29:52 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 03:47:00 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Bai", "Yue", ""], ["Duan", "Leo L.", ""]]}, {"id": "1906.11755", "submitter": "Bernhard Bermeitinger", "authors": "Bernhard Bermeitinger, Tomas Hrycej, Siegfried Handschuh", "title": "Singular Value Decomposition and Neural Networks", "comments": null, "journal-ref": "ICANN 2019: Artificial Neural Networks and Machine Learning - Deep\n  Learning", "doi": "10.1007/978-3-030-30484-3_13", "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Value Decomposition (SVD) constitutes a bridge between the linear\nalgebra concepts and multi-layer neural networks---it is their linear analogy.\nBesides of this insight, it can be used as a good initial guess for the network\nparameters, leading to substantially better optimization results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:58:50 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Bermeitinger", "Bernhard", ""], ["Hrycej", "Tomas", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1906.11759", "submitter": "Francisco Afonso Raposo", "authors": "Francisco Afonso Raposo and David Martins de Matos and Ricardo Ribeiro", "title": "Low-dimensional Embodied Semantics for Music and Language", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied cognition states that semantics is encoded in the brain as firing\npatterns of neural circuits, which are learned according to the statistical\nstructure of human multimodal experience. However, each human brain is\nidiosyncratically biased, according to its subjective experience history,\nmaking this biological semantic machinery noisy with respect to the overall\nsemantics inherent to media artifacts, such as music and language excerpts. We\npropose to represent shared semantics using low-dimensional vector embeddings\nby jointly modeling several brains from human subjects. We show these\nunsupervised efficient representations outperform the original high-dimensional\nfMRI voxel spaces in proxy music genre and language topic classification tasks.\nWe further show that joint modeling of several subjects increases the semantic\nrichness of the learned latent vector spaces.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:09:01 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Raposo", "Francisco Afonso", ""], ["de Matos", "David Martins", ""], ["Ribeiro", "Ricardo", ""]]}, {"id": "1906.11768", "submitter": "John Lee", "authors": "John Lee, Max Dabagia, Eva L. Dyer, Christopher J. Rozell", "title": "Hierarchical Optimal Transport for Multimodal Distribution Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, it is necessary to meaningfully\naggregate, through alignment, different but related datasets. Optimal transport\n(OT)-based approaches pose alignment as a divergence minimization problem: the\naim is to transform a source dataset to match a target dataset using the\nWasserstein distance as a divergence measure. We introduce a hierarchical\nformulation of OT which leverages clustered structure in data to improve\nalignment in noisy, ambiguous, or multimodal settings. To solve this\nnumerically, we propose a distributed ADMM algorithm that also exploits the\nSinkhorn distance, thus it has an efficient computational complexity that\nscales quadratically with the size of the largest cluster. When the\ntransformation between two datasets is unitary, we provide performance\nguarantees that describe when and how well aligned cluster correspondences can\nbe recovered with our formulation, as well as provide worst-case dataset\ngeometry for such a strategy. We apply this method to synthetic datasets that\nmodel data as mixtures of low-rank Gaussians and study the impact that\ndifferent geometric properties of the data have on alignment. Next, we applied\nour approach to a neural decoding application where the goal is to predict\nmovement directions and instantaneous velocities from populations of neurons in\nthe macaque primary motor cortex. Our results demonstrate that when clustered\nstructure exists in datasets, and is consistent across trials or time points, a\nhierarchical alignment strategy that leverages such structure can provide\nsignificant improvements in cross-domain alignment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:18:32 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 06:21:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lee", "John", ""], ["Dabagia", "Max", ""], ["Dyer", "Eva L.", ""], ["Rozell", "Christopher J.", ""]]}, {"id": "1906.11785", "submitter": "Anirban Santara", "authors": "Anirban Santara, Rishabh Madan, Balaraman Ravindran, Pabitra Mitra", "title": "ExTra: Transfer-guided Exploration", "comments": "Published as an extended abstract at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel approach for transfer-guided exploration in\nreinforcement learning that is inspired by the human tendency to leverage\nexperiences from similar encounters in the past while navigating a new task.\nGiven an optimal policy in a related task-environment, we show that its\nbisimulation distance from the current task-environment gives a lower bound on\nthe optimal advantage of state-action pairs in the current task-environment.\nTransfer-guided Exploration (ExTra) samples actions from a Softmax distribution\nover these lower bounds. In this way, actions with potentially higher optimum\nadvantage are sampled more frequently. In our experiments on gridworld\nenvironments, we demonstrate that given access to an optimal policy in a\nrelated task-environment, ExTra can outperform popular domain-specific\nexploration strategies viz. epsilon greedy, Model-Based Interval Estimation -\nExploration Bonus (MBIE-EB), Pursuit and Boltzmann in rate of convergence. We\nfurther show that ExTra is robust to choices of source task and shows a\ngraceful degradation of performance as the dissimilarity of the source task\nincreases. We also demonstrate that ExTra, when used alongside traditional\nexploration algorithms, improves their rate of convergence. Thus it is capable\nof complementing the efficacy of traditional exploration algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:47:54 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 07:35:39 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 12:28:55 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Santara", "Anirban", ""], ["Madan", "Rishabh", ""], ["Ravindran", "Balaraman", ""], ["Mitra", "Pabitra", ""]]}, {"id": "1906.11786", "submitter": "Matej Balog", "authors": "Matej Balog, Bart van Merri\\\"enboer, Subhodeep Moitra, Yujia Li,\n  Daniel Tarlow", "title": "Fast Training of Sparse Graph Neural Networks on Dense Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have become increasingly popular in recent years due to\ntheir ability to naturally encode relational input data and their ability to\nscale to large graphs by operating on a sparse representation of graph\nadjacency matrices. As we look to scale up these models using custom hardware,\na natural assumption would be that we need hardware tailored to sparse\noperations and/or dynamic control flow. In this work, we question this\nassumption by scaling up sparse graph neural networks using a platform targeted\nat dense computation on fixed-size data. Drawing inspiration from optimization\nof numerical algorithms on sparse matrices, we develop techniques that enable\ntraining the sparse graph neural network model from Allamanis et al. [2018] in\n13 minutes using a 512-core TPUv2 Pod, whereas the original training takes\nalmost a day.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:48:29 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Balog", "Matej", ""], ["van Merri\u00ebnboer", "Bart", ""], ["Moitra", "Subhodeep", ""], ["Li", "Yujia", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1906.11790", "submitter": "Richard Shin", "authors": "Richard Shin", "title": "Encoding Database Schemas with Relation-Aware Self-Attention for\n  Text-to-SQL Parsers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When translating natural language questions into SQL queries to answer\nquestions from a database, we would like our methods to generalize to domains\nand database schemas outside of the training set. To handle complex questions\nand database schemas with a neural encoder-decoder paradigm, it is critical to\nproperly encode the schema as part of the input with the question. In this\npaper, we use relation-aware self-attention within the encoder so that it can\nreason about how the tables and columns in the provided schema relate to each\nother and use this information in interpreting the question. We achieve\nsignificant gains on the recently-released Spider dataset with 42.94% exact\nmatch accuracy, compared to the 18.96% reported in published work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:52:29 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Shin", "Richard", ""]]}, {"id": "1906.11796", "submitter": "Aviv Gabbay", "authors": "Aviv Gabbay and Yedid Hoshen", "title": "Demystifying Inter-Class Disentanglement", "comments": "ICLR 2020. Project page: http://www.vision.huji.ac.il/lord", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to disentangle the hidden factors of variations within a set of\nobservations is a key task for artificial intelligence. We present a unified\nformulation for class and content disentanglement and use it to illustrate the\nlimitations of current methods. We therefore introduce LORD, a novel method\nbased on Latent Optimization for Representation Disentanglement. We find that\nlatent optimization, along with an asymmetric noise regularization, is superior\nto amortized inference for achieving disentangled representations. In extensive\nexperiments, our method is shown to achieve better disentanglement performance\nthan both adversarial and non-adversarial methods that use the same level of\nsupervision. We further introduce a clustering-based approach for extending our\nmethod for settings that exhibit in-class variation with promising results on\nthe task of domain translation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:58:26 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 17:28:03 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 18:56:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gabbay", "Aviv", ""], ["Hoshen", "Yedid", ""]]}, {"id": "1906.11798", "submitter": "Klas Leino", "authors": "Klas Leino, Matt Fredrikson", "title": "Stolen Memories: Leveraging Model Memorization for Calibrated White-Box\n  Membership Inference", "comments": "appearing in USENIX 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference (MI) attacks exploit the fact that machine learning\nalgorithms sometimes leak information about their training data through the\nlearned model. In this work, we study membership inference in the white-box\nsetting in order to exploit the internals of a model, which have not been\neffectively utilized by previous work. Leveraging new insights about how\noverfitting occurs in deep neural networks, we show how a model's idiosyncratic\nuse of features can provide evidence for membership to white-box\nattackers---even when the model's black-box behavior appears to generalize\nwell---and demonstrate that this attack outperforms prior black-box methods.\nTaking the position that an effective attack should have the ability to provide\nconfident positive inferences, we find that previous attacks do not often\nprovide a meaningful basis for confidently inferring membership, whereas our\nattack can be effectively calibrated for high precision. Finally, we examine\npopular defenses against MI attacks, finding that (1) smaller generalization\nerror is not sufficient to prevent attacks on real models, and (2) while\nsmall-$\\epsilon$-differential privacy reduces the attack's effectiveness, this\noften comes at a significant cost to the model's accuracy; and for larger\n$\\epsilon$ that are sometimes used in practice (e.g., $\\epsilon=16$), the\nattack can achieve nearly the same accuracy as on the unprotected model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 17:07:51 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 21:06:44 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Leino", "Klas", ""], ["Fredrikson", "Matt", ""]]}, {"id": "1906.11813", "submitter": "Zilong Tan", "authors": "Zilong Tan, Samuel Yeom, Matt Fredrikson, Ameet Talwalkar", "title": "Learning Fair Representations for Kernel Models", "comments": "The 23rd International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair representations are a powerful tool for establishing criteria like\nstatistical parity, proxy non-discrimination, and equality of opportunity in\nlearned models. Existing techniques for learning these representations are\ntypically model-agnostic, as they preprocess the original data such that the\noutput satisfies some fairness criterion, and can be used with arbitrary\nlearning methods. In contrast, we demonstrate the promise of learning a\nmodel-aware fair representation, focusing on kernel-based models. We leverage\nthe classical Sufficient Dimension Reduction (SDR) framework to construct\nrepresentations as subspaces of the reproducing kernel Hilbert space (RKHS),\nwhose member functions are guaranteed to satisfy fairness. Our method supports\nseveral fairness criteria, continuous and discrete data, and multiple protected\nattributes. We further show how to calibrate the accuracy tradeoff by\ncharacterizing it in terms of the principal angles between subspaces of the\nRKHS. Finally, we apply our approach to obtain the first Fair Gaussian Process\n(FGP) prior for fair Bayesian learning, and show that it is competitive with,\nand in some cases outperforms, state-of-the-art methods on real data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 17:39:21 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 18:56:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Tan", "Zilong", ""], ["Yeom", "Samuel", ""], ["Fredrikson", "Matt", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1906.11826", "submitter": "Hananel Hazan", "authors": "Hananel Hazan, Daniel J. Saunders, Darpan T. Sanghavi, Hava\n  Siegelmann, and Robert Kozma", "title": "Lattice Map Spiking Neural Networks (LM-SNNs) for Clustering and\n  Classifying Image Data", "comments": "Original Manuscript Submitted: October 30, 2018. Revised: May 28,\n  2019. Special Issue: \"Cognition and Neurocomputation\" of Annals of\n  Mathematics and Artificial Intelligence. arXiv admin note: text overlap with\n  arXiv:1807.09374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking neural networks (SNNs) with a lattice architecture are introduced in\nthis work, combining several desirable properties of SNNs and self-organized\nmaps (SOMs). Networks are trained with biologically motivated, unsupervised\nlearning rules to obtain a self-organized grid of filters via cooperative and\ncompetitive excitatory-inhibitory interactions. Several inhibition strategies\nare developed and tested, such as (i) incrementally increasing inhibition level\nover the course of network training, and (ii) switching the inhibition level\nfrom low to high (two-level) after an initial training segment. During the\nlabeling phase, the spiking activity generated by data with known labels is\nused to assign neurons to categories of data, which are then used to evaluate\nthe network's classification ability on a held-out set of test data. Several\nbiologically plausible evaluation rules are proposed and compared, including a\npopulation-level confidence rating, and an $n$-gram inspired method. The\neffectiveness of the proposed self-organized learning mechanism is tested using\nthe MNIST benchmark dataset, as well as using images produced by playing the\nAtari Breakout game.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:44:22 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Hazan", "Hananel", ""], ["Saunders", "Daniel J.", ""], ["Sanghavi", "Darpan T.", ""], ["Siegelmann", "Hava", ""], ["Kozma", "Robert", ""]]}, {"id": "1906.11828", "submitter": "Shaoxing Mo", "authors": "Shaoxing Mo, Nicholas Zabaras, Xiaoqing Shi, Jichun Wu", "title": "Integration of adversarial autoencoders with residual dense\n  convolutional networks for estimation of non-Gaussian hydraulic\n  conductivities", "comments": null, "journal-ref": null, "doi": "10.1029/2019WR026082", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse modeling for the estimation of non-Gaussian hydraulic conductivity\nfields in subsurface flow and solute transport models remains a challenging\nproblem. This is mainly due to the non-Gaussian property, the non-linear\nphysics, and the fact that many repeated evaluations of the forward model are\noften required. In this study, we develop a convolutional adversarial\nautoencoder (CAAE) to parameterize non-Gaussian conductivity fields with\nheterogeneous conductivity within each facies using a low-dimensional latent\nrepresentation. In addition, a deep residual dense convolutional network\n(DRDCN) is proposed for surrogate modeling of forward models with\nhigh-dimensional and highly-complex mappings. The two networks are both based\non a multilevel residual learning architecture called residual-in-residual\ndense block. The multilevel residual learning strategy and the dense connection\nstructure ease the training of deep networks, enabling us to efficiently build\ndeeper networks that have an essentially increased capacity for approximating\nmappings of very high-complexity. The CCAE and DRDCN networks are incorporated\ninto an iterative ensemble smoother to formulate an inversion framework. The\nnumerical experiments performed using 2-D and 3-D solute transport models\nillustrate the performance of the integrated method. The obtained results\nindicate that the CAAE is a robust parameterization method for non-Gaussian\nconductivity fields with different heterogeneity patterns. The DRDCN is able to\nobtain accurate approximations of the forward models with high-dimensional and\nhighly-complex mappings using relatively limited training data. The CAAE and\nDRDCN methods together significantly reduce the computation time required to\nachieve accurate inversion results.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 21:32:20 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 20:06:29 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 09:37:59 GMT"}, {"version": "v4", "created": "Mon, 13 Jan 2020 05:59:03 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Mo", "Shaoxing", ""], ["Zabaras", "Nicholas", ""], ["Shi", "Xiaoqing", ""], ["Wu", "Jichun", ""]]}, {"id": "1906.11829", "submitter": "Cody Coleman", "authors": "Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan\n  Mirzasoleiman, Peter Bailis, Percy Liang, Jure Leskovec, Matei Zaharia", "title": "Selection via Proxy: Efficient Data Selection for Deep Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data selection methods, such as active learning and core-set selection, are\nuseful tools for machine learning on large datasets. However, they can be\nprohibitively expensive to apply in deep learning because they depend on\nfeature representations that need to be learned. In this work, we show that we\ncan greatly improve the computational efficiency by using a small proxy model\nto perform data selection (e.g., selecting data points to label for active\nlearning). By removing hidden layers from the target model, using smaller\narchitectures, and training for fewer epochs, we create proxies that are an\norder of magnitude faster to train. Although these small proxy models have\nhigher error rates, we find that they empirically provide useful signals for\ndata selection. We evaluate this \"selection via proxy\" (SVP) approach on\nseveral data selection tasks across five datasets: CIFAR10, CIFAR100, ImageNet,\nAmazon Review Polarity, and Amazon Review Full. For active learning, applying\nSVP can give an order of magnitude improvement in data selection runtime (i.e.,\nthe time it takes to repeatedly train and select points) without significantly\nincreasing the final error (often within 0.1%). For core-set selection on\nCIFAR10, proxies that are over 10x faster to train than their larger, more\naccurate targets can remove up to 50% of the data without harming the final\naccuracy of the target, leading to a 1.6x end-to-end training time improvement.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 23:01:47 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 22:40:23 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 04:28:27 GMT"}, {"version": "v4", "created": "Tue, 27 Oct 2020 00:52:20 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Coleman", "Cody", ""], ["Yeh", "Christopher", ""], ["Mussmann", "Stephen", ""], ["Mirzasoleiman", "Baharan", ""], ["Bailis", "Peter", ""], ["Liang", "Percy", ""], ["Leskovec", "Jure", ""], ["Zaharia", "Matei", ""]]}, {"id": "1906.11876", "submitter": "William Beluch", "authors": "Jan M.K\\\"ohler, Maximilian Autenrieth, William H. Beluch", "title": "Uncertainty Based Detection and Relabeling of Noisy Image Labels", "comments": "Uncertainty and Robustness in Deep Visual Learning Workshop at CVPR\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful tools in computer vision tasks.\nHowever, in many realistic scenarios label noise is prevalent in the training\nimages, and overfitting to these noisy labels can significantly harm the\ngeneralization performance of DNNs. We propose a novel technique to identify\ndata with noisy labels based on the different distributions of the predictive\nuncertainties from a DNN over the clean and noisy data. Additionally, the\nbehavior of the uncertainty over the course of training helps to identify the\nnetwork weights which best can be used to relabel the noisy labels. Data with\nnoisy labels can therefore be cleaned in an iterative process. Our proposed\nmethod can be easily implemented, and shows promising performance on the task\nof noisy label detection on CIFAR-10 and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:44:38 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["K\u00f6hler", "Jan M.", ""], ["Autenrieth", "Maximilian", ""], ["Beluch", "William H.", ""]]}, {"id": "1906.11880", "submitter": "Aviv Gabbay", "authors": "Aviv Gabbay and Yedid Hoshen", "title": "Style Generator Inversion for Image Enhancement and Animation", "comments": "Project page: http://www.vision.huji.ac.il/style-image-prior", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main motivations for training high quality image generative models\nis their potential use as tools for image manipulation. Recently, generative\nadversarial networks (GANs) have been able to generate images of remarkable\nquality. Unfortunately, adversarially-trained unconditional generator networks\nhave not been successful as image priors. One of the main requirements for a\nnetwork to act as a generative image prior, is being able to generate every\npossible image from the target distribution. Adversarial learning often\nexperiences mode-collapse, which manifests in generators that cannot generate\nsome modes of the target distribution. Another requirement often not satisfied\nis invertibility i.e. having an efficient way of finding a valid input latent\ncode given a required output image. In this work, we show that differently from\nearlier GANs, the very recently proposed style-generators are quite easy to\ninvert. We use this important observation to propose style generators as\ngeneral purpose image priors. We show that style generators outperform other\nGANs as well as Deep Image Prior as priors for image enhancement tasks. The\nlatent space spanned by style-generators satisfies linear identity-pose\nrelations. The latent space linearity, combined with invertibility, allows us\nto animate still facial images without supervision. Extensive experiments are\nperformed to support the main contributions of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:58:28 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Gabbay", "Aviv", ""], ["Hoshen", "Yedid", ""]]}, {"id": "1906.11881", "submitter": "Nicki Skafte Detlefsen", "authors": "Nicki Skafte Detlefsen and S{\\o}ren Hauberg", "title": "Explicit Disentanglement of Appearance and Perspective in Generative\n  Models", "comments": "9 main pages + 2 pages references + 8 pages of supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled representation learning finds compact, independent and\neasy-to-interpret factors of the data. Learning such has been shown to require\nan inductive bias, which we explicitly encode in a generative model of images.\nSpecifically, we propose a model with two latent spaces: one that represents\nspatial transformations of the input data, and another that represents the\ntransformed data. We find that the latter naturally captures the intrinsic\nappearance of the data. To realize the generative model, we propose a\nVariationally Inferred Transformational Autoencoder (VITAE) that incorporates a\nspatial transformer into a variational autoencoder. We show how to perform\ninference in the model efficiently by carefully designing the encoders and\nrestricting the transformation class to be diffeomorphic. Empirically, our\nmodel separates the visual style from digit type on MNIST, separates shape and\npose in images of human bodies and facial features from facial shape on CelebA.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:24:03 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 07:18:04 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Detlefsen", "Nicki Skafte", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "1906.11886", "submitter": "Lucas Possatti", "authors": "Lucas C. Possatti, R\\^anik Guidolini, Vinicius B. Cardoso, Rodrigo F.\n  Berriel, Thiago M. Paix\\~ao, Claudine Badue, Alberto F. De Souza and Thiago\n  Oliveira-Santos", "title": "Traffic Light Recognition Using Deep Learning and Prior Maps for\n  Autonomous Cars", "comments": "Accepted in 2019 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8851927", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous terrestrial vehicles must be capable of perceiving traffic lights\nand recognizing their current states to share the streets with human drivers.\nMost of the time, human drivers can easily identify the relevant traffic\nlights. To deal with this issue, a common solution for autonomous cars is to\nintegrate recognition with prior maps. However, additional solution is required\nfor the detection and recognition of the traffic light. Deep learning\ntechniques have showed great performance and power of generalization including\ntraffic related problems. Motivated by the advances in deep learning, some\nrecent works leveraged some state-of-the-art deep detectors to locate (and\nfurther recognize) traffic lights from 2D camera images. However, none of them\ncombine the power of the deep learning-based detectors with prior maps to\nrecognize the state of the relevant traffic lights. Based on that, this work\nproposes to integrate the power of deep learning-based detection with the prior\nmaps used by our car platform IARA (acronym for Intelligent Autonomous Robotic\nAutomobile) to recognize the relevant traffic lights of predefined routes. The\nprocess is divided in two phases: an offline phase for map construction and\ntraffic lights annotation; and an online phase for traffic light recognition\nand identification of the relevant ones. The proposed system was evaluated on\nfive test cases (routes) in the city of Vit\\'oria, each case being composed of\na video sequence and a prior map with the relevant traffic lights for the\nroute. Results showed that the proposed technique is able to correctly identify\nthe relevant traffic light along the trajectory.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:05:25 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Possatti", "Lucas C.", ""], ["Guidolini", "R\u00e2nik", ""], ["Cardoso", "Vinicius B.", ""], ["Berriel", "Rodrigo F.", ""], ["Paix\u00e3o", "Thiago M.", ""], ["Badue", "Claudine", ""], ["De Souza", "Alberto F.", ""], ["Oliveira-Santos", "Thiago", ""]]}, {"id": "1906.11889", "submitter": "Lena A. J\\\"ager", "authors": "Lena A. J\\\"ager, Silvia Makowski, Paul Prasse, Sascha Liehr,\n  Maximilian Seidler and Tobias Scheffer", "title": "Deep Eyedentification: Biometric Identification using Micro-Movements of\n  the Eye", "comments": null, "journal-ref": "In: U. Brefeld et al. (Eds.): Machine Learning and Knowledge\n  Discovery in Databases, ECML PKDD 2019, LNCS 11907, pp. 299-314, Springer\n  Nature, Switzerland, 2020", "doi": "10.1007/978-3-030-46147-8_18", "report-no": null, "categories": "cs.CV cs.CL cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study involuntary micro-movements of the eye for biometric identification.\nWhile prior studies extract lower-frequency macro-movements from the output of\nvideo-based eye-tracking systems and engineer explicit features of these\nmacro-movements, we develop a deep convolutional architecture that processes\nthe raw eye-tracking signal. Compared to prior work, the network attains a\nlower error rate by one order of magnitude and is faster by two orders of\nmagnitude: it identifies users accurately within seconds.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:36:40 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 08:27:02 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 05:14:56 GMT"}, {"version": "v4", "created": "Wed, 15 Apr 2020 10:06:31 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 08:30:44 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["J\u00e4ger", "Lena A.", ""], ["Makowski", "Silvia", ""], ["Prasse", "Paul", ""], ["Liehr", "Sascha", ""], ["Seidler", "Maximilian", ""], ["Scheffer", "Tobias", ""]]}, {"id": "1906.11892", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin and Negar Rostamzadeh and Pedro O. Pinheiro and\n  Christopher Pal", "title": "CLAREL: Classification via retrieval loss for zero-shot learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning fine-grained cross-modal representations.\nWe propose an instance-based deep metric learning approach in joint visual and\ntextual space. The key novelty of this paper is that it shows that using\nper-image semantic supervision leads to substantial improvement in zero-shot\nperformance over using class-only supervision. On top of that, we provide a\nprobabilistic justification for a metric rescaling approach that solves a very\ncommon problem in the generalized zero-shot learning setting, i.e., classifying\ntest images from unseen classes as one of the classes seen during training. We\nevaluate our approach on two fine-grained zero-shot learning datasets: CUB and\nFLOWERS. We find that on the generalized zero-shot classification task CLAREL\nconsistently outperforms the existing approaches on both datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:24:53 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:37:48 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 14:59:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Rostamzadeh", "Negar", ""], ["Pinheiro", "Pedro O.", ""], ["Pal", "Christopher", ""]]}, {"id": "1906.11895", "submitter": "Simon Tamayo Giraldo", "authors": "Salma Benslimane, Simon Tamayo (CAOR), Arnaud de La Fortelle (CAOR)", "title": "Classifying logistic vehicles in cities using Deep learning", "comments": null, "journal-ref": "World Conference on Transport Research, May 2019, Mumbai, India", "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid growth in delivery and freight transportation is increasing in urban\nareas; as a result the use of delivery trucks and light commercial vehicles is\nevolving. Major cities can use traffic counting as a tool to monitor the\npresence of delivery vehicles in order to implement intelligent city planning\nmeasures. Classical methods for counting vehicles use mechanical,\nelectromagnetic or pneumatic sensors, but these devices are costly, difficult\nto implement and only detect the presence of vehicles without giving\ninformation about their category, model or trajectory. This paper proposes a\nDeep Learning tool for classifying vehicles in a given image while considering\ndifferent categories of logistic vehicles, namely: light-duty, medium-duty and\nheavy-duty vehicles. The proposed approach yields two main contributions: first\nwe developed an architecture to create an annotated and balanced database of\nlogistic vehicles, reducing manual annotation efforts. Second, we built a\nclassifier that accurately classifies the logistic vehicles passing through a\ngiven road. The results of this work are: first, a database of 72 000 images\nfor 4 vehicles classes; and second two retrained convolutional neural networks\n(InceptionV3 and MobileNetV2) capable of classifying vehicles with accuracies\nover 90%.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 09:05:20 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Benslimane", "Salma", "", "CAOR"], ["Tamayo", "Simon", "", "CAOR"], ["de La Fortelle", "Arnaud", "", "CAOR"]]}, {"id": "1906.11897", "submitter": "Mark Lee", "authors": "Mark Lee, Zico Kolter", "title": "On Physical Adversarial Patches for Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate a physical adversarial patch attack against\nobject detectors, notably the YOLOv3 detector. Unlike previous work on physical\nobject detection attacks, which required the patch to overlap with the objects\nbeing misclassified or avoiding detection, we show that a properly designed\npatch can suppress virtually all the detected objects in the image. That is, we\ncan place the patch anywhere in the image, causing all existing objects in the\nimage to be missed entirely by the detector, even those far away from the patch\nitself. This in turn opens up new lines of physical attacks against object\ndetection systems, which require no modification of the objects in a scene. A\ndemo of the system can be found at https://youtu.be/WXnQjbZ1e7Y.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:04:57 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Lee", "Mark", ""], ["Kolter", "Zico", ""]]}, {"id": "1906.11898", "submitter": "L\\'eonard Boussioux", "authors": "L\\'eonard Boussioux, Tom\\'as Giro-Larraz, Charles Guille-Escuret,\n  Mehdi Cherti, Bal\\'azs K\\'egl", "title": "InsectUp: Crowdsourcing Insect Observations to Assess Demographic Shifts\n  and Improve Classification", "comments": "Appearing at the International Conference on Machine Learning, AI for\n  Social Good Workshop, Long Beach, United States, 2019 Appearing at the\n  International Conference on Computer Vision, AI for Wildlife Conservation\n  Workshop, Seoul, South Korea, 2019 5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insects play such a crucial role in ecosystems that a shift in demography of\njust a few species can have devastating consequences at environmental, social\nand economic levels. Despite this, evaluation of insect demography is strongly\nlimited by the difficulty of collecting census data at sufficient scale. We\npropose a method to gather and leverage observations from bystanders, hikers,\nand entomology enthusiasts in order to provide researchers with data that could\nsignificantly help anticipate and identify environmental threats. Finally, we\nshow that there is indeed interest on both sides for such collaboration.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:57:15 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:39:03 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Boussioux", "L\u00e9onard", ""], ["Giro-Larraz", "Tom\u00e1s", ""], ["Guille-Escuret", "Charles", ""], ["Cherti", "Mehdi", ""], ["K\u00e9gl", "Bal\u00e1zs", ""]]}, {"id": "1906.11899", "submitter": "Farzad Shafiei Dizaji", "authors": "Farzad Shafiei Dizaji", "title": "Lidar based Detection and Classification of Pedestrians and Vehicles\n  Using Machine Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to classify objects mapped by LiDAR sensor into\ndifferent classes such as vehicles, pedestrians and bikers. Utilizing a\nLiDAR-based object detector and Neural Networks-based classifier, a novel\nreal-time object detection is presented essentially with respect to aid\nself-driving vehicles in recognizing and classifying other objects encountered\nin the course of driving and proceed accordingly. We discuss our work using\nmachine learning methods to tackle a common high-level problem found in machine\nlearning applications for self-driving cars: the classification of pointcloud\ndata obtained from a 3D LiDAR sensor.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 01:39:45 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Dizaji", "Farzad Shafiei", ""]]}, {"id": "1906.11901", "submitter": "Jean-Luc Meunier", "authors": "St\\'ephane Clinchant, Herv\\'e D\\'ejean, Jean-Luc Meunier, Eva Lang,\n  Florian Kleber", "title": "Comparing Machine Learning Approaches for Table Recognition in\n  Historical Register Books", "comments": "DAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper experiments on Table Recognition in hand-written\nregistry books. We first explain how the problem of row and column detection is\nmodeled, and then compare two Machine Learning approaches (Conditional Random\nField and Graph Convolutional Network) for detecting these table elements.\nEvaluation was conducted on death records provided by the Archive of the\nDiocese of Passau. Both methods show similar results, a 89 F1 score, a quality\nwhich allows for Information Extraction. Software and dataset are open\nsource/data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:42:47 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Clinchant", "St\u00e9phane", ""], ["D\u00e9jean", "Herv\u00e9", ""], ["Meunier", "Jean-Luc", ""], ["Lang", "Eva", ""], ["Kleber", "Florian", ""]]}, {"id": "1906.11902", "submitter": "Roshan Prakash Rane", "authors": "Roshan Rane, Edit Sz\\\"ugyi, Vageesh Saxena, Andr\\'e Ofner, Sebastian\n  Stober", "title": "PredNet and Predictive Coding: A Critical Review", "comments": null, "journal-ref": null, "doi": "10.1145/3372278.3390694", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PredNet, a deep predictive coding network developed by Lotter et al.,\ncombines a biologically inspired architecture based on the propagation of\nprediction error with self-supervised representation learning in video. While\nthe architecture has drawn a lot of attention and various extensions of the\nmodel exist, there is a lack of a critical analysis. We fill in the gap by\nevaluating PredNet both as an implementation of the predictive coding theory\nand as a self-supervised video prediction model using a challenging video\naction classification dataset. We design an extended model to test if\nconditioning future frame predictions on the action class of the video improves\nthe model performance. We show that PredNet does not yet completely follow the\nprinciples of predictive coding. The proposed top-down conditioning leads to a\nperformance gain on synthetic data, but does not scale up to the more complex\nreal-world action classification dataset. Our analysis is aimed at guiding\nfuture research on similar architectures based on the predictive coding theory.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 21:58:00 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:29:05 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 09:52:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Rane", "Roshan", ""], ["Sz\u00fcgyi", "Edit", ""], ["Saxena", "Vageesh", ""], ["Ofner", "Andr\u00e9", ""], ["Stober", "Sebastian", ""]]}, {"id": "1906.11904", "submitter": "Natalya Pya Arnqvist", "authors": "Natalya Pya Arnqvist, Blaise Ngendangenzwa, Eric Lindahl, Leif\n  Nilsson, Jun Yu", "title": "Effective degrees of freedom for surface finish defect detection and\n  classification", "comments": "17 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary concerns of product quality control in the automotive\nindustry is an automated detection of defects of small sizes on specular car\nbody surfaces. A new statistical learning approach is presented for surface\nfinish defect detection based on spline smoothing method for feature extraction\nand $k$-nearest neighbour probabilistic classifier. Since the surfaces are\nspecular, structured lightning reflection technique is applied for image\nacquisition. Reduced rank cubic regression splines are used to smooth the pixel\nvalues while the effective degrees of freedom of the obtained smooths serve as\ncomponents of the feature vector. A key advantage of the approach is that it\nallows reaching near zero misclassification error rate when applying standard\nlearning classifiers. We also propose probability based performance evaluation\nmetrics as alternatives to the conventional metrics. The usage of those\nprovides the means for uncertainty estimation of the predictive performance of\na classifier. Experimental classification results on the images obtained from\nthe pilot system located at Volvo GTO Cab plant in Ume{\\aa}, Sweden, show that\nthe proposed approach is much more efficient than the compared methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:13:52 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Arnqvist", "Natalya Pya", ""], ["Ngendangenzwa", "Blaise", ""], ["Lindahl", "Eric", ""], ["Nilsson", "Leif", ""], ["Yu", "Jun", ""]]}, {"id": "1906.11905", "submitter": "Xinjie Lan", "authors": "Xinjie Lan", "title": "A synthetic dataset for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for generating a synthetic dataset\nobeying Gaussian distribution. Compared to the commonly used benchmark datasets\nwith unknown distribution, the synthetic dataset has an explicit distribution,\ni.e., Gaussian distribution. Meanwhile, it has the same characteristics as the\nbenchmark dataset MNIST. As a result, we can easily apply Deep Neural Networks\n(DNNs) on the synthetic dataset. This synthetic dataset provides a novel\nexperimental tool to verify the proposed theories of deep learning.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 05:16:40 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Lan", "Xinjie", ""]]}, {"id": "1906.11909", "submitter": "Sebastian Riedel", "authors": "Sebastian Riedel and Freek Stulp", "title": "Comparing Semi-Parametric Model Learning Algorithms for Dynamic Model\n  Estimation in Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical modeling of robotic system behavior is the foundation for\ncontrolling many robotic mechanisms to a satisfactory degree. Mechanisms are\nalso typically designed in a way that good model accuracy can be achieved with\nrelatively simple models and model identification strategies. If the modeling\naccuracy using physically based models is not enough or too complex, model-free\nmethods based on machine learning techniques can help. Of particular interest\nto us was therefore the question to what degree semi-parametric modeling\ntechniques, meaning combinations of physical models with machine learning,\nincrease the modeling accuracy of inverse dynamics models which are typically\nused in robot control. To this end, we evaluated semi-parametric Gaussian\nprocess regression and a novel model-based neural network architecture, and\ncompared their modeling accuracy to a series of naive semi-parametric,\nparametric-only and non-parametric-only regression methods. The comparison has\nbeen carried out on three test scenarios, one involving a real test-bed and two\ninvolving simulated scenarios, with the most complex scenario targeting the\nmodeling a simulated robot's inverse dynamics model. We found that in all but\none case, semi-parametric Gaussian process regression yields the most accurate\nmodels, also with little tuning required for the training procedure.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 18:56:04 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Riedel", "Sebastian", ""], ["Stulp", "Freek", ""]]}, {"id": "1906.11923", "submitter": "Victor-Emmanuel Brunel", "authors": "Marco Avella-Medina and Victor-Emmanuel Brunel", "title": "Differentially private sub-Gaussian location estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of estimating a location parameter with differential\nprivacy guarantees and sub-Gaussian deviations. Recent work in statistics has\nfocused on the study of estimators that achieve sub-Gaussian type deviations\neven for heavy tailed data. We revisit some of these estimators through the\nlens of differential privacy and show that a naive application of the Laplace\nmechanism can lead to sub-optimal results. We design two private algorithms for\nestimating the median that lead to estimators with sub-Gaussian type errors.\nUnlike most existing differentially private median estimators, both algorithms\nare well defined for unbounded random variables that are not even required to\nhave finite moments. We then turn to the problem of sub-Gaussian mean\nestimation and show that under heavy tails natural differentially private\nalternatives lead to strictly worse deviations than their non-private\nsub-Gaussian counterparts. This is in sharp contrast with recent results that\nshow that from an asymptotic perspective the cost of differential privacy is\nnegligible.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 19:21:30 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Avella-Medina", "Marco", ""], ["Brunel", "Victor-Emmanuel", ""]]}, {"id": "1906.11928", "submitter": "Mason Youngblood", "authors": "Mason Youngblood", "title": "Conformity bias in the cultural transmission of music sampling\n  traditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the fundamental questions of cultural evolutionary research is how\nindividual-level processes scale up to generate population-level patterns.\nPrevious studies in music have revealed that frequency-based bias (e.g.\nconformity and novelty) drives large-scale cultural diversity in different ways\nacross domains and levels of analysis. Music sampling is an ideal research\nmodel for this process because samples are known to be culturally transmitted\nbetween collaborating artists, and sampling events are reliably documented in\nonline databases. The aim of the current study was to determine whether\nfrequency-based bias has played a role in the cultural transmission of music\nsampling traditions, using a longitudinal dataset of sampling events across\nthree decades. Firstly, we assessed whether turn-over rates of popular samples\ndiffer from those expected under neutral evolution. Next, we used agent-based\nsimulations in an approximate Bayesian computation framework to infer what\nlevel of frequency-based bias likely generated the observed data. Despite\nanecdotal evidence of novelty bias, we found that sampling patterns at the\npopulation-level are most consistent with conformity bias.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 19:34:45 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Youngblood", "Mason", ""]]}, {"id": "1906.11941", "submitter": "Oliver Richter", "authors": "Oliver Richter and Roger Wattenhofer", "title": "Learning Policies through Quantile Regression", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient based reinforcement learning algorithms coupled with neural\nnetworks have shown success in learning complex policies in the model free\ncontinuous action space control setting. However, explicitly parameterized\npolicies are limited by the scope of the chosen parametric probability\ndistribution. We show that alternatively to the likelihood based policy\ngradient, a related objective can be optimized through advantage weighted\nquantile regression. Our approach models the policy implicitly in the network,\nwhich gives the agent the freedom to approximate any distribution in each\naction dimension, not limiting its capabilities to the commonly used unimodal\nGaussian parameterization. This broader spectrum of policies makes our\nalgorithm suitable for problems where Gaussian policies cannot fit the optimal\npolicy. Moreover, our results on the MuJoCo physics simulator benchmarks are\ncomparable or superior to state-of-the-art on-policy methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:15:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:55:21 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1906.11951", "submitter": "Evan Racah Mr.", "authors": "Evan Racah, Christopher Pal", "title": "Supervise Thyself: Examining Self-Supervised Representations in\n  Interactive Environments", "comments": "Accepted to the 2019 ICML Workshop on Self-Supervised Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised methods, wherein an agent learns representations solely by\nobserving the results of its actions, become crucial in environments which do\nnot provide a dense reward signal or have labels. In most cases, such methods\nare used for pretraining or auxiliary tasks for \"downstream\" tasks, such as\ncontrol, exploration, or imitation learning. However, it is not clear which\nmethod's representations best capture meaningful features of the environment,\nand which are best suited for which types of environments. We present a\nsmall-scale study of self-supervised methods on two visual environments: Flappy\nBird and Sonic The Hedgehog. In particular, we quantitatively evaluate the\nrepresentations learned from these tasks in two contexts: a) the extent to\nwhich the representations capture true state information of the agent and b)\nhow generalizable these representations are to novel situations, like new\nlevels and textures. Lastly, we evaluate these self-supervised features by\nvisualizing which parts of the environment they focus on. Our results show that\nthe utility of the representations is highly dependent on the visuals and\ndynamics of the environment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:38:47 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Racah", "Evan", ""], ["Pal", "Christopher", ""]]}, {"id": "1906.11957", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Mehran Pesteie, Eitan Prisman, Purang Abolmaesumi,\n  Sidney Fels", "title": "Variational Shape Completion for Virtual Planning of Jaw Reconstructive\n  Surgery", "comments": "Proceedings of Medical Image Computing and Computer Assisted\n  Intervention - {MICCAI} 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32254-0\\_26", "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The premorbid geometry of the mandible is of significant relevance in jaw\nreconstructive surgeries and occasionally unknown to the surgical team. In this\npaper, an optimization framework is introduced to train deep models for\ncompletion (reconstruction) of the missing segments of the bone based on the\nremaining healthy structure. To leverage the contextual information of the\nsurroundings of the dissected region, the voxel-weighted Dice loss is\nintroduced. To address the non-deterministic nature of the shape completion\nproblem, we leverage a weighted multi-target probabilistic solution which is an\nextension to the conditional variational autoencoder (CVAE). This approach\nconsiders multiple targets as acceptable reconstructions, each weighted\naccording to their conformity with the original shape. We quantify the\nperformance gain of the proposed method against similar algorithms, including\nCVAE, where we report statistically significant improvements in both\ndeterministic and probabilistic paradigms. The probabilistic model is also\nevaluated on its ability to generate anatomically relevant variations for the\nmissing bone. As a unique aspect of this work, the model is tested on real\nsurgical cases where the clinical relevancy of its reconstructions and their\ncompliance with surgeon's virtual plan are demonstrated as necessary steps\ntowards clinical adoption.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:45:46 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 23:42:47 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 18:44:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Abdi", "Amir H.", ""], ["Pesteie", "Mehran", ""], ["Prisman", "Eitan", ""], ["Abolmaesumi", "Purang", ""], ["Fels", "Sidney", ""]]}, {"id": "1906.11985", "submitter": "Nimit Sohoni", "authors": "Oliver Hinder and Aaron Sidford and Nimit Sharad Sohoni", "title": "Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide near-optimal accelerated first-order methods for\nminimizing a broad class of smooth nonconvex functions that are strictly\nunimodal on all lines through a minimizer. This function class, which we call\nthe class of smooth quasar-convex functions, is parameterized by a constant\n$\\gamma \\in (0,1]$, where $\\gamma = 1$ encompasses the classes of smooth convex\nand star-convex functions, and smaller values of $\\gamma$ indicate that the\nfunction can be \"more nonconvex.\" We develop a variant of accelerated gradient\ndescent that computes an $\\epsilon$-approximate minimizer of a smooth\n$\\gamma$-quasar-convex function with at most $O(\\gamma^{-1} \\epsilon^{-1/2}\n\\log(\\gamma^{-1} \\epsilon^{-1}))$ total function and gradient evaluations. We\nalso derive a lower bound of $\\Omega(\\gamma^{-1} \\epsilon^{-1/2})$ on the\nnumber of gradient evaluations required by any deterministic first-order method\nin the worst case, showing that, up to a logarithmic factor, no deterministic\nfirst-order algorithm can improve upon ours.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 22:39:35 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Hinder", "Oliver", ""], ["Sidford", "Aaron", ""], ["Sohoni", "Nimit Sharad", ""]]}, {"id": "1906.11994", "submitter": "Chaoyang He", "authors": "Chaoyang He, Tian Xie, Yu Rong, Wenbing Huang, Junzhou Huang, Xiang\n  Ren, Cyrus Shahabi", "title": "Cascade-BGNN: Toward Efficient Self-supervised Representation Learning\n  on Large-scale Bipartite Graphs", "comments": "KDD 2020 Submission. Our code is open-sourced at\n  https://github.com/chaoyanghe/bipartite-graph-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bipartite graphs have been used to represent data relationships in many\ndata-mining applications such as in E-commerce recommendation systems. Since\nlearning in graph space is more complicated than in Euclidian space, recent\nstudies have extensively utilized neural nets to effectively and efficiently\nembed a graph's nodes into a multidimensional space. However, this embedding\nmethod has not yet been applied to large-scale bipartite graphs. Existing\ntechniques either cannot be scaled to large-scale bipartite graphs that have\nlimited labels or cannot exploit the unique structure of bipartite graphs,\nwhich have distinct node features in two domains. Thus, we propose Cascade\nBipartite Graph Neural Networks, Cascade-BGNN, a novel node representation\nlearning for bipartite graphs that is domain-consistent, self-supervised, and\nefficient. To efficiently aggregate information both across and within the two\npartitions of a bipartite graph, BGNN utilizes a customized Inter-domain\nMessage Passing (IDMP) and Intra-domain Alignment (IDA), which is our\nadaptation of adversarial learning, for message aggregation across and within\npartitions, respectively. BGNN is trained in a self-supervised manner.\nMoreover, we formulate a multi-layer BGNN in a cascaded training manner to\nenable multi-hop relationship modeling while improving training efficiency.\nExtensive experiments on several datasets of varying scales verify the\neffectiveness and efficiency of BGNN over baselines. Our design is further\naffirmed through theoretical analysis for domain alignment. The scalability of\nBGNN is additionally verified through its demonstrated rapid training speed and\nlow memory cost over a large-scale real-world bipartite graph.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 23:34:45 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 20:25:05 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 06:35:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["He", "Chaoyang", ""], ["Xie", "Tian", ""], ["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Huang", "Junzhou", ""], ["Ren", "Xiang", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1906.12005", "submitter": "Sina Baharlouei", "authors": "Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, Meisam Razaviyayn", "title": "R\\'enyi Fair Inference", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have been increasingly deployed in critical\nautomated decision-making systems that directly affect human lives. When these\nalgorithms are only trained to minimize the training/test error, they could\nsuffer from systematic discrimination against individuals based on their\nsensitive attributes such as gender or race. Recently, there has been a surge\nin machine learning society to develop algorithms for fair machine learning. In\nparticular, many adversarial learning procedures have been proposed to impose\nfairness. Unfortunately, these algorithms either can only impose fairness up to\nfirst-order dependence between the variables, or they lack computational\nconvergence guarantees. In this paper, we use R\\'enyi correlation as a measure\nof fairness of machine learning models and develop a general training framework\nto impose fairness. In particular, we propose a min-max formulation which\nbalances the accuracy and fairness when solved to optimality. For the case of\ndiscrete sensitive attributes, we suggest an iterative algorithm with\ntheoretical convergence guarantee for solving the proposed min-max problem. Our\nalgorithm and analysis are then specialized to fair classification and the fair\nclustering problem under disparate impact doctrine. Finally, the performance of\nthe proposed R\\'enyi fair inference framework is evaluated on Adult and Bank\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 00:36:30 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 02:51:47 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Baharlouei", "Sina", ""], ["Nouiehed", "Maher", ""], ["Beirami", "Ahmad", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "1906.12024", "submitter": "Kevin Bello", "authors": "Asish Ghoshal and Kevin Bello and Jean Honorio", "title": "Direct Learning with Guarantees of the Difference DAG Between Structural\n  Equation Models", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering cause-effect relationships between variables from observational\ndata is a fundamental challenge in many scientific disciplines. However, in\nmany situations it is desirable to directly estimate the change in causal\nrelationships across two different conditions, e.g., estimating the change in\ngenetic expression across healthy and diseased subjects can help isolate\ngenetic factors behind the disease. This paper focuses on the problem of\ndirectly estimating the structural difference between two structural equation\nmodels (SEMs), having the same topological ordering, given two sets of samples\ndrawn from the individual SEMs. We present an principled algorithm that can\nrecover the difference SEM in $\\mathcal{O}(d^2 \\log p)$ samples, where $d$ is\nrelated to the number of edges in the difference SEM of $p$ nodes. We also\nstudy the fundamental limits and show that any method requires at least\n$\\Omega(d' \\log \\frac{p}{d'})$ samples to learn difference SEMs with at most\n$d'$ parents per node. Finally, we validate our theoretical results with\nsynthetic experiments and show that our method outperforms the\nstate-of-the-art. Moreover, we show the usefulness of our method by using data\nfrom the medical domain.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 03:04:02 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 05:36:34 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ghoshal", "Asish", ""], ["Bello", "Kevin", ""], ["Honorio", "Jean", ""]]}, {"id": "1906.12043", "submitter": "Shuheng Shen", "authors": "Shuheng Shen and Linli Xu and Jingchang Liu and Xianfeng Liang and\n  Yifei Cheng", "title": "Faster Distributed Deep Net Training: Computation and Communication\n  Decoupled Stochastic Gradient Descent", "comments": "IJCAI2019, 20 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in the amount of data and the expansion of model scale,\ndistributed parallel training becomes an important and successful technique to\naddress the optimization challenges. Nevertheless, although distributed\nstochastic gradient descent (SGD) algorithms can achieve a linear iteration\nspeedup, they are limited significantly in practice by the communication cost,\nmaking it difficult to achieve a linear time speedup. In this paper, we propose\na computation and communication decoupled stochastic gradient descent\n(CoCoD-SGD) algorithm to run computation and communication in parallel to\nreduce the communication cost. We prove that CoCoD-SGD has a linear iteration\nspeedup with respect to the total computation capability of the hardware\nresources. In addition, it has a lower communication complexity and better time\nspeedup comparing with traditional distributed SGD algorithms. Experiments on\ndeep neural network training demonstrate the significant improvements of\nCoCoD-SGD: when training ResNet18 and VGG16 with 16 Geforce GTX 1080Ti GPUs,\nCoCoD-SGD is up to 2-3$\\times$ faster than traditional synchronous SGD.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 05:20:05 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 05:35:35 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Shen", "Shuheng", ""], ["Xu", "Linli", ""], ["Liu", "Jingchang", ""], ["Liang", "Xianfeng", ""], ["Cheng", "Yifei", ""]]}, {"id": "1906.12056", "submitter": "Bao Wang", "authors": "Bao Wang, Quanquan Gu, March Boedihardjo, Farzin Barekat, Stanley J.\n  Osher", "title": "DP-LSSGD: A Stochastic Optimization Method to Lift the Utility in\n  Privacy-Preserving ERM", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models trained by differentially private stochastic\ngradient descent (DP-SGD) have much lower utility than the non-private ones. To\nmitigate this degradation, we propose a DP Laplacian smoothing SGD (DP-LSSGD)\nto train ML models with differential privacy (DP) guarantees. At the core of\nDP-LSSGD is the Laplacian smoothing, which smooths out the Gaussian noise used\nin the Gaussian mechanism. Under the same amount of noise used in the Gaussian\nmechanism, DP-LSSGD attains the same DP guarantee, but in practice, DP-LSSGD\nmakes training both convex and nonconvex ML models more stable and enables the\ntrained models to generalize better. The proposed algorithm is simple to\nimplement and the extra computational complexity and memory overhead compared\nwith DP-SGD are negligible. DP-LSSGD is applicable to train a large variety of\nML models, including DNNs. The code is available at\n\\url{https://github.com/BaoWangMath/DP-LSSGD}.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 06:25:41 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 07:49:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Wang", "Bao", ""], ["Gu", "Quanquan", ""], ["Boedihardjo", "March", ""], ["Barekat", "Farzin", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1906.12061", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Aaron Havens, Girish Chowdhary, Soumik Sarkar", "title": "Learning to Cope with Adversarial Attacks", "comments": "arXiv paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of Deep Reinforcement Learning (Deep RL) algorithms deployed in\nreal life applications are of a primary concern. In particular, the robustness\nof RL agents in cyber-physical systems against adversarial attacks are\nespecially vital since the cost of a malevolent intrusions can be extremely\nhigh. Studies have shown Deep Neural Networks (DNN), which forms the core\ndecision-making unit in most modern RL algorithms, are easily subjected to\nadversarial attacks. Hence, it is imperative that RL agents deployed in\nreal-life applications have the capability to detect and mitigate adversarial\nattacks in an online fashion. An example of such a framework is the\nMeta-Learned Advantage Hierarchy (MLAH) agent that utilizes a meta-learning\nframework to learn policies robustly online. Since the mechanism of this\nframework are still not fully explored, we conducted multiple experiments to\nbetter understand the framework's capabilities and limitations. Our results\nshows that the MLAH agent exhibits interesting coping behaviors when subjected\nto different adversarial attacks to maintain a nominal reward. Additionally,\nthe framework exhibits a hierarchical coping capability, based on the\nadaptability of the Master policy and sub-policies themselves. From empirical\nresults, we also observed that as the interval of adversarial attacks increase,\nthe MLAH agent can maintain a higher distribution of rewards, though at the\ncost of higher instabilities.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:10:30 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Havens", "Aaron", ""], ["Chowdhary", "Girish", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1906.12063", "submitter": "Simon Luo", "authors": "Simon Luo and Mahito Sugiyama", "title": "Bias-Variance Trade-Off in Hierarchical Probabilistic Models Using\n  Higher-Order Feature Interactions", "comments": "8 pages, 28 figures, accepted to the Thirty-Third AAAI Conference on\n  Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical probabilistic models are able to use a large number of\nparameters to create a model with a high representation power. However, it is\nwell known that increasing the number of parameters also increases the\ncomplexity of the model which leads to a bias-variance trade-off. Although it\nis a classical problem, the bias-variance trade-off between hidden layers and\nhigher-order interactions have not been well studied. In our study, we propose\nan efficient inference algorithm for the log-linear formulation of the\nhigher-order Boltzmann machine using a combination of Gibbs sampling and\nannealed importance sampling. We then perform a bias-variance decomposition to\nstudy the differences in hidden layers and higher-order interactions. Our\nresults have shown that using hidden layers and higher-order interactions have\na comparable error with a similar order of magnitude and using higher-order\ninteractions produce less variance for smaller sample size.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:14:34 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Luo", "Simon", ""], ["Sugiyama", "Mahito", ""]]}, {"id": "1906.12072", "submitter": "Yohann de Castro", "authors": "J.-M. Aza\\\"is and Y. De Castro", "title": "Multiple Testing and Variable Selection along Least Angle Regression's\n  path", "comments": "62 pages; new: FDR control and power comparison between Knockoff,\n  FCD, Slope and our proposed method; new: the introduction has been revised\n  and now present a synthetic presentation of the main results. We believe that\n  this introduction brings new insists compared to previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we investigate multiple testing and variable selection using\nLeast Angle Regression (LARS) algorithm in high dimensions under the Gaussian\nnoise assumption. LARS is known to produce a piecewise affine solutions path\nwith change points referred to as knots of the LARS path. The cornerstone of\nthe present work is the expression in closed form of the exact joint law of\nK-uplets of knots conditional on the variables selected by LARS, namely the\nso-called post-selection joint law of the LARS knots. Numerical experiments\ndemonstrate the perfect fit of our finding.\n  Our main contributions are three fold. First, we build testing procedures on\nvariables entering the model along the LARS path in the general design case\nwhen the noise level can be unknown. This testing procedures are referred to as\nthe Generalized t-Spacing tests (GtSt) and we prove that they have exact\nnon-asymptotic level (i.e., Type I error is exactly controlled). In that way,\nwe extend a work from (Taylor et al., 2014) where the Spacing test works for\nconsecutive knots and known variance. Second, we introduce a new exact multiple\nfalse negatives test after model selection in the general design case when the\nnoise level can be unknown. We prove that this testing procedure has exact\nnon-asymptotic level for general design and unknown noise level. Last, we give\nan exact control of the false discovery rate (FDR) under orthogonal design\nassumption. Monte-Carlo simulations and a real data experiment are provided to\nillustrate our results in this case. Of independent interest, we introduce an\nequivalent formulation of LARS algorithm based on a recursive function.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:43:43 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 22:50:10 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 12:16:42 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Aza\u00efs", "J. -M.", ""], ["De Castro", "Y.", ""]]}, {"id": "1906.12077", "submitter": "Remi Flamary", "authors": "Laurent Dragoni, R\\'emi Flamary, Karim Lounici, Patricia\n  Reynaud-Bouret", "title": "Large scale Lasso with windowed active set for convolutional spike\n  sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.OC stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike sorting is a fundamental preprocessing step in neuroscience that is\ncentral to access simultaneous but distinct neuronal activities and therefore\nto better understand the animal or even human brain. But numerical complexity\nlimits studies that require processing large scale datasets in terms of number\nof electrodes, neurons, spikes and length of the recorded signals. We propose\nin this work a novel active set algorithm aimed at solving the Lasso for a\nclassical convolutional model. Our algorithm can be implemented efficiently on\nparallel architecture and has a linear complexity w.r.t. the temporal\ndimensionality which ensures scaling and will open the door to online spike\nsorting. We provide theoretical results about the complexity of the algorithm\nand illustrate it in numerical experiments along with results about the\naccuracy of the spike recovery and robustness to the regularization parameter.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:48:04 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Dragoni", "Laurent", ""], ["Flamary", "R\u00e9mi", ""], ["Lounici", "Karim", ""], ["Reynaud-Bouret", "Patricia", ""]]}, {"id": "1906.12085", "submitter": "Xiaocan Li", "authors": "Xiaocan Li, Shuo Wang, Yinghao Cai", "title": "Tutorial: Complexity analysis of Singular Value Decomposition and its\n  variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compared the regular Singular Value Decomposition (SVD), truncated SVD,\nKrylov method and Randomized PCA, in terms of time and space complexity. It is\nwell-known that Krylov method and Randomized PCA only performs well when k <<\nn, i.e. the number of eigenpair needed is far less than that of matrix size. We\ncompared them for calculating all the eigenpairs. We also discussed the\nrelationship between Principal Component Analysis and SVD.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:17:53 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 03:25:43 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 10:44:32 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Xiaocan", ""], ["Wang", "Shuo", ""], ["Cai", "Yinghao", ""]]}, {"id": "1906.12086", "submitter": "Sebastian Curi", "authors": "Marcello Fiducioso, Sebastian Curi, Benedikt Schumacher, Markus\n  Gwerder, Andreas Krause", "title": "Safe Contextual Bayesian Optimization for Sustainable Room Temperature\n  PID Control Tuning", "comments": "7 pages; Published in IJCAI 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tune one of the most common heating, ventilation, and air conditioning\n(HVAC) control loops, namely the temperature control of a room. For economical\nand environmental reasons, it is of prime importance to optimize the\nperformance of this system. Buildings account from 20 to 40% of a country\nenergy consumption, and almost 50% of it comes from HVAC systems. Scenario\nprojections predict a 30% decrease in heating consumption by 2050 due to\nefficiency increase. Advanced control techniques can improve performance;\nhowever, the proportional-integral-derivative (PID) control is typically used\ndue to its simplicity and overall performance. We use Safe Contextual Bayesian\nOptimization to optimize the PID parameters without human intervention. We\nreduce costs by 32% compared to the current PID controller setting while\nassuring safety and comfort to people in the room. The results of this work\nhave an immediate impact on the room control loop performances and its related\ncommissioning costs. Furthermore, this successful attempt paves the way for\nfurther use at different levels of HVAC systems, with promising energy,\noperational, and commissioning costs savings, and it is a practical\ndemonstration of the positive effects that Artificial Intelligence can have on\nenvironmental sustainability.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:21:04 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Fiducioso", "Marcello", ""], ["Curi", "Sebastian", ""], ["Schumacher", "Benedikt", ""], ["Gwerder", "Markus", ""], ["Krause", "Andreas", ""]]}, {"id": "1906.12087", "submitter": "Zhangheng Li", "authors": "Zhangheng Li, Jia-Xing Zhong, Jingjia Huang, Tao Zhang, Thomas Li and\n  Ge Li", "title": "ARMIN: Towards a More Efficient and Light-weight Recurrent Memory\n  Network", "comments": "Published in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, memory-augmented neural networks(MANNs) have shown promising\npower to enhance the memory ability of neural networks for sequential\nprocessing tasks. However, previous MANNs suffer from complex memory addressing\nmechanism, making them relatively hard to train and causing computational\noverheads. Moreover, many of them reuse the classical RNN structure such as\nLSTM for memory processing, causing inefficient exploitations of memory\ninformation. In this paper, we introduce a novel MANN, the Auto-addressing and\nRecurrent Memory Integrating Network (ARMIN) to address these issues. The ARMIN\nonly utilizes hidden state ht for automatic memory addressing, and uses a novel\nRNN cell for refined integration of memory information. Empirical results on a\nvariety of experiments demonstrate that the ARMIN is more light-weight and\nefficient compared to existing memory networks. Moreover, we demonstrate that\nthe ARMIN can achieve much lower computational overhead than vanilla LSTM while\nkeeping similar performances. Codes are available on github.com/zoharli/armin.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:21:49 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Li", "Zhangheng", ""], ["Zhong", "Jia-Xing", ""], ["Huang", "Jingjia", ""], ["Zhang", "Tao", ""], ["Li", "Thomas", ""], ["Li", "Ge", ""]]}, {"id": "1906.12091", "submitter": "Quanming Yao", "authors": "Quanming Yao, Xiangning Chen, James Kwok, Yong Li, Cho-Jui Hsieh", "title": "Efficient Neural Interaction Function Search for Collaborative Filtering", "comments": "Accepted to WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In collaborative filtering (CF), interaction function (IFC) plays the\nimportant role of capturing interactions among items and users. The most\npopular IFC is the inner product, which has been successfully used in low-rank\nmatrix factorization. However, interactions in real-world applications can be\nhighly complex. Thus, other operations (such as plus and concatenation), which\nmay potentially offer better performance, have been proposed. Nevertheless, it\nis still hard for existing IFCs to have consistently good performance across\ndifferent application scenarios. Motivated by the recent success of automated\nmachine learning (AutoML), we propose in this paper the search for simple\nneural interaction functions (SIF) in CF. By examining and generalizing\nexisting CF approaches, an expressive SIF search space is designed and\nrepresented as a structured multi-layer perceptron. We propose an one-shot\nsearch algorithm that simultaneously updates both the architecture and learning\nparameters. Experimental results demonstrate that the proposed method can be\nmuch more efficient than popular AutoML approaches, can obtain much better\nprediction performance than state-of-the-art CF approaches, and can discover\ndistinct IFCs for different data sets and tasks\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:37:02 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 03:48:44 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 11:45:17 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yao", "Quanming", ""], ["Chen", "Xiangning", ""], ["Kwok", "James", ""], ["Li", "Yong", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.12120", "submitter": "Loveperteek Singh", "authors": "Loveperteek Singh, Shreya Singh, Sagar Arora, Sumit Borar", "title": "One Embedding To Do Them All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online shopping caters to the needs of millions of users daily. Search,\nrecommendations, personalization have become essential building blocks for\nserving customer needs. Efficacy of such systems is dependent on a thorough\nunderstanding of products and their representation. Multiple information\nsources and data types provide a complete picture of the product on the\nplatform. While each of these tasks shares some common characteristics,\ntypically product embeddings are trained and used in isolation.\n  In this paper, we propose a framework to combine multiple data sources and\nlearn unified embeddings for products on our e-commerce platform. Our product\nembeddings are built from three types of data sources - catalog text data, a\nuser's clickstream session data and product images. We use various techniques\nlike denoising auto-encoders for text, Bayesian personalized ranking (BPR) for\nclickstream data, Siamese neural network architecture for image data and\ncombined ensemble over the above methods for unified embeddings. Further, we\ncompare and analyze the performance of these embeddings across three unrelated\nreal-world e-commerce tasks specifically checking product attribute coverage,\nfinding similar products and predicting returns. We show that unified product\nembeddings perform uniformly well across all these tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 10:08:13 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Singh", "Loveperteek", ""], ["Singh", "Shreya", ""], ["Arora", "Sagar", ""], ["Borar", "Sumit", ""]]}, {"id": "1906.12128", "submitter": "Sajan Kedia", "authors": "Sajan Kedia, Manchit Madan, Sumit Borar", "title": "Early Bird Catches the Worm: Predicting Returns Even Before Purchase in\n  Fashion E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rapid growth in fashion e-commerce and customer-friendly product\nreturn policies, the cost to handle returned products has become a significant\nchallenge. E-tailers incur huge losses in terms of reverse logistics costs,\nliquidation cost due to damaged returns or fraudulent behavior. Accurate\nprediction of product returns prior to order placement can be critical for\ncompanies. It can facilitate e-tailers to take preemptive measures even before\nthe order is placed, hence reducing overall returns. Furthermore, finding\nreturn probability for millions of customers at the cart page in real-time can\nbe difficult. To address this problem we propose a novel approach based on Deep\nNeural Network. Users' taste & products' latent hidden features were captured\nusing product embeddings based on Bayesian Personalized Ranking (BPR). Another\nset of embeddings was used which captured users' body shape and size by using\nskip-gram based model. The deep neural network incorporates these embeddings\nalong with the engineered features to predict return probability. Using this\nreturn probability, several live experiments were conducted on one of the major\nfashion e-commerce platform in order to reduce overall returns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 10:58:29 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kedia", "Sajan", ""], ["Madan", "Manchit", ""], ["Borar", "Sumit", ""]]}, {"id": "1906.12177", "submitter": "Rihuan Ke", "authors": "Rihuan Ke, Aur\\'elie Bugeau, Nicolas Papadakis, Peter Schuetz,\n  Carola-Bibiane Sch\\\"onlieb", "title": "Learning to segment microscopy images with lazy labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for labour intensive pixel-wise annotation is a major limitation of\nmany fully supervised learning methods for segmenting bioimages that can\ncontain numerous object instances with thin separations. In this paper, we\nintroduce a deep convolutional neural network for microscopy image\nsegmentation. Annotation issues are circumvented by letting the network being\ntrainable on coarse labels combined with only a very small number of images\nwith pixel-wise annotations. We call this new labelling strategy `lazy' labels.\nImage segmentation is stratified into three connected tasks: rough inner region\ndetection, object separation and pixel-wise segmentation. These tasks are\nlearned in an end-to-end multi-task learning framework. The method is\ndemonstrated on two microscopy datasets, where we show that the model gives\naccurate segmentation results even if exact boundary labels are missing for a\nmajority of annotated data. It brings more flexibility and efficiency for\ntraining deep neural networks that are data hungry and is applicable to\nbiomedical images with poor contrast at the object boundaries or with diverse\ntextures and repeated patterns.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 17:38:54 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 10:08:44 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Ke", "Rihuan", ""], ["Bugeau", "Aur\u00e9lie", ""], ["Papadakis", "Nicolas", ""], ["Schuetz", "Peter", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1906.12179", "submitter": "Dominik Janzing", "authors": "Dominik Janzing", "title": "Causal Regularization", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I argue that regularizing terms in standard regression methods not only help\nagainst overfitting finite data, but sometimes also yield better causal models\nin the infinite sample regime. I first consider a multi-dimensional variable\nlinearly influencing a target variable with some multi-dimensional unobserved\ncommon cause, where the confounding effect can be decreased by keeping the\npenalizing term in Ridge and Lasso regression even in the population limit.\nChoosing the size of the penalizing term, is however challenging, because cross\nvalidation is pointless. Here it is done by first estimating the strength of\nconfounding via a method proposed earlier, which yielded some reasonable\nresults for simulated and real data.\n  Further, I prove a `causal generalization bound' which states (subject to a\nparticular model of confounding) that the error made by interpreting any\nnon-linear regression as causal model can be bounded from above whenever\nfunctions are taken from a not too rich class. In other words, the bound\nguarantees \"generalization\" from observational to interventional distributions,\nwhich is usually not subject of statistical learning theory (and is only\npossible due to the underlying symmetries of the confounder model).\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 12:48:28 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Janzing", "Dominik", ""]]}, {"id": "1906.12183", "submitter": "Benny Avelin", "authors": "Benny Avelin and Kaj Nystr\\\"om", "title": "Neural ODEs as the Deep Limit of ResNets with constant weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove that, in the deep limit, the stochastic gradient\ndescent on a ResNet type deep neural network, where each layer shares the same\nweight matrix, converges to the stochastic gradient descent for a Neural ODE\nand that the corresponding value/loss functions converge. Our result gives, in\nthe context of minimization by stochastic gradient descent, a theoretical\nfoundation for considering Neural ODEs as the deep limit of ResNets. Our proof\nis based on certain decay estimates for associated Fokker-Planck equations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 12:53:54 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 07:14:06 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Avelin", "Benny", ""], ["Nystr\u00f6m", "Kaj", ""]]}, {"id": "1906.12187", "submitter": "Daniel Brodeski", "authors": "Daniel Brodeski, Igal Bilik, Raja Giryes", "title": "Deep Radar Detector", "comments": "Accepted to RadarConf 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While camera and LiDAR processing have been revolutionized since the\nintroduction of deep learning, radar processing still relies on classical\ntools. In this paper, we introduce a deep learning approach for radar\nprocessing, working directly with the radar complex data. To overcome the lack\nof radar labeled data, we rely in training only on the radar calibration data\nand introduce new radar augmentation techniques. We evaluate our method on the\nradar 4D detection task and demonstrate superior performance compared to the\nclassical approaches while keeping real-time performance. Applying deep\nlearning on radar data has several advantages such as eliminating the need for\nan expensive radar calibration process each time and enabling classification of\nthe detected objects with almost zero-overhead.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:30:45 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Brodeski", "Daniel", ""], ["Bilik", "Igal", ""], ["Giryes", "Raja", ""]]}, {"id": "1906.12192", "submitter": "Marc Brockschmidt", "authors": "Marc Brockschmidt", "title": "GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation", "comments": "As published in ICML 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new Graph Neural Network (GNN) type using feature-wise\nlinear modulation (FiLM). Many standard GNN variants propagate information\nalong the edges of a graph by computing \"messages\" based only on the\nrepresentation of the source of each edge. In GNN-FiLM, the representation of\nthe target node of an edge is additionally used to compute a transformation\nthat can be applied to all incoming messages, allowing feature-wise modulation\nof the passed information.\n  Results of experiments comparing different GNN architectures on three tasks\nfrom the literature are presented, based on re-implementations of baseline\nmethods. Hyperparameters for all methods were found using extensive search,\nyielding somewhat surprising results: differences between baseline models are\nsmaller than reported in the literature. Nonetheless, GNN-FiLM outperforms\nbaseline methods on a regression task on molecular graphs and performs\ncompetitively on other tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:07:22 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 11:48:10 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 13:23:27 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 12:48:01 GMT"}, {"version": "v5", "created": "Fri, 26 Jun 2020 16:45:48 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Brockschmidt", "Marc", ""]]}, {"id": "1906.12195", "submitter": "Paolo Galeone", "authors": "Emanuele Ghelfi, Paolo Galeone, Michele De Simoni, Federico Di Mattia", "title": "Adversarial Pixel-Level Generation of Semantic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have obtained extraordinary success in\nthe generation of realistic images, a domain where a lower pixel-level accuracy\nis acceptable. We study the problem, not yet tackled in the literature, of\ngenerating semantic images starting from a prior distribution. Intuitively this\nproblem can be approached using standard methods and architectures. However, a\nbetter-suited approach is needed to avoid generating blurry, hallucinated and\nthus unusable images since tasks like semantic segmentation require pixel-level\nexactness. In this work, we present a novel architecture for learning to\ngenerate pixel-level accurate semantic images, namely Semantic Generative\nAdversarial Networks (SemGANs). The experimental evaluation shows that our\narchitecture outperforms standard ones from both a quantitative and a\nqualitative point of view in many semantic image generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 14:25:11 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Ghelfi", "Emanuele", ""], ["Galeone", "Paolo", ""], ["De Simoni", "Michele", ""], ["Di Mattia", "Federico", ""]]}, {"id": "1906.12218", "submitter": "Hung Nguyen", "authors": "Hung Nguyen, Xuejian Wang, Leman Akoglu", "title": "Continual Rare-Class Recognition with Emerging Novel Subclasses", "comments": "accepted to PKDD ECML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a labeled dataset that contains a rare (or minority) class of\nof-interest instances, as well as a large class of instances that are not of\ninterest, how can we learn to recognize future of-interest instances over a\ncontinuous stream? We introduce RaRecognize, which (i) estimates a general\ndecision boundary between the rare and the majority class, (ii) learns to\nrecognize individual rare subclasses that exist within the training data, as\nwell as (iii) flags instances from previously unseen rare subclasses as newly\nemerging. The learner in (i) is general in the sense that by construction it is\ndissimilar to the specialized learners in (ii), thus distinguishes minority\nfrom the majority without overly tuning to what is seen in the training data.\nThanks to this generality, RaRecognize ignores all future instances that it\nlabels as majority and recognizes the recurrent as well as emerging rare\nsubclasses only. This saves effort at test time as well as ensures that the\nmodel size grows moderately over time as it only maintains specialized minority\nlearners. Through extensive experiments, we show that RaRecognize outperforms\nstate-of-the art baselines on three real-world datasets that contain\ncorporate-risk and disaster documents as rare classes.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:45:24 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Nguyen", "Hung", ""], ["Wang", "Xuejian", ""], ["Akoglu", "Leman", ""]]}, {"id": "1906.12225", "submitter": "Kin Quan", "authors": "Kin Quan, Ryutaro Tanno, Michael Duong, Arjun Nair, Rebecca Shipley,\n  Mark Jones, Christopher Brereton, John Hurst, David Hawkes and Joseph Jacob", "title": "Modelling Airway Geometry as Stock Market Data using Bayesian\n  Changepoint Detection", "comments": "14 pages, 7 figures, Accepted to The 10th International Workshop on\n  Machine Learning in Medical Imaging (MLMI 2019). In conjunction with MICCAI\n  2019, Shenzhen, China", "journal-ref": "In Lecture Notes in Computer Science, vol 11861. (2019) Springer,\n  Cham", "doi": "10.1007/978-3-030-32692-0_40", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous lung diseases, such as idiopathic pulmonary fibrosis (IPF), exhibit\ndilation of the airways. Accurate measurement of dilatation enables assessment\nof the progression of disease. Unfortunately the combination of image noise and\nairway bifurcations causes high variability in the profiles of cross-sectional\nareas, rendering the identification of affected regions very difficult. Here we\nintroduce a noise-robust method for automatically detecting the location of\nprogressive airway dilatation given two profiles of the same airway acquired at\ndifferent time points. We propose a probabilistic model of abrupt relative\nvariations between profiles and perform inference via Reversible Jump Markov\nChain Monte Carlo sampling. We demonstrate the efficacy of the proposed method\non two datasets; (i) images of healthy airways with simulated dilatation; (ii)\npairs of real images of IPF-affected airways acquired at 1 year intervals. Our\nmodel is able to detect the starting location of airway dilatation with an\naccuracy of 2.5mm on simulated data. The experiments on the IPF dataset display\nreasonable agreement with radiologists. We can compute a relative change in\nairway volume that may be useful for quantifying IPF disease progression. The\ncode is available at\nhttps://github.com/quan14/Modelling_Airway_Geometry_as_Stock_Market_Data\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:56:58 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 18:09:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Quan", "Kin", ""], ["Tanno", "Ryutaro", ""], ["Duong", "Michael", ""], ["Nair", "Arjun", ""], ["Shipley", "Rebecca", ""], ["Jones", "Mark", ""], ["Brereton", "Christopher", ""], ["Hurst", "John", ""], ["Hawkes", "David", ""], ["Jacob", "Joseph", ""]]}, {"id": "1906.12230", "submitter": "Andrew Moore", "authors": "Henry B. Moss, Andrew Moore, David S. Leslie, Paul Rayson", "title": "FIESTA: Fast IdEntification of State-of-The-Art models using adaptive\n  bandit algorithms", "comments": "ACL 2019. Code available at: https://github.com/apmoore1/fiesta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FIESTA, a model selection approach that significantly reduces the\ncomputational resources required to reliably identify state-of-the-art\nperformance from large collections of candidate models. Despite being known to\nproduce unreliable comparisons, it is still common practice to compare model\nevaluations based on single choices of random seeds. We show that reliable\nmodel selection also requires evaluations based on multiple train-test splits\n(contrary to common practice in many shared tasks). Using bandit theory from\nthe statistics literature, we are able to adaptively determine appropriate\nnumbers of data splits and random seeds used to evaluate each model, focusing\ncomputational resources on the evaluation of promising models whilst avoiding\nwasting evaluations on models with lower performance. Furthermore, our\nuser-friendly Python implementation produces confidence guarantees of correctly\nselecting the optimal model. We evaluate our algorithms by selecting between 8\ntarget-dependent sentiment analysis methods using dramatically fewer model\nevaluations than current model selection approaches.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:11:13 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Moss", "Henry B.", ""], ["Moore", "Andrew", ""], ["Leslie", "David S.", ""], ["Rayson", "Paul", ""]]}, {"id": "1906.12239", "submitter": "Martin Tappler", "authors": "Martin Tappler and Bernhard K. Aichernig and Giovanni Bacci and Maria\n  Eichlseder and Kim G. Larsen", "title": "L*-Based Learning of Markov Decision Processes (Extended Version)", "comments": "an extended version of a conference paper accepted for presentation\n  at FM 2019, the 23rd international symposium on formal methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automata learning techniques automatically generate system models from test\nobservations. These techniques usually fall into two categories: passive and\nactive. Passive learning uses a predetermined data set, e.g., system logs. In\ncontrast, active learning actively queries the system under learning, which is\nconsidered more efficient.\n  An influential active learning technique is Angluin's L* algorithm for\nregular languages which inspired several generalisations from DFAs to other\nautomata-based modelling formalisms. In this work, we study L*-based learning\nof deterministic Markov decision processes, first assuming an ideal setting\nwith perfect information. Then, we relax this assumption and present a novel\nlearning algorithm that collects information by sampling system traces via\ntesting. Experiments with the implementation of our sampling-based algorithm\nsuggest that it achieves better accuracy than state-of-the-art passive learning\ntechniques with the same amount of test data. Unlike existing learning\nalgorithms with predefined states, our algorithm learns the complete model\nstructure including the states.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:31:49 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Tappler", "Martin", ""], ["Aichernig", "Bernhard K.", ""], ["Bacci", "Giovanni", ""], ["Eichlseder", "Maria", ""], ["Larsen", "Kim G.", ""]]}, {"id": "1906.12266", "submitter": "Gregory Farquhar", "authors": "Gregory Farquhar, Laura Gustafson, Zeming Lin, Shimon Whiteson,\n  Nicolas Usunier, Gabriel Synnaeve", "title": "Growing Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex tasks, such as those with large combinatorial action spaces,\nrandom exploration may be too inefficient to achieve meaningful learning\nprogress. In this work, we use a curriculum of progressively growing action\nspaces to accelerate learning. We assume the environment is out of our control,\nbut that the agent may set an internal curriculum by initially restricting its\naction space. Our approach uses off-policy reinforcement learning to estimate\noptimal value functions for multiple action spaces simultaneously and\nefficiently transfers data, value estimates, and state representations from\nrestricted action spaces to the full task. We show the efficacy of our approach\nin proof-of-concept control tasks and on challenging large-scale StarCraft\nmicromanagement tasks with large, multi-agent action spaces.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 15:35:11 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Farquhar", "Gregory", ""], ["Gustafson", "Laura", ""], ["Lin", "Zeming", ""], ["Whiteson", "Shimon", ""], ["Usunier", "Nicolas", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1906.12269", "submitter": "Daniel Z\\\"ugner", "authors": "Daniel Z\\\"ugner and Stephan G\\\"unnemann", "title": "Certifiable Robustness and Robust Training for Graph Convolutional\n  Networks", "comments": "Published as a Conference Paper at ACM SIGKDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330905", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that Graph Neural Networks (GNNs) are highly non-robust\nwith respect to adversarial attacks on both the graph structure and the node\nattributes, making their outcomes unreliable. We propose the first method for\ncertifiable (non-)robustness of graph convolutional networks with respect to\nperturbations of the node attributes. We consider the case of binary node\nattributes (e.g. bag-of-words) and perturbations that are L_0-bounded. If a\nnode has been certified with our method, it is guaranteed to be robust under\nany possible perturbation given the attack model. Likewise, we can certify\nnon-robustness. Finally, we propose a robust semi-supervised training procedure\nthat treats the labeled and unlabeled nodes jointly. As shown in our\nexperimental evaluation, our method significantly improves the robustness of\nthe GNN with only minimal effect on the predictive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 15:40:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1906.12304", "submitter": "Pierre Laforgue", "authors": "Pierre Laforgue, Stephan Cl\\'emen\\c{c}on", "title": "Statistical Learning from Biased Training Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the deluge of digitized information in the Big Data era, massive\ndatasets are becoming increasingly available for learning predictive models.\nHowever, in many situations, the poor control of the data acquisition processes\nmay naturally jeopardize the outputs of machine-learning algorithms and\nselection bias issues are now the subject of much attention in the literature.\nIt is precisely the purpose of the present article to investigate how to extend\nEmpirical Risk Minimization (ERM), the main paradigm of statistical learning,\nwhen the training observations are generated from biased models, i.e. from\ndistributions that are different from that of the data in the test/prediction\nstage. Precisely, we show how to build a \"nearly debiased\" training statistical\npopulation from biased samples and the related biasing functions following in\nthe footsteps of the approach originally proposed in Vardi (1985). Furthermore,\nwe study from a non asymptotic perspective the performance of minimizers of an\nempirical version of the risk computed from the statistical population thus\nconstructed. Remarkably, the learning rate achieved by this procedure is of the\nsame order as that attained in absence of any selection bias phenomenon. Beyond\nthese theoretical guarantees, illustrative experimental results supporting the\nrelevance of the algorithmic approach promoted in this paper are also\ndisplayed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 16:47:36 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 21:49:50 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Laforgue", "Pierre", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "1906.12309", "submitter": "Yang Ni", "authors": "Yang Ni, Yuan Ji, Peter Mueller", "title": "Consensus Monte Carlo for Random Subsets using Shared Anchors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a consensus Monte Carlo algorithm that scales existing Bayesian\nnonparametric models for clustering and feature allocation to big data. The\nalgorithm is valid for any prior on random subsets such as partitions and\nlatent feature allocation, under essentially any sampling model. Motivated by\nthree case studies, we focus on clustering induced by a Dirichlet process\nmixture sampling model, inference under an Indian buffet process prior with a\nbinomial sampling model, and with a categorical sampling model. We assess the\nproposed algorithm with simulation studies and show results for inference with\nthree datasets: an MNIST image dataset, a dataset of pancreatic cancer\nmutations, and a large set of electronic health records (EHR). Supplementary\nmaterials for this article are available online.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 16:57:33 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 17:31:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ni", "Yang", ""], ["Ji", "Yuan", ""], ["Mueller", "Peter", ""]]}, {"id": "1906.12328", "submitter": "Renhao Wang", "authors": "Junhao Wang, Renhao Wang, Aayushi Kulshrestha, Reihaneh Rabbany", "title": "Anomaly Detection with Joint Representation Learning of Content and\n  Connection", "comments": "2019 International Conference on Machine Learning Workshop on AI for\n  Social Good", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media sites are becoming a key factor in politics. These platforms are\neasy to manipulate for the purpose of distorting information space to confuse\nand distract voters. Past works to identify disruptive patterns are mostly\nfocused on analyzing the content of tweets. In this study, we jointly embed the\ninformation from both user posted content as well as a user's follower network,\nto detect groups of densely connected users in an unsupervised fashion. We then\ninvestigate these dense sub-blocks of users to flag anomalous behavior. In our\nexperiments, we study the tweets related to the upcoming 2019 Canadian\nElections, and observe a set of densely-connected users engaging in local\npolitics in different provinces, and exhibiting troll-like behavior.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 21:32:40 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Wang", "Junhao", ""], ["Wang", "Renhao", ""], ["Kulshrestha", "Aayushi", ""], ["Rabbany", "Reihaneh", ""]]}, {"id": "1906.12329", "submitter": "Telmo Felgueira", "authors": "Telmo Felgueira, Silvio Rodrigues, Christian S. Perone, Rui Castro", "title": "The Impact of Feature Causality on Normal Behaviour Models for\n  SCADA-based Wind Turbine Fault Detection", "comments": "Presented at ICML 2019 Workshop: Climate Change: How Can AI Help?", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The cost of wind energy can be reduced by using SCADA data to detect faults\nin wind turbine components. Normal behavior models are one of the main fault\ndetection approaches, but there is a lack of consensus in how different input\nfeatures affect the results. In this work, a new taxonomy based on the causal\nrelations between the input features and the target is presented. Based on this\ntaxonomy, the impact of different input feature configurations on the modelling\nand fault detection performance is evaluated. To this end, a framework that\nformulates the detection of faults as a classification problem is also\npresented.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 17:32:41 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Felgueira", "Telmo", ""], ["Rodrigues", "Silvio", ""], ["Perone", "Christian S.", ""], ["Castro", "Rui", ""]]}, {"id": "1906.12331", "submitter": "Devashish Khulbe", "authors": "Devashish Khulbe and Manu Pathak", "title": "Modeling Food Popularity Dependencies using Social Media data", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise in popularity of major social media platforms have enabled people to\nshare photos and textual information about their daily life. One of the popular\ntopics about which information is shared is food. Since a lot of media about\nfood are attributed to particular locations and restaurants, information like\nspatio-temporal popularity of various cuisines can be analyzed. Tracking the\npopularity of food types and retail locations across space and time can also be\nuseful for business owners and restaurant investors. In this work, we present\nan approach using off-the shelf machine learning techniques to identify trends\nand popularity of cuisine types in an area using geo-tagged data from social\nmedia, Google images and Yelp. After adjusting for time, we use the Kernel\nDensity Estimation to get hot spots across the location and model the\ndependencies among food cuisines popularity using Bayesian Networks. We\nconsider the Manhattan borough of New York City as the location for our\nanalyses but the approach can be used for any area with social media data and\ninformation about retail businesses.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 04:31:39 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:20:18 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Khulbe", "Devashish", ""], ["Pathak", "Manu", ""]]}, {"id": "1906.12340", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Mantas Mazeika and Saurav Kadavath and Dawn Song", "title": "Using Self-Supervised Learning Can Improve Model Robustness and\n  Uncertainty", "comments": "NeurIPS 2019; code and data available at\n  https://github.com/hendrycks/ss-ood", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervision provides effective representations for downstream tasks\nwithout requiring labels. However, existing approaches lag behind fully\nsupervised training and are often not thought beneficial beyond obviating or\nreducing the need for annotations. We find that self-supervision can benefit\nrobustness in a variety of ways, including robustness to adversarial examples,\nlabel corruption, and common input corruptions. Additionally, self-supervision\ngreatly benefits out-of-distribution detection on difficult, near-distribution\noutliers, so much so that it exceeds the performance of fully supervised\nmethods. These results demonstrate the promise of self-supervision for\nimproving robustness and uncertainty estimation and establish these tasks as\nnew axes of evaluation for future self-supervised learning research.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 17:44:00 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 17:57:27 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Hendrycks", "Dan", ""], ["Mazeika", "Mantas", ""], ["Kadavath", "Saurav", ""], ["Song", "Dawn", ""]]}, {"id": "1906.12348", "submitter": "Shubhra Kanti Karmaker Santu", "authors": "Lei Xu, Shubhra Kanti Karmaker Santu and Kalyan Veeramachaneni", "title": "MLFriend: Interactive Prediction Task Recommendation for Event-Driven\n  Time-Series Data", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most automation in machine learning focuses on model selection and hyper\nparameter tuning, and many overlook the challenge of automatically defining\npredictive tasks. We still heavily rely on human experts to define prediction\ntasks, and generate labels by aggregating raw data. In this paper, we tackle\nthe challenge of defining useful prediction problems on event-driven\ntime-series data. We introduce MLFriend to address this challenge. MLFriend\nfirst generates all possible prediction tasks under a predefined space, then\ninteracts with a data scientist to learn the context of the data and recommend\ngood prediction tasks from all the tasks in the space. We evaluate our system\non three different datasets and generate a total of 2885 prediction tasks and\nsolve them. Out of these 722 were deemed useful by expert data scientists. We\nalso show that an automatic prediction task discovery system is able to\nidentify top 10 tasks that a user may like within a batch of 100 tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 17:59:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Xu", "Lei", ""], ["Santu", "Shubhra Kanti Karmaker", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1906.12350", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi", "title": "Split Q Learning: Reinforcement Learning with Two-Stream Rewards", "comments": "IJCAI 2019. This article supersedes our work arXiv:1706.02897 into RL\n  setting, with a different focus by applying Inverse Reinforcement Learning to\n  model human clinical behavioral bias. It also precedes our work\n  arXiv:1906.11286 which introduces extensive emphases in RL games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing an inspiration from behavioral studies of human decision making, we\npropose here a general parametric framework for a reinforcement learning\nproblem, which extends the standard Q-learning approach to incorporate a\ntwo-stream framework of reward processing with biases biologically associated\nwith several neurological and psychiatric conditions, including Parkinson's and\nAlzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD),\naddiction, and chronic pain. For AI community, the development of agents that\nreact differently to different types of rewards can enable us to understand a\nwide spectrum of multi-agent interactions in complex real-world socioeconomic\nsystems. Moreover, from the behavioral modeling perspective, our parametric\nframework can be viewed as a first step towards a unifying computational model\ncapturing reward processing abnormalities across multiple mental conditions and\nuser preferences in long-term recommendation systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:59:52 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 19:10:05 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""], ["Cecchi", "Guillermo", ""]]}]