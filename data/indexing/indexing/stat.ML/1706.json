[{"id": "1706.00038", "submitter": "Arash Vahdat", "authors": "Arash Vahdat", "title": "Toward Robustness against Label Noise in Training Deep Discriminative\n  Neural Networks", "comments": "To appear in Neural Information Processing Systems (NIPS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting large training datasets, annotated with high-quality labels, is\ncostly and time-consuming. This paper proposes a novel framework for training\ndeep convolutional neural networks from noisy labeled datasets that can be\nobtained cheaply. The problem is formulated using an undirected graphical model\nthat represents the relationship between noisy and clean labels, trained in a\nsemi-supervised setting. In our formulation, the inference over latent clean\nlabels is tractable and is regularized during training using auxiliary sources\nof information. The proposed model is applied to the image labeling problem and\nis shown to be effective in labeling unseen images as well as reducing label\nnoise in training on CIFAR-10 and MS COCO datasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 18:16:49 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 01:47:50 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Vahdat", "Arash", ""]]}, {"id": "1706.00051", "submitter": "Morteza Mardani", "authors": "Morteza Mardani, Enhao Gong, Joseph Y. Cheng, Shreyas Vasanawala, Greg\n  Zaharchuk, Marcus Alley, Neil Thakur, Song Han, William Dally, John M. Pauly,\n  and Lei Xing", "title": "Deep Generative Adversarial Networks for Compressed Sensing Automates\n  MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance image (MRI) reconstruction is a severely ill-posed linear\ninverse task demanding time and resource intensive computations that can\nsubstantially trade off {\\it accuracy} for {\\it speed} in real-time imaging. In\naddition, state-of-the-art compressed sensing (CS) analytics are not cognizant\nof the image {\\it diagnostic quality}. To cope with these challenges we put\nforth a novel CS framework that permeates benefits from generative adversarial\nnetworks (GAN) to train a (low-dimensional) manifold of diagnostic-quality MR\nimages from historical patients. Leveraging a mixture of least-squares (LS)\nGANs and pixel-wise $\\ell_1$ cost, a deep residual network with skip\nconnections is trained as the generator that learns to remove the {\\it\naliasing} artifacts by projecting onto the manifold. LSGAN learns the texture\ndetails, while $\\ell_1$ controls the high-frequency noise. A multilayer\nconvolutional neural network is then jointly trained based on diagnostic\nquality images to discriminate the projection quality. The test phase performs\nfeed-forward propagation over the generator network that demands a very low\ncomputational overhead. Extensive evaluations are performed on a large\ncontrast-enhanced MR dataset of pediatric patients. In particular, images rated\nbased on expert radiologists corroborate that GANCS retrieves high contrast\nimages with detailed texture relative to conventional CS, and pixel-wise\nschemes. In addition, it offers reconstruction under a few milliseconds, two\norders of magnitude faster than state-of-the-art CS-MRI schemes.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 19:12:14 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Mardani", "Morteza", ""], ["Gong", "Enhao", ""], ["Cheng", "Joseph Y.", ""], ["Vasanawala", "Shreyas", ""], ["Zaharchuk", "Greg", ""], ["Alley", "Marcus", ""], ["Thakur", "Neil", ""], ["Han", "Song", ""], ["Dally", "William", ""], ["Pauly", "John M.", ""], ["Xing", "Lei", ""]]}, {"id": "1706.00061", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Kannan Ramchandran", "title": "The Sample Complexity of Online One-Class Collaborative Filtering", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online one-class collaborative filtering (CF) problem that\nconsists of recommending items to users over time in an online fashion based on\npositive ratings only. This problem arises when users respond only occasionally\nto a recommendation with a positive rating, and never with a negative one. We\nstudy the impact of the probability of a user responding to a recommendation,\np_f, on the sample complexity, i.e., the number of ratings required to make\n`good' recommendations, and ask whether receiving positive and negative\nratings, instead of positive ratings only, improves the sample complexity. Both\nquestions arise in the design of recommender systems. We introduce a simple\nprobabilistic user model, and analyze the performance of an online user-based\nCF algorithm. We prove that after an initial cold start phase, where\nrecommendations are invested in exploring the user's preferences, this\nalgorithm makes---up to a fraction of the recommendations required for updating\nthe user's preferences---perfect recommendations. The number of ratings\nrequired for the cold start phase is nearly proportional to 1/p_f, and that for\nupdating the user's preferences is essentially independent of p_f. As a\nconsequence we find that, receiving positive and negative ratings instead of\nonly positive ones improves the number of ratings required for initial\nexploration by a factor of 1/p_f, which can be significant.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 19:37:12 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Heckel", "Reinhard", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1706.00090", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett, Ilijia Bogunovic, Volkan Cevher", "title": "Lower Bounds on Regret for Noisy Gaussian Process Bandit Optimization", "comments": "Appearing in COLT 2017. This version corrects a few minor mistakes in\n  Table I, which summarizes the new and existing regret bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of sequentially optimizing a black-box\nfunction $f$ based on noisy samples and bandit feedback. We assume that $f$ is\nsmooth in the sense of having a bounded norm in some reproducing kernel Hilbert\nspace (RKHS), yielding a commonly-considered non-Bayesian form of Gaussian\nprocess bandit optimization. We provide algorithm-independent lower bounds on\nthe simple regret, measuring the suboptimality of a single point reported after\n$T$ rounds, and on the cumulative regret, measuring the sum of regrets over the\n$T$ chosen points. For the isotropic squared-exponential kernel in $d$\ndimensions, we find that an average simple regret of $\\epsilon$ requires $T =\n\\Omega\\big(\\frac{1}{\\epsilon^2} (\\log\\frac{1}{\\epsilon})^{d/2}\\big)$, and the\naverage cumulative regret is at least $\\Omega\\big( \\sqrt{T(\\log T)^{d/2}}\n\\big)$, thus matching existing upper bounds up to the replacement of $d/2$ by\n$2d+O(1)$ in both cases. For the Mat\\'ern-$\\nu$ kernel, we give analogous\nbounds of the form $\\Omega\\big( (\\frac{1}{\\epsilon})^{2+d/\\nu}\\big)$ and\n$\\Omega\\big( T^{\\frac{\\nu + d}{2\\nu + d}} \\big)$, and discuss the resulting\ngaps to the existing upper bounds.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 21:14:06 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 13:45:34 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 08:05:38 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Scarlett", "Jonathan", ""], ["Bogunovic", "Ilijia", ""], ["Cevher", "Volkan", ""]]}, {"id": "1706.00098", "submitter": "Lei Sun", "authors": "Nicholas G. Polson and Lei Sun", "title": "Bayesian $l_0$-regularized Least Squares", "comments": "22 pages, 6 figures, 1 table", "journal-ref": null, "doi": "10.1002/asmb.2381", "report-no": null, "categories": "stat.ML stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian $l_0$-regularized least squares is a variable selection technique\nfor high dimensional predictors. The challenge is optimizing a non-convex\nobjective function via search over model space consisting of all possible\npredictor combinations. Spike-and-slab (a.k.a. Bernoulli-Gaussian) priors are\nthe gold standard for Bayesian variable selection, with a caveat of\ncomputational speed and scalability. Single Best Replacement (SBR) provides a\nfast scalable alternative. We provide a link between Bayesian regularization\nand proximal updating, which provides an equivalence between finding a\nposterior mode and a posterior mean with a different regularization prior. This\nallows us to use SBR to find the spike-and-slab estimator. To illustrate our\nmethodology, we provide simulation evidence and a real data example on the\nstatistical properties and computational efficiency of SBR versus direct\nposterior sampling using spike-and-slab priors. Finally, we conclude with\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 21:29:40 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 17:10:53 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Polson", "Nicholas G.", ""], ["Sun", "Lei", ""]]}, {"id": "1706.00119", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis and Yang Liu and David Parkes and Goran\n  Radanovic", "title": "Bayesian fairness", "comments": "13 pages, 8 figures, to appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of how decision making can be fair when the\nunderlying probabilistic model of the world is not known with certainty. We\nargue that recent notions of fairness in machine learning need to explicitly\nincorporate parameter uncertainty, hence we introduce the notion of {\\em\nBayesian fairness} as a suitable candidate for fair decision rules. Using\nbalance, a definition of fairness introduced by Kleinberg et al (2016), we show\nhow a Bayesian perspective can lead to well-performing, fair decision rules\neven under high uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 23:13:35 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 10:09:37 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 13:22:20 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Dimitrakakis", "Christos", ""], ["Liu", "Yang", ""], ["Parkes", "David", ""], ["Radanovic", "Goran", ""]]}, {"id": "1706.00136", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Aniruddha Bhargava, Robert Nowak, Rebecca Willett", "title": "Scalable Generalized Linear Bandits: Online Computation and Hashing", "comments": "accepted to NIPS'17 (typos fixed)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Linear Bandits (GLBs), a natural extension of the stochastic\nlinear bandits, has been popular and successful in recent years. However,\nexisting GLBs scale poorly with the number of rounds and the number of arms,\nlimiting their utility in practice. This paper proposes new, scalable solutions\nto the GLB problem in two respects. First, unlike existing GLBs, whose\nper-time-step space and time complexity grow at least linearly with time $t$,\nwe propose a new algorithm that performs online computations to enjoy a\nconstant space and time complexity. At its heart is a novel Generalized Linear\nextension of the Online-to-confidence-set Conversion (GLOC method) that takes\n\\emph{any} online learning algorithm and turns it into a GLB algorithm. As a\nspecial case, we apply GLOC to the online Newton step algorithm, which results\nin a low-regret GLB algorithm with much lower time and memory complexity than\nprior work. Second, for the case where the number $N$ of arms is very large, we\npropose new algorithms in which each next arm is selected via an inner product\nsearch. Such methods can be implemented via hashing algorithms (i.e.,\n\"hash-amenable\") and result in a time complexity sublinear in $N$. While a\nThompson sampling extension of GLOC is hash-amenable, its regret bound for\n$d$-dimensional arm sets scales with $d^{3/2}$, whereas GLOC's regret bound\nscales with $d$. Towards closing this gap, we propose a new hash-amenable\nalgorithm whose regret bound scales with $d^{5/4}$. Finally, we propose a fast\napproximate hash-key computation (inner product) with a better accuracy than\nthe state-of-the-art, which can be of independent interest. We conclude the\npaper with preliminary experimental results confirming the merits of our\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 00:41:42 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 03:18:58 GMT"}, {"version": "v3", "created": "Sat, 21 Oct 2017 17:40:05 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Bhargava", "Aniruddha", ""], ["Nowak", "Robert", ""], ["Willett", "Rebecca", ""]]}, {"id": "1706.00182", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland and Kazushi Ikeda", "title": "Efficient learning with robust gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing the empirical risk is a popular training strategy, but for\nlearning tasks where the data may be noisy or heavy-tailed, one may require\nmany observations in order to generalize well. To achieve better performance\nunder less stringent requirements, we introduce a procedure which constructs a\nrobust approximation of the risk gradient for use in an iterative learning\nroutine. Using high-probability bounds on the excess risk of this algorithm, we\nshow that our update does not deviate far from the ideal gradient-based update.\nEmpirical tests using both controlled simulations and real-world benchmark data\nshow that in diverse settings, the proposed procedure can learn more\nefficiently, using less resources (iterations and observations) while\ngeneralizing better.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 07:00:56 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 09:32:31 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 02:51:50 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Holland", "Matthew J.", ""], ["Ikeda", "Kazushi", ""]]}, {"id": "1706.00241", "submitter": "Filip De Roos", "authors": "Filip de Roos and Philipp Hennig", "title": "Krylov Subspace Recycling for Fast Iterative Least-Squares in Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving symmetric positive definite linear problems is a fundamental\ncomputational task in machine learning. The exact solution, famously, is\ncubicly expensive in the size of the matrix. To alleviate this problem, several\nlinear-time approximations, such as spectral and inducing-point methods, have\nbeen suggested and are now in wide use. These are low-rank approximations that\nchoose the low-rank space a priori and do not refine it over time. While this\nallows linear cost in the data-set size, it also causes a finite, uncorrected\napproximation error. Authors from numerical linear algebra have explored ways\nto iteratively refine such low-rank approximations, at a cost of a small number\nof matrix-vector multiplications. This idea is particularly interesting in the\nmany situations in machine learning where one has to solve a sequence of\nrelated symmetric positive definite linear problems. From the machine learning\nperspective, such deflation methods can be interpreted as transfer learning of\na low-rank approximation across a time-series of numerical tasks. We study the\nuse of such methods for our field. Our empirical results show that, on\nregression and classification problems of intermediate size, this approach can\ninterpolate between low computational cost and numerical precision.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 10:17:12 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["de Roos", "Filip", ""], ["Hennig", "Philipp", ""]]}, {"id": "1706.00244", "submitter": "Jean-Philippe Vert", "authors": "Marine Le Morvan (CBIO), Jean-Philippe Vert (DMA, CBIO)", "title": "Supervised Quantile Normalisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile normalisation is a popular normalisation method for data subject to\nunwanted variations such as images, speech, or genomic data. It applies a\nmonotonic transformation to the feature values of each sample to ensure that\nafter normalisation, they follow the same target distribution for each sample.\nChoosing a \"good\" target distribution remains however largely empirical and\nheuristic, and is usually done independently of the subsequent analysis of\nnormalised data. We propose instead to couple the quantile normalisation step\nwith the subsequent analysis, and to optimise the target distribution jointly\nwith the other parameters in the analysis. We illustrate this principle on the\nproblem of estimating a linear model over normalised data, and show that it\nleads to a particular low-rank matrix regression problem that can be solved\nefficiently. We illustrate the potential of our method, which we term SUQUAN,\non simulated data, images and genomic data, where it outperforms standard\nquantile normalisation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 10:25:50 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Morvan", "Marine Le", "", "CBIO"], ["Vert", "Jean-Philippe", "", "DMA, CBIO"]]}, {"id": "1706.00290", "submitter": "Julius Kunze", "authors": "Julius Kunze, Louis Kirsch, Ilia Kurenkov, Andreas Krug, Jens\n  Johannsmeier and Sebastian Stober", "title": "Transfer Learning for Speech Recognition on a Budget", "comments": "Accepted for 2nd ACL Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training of automated speech recognition (ASR) systems requires\nmassive data and compute resources. We explore transfer learning based on model\nadaptation as an approach for training ASR models under constrained GPU memory,\nthroughput and training data. We conduct several systematic experiments\nadapting a Wav2Letter convolutional neural network originally trained for\nEnglish ASR to the German language. We show that this technique allows faster\ntraining on consumer-grade resources while requiring less training data in\norder to achieve the same accuracy, thereby lowering the cost of training ASR\nmodels in other languages. Model introspection revealed that small adaptations\nto the network's weights were sufficient for good performance, especially for\ninner layers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 13:33:54 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Kunze", "Julius", ""], ["Kirsch", "Louis", ""], ["Kurenkov", "Ilia", ""], ["Krug", "Andreas", ""], ["Johannsmeier", "Jens", ""], ["Stober", "Sebastian", ""]]}, {"id": "1706.00292", "submitter": "Gabriel Peyr\\'e", "authors": "Aude Genevay, Gabriel Peyr\\'e, Marco Cuturi", "title": "Learning Generative Models with Sinkhorn Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compare two degenerate probability distributions (i.e. two\nprobability distributions supported on two distinct low-dimensional manifolds\nliving in a much higher-dimensional space) is a crucial problem arising in the\nestimation of generative models for high-dimensional observations such as those\narising in computer vision or natural language. It is known that optimal\ntransport metrics can represent a cure for this problem, since they were\nspecifically designed as an alternative to information divergences to handle\nsuch problematic scenarios. Unfortunately, training generative machines using\nOT raises formidable computational and statistical challenges, because of (i)\nthe computational burden of evaluating OT losses, (ii) the instability and lack\nof smoothness of these losses, (iii) the difficulty to estimate robustly these\nlosses and their gradients in high dimension. This paper presents the first\ntractable computational method to train large scale generative models using an\noptimal transport loss, and tackles these three issues by relying on two key\nideas: (a) entropic smoothing, which turns the original OT loss into one that\ncan be computed using Sinkhorn fixed point iterations; (b) algorithmic\n(automatic) differentiation of these iterations. These two approximations\nresult in a robust and differentiable approximation of the OT loss with\nstreamlined GPU execution. Entropic smoothing generates a family of losses\ninterpolating between Wasserstein (OT) and Maximum Mean Discrepancy (MMD), thus\nallowing to find a sweet spot leveraging the geometry of OT and the favorable\nhigh-dimensional sample complexity of MMD which comes with unbiased gradient\nestimates. The resulting computational architecture complements nicely standard\ndeep network generative models by a stack of extra layers implementing the loss\nfunction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 13:37:37 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 10:47:52 GMT"}, {"version": "v3", "created": "Fri, 20 Oct 2017 09:53:12 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Genevay", "Aude", ""], ["Peyr\u00e9", "Gabriel", ""], ["Cuturi", "Marco", ""]]}, {"id": "1706.00326", "submitter": "Matthias Bauer", "authors": "Matthias Bauer, Mateo Rojas-Carulla, Jakub Bart{\\l}omiej\n  \\'Swi\\k{a}tkowski, Bernhard Sch\\\"olkopf, Richard E. Turner", "title": "Discriminative k-shot learning using probabilistic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a probabilistic framework for k-shot image\nclassification. The goal is to generalise from an initial large-scale\nclassification task to a separate task comprising new classes and small numbers\nof examples. The new approach not only leverages the feature-based\nrepresentation learned by a neural network from the initial task\n(representational transfer), but also information about the classes (concept\ntransfer). The concept information is encapsulated in a probabilistic model for\nthe final layer weights of the neural network which acts as a prior for\nprobabilistic k-shot learning. We show that even a simple probabilistic model\nachieves state-of-the-art on a standard k-shot learning dataset by a large\nmargin. Moreover, it is able to accurately model uncertainty, leading to well\ncalibrated classifiers, and is easily extensible and flexible, unlike many\nrecent approaches to k-shot learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 14:43:25 GMT"}, {"version": "v2", "created": "Sat, 9 Dec 2017 00:09:06 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Bauer", "Matthias", ""], ["Rojas-Carulla", "Mateo", ""], ["\u015awi\u0105tkowski", "Jakub Bart\u0142omiej", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Turner", "Richard E.", ""]]}, {"id": "1706.00348", "submitter": "David Schnoerr", "authors": "David Schnoerr, Botond Cseke, Ramon Grima and Guido Sanguinetti", "title": "Efficient Low-Order Approximation of First-Passage Time Distributions", "comments": "5 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 119, 210601 (2017)", "doi": "10.1103/PhysRevLett.119.210601", "report-no": null, "categories": "physics.comp-ph physics.bio-ph q-bio.QM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing first-passage time distributions for\nreaction processes modelled by master equations. We show that this generally\nintractable class of problems is equivalent to a sequential Bayesian inference\nproblem for an auxiliary observation process. The solution can be approximated\nefficiently by solving a closed set of coupled ordinary differential equations\n(for the low-order moments of the process) whose size scales with the number of\nspecies. We apply it to an epidemic model and a trimerisation process, and show\ngood agreement with stochastic simulations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 15:26:29 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 16:07:34 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Schnoerr", "David", ""], ["Cseke", "Botond", ""], ["Grima", "Ramon", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1706.00400", "submitter": "Narayanaswamy Siddharth", "authors": "N. Siddharth, Brooks Paige, Jan-Willem van de Meent, Alban Desmaison,\n  Noah D. Goodman, Pushmeet Kohli, Frank Wood, Philip H.S. Torr", "title": "Learning Disentangled Representations with Semi-Supervised Deep\n  Generative Models", "comments": "Accepted for publication at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) learn representations of data by jointly\ntraining a probabilistic encoder and decoder network. Typically these models\nencode all features of the data into a single variable. Here we are interested\nin learning disentangled representations that encode distinct aspects of the\ndata into separate variables. We propose to learn such representations using\nmodel architectures that generalise from standard VAEs, employing a general\ngraphical model structure in the encoder and decoder. This allows us to train\npartially-specified models that make relatively strong assumptions about a\nsubset of interpretable variables and rely on the flexibility of neural\nnetworks to learn representations for the remaining variables. We further\ndefine a general objective for semi-supervised learning in this model class,\nwhich can be approximated using an importance sampling procedure. We evaluate\nour framework's ability to learn disentangled representations, both by\nqualitative exploration of its generative capacity, and quantitative evaluation\nof its discriminative ability on a variety of models and datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 17:23:07 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 17:55:15 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Siddharth", "N.", ""], ["Paige", "Brooks", ""], ["van de Meent", "Jan-Willem", ""], ["Desmaison", "Alban", ""], ["Goodman", "Noah D.", ""], ["Kohli", "Pushmeet", ""], ["Wood", "Frank", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1706.00473", "submitter": "Vadim Sokolov", "authors": "Nicholas Polson and Vadim Sokolov", "title": "Deep Learning: A Bayesian Perspective", "comments": null, "journal-ref": null, "doi": "10.1214/17-BA1082", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a form of machine learning for nonlinear high dimensional\npattern matching and prediction. By taking a Bayesian probabilistic\nperspective, we provide a number of insights into more efficient algorithms for\noptimisation and hyper-parameter tuning. Traditional high-dimensional data\nreduction techniques, such as principal component analysis (PCA), partial least\nsquares (PLS), reduced rank regression (RRR), projection pursuit regression\n(PPR) are all shown to be shallow learners. Their deep learning counterparts\nexploit multiple deep layers of data reduction which provide predictive\nperformance gains. Stochastic gradient descent (SGD) training optimisation and\nDropout (DO) regularization provide estimation and variable selection. Bayesian\nregularization is central to finding weights and connections in networks to\noptimize the predictive bias-variance trade-off. To illustrate our methodology,\nwe provide an analysis of international bookings on Airbnb. Finally, we\nconclude with directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 19:50:37 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 00:57:42 GMT"}, {"version": "v3", "created": "Tue, 5 Sep 2017 01:33:09 GMT"}, {"version": "v4", "created": "Tue, 14 Nov 2017 03:36:51 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Polson", "Nicholas", ""], ["Sokolov", "Vadim", ""]]}, {"id": "1706.00476", "submitter": "Po-Wei Wang", "authors": "Po-Wei Wang, Wei-Cheng Chang, J. Zico Kolter", "title": "The Mixing method: low-rank coordinate descent for semidefinite\n  programming with diagonal constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a low-rank coordinate descent approach to\nstructured semidefinite programming with diagonal constraints. The approach,\nwhich we call the Mixing method, is extremely simple to implement, has no free\nparameters, and typically attains an order of magnitude or better improvement\nin optimization performance over the current state of the art. We show that the\nmethod is strictly decreasing, converges to a critical point, and further that\nfor sufficient rank all non-optimal critical points are unstable. Moreover, we\nprove that with a step size, the Mixing method converges to the global optimum\nof the semidefinite program almost surely in a locally linear rate under random\ninitialization. This is the first low-rank semidefinite programming method that\nhas been shown to achieve a global optimum on the spherical manifold without\nassumption. We apply our algorithm to two related domains: solving the maximum\ncut semidefinite relaxation, and solving a maximum satisfiability relaxation\n(we also briefly consider additional applications such as learning word\nembeddings). In all settings, we demonstrate substantial improvement over the\nexisting state of the art along various dimensions, and in total, this work\nexpands the scope and scale of problems that can be solved using semidefinite\nprogramming methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 19:58:38 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 05:19:39 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 17:04:36 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Wang", "Po-Wei", ""], ["Chang", "Wei-Cheng", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1706.00514", "submitter": "Yuta Umezu", "authors": "Yuta Umezu and Ichiro Takeuchi", "title": "Selective Inference for Change Point Detection in Multi-dimensional\n  Sequences", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting change points (CPs) that are characterized\nby a subset of dimensions in a multi-dimensional sequence. A method for\ndetecting those CPs can be formulated as a two-stage method: one for selecting\nrelevant dimensions, and another for selecting CPs. It has been difficult to\nproperly control the false detection probability of these CP detection methods\nbecause selection bias in each stage must be properly corrected. Our main\ncontribution in this paper is to formulate a CP detection problem as a\nselective inference problem, and show that exact (non-asymptotic) inference is\npossible for a class of CP detection methods. We demonstrate the performances\nof the proposed selective inference framework through numerical simulations and\nits application to our motivating medical data analysis problem.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 22:31:37 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 02:43:13 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 01:08:09 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Umezu", "Yuta", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1706.00544", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen and Sijia Liu", "title": "Bias-Variance Tradeoff of Graph Laplacian Regularizer", "comments": "accepted by IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2017.2712141", "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a bias-variance tradeoff of graph Laplacian regularizer,\nwhich is widely used in graph signal processing and semi-supervised learning\ntasks. The scaling law of the optimal regularization parameter is specified in\nterms of the spectral graph properties and a novel signal-to-noise ratio\nparameter, which suggests selecting a mediocre regularization parameter is\noften suboptimal. The analysis is applied to three applications, including\nrandom, band-limited, and multiple-sampled graph signals. Experiments on\nsynthetic and real-world graphs demonstrate near-optimal performance of the\nestablished analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 03:28:50 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""]]}, {"id": "1706.00550", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric P. Xing", "title": "On Unifying Deep Generative Models", "comments": "Polished and extended content over the ICLR conference version:\n  https://openreview.net/pdf?id=rylSzl-R-", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have achieved impressive success in recent years.\nGenerative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as\nemerging families for generative model learning, have largely been considered\nas two distinct paradigms and received extensive independent studies\nrespectively. This paper aims to establish formal connections between GANs and\nVAEs through a new formulation of them. We interpret sample generation in GANs\nas performing posterior inference, and show that GANs and VAEs involve\nminimizing KL divergences of respective posterior and inference distributions\nwith opposite directions, extending the two learning phases of classic\nwake-sleep algorithm, respectively. The unified view provides a powerful tool\nto analyze a diverse set of existing model variants, and enables to transfer\ntechniques across research lines in a principled way. For example, we apply the\nimportance weighting method in VAE literatures for improved GAN learning, and\nenhance VAEs with an adversarial mechanism that leverages generated samples.\nExperiments show generality and effectiveness of the transferred techniques.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 04:15:44 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 02:43:28 GMT"}, {"version": "v3", "created": "Sun, 16 Jul 2017 20:13:20 GMT"}, {"version": "v4", "created": "Sun, 1 Apr 2018 02:40:59 GMT"}, {"version": "v5", "created": "Wed, 11 Jul 2018 15:01:24 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1706.00598", "submitter": "J\\\"orn-Henrik Jacobsen", "authors": "J\\\"orn-Henrik Jacobsen, Bert de Brabandere, Arnold W.M. Smeulders", "title": "Dynamic Steerable Blocks in Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filters in convolutional networks are typically parameterized in a pixel\nbasis, that does not take prior knowledge about the visual world into account.\nWe investigate the generalized notion of frames designed with image properties\nin mind, as alternatives to this parametrization. We show that frame-based\nResNets and Densenets can improve performance on Cifar-10+ consistently, while\nhaving additional pleasant properties like steerability. By exploiting these\ntransformation properties explicitly, we arrive at dynamic steerable blocks.\nThey are an extension of residual blocks, that are able to seamlessly transform\nfilters under pre-defined transformations, conditioned on the input at training\nand inference time. Dynamic steerable blocks learn the degree of invariance\nfrom data and locally adapt filters, allowing them to apply a different\ngeometrical variant of the same filter to each location of the feature map.\nWhen evaluated on the Berkeley Segmentation contour detection dataset, our\napproach outperforms all competing approaches that do not utilize pre-training.\nOur results highlight the benefits of image-based regularization to deep\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 09:08:09 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 15:12:52 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", ""], ["de Brabandere", "Bert", ""], ["Smeulders", "Arnold W. M.", ""]]}, {"id": "1706.00636", "submitter": "Caifa Zhou", "authors": "Yang Gu, Caifa Zhou, Andreas Wieser, and Zhimin Zhou", "title": "WiFi based trajectory alignment, calibration and easy site survey using\n  smart phones and foot-mounted IMUs", "comments": "9 figures, 6 pages, paper under review of IPIN 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foot-mounted inertial positioning (FMIP) can face problems of inertial drifts\nand unknown initial states in real applications, which renders the estimated\ntrajectories inaccurate and not obtained in a well defined coordinate system\nfor matching trajectories of different users. In this paper, an approach\nadopting received signal strength (RSS) measurements for Wifi access points\n(APs) are proposed to align and calibrate the trajectories estimated from foot\nmounted inertial measurement units (IMUs). A crowd-sourced radio map (RM) can\nbe built subsequently and can be used for fingerprinting based Wifi indoor\npositioning (FWIP). The foundation of the proposed approach is graph based\nsimultaneously localization and mapping (SLAM). The nodes in the graph denote\nusers poses and the edges denote the pairwise constrains between the nodes. The\nconstrains are derived from: (1) inertial estimated trajectories; (2) vicinity\nin the RSS space. With these constrains, an error functions is defined. By\nminimizing the error function, the graph is optimized and the\naligned/calibrated trajectories along with the RM are acquired. The\nexperimental results have corroborated the effectiveness of the approach for\ntrajectory alignment, calibration as well as RM construction.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 11:34:01 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Gu", "Yang", ""], ["Zhou", "Caifa", ""], ["Wieser", "Andreas", ""], ["Zhou", "Zhimin", ""]]}, {"id": "1706.00705", "submitter": "Andre Manoel", "authors": "Andre Manoel, Florent Krzakala, Eric W. Tramel, Lenka Zdeborov\\'a", "title": "Streaming Bayesian inference: theoretical limits and mini-batch\n  approximate message-passing", "comments": "19 pages, 4 figures", "journal-ref": "2017 55th Annual Allerton Conference on Communication, Control,\n  and Computing (Allerton), Monticello, IL, USA, 2017, pp. 1048-1055", "doi": "10.1109/ALLERTON.2017.8262853", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning for real-world large-scale data problems, one must\noften resort to \"streaming\" algorithms which operate sequentially on small\nbatches of data. In this work, we present an analysis of the\ninformation-theoretic limits of mini-batch inference in the context of\ngeneralized linear models and low-rank matrix factorization. In a controlled\nBayes-optimal setting, we characterize the optimal performance and phase\ntransitions as a function of mini-batch size. We base part of our results on a\ndetailed analysis of a mini-batch version of the approximate message-passing\nalgorithm (Mini-AMP), which we introduce. Additionally, we show that this\ntheoretical optimality carries over into real-data problems by illustrating\nthat Mini-AMP is competitive with standard streaming algorithms for clustering.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 14:45:15 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Manoel", "Andre", ""], ["Krzakala", "Florent", ""], ["Tramel", "Eric W.", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1706.00729", "submitter": "Daniel Hsu", "authors": "Arushi Gupta, Daniel Hsu", "title": "Parameter identification in Markov chain choice models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the parameter identification problem for the Markov chain\nchoice model of Blanchet, Gallego, and Goyal used in assortment planning. In\nthis model, the product selected by a customer is determined by a Markov chain\nover the products, where the products in the offered assortment are absorbing\nstates. The underlying parameters of the model were previously shown to be\nidentifiable from the choice probabilities for the all-products assortment,\ntogether with choice probabilities for assortments of all-but-one products.\nObtaining and estimating choice probabilities for such large assortments is not\ndesirable in many settings. The main result of this work is that the parameters\nmay be identified from assortments of sizes two and three, regardless of the\ntotal number of products. The result is obtained via a simple and efficient\nparameter recovery algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 15:47:17 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 18:21:52 GMT"}, {"version": "v3", "created": "Tue, 25 Jul 2017 21:03:33 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Gupta", "Arushi", ""], ["Hsu", "Daniel", ""]]}, {"id": "1706.00754", "submitter": "Kevin Bello", "authors": "Kevin Bello and Jean Honorio", "title": "Computationally and statistically efficient learning of causal Bayes\n  nets using path queries", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS) 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from empirical data is a fundamental problem in many\nscientific domains. Observational data allows for identifiability only up to\nMarkov equivalence class. In this paper we first propose a polynomial time\nalgorithm for learning the exact correctly-oriented structure of the transitive\nreduction of any causal Bayesian network with high probability, by using\ninterventional path queries. Each path query takes as input an origin node and\na target node, and answers whether there is a directed path from the origin to\nthe target. This is done by intervening on the origin node and observing\nsamples from the target node. We theoretically show the logarithmic sample\ncomplexity for the size of interventional data per path query, for continuous\nand discrete networks. We then show how to learn the transitive edges using\nalso logarithmic sample complexity (albeit in time exponential in the maximum\nnumber of parents for discrete networks), which allows us to learn the full\nnetwork. We further extend our work by reducing the number of interventional\npath queries for learning rooted trees. We also provide an analysis of\nimperfect interventions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 17:00:01 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 20:56:02 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 19:49:03 GMT"}, {"version": "v4", "created": "Fri, 16 Aug 2019 04:09:36 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Bello", "Kevin", ""], ["Honorio", "Jean", ""]]}, {"id": "1706.00764", "submitter": "Yang Yuan", "authors": "Elad Hazan, Adam Klivans, Yang Yuan", "title": "Hyperparameter Optimization: A Spectral Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple, fast algorithm for hyperparameter optimization inspired by\ntechniques from the analysis of Boolean functions. We focus on the\nhigh-dimensional regime where the canonical example is training a neural\nnetwork with a large number of hyperparameters. The algorithm --- an iterative\napplication of compressed sensing techniques for orthogonal polynomials ---\nrequires only uniform sampling of the hyperparameters and is thus easily\nparallelizable.\n  Experiments for training deep neural networks on Cifar-10 show that compared\nto state-of-the-art tools (e.g., Hyperband and Spearmint), our algorithm finds\nsignificantly improved solutions, in some cases better than what is attainable\nby hand-tuning. In terms of overall running time (i.e., time required to sample\nvarious settings of hyperparameters plus additional computation time), we are\nat least an order of magnitude faster than Hyperband and Bayesian Optimization.\nWe also outperform Random Search 8x.\n  Additionally, our method comes with provable guarantees and yields the first\nimprovements on the sample complexity of learning decision trees in over two\ndecades. In particular, we obtain the first quasi-polynomial time algorithm for\nlearning noisy decision trees with polynomial sample complexity.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 17:25:58 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 16:51:58 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 02:54:31 GMT"}, {"version": "v4", "created": "Sat, 20 Jan 2018 03:49:23 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Hazan", "Elad", ""], ["Klivans", "Adam", ""], ["Yuan", "Yang", ""]]}, {"id": "1706.00820", "submitter": "Adam Smith", "authors": "Adam Smith", "title": "Information, Privacy and Stability in Adaptive Data Analysis", "comments": "15 pages, first drafted February 2017. A version of this survey\n  appears in the Information Theory Society Newsletter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional statistical theory assumes that the analysis to be performed on a\ngiven data set is selected independently of the data themselves. This\nassumption breaks downs when data are re-used across analyses and the analysis\nto be performed at a given stage depends on the results of earlier stages. Such\ndependency can arise when the same data are used by several scientific studies,\nor when a single analysis consists of multiple stages.\n  How can we draw statistically valid conclusions when data are re-used? This\nis the focus of a recent and active line of work. At a high level, these\nresults show that limiting the information revealed by earlier stages of\nanalysis controls the bias introduced in later stages by adaptivity.\n  Here we review some known results in this area and highlight the role of\ninformation-theoretic concepts, notably several one-shot notions of mutual\ninformation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 19:03:47 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Smith", "Adam", ""]]}, {"id": "1706.00856", "submitter": "Murat Seckin Ayhan", "authors": "Murat Seckin Ayhan and Vijay Raghavan and Alzheimer's disease\n  Neuroimaging Initiative", "title": "Multiple Kernel Learning and Automatic Subspace Relevance Determination\n  for High-dimensional Neuroimaging Data", "comments": "The material presented here is to promote the dissemination of\n  scholarly and technical work in a timely fashion. Data in this article are\n  from ADNI (adni.loni.usc.edu). As such, ADNI provided data but did not\n  participate in writing of this report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease is a major cause of dementia. Its diagnosis requires\naccurate biomarkers that are sensitive to disease stages. In this respect, we\nregard probabilistic classification as a method of designing a probabilistic\nbiomarker for disease staging. Probabilistic biomarkers naturally support the\ninterpretation of decisions and evaluation of uncertainty associated with them.\nIn this paper, we obtain probabilistic biomarkers via Gaussian Processes.\nGaussian Processes enable probabilistic kernel machines that offer flexible\nmeans to accomplish Multiple Kernel Learning. Exploiting this flexibility, we\npropose a new variation of Automatic Relevance Determination and tackle the\nchallenges of high dimensionality through multiple kernels. Our research\nresults demonstrate that the Gaussian Process models are competitive with or\nbetter than the well-known Support Vector Machine in terms of classification\nperformance even in the cases of single kernel learning. Extending the basic\nscheme towards the Multiple Kernel Learning, we improve the efficacy of the\nGaussian Process models and their interpretability in terms of the known\nanatomical correlates of the disease. For instance, the disease pathology\nstarts in and around the hippocampus and entorhinal cortex. Through the use of\nGaussian Processes and Multiple Kernel Learning, we have automatically and\nefficiently determined those portions of neuroimaging data. In addition to\ntheir interpretability, our Gaussian Process models are competitive with recent\ndeep learning solutions under similar settings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 21:16:50 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Ayhan", "Murat Seckin", ""], ["Raghavan", "Vijay", ""], ["Initiative", "Alzheimer's disease Neuroimaging", ""]]}, {"id": "1706.00868", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov, Hendrik Poulsen Nautrup, Mario Krenn, Vedran\n  Dunjko, Markus Tiersch, Anton Zeilinger, Hans J. Briegel", "title": "Active learning machine learns to create new quantum experiments", "comments": "11 pages, 6 figures, 1 table; A. A. Melnikov and H. Poulsen Nautrup\n  contributed equally to this work", "journal-ref": "PNAS 115(6), 1221-1226 (2018)", "doi": "10.1073/pnas.1714936115", "report-no": null, "categories": "quant-ph cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How useful can machine learning be in a quantum laboratory? Here we raise the\nquestion of the potential of intelligent machines in the context of scientific\nresearch. A major motivation for the present work is the unknown reachability\nof various entanglement classes in quantum experiments. We investigate this\nquestion by using the projective simulation model, a physics-oriented approach\nto artificial intelligence. In our approach, the projective simulation system\nis challenged to design complex photonic quantum experiments that produce\nhigh-dimensional entangled multiphoton states, which are of high interest in\nmodern quantum experiments. The artificial intelligence system learns to create\na variety of entangled states, and improves the efficiency of their\nrealization. In the process, the system autonomously (re)discovers experimental\ntechniques which are only now becoming standard in modern quantum optical\nexperiments - a trait which was not explicitly demanded from the system but\nemerged through the process of learning. Such features highlight the\npossibility that machines could have a significantly more creative role in\nfuture research.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 22:35:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 17:27:05 GMT"}, {"version": "v3", "created": "Thu, 8 Feb 2018 15:40:01 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Nautrup", "Hendrik Poulsen", ""], ["Krenn", "Mario", ""], ["Dunjko", "Vedran", ""], ["Tiersch", "Markus", ""], ["Zeilinger", "Anton", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1706.01014", "submitter": "Ming Yan", "authors": "Xiaolin Huang and Ming Yan", "title": "Nonconvex penalties with analytical solutions for one-bit compressive\n  sensing", "comments": null, "journal-ref": "X. Huang and M. Yan, Non-convex penalties with analytical\n  solutions for one-bit compressive sensing, Signal Processing, 144 (2018),\n  341-351", "doi": "10.1016/j.sigpro.2017.10.023", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-bit measurements widely exist in the real world, and they can be used to\nrecover sparse signals. This task is known as the problem of learning\nhalfspaces in learning theory and one-bit compressive sensing (1bit-CS) in\nsignal processing. In this paper, we propose novel algorithms based on both\nconvex and nonconvex sparsity-inducing penalties for robust 1bit-CS. We provide\na sufficient condition to verify whether a solution is globally optimal or not.\nThen we show that the globally optimal solution for positive homogeneous\npenalties can be obtained in two steps: a proximal operator and a normalization\nstep. For several nonconvex penalties, including minimax concave penalty (MCP),\n$\\ell_0$ norm, and sorted $\\ell_1$ penalty, we provide fast algorithms for\nfinding the analytical solutions by solving the dual problem. Specifically, our\nalgorithm is more than $200$ times faster than the existing algorithm for MCP.\nIts efficiency is comparable to the algorithm for the $\\ell_1$ penalty in time,\nwhile its performance is much better. Among these penalties, the sorted\n$\\ell_1$ penalty is most robust to noise in different settings.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 02:17:12 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 21:44:00 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Huang", "Xiaolin", ""], ["Yan", "Ming", ""]]}, {"id": "1706.01081", "submitter": "Mingda Qiao", "authors": "Lijie Chen, Anupam Gupta, Jian Li, Mingda Qiao, Ruosong Wang", "title": "Nearly Optimal Sampling Algorithms for Combinatorial Pure Exploration", "comments": "Accepted to COLT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the combinatorial pure exploration problem Best-Set in stochastic\nmulti-armed bandits. In a Best-Set instance, we are given $n$ arms with unknown\nreward distributions, as well as a family $\\mathcal{F}$ of feasible subsets\nover the arms. Our goal is to identify the feasible subset in $\\mathcal{F}$\nwith the maximum total mean using as few samples as possible. The problem\ngeneralizes the classical best arm identification problem and the top-$k$ arm\nidentification problem, both of which have attracted significant attention in\nrecent years. We provide a novel instance-wise lower bound for the sample\ncomplexity of the problem, as well as a nontrivial sampling algorithm, matching\nthe lower bound up to a factor of $\\ln|\\mathcal{F}|$. For an important class of\ncombinatorial families, we also provide polynomial time implementation of the\nsampling algorithm, using the equivalence of separation and optimization for\nconvex program, and approximate Pareto curves in multi-objective optimization.\nWe also show that the $\\ln|\\mathcal{F}|$ factor is inevitable in general\nthrough a nontrivial lower bound construction. Our results significantly\nimprove several previous results for several important combinatorial\nconstraints, and provide a tighter understanding of the general Best-Set\nproblem.\n  We further introduce an even more general problem, formulated in geometric\nterms. We are given $n$ Gaussian arms with unknown means and unit variance.\nConsider the $n$-dimensional Euclidean space $\\mathbb{R}^n$, and a collection\n$\\mathcal{O}$ of disjoint subsets. Our goal is to determine the subset in\n$\\mathcal{O}$ that contains the $n$-dimensional vector of the means. The\nproblem generalizes most pure exploration bandit problems studied in the\nliterature. We provide the first nearly optimal sample complexity upper and\nlower bounds for the problem.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 14:27:17 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Chen", "Lijie", ""], ["Gupta", "Anupam", ""], ["Li", "Jian", ""], ["Qiao", "Mingda", ""], ["Wang", "Ruosong", ""]]}, {"id": "1706.01108", "submitter": "Peter Richt\\'arik", "authors": "Peter Richt\\'arik and Martin Tak\\'a\\v{c}", "title": "Stochastic Reformulations of Linear Systems: Algorithms and Convergence\n  Theory", "comments": "Accepted to SIAM Journal on Matrix Analysis and Applications. This\n  arXiv version has an additional section (Section 6.2), listing several\n  extensions done since the paper was first written. Statistics: 39 pages, 4\n  reformulations, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a family of reformulations of an arbitrary consistent linear\nsystem into a stochastic problem. The reformulations are governed by two\nuser-defined parameters: a positive definite matrix defining a norm, and an\narbitrary discrete or continuous distribution over random matrices. Our\nreformulation has several equivalent interpretations, allowing for researchers\nfrom various communities to leverage their domain specific insights. In\nparticular, our reformulation can be equivalently seen as a stochastic\noptimization problem, stochastic linear system, stochastic fixed point problem\nand a probabilistic intersection problem. We prove sufficient, and necessary\nand sufficient conditions for the reformulation to be exact. Further, we\npropose and analyze three stochastic algorithms for solving the reformulated\nproblem---basic, parallel and accelerated methods---with global linear\nconvergence rates. The rates can be interpreted as condition numbers of a\nmatrix which depends on the system matrix and on the reformulation parameters.\nThis gives rise to a new phenomenon which we call stochastic preconditioning,\nand which refers to the problem of finding parameters (matrix and distribution)\nleading to a sufficiently small condition number. Our basic method can be\nequivalently interpreted as stochastic gradient descent, stochastic Newton\nmethod, stochastic proximal point method, stochastic fixed point method, and\nstochastic projection method, with fixed stepsize (relaxation parameter),\napplied to the reformulations.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 17:04:15 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 04:44:19 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 11:21:42 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 16:50:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1706.01109", "submitter": "Tatiana Likhomanenko", "authors": "Alex Rogozhnikov and Tatiana Likhomanenko", "title": "InfiniteBoost: building infinite ensembles with gradient descent", "comments": "7 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning ensemble methods have demonstrated high accuracy for the\nvariety of problems in different areas. Two notable ensemble methods widely\nused in practice are gradient boosting and random forests. In this paper we\npresent InfiniteBoost - a novel algorithm, which combines important properties\nof these two approaches. The algorithm constructs the ensemble of trees for\nwhich two properties hold: trees of the ensemble incorporate the mistakes done\nby others; at the same time the ensemble could contain the infinite number of\ntrees without the over-fitting effect. The proposed algorithm is evaluated on\nthe regression, classification, and ranking tasks using large scale, publicly\navailable datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 17:06:18 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 17:20:36 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Rogozhnikov", "Alex", ""], ["Likhomanenko", "Tatiana", ""]]}, {"id": "1706.01120", "submitter": "Unai Garciarena", "authors": "Unai Garciarena, Roberto Santana, Alexander Mendiburu", "title": "Evolving imputation strategies for missing data in classification\n  problems with TPOT", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data has a ubiquitous presence in real-life applications of machine\nlearning techniques. Imputation methods are algorithms conceived for restoring\nmissing values in the data, based on other entries in the database. The choice\nof the imputation method has an influence on the performance of the machine\nlearning technique, e.g., it influences the accuracy of the classification\nalgorithm applied to the data. Therefore, selecting and applying the right\nimputation method is important and usually requires a substantial amount of\nhuman intervention. In this paper we propose the use of genetic programming\ntechniques to search for the right combination of imputation and classification\nalgorithms. We build our work on the recently introduced Python-based TPOT\nlibrary, and incorporate a heterogeneous set of imputation algorithms as part\nof the machine learning pipeline search. We show that genetic programming can\nautomatically find increasingly better pipelines that include the most\neffective combinations of imputation methods, feature pre-processing, and\nclassifiers for a variety of classification problems with missing data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 18:20:07 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 22:38:19 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Garciarena", "Unai", ""], ["Santana", "Roberto", ""], ["Mendiburu", "Alexander", ""]]}, {"id": "1706.01151", "submitter": "Neev Samuel", "authors": "Neev Samuel, Tzvi Diskin and Ami Wiesel", "title": "Deep MIMO Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the use of deep neural networks in the context of\nMultiple-Input-Multiple-Output (MIMO) detection. We give a brief introduction\nto deep learning and propose a modern neural network architecture suitable for\nthis detection task. First, we consider the case in which the MIMO channel is\nconstant, and we learn a detector for a specific system. Next, we consider the\nharder case in which the parameters are known yet changing and a single\ndetector must be learned for all multiple varying channels. We demonstrate the\nperformance of our deep MIMO detector using numerical simulations in comparison\nto competing methods including approximate message passing and semidefinite\nrelaxation. The results show that deep networks can achieve state of the art\naccuracy with significantly lower complexity while providing robustness against\nill conditioned channels and mis-specified noise variance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 21:33:11 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Samuel", "Neev", ""], ["Diskin", "Tzvi", ""], ["Wiesel", "Ami", ""]]}, {"id": "1706.01158", "submitter": "Qiang Sun", "authors": "Qiang Sun, Kean Ming Tan, Han Liu, Tong Zhang", "title": "Graphical Nonconvex Optimization for Optimal Estimation in Gaussian\n  Graphical Models", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning high-dimensional Gaussian graphical\nmodels. The graphical lasso is one of the most popular methods for estimating\nGaussian graphical models. However, it does not achieve the oracle rate of\nconvergence. In this paper, we propose the graphical nonconvex optimization for\noptimal estimation in Gaussian graphical models, which is then approximated by\na sequence of convex programs. Our proposal is computationally tractable and\nproduces an estimator that achieves the oracle rate of convergence. The\nstatistical error introduced by the sequential approximation using the convex\nprograms are clearly demonstrated via a contraction property. The rate of\nconvergence can be further improved using the notion of sparsity pattern. The\nproposed methodology is then extended to semiparametric graphical models. We\nshow through numerical studies that the proposed estimator outperforms other\npopular methods for estimating Gaussian graphical models.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 23:20:13 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Sun", "Qiang", ""], ["Tan", "Kean Ming", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""]]}, {"id": "1706.01191", "submitter": "Pragya Sur", "authors": "Pragya Sur, Yuxin Chen, Emmanuel J. Cand\\`es", "title": "The Likelihood Ratio Test in High-Dimensional Logistic Regression Is\n  Asymptotically a Rescaled Chi-Square", "comments": "58 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is used thousands of times a day to fit data, predict\nfuture outcomes, and assess the statistical significance of explanatory\nvariables. When used for the purpose of statistical inference, logistic models\nproduce p-values for the regression coefficients by using an approximation to\nthe distribution of the likelihood-ratio test. Indeed, Wilks' theorem asserts\nthat whenever we have a fixed number $p$ of variables, twice the log-likelihood\nratio (LLR) $2\\Lambda$ is distributed as a $\\chi^2_k$ variable in the limit of\nlarge sample sizes $n$; here, $k$ is the number of variables being tested. In\nthis paper, we prove that when $p$ is not negligible compared to $n$, Wilks'\ntheorem does not hold and that the chi-square approximation is grossly\nincorrect; in fact, this approximation produces p-values that are far too small\n(under the null hypothesis). Assume that $n$ and $p$ grow large in such a way\nthat $p/n\\rightarrow\\kappa$ for some constant $\\kappa < 1/2$. We prove that for\na class of logistic models, the LLR converges to a rescaled chi-square, namely,\n$2\\Lambda~\\stackrel{\\mathrm{d}}{\\rightarrow}~\\alpha(\\kappa)\\chi_k^2$, where the\nscaling factor $\\alpha(\\kappa)$ is greater than one as soon as the\ndimensionality ratio $\\kappa$ is positive. Hence, the LLR is larger than\nclassically assumed. For instance, when $\\kappa=0.3$,\n$\\alpha(\\kappa)\\approx1.5$. In general, we show how to compute the scaling\nfactor by solving a nonlinear system of two equations with two unknowns. Our\nmathematical arguments are involved and use techniques from approximate message\npassing theory, non-asymptotic random matrix theory and convex geometry. We\nalso complement our mathematical study by showing that the new limiting\ndistribution is accurate for finite sample sizes. Finally, all the results from\nthis paper extend to some other regression models such as the probit regression\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 05:21:07 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Sur", "Pragya", ""], ["Chen", "Yuxin", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1706.01214", "submitter": "Azad Naik", "authors": "Azad Naik, Huzefa Rangwala", "title": "Inconsistent Node Flattening for Improving Top-down Hierarchical\n  Classification", "comments": "IEEE International Conference on Data Science and Advanced Analytics\n  (DSAA), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Large-scale classification of data where classes are structurally organized\nin a hierarchy is an important area of research. Top-down approaches that\nexploit the hierarchy during the learning and prediction phase are efficient\nfor large scale hierarchical classification. However, accuracy of top-down\napproaches is poor due to error propagation i.e., prediction errors made at\nhigher levels in the hierarchy cannot be corrected at lower levels. One of the\nmain reason behind errors at the higher levels is the presence of inconsistent\nnodes that are introduced due to the arbitrary process of creating these\nhierarchies by domain experts. In this paper, we propose two different\ndata-driven approaches (local and global) for hierarchical structure\nmodification that identifies and flattens inconsistent nodes present within the\nhierarchy. Our extensive empirical evaluation of the proposed approaches on\nseveral image and text datasets with varying distribution of features, classes\nand training instances per class shows improved classification performance over\ncompeting hierarchical modification approaches. Specifically, we see an\nimprovement upto 7% in Macro-F1 score with our approach over best TD baseline.\nSOURCE CODE: http://www.cs.gmu.edu/~mlbio/InconsistentNodeFlattening\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 06:53:30 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Naik", "Azad", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1706.01242", "submitter": "Jos van der Westhuizen", "authors": "Jos van der Westhuizen and Joan Lasenby", "title": "Bayesian LSTMs in medicine", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medical field stands to see significant benefits from the recent advances\nin deep learning. Knowing the uncertainty in the decision made by any machine\nlearning algorithm is of utmost importance for medical practitioners. This\nstudy demonstrates the utility of using Bayesian LSTMs for classification of\nmedical time series. Four medical time series datasets are used to show the\naccuracy improvement Bayesian LSTMs provide over standard LSTMs. Moreover, we\nshow cherry-picked examples of confident and uncertain classifications of the\nmedical time series. With simple modifications of the common practice for deep\nlearning, significant improvements can be made for the medical practitioner and\npatient.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 09:04:07 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["van der Westhuizen", "Jos", ""], ["Lasenby", "Joan", ""]]}, {"id": "1706.01252", "submitter": "Takeru Matsuda", "authors": "Takeru Matsuda and Fumiyasu Komaki", "title": "Empirical Bayes Matrix Completion", "comments": "15 pages", "journal-ref": "Computational Statistics & Data Analysis, Vol. 137, pp. 195--210,\n  2019", "doi": "10.1016/j.csda.2019.02.006", "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an empirical Bayes (EB) algorithm for the matrix completion\nproblems. The EB algorithm is motivated from the singular value shrinkage\nestimator for matrix means by Efron and Morris (1972). Since the EB algorithm\nis essentially the EM algorithm applied to a simple model, it does not require\nheuristic parameter tuning other than tolerance. Numerical results demonstrated\nthat the EB algorithm achieves a good trade-off between accuracy and efficiency\ncompared to existing algorithms and that it works particularly well when the\ndifference between the number of rows and columns is large. Application to real\ndata also shows the practical utility of the EB algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 09:50:59 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 10:42:32 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Matsuda", "Takeru", ""], ["Komaki", "Fumiyasu", ""]]}, {"id": "1706.01338", "submitter": "Thomas Moreau", "authors": "Thomas Moreau, Joan Bruna", "title": "Understanding the Learned Iterative Soft Thresholding Algorithm with\n  matrix factorization", "comments": "Ongoing work - This document is not complete and might contains\n  errors. arXiv admin note: text overlap with arXiv:1609.00285", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding is a core building block in many data analysis and machine\nlearning pipelines. Typically it is solved by relying on generic optimization\ntechniques, such as the Iterative Soft Thresholding Algorithm and its\naccelerated version (ISTA, FISTA). These methods are optimal in the class of\nfirst-order methods for non-smooth, convex functions. However, they do not\nexploit the particular structure of the problem at hand nor the input data\ndistribution. An acceleration using neural networks, coined LISTA, was proposed\nin Gregor and Le Cun (2010), which showed empirically that one could achieve\nhigh quality estimates with few iterations by modifying the parameters of the\nproximal splitting appropriately.\n  In this paper we study the reasons for such acceleration. Our mathematical\nanalysis reveals that it is related to a specific matrix factorization of the\nGram kernel of the dictionary, which attempts to nearly diagonalise the kernel\nwith a basis that produces a small perturbation of the $\\ell_1$ ball. When this\nfactorization succeeds, we prove that the resulting splitting algorithm enjoys\nan improved convergence bound with respect to the non-adaptive version.\nMoreover, our analysis also shows that conditions for acceleration occur mostly\nat the beginning of the iterative process, consistent with numerical\nexperiments. We further validate our analysis by showing that on dictionaries\nwhere this factorization does not exist, adaptive acceleration fails.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 07:24:10 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Moreau", "Thomas", ""], ["Bruna", "Joan", ""]]}, {"id": "1706.01350", "submitter": "Alessandro Achille", "authors": "Alessandro Achille and Stefano Soatto", "title": "Emergence of Invariance and Disentanglement in Deep Representations", "comments": "Deep learning, neural network, representation, flat minima,\n  information bottleneck, overfitting, generalization, sufficiency, minimality,\n  sensitivity, information complexity, stochastic gradient descent,\n  regularization, total correlation, PAC-Bayes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using established principles from Statistics and Information Theory, we show\nthat invariance to nuisance factors in a deep neural network is equivalent to\ninformation minimality of the learned representation, and that stacking layers\nand injecting noise during training naturally bias the network towards learning\ninvariant representations. We then decompose the cross-entropy loss used during\ntraining and highlight the presence of an inherent overfitting term. We propose\nregularizing the loss by bounding such a term in two equivalent ways: One with\na Kullbach-Leibler term, which relates to a PAC-Bayes perspective; the other\nusing the information in the weights as a measure of complexity of a learned\nmodel, yielding a novel Information Bottleneck for the weights. Finally, we\nshow that invariance and independence of the components of the representation\nlearned by the network are bounded above and below by the information in the\nweights, and therefore are implicitly optimized during training. The theory\nenables us to quantify and predict sharp phase transitions between underfitting\nand overfitting of random labels when using our regularized loss, which we\nverify in experiments, and sheds light on the relation between the geometry of\nthe loss function, invariance properties of the learned representation, and\ngeneralization error.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 14:31:03 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 01:21:49 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 17:50:54 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1706.01362", "submitter": "Stefan Steinerberger", "authors": "Xiuyuan Cheng, Gal Mishne, Stefan Steinerberger", "title": "The Geometry of Nodal Sets and Outlier Detection", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.SP math-ph math.AP math.FA math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(M,g)$ be a compact manifold and let $-\\Delta \\phi_k = \\lambda_k \\phi_k$\nbe the sequence of Laplacian eigenfunctions. We present a curious new\nphenomenon which, so far, we only managed to understand in a few highly\nspecialized cases: the family of functions $f_N:M \\rightarrow \\mathbb{R}_{\\geq\n0}$ $$ f_N(x) = \\sum_{k \\leq N}{ \\frac{1}{\\sqrt{\\lambda_k}}\n\\frac{|\\phi_k(x)|}{\\|\\phi_k\\|_{L^{\\infty}(M)}}}$$ seems strangely suited for\nthe detection of anomalous points on the manifold. It may be heuristically\ninterpreted as the sum over distances to the nearest nodal line and potentially\nhints at a new phenomenon in spectral geometry. We give rigorous statements on\nthe unit square $[0,1]^2$ (where minima localize in $\\mathbb{Q}^2$) and on\nPaley graphs (where $f_N$ recovers the geometry of quadratic residues of the\nunderlying finite field $\\mathbb{F}_p$). Numerical examples show that the\nphenomenon seems to arise on fairly generic manifolds.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 15:04:36 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Mishne", "Gal", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "1706.01418", "submitter": "Steve Hanneke", "authors": "Steve Hanneke", "title": "Learning Whenever Learning is Possible: Universal Learning under General\n  Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work initiates a general study of learning and generalization without\nthe i.i.d. assumption, starting from first principles. While the traditional\napproach to statistical learning theory typically relies on standard\nassumptions from probability theory (e.g., i.i.d. or stationary ergodic), in\nthis work we are interested in developing a theory of learning based only on\nthe most fundamental and necessary assumptions implicit in the requirements of\nthe learning problem itself. We specifically study universally consistent\nfunction learning, where the objective is to obtain low long-run average loss\nfor any target function, when the data follow a given stochastic process. We\nare then interested in the question of whether there exist learning rules\nguaranteed to be universally consistent given only the assumption that\nuniversally consistent learning is possible for the given data process. The\nreasoning that motivates this criterion emanates from a kind of optimist's\ndecision theory, and so we refer to such learning rules as being optimistically\nuniversal. We study this question in three natural learning settings:\ninductive, self-adaptive, and online. Remarkably, as our strongest positive\nresult, we find that optimistically universal learning rules do indeed exist in\nthe self-adaptive learning setting. Establishing this fact requires us to\ndevelop new approaches to the design of learning algorithms. Along the way, we\nalso identify concise characterizations of the family of processes under which\nuniversally consistent learning is possible in the inductive and self-adaptive\nsettings. We additionally pose a number of enticing open problems, particularly\nfor the online learning setting.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 16:51:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 16:25:14 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Hanneke", "Steve", ""]]}, {"id": "1706.01445", "submitter": "Zi Wang", "authors": "Zi Wang and Clement Gehring and Pushmeet Kohli and Stefanie Jegelka", "title": "Batched Large-scale Bayesian Optimization in High-dimensional Spaces", "comments": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) has become an effective approach for black-box\nfunction optimization problems when function evaluations are expensive and the\noptimum can be achieved within a relatively small number of queries. However,\nmany cases, such as the ones with high-dimensional inputs, may require a much\nlarger number of observations for optimization. Despite an abundance of\nobservations thanks to parallel experiments, current BO techniques have been\nlimited to merely a few thousand observations. In this paper, we propose\nensemble Bayesian optimization (EBO) to address three current challenges in BO\nsimultaneously: (1) large-scale observations; (2) high dimensional input\nspaces; and (3) selections of batch queries that balance quality and diversity.\nThe key idea of EBO is to operate on an ensemble of additive Gaussian process\nmodels, each of which possesses a randomized strategy to divide and conquer. We\nshow unprecedented, previously impossible results of scaling up BO to tens of\nthousands of observations within minutes of computation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 17:50:44 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 18:10:18 GMT"}, {"version": "v3", "created": "Sat, 6 Jan 2018 17:55:33 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 01:16:10 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Wang", "Zi", ""], ["Gehring", "Clement", ""], ["Kohli", "Pushmeet", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1706.01498", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Changyou Chen, Zhe Gan, Ricardo Henao, Lawrence Carin", "title": "Stochastic Gradient Monomial Gamma Sampler", "comments": "Published on ICML 2017", "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, PMLR 70:3996-4005, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in stochastic gradient techniques have made it possible to\nestimate posterior distributions from large datasets via Markov Chain Monte\nCarlo (MCMC). However, when the target posterior is multimodal, mixing\nperformance is often poor. This results in inadequate exploration of the\nposterior distribution. A framework is proposed to improve the sampling\nefficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. A\ngeneralized kinetic function is leveraged, delivering superior stationary\nmixing, especially for multimodal distributions. Techniques are also discussed\nto overcome the practical issues introduced by this generalization. It is shown\nthat the proposed approach is better at exploring complex multimodal posterior\ndistributions, as demonstrated on multiple applications and in comparison with\nother stochastic gradient MCMC methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 18:48:31 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 19:38:23 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Zhang", "Yizhe", ""], ["Chen", "Changyou", ""], ["Gan", "Zhe", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1706.01502", "submitter": "Richard Y. Chen", "authors": "Richard Y. Chen, Szymon Sidor, Pieter Abbeel, John Schulman", "title": "UCB Exploration via Q-Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how an ensemble of $Q^*$-functions can be leveraged for more\neffective exploration in deep reinforcement learning. We build on well\nestablished algorithms from the bandit setting, and adapt them to the\n$Q$-learning setting. We propose an exploration strategy based on\nupper-confidence bounds (UCB). Our experiments show significant gains on the\nAtari benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 19:01:26 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 18:54:53 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 20:45:59 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Chen", "Richard Y.", ""], ["Sidor", "Szymon", ""], ["Abbeel", "Pieter", ""], ["Schulman", "John", ""]]}, {"id": "1706.01509", "submitter": "Prudhvi Raj Dachapally", "authors": "Prudhvi Raj Dachapally", "title": "Facial Emotion Detection Using Convolutional Neural Networks and\n  Representational Autoencoder Units", "comments": "6 pages, 8 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion being a subjective thing, leveraging knowledge and science behind\nlabeled data and extracting the components that constitute it, has been a\nchallenging problem in the industry for many years. With the evolution of deep\nlearning in computer vision, emotion recognition has become a widely-tackled\nresearch problem. In this work, we propose two independent methods for this\nvery task. The first method uses autoencoders to construct a unique\nrepresentation of each emotion, while the second method is an 8-layer\nconvolutional neural network (CNN). These methods were trained on the\nposed-emotion dataset (JAFFE), and to test their robustness, both the models\nwere also tested on 100 random images from the Labeled Faces in the Wild (LFW)\ndataset, which consists of images that are candid than posed. The results show\nthat with more fine-tuning and depth, our CNN model can outperform the\nstate-of-the-art methods for emotion recognition. We also propose some exciting\nideas for expanding the concept of representational autoencoders to improve\ntheir performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 19:25:34 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Dachapally", "Prudhvi Raj", ""]]}, {"id": "1706.01513", "submitter": "Keith Feldman", "authors": "Keith Feldman, Louis Faust, Xian Wu, Chao Huang, and Nitesh V. Chawla", "title": "Beyond Volume: The Impact of Complex Healthcare Data on the Machine\n  Learning Pipeline", "comments": "Healthcare Informatics, Machine Learning, Knowledge Discovery: 20\n  Pages, 1 Figure", "journal-ref": "Towards Integrative Machine Learning and Knowledge Extraction,\n  LNCS vol 10344 (2017) 150-169", "doi": "10.1007/978-3-319-69775-8_9", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From medical charts to national census, healthcare has traditionally operated\nunder a paper-based paradigm. However, the past decade has marked a long and\narduous transformation bringing healthcare into the digital age. Ranging from\nelectronic health records, to digitized imaging and laboratory reports, to\npublic health datasets, today, healthcare now generates an incredible amount of\ndigital information. Such a wealth of data presents an exciting opportunity for\nintegrated machine learning solutions to address problems across multiple\nfacets of healthcare practice and administration. Unfortunately, the ability to\nderive accurate and informative insights requires more than the ability to\nexecute machine learning models. Rather, a deeper understanding of the data on\nwhich the models are run is imperative for their success. While a significant\neffort has been undertaken to develop models able to process the volume of data\nobtained during the analysis of millions of digitalized patient records, it is\nimportant to remember that volume represents only one aspect of the data. In\nfact, drawing on data from an increasingly diverse set of sources, healthcare\ndata presents an incredibly complex set of attributes that must be accounted\nfor throughout the machine learning pipeline. This chapter focuses on\nhighlighting such challenges, and is broken down into three distinct\ncomponents, each representing a phase of the pipeline. We begin with attributes\nof the data accounted for during preprocessing, then move to considerations\nduring model building, and end with challenges to the interpretation of model\noutput. For each component, we present a discussion around data as it relates\nto the healthcare domain and offer insight into the challenges each may impose\non the efficiency of machine learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 20:34:41 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 15:05:34 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Feldman", "Keith", ""], ["Faust", "Louis", ""], ["Wu", "Xian", ""], ["Huang", "Chao", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "1706.01566", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Kevin Jamieson, Noah A. Smith", "title": "Open Loop Hyperparameter Optimization and Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the need for parallelizable hyperparameter optimization methods,\nthis paper studies \\emph{open loop} search methods: sequences that are\npredetermined and can be generated before a single configuration is evaluated.\nExamples include grid search, uniform random search, low discrepancy sequences,\nand other sampling distributions. In particular, we propose the use of\n$k$-determinantal point processes in hyperparameter optimization via random\nsearch. Compared to conventional uniform random search where hyperparameter\nsettings are sampled independently, a $k$-DPP promotes diversity. We describe\nan approach that transforms hyperparameter search spaces for efficient use with\na $k$-DPP. In addition, we introduce a novel Metropolis-Hastings algorithm\nwhich can sample from $k$-DPPs defined over any space from which uniform\nsamples can be drawn, including spaces with a mixture of discrete and\ncontinuous dimensions or tree structure. Our experiments show significant\nbenefits in realistic scenarios with a limited budget for training supervised\nlearners, whether in serial or parallel.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 00:14:05 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 21:29:38 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 02:00:13 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 01:32:23 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Dodge", "Jesse", ""], ["Jamieson", "Kevin", ""], ["Smith", "Noah A.", ""]]}, {"id": "1706.01581", "submitter": "Azad Naik", "authors": "Azad Naik and Huzefa Rangwala", "title": "Embedding Feature Selection for Large-scale Hierarchical Classification", "comments": "IEEE International Conference on Big Data (IEEE BigData 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Large-scale Hierarchical Classification (HC) involves datasets consisting of\nthousands of classes and millions of training instances with high-dimensional\nfeatures posing several big data challenges. Feature selection that aims to\nselect the subset of discriminant features is an effective strategy to deal\nwith large-scale HC problem. It speeds up the training process, reduces the\nprediction time and minimizes the memory requirements by compressing the total\nsize of learned model weight vectors. Majority of the studies have also shown\nfeature selection to be competent and successful in improving the\nclassification accuracy by removing irrelevant features. In this work, we\ninvestigate various filter-based feature selection methods for dimensionality\nreduction to solve the large-scale HC problem. Our experimental evaluation on\ntext and image datasets with varying distribution of features, classes and\ninstances shows upto 3x order of speed-up on massive datasets and upto 45% less\nmemory requirements for storing the weight vectors of learned model without any\nsignificant loss (improvement for some datasets) in the classification\naccuracy. Source Code: https://cs.gmu.edu/~mlbio/featureselection.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 01:56:51 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Naik", "Azad", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1706.01583", "submitter": "Azad Naik", "authors": "Azad Naik, Anveshi Charuvaka and Huzefa Rangwala", "title": "Classifying Documents within Multiple Hierarchical Datasets using\n  Multi-Task Learning", "comments": "IEEE International Conference on Tools with Artificial Intelligence\n  (ICTAI), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Multi-task learning (MTL) is a supervised learning paradigm in which the\nprediction models for several related tasks are learned jointly to achieve\nbetter generalization performance. When there are only a few training examples\nper task, MTL considerably outperforms the traditional Single task learning\n(STL) in terms of prediction accuracy. In this work we develop an MTL based\napproach for classifying documents that are archived within dual concept\nhierarchies, namely, DMOZ and Wikipedia. We solve the multi-class\nclassification problem by defining one-versus-rest binary classification tasks\nfor each of the different classes across the two hierarchical datasets. Instead\nof learning a linear discriminant for each of the different tasks\nindependently, we use a MTL approach with relationships between the different\ntasks across the datasets established using the non-parametric, lazy, nearest\nneighbor approach. We also develop and evaluate a transfer learning (TL)\napproach and compare the MTL (and TL) methods against the standard single task\nlearning and semi-supervised learning approaches. Our empirical results\ndemonstrate the strength of our developed methods that show an improvement\nespecially when there are fewer number of training examples per classification\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 02:17:40 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Naik", "Azad", ""], ["Charuvaka", "Anveshi", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1706.01604", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris and Rene Vidal", "title": "Hyperplane Clustering Via Dual Principal Component Pursuit", "comments": null, "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, PMLR 70:3472-3481, 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the theoretical analysis of a recently proposed single subspace\nlearning algorithm, called Dual Principal Component Pursuit (DPCP), to the case\nwhere the data are drawn from of a union of hyperplanes. To gain insight into\nthe properties of the $\\ell_1$ non-convex problem associated with DPCP, we\ndevelop a geometric analysis of a closely related continuous optimization\nproblem. Then transferring this analysis to the discrete problem, our results\nstate that as long as the hyperplanes are sufficiently separated, the dominant\nhyperplane is sufficiently dominant and the points are uniformly distributed\ninside the associated hyperplanes, then the non-convex DPCP problem has a\nunique global solution, equal to the normal vector of the dominant hyperplane.\nThis suggests the correctness of a sequential hyperplane learning algorithm\nbased on DPCP. A thorough experimental evaluation reveals that hyperplane\nlearning schemes based on DPCP dramatically improve over the state-of-the-art\nmethods for the case of synthetic data, while are competitive to the\nstate-of-the-art in the case of 3D plane clustering for Kinect data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 04:27:24 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 19:20:23 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Tsakiris", "Manolis C.", ""], ["Vidal", "Rene", ""]]}, {"id": "1706.01643", "submitter": "Bowen Liu", "authors": "Bowen Liu, Bharath Ramsundar, Prasad Kawthekar, Jade Shi, Joseph\n  Gomes, Quang Luu Nguyen, Stephen Ho, Jack Sloane, Paul Wender, Vijay Pande", "title": "Retrosynthetic reaction prediction using neural sequence-to-sequence\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a fully data driven model that learns to perform a retrosynthetic\nreaction prediction task, which is treated as a sequence-to-sequence mapping\nproblem. The end-to-end trained model has an encoder-decoder architecture that\nconsists of two recurrent neural networks, which has previously shown great\nsuccess in solving other sequence-to-sequence prediction tasks such as machine\ntranslation. The model is trained on 50,000 experimental reaction examples from\nthe United States patent literature, which span 10 broad reaction types that\nare commonly used by medicinal chemists. We find that our model performs\ncomparably with a rule-based expert system baseline model, and also overcomes\ncertain limitations associated with rule-based expert systems and with any\nmachine learning approach that contains a rule-based expert system component.\nOur model provides an important first step towards solving the challenging\nproblem of computational retrosynthetic analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 07:50:54 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Liu", "Bowen", ""], ["Ramsundar", "Bharath", ""], ["Kawthekar", "Prasad", ""], ["Shi", "Jade", ""], ["Gomes", "Joseph", ""], ["Nguyen", "Quang Luu", ""], ["Ho", "Stephen", ""], ["Sloane", "Jack", ""], ["Wender", "Paul", ""], ["Pande", "Vijay", ""]]}, {"id": "1706.01686", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani", "title": "Limitations on Variance-Reduction and Acceleration Schemes for Finite\n  Sum Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the conditions under which one is able to efficiently apply\nvariance-reduction and acceleration schemes on finite sum optimization\nproblems. First, we show that, perhaps surprisingly, the finite sum structure\nby itself, is not sufficient for obtaining a complexity bound of\n$\\tilde{\\cO}((n+L/\\mu)\\ln(1/\\epsilon))$ for $L$-smooth and $\\mu$-strongly\nconvex individual functions - one must also know which individual function is\nbeing referred to by the oracle at each iteration. Next, we show that for a\nbroad class of first-order and coordinate-descent finite sum algorithms\n(including, e.g., SDCA, SVRG, SAG), it is not possible to get an `accelerated'\ncomplexity bound of $\\tilde{\\cO}((n+\\sqrt{n L/\\mu})\\ln(1/\\epsilon))$, unless\nthe strong convexity parameter is given explicitly. Lastly, we show that when\nthis class of algorithms is used for minimizing $L$-smooth and convex finite\nsums, the optimal complexity bound is $\\tilde{\\cO}(n+L/\\epsilon)$, assuming\nthat (on average) the same update rule is used in every iteration, and\n$\\tilde{\\cO}(n+\\sqrt{nL/\\epsilon})$, otherwise.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 10:35:33 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 19:16:39 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Arjevani", "Yossi", ""]]}, {"id": "1706.01724", "submitter": "Mingyuan Zhou", "authors": "Yulai Cong, Bo Chen, Hongwei Liu, Mingyuan Zhou", "title": "Deep Latent Dirichlet Allocation with Topic-Layer-Adaptive Stochastic\n  Gradient Riemannian MCMC", "comments": "Appearing in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging to develop stochastic gradient based scalable inference for\ndeep discrete latent variable models (LVMs), due to the difficulties in not\nonly computing the gradients, but also adapting the step sizes to different\nlatent factors and hidden layers. For the Poisson gamma belief network (PGBN),\na recently proposed deep discrete LVM, we derive an alternative representation\nthat is referred to as deep latent Dirichlet allocation (DLDA). Exploiting data\naugmentation and marginalization techniques, we derive a block-diagonal Fisher\ninformation matrix and its inverse for the simplex-constrained global model\nparameters of DLDA. Exploiting that Fisher information matrix with stochastic\ngradient MCMC, we present topic-layer-adaptive stochastic gradient Riemannian\n(TLASGR) MCMC that jointly learns simplex-constrained global parameters across\nall layers and topics, with topic and layer specific learning rates.\nState-of-the-art results are demonstrated on big data sets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 12:15:42 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Cong", "Yulai", ""], ["Chen", "Bo", ""], ["Liu", "Hongwei", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1706.01807", "submitter": "Gabriel Peyr\\'e", "authors": "Aude Genevay, Gabriel Peyr\\'e, Marco Cuturi", "title": "GAN and VAE from an Optimal Transport Point of View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short article revisits some of the ideas introduced in arXiv:1701.07875\nand arXiv:1705.07642 in a simple setup. This sheds some lights on the\nconnexions between Variational Autoencoders (VAE), Generative Adversarial\nNetworks (GAN) and Minimum Kantorovitch Estimators (MKE).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 15:03:15 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Genevay", "Aude", ""], ["Peyr\u00e9", "Gabriel", ""], ["Cuturi", "Marco", ""]]}, {"id": "1706.01824", "submitter": "Peng Yang", "authors": "Peng Yang, Peilin Zhao, Xin Gao", "title": "Robust Online Multi-Task Learning with Correlative and Personalized\n  Structures", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2017.2703106", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Task Learning (MTL) can enhance a classifier's generalization\nperformance by learning multiple related tasks simultaneously. Conventional MTL\nworks under the offline or batch setting, and suffers from expensive training\ncost and poor scalability. To address such inefficiency issues, online learning\ntechniques have been applied to solve MTL problems. However, most existing\nalgorithms of online MTL constrain task relatedness into a presumed structure\nvia a single weight matrix, which is a strict restriction that does not always\nhold in practice. In this paper, we propose a robust online MTL framework that\novercomes this restriction by decomposing the weight matrix into two\ncomponents: the first one captures the low-rank common structure among tasks\nvia a nuclear norm and the second one identifies the personalized patterns of\noutlier tasks via a group lasso. Theoretical analysis shows the proposed\nalgorithm can achieve a sub-linear regret with respect to the best linear model\nin hindsight. Even though the above framework achieves good performance, the\nnuclear norm that simply adds all nonzero singular values together may not be a\ngood low-rank approximation. To improve the results, we use a log-determinant\nfunction as a non-convex rank approximation. The gradient scheme is applied to\noptimize log-determinant function and can obtain a closed-form solution for\nthis refined problem. Experimental results on a number of real-world\napplications verify the efficacy of our method.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 15:53:26 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Yang", "Peng", ""], ["Zhao", "Peilin", ""], ["Gao", "Xin", ""]]}, {"id": "1706.01825", "submitter": "Jos\\'e Miguel Hern\\'andez-Lobato", "authors": "Jos\\'e Miguel Hern\\'andez-Lobato, James Requeima, Edward O.\n  Pyzer-Knapp and Al\\'an Aspuru-Guzik", "title": "Parallel and Distributed Thompson Sampling for Large-scale Accelerated\n  Exploration of Chemical Space", "comments": "Accepted for publication in the proceedings of the 2017 ICML\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical space is so large that brute force searches for new interesting\nmolecules are infeasible. High-throughput virtual screening via computer\ncluster simulations can speed up the discovery process by collecting very large\namounts of data in parallel, e.g., up to hundreds or thousands of parallel\nmeasurements. Bayesian optimization (BO) can produce additional acceleration by\nsequentially identifying the most useful simulations or experiments to be\nperformed next. However, current BO methods cannot scale to the large numbers\nof parallel measurements and the massive libraries of molecules currently used\nin high-throughput screening. Here, we propose a scalable solution based on a\nparallel and distributed implementation of Thompson sampling (PDTS). We show\nthat, in small scale problems, PDTS performs similarly as parallel expected\nimprovement (EI), a batch version of the most widely used BO heuristic.\nAdditionally, in settings where parallel EI does not scale, PDTS outperforms\nother scalable baselines such as a greedy search, $\\epsilon$-greedy approaches\nand a random search method. These results show that PDTS is a successful\nsolution for large-scale parallel BO.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 15:57:17 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Requeima", "James", ""], ["Pyzer-Knapp", "Edward O.", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "1706.01833", "submitter": "Yaxiong Zeng", "authors": "Yaxiong Zeng, Diego Klabjan", "title": "Online Adaptive Machine Learning Based Algorithm for Implied Volatility\n  Surface Modeling", "comments": "34 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we design a machine learning based method, online adaptive\nprimal support vector regression (SVR), to model the implied volatility surface\n(IVS). The algorithm proposed is the first derivation and implementation of an\nonline primal kernel SVR. It features enhancements that allow efficient online\nadaptive learning by embedding the idea of local fitness and budget maintenance\nto dynamically update support vectors upon pattern drifts. For algorithm\nacceleration, we implement its most computationally intensive parts in a Field\nProgrammable Gate Arrays hardware, where a 132x speedup over CPU is achieved\nduring online prediction. Using intraday tick data from the E-mini S&P 500\noptions market, we show that the Gaussian kernel outperforms the linear kernel\nin regulating the size of support vectors, and that our empirical IVS algorithm\nbeats two competing online methods with regards to model complexity and\nregression errors (the mean absolute percentage error of our algorithm is up to\n13%). Best results are obtained at the center of the IVS grid due to its larger\nnumber of adjacent support vectors than the edges of the grid. Sensitivity\nanalysis is also presented to demonstrate how hyper parameters affect the error\nrates and model complexity.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 16:09:57 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 15:28:49 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Zeng", "Yaxiong", ""], ["Klabjan", "Diego", ""]]}, {"id": "1706.01860", "submitter": "Jundong Li", "authors": "Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, Huan Liu", "title": "Attributed Network Embedding for Learning in a Dynamic Environment", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3132847.3132919", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding leverages the node proximity manifested to learn a\nlow-dimensional node vector representation for each node in the network. The\nlearned embeddings could advance various learning tasks such as node\nclassification, network clustering, and link prediction. Most, if not all, of\nthe existing works, are overwhelmingly performed in the context of plain and\nstatic networks. Nonetheless, in reality, network structure often evolves over\ntime with addition/deletion of links and nodes. Also, a vast majority of\nreal-world networks are associated with a rich set of node attributes, and\ntheir attribute values are also naturally changing, with the emerging of new\ncontent patterns and the fading of old content patterns. These changing\ncharacteristics motivate us to seek an effective embedding representation to\ncapture network and attribute evolving patterns, which is of fundamental\nimportance for learning in a dynamic environment. To our best knowledge, we are\nthe first to tackle this problem with the following two challenges: (1) the\ninherently correlated network and node attributes could be noisy and\nincomplete, it necessitates a robust consensus representation to capture their\nindividual properties and correlations; (2) the embedding learning needs to be\nperformed in an online fashion to adapt to the changes accordingly. In this\npaper, we tackle this problem by proposing a novel dynamic attributed network\nembedding framework - DANE. In particular, DANE first provides an offline\nmethod for a consensus embedding and then leverages matrix perturbation theory\nto maintain the freshness of the end embedding results in an online manner. We\nperform extensive experiments on both synthetic and real attributed networks to\ncorroborate the effectiveness and efficiency of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 17:18:38 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 20:50:58 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Li", "Jundong", ""], ["Dani", "Harsh", ""], ["Hu", "Xia", ""], ["Tang", "Jiliang", ""], ["Chang", "Yi", ""], ["Liu", "Huan", ""]]}, {"id": "1706.01865", "submitter": "Aleksandr Aravkin", "authors": "Peng Zheng, Aleksandr Y. Aravkin and Karthikeyan Natesan Ramamurthy", "title": "Estimating Shape Parameters of Piecewise Linear-Quadratic Problems", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piecewise Linear-Quadratic (PLQ) penalties are widely used to develop models\nin statistical inference, signal processing, and machine learning. Common\nexamples of PLQ penalties include least squares, Huber, Vapnik, 1-norm, and\ntheir asymmetric generalizations. Properties of these estimators depend on the\nchoice of penalty and its shape parameters, such as degree of asymmetry for the\nquantile loss, and transition point between linear and quadratic pieces for the\nHuber function. In this paper, we develop a statistical framework that can help\nthe modeler to automatically tune shape parameters once the shape of the\npenalty has been chosen. The choice of the parameter is informed by the basic\nnotion that each QS penalty should correspond to a true statistical density.\nThe normalization constant inherent in this requirement helps to inform the\noptimization over shape parameters, giving a joint optimization problem over\nthese as well as primary parameters of interest. A second contribution is to\nconsider optimization methods for these joint problems. We show that basic\nfirst-order methods can be immediately brought to bear, and design specialized\nextensions of interior point (IP) methods for PLQ problems that can quickly and\nefficiently solve the joint problem. Synthetic problems and larger-scale\npractical examples illustrate the potential of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 17:27:48 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 05:22:09 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zheng", "Peng", ""], ["Aravkin", "Aleksandr Y.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1706.01905", "submitter": "Matthias Plappert", "authors": "Matthias Plappert, Rein Houthooft, Prafulla Dhariwal, Szymon Sidor,\n  Richard Y. Chen, Xi Chen, Tamim Asfour, Pieter Abbeel, Marcin Andrychowicz", "title": "Parameter Space Noise for Exploration", "comments": "Updated to camera-ready ICLR submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) methods generally engage in exploratory\nbehavior through noise injection in the action space. An alternative is to add\nnoise directly to the agent's parameters, which can lead to more consistent\nexploration and a richer set of behaviors. Methods such as evolutionary\nstrategies use parameter perturbations, but discard all temporal structure in\nthe process and require significantly more samples. Combining parameter noise\nwith traditional RL methods allows to combine the best of both worlds. We\ndemonstrate that both off- and on-policy methods benefit from this approach\nthrough experimental comparison of DQN, DDPG, and TRPO on high-dimensional\ndiscrete action environments as well as continuous control tasks. Our results\nshow that RL with parameter noise learns more efficiently than traditional RL\nwith action space noise and evolutionary strategies individually.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 18:09:29 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 09:05:10 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Plappert", "Matthias", ""], ["Houthooft", "Rein", ""], ["Dhariwal", "Prafulla", ""], ["Sidor", "Szymon", ""], ["Chen", "Richard Y.", ""], ["Chen", "Xi", ""], ["Asfour", "Tamim", ""], ["Abbeel", "Pieter", ""], ["Andrychowicz", "Marcin", ""]]}, {"id": "1706.01983", "submitter": "Mrinal Haloi", "authors": "Mrinal Haloi", "title": "Deep Learning: Generalization Requires Deep Compositional Feature Space\n  Design", "comments": "fig added, with minor typo corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization error defines the discriminability and the representation\npower of a deep model. In this work, we claim that feature space design using\ndeep compositional function plays a significant role in generalization along\nwith explicit and implicit regularizations. Our claims are being established\nwith several image classification experiments. We show that the information\nloss due to convolution and max pooling can be marginalized with the\ncompositional design, improving generalization performance. Also, we will show\nthat learning rate decay acts as an implicit regularizer in deep model\ntraining.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 21:10:07 GMT"}, {"version": "v2", "created": "Sat, 8 Jul 2017 22:31:36 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Haloi", "Mrinal", ""]]}, {"id": "1706.02052", "submitter": "Ravi Adepu Sankar", "authors": "Adepu Ravi Sankar, Vineeth N Balasubramanian", "title": "Are Saddles Good Enough for Deep Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a growing interest in understanding deep neural\nnetworks from an optimization perspective. It is understood now that converging\nto low-cost local minima is sufficient for such models to become effective in\npractice. However, in this work, we propose a new hypothesis based on recent\ntheoretical findings and empirical studies that deep neural network models\nactually converge to saddle points with high degeneracy. Our findings from this\nwork are new, and can have a significant impact on the development of gradient\ndescent based methods for training deep networks. We validated our hypotheses\nusing an extensive experimental evaluation on standard datasets such as MNIST\nand CIFAR-10, and also showed that recent efforts that attempt to escape\nsaddles finally converge to saddles with high degeneracy, which we define as\n`good saddles'. We also verified the famous Wigner's Semicircle Law in our\nexperimental results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 05:44:07 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Sankar", "Adepu Ravi", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1706.02093", "submitter": "Shichen Liu", "authors": "Shichen Liu, Fei Xiao, Wenwu Ou, Luo Si", "title": "Cascade Ranking for Operational E-commerce Search", "comments": null, "journal-ref": null, "doi": "10.1145/3097983.3098011", "report-no": null, "categories": "stat.ML cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 'Big Data' era, many real-world applications like search involve the\nranking problem for a large number of items. It is important to obtain\neffective ranking results and at the same time obtain the results efficiently\nin a timely manner for providing good user experience and saving computational\ncosts. Valuable prior research has been conducted for learning to efficiently\nrank like the cascade ranking (learning) model, which uses a sequence of\nranking functions to progressively filter some items and rank the remaining\nitems. However, most existing research of learning to efficiently rank in\nsearch is studied in a relatively small computing environments with simulated\nuser queries.\n  This paper presents novel research and thorough study of designing and\ndeploying a Cascade model in a Large-scale Operational E-commerce Search\napplication (CLOES), which deals with hundreds of millions of user queries per\nday with hundreds of servers. The challenge of the real-world application\nprovides new insights for research: 1). Real-world search applications often\ninvolve multiple factors of preferences or constraints with respect to user\nexperience and computational costs such as search accuracy, search latency,\nsize of search results and total CPU cost, while most existing search solutions\nonly address one or two factors; 2). Effectiveness of e-commerce search\ninvolves multiple types of user behaviors such as click and purchase, while\nmost existing cascade ranking in search only models the click behavior. Based\non these observations, a novel cascade ranking model is designed and deployed\nin an operational e-commerce search application. An extensive set of\nexperiments demonstrate the advantage of the proposed work to address multiple\nfactors of effectiveness, efficiency and user experience in the real-world\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 09:03:13 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Liu", "Shichen", ""], ["Xiao", "Fei", ""], ["Ou", "Wenwu", ""], ["Si", "Luo", ""]]}, {"id": "1706.02216", "submitter": "William L Hamilton", "authors": "William L. Hamilton, Rex Ying, Jure Leskovec", "title": "Inductive Representation Learning on Large Graphs", "comments": "Published in NIPS 2017; version with full appendix and minor\n  corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional embeddings of nodes in large graphs have proved extremely\nuseful in a variety of prediction tasks, from content recommendation to\nidentifying protein functions. However, most existing approaches require that\nall nodes in the graph are present during training of the embeddings; these\nprevious approaches are inherently transductive and do not naturally generalize\nto unseen nodes. Here we present GraphSAGE, a general, inductive framework that\nleverages node feature information (e.g., text attributes) to efficiently\ngenerate node embeddings for previously unseen data. Instead of training\nindividual embeddings for each node, we learn a function that generates\nembeddings by sampling and aggregating features from a node's local\nneighborhood. Our algorithm outperforms strong baselines on three inductive\nnode-classification benchmarks: we classify the category of unseen nodes in\nevolving information graphs based on citation and Reddit post data, and we show\nthat our algorithm generalizes to completely unseen graphs using a multi-graph\ndataset of protein-protein interactions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 14:51:05 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 01:45:25 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 15:40:00 GMT"}, {"version": "v4", "created": "Mon, 10 Sep 2018 14:26:58 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Hamilton", "William L.", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""]]}, {"id": "1706.02222", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Ruli Manurung, Mirna Adriani and\n  Satoshi Nakamura", "title": "Gated Recurrent Neural Tensor Network", "comments": "Accepted at IJCNN 2016 URL :\n  http://ieeexplore.ieee.org/document/7727233/", "journal-ref": null, "doi": "10.1109/IJCNN.2016.7727233", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs), which are a powerful scheme for modeling\ntemporal and sequential data need to capture long-term dependencies on datasets\nand represent them in hidden layers with a powerful model to capture more\ninformation from inputs. For modeling long-term dependencies in a dataset, the\ngating mechanism concept can help RNNs remember and forget previous\ninformation. Representing the hidden layers of an RNN with more expressive\noperations (i.e., tensor products) helps it learn a more complex relationship\nbetween the current input and the previous hidden layer information. These\nideas can generally improve RNN performances. In this paper, we proposed a\nnovel RNN architecture that combine the concepts of gating mechanism and the\ntensor product into a single model. By combining these two concepts into a\nsingle RNN, our proposed models learn long-term dependencies by modeling with\ngating units and obtain more expressive and direct interaction between input\nand hidden layers using a tensor product on 3-dimensional array (tensor) weight\nparameters. We use Long Short Term Memory (LSTM) RNN and Gated Recurrent Unit\n(GRU) RNN and combine them with a tensor product inside their formulations. Our\nproposed RNNs, which are called a Long-Short Term Memory Recurrent Neural\nTensor Network (LSTMRNTN) and Gated Recurrent Unit Recurrent Neural Tensor\nNetwork (GRURNTN), are made by combining the LSTM and GRU RNN models with the\ntensor product. We conducted experiments with our proposed models on word-level\nand character-level language modeling tasks and revealed that our proposed\nmodels significantly improved their performance compared to our baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 15:05:39 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Manurung", "Ruli", ""], ["Adriani", "Mirna", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1706.02237", "submitter": "Sudeep Raja Putta", "authors": "Sudeep Raja Putta, Theja Tulabandhula", "title": "Efficient Reinforcement Learning via Initial Pure Exploration", "comments": "4 pages, 3 figures, Presented at Reinforcement Learning and Decision\n  Making 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several realistic situations, an interactive learning agent can practice\nand refine its strategy before going on to be evaluated. For instance, consider\na student preparing for a series of tests. She would typically take a few\npractice tests to know which areas she needs to improve upon. Based of the\nscores she obtains in these practice tests, she would formulate a strategy for\nmaximizing her scores in the actual tests. We treat this scenario in the\ncontext of an agent exploring a fixed-horizon episodic Markov Decision Process\n(MDP), where the agent can practice on the MDP for some number of episodes (not\nnecessarily known in advance) before starting to incur regret for its actions.\n  During practice, the agent's goal must be to maximize the probability of\nfollowing an optimal policy. This is akin to the problem of Pure Exploration\n(PE). We extend the PE problem of Multi Armed Bandits (MAB) to MDPs and propose\na Bayesian algorithm called Posterior Sampling for Pure Exploration (PSPE),\nwhich is similar to its bandit counterpart. We show that the Bayesian simple\nregret converges at an optimal exponential rate when using PSPE.\n  When the agent starts being evaluated, its goal would be to minimize the\ncumulative regret incurred. This is akin to the problem of Reinforcement\nLearning (RL). The agent uses the Posterior Sampling for Reinforcement Learning\nalgorithm (PSRL) initialized with the posteriors of the practice phase. We\nhypothesize that this PSPE + PSRL combination is an optimal strategy for\nminimizing regret in RL problems with an initial practice phase. We show\nempirical results which prove that having a lower simple regret at the end of\nthe practice phase results in having lower cumulative regret during evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 16:18:44 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Putta", "Sudeep Raja", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1706.02256", "submitter": "Ana Marasovi\\'c", "authors": "Ana Marasovi\\'c, Leo Born, Juri Opitz and Anette Frank", "title": "A Mention-Ranking Model for Abstract Anaphora Resolution", "comments": "In Proceedings of the 2017 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP). Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolving abstract anaphora is an important, but difficult task for text\nunderstanding. Yet, with recent advances in representation learning this task\nbecomes a more tangible aim. A central property of abstract anaphora is that it\nestablishes a relation between the anaphor embedded in the anaphoric sentence\nand its (typically non-nominal) antecedent. We propose a mention-ranking model\nthat learns how abstract anaphors relate to their antecedents with an\nLSTM-Siamese Net. We overcome the lack of training data by generating\nartificial anaphoric sentence--antecedent pairs. Our model outperforms\nstate-of-the-art results on shell noun resolution. We also report first\nbenchmark results on an abstract anaphora subset of the ARRAU corpus. This\ncorpus presents a greater challenge due to a mixture of nominal and pronominal\nanaphors and a greater range of confounders. We found model variants that\noutperform the baselines for nominal anaphors, without training on individual\nanaphor data, but still lag behind for pronominal anaphors. Our model selects\nsyntactically plausible candidates and -- if disregarding syntax --\ndiscriminates candidates using deeper features.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 16:58:59 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 12:12:04 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Marasovi\u0107", "Ana", ""], ["Born", "Leo", ""], ["Opitz", "Juri", ""], ["Frank", "Anette", ""]]}, {"id": "1706.02257", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Eric Martinson, Vijay Chintalapudi, Rui Guo", "title": "Driver Action Prediction Using Deep (Bidirectional) Recurrent Neural\n  Network", "comments": "ITSC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced driver assistance systems (ADAS) can be significantly improved with\neffective driver action prediction (DAP). Predicting driver actions early and\naccurately can help mitigate the effects of potentially unsafe driving\nbehaviors and avoid possible accidents. In this paper, we formulate driver\naction prediction as a timeseries anomaly prediction problem. While the anomaly\n(driver actions of interest) detection might be trivial in this context,\nfinding patterns that consistently precede an anomaly requires searching for or\nextracting features across multi-modal sensory inputs. We present such a driver\naction prediction system, including a real-time data acquisition, processing\nand learning framework for predicting future or impending driver action. The\nproposed system incorporates camera-based knowledge of the driving environment\nand the driver themselves, in addition to traditional vehicle dynamics. It then\nuses a deep bidirectional recurrent neural network (DBRNN) to learn the\ncorrelation between sensory inputs and impending driver behavior achieving\naccurate and high horizon action prediction. The proposed system performs\nbetter than other existing systems on driver action prediction tasks and can\naccurately predict key driver actions including acceleration, braking, lane\nchange and turning at durations of 5sec before the action is executed by the\ndriver.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 17:00:08 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Martinson", "Eric", ""], ["Chintalapudi", "Vijay", ""], ["Guo", "Rui", ""]]}, {"id": "1706.02262", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Jiaming Song, Stefano Ermon", "title": "InfoVAE: Information Maximizing Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key advance in learning generative models is the use of amortized inference\ndistributions that are jointly trained with the models. We find that existing\ntraining objectives for variational autoencoders can lead to inaccurate\namortized inference distributions and, in some cases, improving the objective\nprovably degrades the inference quality. In addition, it has been observed that\nvariational autoencoders tend to ignore the latent variables when combined with\na decoding distribution that is too flexible. We again identify the cause in\nexisting training criteria and propose a new class of objectives (InfoVAE) that\nmitigate these problems. We show that our model can significantly improve the\nquality of the variational posterior and can make effective use of the latent\nfeatures regardless of the flexibility of the decoding distribution. Through\nextensive qualitative and quantitative analyses, we demonstrate that our models\noutperform competing approaches on multiple performance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 17:05:01 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 18:35:30 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 17:28:31 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1706.02263", "submitter": "Rianne van den Berg", "authors": "Rianne van den Berg, Thomas N. Kipf, Max Welling", "title": "Graph Convolutional Matrix Completion", "comments": "9 pages, 3 figures, updated with additional experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider matrix completion for recommender systems from the point of view\nof link prediction on graphs. Interaction data such as movie ratings can be\nrepresented by a bipartite user-item graph with labeled edges denoting observed\nratings. Building on recent progress in deep learning on graph-structured data,\nwe propose a graph auto-encoder framework based on differentiable message\npassing on the bipartite interaction graph. Our model shows competitive\nperformance on standard collaborative filtering benchmarks. In settings where\ncomplimentary feature information or structured data such as a social network\nis available, our framework outperforms recent state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 17:05:19 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 19:20:03 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Berg", "Rianne van den", ""], ["Kipf", "Thomas N.", ""], ["Welling", "Max", ""]]}, {"id": "1706.02326", "submitter": "Jakub Tomczak Ph.D.", "authors": "Jakub M. Tomczak and Max Welling", "title": "Improving Variational Auto-Encoders using convex combination linear\n  Inverse Autoregressive Flow", "comments": "Published at Benelearn 2017 (Eindhoven, the Netherlands)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new volume-preserving flow and show that it\nperforms similarly to the linear general normalizing flow. The idea is to\nenrich a linear Inverse Autoregressive Flow by introducing multiple\nlower-triangular matrices with ones on the diagonal and combining them using a\nconvex combination. In the experimental studies on MNIST and Histopathology\ndata we show that the proposed approach outperforms other volume-preserving\nflows and is competitive with current state-of-the-art linear normalizing flow.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 18:25:12 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:50:00 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Tomczak", "Jakub M.", ""], ["Welling", "Max", ""]]}, {"id": "1706.02332", "submitter": "Matthijs Douze", "authors": "Matthijs Douze and Arthur Szlam and Bharath Hariharan and Herv\\'e\n  J\\'egou", "title": "Low-shot learning with large-scale diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of inferring image labels from images when\nonly a few annotated examples are available at training time. This setup is\noften referred to as low-shot learning, where a standard approach is to\nre-train the last few layers of a convolutional neural network learned on\nseparate classes for which training examples are abundant. We consider a\nsemi-supervised setting based on a large collection of images to support label\npropagation. This is possible by leveraging the recent advances on large-scale\nsimilarity graph construction.\n  We show that despite its conceptual simplicity, scaling label propagation up\nto hundred millions of images leads to state of the art accuracy in the\nlow-shot learning regime.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 18:40:26 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 13:59:23 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 15:31:37 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Douze", "Matthijs", ""], ["Szlam", "Arthur", ""], ["Hariharan", "Bharath", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1706.02375", "submitter": "Jeffrey Regier", "authors": "Jeffrey Regier and Michael I. Jordan and Jon McAuliffe", "title": "Fast Black-box Variational Inference through Stochastic Trust-Region\n  Optimization", "comments": "NIPS 2017 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TrustVI, a fast second-order algorithm for black-box variational\ninference based on trust-region optimization and the reparameterization trick.\nAt each iteration, TrustVI proposes and assesses a step based on minibatches of\ndraws from the variational distribution. The algorithm provably converges to a\nstationary point. We implemented TrustVI in the Stan framework and compared it\nto two alternatives: Automatic Differentiation Variational Inference (ADVI) and\nHessian-free Stochastic Gradient Variational Inference (HFSGVI). The former is\nbased on stochastic first-order optimization. The latter uses second-order\ninformation, but lacks convergence guarantees. TrustVI typically converged at\nleast one order of magnitude faster than ADVI, demonstrating the value of\nstochastic second-order information. TrustVI often found substantially better\nvariational distributions than HFSGVI, demonstrating that our convergence\ntheory can matter in practice.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 20:37:09 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 00:28:47 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Regier", "Jeffrey", ""], ["Jordan", "Michael I.", ""], ["McAuliffe", "Jon", ""]]}, {"id": "1706.02379", "submitter": "Hao Li", "authors": "Hao Li, Soham De, Zheng Xu, Christoph Studer, Hanan Samet, Tom\n  Goldstein", "title": "Training Quantized Nets: A Deeper Understanding", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, deep neural networks are deployed on low-power portable devices by\nfirst training a full-precision model using powerful hardware, and then\nderiving a corresponding low-precision model for efficient inference on such\nsystems. However, training models directly with coarsely quantized weights is a\nkey step towards learning on embedded platforms that have limited computing\nresources, memory capacity, and power consumption. Numerous recent publications\nhave studied methods for training quantized networks, but these studies have\nmostly been empirical. In this work, we investigate training methods for\nquantized neural networks from a theoretical viewpoint. We first explore\naccuracy guarantees for training methods under convexity assumptions. We then\nlook at the behavior of these algorithms for non-convex problems, and show that\ntraining algorithms that exploit high-precision representations have an\nimportant greedy search phase that purely quantized training methods lack,\nwhich explains the difficulty of training using low-precision arithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 21:01:15 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 10:28:36 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 16:32:39 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Li", "Hao", ""], ["De", "Soham", ""], ["Xu", "Zheng", ""], ["Studer", "Christoph", ""], ["Samet", "Hanan", ""], ["Goldstein", "Tom", ""]]}, {"id": "1706.02386", "submitter": "Daniele Ramazzotti", "authors": "Giulio Caravagna and Daniele Ramazzotti", "title": "Learning the structure of Bayesian Networks via the bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of dependencies among multiple random variables is a\nproblem of considerable theoretical and practical interest. Within the context\nof Bayesian Networks, a practical and surprisingly successful solution to this\nlearning problem is achieved by adopting score-functions optimisation schema,\naugmented with multiple restarts to avoid local optima. Yet, the conditions\nunder which such strategies work well are poorly understood, and there are also\nsome intrinsic limitations to learning the directionality of the interaction\namong the variables. Following an early intuition of Friedman and Koller, we\npropose to decouple the learning problem into two steps: first, we identify a\npartial ordering among input variables which constrains the structural learning\nproblem, and then propose an effective bootstrap-based algorithm to simulate\naugmented data sets, and select the most important dependencies among the\nvariables. By using several synthetic data sets, we show that our algorithm\nyields better recovery performance than the state of the art, increasing the\nchances of identifying a globally-optimal solution to the learning problem, and\nsolving also well-known identifiability issues that affect the standard\napproach. We use our new algorithm to infer statistical dependencies between\ncancer driver somatic mutations detected by high-throughput genome sequencing\ndata of multiple colorectal cancer patients. In this way, we also show how the\nproposed methods can shade new insights about cancer initiation, and\nprogression. Code: https://github.com/caravagn/Bootstrap-based-Learning\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 21:30:47 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 17:26:12 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Caravagna", "Giulio", ""], ["Ramazzotti", "Daniele", ""]]}, {"id": "1706.02409", "submitter": "Shahin Jabbari", "authors": "Richard Berk, Hoda Heidari, Shahin Jabbari, Matthew Joseph, Michael\n  Kearns, Jamie Morgenstern, Seth Neel, Aaron Roth", "title": "A Convex Framework for Fair Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a flexible family of fairness regularizers for (linear and\nlogistic) regression problems. These regularizers all enjoy convexity,\npermitting fast optimization, and they span the rang from notions of group\nfairness to strong individual fairness. By varying the weight on the fairness\nregularizer, we can compute the efficient frontier of the accuracy-fairness\ntrade-off on any given dataset, and we measure the severity of this trade-off\nvia a numerical quantity we call the Price of Fairness (PoF). The centerpiece\nof our results is an extensive comparative study of the PoF across six\ndifferent datasets in which fairness is a primary consideration.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 23:09:28 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Berk", "Richard", ""], ["Heidari", "Hoda", ""], ["Jabbari", "Shahin", ""], ["Joseph", "Matthew", ""], ["Kearns", "Michael", ""], ["Morgenstern", "Jamie", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""]]}, {"id": "1706.02412", "submitter": "Ruidi Chen", "authors": "Ruidi Chen and Ioannis Ch. Paschalidis", "title": "A Robust Learning Algorithm for Regression Models Using Distributionally\n  Robust Optimization under the Wasserstein Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Distributionally Robust Optimization (DRO) approach to estimate\na robustified regression plane in a linear regression setting, when the\nobserved samples are potentially contaminated with adversarially corrupted\noutliers. Our approach mitigates the impact of outliers through hedging against\na family of distributions on the observed data, some of which assign very low\nprobabilities to the outliers. The set of distributions under consideration are\nclose to the empirical distribution in the sense of the Wasserstein metric. We\nshow that this DRO formulation can be relaxed to a convex optimization problem\nwhich encompasses a class of models. By selecting proper norm spaces for the\nWasserstein metric, we are able to recover several commonly used regularized\nregression models. We provide new insights into the regularization term and\ngive guidance on the selection of the regularization coefficient from the\nstandpoint of a confidence region. We establish two types of performance\nguarantees for the solution to our formulation under mild conditions. One is\nrelated to its out-of-sample behavior (prediction bias), and the other concerns\nthe discrepancy between the estimated and true regression planes (estimation\nbias). Extensive numerical results demonstrate the superiority of our approach\nto a host of regression models, in terms of the prediction and estimation\naccuracies. We also consider the application of our robust learning procedure\nto outlier detection, and show that our approach achieves a much higher AUC\n(Area Under the ROC Curve) than M-estimation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 23:35:13 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 18:57:32 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Chen", "Ruidi", ""], ["Paschalidis", "Ioannis Ch.", ""]]}, {"id": "1706.02419", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky, Brendan D. Tracey", "title": "Estimating Mixture Entropy with Pairwise Distances", "comments": "Corrects several errata in published version, in particular in\n  Section V (bounds on mutual information)", "journal-ref": "Entropy 2017, 19(7), 361", "doi": "10.3390/e19070361", "report-no": null, "categories": "cs.IT math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture distributions arise in many parametric and non-parametric settings --\nfor example, in Gaussian mixture models and in non-parametric estimation. It is\noften necessary to compute the entropy of a mixture, but, in most cases, this\nquantity has no closed-form expression, making some form of approximation\nnecessary. We propose a family of estimators based on a pairwise distance\nfunction between mixture components, and show that this estimator class has\nmany attractive properties. For many distributions of interest, the proposed\nestimators are efficient to compute, differentiable in the mixture parameters,\nand become exact when the mixture components are clustered. We prove this\nfamily includes lower and upper bounds on the mixture entropy. The Chernoff\n$\\alpha$-divergence gives a lower bound when chosen as the distance function,\nwith the Bhattacharyya distance providing the tightest lower bound for\ncomponents that are symmetric and members of a location family. The\nKullback-Leibler divergence gives an upper bound when used as the distance\nfunction. We provide closed-form expressions of these bounds for mixtures of\nGaussians, and discuss their applications to the estimation of mutual\ninformation. We then demonstrate that our bounds are significantly tighter than\nwell-known existing bounds using numeric simulations. This estimator class is\nvery useful in optimization problems involving maximization/minimization of\nentropy and mutual information, such as MaxEnt and rate distortion problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 00:47:46 GMT"}, {"version": "v2", "created": "Fri, 14 Jul 2017 20:06:34 GMT"}, {"version": "v3", "created": "Wed, 8 Nov 2017 01:25:04 GMT"}, {"version": "v4", "created": "Wed, 22 Aug 2018 05:33:38 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Kolchinsky", "Artemy", ""], ["Tracey", "Brendan D.", ""]]}, {"id": "1706.02471", "submitter": "Zhi-Hua Zhou", "authors": "Peng Zhao and Zhi-Hua Zhou", "title": "Distribution-Free One-Pass Learning", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering 2019", "doi": "10.1109/TKDE.2019.2937078", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many large-scale machine learning applications, data are accumulated with\ntime, and thus, an appropriate model should be able to update in an online\nparadigm. Moreover, as the whole data volume is unknown when constructing the\nmodel, it is desired to scan each data item only once with a storage\nindependent with the data volume. It is also noteworthy that the distribution\nunderlying may change during the data accumulation procedure. To handle such\ntasks, in this paper we propose DFOP, a distribution-free one-pass learning\napproach. This approach works well when distribution change occurs during data\naccumulation, without requiring prior knowledge about the change. Every data\nitem can be discarded once it has been scanned. Besides, theoretical guarantee\nshows that the estimate error, under a mild assumption, decreases until\nconvergence with high probability. The performance of DFOP for both regression\nand classification are validated in experiments.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 08:09:29 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhao", "Peng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1706.02480", "submitter": "Jeffrey Humpherys", "authors": "Chris Hettinger, Tanner Christensen, Ben Ehlert, Jeffrey Humpherys,\n  Tyler Jarvis, and Sean Wade", "title": "Forward Thinking: Building and Training Neural Networks One Layer at a\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for training deep neural networks without\nbackpropagation. This substantially decreases training time and also allows for\nconstruction of deep networks with many sorts of learners, including networks\nwhose layers are defined by functions that are not easily differentiated, like\ndecision trees. The main idea is that layers can be trained one at a time, and\nonce they are trained, the input data are mapped forward through the layer to\ncreate a new learning problem. The process is repeated, transforming the data\nthrough multiple layers, one at a time, rendering a new data set, which is\nexpected to be better behaved, and on which a final output layer can achieve\ngood performance. We call this forward thinking and demonstrate a proof of\nconcept by achieving state-of-the-art accuracy on the MNIST dataset for\nconvolutional neural networks. We also provide a general mathematical\nformulation of forward thinking that allows for other types of deep learning\nproblems to be considered.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 08:53:00 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Hettinger", "Chris", ""], ["Christensen", "Tanner", ""], ["Ehlert", "Ben", ""], ["Humpherys", "Jeffrey", ""], ["Jarvis", "Tyler", ""], ["Wade", "Sean", ""]]}, {"id": "1706.02492", "submitter": "Alessio Sancetta", "authors": "Alessio Sancetta", "title": "Consistency Results for Stationary Autoregressive Processes with\n  Constrained Coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stationary autoregressive processes with coefficients restricted\nto an ellipsoid, which includes autoregressive processes with absolutely\nsummable coefficients. We provide consistency results under different norms for\nthe estimation of such processes using constrained and penalized estimators. As\nan application we show some weak form of universal consistency. Simulations\nshow that directly including the constraint in the estimation can lead to more\nrobust results.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:34:31 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Sancetta", "Alessio", ""]]}, {"id": "1706.02495", "submitter": "Giulio Bottegal", "authors": "Giulio Bottegal and Gianluigi Pillonetto", "title": "The Generalized Cross Validation Filter", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized cross validation (GCV) is one of the most important approaches\nused to estimate parameters in the context of inverse problems and\nregularization techniques. A notable example is the determination of the\nsmoothness parameter in splines. When the data are generated by a state space\nmodel, like in the spline case, efficient algorithms are available to evaluate\nthe GCV score with complexity that scales linearly in the data set size.\nHowever, these methods are not amenable to on-line applications since they rely\non forward and backward recursions. Hence, if the objective has been evaluated\nat time $t-1$ and new data arrive at time t, then O(t) operations are needed to\nupdate the GCV score. In this paper we instead show that the update cost is\n$O(1)$, thus paving the way to the on-line use of GCV. This result is obtained\nby deriving the novel GCV filter which extends the classical Kalman filter\nequations to efficiently propagate the GCV score over time. We also illustrate\napplications of the new filter in the context of state estimation and on-line\nregularized linear system identification.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:49:25 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Bottegal", "Giulio", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1706.02496", "submitter": "Franziska Horn", "authors": "Franziska Horn", "title": "Context encoders as a simple but powerful extension of word2vec", "comments": "ACL 2017 2nd Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a simple architecture and the ability to learn meaningful word\nembeddings efficiently from texts containing billions of words, word2vec\nremains one of the most popular neural language models used today. However, as\nonly a single embedding is learned for every word in the vocabulary, the model\nfails to optimally represent words with multiple meanings. Additionally, it is\nnot possible to create embeddings for new (out-of-vocabulary) words on the\nspot. Based on an intuitive interpretation of the continuous bag-of-words\n(CBOW) word2vec model's negative sampling training objective in terms of\npredicting context based similarities, we motivate an extension of the model we\ncall context encoders (ConEc). By multiplying the matrix of trained word2vec\nembeddings with a word's average context vector, out-of-vocabulary (OOV)\nembeddings and representations for a word with multiple meanings can be created\nbased on the word's local contexts. The benefits of this approach are\nillustrated by using these word embeddings as features in the CoNLL 2003 named\nentity recognition (NER) task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:56:11 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Horn", "Franziska", ""]]}, {"id": "1706.02515", "submitter": "G\\\"unter Klambauer", "authors": "G\\\"unter Klambauer, Thomas Unterthiner, Andreas Mayr and Sepp\n  Hochreiter", "title": "Self-Normalizing Neural Networks", "comments": "9 pages (+ 93 pages appendix)", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS 2017)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has revolutionized vision via convolutional neural networks\n(CNNs) and natural language processing via recurrent neural networks (RNNs).\nHowever, success stories of Deep Learning with standard feed-forward neural\nnetworks (FNNs) are rare. FNNs that perform well are typically shallow and,\ntherefore cannot exploit many levels of abstract representations. We introduce\nself-normalizing neural networks (SNNs) to enable high-level abstract\nrepresentations. While batch normalization requires explicit normalization,\nneuron activations of SNNs automatically converge towards zero mean and unit\nvariance. The activation function of SNNs are \"scaled exponential linear units\"\n(SELUs), which induce self-normalizing properties. Using the Banach fixed-point\ntheorem, we prove that activations close to zero mean and unit variance that\nare propagated through many network layers will converge towards zero mean and\nunit variance -- even under the presence of noise and perturbations. This\nconvergence property of SNNs allows to (1) train deep networks with many\nlayers, (2) employ strong regularization, and (3) to make learning highly\nrobust. Furthermore, for activations not close to unit variance, we prove an\nupper and lower bound on the variance, thus, vanishing and exploding gradients\nare impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning\nrepository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with\nstandard FNNs and other machine learning methods such as random forests and\nsupport vector machines. SNNs significantly outperformed all competing FNN\nmethods at 121 UCI tasks, outperformed all competing methods at the Tox21\ndataset, and set a new record at an astronomy data set. The winning SNN\narchitectures are often very deep. Implementations are available at:\ngithub.com/bioinf-jku/SNNs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 11:14:24 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 12:01:44 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 10:46:17 GMT"}, {"version": "v4", "created": "Wed, 6 Sep 2017 13:33:53 GMT"}, {"version": "v5", "created": "Thu, 7 Sep 2017 10:39:00 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Klambauer", "G\u00fcnter", ""], ["Unterthiner", "Thomas", ""], ["Mayr", "Andreas", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1706.02524", "submitter": "Hyunjik Kim", "authors": "Hyunjik Kim and Yee Whye Teh", "title": "Scaling up the Automatic Statistician: Scalable Structure Discovery\n  using Gaussian Processes", "comments": "AISTATS 2018 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating statistical modelling is a challenging problem in artificial\nintelligence. The Automatic Statistician takes a first step in this direction,\nby employing a kernel search algorithm with Gaussian Processes (GP) to provide\ninterpretable statistical models for regression problems. However this does not\nscale due to its $O(N^3)$ running time for the model selection. We propose\nScalable Kernel Composition (SKC), a scalable kernel search algorithm that\nextends the Automatic Statistician to bigger data sets. In doing so, we derive\na cheap upper bound on the GP marginal likelihood that sandwiches the marginal\nlikelihood with the variational lower bound . We show that the upper bound is\nsignificantly tighter than the lower bound and thus useful for model selection.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 11:41:51 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 12:56:33 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Kim", "Hyunjik", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1706.02542", "submitter": "Chris Larson", "authors": "Chris Larson, Josef Spjut, Ross Knepper, Robert Shepherd", "title": "A Deformable Interface for Human Touch Recognition using Stretchable\n  Carbon Nanotube Dielectric Elastomer Sensors and Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User interfaces provide an interactive window between physical and virtual\nenvironments. A new concept in the field of human-computer interaction is a\nsoft user interface; a compliant surface that facilitates touch interaction\nthrough deformation. Despite the potential of these interfaces, they currently\nlack a signal processing framework that can efficiently extract information\nfrom their deformation. Here we present OrbTouch, a device that uses\nstatistical learning algorithms, based on convolutional neural networks, to map\ndeformations from human touch to categorical labels (i.e., gestures) and touch\nlocation using stretchable capacitor signals as inputs. We demonstrate this\napproach by using the device to control the popular game Tetris. OrbTouch\nprovides a modular, robust framework to interpret deformation in soft media,\nlaying a foundation for new modes of human computer interaction through shape\nchanging solids.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 12:20:44 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 13:17:27 GMT"}, {"version": "v3", "created": "Sat, 24 Mar 2018 14:45:12 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Larson", "Chris", ""], ["Spjut", "Josef", ""], ["Knepper", "Ross", ""], ["Shepherd", "Robert", ""]]}, {"id": "1706.02562", "submitter": "Benjamin Rubinstein", "authors": "Benjamin I. P. Rubinstein, Francesco Ald\\`a", "title": "Pain-Free Random Differential Privacy with Sensitivity Sampling", "comments": "12 pages, 9 figures, 1 table; full report of paper accepted into\n  ICML'2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular approaches to differential privacy, such as the Laplace and\nexponential mechanisms, calibrate randomised smoothing through global\nsensitivity of the target non-private function. Bounding such sensitivity is\noften a prohibitively complex analytic calculation. As an alternative, we\npropose a straightforward sampler for estimating sensitivity of non-private\nmechanisms. Since our sensitivity estimates hold with high probability, any\nmechanism that would be $(\\epsilon,\\delta)$-differentially private under\nbounded global sensitivity automatically achieves\n$(\\epsilon,\\delta,\\gamma)$-random differential privacy (Hall et al., 2012),\nwithout any target-specific calculations required. We demonstrate on worked\nexample learners how our usable approach adopts a naturally-relaxed privacy\nguarantee, while achieving more accurate releases even for non-private\nfunctions that are black-box computer programs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 13:06:34 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Rubinstein", "Benjamin I. P.", ""], ["Ald\u00e0", "Francesco", ""]]}, {"id": "1706.02582", "submitter": "Stefan Steinerberger", "authors": "George C. Linderman, Stefan Steinerberger", "title": "Clustering with t-SNE, provably", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-distributed Stochastic Neighborhood Embedding (t-SNE), a clustering and\nvisualization method proposed by van der Maaten & Hinton in 2008, has rapidly\nbecome a standard tool in a number of natural sciences. Despite its\noverwhelming success, there is a distinct lack of mathematical foundations and\nthe inner workings of the algorithm are not well understood. The purpose of\nthis paper is to prove that t-SNE is able to recover well-separated clusters;\nmore precisely, we prove that t-SNE in the `early exaggeration' phase, an\noptimization technique proposed by van der Maaten & Hinton (2008) and van der\nMaaten (2014), can be rigorously analyzed. As a byproduct, the proof suggests\nnovel ways for setting the exaggeration parameter $\\alpha$ and step size $h$.\nNumerical examples illustrate the effectiveness of these rules: in particular,\nthe quality of embedding of topological structures (e.g. the swiss roll)\nimproves. We also discuss a connection to spectral clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 13:44:15 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Linderman", "George C.", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "1706.02586", "submitter": "Amir Ali Ahmadi", "authors": "Amir Ali Ahmadi and Anirudha Majumdar", "title": "DSOS and SDSOS Optimization: More Tractable Alternatives to Sum of\n  Squares and Semidefinite Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, optimization theory has been greatly impacted by the advent\nof sum of squares (SOS) optimization. The reliance of this technique on\nlarge-scale semidefinite programs however, has limited the scale of problems to\nwhich it can be applied. In this paper, we introduce DSOS and SDSOS\noptimization as linear programming and second-order cone programming-based\nalternatives to sum of squares optimization that allow one to trade off\ncomputation time with solution quality. These are optimization problems over\ncertain subsets of sum of squares polynomials (or equivalently subsets of\npositive semidefinite matrices), which can be of interest in general\napplications of semidefinite programming where scalability is a limitation. We\nshow that some basic theorems from SOS optimization which rely on results from\nreal algebraic geometry are still valid for DSOS and SDSOS optimization.\nFurthermore, we show with numerical experiments from diverse application\nareas---polynomial optimization, statistics and machine learning, derivative\npricing, and control theory---that with reasonable tradeoffs in accuracy, we\ncan handle problems at scales that are currently significantly beyond the reach\nof traditional sum of squares approaches. Finally, we provide a review of\nrecent techniques that bridge the gap between our DSOS/SDSOS approach and the\nSOS approach at the expense of additional running time. The Supplementary\nMaterial of the paper introduces an accompanying MATLAB package for DSOS and\nSDSOS optimization.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 13:52:23 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 20:08:30 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 19:51:04 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "1706.02609", "submitter": "Yujie Wu", "authors": "Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, Luping Shi", "title": "Spatio-Temporal Backpropagation for Training High-performance Spiking\n  Neural Networks", "comments": null, "journal-ref": "Frontiers in neuroscience, 2018, 12", "doi": "10.3389/fnins.2018.00331", "report-no": null, "categories": "cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with artificial neural networks (ANNs), spiking neural networks\n(SNNs) are promising to explore the brain-like behaviors since the spikes could\nencode more spatio-temporal information. Although pre-training from ANN or\ndirect training based on backpropagation (BP) makes the supervised training of\nSNNs possible, these methods only exploit the networks' spatial domain\ninformation which leads to the performance bottleneck and requires many\ncomplicated training skills. Another fundamental issue is that the spike\nactivity is naturally non-differentiable which causes great difficulties in\ntraining SNNs. To this end, we build an iterative LIF model that is more\nfriendly for gradient descent training. By simultaneously considering the\nlayer-by-layer spatial domain (SD) and the timing-dependent temporal domain\n(TD) in the training phase, as well as an approximated derivative for the spike\nactivity, we propose a spatio-temporal backpropagation (STBP) training\nframework without using any complicated technology. We achieve the best\nperformance of multi-layered perceptron (MLP) compared with existing\nstate-of-the-art algorithms over the static MNIST and the dynamic N-MNIST\ndataset as well as a custom object detection dataset. This work provides a new\nperspective to explore the high-performance SNNs for future brain-like\ncomputing paradigm with rich spatio-temporal dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 14:33:55 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 02:40:45 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 10:50:05 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Zhu", "Jun", ""], ["Shi", "Luping", ""]]}, {"id": "1706.02631", "submitter": "Zhiwu Huang", "authors": "Jiqing Wu, Zhiwu Huang, Dinesh Acharya, Wen Li, Janine Thoma, Danda\n  Pani Paudel, Luc Van Gool", "title": "Sliced Wasserstein Generative Models", "comments": "This paper is accepted by CVPR 2019, accidentally uploaded as a new\n  submission (arXiv:1904.05408, which has been withdrawn). The code is\n  available at this https URL https:// github.com/musikisomorphie/swd.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In generative modeling, the Wasserstein distance (WD) has emerged as a useful\nmetric to measure the discrepancy between generated and real data\ndistributions. Unfortunately, it is challenging to approximate the WD of\nhigh-dimensional distributions. In contrast, the sliced Wasserstein distance\n(SWD) factorizes high-dimensional distributions into their multiple\none-dimensional marginal distributions and is thus easier to approximate. In\nthis paper, we introduce novel approximations of the primal and dual SWD.\nInstead of using a large number of random projections, as it is done by\nconventional SWD approximation methods, we propose to approximate SWDs with a\nsmall number of parameterized orthogonal projections in an end-to-end deep\nlearning fashion. As concrete applications of our SWD approximations, we design\ntwo types of differentiable SWD blocks to equip modern generative\nframeworks---Auto-Encoders (AE) and Generative Adversarial Networks (GAN). In\nthe experiments, we not only show the superiority of the proposed generative\nmodels on standard image synthesis benchmarks, but also demonstrate the\nstate-of-the-art performance on challenging high resolution image and video\ngeneration in an unsupervised manner.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 15:16:36 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 16:58:22 GMT"}, {"version": "v3", "created": "Mon, 5 Mar 2018 09:01:58 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2019 20:56:19 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wu", "Jiqing", ""], ["Huang", "Zhiwu", ""], ["Acharya", "Dinesh", ""], ["Li", "Wen", ""], ["Thoma", "Janine", ""], ["Paudel", "Danda Pani", ""], ["Van Gool", "Luc", ""]]}, {"id": "1706.02633", "submitter": "Stephanie L. Hyland", "authors": "Crist\\'obal Esteban, Stephanie L. Hyland, Gunnar R\\\"atsch", "title": "Real-valued (Medical) Time Series Generation with Recurrent Conditional\n  GANs", "comments": "13 pages, 4 figures, 3 tables (update with differential privacy)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown remarkable success as a\nframework for training models to produce realistic-looking data. In this work,\nwe propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to\nproduce realistic real-valued multi-dimensional time series, with an emphasis\non their application to medical data. RGANs make use of recurrent neural\nnetworks in the generator and the discriminator. In the case of RCGANs, both of\nthese RNNs are conditioned on auxiliary information. We demonstrate our models\nin a set of toy datasets, where we show visually and quantitatively (using\nsample likelihood and maximum mean discrepancy) that they can successfully\ngenerate realistic time-series. We also describe novel evaluation methods for\nGANs, where we generate a synthetic labelled training dataset, and evaluate on\na real test set the performance of a model trained on the synthetic data, and\nvice-versa. We illustrate with these metrics that RCGANs can generate\ntime-series data useful for supervised training, with only minor degradation in\nperformance on real test data. This is demonstrated on digit classification\nfrom 'serialised' MNIST and by training an early warning system on a medical\ndataset of 17,000 patients from an intensive care unit. We further discuss and\nanalyse the privacy concerns that may arise when using RCGANs to generate\nrealistic synthetic medical time series data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 15:19:02 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 04:31:38 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Esteban", "Crist\u00f3bal", ""], ["Hyland", "Stephanie L.", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1706.02645", "submitter": "Tom Viering", "authors": "Tom J. Viering, Jesse H. Krijthe, Marco Loog", "title": "Nuclear Discrepancy for Active Learning", "comments": "32 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning algorithms propose which unlabeled objects should be queried\nfor their labels to improve a predictive model the most. We study active\nlearners that minimize generalization bounds and uncover relationships between\nthese bounds that lead to an improved approach to active learning. In\nparticular we show the relation between the bound of the state-of-the-art\nMaximum Mean Discrepancy (MMD) active learner, the bound of the Discrepancy,\nand a new and looser bound that we refer to as the Nuclear Discrepancy bound.\nWe motivate this bound by a probabilistic argument: we show it considers\nsituations which are more likely to occur. Our experiments indicate that active\nlearning using the tightest Discrepancy bound performs the worst in terms of\nthe squared loss. Overall, our proposed loosest Nuclear Discrepancy\ngeneralization bound performs the best. We confirm our probabilistic argument\nempirically: the other bounds focus on more pessimistic scenarios that are\nrarer in practice. We conclude that tightness of bounds is not always of main\nimportance and that active learning methods should concentrate on realistic\nscenarios in order to improve performance.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 15:35:28 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Viering", "Tom J.", ""], ["Krijthe", "Jesse H.", ""], ["Loog", "Marco", ""]]}, {"id": "1706.02690", "submitter": "Yixuan Li", "authors": "Shiyu Liang, Yixuan Li and R. Srikant", "title": "Enhancing The Reliability of Out-of-distribution Image Detection in\n  Neural Networks", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting out-of-distribution images in neural\nnetworks. We propose ODIN, a simple and effective method that does not require\nany change to a pre-trained neural network. Our method is based on the\nobservation that using temperature scaling and adding small perturbations to\nthe input can separate the softmax score distributions between in- and\nout-of-distribution images, allowing for more effective detection. We show in a\nseries of experiments that ODIN is compatible with diverse network\narchitectures and datasets. It consistently outperforms the baseline approach\nby a large margin, establishing a new state-of-the-art performance on this\ntask. For example, ODIN reduces the false positive rate from the baseline 34.7%\nto 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is\n95%.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 17:43:56 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 17:48:16 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 18:33:49 GMT"}, {"version": "v4", "created": "Sun, 25 Feb 2018 18:51:13 GMT"}, {"version": "v5", "created": "Sun, 30 Aug 2020 16:50:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Liang", "Shiyu", ""], ["Li", "Yixuan", ""], ["Srikant", "R.", ""]]}, {"id": "1706.02714", "submitter": "Yang-Hui He", "authors": "Yang-Hui He", "title": "Deep-Learning the Landscape", "comments": "35 pages, 4 figures, code available, refs and comments added on v2,\n  substantial updates on training curves and validation on v3", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th hep-ph math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a paradigm to deep-learn the ever-expanding databases which have\nemerged in mathematical physics and particle phenomenology, as diverse as the\nstatistics of string vacua or combinatorial and algebraic geometry. As concrete\nexamples, we establish multi-layer neural networks as both classifiers and\npredictors and train them with a host of available data ranging from Calabi-Yau\nmanifolds and vector bundles, to quiver representations for gauge theories. We\nfind that even a relatively simple neural network can learn many significant\nquantities to astounding accuracy in a matter of minutes and can also predict\nhithertofore unencountered results. This paradigm should prove a valuable tool\nin various investigations in landscapes in physics as well as pure mathematics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 18:01:02 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 21:28:02 GMT"}, {"version": "v3", "created": "Sat, 27 Jan 2018 09:50:52 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["He", "Yang-Hui", ""]]}, {"id": "1706.02744", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus, Mateo Rojas-Carulla, Giambattista Parascandolo, Moritz\n  Hardt, Dominik Janzing, Bernhard Sch\\\"olkopf", "title": "Avoiding Discrimination through Causal Reasoning", "comments": "Advances in Neural Information Processing Systems 30, 2017\n  http://papers.nips.cc/paper/6668-avoiding-discrimination-through-causal-reasoning", "journal-ref": "Advances in Neural Information Processing Systems 30, 2017, p.\n  656--666", "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on fairness in machine learning has focused on various\nstatistical discrimination criteria and how they trade off. Most of these\ncriteria are observational: They depend only on the joint distribution of\npredictor, protected attribute, features, and outcome. While convenient to work\nwith, observational criteria have severe inherent limitations that prevent them\nfrom resolving matters of fairness conclusively.\n  Going beyond observational criteria, we frame the problem of discrimination\nbased on protected attributes in the language of causal reasoning. This\nviewpoint shifts attention from \"What is the right fairness criterion?\" to\n\"What do we want to assume about the causal data generating process?\" Through\nthe lens of causality, we make several contributions. First, we crisply\narticulate why and when observational criteria fail, thus formalizing what was\nbefore a matter of opinion. Second, our approach exposes previously ignored\nsubtleties and why they are fundamental to the problem. Finally, we put forward\nnatural causal non-discrimination criteria and develop algorithms that satisfy\nthem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 19:50:56 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 16:39:51 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Kilbertus", "Niki", ""], ["Rojas-Carulla", "Mateo", ""], ["Parascandolo", "Giambattista", ""], ["Hardt", "Moritz", ""], ["Janzing", "Dominik", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1706.02761", "submitter": "Li Jing", "authors": "Li Jing, Caglar Gulcehre, John Peurifoy, Yichen Shen, Max Tegmark,\n  Marin Solja\\v{c}i\\'c, Yoshua Bengio", "title": "Gated Orthogonal Recurrent Units: On Learning to Forget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel recurrent neural network (RNN) based model that combines\nthe remembering ability of unitary RNNs with the ability of gated RNNs to\neffectively forget redundant/irrelevant information in its memory. We achieve\nthis by extending unitary RNNs with a gating mechanism. Our model is able to\noutperform LSTMs, GRUs and Unitary RNNs on several long-term dependency\nbenchmark tasks. We empirically both show the orthogonal/unitary RNNs lack the\nability to forget and also the ability of GORU to simultaneously remember long\nterm dependencies while forgetting irrelevant information. This plays an\nimportant role in recurrent neural networks. We provide competitive results\nalong with an analysis of our model on many natural sequential tasks including\nthe bAbI Question Answering, TIMIT speech spectrum prediction, Penn TreeBank,\nand synthetic tasks that involve long-term dependencies such as algorithmic,\nparenthesis, denoising and copying tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 20:40:32 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 13:47:17 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 15:17:03 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Jing", "Li", ""], ["Gulcehre", "Caglar", ""], ["Peurifoy", "John", ""], ["Shen", "Yichen", ""], ["Tegmark", "Max", ""], ["Solja\u010di\u0107", "Marin", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1706.02776", "submitter": "Matt Shannon", "authors": "Matt Shannon", "title": "Optimizing expected word error rate via sampling for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-level minimum Bayes risk (sMBR) training has become the de facto\nstandard for sequence-level training of speech recognition acoustic models. It\nhas an elegant formulation using the expectation semiring, and gives large\nimprovements in word error rate (WER) over models trained solely using\ncross-entropy (CE) or connectionist temporal classification (CTC). sMBR\ntraining optimizes the expected number of frames at which the reference and\nhypothesized acoustic states differ. It may be preferable to optimize the\nexpected WER, but WER does not interact well with the expectation semiring, and\nprevious approaches based on computing expected WER exactly involve expanding\nthe lattices used during training. In this paper we show how to perform\noptimization of the expected WER by sampling paths from the lattices used\nduring conventional sMBR training. The gradient of the expected WER is itself\nan expectation, and so may be approximated using Monte Carlo sampling. We show\nexperimentally that optimizing WER during acoustic model training gives 5%\nrelative improvement in WER over a well-tuned sMBR baseline on a 2-channel\nquery recognition task (Google Home).\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 21:14:48 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Shannon", "Matt", ""]]}, {"id": "1706.02795", "submitter": "Thai Pham", "authors": "Thai T. Pham and Yuanyuan Shen", "title": "A Deep Causal Inference Approach to Measuring the Effects of Forming\n  Group Loans in Online Non-profit Microfinance Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kiva is an online non-profit crowdsouring microfinance platform that raises\nfunds for the poor in the third world. The borrowers on Kiva are small business\nowners and individuals in urgent need of money. To raise funds as fast as\npossible, they have the option to form groups and post loan requests in the\nname of their groups. While it is generally believed that group loans pose less\nrisk for investors than individual loans do, we study whether this is the case\nin a philanthropic online marketplace. In particular, we measure the effect of\ngroup loans on funding time while controlling for the loan sizes and other\nfactors. Because loan descriptions (in the form of texts) play an important\nrole in lenders' decision process on Kiva, we make use of this information\nthrough deep learning in natural language processing. In this aspect, this is\nthe first paper that uses one of the most advanced deep learning techniques to\ndeal with unstructured data in a way that can take advantage of its superior\nprediction power to answer causal questions. We find that on average, forming\ngroup loans speeds up the funding time by about 3.3 days.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 23:43:12 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Pham", "Thai T.", ""], ["Shen", "Yuanyuan", ""]]}, {"id": "1706.02803", "submitter": "Shusen Wang", "authors": "Shusen Wang and Alex Gittens and Michael W. Mahoney", "title": "Scalable Kernel K-Means Clustering with Nystrom Approximation:\n  Relative-Error Bounds", "comments": null, "journal-ref": "Journal of Machine Learning Research 20 (2019) 1-49", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel $k$-means clustering can correctly identify and extract a far more\nvaried collection of cluster structures than the linear $k$-means clustering\nalgorithm. However, kernel $k$-means clustering is computationally expensive\nwhen the non-linear feature map is high-dimensional and there are many input\npoints. Kernel approximation, e.g., the Nystr\\\"om method, has been applied in\nprevious works to approximately solve kernel learning problems when both of the\nabove conditions are present. This work analyzes the application of this\nparadigm to kernel $k$-means clustering, and shows that applying the linear\n$k$-means clustering algorithm to $\\frac{k}{\\epsilon} (1 + o(1))$ features\nconstructed using a so-called rank-restricted Nystr\\\"om approximation results\nin cluster assignments that satisfy a $1 + \\epsilon$ approximation ratio in\nterms of the kernel $k$-means cost function, relative to the guarantee provided\nby the same algorithm without the use of the Nystr\\\"om method. As part of the\nanalysis, this work establishes a novel $1 + \\epsilon$ relative-error trace\nnorm guarantee for low-rank approximation using the rank-restricted Nystr\\\"om\napproximation. Empirical evaluations on the $8.1$ million instance MNIST8M\ndataset demonstrate the scalability and usefulness of kernel $k$-means\nclustering with Nystr\\\"om approximation. This work argues that spectral\nclustering using Nystr\\\"om approximation---a popular and computationally\nefficient, but theoretically unsound approach to non-linear clustering---should\nbe replaced with the efficient and theoretically sound combination of kernel\n$k$-means clustering with Nystr\\\"om approximation. The superior performance of\nthe latter approach is empirically verified.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 01:17:20 GMT"}, {"version": "v2", "created": "Sat, 24 Jun 2017 20:17:36 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2019 02:33:30 GMT"}, {"version": "v4", "created": "Sun, 10 Feb 2019 17:21:08 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Wang", "Shusen", ""], ["Gittens", "Alex", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1706.02829", "submitter": "Aleksandr Aravkin", "authors": "Avner Abrami, Aleksandr Y. Aravkin, and Younghun Kim", "title": "Time Series Using Exponential Smoothing Cells", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series analysis is used to understand and predict dynamic processes,\nincluding evolving demands in business, weather, markets, and biological\nrhythms. Exponential smoothing is used in all these domains to obtain simple\ninterpretable models of time series and to forecast future values. Despite its\npopularity, exponential smoothing fails dramatically in the presence of\noutliers, large amounts of noise, or when the underlying time series changes.\n  We propose a flexible model for time series analysis, using exponential\nsmoothing cells for overlapping time windows. The approach can detect and\nremove outliers, denoise data, fill in missing observations, and provide\nmeaningful forecasts in challenging situations. In contrast to classic\nexponential smoothing, which solves a nonconvex optimization problem over the\nsmoothing parameters and initial state, the proposed approach requires solving\na single structured convex optimization problem. Recent developments in\nefficient convex optimization of large-scale dynamic models make the approach\ntractable. We illustrate new capabilities using synthetic examples, and then\nuse the approach to analyze and forecast noisy real-world time series. Code for\nthe approach and experiments is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 04:05:01 GMT"}, {"version": "v2", "created": "Sun, 25 Jun 2017 13:21:43 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 16:15:18 GMT"}, {"version": "v4", "created": "Fri, 29 Sep 2017 12:06:23 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Abrami", "Avner", ""], ["Aravkin", "Aleksandr Y.", ""], ["Kim", "Younghun", ""]]}, {"id": "1706.02857", "submitter": "Matthias Gall\\'e", "authors": "Ariadna Quattoni, Xavier Carreras, Matthias Gall\\'e", "title": "A Maximum Matching Algorithm for Basis Selection in Spectral Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a solution to scale spectral algorithms for learning sequence\nfunctions. We are interested in the case where these functions are sparse (that\nis, for most sequences they return 0). Spectral algorithms reduce the learning\nproblem to the task of computing an SVD decomposition over a special type of\nmatrix called the Hankel matrix. This matrix is designed to capture the\nrelevant statistics of the training sequences. What is crucial is that to\ncapture long range dependencies we must consider very large Hankel matrices.\nThus the computation of the SVD becomes a critical bottleneck. Our solution\nfinds a subset of rows and columns of the Hankel that realizes a compact and\ninformative Hankel submatrix. The novelty lies in the way that this subset is\nselected: we exploit a maximal bipartite matching combinatorial algorithm to\nlook for a sub-block with full structural rank, and show how computation of\nthis sub-block can be further improved by exploiting the specific structure of\nHankel matrices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 07:43:46 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Quattoni", "Ariadna", ""], ["Carreras", "Xavier", ""], ["Gall\u00e9", "Matthias", ""]]}, {"id": "1706.02899", "submitter": "Yanfei Zhang", "authors": "Yanfei Zhang and Junbin Gao", "title": "Assessing the Performance of Deep Learning Algorithms for Newsvendor\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In retailer management, the Newsvendor problem has widely attracted attention\nas one of basic inventory models. In the traditional approach to solving this\nproblem, it relies on the probability distribution of the demand. In theory, if\nthe probability distribution is known, the problem can be considered as fully\nsolved. However, in any real world scenario, it is almost impossible to even\napproximate or estimate a better probability distribution for the demand. In\nrecent years, researchers start adopting machine learning approach to learn a\ndemand prediction model by using other feature information. In this paper, we\npropose a supervised learning that optimizes the demand quantities for products\nbased on feature information. We demonstrate that the original Newsvendor loss\nfunction as the training objective outperforms the recently suggested quadratic\nloss function. The new algorithm has been assessed on both the synthetic data\nand real-world data, demonstrating better performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 11:21:35 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Zhang", "Yanfei", ""], ["Gao", "Junbin", ""]]}, {"id": "1706.02932", "submitter": "James Thewlis", "authors": "James Thewlis and Hakan Bilen and Andrea Vedaldi", "title": "Unsupervised learning of object frames by dense equivariant image\n  labelling", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges of visual perception is to extract abstract models\nof 3D objects and object categories from visual measurements, which are\naffected by complex nuisance factors such as viewpoint, occlusion, motion, and\ndeformations. Starting from the recent idea of viewpoint factorization, we\npropose a new approach that, given a large number of images of an object and no\nother supervision, can extract a dense object-centric coordinate frame. This\ncoordinate frame is invariant to deformations of the images and comes with a\ndense equivariant labelling neural network that can map image pixels to their\ncorresponding object coordinates. We demonstrate the applicability of this\nmethod to simple articulated objects and deformable objects such as human\nfaces, learning embeddings from random synthetic transformations or optical\nflow correspondences, all without any manual supervision.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 12:49:36 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 02:36:48 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Thewlis", "James", ""], ["Bilen", "Hakan", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1706.02952", "submitter": "Amit Dhurandhar", "authors": "Amit Dhurandhar, Vijay Iyengar, Ronny Luss and Karthikeyan Shanmugam", "title": "TIP: Typifying the Interpretability of Procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking them to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability. Finally, principled interpretable strategies are\nproposed and empirically evaluated on synthetic data, as well as on the largest\npublic olfaction dataset that was made recently available \\cite{olfs}. We also\nexperiment on MNIST with a simple target model and different oracle models of\nvarying complexity. This leads to the insight that the improvement in the\ntarget model is not only a function of the oracle model's performance, but also\nits relative complexity with respect to the target model. Further experiments\non CIFAR-10, a real manufacturing dataset and FICO dataset showcase the benefit\nof our methods over Knowledge Distillation when the target models are simple\nand the complex model is a neural network.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 13:55:18 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 16:12:02 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 15:49:37 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Iyengar", "Vijay", ""], ["Luss", "Ronny", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "1706.02986", "submitter": "Emilie Kaufmann", "authors": "Emilie Kaufmann (CNRS, CRIStAL, SEQUEL), Wouter Koolen (CWI)", "title": "Monte-Carlo Tree Search by Best Arm Identification", "comments": "Advances in Neural Information Processing Systems (NIPS), Dec 2017,\n  Long Beach, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in bandit tools and techniques for sequential learning are\nsteadily enabling new applications and are promising the resolution of a range\nof challenging related problems. We study the game tree search problem, where\nthe goal is to quickly identify the optimal move in a given game tree by\nsequentially sampling its stochastic payoffs. We develop new algorithms for\ntrees of arbitrary depth, that operate by summarizing all deeper levels of the\ntree into confidence intervals at depth one, and applying a best arm\nidentification procedure at the root. We prove new sample complexity guarantees\nwith a refined dependence on the problem instance. We show experimentally that\nour algorithms outperform existing elimination-based algorithms and match\nprevious special-purpose methods for depth-two trees.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 14:58:10 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 07:48:45 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Kaufmann", "Emilie", "", "CNRS, CRIStAL, SEQUEL"], ["Koolen", "Wouter", "", "CWI"]]}, {"id": "1706.02999", "submitter": "Theja Tulabandhula", "authors": "Anuj Mahajan and Theja Tulabandhula", "title": "Symmetry Learning for Function Approximation in Reinforcement Learning", "comments": "12 pages, 3 figures. A preliminary version appears in AAMAS 2017.\n  Also presented at the 3rd Multidisciplinary Conference on Reinforcement\n  Learning and Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore methods to exploit symmetries for ensuring sample\nefficiency in reinforcement learning (RL), this problem deserves ever\nincreasing attention with the recent advances in the use of deep networks for\ncomplex RL tasks which require large amount of training data. We introduce a\nnovel method to detect symmetries using reward trails observed during episodic\nexperience and prove its completeness. We also provide a framework to\nincorporate the discovered symmetries for functional approximation. Finally we\nshow that the use of potential based reward shaping is especially effective for\nour symmetry exploitation mechanism. Experiments on various classical problems\nshow that our method improves the learning performance significantly by\nutilizing symmetry information.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 15:30:32 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Mahajan", "Anuj", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1706.03078", "submitter": "Alberto Bietti", "authors": "Alberto Bietti and Julien Mairal", "title": "Group Invariance, Stability to Deformations, and Complexity of Deep\n  Convolutional Representations", "comments": null, "journal-ref": "Journal of Machine Learning Research 20 (2019) 1-49", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep convolutional architectures is often attributed in part\nto their ability to learn multiscale and invariant representations of natural\nsignals. However, a precise study of these properties and how they affect\nlearning guarantees is still missing. In this paper, we consider deep\nconvolutional representations of signals; we study their invariance to\ntranslations and to more general groups of transformations, their stability to\nthe action of diffeomorphisms, and their ability to preserve signal\ninformation. This analysis is carried by introducing a multilayer kernel based\non convolutional kernel networks and by studying the geometry induced by the\nkernel mapping. We then characterize the corresponding reproducing kernel\nHilbert space (RKHS), showing that it contains a large class of convolutional\nneural networks with homogeneous activation functions. This analysis allows us\nto separate data representation from learning, and to provide a canonical\nmeasure of model complexity, the RKHS norm, which controls both stability and\ngeneralization of any learned model. In addition to models in the constructed\nRKHS, our stability analysis also applies to convolutional networks with\ngeneric activations such as rectified linear units, and we discuss its\nrelationship with recent generalization bounds based on spectral norms.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 18:02:47 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 12:08:20 GMT"}, {"version": "v3", "created": "Sun, 8 Apr 2018 14:36:45 GMT"}, {"version": "v4", "created": "Wed, 10 Oct 2018 21:17:35 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Bietti", "Alberto", ""], ["Mairal", "Julien", ""]]}, {"id": "1706.03100", "submitter": "Philip Thomas", "authors": "Philip S. Thomas and Christoph Dann and Emma Brunskill", "title": "Decoupling Learning Rules from Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the artificial intelligence field, learning often corresponds to changing\nthe parameters of a parameterized function. A learning rule is an algorithm or\nmathematical expression that specifies precisely how the parameters should be\nchanged. When creating an artificial intelligence system, we must make two\ndecisions: what representation should be used (i.e., what parameterized\nfunction should be used) and what learning rule should be used to search\nthrough the resulting set of representable functions. Using most learning\nrules, these two decisions are coupled in a subtle (and often unintentional)\nway. That is, using the same learning rule with two different representations\nthat can represent the same sets of functions can result in two different\noutcomes. After arguing that this coupling is undesirable, particularly when\nusing artificial neural networks, we present a method for partially decoupling\nthese two decisions for a broad class of learning rules that span unsupervised\nlearning, reinforcement learning, and supervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 19:34:03 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Thomas", "Philip S.", ""], ["Dann", "Christoph", ""], ["Brunskill", "Emma", ""]]}, {"id": "1706.03149", "submitter": "Peter Bloem", "authors": "Peter Bloem and Steven de Rooij", "title": "An Expectation-Maximization Algorithm for the Fractal Inverse Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an Expectation-Maximization algorithm for the fractal inverse\nproblem: the problem of fitting a fractal model to data. In our setting the\nfractals are Iterated Function Systems (IFS), with similitudes as the family of\ntransformations. The data is a point cloud in ${\\mathbb R}^H$ with arbitrary\ndimension $H$. Each IFS defines a probability distribution on ${\\mathbb R}^H$,\nso that the fractal inverse problem can be cast as a problem of parameter\nestimation. We show that the algorithm reconstructs well-known fractals from\ndata, with the model converging to high precision parameters. We also show the\nutility of the model as an approximation for datasources outside the IFS model\nclass.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 22:50:32 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 14:05:00 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Bloem", "Peter", ""], ["de Rooij", "Steven", ""]]}, {"id": "1706.03175", "submitter": "Zhao Song", "authors": "Kai Zhong, Zhao Song, Prateek Jain, Peter L. Bartlett, Inderjit S.\n  Dhillon", "title": "Recovery Guarantees for One-hidden-layer Neural Networks", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider regression problems with one-hidden-layer neural\nnetworks (1NNs). We distill some properties of activation functions that lead\nto $\\mathit{local~strong~convexity}$ in the neighborhood of the ground-truth\nparameters for the 1NN squared-loss objective. Most popular nonlinear\nactivation functions satisfy the distilled properties, including rectified\nlinear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activation\nfunctions that are also smooth, we show $\\mathit{local~linear~convergence}$\nguarantees of gradient descent under a resampling rule. For homogeneous\nactivations, we show tensor methods are able to initialize the parameters to\nfall into the local strong convexity region. As a result, tensor initialization\nfollowed by gradient descent is guaranteed to recover the ground truth with\nsample complexity $ d \\cdot \\log(1/\\epsilon) \\cdot \\mathrm{poly}(k,\\lambda )$\nand computational complexity $n\\cdot d \\cdot \\mathrm{poly}(k,\\lambda) $ for\nsmooth homogeneous activations with high probability, where $d$ is the\ndimension of the input, $k$ ($k\\leq d$) is the number of hidden nodes,\n$\\lambda$ is a conditioning property of the ground-truth parameter matrix\nbetween the input layer and the hidden layer, $\\epsilon$ is the targeted\nprecision and $n$ is the number of samples. To the best of our knowledge, this\nis the first work that provides recovery guarantees for 1NNs with both sample\ncomplexity and computational complexity $\\mathit{linear}$ in the input\ndimension and $\\mathit{logarithmic}$ in the precision.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 02:56:39 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Zhong", "Kai", ""], ["Song", "Zhao", ""], ["Jain", "Prateek", ""], ["Bartlett", "Peter L.", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1706.03261", "submitter": "Andr\\'es Almansa", "authors": "Cecilia Aguerrebere, Andr\\'es Almansa, Julie Delon, Yann Gousseau,\n  Pablo Mus\\'e", "title": "A Bayesian Hyperprior Approach for Joint Image Denoising and\n  Interpolation, with an Application to HDR Imaging", "comments": "Some figures are reduced to comply with arxiv's size constraints.\n  Full size images are available as HAL technical report hal-01107519v5, IEEE\n  Transactions on Computational Imaging, 2017", "journal-ref": null, "doi": "10.1109/TCI.2017.2704439", "report-no": null, "categories": "cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, impressive denoising results have been achieved by Bayesian\napproaches which assume Gaussian models for the image patches. This improvement\nin performance can be attributed to the use of per-patch models. Unfortunately\nsuch an approach is particularly unstable for most inverse problems beyond\ndenoising. In this work, we propose the use of a hyperprior to model image\npatches, in order to stabilize the estimation procedure. There are two main\nadvantages to the proposed restoration scheme: Firstly it is adapted to\ndiagonal degradation matrices, and in particular to missing data problems (e.g.\ninpainting of missing pixels or zooming). Secondly it can deal with signal\ndependent noise models, particularly suited to digital cameras. As such, the\nscheme is especially adapted to computational photography. In order to\nillustrate this point, we provide an application to high dynamic range imaging\nfrom a single image taken with a modified sensor, which shows the effectiveness\nof the proposed scheme.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 17:37:01 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Aguerrebere", "Cecilia", ""], ["Almansa", "Andr\u00e9s", ""], ["Delon", "Julie", ""], ["Gousseau", "Yann", ""], ["Mus\u00e9", "Pablo", ""]]}, {"id": "1706.03265", "submitter": "Jonathan Landy", "authors": "Jonathan Landy", "title": "Stepwise regression for unsupervised learning", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I consider unsupervised extensions of the fast stepwise linear regression\nalgorithm \\cite{efroymson1960multiple}. These extensions allow one to\nefficiently identify highly-representative feature variable subsets within a\ngiven set of jointly distributed variables. This in turn allows for the\nefficient dimensional reduction of large data sets via the removal of redundant\nfeatures. Fast search is effected here through the avoidance of repeat\ncomputations across trial fits, allowing for a full representative-importance\nranking of a set of feature variables to be carried out in $O(n^2 m)$ time,\nwhere $n$ is the number of variables and $m$ is the number of data samples\navailable. This runtime complexity matches that needed to carry out a single\nregression and is $O(n^2)$ faster than that of naive implementations. I present\npseudocode suitable for efficient forward, reverse, and forward-reverse\nunsupervised feature selection. To illustrate the algorithm's application, I\napply it to the problem of identifying representative stocks within a given\nfinancial market index -- a challenge relevant to the design of Exchange Traded\nFunds (ETFs). I also characterize the growth of numerical error with iteration\nstep in these algorithms, and finally demonstrate and rationalize the\nobservation that the forward and reverse algorithms return exactly inverted\nfeature orderings in the weakly-correlated feature set regime.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 18:13:42 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Landy", "Jonathan", ""]]}, {"id": "1706.03267", "submitter": "Reshad Hosseini", "authors": "Reshad Hosseini, Suvrit Sra", "title": "An Alternative to EM for Gaussian Mixture Models: Batch and Stochastic\n  Riemannian Optimization", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider maximum likelihood estimation for Gaussian Mixture Models (Gmms).\nThis task is almost invariably solved (in theory and practice) via the\nExpectation Maximization (EM) algorithm. EM owes its success to various\nfactors, of which is its ability to fulfill positive definiteness constraints\nin closed form is of key importance. We propose an alternative to EM by\nappealing to the rich Riemannian geometry of positive definite matrices, using\nwhich we cast Gmm parameter estimation as a Riemannian optimization problem.\nSurprisingly, such an out-of-the-box Riemannian formulation completely fails\nand proves much inferior to EM. This motivates us to take a closer look at the\nproblem geometry, and derive a better formulation that is much more amenable to\nRiemannian optimization. We then develop (Riemannian) batch and stochastic\ngradient algorithms that outperform EM, often substantially. We provide a\nnon-asymptotic convergence analysis for our stochastic method, which is also\nthe first (to our knowledge) such global analysis for Riemannian stochastic\ngradient. Numerous empirical results are included to demonstrate the\neffectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 18:30:53 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Hosseini", "Reshad", ""], ["Sra", "Suvrit", ""]]}, {"id": "1706.03269", "submitter": "Aurelien Lucchi", "authors": "Paulina Grnarova and Kfir Y. Levy and Aurelien Lucchi and Thomas\n  Hofmann and Andreas Krause", "title": "An Online Learning Approach to Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training generative models with a Generative\nAdversarial Network (GAN). Although GANs can accurately model complex\ndistributions, they are known to be difficult to train due to instabilities\ncaused by a difficult minimax optimization problem. In this paper, we view the\nproblem of training GANs as finding a mixed strategy in a zero-sum game.\nBuilding on ideas from online learning we propose a novel training method named\nChekhov GAN 1 . On the theory side, we show that our method provably converges\nto an equilibrium for semi-shallow GAN architectures, i.e. architectures where\nthe discriminator is a one layer network and the generator is arbitrary. On the\npractical side, we develop an efficient heuristic guided by our theoretical\nresults, which we apply to commonly used deep GAN architectures. On several\nreal world tasks our approach exhibits improved stability and performance\ncompared to standard GAN training.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 18:49:07 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Grnarova", "Paulina", ""], ["Levy", "Kfir Y.", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""], ["Krause", "Andreas", ""]]}, {"id": "1706.03292", "submitter": "Hao Zhang", "authors": "Hao Zhang, Zeyu Zheng, Shizhen Xu, Wei Dai, Qirong Ho, Xiaodan Liang,\n  Zhiting Hu, Jinliang Wei, Pengtao Xie, Eric P. Xing", "title": "Poseidon: An Efficient Communication Architecture for Distributed Deep\n  Learning on GPU Clusters", "comments": "To appear in 2017 USENIX Annual Technical Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models can take weeks to train on a single GPU-equipped\nmachine, necessitating scaling out DL training to a GPU-cluster. However,\ncurrent distributed DL implementations can scale poorly due to substantial\nparameter synchronization over the network, because the high throughput of GPUs\nallows more data batches to be processed per unit time than CPUs, leading to\nmore frequent network synchronization. We present Poseidon, an efficient\ncommunication architecture for distributed DL on GPUs. Poseidon exploits the\nlayered model structures in DL programs to overlap communication and\ncomputation, reducing bursty network communication. Moreover, Poseidon uses a\nhybrid communication scheme that optimizes the number of bytes required to\nsynchronize each layer, according to layer properties and the number of\nmachines. We show that Poseidon is applicable to different DL frameworks by\nplugging Poseidon into Caffe and TensorFlow. We show that Poseidon enables\nCaffe and TensorFlow to achieve 15.5x speed-up on 16 single-GPU machines, even\nwith limited bandwidth (10GbE) and the challenging VGG19-22K network for image\nclassification. Moreover, Poseidon-enabled TensorFlow achieves 31.5x speed-up\nwith 32 single-GPU machines on Inception-V3, a 50% improvement over the\nopen-source TensorFlow (20x speed-up).\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 01:11:06 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Zhang", "Hao", ""], ["Zheng", "Zeyu", ""], ["Xu", "Shizhen", ""], ["Dai", "Wei", ""], ["Ho", "Qirong", ""], ["Liang", "Xiaodan", ""], ["Hu", "Zhiting", ""], ["Wei", "Jinliang", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1706.03301", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky", "title": "Neural networks and rational functions", "comments": "To appear, ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and rational functions efficiently approximate each other. In\nmore detail, it is shown here that for any ReLU network, there exists a\nrational function of degree $O(\\text{polylog}(1/\\epsilon))$ which is\n$\\epsilon$-close, and similarly for any rational function there exists a ReLU\nnetwork of size $O(\\text{polylog}(1/\\epsilon))$ which is $\\epsilon$-close. By\ncontrast, polynomials need degree $\\Omega(\\text{poly}(1/\\epsilon))$ to\napproximate even a single ReLU. When converting a ReLU network to a rational\nfunction as above, the hidden constants depend exponentially on the number of\nlayers, which is shown to be tight; in other words, a compositional\nrepresentation can be beneficial even for rational functions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 03:07:42 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Telgarsky", "Matus", ""]]}, {"id": "1706.03353", "submitter": "Greg Ver Steeg", "authors": "Greg Ver Steeg, Hrayr Harutyunyan, Daniel Moyer, Aram Galstyan", "title": "Fast structure learning with modular regularization", "comments": "22 pages, accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating graphical model structure from high-dimensional and undersampled\ndata is a fundamental problem in many scientific fields. Existing approaches,\nsuch as GLASSO, latent variable GLASSO, and latent tree models, suffer from\nhigh computational complexity and may impose unrealistic sparsity priors in\nsome cases. We introduce a novel method that leverages a newly discovered\nconnection between information-theoretic measures and structured latent factor\nmodels to derive an optimization objective which encourages modular structures\nwhere each observed variable has a single latent parent. The proposed method\nhas linear stepwise computational complexity w.r.t. the number of observed\nvariables. Our experiments on synthetic data demonstrate that our approach is\nthe only method that recovers modular structure better as the dimensionality\nincreases. We also use our approach for estimating covariance structure for a\nnumber of real-world datasets and show that it consistently outperforms\nstate-of-the-art estimators at a fraction of the computational cost. Finally,\nwe apply the proposed method to high-resolution fMRI data (with more than 10^5\nvoxels) and show that it is capable of extracting meaningful patterns.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 13:36:00 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 16:56:26 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 19:11:16 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Steeg", "Greg Ver", ""], ["Harutyunyan", "Hrayr", ""], ["Moyer", "Daniel", ""], ["Galstyan", "Aram", ""]]}, {"id": "1706.03358", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carri\\`ere and Marco Cuturi and Steve Oudot", "title": "Sliced Wasserstein Kernel for Persistence Diagrams", "comments": "Minor modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams (PDs) play a key role in topological data analysis\n(TDA), in which they are routinely used to describe topological properties of\ncomplicated shapes. PDs enjoy strong stability properties and have proven their\nutility in various learning contexts. They do not, however, live in a space\nnaturally endowed with a Hilbert structure and are usually compared with\nspecific distances, such as the bottleneck distance. To incorporate PDs in a\nlearning pipeline, several kernels have been proposed for PDs with a strong\nemphasis on the stability of the RKHS distance w.r.t. perturbations of the PDs.\nIn this article, we use the Sliced Wasserstein approximation SW of the\nWasserstein distance to define a new kernel for PDs, which is not only provably\nstable but also provably discriminative (depending on the number of points in\nthe PDs) w.r.t. the Wasserstein distance $d_1$ between PDs. We also demonstrate\nits practicality, by developing an approximation technique to reduce kernel\ncomputation time, and show that our proposal compares favorably to existing\nkernels for PDs on several benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 14:47:19 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 08:44:30 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 14:47:06 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Carri\u00e8re", "Mathieu", ""], ["Cuturi", "Marco", ""], ["Oudot", "Steve", ""]]}, {"id": "1706.03369", "submitter": "Francois-Xavier Briol", "authors": "Francois-Xavier Briol and Chris J. Oates and Jon Cockayne and Wilson\n  Ye Chen and Mark Girolami", "title": "On the Sampling Problem for Kernel Quadrature", "comments": "To appear at Thirty-fourth International Conference on Machine\n  Learning (ICML 2017)", "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, PMLR 70:586-595, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard Kernel Quadrature method for numerical integration with random\npoint sets (also called Bayesian Monte Carlo) is known to converge in root mean\nsquare error at a rate determined by the ratio $s/d$, where $s$ and $d$ encode\nthe smoothness and dimension of the integrand. However, an empirical\ninvestigation reveals that the rate constant $C$ is highly sensitive to the\ndistribution of the random points. In contrast to standard Monte Carlo\nintegration, for which optimal importance sampling is well-understood, the\nsampling distribution that minimises $C$ for Kernel Quadrature does not admit a\nclosed form. This paper argues that the practical choice of sampling\ndistribution is an important open problem. One solution is considered; a novel\nautomatic approach based on adaptive tempering and sequential Monte Carlo.\nEmpirical results demonstrate a dramatic reduction in integration error of up\nto 4 orders of magnitude can be achieved with the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 16:08:17 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Briol", "Francois-Xavier", ""], ["Oates", "Chris J.", ""], ["Cockayne", "Jon", ""], ["Chen", "Wilson Ye", ""], ["Girolami", "Mark", ""]]}, {"id": "1706.03373", "submitter": "Changzhe Jiao", "authors": "Changzhe Jiao, Bo-Yu Su, Princess Lyons, Alina Zare, K. C. Ho,\n  Marjorie Skubic", "title": "Multiple Instance Dictionary Learning for Beat-to-Beat Heart Rate\n  Monitoring from Ballistocardiograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multiple instance dictionary learning approach, Dictionary Learning using\nFunctions of Multiple Instances (DL-FUMI), is used to perform beat-to-beat\nheart rate estimation and to characterize heartbeat signatures from\nballistocardiogram (BCG) signals collected with a hydraulic bed sensor. DL-FUMI\nestimates a \"heartbeat concept\" that represents an individual's personal\nballistocardiogram heartbeat pattern. DL-FUMI formulates heartbeat detection\nand heartbeat characterization as a multiple instance learning problem to\naddress the uncertainty inherent in aligning BCG signals with ground truth\nduring training. Experimental results show that the estimated heartbeat concept\nfound by DL-FUMI is an effective heartbeat prototype and achieves superior\nperformance over comparison algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 16:21:08 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 01:39:54 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Jiao", "Changzhe", ""], ["Su", "Bo-Yu", ""], ["Lyons", "Princess", ""], ["Zare", "Alina", ""], ["Ho", "K. C.", ""], ["Skubic", "Marjorie", ""]]}, {"id": "1706.03412", "submitter": "Evgeny Burnaev", "authors": "Vladislav Ishimtsev, Ivan Nazarov, Alexander Bernstein and Evgeny\n  Burnaev", "title": "Conformal k-NN Anomaly Detector for Univariate Data Streams", "comments": "15 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies in time-series data give essential and often actionable information\nin many applications. In this paper we consider a model-free anomaly detection\nmethod for univariate time-series which adapts to non-stationarity in the data\nstream and provides probabilistic abnormality scores based on the conformal\nprediction paradigm. Despite its simplicity the method performs on par with\ncomplex prediction-based models on the Numenta Anomaly Detection benchmark and\nthe Yahoo! S5 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 21:45:24 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Ishimtsev", "Vladislav", ""], ["Nazarov", "Ivan", ""], ["Bernstein", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1706.03415", "submitter": "Evgeny Burnaev", "authors": "Denis Volkhonskiy, Ilia Nouretdinov, Alexander Gammerman, Vladimir\n  Vovk, Evgeny Burnaev", "title": "Inductive Conformal Martingales for Change-Point Detection", "comments": "22 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quickest change-point detection in data streams.\nClassical change-point detection procedures, such as CUSUM, Shiryaev-Roberts\nand Posterior Probability statistics, are optimal only if the change-point\nmodel is known, which is an unrealistic assumption in typical applied problems.\nInstead we propose a new method for change-point detection based on Inductive\nConformal Martingales, which requires only the independence and identical\ndistribution of observations. We compare the proposed approach to standard\nmethods, as well as to change-point detection oracles, which model a typical\npractical situation when we have only imprecise (albeit parametric) information\nabout pre- and post-change data distributions. Results of comparison provide\nevidence that change-point detection based on Inductive Conformal Martingales\nis an efficient tool, capable to work under quite general conditions unlike\ntraditional approaches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 21:49:19 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Volkhonskiy", "Denis", ""], ["Nouretdinov", "Ilia", ""], ["Gammerman", "Alexander", ""], ["Vovk", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1706.03446", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Patrick Tighe, Azra Bihorac, Parisa Rashidi", "title": "Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for\n  Electronic Health Record (EHR) Analysis", "comments": "Accepted for publication with Journal of Biomedical and Health\n  Informatics: http://ieeexplore.ieee.org/abstract/document/8086133/", "journal-ref": null, "doi": "10.1109/JBHI.2017.2767063", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen an explosion in the amount of digital information\nstored in electronic health records (EHR). While primarily designed for\narchiving patient clinical information and administrative healthcare tasks,\nmany researchers have found secondary use of these records for various clinical\ninformatics tasks. Over the same period, the machine learning community has\nseen widespread advances in deep learning techniques, which also have been\nsuccessfully applied to the vast amount of EHR data. In this paper, we review\nthese deep EHR systems, examining architectures, technical aspects, and\nclinical applications. We also identify shortcomings of current techniques and\ndiscuss avenues of future research for EHR-based deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 03:03:15 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 01:41:18 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Shickel", "Benjamin", ""], ["Tighe", "Patrick", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1706.03471", "submitter": "Jian Zhang", "authors": "Jian Zhang, Ioannis Mitliagkas", "title": "YellowFin and the Art of Momentum Tuning", "comments": "Updated to reflect improved stability discussion and work for SysML\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning is one of the most time-consuming workloads in deep\nlearning. State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam,\nreduce this labor by adaptively tuning an individual learning rate for each\nvariable. Recently researchers have shown renewed interest in simpler methods\nlike momentum SGD as they may yield better test metrics. Motivated by this\ntrend, we ask: can simple adaptive methods based on SGD perform as well or\nbetter? We revisit the momentum SGD algorithm and show that hand-tuning a\nsingle learning rate and momentum makes it competitive with Adam. We then\nanalyze its robustness to learning rate misspecification and objective\ncurvature variation. Based on these insights, we design YellowFin, an automatic\ntuner for momentum and learning rate in SGD. YellowFin optionally uses a\nnegative-feedback loop to compensate for the momentum dynamics in asynchronous\nsettings on the fly. We empirically show that YellowFin can converge in fewer\niterations than Adam on ResNets and LSTMs for image recognition, language\nmodeling and constituency parsing, with a speedup of up to 3.28x in synchronous\nand up to 2.69x in asynchronous settings.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 05:43:56 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 20:46:23 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Zhang", "Jian", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1706.03472", "submitter": "Genki Kusano", "authors": "Genki Kusano, Kenji Fukumizu, Yasuaki Hiraoka", "title": "Kernel method for persistence diagrams via kernel embedding and weight\n  factor", "comments": "12 figures, 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.AT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis is an emerging mathematical concept for\ncharacterizing shapes in multi-scale data. In this field, persistence diagrams\nare widely used as a descriptor of the input data, and can distinguish robust\nand noisy topological properties. Nowadays, it is highly desired to develop a\nstatistical framework on persistence diagrams to deal with practical data. This\npaper proposes a kernel method on persistence diagrams. A theoretical\ncontribution of our method is that the proposed kernel allows one to control\nthe effect of persistence, and, if necessary, noisy topological properties can\nbe discounted in data analysis. Furthermore, the method provides a fast\napproximation technique. The method is applied into several problems including\npractical data in physics, and the results show the advantage compared to the\nexisting kernel method on persistence diagrams.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 05:44:09 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Kusano", "Genki", ""], ["Fukumizu", "Kenji", ""], ["Hiraoka", "Yasuaki", ""]]}, {"id": "1706.03475", "submitter": "Kimin Lee", "authors": "Kimin Lee, Changho Hwang, KyoungSoo Park, Jinwoo Shin", "title": "Confident Multiple Choice Learning", "comments": "Accepted in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods are arguably the most trustworthy techniques for boosting\nthe performance of machine learning models. Popular independent ensembles (IE)\nrelying on naive averaging/voting scheme have been of typical choice for most\napplications involving deep neural networks, but they do not consider advanced\ncollaboration among ensemble models. In this paper, we propose new ensemble\nmethods specialized for deep neural networks, called confident multiple choice\nlearning (CMCL): it is a variant of multiple choice learning (MCL) via\naddressing its overconfidence issue.In particular, the proposed major\ncomponents of CMCL beyond the original MCL scheme are (i) new loss, i.e.,\nconfident oracle loss, (ii) new architecture, i.e., feature sharing and (iii)\nnew training method, i.e., stochastic labeling. We demonstrate the effect of\nCMCL via experiments on the image classification on CIFAR and SVHN, and the\nforeground-background segmentation on the iCoseg. In particular, CMCL using 5\nresidual networks provides 14.05% and 6.60% relative reductions in the top-1\nerror rates from the corresponding IE scheme for the classification task on\nCIFAR and SVHN, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 05:55:38 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 05:56:57 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Lee", "Kimin", ""], ["Hwang", "Changho", ""], ["Park", "KyoungSoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1706.03492", "submitter": "Timothy Au", "authors": "Timothy C. Au", "title": "Random Forests, Decision Trees, and Categorical Predictors: The \"Absent\n  Levels\" Problem", "comments": "Updated to the published version that appears at\n  http://www.jmlr.org/papers/volume19/16-474/16-474.pdf", "journal-ref": "Journal of Machine Learning Research 19(45):1-30, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One advantage of decision tree based methods like random forests is their\nability to natively handle categorical predictors without having to first\ntransform them (e.g., by using feature engineering techniques). However, in\nthis paper, we show how this capability can lead to an inherent \"absent levels\"\nproblem for decision tree based methods that has never been thoroughly\ndiscussed, and whose consequences have never been carefully explored. This\nproblem occurs whenever there is an indeterminacy over how to handle an\nobservation that has reached a categorical split which was determined when the\nobservation in question's level was absent during training. Although these\nincidents may appear to be innocuous, by using Leo Breiman and Adele Cutler's\nrandom forests FORTRAN code and the randomForest R package (Liaw and Wiener,\n2002) as motivating case studies, we examine how overlooking the absent levels\nproblem can systematically bias a model. Furthermore, by using three real data\nexamples, we illustrate how absent levels can dramatically alter a model's\nperformance in practice, and we empirically demonstrate how some simple\nheuristics can be used to help mitigate the effects of the absent levels\nproblem until a more robust theoretical solution is found.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 07:34:49 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 17:44:59 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Au", "Timothy C.", ""]]}, {"id": "1706.03533", "submitter": "Steven Van Vaerenbergh", "authors": "Steven Van Vaerenbergh, Simone Scardapane, Ignacio Santamaria", "title": "Recursive Multikernel Filters Exploiting Nonlinear Temporal Structure", "comments": "Eusipco 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In kernel methods, temporal information on the data is commonly included by\nusing time-delayed embeddings as inputs. Recently, an alternative formulation\nwas proposed by defining a gamma-filter explicitly in a reproducing kernel\nHilbert space, giving rise to a complex model where multiple kernels operate on\ndifferent temporal combinations of the input signal. In the original\nformulation, the kernels are then simply combined to obtain a single kernel\nmatrix (for instance by averaging), which provides computational benefits but\ndiscards important information on the temporal structure of the signal.\nInspired by works on multiple kernel learning, we overcome this drawback by\nconsidering the different kernels separately. We propose an efficient strategy\nto adaptively combine and select these kernels during the training phase. The\nresulting batch and online algorithms automatically learn to process highly\nnonlinear temporal information extracted from the input signal, which is\nimplicitly encoded in the kernel values. We evaluate our proposal on several\nartificial and real tasks, showing that it can outperform classical approaches\nboth in batch and online settings.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 09:24:42 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Van Vaerenbergh", "Steven", ""], ["Scardapane", "Simone", ""], ["Santamaria", "Ignacio", ""]]}, {"id": "1706.03591", "submitter": "Lionel Martin", "authors": "Lionel Martin, Andreas Loukas and Pierre Vandergheynst", "title": "Fast Approximate Spectral Clustering for Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a widely studied problem, yet its complexity is\nprohibitive for dynamic graphs of even modest size. We claim that it is\npossible to reuse information of past cluster assignments to expedite\ncomputation. Our approach builds on a recent idea of sidestepping the main\nbottleneck of spectral clustering, i.e., computing the graph eigenvectors, by\nusing fast Chebyshev graph filtering of random signals. We show that the\nproposed algorithm achieves clustering assignments with quality approximating\nthat of spectral clustering and that it can yield significant complexity\nbenefits when the graph dynamics are appropriately bounded.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 12:12:58 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Martin", "Lionel", ""], ["Loukas", "Andreas", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1706.03649", "submitter": "Umut \\c{S}im\\c{s}ekli", "authors": "Umut \\c{S}im\\c{s}ekli", "title": "Fractional Langevin Monte Carlo: Exploring L\\'{e}vy Driven Stochastic\n  Differential Equations for Markov Chain Monte Carlo", "comments": "Published in the International Conference on Machine Learning (ICML\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the recent advances in scalable Markov Chain Monte Carlo methods,\nsampling techniques that are based on Langevin diffusions have started\nreceiving increasing attention. These so called Langevin Monte Carlo (LMC)\nmethods are based on diffusions driven by a Brownian motion, which gives rise\nto Gaussian proposal distributions in the resulting algorithms. Even though\nthese approaches have proven successful in many applications, their performance\ncan be limited by the light-tailed nature of the Gaussian proposals. In this\nstudy, we extend classical LMC and develop a novel Fractional LMC (FLMC)\nframework that is based on a family of heavy-tailed distributions, called\n$\\alpha$-stable L\\'{e}vy distributions. As opposed to classical approaches, the\nproposed approach can possess large jumps while targeting the correct\ndistribution, which would be beneficial for efficient exploration of the state\nspace. We develop novel computational methods that can scale up to large-scale\nproblems and we provide formal convergence analysis of the proposed scheme. Our\nexperiments support our theory: FLMC can provide superior performance in\nmulti-modal settings, improved convergence rates, and robustness to algorithm\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 14:07:00 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["\u015eim\u015fekli", "Umut", ""]]}, {"id": "1706.03662", "submitter": "Aleksandar Botev", "authors": "Aleksandar Botev, Hippolyt Ritter, David Barber", "title": "Practical Gauss-Newton Optimisation for Deep Learning", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient block-diagonal ap- proximation to the Gauss-Newton\nmatrix for feedforward neural networks. Our result- ing algorithm is\ncompetitive against state- of-the-art first order optimisation methods, with\nsometimes significant improvement in optimisation performance. Unlike\nfirst-order methods, for which hyperparameter tuning of the optimisation\nparameters is often a labo- rious process, our approach can provide good\nperformance even when used with default set- tings. A side result of our work\nis that for piecewise linear transfer functions, the net- work objective\nfunction can have no differ- entiable local maxima, which may partially explain\nwhy such transfer functions facilitate effective optimisation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 14:39:48 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 17:56:09 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Botev", "Aleksandar", ""], ["Ritter", "Hippolyt", ""], ["Barber", "David", ""]]}, {"id": "1706.03673", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an, Daniel Hern\\'andez-Lobato", "title": "Dealing with Integer-valued Variables in Bayesian Optimization with\n  Gaussian Processes", "comments": "7 pages", "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.004", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) methods are useful for optimizing functions that\nare expensive to evaluate, lack an analytical expression and whose evaluations\ncan be contaminated by noise. These methods rely on a probabilistic model of\nthe objective function, typically a Gaussian process (GP), upon which an\nacquisition function is built. This function guides the optimization process\nand measures the expected utility of performing an evaluation of the objective\nat a new point. GPs assume continous input variables. When this is not the\ncase, such as when some of the input variables take integer values, one has to\nintroduce extra approximations. A common approach is to round the suggested\nvariable value to the closest integer before doing the evaluation of the\nobjective. We show that this can lead to problems in the optimization process\nand describe a more principled approach to account for input variables that are\ninteger-valued. We illustrate in both synthetic and a real experiments the\nutility of our approach, which significantly improves the results of standard\nBO methods on problems involving integer-valued variables.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 14:52:41 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 08:51:22 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "1706.03692", "submitter": "Vahid Noroozi", "authors": "Vahid Noroozi, Lei Zheng, Sara Bahaadini, Sihong Xie, Philip S. Yu", "title": "SEVEN: Deep Semi-supervised Verification Networks", "comments": "7 pages, 2 figures, accepted to the 2017 International Joint\n  Conference on Artificial Intelligence (IJCAI-17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification determines whether two samples belong to the same class or not,\nand has important applications such as face and fingerprint verification, where\nthousands or millions of categories are present but each category has scarce\nlabeled examples, presenting two major challenges for existing deep learning\nmodels. We propose a deep semi-supervised model named SEmi-supervised\nVErification Network (SEVEN) to address these challenges. The model consists of\ntwo complementary components. The generative component addresses the lack of\nsupervision within each category by learning general salient structures from a\nlarge amount of data across categories. The discriminative component exploits\nthe learned general features to mitigate the lack of supervision within\ncategories, and also directs the generative component to find more informative\nstructures of the whole data manifold. The two components are tied together in\nSEVEN to allow an end-to-end training of the two components. Extensive\nexperiments on four verification tasks demonstrate that SEVEN significantly\noutperforms other state-of-the-art deep semi-supervised techniques when labeled\ndata are in short supply. Furthermore, SEVEN is competitive with fully\nsupervised baselines trained with a larger amount of labeled data. It indicates\nthe importance of the generative component in SEVEN.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 15:39:51 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 23:40:59 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Noroozi", "Vahid", ""], ["Zheng", "Lei", ""], ["Bahaadini", "Sara", ""], ["Xie", "Sihong", ""], ["Yu", "Philip S.", ""]]}, {"id": "1706.03741", "submitter": "Paul Christiano", "authors": "Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg,\n  Dario Amodei", "title": "Deep reinforcement learning from human preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sophisticated reinforcement learning (RL) systems to interact usefully\nwith real-world environments, we need to communicate complex goals to these\nsystems. In this work, we explore goals defined in terms of (non-expert) human\npreferences between pairs of trajectory segments. We show that this approach\ncan effectively solve complex RL tasks without access to the reward function,\nincluding Atari games and simulated robot locomotion, while providing feedback\non less than one percent of our agent's interactions with the environment. This\nreduces the cost of human oversight far enough that it can be practically\napplied to state-of-the-art RL systems. To demonstrate the flexibility of our\napproach, we show that we can successfully train complex novel behaviors with\nabout an hour of human time. These behaviors and environments are considerably\nmore complex than any that have been previously learned from human feedback.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 17:23:59 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 20:25:56 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 20:18:41 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Christiano", "Paul", ""], ["Leike", "Jan", ""], ["Brown", "Tom B.", ""], ["Martic", "Miljan", ""], ["Legg", "Shane", ""], ["Amodei", "Dario", ""]]}, {"id": "1706.03768", "submitter": "Kun Zhang", "authors": "Kun Zhang, Mingming Gong, Joseph Ramsey, Kayhan Batmanghelich, Peter\n  Spirtes, Clark Glymour", "title": "Causal Discovery in the Presence of Measurement Error: Identifiability\n  Conditions", "comments": "15 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Measurement error in the observed values of the variables can greatly change\nthe output of various causal discovery methods. This problem has received much\nattention in multiple fields, but it is not clear to what extent the causal\nmodel for the measurement-error-free variables can be identified in the\npresence of measurement error with unknown variance. In this paper, we study\nprecise sufficient identifiability conditions for the measurement-error-free\ncausal model and show what information of the causal model can be recovered\nfrom observed data. In particular, we present two different sets of\nidentifiability conditions, based on the second-order statistics and\nhigher-order statistics of the data, respectively. The former was inspired by\nthe relationship between the generating model of the\nmeasurement-error-contaminated data and the factor analysis model, and the\nlatter makes use of the identifiability result of the over-complete independent\ncomponent analysis problem.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 17:22:26 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Zhang", "Kun", ""], ["Gong", "Mingming", ""], ["Ramsey", "Joseph", ""], ["Batmanghelich", "Kayhan", ""], ["Spirtes", "Peter", ""], ["Glymour", "Clark", ""]]}, {"id": "1706.03779", "submitter": "Isabel Valera", "authors": "Isabel Valera, Melanie F. Pradier, Maria Lomeli and Zoubin Ghahramani", "title": "General Latent Feature Models for Heterogeneous Datasets", "comments": "Software library available at https://github.com/ivaleraM/GLFM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent feature modeling allows capturing the latent structure responsible for\ngenerating the observed properties of a set of objects. It is often used to\nmake predictions either for new values of interest or missing information in\nthe original data, as well as to perform data exploratory analysis. However,\nalthough there is an extensive literature on latent feature models for\nhomogeneous datasets, where all the attributes that describe each object are of\nthe same (continuous or discrete) nature, there is a lack of work on latent\nfeature modeling for heterogeneous databases. In this paper, we introduce a\ngeneral Bayesian nonparametric latent feature model suitable for heterogeneous\ndatasets, where the attributes describing each object can be either discrete,\ncontinuous or mixed variables. The proposed model presents several important\nproperties. First, it accounts for heterogeneous data while keeping the\nproperties of conjugate models, which allow us to infer the model in linear\ntime with respect to the number of objects and attributes. Second, its Bayesian\nnonparametric nature allows us to automatically infer the model complexity from\nthe data, i.e., the number of features necessary to capture the latent\nstructure in the data. Third, the latent features in the model are\nbinary-valued variables, easing the interpretability of the obtained latent\nfeatures in data exploratory analysis. We show the flexibility of the proposed\nmodel by solving both prediction and data analysis tasks on several real-world\ndatasets. Moreover, a software package of the GLFM is publicly available for\nother researcher to use and improve it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 18:00:03 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 06:40:37 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Valera", "Isabel", ""], ["Pradier", "Melanie F.", ""], ["Lomeli", "Maria", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1706.03825", "submitter": "Daniel Smilkov", "authors": "Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi\\'egas, Martin\n  Wattenberg", "title": "SmoothGrad: removing noise by adding noise", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the output of a deep network remains a challenge. In the case of\nan image classifier, one type of explanation is to identify pixels that\nstrongly influence the final decision. A starting point for this strategy is\nthe gradient of the class score function with respect to the input image. This\ngradient can be interpreted as a sensitivity map, and there are several\ntechniques that elaborate on this basic idea. This paper makes two\ncontributions: it introduces SmoothGrad, a simple method that can help visually\nsharpen gradient-based sensitivity maps, and it discusses lessons in the\nvisualization of these maps. We publish the code for our experiments and a\nwebsite with our results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 19:53:30 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Smilkov", "Daniel", ""], ["Thorat", "Nikhil", ""], ["Kim", "Been", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""]]}, {"id": "1706.03850", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Zhe Gan, Kai Fan, Zhi Chen, Ricardo Henao, Dinghan Shen,\n  Lawrence Carin", "title": "Adversarial Feature Matching for Text Generation", "comments": "Accepted by ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generative Adversarial Network (GAN) has achieved great success in\ngenerating realistic (real-valued) synthetic data. However, convergence issues\nand difficulties dealing with discrete data hinder the applicability of GAN to\ntext. We propose a framework for generating realistic text via adversarial\ntraining. We employ a long short-term memory network as generator, and a\nconvolutional network as discriminator. Instead of using the standard objective\nof GAN, we propose matching the high-dimensional latent feature distributions\nof real and synthetic sentences, via a kernelized discrepancy metric. This\neases adversarial training by alleviating the mode-collapsing problem. Our\nexperiments show superior performance in quantitative evaluation, and\ndemonstrate that our model can generate realistic-looking sentences.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 20:55:51 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 05:50:13 GMT"}, {"version": "v3", "created": "Sat, 18 Nov 2017 18:40:04 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Zhang", "Yizhe", ""], ["Gan", "Zhe", ""], ["Fan", "Kai", ""], ["Chen", "Zhi", ""], ["Henao", "Ricardo", ""], ["Shen", "Dinghan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1706.03860", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani and George Atia", "title": "Subspace Clustering via Optimal Direction Search", "comments": null, "journal-ref": "IEEE Signal Processing Letters ( Volume: 24, Issue: 12, Dec. 2017\n  )", "doi": "10.1109/LSP.2017.2757901", "report-no": null, "categories": "cs.CV cs.IR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter presents a new spectral-clustering-based approach to the subspace\nclustering problem. Underpinning the proposed method is a convex program for\noptimal direction search, which for each data point d finds an optimal\ndirection in the span of the data that has minimum projection on the other data\npoints and non-vanishing projection on d. The obtained directions are\nsubsequently leveraged to identify a neighborhood set for each data point. An\nalternating direction method of multipliers framework is provided to\nefficiently solve for the optimal directions. The proposed method is shown to\nnotably outperform the existing subspace clustering methods, particularly for\nunwieldy scenarios involving high levels of noise and close subspaces, and\nyields the state-of-the-art results for the problem of face clustering using\nsubspace segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 21:52:57 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 22:56:21 GMT"}, {"version": "v3", "created": "Sun, 23 Jul 2017 20:36:57 GMT"}, {"version": "v4", "created": "Sun, 26 Nov 2017 15:43:15 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Atia", "George", ""]]}, {"id": "1706.03883", "submitter": "Nhat Ho", "authors": "Nhat Ho, XuanLong Nguyen, Mikhail Yurochkin, Hung Hai Bui, Viet Huynh,\n  Dinh Phung", "title": "Multilevel Clustering via Wasserstein Means", "comments": "Proceedings of the ICML, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to the problem of multilevel clustering, which\naims to simultaneously partition data in each group and discover grouping\npatterns among groups in a potentially large hierarchically structured corpus\nof data. Our method involves a joint optimization formulation over several\nspaces of discrete probability measures, which are endowed with Wasserstein\ndistance metrics. We propose a number of variants of this problem, which admit\nfast optimization algorithms, by exploiting the connection to the problem of\nfinding Wasserstein barycenters. Consistency properties are established for the\nestimates of both local and global clusters. Finally, experiment results with\nboth synthetic and real data are presented to demonstrate the flexibility and\nscalability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 01:15:04 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Ho", "Nhat", ""], ["Nguyen", "XuanLong", ""], ["Yurochkin", "Mikhail", ""], ["Bui", "Hung Hai", ""], ["Huynh", "Viet", ""], ["Phung", "Dinh", ""]]}, {"id": "1706.03896", "submitter": "Tyler Maunu", "authors": "Tyler Maunu, Teng Zhang, Gilad Lerman", "title": "A Well-Tempered Landscape for Non-convex Robust Subspace Recovery", "comments": "58 pages, 6 figures, 1 table", "journal-ref": "Journal of Machine Learning Research, 20(37):1-59, 2019", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mathematical analysis of a non-convex energy landscape for\nrobust subspace recovery. We prove that an underlying subspace is the only\nstationary point and local minimizer in a specified neighborhood under a\ndeterministic condition on a dataset. If the deterministic condition is\nsatisfied, we further show that a geodesic gradient descent method over the\nGrassmannian manifold can exactly recover the underlying subspace when the\nmethod is properly initialized. Proper initialization by principal component\nanalysis is guaranteed with a simple deterministic condition. Under slightly\nstronger assumptions, the gradient descent method with a piecewise constant\nstep-size scheme achieves linear convergence. The practicality of the\ndeterministic condition is demonstrated on some statistical models of data, and\nthe method achieves almost state-of-the-art recovery guarantees on the Haystack\nModel for different regimes of sample size and ambient dimension. In\nparticular, when the ambient dimension is fixed and the sample size is large\nenough, we show that our gradient method can exactly recover the underlying\nsubspace for any fixed fraction of outliers (less than 1).\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 03:04:58 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 13:24:48 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 20:00:44 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Maunu", "Tyler", ""], ["Zhang", "Teng", ""], ["Lerman", "Gilad", ""]]}, {"id": "1706.03922", "submitter": "Yizhen Wang", "authors": "Yizhen Wang, Somesh Jha, Kamalika Chaudhuri", "title": "Analyzing the Robustness of Nearest Neighbors to Adversarial Examples", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML) 2018, Page\n  5133--5142", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by safety-critical applications, test-time attacks on classifiers\nvia adversarial examples has recently received a great deal of attention.\nHowever, there is a general lack of understanding on why adversarial examples\narise; whether they originate due to inherent properties of data or due to lack\nof training samples remains ill-understood. In this work, we introduce a\ntheoretical framework analogous to bias-variance theory for understanding these\neffects.\n  We use our framework to analyze the robustness of a canonical non-parametric\nclassifier - the k-nearest neighbors. Our analysis shows that its robustness\nproperties depend critically on the value of k - the classifier may be\ninherently non-robust for small k, but its robustness approaches that of the\nBayes Optimal classifier for fast-growing k. We propose a novel modified\n1-nearest neighbor classifier, and guarantee its robustness in the large sample\nlimit. Our experiments suggest that this classifier may have good robustness\nproperties even for reasonable data set sizes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 06:47:50 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 23:14:43 GMT"}, {"version": "v3", "created": "Sun, 11 Mar 2018 04:35:04 GMT"}, {"version": "v4", "created": "Wed, 13 Jun 2018 05:08:22 GMT"}, {"version": "v5", "created": "Sun, 15 Jul 2018 05:53:06 GMT"}, {"version": "v6", "created": "Wed, 19 Jun 2019 03:55:10 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wang", "Yizhen", ""], ["Jha", "Somesh", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1706.03946", "submitter": "Isabelle Augenstein", "authors": "Ed Collins and Isabelle Augenstein and Sebastian Riedel", "title": "A Supervised Approach to Extractive Summarisation of Scientific Papers", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarisation is a popular approach to reduce a document to its\nmain arguments. Recent research in the area has focused on neural approaches to\nsummarisation, which can be very data-hungry. However, few large datasets exist\nand none for the traditionally popular domain of scientific publications, which\nopens up challenging research avenues centered on encoding large, complex\ndocuments. In this paper, we introduce a new dataset for summarisation of\ncomputer science publications by exploiting a large resource of author provided\nsummaries and show straightforward ways of extending it further. We develop\nmodels on the dataset making use of both neural sentence encoding and\ntraditionally used summarisation features and show that models which encode\nsentences as well as their local and global context perform best, significantly\noutperforming well-established baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 08:15:25 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Collins", "Ed", ""], ["Augenstein", "Isabelle", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1706.04026", "submitter": "Panayiotis Christodoulou", "authors": "Sotirios Chatzis, Panayiotis Christodoulou, Andreas S. Andreou", "title": "Recurrent Latent Variable Networks for Session-Based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we attempt to ameliorate the impact of data sparsity in the\ncontext of session-based recommendation. Specifically, we seek to devise a\nmachine learning mechanism capable of extracting subtle and complex underlying\ntemporal dynamics in the observed session data, so as to inform the\nrecommendation algorithm. To this end, we improve upon systems that utilize\ndeep learning techniques with recurrently connected units; we do so by adopting\nconcepts from the field of Bayesian statistics, namely variational inference.\nOur proposed approach consists in treating the network recurrent units as\nstochastic latent variables with a prior distribution imposed over them. On\nthis basis, we proceed to infer corresponding posteriors; these can be used for\nprediction and recommendation generation, in a way that accounts for the\nuncertainty in the available sparse training data. To allow for our approach to\neasily scale to large real-world datasets, we perform inference under an\napproximate amortized variational inference (AVI) setup, whereby the learned\nposteriors are parameterized via (conventional) neural networks. We perform an\nextensive experimental evaluation of our approach using challenging benchmark\ndatasets, and illustrate its superiority over existing state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 12:35:56 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Chatzis", "Sotirios", ""], ["Christodoulou", "Panayiotis", ""], ["Andreou", "Andreas S.", ""]]}, {"id": "1706.04038", "submitter": "Ahmad Al Sallab Dr", "authors": "Ahmad El Sallab, Mahmoud Saeed, Omar Abdel Tawab, Mohammed Abdou", "title": "Meta learning Framework for Automated Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The success of automated driving deployment is highly depending on the\nability to develop an efficient and safe driving policy. The problem is well\nformulated under the framework of optimal control as a cost optimization\nproblem. Model based solutions using traditional planning are efficient, but\nrequire the knowledge of the environment model. On the other hand, model free\nsolutions suffer sample inefficiency and require too many interactions with the\nenvironment, which is infeasible in practice. Methods under the Reinforcement\nLearning framework usually require the notion of a reward function, which is\nnot available in the real world. Imitation learning helps in improving sample\nefficiency by introducing prior knowledge obtained from the demonstrated\nbehavior, on the risk of exact behavior cloning without generalizing to unseen\nenvironments. In this paper we propose a Meta learning framework, based on data\nset aggregation, to improve generalization of imitation learning algorithms.\nUnder the proposed framework, we propose MetaDAgger, a novel algorithm which\ntackles the generalization issues in traditional imitation learning. We use The\nOpen Race Car Simulator (TORCS) to test our algorithm. Results on unseen test\ntracks show significant improvement over traditional imitation learning\nalgorithms, improving the learning time and sample efficiency in the same time.\nThe results are also supported by visualization of the learnt features to prove\ngeneralization of the captured details.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 12:32:30 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Sallab", "Ahmad El", ""], ["Saeed", "Mahmoud", ""], ["Tawab", "Omar Abdel", ""], ["Abdou", "Mohammed", ""]]}, {"id": "1706.04074", "submitter": "Jian Du", "authors": "Jian Du, Shaodan Ma, Yik-Chung Wu, Soummya Kar and Jos\\'e M. F. Moura", "title": "Convergence analysis of belief propagation for pairwise linear Gaussian\n  models", "comments": "published in GlobalSIP 2017, Montreal, Canada. arXiv admin note: text\n  overlap with arXiv:1704.03969", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian belief propagation (BP) has been widely used for distributed\ninference in large-scale networks such as the smart grid, sensor networks, and\nsocial networks, where local measurements/observations are scattered over a\nwide geographical area. One particular case is when two neighboring agents\nshare a common observation. For example, to estimate voltage in the direct\ncurrent (DC) power flow model, the current measurement over a power line is\nproportional to the voltage difference between two neighboring buses. When\napplying the Gaussian BP algorithm to this type of problem, the convergence\ncondition remains an open issue. In this paper, we analyze the convergence\nproperties of Gaussian BP for this pairwise linear Gaussian model. We show\nanalytically that the updating information matrix converges at a geometric rate\nto a unique positive definite matrix with arbitrary positive semidefinite\ninitial value and further provide the necessary and sufficient convergence\ncondition for the belief mean vector to the optimal estimate.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 01:22:57 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 02:27:57 GMT"}, {"version": "v3", "created": "Sun, 3 Sep 2017 03:21:02 GMT"}, {"version": "v4", "created": "Sat, 18 Nov 2017 03:27:52 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Du", "Jian", ""], ["Ma", "Shaodan", ""], ["Wu", "Yik-Chung", ""], ["Kar", "Soummya", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1706.04097", "submitter": "Yingyu Liang", "authors": "Yuanzhi Li, Yingyu Liang", "title": "Provable Alternating Gradient Descent for Non-negative Matrix\n  Factorization with Strong Correlations", "comments": "Accepted to the International Conference on Machine Learning (ICML),\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization is a basic tool for decomposing data into\nthe feature and weight matrices under non-negativity constraints, and in\npractice is often solved in the alternating minimization framework. However, it\nis unclear whether such algorithms can recover the ground-truth feature matrix\nwhen the weights for different features are highly correlated, which is common\nin applications. This paper proposes a simple and natural alternating gradient\ndescent based algorithm, and shows that with a mild initialization it provably\nrecovers the ground-truth in the presence of strong correlations. In most\ninteresting cases, the correlation can be in the same order as the highest\npossible. Our analysis also reveals its several favorable features including\nrobustness to noise. We complement our theoretical results with empirical\nstudies on semi-synthetic datasets, demonstrating its advantage over several\npopular methods in recovering the ground-truth.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 14:39:59 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Li", "Yuanzhi", ""], ["Liang", "Yingyu", ""]]}, {"id": "1706.04152", "submitter": "Joseph Futoma", "authors": "Joseph Futoma, Sanjay Hariharan, Katherine Heller", "title": "Learning to Detect Sepsis with a Multitask Gaussian Process RNN\n  Classifier", "comments": "Presented at 34th International Conference on Machine Learning (ICML\n  2017), Sydney, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable end-to-end classifier that uses streaming physiological\nand medication data to accurately predict the onset of sepsis, a\nlife-threatening complication from infections that has high mortality and\nmorbidity. Our proposed framework models the multivariate trajectories of\ncontinuous-valued physiological time series using multitask Gaussian processes,\nseamlessly accounting for the high uncertainty, frequent missingness, and\nirregular sampling rates typically associated with real clinical data. The\nGaussian process is directly connected to a black-box classifier that predicts\nwhether a patient will become septic, chosen in our case to be a recurrent\nneural network to account for the extreme variability in the length of patient\nencounters. We show how to scale the computations associated with the Gaussian\nprocess in a manner so that the entire system can be discriminatively trained\nend-to-end using backpropagation. In a large cohort of heterogeneous inpatient\nencounters at our university health system we find that it outperforms several\nbaselines at predicting sepsis, and yields 19.4% and 55.5% improved areas under\nthe Receiver Operating Characteristic and Precision Recall curves as compared\nto the NEWS score currently used by our hospital.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 16:42:01 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Futoma", "Joseph", ""], ["Hariharan", "Sanjay", ""], ["Heller", "Katherine", ""]]}, {"id": "1706.04156", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, J. Zico Kolter", "title": "Gradient descent GAN optimization is locally stable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing prominence of generative adversarial networks (GANs),\noptimization in GANs is still a poorly understood topic. In this paper, we\nanalyze the \"gradient descent\" form of GAN optimization i.e., the natural\nsetting where we simultaneously take small gradient steps in both generator and\ndiscriminator parameters. We show that even though GAN optimization does not\ncorrespond to a convex-concave game (even for simple parameterizations), under\nproper conditions, equilibrium points of this optimization procedure are still\n\\emph{locally asymptotically stable} for the traditional GAN formulation. On\nthe other hand, we show that the recently proposed Wasserstein GAN can have\nnon-convergent limit cycles near equilibrium. Motivated by this stability\nanalysis, we propose an additional regularization term for gradient descent GAN\nupdates, which \\emph{is} able to guarantee local stability for both the WGAN\nand the traditional GAN, and also shows practical promise in speeding up\nconvergence and addressing mode collapse.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 16:49:13 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 03:29:12 GMT"}, {"version": "v3", "created": "Sat, 13 Jan 2018 18:39:22 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1706.04161", "submitter": "Matej Balog", "authors": "Matej Balog, Nilesh Tripuraneni, Zoubin Ghahramani, Adrian Weller", "title": "Lost Relatives of the Gumbel Trick", "comments": "34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gumbel trick is a method to sample from a discrete probability\ndistribution, or to estimate its normalizing partition function. The method\nrelies on repeatedly applying a random perturbation to the distribution in a\nparticular way, each time solving for the most likely configuration. We derive\nan entire family of related methods, of which the Gumbel trick is one member,\nand show that the new methods have superior properties in several settings with\nminimal additional computational cost. In particular, for the Gumbel trick to\nyield computational benefits for discrete graphical models, Gumbel\nperturbations on all configurations are typically replaced with so-called\nlow-rank perturbations. We show how a subfamily of our new methods adapts to\nthis setting, proving new upper and lower bounds on the log partition function\nand deriving a family of sequential samplers for the Gibbs distribution.\nFinally, we balance the discussion by showing how the simpler analytical form\nof the Gumbel trick enables additional theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 17:01:54 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Balog", "Matej", ""], ["Tripuraneni", "Nilesh", ""], ["Ghahramani", "Zoubin", ""], ["Weller", "Adrian", ""]]}, {"id": "1706.04241", "submitter": "Ian Osband", "authors": "Ian Osband, Benjamin Van Roy", "title": "On Optimistic versus Randomized Exploration in Reinforcement Learning", "comments": "Extended abstract for RLDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the relative merits of optimistic and randomized approaches to\nexploration in reinforcement learning. Optimistic approaches presented in the\nliterature apply an optimistic boost to the value estimate at each state-action\npair and select actions that are greedy with respect to the resulting\noptimistic value function. Randomized approaches sample from among\nstatistically plausible value functions and select actions that are greedy with\nrespect to the random sample. Prior computational experience suggests that\nrandomized approaches can lead to far more statistically efficient learning. We\npresent two simple analytic examples that elucidate why this is the case. In\nprinciple, there should be optimistic approaches that fare well relative to\nrandomized approaches, but that would require intractable computation.\nOptimistic approaches that have been proposed in the literature sacrifice\nstatistical efficiency for the sake of computational efficiency. Randomized\napproaches, on the other hand, may enable simultaneous statistical and\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 20:22:54 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1706.04289", "submitter": "Wray Buntine", "authors": "He Zhao, Lan Du, Wray Buntine", "title": "Leveraging Node Attributes for Incomplete Relational Data", "comments": "Appearing in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data are usually highly incomplete in practice, which inspires us\nto leverage side information to improve the performance of community detection\nand link prediction. This paper presents a Bayesian probabilistic approach that\nincorporates various kinds of node attributes encoded in binary form in\nrelational models with Poisson likelihood. Our method works flexibly with both\ndirected and undirected relational networks. The inference can be done by\nefficient Gibbs sampling which leverages sparsity of both networks and node\nattributes. Extensive experiments show that our models achieve the\nstate-of-the-art link prediction results, especially with highly incomplete\nrelational data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 00:37:07 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Zhao", "He", ""], ["Du", "Lan", ""], ["Buntine", "Wray", ""]]}, {"id": "1706.04336", "submitter": "David Carey", "authors": "David L. Carey, Kok-Leong Ong, Rod Whiteley, Kay M. Crossley, Justin\n  Crow and Meg E. Morris", "title": "Predictive modelling of training loads and injury in Australian football", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": "10.2478/ijcss-2018-0002", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To investigate whether training load monitoring data could be used to predict\ninjuries in elite Australian football players, data were collected from elite\nathletes over 3 seasons at an Australian football club. Loads were quantified\nusing GPS devices, accelerometers and player perceived exertion ratings.\nAbsolute and relative training load metrics were calculated for each player\neach day (rolling average, exponentially weighted moving average, acute:chronic\nworkload ratio, monotony and strain). Injury prediction models (regularised\nlogistic regression, generalised estimating equations, random forests and\nsupport vector machines) were built for non-contact, non-contact time-loss and\nhamstring specific injuries using the first two seasons of data. Injury\npredictions were generated for the third season and evaluated using the area\nunder the receiver operator characteristic (AUC). Predictive performance was\nonly marginally better than chance for models of non-contact and non-contact\ntime-loss injuries (AUC$<$0.65). The best performing model was a multivariate\nlogistic regression for hamstring injuries (best AUC=0.76). Learning curves\nsuggested logistic regression was underfitting the load-injury relationship and\nthat using a more complex model or increasing the amount of model building data\nmay lead to future improvements. Injury prediction models built using training\nload data from a single club showed poor ability to predict injuries when\ntested on previously unseen data, suggesting they are limited as a daily\ndecision tool for practitioners. Focusing the modelling approach on specific\ninjury types and increasing the amount of training data may lead to the\ndevelopment of improved predictive models for injury prevention.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 07:09:33 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Carey", "David L.", ""], ["Ong", "Kok-Leong", ""], ["Whiteley", "Rod", ""], ["Crossley", "Kay M.", ""], ["Crow", "Justin", ""], ["Morris", "Meg E.", ""]]}, {"id": "1706.04397", "submitter": "Hinrich B Winther", "authors": "Hinrich B Winther, Christian Hundt, Bertil Schmidt, Christoph Czerner,\n  Johann Bauersachs, Frank Wacker, Jens Vogel-Claussen", "title": "$\\nu$-net: Deep Learning for Generalized Biventricular Cardiac Mass and\n  Function Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Cardiac MRI derived biventricular mass and function parameters,\nsuch as end-systolic volume (ESV), end-diastolic volume (EDV), ejection\nfraction (EF), stroke volume (SV), and ventricular mass (VM) are clinically\nwell established. Image segmentation can be challenging and time-consuming, due\nto the complex anatomy of the human heart.\n  Objectives: This study introduces $\\nu$-net (/nju:n$\\varepsilon$t/) -- a deep\nlearning approach allowing for fully-automated high quality segmentation of\nright (RV) and left ventricular (LV) endocardium and epicardium for extraction\nof cardiac function parameters.\n  Methods: A set consisting of 253 manually segmented cases has been used to\ntrain a deep neural network. Subsequently, the network has been evaluated on 4\ndifferent multicenter data sets with a total of over 1000 cases.\n  Results: For LV EF the intraclass correlation coefficient (ICC) is 98, 95,\nand 80 % (95 %), and for RV EF 96, and 87 % (80 %) on the respective data sets\n(human expert ICCs reported in parenthesis). The LV VM ICC is 95, and 94 % (84\n%), and the RV VM ICC is 83, and 83 % (54 %). This study proposes a simple\nadjustment procedure, allowing for the adaptation to distinct segmentation\nphilosophies. $\\nu$-net exhibits state of-the-art performance in terms of dice\ncoefficient.\n  Conclusions: Biventricular mass and function parameters can be determined\nreliably in high quality by applying a deep neural network for cardiac MRI\nsegmentation, especially in the anatomically complex right ventricle. Adaption\nto individual segmentation styles by applying a simple adjustment procedure is\nviable, allowing for the processing of novel data without time-consuming\nadditional training.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 10:36:30 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Winther", "Hinrich B", ""], ["Hundt", "Christian", ""], ["Schmidt", "Bertil", ""], ["Czerner", "Christoph", ""], ["Bauersachs", "Johann", ""], ["Wacker", "Frank", ""], ["Vogel-Claussen", "Jens", ""]]}, {"id": "1706.04410", "submitter": "Ramji Venkataramanan", "authors": "Ramji Venkataramanan, Oliver Johnson", "title": "A strong converse bound for multiple hypothesis testing, with\n  applications to high-dimensional estimation", "comments": "In the latest version, the value of $\\lambda$ in the statements of\n  Lemma 4.1 and Proposition 4.2 is restricted to the interval $(0,1]$. This is\n  the correct condition, rather than $\\lambda>0$ stated in the journal version\n  below", "journal-ref": "Electronic Journal of Statistics, Vol. 12, No. 1, pp. 1126-1149,\n  2018", "doi": "10.1214/18-EJS1419", "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical inference problems, we wish to obtain lower bounds on the\nminimax risk, that is to bound the performance of any possible estimator. A\nstandard technique to obtain risk lower bounds involves the use of Fano's\ninequality. In an information-theoretic setting, it is known that Fano's\ninequality typically does not give a sharp converse result (error lower bound)\nfor channel coding problems. Moreover, recent work has shown that an argument\nbased on binary hypothesis testing gives tighter results. We adapt this\ntechnique to the statistical setting, and argue that Fano's inequality can\nalways be replaced by this approach to obtain tighter lower bounds that can be\neasily computed and are asymptotically sharp. We illustrate our technique in\nthree applications: density estimation, active learning of a binary classifier,\nand compressed sensing, obtaining tighter risk lower bounds in each case.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 11:21:02 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:47:33 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 18:54:51 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Venkataramanan", "Ramji", ""], ["Johnson", "Oliver", ""]]}, {"id": "1706.04416", "submitter": "Reza Mohammadi", "authors": "Reza Mohammadi, Helene Massam, Gerard Letac", "title": "Accelerating Bayesian Structure Learning in Sparse Gaussian Graphical\n  Models", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models are relevant tools to learn conditional\nindependence structure between variables. In this class of models, Bayesian\nstructure learning is often done by search algorithms over the graph space. The\nconjugate prior for the precision matrix satisfying graphical constraints is\nthe well-known G-Wishart. With this prior, the transition probabilities in the\nsearch algorithms necessitate evaluating the ratios of the prior normalizing\nconstants of G-Wishart. In moderate to high-dimensions, this ratio is often\napproximated using sampling-based methods as computationally expensive updates\nin the search algorithm. Calculating this ratio so far has been a major\ncomputational bottleneck. We overcome this issue by representing a search\nalgorithm in which the ratio of normalizing constant is carried out by an\nexplicit closed-form approximation. Using this approximation within our search\nalgorithm yields significant improvement in the scalability of structure\nlearning without sacrificing structure learning accuracy. We study the\nconditions under which the approximation is valid. We also evaluate the\nefficacy of our method with simulation studies. We show that the new search\nalgorithm with our approximation outperforms state-of-the-art methods in both\ncomputational efficiency and accuracy. The implementation of our work is\navailable in the R package BDgraph.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 11:41:06 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 12:26:11 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 14:38:50 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mohammadi", "Reza", ""], ["Massam", "Helene", ""], ["Letac", "Gerard", ""]]}, {"id": "1706.04499", "submitter": "R\\'emi Leblond", "authors": "R\\'emi Leblond, Jean-Baptiste Alayrac, Anton Osokin and Simon\n  Lacoste-Julien", "title": "SEARNN: Training RNNs with Global-Local Losses", "comments": "Published as a conference paper at ICLR 2018, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SEARNN, a novel training algorithm for recurrent neural networks\n(RNNs) inspired by the \"learning to search\" (L2S) approach to structured\nprediction. RNNs have been widely successful in structured prediction\napplications such as machine translation or parsing, and are commonly trained\nusing maximum likelihood estimation (MLE). Unfortunately, this training loss is\nnot always an appropriate surrogate for the test error: by only maximizing the\nground truth probability, it fails to exploit the wealth of information offered\nby structured losses. Further, it introduces discrepancies between training and\npredicting (such as exposure bias) that may hurt test performance. Instead,\nSEARNN leverages test-alike search space exploration to introduce global-local\nlosses that are closer to the test error. We first demonstrate improved\nperformance over MLE on two different tasks: OCR and spelling correction. Then,\nwe propose a subsampling strategy to enable SEARNN to scale to large vocabulary\nsizes. This allows us to validate the benefits of our approach on a machine\ntranslation task.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 14:00:58 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 22:09:29 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2018 15:44:13 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Leblond", "R\u00e9mi", ""], ["Alayrac", "Jean-Baptiste", ""], ["Osokin", "Anton", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1706.04546", "submitter": "Theodoros Tsiligkaridis", "authors": "Theodoros Tsiligkaridis, David Romero", "title": "Reinforcement Learning with Budget-Constrained Nonparametric Function\n  Approximation for Opportunistic Spectrum Access", "comments": "6 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opportunistic spectrum access is one of the emerging techniques for\nmaximizing throughput in congested bands and is enabled by predicting idle\nslots in spectrum. We propose a kernel-based reinforcement learning approach\ncoupled with a novel budget-constrained sparsification technique that\nefficiently captures the environment to find the best channel access actions.\nThis approach allows learning and planning over the intrinsic state-action\nspace and extends well to large state spaces. We apply our methods to evaluate\ncoexistence of a reinforcement learning-based radio with a multi-channel\nadversarial radio and a single-channel CSMA-CA radio. Numerical experiments\nshow the performance gains over carrier-sense systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 15:44:52 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 19:46:21 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Tsiligkaridis", "Theodoros", ""], ["Romero", "David", ""]]}, {"id": "1706.04572", "submitter": "Miha Skalic", "authors": "Miha Skalic, Marcin Pekalski, Xingguo E. Pan", "title": "Deep Learning Methods for Efficient Large Scale Video Labeling", "comments": "7 pages, 5 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a solution to \"Google Cloud and YouTube-8M Video Understanding\nChallenge\" that ranked 5th place. The proposed model is an ensemble of three\nmodel families, two frame level and one video level. The training was performed\non augmented dataset, with cross validation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 16:24:18 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Skalic", "Miha", ""], ["Pekalski", "Marcin", ""], ["Pan", "Xingguo E.", ""]]}, {"id": "1706.04601", "submitter": "Andrej Risteski", "authors": "Sanjeev Arora, Andrej Risteski", "title": "Provable benefits of representation learning", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is general consensus that learning representations is useful for a\nvariety of reasons, e.g. efficient use of labeled data (semi-supervised\nlearning), transfer learning and understanding hidden structure of data.\nPopular techniques for representation learning include clustering, manifold\nlearning, kernel-learning, autoencoders, Boltzmann machines, etc.\n  To study the relative merits of these techniques, it's essential to formalize\nthe definition and goals of representation learning, so that they are all\nbecome instances of the same definition. This paper introduces such a formal\nframework that also formalizes the utility of learning the representation. It\nis related to previous Bayesian notions, but with some new twists. We show the\nusefulness of our framework by exhibiting simple and natural settings -- linear\nmixture models and loglinear models, where the power of representation learning\ncan be formally shown. In these examples, representation learning can be\nperformed provably and efficiently under plausible assumptions (despite being\nNP-hard), and furthermore: (i) it greatly reduces the need for labeled data\n(semi-supervised learning) and (ii) it allows solving classification tasks when\nsimpler approaches like nearest neighbors require too much data (iii) it is\nmore powerful than manifold learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 17:35:21 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Arora", "Sanjeev", ""], ["Risteski", "Andrej", ""]]}, {"id": "1706.04606", "submitter": "Olli-Pekka Koistinen", "authors": "Olli-Pekka Koistinen, Freyja B. Dagbjartsd\\'ottir, Vilhj\\'almur\n  \\'Asgeirsson, Aki Vehtari, Hannes J\\'onsson", "title": "Nudged elastic band calculations accelerated with Gaussian process\n  regression", "comments": null, "journal-ref": "The Journal of Chemical Physics 147, 152720 (2017)", "doi": "10.1063/1.4986787", "report-no": null, "categories": "physics.chem-ph physics.atm-clus physics.comp-ph stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum energy paths for transitions such as atomic and/or spin\nrearrangements in thermalized systems are the transition paths of largest\nstatistical weight. Such paths are frequently calculated using the nudged\nelastic band method, where an initial path is iteratively shifted to the\nnearest minimum energy path. The computational effort can be large, especially\nwhen ab initio or electron density functional calculations are used to evaluate\nthe energy and atomic forces. Here, we show how the number of such evaluations\ncan be reduced by an order of magnitude using a Gaussian process regression\napproach where an approximate energy surface is generated and refined in each\niteration. When the goal is to evaluate the transition rate within harmonic\ntransition state theory, the evaluation of the Hessian matrix at the initial\nand final state minima can be carried out beforehand and used as input in the\nminimum energy path calculation, thereby improving stability and reducing the\nnumber of iterations needed for convergence. A Gaussian process model also\nprovides an uncertainty estimate for the approximate energy surface, and this\ncan be used to focus the calculations on the lesser-known part of the path,\nthereby reducing the number of needed energy and force evaluations to a half in\nthe present calculations. The methodology is illustrated using the\ntwo-dimensional M\\\"uller-Brown potential surface and performance assessed on an\nestablished benchmark involving 13 rearrangement transitions of a heptamer\nisland on a solid surface.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 17:48:49 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 15:03:41 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Koistinen", "Olli-Pekka", ""], ["Dagbjartsd\u00f3ttir", "Freyja B.", ""], ["\u00c1sgeirsson", "Vilhj\u00e1lmur", ""], ["Vehtari", "Aki", ""], ["J\u00f3nsson", "Hannes", ""]]}, {"id": "1706.04632", "submitter": "Yi-An Ma", "authors": "Yi-An Ma and Nicholas J. Foti and Emily B. Fox", "title": "Stochastic Gradient MCMC Methods for Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient MCMC (SG-MCMC) algorithms have proven useful in scaling\nBayesian inference to large datasets under an assumption of i.i.d data. We\ninstead develop an SG-MCMC algorithm to learn the parameters of hidden Markov\nmodels (HMMs) for time-dependent data. There are two challenges to applying\nSG-MCMC in this setting: The latent discrete states, and needing to break\ndependencies when considering minibatches. We consider a marginal likelihood\nrepresentation of the HMM and propose an algorithm that harnesses the inherent\nmemory decay of the process. We demonstrate the effectiveness of our algorithm\non synthetic experiments and an ion channel recording data, with runtimes\nsignificantly outperforming batch MCMC.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 18:44:29 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Ma", "Yi-An", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily B.", ""]]}, {"id": "1706.04635", "submitter": "Yan Zhang", "authors": "Yan Zhang and Mete Ozay and Zhun Sun and Takayuki Okatani", "title": "Information Potential Auto-Encoders", "comments": "Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we suggest a framework to make use of mutual information as a\nregularization criterion to train Auto-Encoders (AEs). In the proposed\nframework, AEs are regularized by minimization of the mutual information\nbetween input and encoding variables of AEs during the training phase. In order\nto estimate the entropy of the encoding variables and the mutual information,\nwe propose a non-parametric method. We also give an information theoretic view\nof Variational AEs (VAEs), which suggests that VAEs can be considered as\nparametric methods that estimate entropy. Experimental results show that the\nproposed non-parametric models have more degree of freedom in terms of\nrepresentation learning of features drawn from complex distributions such as\nMixture of Gaussians, compared to methods which estimate entropy using\nparametric approaches, such as Variational AEs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 18:52:54 GMT"}, {"version": "v2", "created": "Sun, 6 Aug 2017 06:44:19 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Zhang", "Yan", ""], ["Ozay", "Mete", ""], ["Sun", "Zhun", ""], ["Okatani", "Takayuki", ""]]}, {"id": "1706.04646", "submitter": "Garrett Bernstein", "authors": "Garrett Bernstein, Ryan McKenna, Tao Sun, Daniel Sheldon, Michael Hay,\n  Gerome Miklau", "title": "Differentially Private Learning of Undirected Graphical Models using\n  Collective Graphical Models", "comments": "Accepted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning discrete, undirected graphical models\nin a differentially private way. We show that the approach of releasing noisy\nsufficient statistics using the Laplace mechanism achieves a good trade-off\nbetween privacy, utility, and practicality. A naive learning algorithm that\nuses the noisy sufficient statistics \"as is\" outperforms general-purpose\ndifferentially private learning algorithms. However, it has three limitations:\nit ignores knowledge about the data generating process, rests on uncertain\ntheoretical foundations, and exhibits certain pathologies. We develop a more\nprincipled approach that applies the formalism of collective graphical models\nto perform inference over the true sufficient statistics within an\nexpectation-maximization framework. We show that this learns better models than\ncompeting approaches on both synthetic data and on real human mobility data\nused as a case study.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 19:27:25 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Bernstein", "Garrett", ""], ["McKenna", "Ryan", ""], ["Sun", "Tao", ""], ["Sheldon", "Daniel", ""], ["Hay", "Michael", ""], ["Miklau", "Gerome", ""]]}, {"id": "1706.04687", "submitter": "Ryan McNellis", "authors": "Adam N. Elmachtoub, Ryan McNellis, Sechan Oh, Marek Petrik", "title": "A Practical Method for Solving Contextual Bandit Problems Using Decision\n  Trees", "comments": "Proceedings of the 33rd Conference on Uncertainty in Artificial\n  Intelligence (UAI 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many efficient algorithms with strong theoretical guarantees have been\nproposed for the contextual multi-armed bandit problem. However, applying these\nalgorithms in practice can be difficult because they require domain expertise\nto build appropriate features and to tune their parameters. We propose a new\nmethod for the contextual bandit problem that is simple, practical, and can be\napplied with little or no domain expertise. Our algorithm relies on decision\ntrees to model the context-reward relationship. Decision trees are\nnon-parametric, interpretable, and work well without hand-crafted features. To\nguide the exploration-exploitation trade-off, we use a bootstrapping approach\nwhich abstracts Thompson sampling to non-Bayesian settings. We also discuss\nseveral computational heuristics and demonstrate the performance of our method\non several datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 22:38:06 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 19:45:03 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Elmachtoub", "Adam N.", ""], ["McNellis", "Ryan", ""], ["Oh", "Sechan", ""], ["Petrik", "Marek", ""]]}, {"id": "1706.04692", "submitter": "Dean Eckles", "authors": "Dean Eckles, Eytan Bakshy", "title": "Bias and high-dimensional adjustment in observational studies of peer\n  effects", "comments": "25 pages, 3 figures, 2 tables; supplementary information as ancillary\n  file", "journal-ref": "Journal of the American Statistical Association (2020)", "doi": "10.1080/01621459.2020.1796393", "report-no": null, "categories": "stat.ME cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer effects, in which the behavior of an individual is affected by the\nbehavior of their peers, are posited by multiple theories in the social\nsciences. Other processes can also produce behaviors that are correlated in\nnetworks and groups, thereby generating debate about the credibility of\nobservational (i.e. nonexperimental) studies of peer effects. Randomized field\nexperiments that identify peer effects, however, are often expensive or\ninfeasible. Thus, many studies of peer effects use observational data, and\nprior evaluations of causal inference methods for adjusting observational data\nto estimate peer effects have lacked an experimental \"gold standard\" for\ncomparison. Here we show, in the context of information and media diffusion on\nFacebook, that high-dimensional adjustment of a nonexperimental control group\n(677 million observations) using propensity score models produces estimates of\npeer effects statistically indistinguishable from those from using a large\nrandomized experiment (220 million observations). Naive observational\nestimators overstate peer effects by 320% and commonly used variables (e.g.,\ndemographics) offer little bias reduction, but adjusting for a measure of prior\nbehaviors closely related to the focal behavior reduces bias by 91%.\nHigh-dimensional models adjusting for over 3,700 past behaviors provide\nadditional bias reduction, such that the full model reduces bias by over 97%.\nThis experimental evaluation demonstrates that detailed records of individuals'\npast behavior can improve studies of social influence, information diffusion,\nand imitation; these results are encouraging for the credibility of some\nstudies but also cautionary for studies of rare or new behaviors. More\ngenerally, these results show how large, high-dimensional data sets and\nstatistical learning techniques can be used to improve causal inference in the\nbehavioral sciences.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 23:21:37 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Eckles", "Dean", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1706.04698", "submitter": "Dongsung Huh", "authors": "Dongsung Huh, Terrence J. Sejnowski", "title": "Gradient Descent for Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of studies on neural computation are based on network models of static\nneurons that produce analog output, despite the fact that information\nprocessing in the brain is predominantly carried out by dynamic neurons that\nproduce discrete pulses called spikes. Research in spike-based computation has\nbeen impeded by the lack of efficient supervised learning algorithm for spiking\nnetworks. Here, we present a gradient descent method for optimizing spiking\nnetwork models by introducing a differentiable formulation of spiking networks\nand deriving the exact gradient calculation. For demonstration, we trained\nrecurrent spiking networks on two dynamic tasks: one that requires optimizing\nfast (~millisecond) spike-based interactions for efficient encoding of\ninformation, and a delayed memory XOR task over extended duration (~second).\nThe results show that our method indeed optimizes the spiking network dynamics\non the time scale of individual spikes as well as behavioral time scales. In\nconclusion, our result offers a general purpose supervised learning algorithm\nfor spiking neural networks, thus advancing further investigations on\nspike-based computation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 23:56:57 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 22:11:20 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Huh", "Dongsung", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1706.04702", "submitter": "Arnulf Jentzen", "authors": "Weinan E and Jiequn Han and Arnulf Jentzen", "title": "Deep learning-based numerical methods for high-dimensional parabolic\n  partial differential equations and backward stochastic differential equations", "comments": "39 pages, 15 figures", "journal-ref": "Commun. Math. Stat. 5, 349-380 (2017)", "doi": "10.1007/s40304-017-0117-6", "report-no": null, "categories": "math.NA cs.LG cs.NE math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for solving parabolic partial differential\nequations (PDEs) and backward stochastic differential equations (BSDEs) in high\ndimension, by making an analogy between the BSDE and reinforcement learning\nwith the gradient of the solution playing the role of the policy function, and\nthe loss function given by the error between the prescribed terminal condition\nand the solution of the BSDE. The policy function is then approximated by a\nneural network, as is done in deep reinforcement learning. Numerical results\nusing TensorFlow illustrate the efficiency and accuracy of the proposed\nalgorithms for several 100-dimensional nonlinear PDEs from physics and finance\nsuch as the Allen-Cahn equation, the Hamilton-Jacobi-Bellman equation, and a\nnonlinear pricing model for financial derivatives.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 00:28:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["E", "Weinan", ""], ["Han", "Jiequn", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1706.04711", "submitter": "Aurko Roy", "authors": "Aurko Roy, Huan Xu and Sebastian Pokutta", "title": "Reinforcement Learning under Model Mismatch", "comments": "To appear in Proceedings of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning under model misspecification, where we do not\nhave access to the true environment but only to a reasonably close\napproximation to it. We address this problem by extending the framework of\nrobust MDPs to the model-free Reinforcement Learning setting, where we do not\nhave access to the model parameters, but can only sample states from it. We\ndefine robust versions of Q-learning, SARSA, and TD-learning and prove\nconvergence to an approximately optimal robust policy and approximate value\nfunction respectively. We scale up the robust algorithms to large MDPs via\nfunction approximation and prove convergence under two different settings. We\nprove convergence of robust approximate policy iteration and robust approximate\nvalue iteration for linear architectures (under mild assumptions). We also\ndefine a robust loss function, the mean squared robust projected Bellman error\nand give stochastic gradient descent algorithms that are guaranteed to converge\nto a local minimum.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 01:06:05 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 01:09:29 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Roy", "Aurko", ""], ["Xu", "Huan", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1706.04729", "submitter": "Yao Xie", "authors": "Liyan Xie, Yao Xie", "title": "Sequential detection of low-rank changes using extreme eigenvalues", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting an abrupt change to the signal covariance\nmatrix. In particular, the covariance changes from a \"white\" identity matrix to\nan unknown spiked or low-rank matrix. Two sequential change-point detection\nprocedures are presented, based on the largest and the smallest eigenvalues of\nthe sample covariance matrix. To control false-alarm-rate, we present an\naccurate theoretical approximation to the average-run-length (ARL) and expected\ndetection delay (EDD) of the detection, leveraging the extreme eigenvalue\ndistributions from random matrix theory and by capturing a non-negligible\ntemporal correlation in the sequence of scan statistics due to the sliding\nwindow approach. Real data examples demonstrate the good performance of our\nmethod for detecting behavior change of a swarm.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 03:42:02 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Xie", "Liyan", ""], ["Xie", "Yao", ""]]}, {"id": "1706.04769", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Paolo Di Lorenzo", "title": "Stochastic Training of Neural Networks via Successive Convex\n  Approximations", "comments": "Preprint submitted to IEEE Transactions on Neural Networks and\n  Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new family of algorithms for training neural networks\n(NNs). These are based on recent developments in the field of non-convex\noptimization, going under the general name of successive convex approximation\n(SCA) techniques. The basic idea is to iteratively replace the original\n(non-convex, highly dimensional) learning problem with a sequence of (strongly\nconvex) approximations, which are both accurate and simple to optimize.\nDifferently from similar ideas (e.g., quasi-Newton algorithms), the\napproximations can be constructed using only first-order information of the\nneural network function, in a stochastic fashion, while exploiting the overall\nstructure of the learning problem for a faster convergence. We discuss several\nuse cases, based on different choices for the loss function (e.g., squared loss\nand cross-entropy loss), and for the regularization of the NN's weights. We\nexperiment on several medium-sized benchmark problems, and on a large-scale\ndataset involving simulated physical data. The results show how the algorithm\noutperforms state-of-the-art techniques, providing faster convergence to a\nbetter minimum. Additionally, we show how the algorithm can be easily\nparallelized over multiple computational units without hindering its\nperformance. In particular, each computational unit can optimize a tailored\nsurrogate function defined on a randomly assigned subset of the input\nvariables, whose dimension can be selected depending entirely on the available\ncomputational power.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 08:11:22 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Scardapane", "Simone", ""], ["Di Lorenzo", "Paolo", ""]]}, {"id": "1706.04792", "submitter": "Martin Rosvall", "authors": "Daniel Edler, Ludvig Bohlin, and Martin Rosvall", "title": "Mapping higher-order network flows in memory and multilayer networks\n  with Infomap", "comments": "23 pages, 4 figures", "journal-ref": "Algorithms 2017, 10(4), 112", "doi": "10.3390/a10040112", "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehending complex systems by simplifying and highlighting important\ndynamical patterns requires modeling and mapping higher-order network flows.\nHowever, complex systems come in many forms and demand a range of\nrepresentations, including memory and multilayer networks, which in turn call\nfor versatile community-detection algorithms to reveal important modular\nregularities in the flows. Here we show that various forms of higher-order\nnetwork flows can be represented in a unified way with networks that\ndistinguish physical nodes for representing a~complex system's objects from\nstate nodes for describing flows between the objects. Moreover, these so-called\nsparse memory networks allow the information-theoretic community detection\nmethod known as the map equation to identify overlapping and nested flow\nmodules in data from a range of~different higher-order interactions such as\nmultistep, multi-source, and temporal data. We derive the map equation applied\nto sparse memory networks and describe its search algorithm Infomap, which can\nexploit the flexibility of sparse memory networks. Together they provide a\ngeneral solution to reveal overlapping modular patterns in higher-order flows\nthrough complex systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 09:36:25 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 18:47:47 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Edler", "Daniel", ""], ["Bohlin", "Ludvig", ""], ["Rosvall", "Martin", ""]]}, {"id": "1706.04892", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Alessandro Lazaric and Michal Valko", "title": "Second-Order Kernel Online Convex Optimization with Adaptive Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel online convex optimization (KOCO) is a framework combining the\nexpressiveness of non-parametric kernel models with the regret guarantees of\nonline learning. First-order KOCO methods such as functional gradient descent\nrequire only $\\mathcal{O}(t)$ time and space per iteration, and, when the only\ninformation on the losses is their convexity, achieve a minimax optimal\n$\\mathcal{O}(\\sqrt{T})$ regret. Nonetheless, many common losses in kernel\nproblems, such as squared loss, logistic loss, and squared hinge loss posses\nstronger curvature that can be exploited. In this case, second-order KOCO\nmethods achieve $\\mathcal{O}(\\log(\\text{Det}(\\boldsymbol{K})))$ regret, which\nwe show scales as $\\mathcal{O}(d_{\\text{eff}}\\log T)$, where $d_{\\text{eff}}$\nis the effective dimension of the problem and is usually much smaller than\n$\\mathcal{O}(\\sqrt{T})$. The main drawback of second-order methods is their\nmuch higher $\\mathcal{O}(t^2)$ space and time complexity. In this paper, we\nintroduce kernel online Newton step (KONS), a new second-order KOCO method that\nalso achieves $\\mathcal{O}(d_{\\text{eff}}\\log T)$ regret. To address the\ncomputational complexity of second-order methods, we introduce a new matrix\nsketching algorithm for the kernel matrix $\\boldsymbol{K}_t$, and show that for\na chosen parameter $\\gamma \\leq 1$ our Sketched-KONS reduces the space and time\ncomplexity by a factor of $\\gamma^2$ to $\\mathcal{O}(t^2\\gamma^2)$ space and\ntime per iteration, while incurring only $1/\\gamma$ times more regret.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 14:33:08 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Calandriello", "Daniele", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""]]}, {"id": "1706.04918", "submitter": "Jonathan Scarlett", "authors": "Ilija Bogunovic, Slobodan Mitrovi\\'c, Jonathan Scarlett, Volkan Cevher", "title": "Robust Submodular Maximization: A Non-Uniform Partitioning Approach", "comments": "Accepted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing a monotone submodular function subject to\na cardinality constraint $k$, with the added twist that a number of items\n$\\tau$ from the returned set may be removed. We focus on the worst-case setting\nconsidered in (Orlin et al., 2016), in which a constant-factor approximation\nguarantee was given for $\\tau = o(\\sqrt{k})$. In this paper, we solve a key\nopen problem raised therein, presenting a new Partitioned Robust (PRo)\nsubmodular maximization algorithm that achieves the same guarantee for more\ngeneral $\\tau = o(k)$. Our algorithm constructs partitions consisting of\nbuckets with exponentially increasing sizes, and applies standard submodular\noptimization subroutines on the buckets in order to construct the robust\nsolution. We numerically demonstrate the performance of PRo in data\nsummarization and influence maximization, demonstrating gains over both the\ngreedy algorithm and the algorithm of (Orlin et al., 2016).\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 15:15:10 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Bogunovic", "Ilija", ""], ["Mitrovi\u0107", "Slobodan", ""], ["Scarlett", "Jonathan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1706.04983", "submitter": "Andrew Brock", "authors": "Andrew Brock, Theodore Lim, J.M. Ritchie, Nick Weston", "title": "FreezeOut: Accelerate Training by Progressively Freezing Layers", "comments": "Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early layers of a deep neural net have the fewest parameters, but take up\nthe most computation. In this extended abstract, we propose to only train the\nhidden layers for a set portion of the training run, freezing them out\none-by-one and excluding them from the backward pass. Through experiments on\nCIFAR, we empirically demonstrate that FreezeOut yields savings of up to 20%\nwall-clock time during training with 3% loss in accuracy for DenseNets, a 20%\nspeedup without loss of accuracy for ResNets, and no improvement for VGG\nnetworks. Our code is publicly available at\nhttps://github.com/ajbrock/FreezeOut\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 17:35:15 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 16:15:21 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Brock", "Andrew", ""], ["Lim", "Theodore", ""], ["Ritchie", "J. M.", ""], ["Weston", "Nick", ""]]}, {"id": "1706.04987", "submitter": "Mihaela Rosca", "authors": "Mihaela Rosca, Balaji Lakshminarayanan, David Warde-Farley, Shakir\n  Mohamed", "title": "Variational Approaches for Auto-Encoding Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-encoding generative adversarial networks (GANs) combine the standard GAN\nalgorithm, which discriminates between real and model-generated data, with a\nreconstruction loss given by an auto-encoder. Such models aim to prevent mode\ncollapse in the learned generative model by ensuring that it is grounded in all\nthe available training data. In this paper, we develop a principle upon which\nauto-encoders can be combined with generative adversarial networks by\nexploiting the hierarchical structure of the generative model. The underlying\nprinciple shows that variational inference can be used a basic tool for\nlearning, but with the in- tractable likelihood replaced by a synthetic\nlikelihood, and the unknown posterior distribution replaced by an implicit\ndistribution; both synthetic likelihoods and implicit posterior distributions\ncan be learned using discriminators. This allows us to develop a natural fusion\nof variational auto-encoders and generative adversarial networks, combining the\nbest of both these methods. We describe a unified objective for optimization,\ndiscuss the constraints needed to guide learning, connect to the wide range of\nexisting work, and use a battery of tests to systematically and quantitatively\nassess the performance of our method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 17:47:56 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 11:58:36 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Rosca", "Mihaela", ""], ["Lakshminarayanan", "Balaji", ""], ["Warde-Farley", "David", ""], ["Mohamed", "Shakir", ""]]}, {"id": "1706.05069", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Thomas Steinke", "title": "Generalization for Adaptively-chosen Estimators via Stable Median", "comments": "To appear in Conference on Learning Theory (COLT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets are often reused to perform multiple statistical analyses in an\nadaptive way, in which each analysis may depend on the outcomes of previous\nanalyses on the same dataset. Standard statistical guarantees do not account\nfor these dependencies and little is known about how to provably avoid\noverfitting and false discovery in the adaptive setting. We consider a natural\nformalization of this problem in which the goal is to design an algorithm that,\ngiven a limited number of i.i.d.~samples from an unknown distribution, can\nanswer adaptively-chosen queries about that distribution.\n  We present an algorithm that estimates the expectations of $k$ arbitrary\nadaptively-chosen real-valued estimators using a number of samples that scales\nas $\\sqrt{k}$. The answers given by our algorithm are essentially as accurate\nas if fresh samples were used to evaluate each estimator. In contrast, prior\nwork yields error guarantees that scale with the worst-case sensitivity of each\nestimator. We also give a version of our algorithm that can be used to verify\nanswers to such queries where the sample complexity depends logarithmically on\nthe number of queries $k$ (as in the reusable holdout technique).\n  Our algorithm is based on a simple approximate median algorithm that\nsatisfies the strong stability guarantees of differential privacy. Our\ntechniques provide a new approach for analyzing the generalization guarantees\nof differentially private algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 20:21:17 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Feldman", "Vitaly", ""], ["Steinke", "Thomas", ""]]}, {"id": "1706.05084", "submitter": "James Wilson", "authors": "Kelsey MacMillan and James D. Wilson", "title": "Topic supervised non-negative matrix factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have been extensively used to organize and interpret the\ncontents of large, unstructured corpora of text documents. Although topic\nmodels often perform well on traditional training vs. test set evaluations, it\nis often the case that the results of a topic model do not align with human\ninterpretation. This interpretability fallacy is largely due to the\nunsupervised nature of topic models, which prohibits any user guidance on the\nresults of a model. In this paper, we introduce a semi-supervised method called\ntopic supervised non-negative matrix factorization (TS-NMF) that enables the\nuser to provide labeled example documents to promote the discovery of more\nmeaningful semantic structure of a corpus. In this way, the results of TS-NMF\nbetter match the intuition and desired labeling of the user. The core of TS-NMF\nrelies on solving a non-convex optimization problem for which we derive an\niterative algorithm that is shown to be monotonic and convergent to a local\noptimum. We demonstrate the practical utility of TS-NMF on the Reuters and\nPubMed corpora, and find that TS-NMF is especially useful for conceptual or\nbroad topics, where topic key terms are not well understood. Although\nidentifying an optimal latent structure for the data is not a primary objective\nof the proposed approach, we find that TS-NMF achieves higher weighted Jaccard\nsimilarity scores than the contemporary methods, (unsupervised) NMF and latent\nDirichlet allocation, at supervision rates as low as 10% to 20%.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 04:20:04 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 16:00:27 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["MacMillan", "Kelsey", ""], ["Wilson", "James D.", ""]]}, {"id": "1706.05098", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder", "title": "An Overview of Multi-Task Learning in Deep Neural Networks", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) has led to successes in many applications of\nmachine learning, from natural language processing and speech recognition to\ncomputer vision and drug discovery. This article aims to give a general\noverview of MTL, particularly in deep neural networks. It introduces the two\nmost common methods for MTL in Deep Learning, gives an overview of the\nliterature, and discusses recent advances. In particular, it seeks to help ML\npractitioners apply MTL by shedding light on how MTL works and providing\nguidelines for choosing appropriate auxiliary tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 21:38:12 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Ruder", "Sebastian", ""]]}, {"id": "1706.05136", "submitter": "Changwei Hu", "authors": "Changwei Hu, Piyush Rai, Lawrence Carin", "title": "Deep Generative Models for Relational Data with Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic framework for overlapping community discovery and\nlink prediction for relational data, given as a graph. The proposed framework\nhas: (1) a deep architecture which enables us to infer multiple layers of\nlatent features/communities for each node, providing superior link prediction\nperformance on more complex networks and better interpretability of the latent\nfeatures; and (2) a regression model which allows directly conditioning the\nnode latent features on the side information available in form of node\nattributes. Our framework handles both (1) and (2) via a clean, unified model,\nwhich enjoys full local conjugacy via data augmentation, and facilitates\nefficient inference via closed form Gibbs sampling. Moreover, inference cost\nscales in the number of edges which is attractive for massive but sparse\nnetworks. Our framework is also easily extendable to model weighted networks\nwith count-valued edges. We compare with various state-of-the-art methods and\nreport results, both quantitative and qualitative, on several benchmark data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 02:52:38 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Hu", "Changwei", ""], ["Rai", "Piyush", ""], ["Carin", "Lawrence", ""]]}, {"id": "1706.05137", "submitter": "{\\L}ukasz Kaiser", "authors": "Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki\n  Parmar, Llion Jones, Jakob Uszkoreit", "title": "One Model To Learn Them All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning yields great results across many fields, from speech\nrecognition, image classification, to translation. But for each problem,\ngetting a deep model to work well involves research into the architecture and a\nlong period of tuning. We present a single model that yields good results on a\nnumber of problems spanning multiple domains. In particular, this single model\nis trained concurrently on ImageNet, multiple translation tasks, image\ncaptioning (COCO dataset), a speech recognition corpus, and an English parsing\ntask. Our model architecture incorporates building blocks from multiple\ndomains. It contains convolutional layers, an attention mechanism, and\nsparsely-gated layers. Each of these computational blocks is crucial for a\nsubset of the tasks we train on. Interestingly, even if a block is not crucial\nfor a task, we observe that adding it never hurts performance and in most cases\nimproves it on all tasks. We also show that tasks with less data benefit\nlargely from joint training with other tasks, while performance on large tasks\ndegrades only slightly if at all.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 03:10:03 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Kaiser", "Lukasz", ""], ["Gomez", "Aidan N.", ""], ["Shazeer", "Noam", ""], ["Vaswani", "Ashish", ""], ["Parmar", "Niki", ""], ["Jones", "Llion", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1706.05249", "submitter": "Frosti Palsson", "authors": "Frosti Palsson, Johannes R. Sveinsson, Magnus O. Ulfarsson", "title": "Multispectral and Hyperspectral Image Fusion Using a 3-D-Convolutional\n  Neural Network", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2017.2668299", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method using a three dimensional convolutional\nneural network (3-D-CNN) to fuse together multispectral (MS) and hyperspectral\n(HS) images to obtain a high resolution hyperspectral image. Dimensionality\nreduction of the hyperspectral image is performed prior to fusion in order to\nsignificantly reduce the computational time and make the method more robust to\nnoise. Experiments are performed on a data set simulated using a real\nhyperspectral image. The results obtained show that the proposed approach is\nvery promising when compared to conventional methods. This is especially true\nwhen the hyperspectral image is corrupted by additive noise.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 12:38:44 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Palsson", "Frosti", ""], ["Sveinsson", "Johannes R.", ""], ["Ulfarsson", "Magnus O.", ""]]}, {"id": "1706.05259", "submitter": "Zhi-Hua Zhou", "authors": "Bo-Jian Hou and Lijun Zhang and Zhi-Hua Zhou", "title": "Learning with Feature Evolvable Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with streaming data has attracted much attention during the past few\nyears. Though most studies consider data stream with fixed features, in real\npractice the features may be evolvable. For example, features of data gathered\nby limited-lifespan sensors will change when these sensors are substituted by\nnew ones. In this paper, we propose a novel learning paradigm: \\emph{Feature\nEvolvable Streaming Learning} where old features would vanish and new features\nwould occur. Rather than relying on only the current features, we attempt to\nrecover the vanished features and exploit it to improve performance.\nSpecifically, we learn two models from the recovered features and the current\nfeatures, respectively. To benefit from the recovered features, we develop two\nensemble methods. In the first method, we combine the predictions from two\nmodels and theoretically show that with the assistance of old features, the\nperformance on new features can be improved. In the second approach, we\ndynamically select the best single prediction and establish a better\nperformance guarantee when the best model switches. Experiments on both\nsynthetic and real data validate the effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 13:12:49 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 09:10:10 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Hou", "Bo-Jian", ""], ["Zhang", "Lijun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1706.05295", "submitter": "Eun Jee Lee", "authors": "Emmanuel Abbe, Sanjeev Kulkarni, Eun Jee Lee", "title": "Nonbacktracking Bounds on the Influence in Independent Cascade Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops upper and lower bounds on the influence measure in a\nnetwork, more precisely, the expected number of nodes that a seed set can\ninfluence in the independent cascade model. In particular, our bounds exploit\nnonbacktracking walks, Fortuin-Kasteleyn-Ginibre (FKG) type inequalities, and\nare computed by message passing implementation. Nonbacktracking walks have\nrecently allowed for headways in community detection, and this paper shows that\ntheir use can also impact the influence computation. Further, we provide a knob\nto control the trade-off between the efficiency and the accuracy of the bounds.\nFinally, the tightness of the bounds is illustrated with simulations on various\nnetwork models.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 00:09:46 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 05:48:49 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Kulkarni", "Sanjeev", ""], ["Lee", "Eun Jee", ""]]}, {"id": "1706.05335", "submitter": "Twan van Laarhoven", "authors": "Twan van Laarhoven and Elena Marchiori", "title": "Unsupervised Domain Adaptation with Random Walks on Target Labelings", "comments": "Source code to reproduce our experiments is available at\n  https://github.com/twanvl/rwa-da", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation (DA) is used to automatize the task of\nlabeling data: an unlabeled dataset (target) is annotated using a labeled\ndataset (source) from a related domain. We cast domain adaptation as the\nproblem of finding stable labels for target examples. A new definition of label\nstability is proposed, motivated by a generalization error bound for large\nmargin linear classifiers: a target labeling is stable when, with high\nprobability, a classifier trained on a random subsample of the target with that\nlabeling yields the same labeling. We find stable labelings using a random walk\non a directed graph with transition probabilities based on labeling stability.\nThe majority vote of those labelings visited by the walk yields a stable label\nfor each target example. The resulting domain adaptation algorithm is\nstrikingly easy to implement and apply: It does not rely on data\ntransformations, which are in general computational prohibitive in the presence\nof many input features, and does not need to access the source data, which is\nadvantageous when data sharing is restricted. By acting on the original feature\nspace, our method is able to take full advantage of deep features from external\npre-trained neural networks, as demonstrated by the results of our experiments.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 16:21:10 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 18:59:38 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""]]}, {"id": "1706.05350", "submitter": "Twan van Laarhoven", "authors": "Twan van Laarhoven", "title": "L2 Regularization versus Batch and Weight Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization is a commonly used trick to improve the training of deep\nneural networks. These neural networks use L2 regularization, also called\nweight decay, ostensibly to prevent overfitting. However, we show that L2\nregularization has no regularizing effect when combined with normalization.\nInstead, regularization has an influence on the scale of weights, and thereby\non the effective learning rate. We investigate this dependence, both in theory,\nand experimentally. We show that popular optimization methods such as ADAM only\npartially eliminate the influence of normalization on the learning rate. This\nleads to a discussion on other ways to mitigate this issue.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 17:08:08 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["van Laarhoven", "Twan", ""]]}, {"id": "1706.05358", "submitter": "Chong Huang", "authors": "Chong Huang, Qiong Liu, Yan-Ying Chen, Kwang-Ting (Tim) Cheng", "title": "Local Feature Descriptor Learning with Adaptive Siamese Network", "comments": "4 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the recent progress in the deep neural network has led to the\ndevelopment of learnable local feature descriptors, there is no explicit answer\nfor estimation of the necessary size of a neural network. Specifically, the\nlocal feature is represented in a low dimensional space, so the neural network\nshould have more compact structure. The small networks required for local\nfeature descriptor learning may be sensitive to initial conditions and learning\nparameters and more likely to become trapped in local minima. In order to\naddress the above problem, we introduce an adaptive pruning Siamese\nArchitecture based on neuron activation to learn local feature descriptors,\nmaking the network more computationally efficient with an improved recognition\nrate over more complex networks. Our experiments demonstrate that our learned\nlocal feature descriptors outperform the state-of-art methods in patch\nmatching.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 17:27:41 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Huang", "Chong", "", "Tim"], ["Liu", "Qiong", "", "Tim"], ["Chen", "Yan-Ying", "", "Tim"], ["Kwang-Ting", "", "", "Tim"], ["Cheng", "", ""]]}, {"id": "1706.05374", "submitter": "Kamil Ciosek", "authors": "Kamil Ciosek and Shimon Whiteson", "title": "Expected Policy Gradients", "comments": "Conference paper, AAAI-18, 12 pages including supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose expected policy gradients (EPG), which unify stochastic policy\ngradients (SPG) and deterministic policy gradients (DPG) for reinforcement\nlearning. Inspired by expected sarsa, EPG integrates across the action when\nestimating the gradient, instead of relying only on the action in the sampled\ntrajectory. We establish a new general policy gradient theorem, of which the\nstochastic and deterministic policy gradient theorems are special cases. We\nalso prove that EPG reduces the variance of the gradient estimates without\nrequiring deterministic policies and, for the Gaussian case, with no\ncomputational overhead. Finally, we show that it is optimal in a certain sense\nto explore with a Gaussian policy such that the covariance is proportional to\nthe exponential of the scaled Hessian of the critic with respect to the\nactions. We present empirical results confirming that this new form of\nexploration substantially outperforms DPG with the Ornstein-Uhlenbeck heuristic\nin four challenging MuJoCo domains.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 18:27:03 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 16:58:25 GMT"}, {"version": "v3", "created": "Tue, 14 Nov 2017 09:58:50 GMT"}, {"version": "v4", "created": "Thu, 30 Nov 2017 20:08:18 GMT"}, {"version": "v5", "created": "Tue, 20 Mar 2018 10:58:12 GMT"}, {"version": "v6", "created": "Fri, 13 Apr 2018 19:25:12 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ciosek", "Kamil", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1706.05378", "submitter": "Fanny Yang", "authors": "Fanny Yang, Aaditya Ramdas, Kevin Jamieson, Martin J. Wainwright", "title": "A framework for Multi-A(rmed)/B(andit) testing with online FDR control", "comments": "Published as a conference paper at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alternative framework to existing setups for controlling false\nalarms when multiple A/B tests are run over time. This setup arises in many\npractical applications, e.g. when pharmaceutical companies test new treatment\noptions against control pills for different diseases, or when internet\ncompanies test their default webpages versus various alternatives over time.\nOur framework proposes to replace a sequence of A/B tests by a sequence of\nbest-arm MAB instances, which can be continuously monitored by the data\nscientist. When interleaving the MAB tests with an an online false discovery\nrate (FDR) algorithm, we can obtain the best of both worlds: low sample\ncomplexity and any time online FDR control. Our main contributions are: (i) to\npropose reasonable definitions of a null hypothesis for MAB instances; (ii) to\ndemonstrate how one can derive an always-valid sequential p-value that allows\ncontinuous monitoring of each MAB test; and (iii) to show that using rejection\nthresholds of online-FDR algorithms as the confidence levels for the MAB\nalgorithms results in both sample-optimality, high power and low FDR at any\npoint in time. We run extensive simulations to verify our claims, and also\nreport results on real data collected from the New Yorker Cartoon Caption\ncontest.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 18:00:00 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 07:25:12 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Yang", "Fanny", ""], ["Ramdas", "Aaditya", ""], ["Jamieson", "Kevin", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1706.05394", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Stanis{\\l}aw Jastrz\\k{e}bski, Nicolas Ballas, David\n  Krueger, Emmanuel Bengio, Maxinder S. Kanwal, Tegan Maharaj, Asja Fischer,\n  Aaron Courville, Yoshua Bengio, Simon Lacoste-Julien", "title": "A Closer Look at Memorization in Deep Networks", "comments": "Appears in Proceedings of the 34th International Conference on\n  Machine Learning (ICML 2017), Devansh Arpit, Stanis{\\l}aw Jastrz\\k{e}bski,\n  Nicolas Ballas, and David Krueger contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the role of memorization in deep learning, drawing connections to\ncapacity, generalization, and adversarial robustness. While deep networks are\ncapable of memorizing noise data, our results suggest that they tend to\nprioritize learning simple patterns first. In our experiments, we expose\nqualitative differences in gradient-based optimization of deep neural networks\n(DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned\nexplicit regularization (e.g., dropout) we can degrade DNN training performance\non noise datasets without compromising generalization on real data. Our\nanalysis suggests that the notions of effective capacity which are dataset\nindependent are unlikely to explain the generalization performance of deep\nnetworks when trained with gradient based methods because training data itself\nplays an important role in determining the degree of memorization.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 18:11:09 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 14:26:51 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Arpit", "Devansh", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Ballas", "Nicolas", ""], ["Krueger", "David", ""], ["Bengio", "Emmanuel", ""], ["Kanwal", "Maxinder S.", ""], ["Maharaj", "Tegan", ""], ["Fischer", "Asja", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1706.05439", "submitter": "Jack Baker", "authors": "Jack Baker, Paul Fearnhead, Emily B. Fox, Christopher Nemeth", "title": "Control Variates for Stochastic Gradient MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Markov chain Monte Carlo (MCMC) methods scale poorly\nwith dataset size. A popular class of methods for solving this issue is\nstochastic gradient MCMC. These methods use a noisy estimate of the gradient of\nthe log posterior, which reduces the per iteration computational cost of the\nalgorithm. Despite this, there are a number of results suggesting that\nstochastic gradient Langevin dynamics (SGLD), probably the most popular of\nthese methods, still has computational cost proportional to the dataset size.\nWe suggest an alternative log posterior gradient estimate for stochastic\ngradient MCMC, which uses control variates to reduce the variance. We analyse\nSGLD using this gradient estimate, and show that, under log-concavity\nassumptions on the target distribution, the computational cost required for a\ngiven level of accuracy is independent of the dataset size. Next we show that a\ndifferent control variate technique, known as zero variance control variates\ncan be applied to SGMCMC algorithms for free. This post-processing step\nimproves the inference of the algorithm by reducing the variance of the MCMC\noutput. Zero variance control variates rely on the gradient of the log\nposterior; we explore how the variance reduction is affected by replacing this\nwith the noisy gradient estimate calculated by SGMCMC.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 22:00:54 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 09:53:14 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Baker", "Jack", ""], ["Fearnhead", "Paul", ""], ["Fox", "Emily B.", ""], ["Nemeth", "Christopher", ""]]}, {"id": "1706.05446", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Rui Luo, Yuanyuan Liu", "title": "Adversarial Variational Bayes Methods for Tweedie Compound Poisson Mixed\n  Models", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tweedie Compound Poisson-Gamma model is routinely used for modeling\nnon-negative continuous data with a discrete probability mass at zero. Mixed\nmodels with random effects account for the covariance structure related to the\ngrouping hierarchy in the data. An important application of Tweedie mixed\nmodels is pricing the insurance policies, e.g. car insurance. However, the\nintractable likelihood function, the unknown variance function, and the\nhierarchical structure of mixed effects have presented considerable challenges\nfor drawing inferences on Tweedie. In this study, we tackle the Bayesian\nTweedie mixed-effects models via variational inference approaches. In\nparticular, we empower the posterior approximation by implicit models trained\nin an adversarial setting. To reduce the variance of gradients, we\nreparameterize random effects, and integrate out one local latent variable of\nTweedie. We also employ a flexible hyper prior to ensure the richness of the\napproximation. Our method is evaluated on both simulated and real-world data.\nResults show that the proposed method has smaller estimation bias on the random\neffects compared to traditional inference methods including MCMC; it also\nachieves a state-of-the-art predictive performance, meanwhile offering a richer\nestimation of the variance function.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 22:33:13 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 14:27:25 GMT"}, {"version": "v3", "created": "Sun, 16 Jul 2017 23:06:29 GMT"}, {"version": "v4", "created": "Wed, 14 Feb 2018 16:30:46 GMT"}, {"version": "v5", "created": "Sun, 3 Feb 2019 11:33:39 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Liu", "Yuanyuan", ""]]}, {"id": "1706.05477", "submitter": "Ehsan Abbasnejad M", "authors": "M. Ehsan Abbasnejad, Qinfeng Shi, Iman Abbasnejad, Anton van den\n  Hengel, Anthony Dick", "title": "Bayesian Conditional Generative Adverserial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional GANs use a deterministic generator function (typically a neural\nnetwork) to transform a random noise input $z$ to a sample $\\mathbf{x}$ that\nthe discriminator seeks to distinguish. We propose a new GAN called Bayesian\nConditional Generative Adversarial Networks (BC-GANs) that use a random\ngenerator function to transform a deterministic input $y'$ to a sample\n$\\mathbf{x}$. Our BC-GANs extend traditional GANs to a Bayesian framework, and\nnaturally handle unsupervised learning, supervised learning, and\nsemi-supervised learning problems. Experiments show that the proposed BC-GANs\noutperforms the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 05:29:13 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Abbasnejad", "M. Ehsan", ""], ["Shi", "Qinfeng", ""], ["Abbasnejad", "Iman", ""], ["Hengel", "Anton van den", ""], ["Dick", "Anthony", ""]]}, {"id": "1706.05507", "submitter": "Mahesh Chandra Mukkamala", "authors": "Mahesh Chandra Mukkamala, Matthias Hein", "title": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds", "comments": "ICML 2017, 16 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods have become recently very popular, in particular as\nthey have been shown to be useful in the training of deep neural networks. In\nthis paper we have analyzed RMSProp, originally proposed for the training of\ndeep neural networks, in the context of online convex optimization and show\n$\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and\nSC-RMSProp for which we show logarithmic regret bounds for strongly convex\nfunctions. Finally, we demonstrate in the experiments that these new variants\noutperform other adaptive gradient techniques or stochastic gradient descent in\nthe optimization of strongly convex functions as well as in training of deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 09:48:55 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 18:47:37 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1706.05528", "submitter": "Christian Bauckhage", "authors": "Christian Bauckhage, Eduardo Brito, Kostadin Cvejoski, Cesar Ojeda,\n  Rafet Sifa, Stefan Wrobel", "title": "Adiabatic Quantum Computing for Binary Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing for machine learning attracts increasing attention and\nrecent technological developments suggest that especially adiabatic quantum\ncomputing may soon be of practical interest. In this paper, we therefore\nconsider this paradigm and discuss how to adopt it to the problem of binary\nclustering. Numerical simulations demonstrate the feasibility of our approach\nand illustrate how systems of qubits adiabatically evolve towards a solution.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 12:39:03 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Bauckhage", "Christian", ""], ["Brito", "Eduardo", ""], ["Cvejoski", "Kostadin", ""], ["Ojeda", "Cesar", ""], ["Sifa", "Rafet", ""], ["Wrobel", "Stefan", ""]]}, {"id": "1706.05544", "submitter": "Charles Danko", "authors": "Zhong Wang, Tinyi Chu, Lauren A Choate, Charles G Danko", "title": "Rgtsvm: Support Vector Machines on a GPU in R", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rgtsvm provides a fast and flexible support vector machine (SVM)\nimplementation for the R language. The distinguishing feature of Rgtsvm is that\nsupport vector classification and support vector regression tasks are\nimplemented on a graphical processing unit (GPU), allowing the libraries to\nscale to millions of examples with >100-fold improvement in performance over\nexisting implementations. Nevertheless, Rgtsvm retains feature parity and has\nan interface that is compatible with the popular e1071 SVM package in R.\nAltogether, Rgtsvm enables large SVM models to be created by both experienced\nand novice practitioners.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 14:22:46 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Wang", "Zhong", ""], ["Chu", "Tinyi", ""], ["Choate", "Lauren A", ""], ["Danko", "Charles G", ""]]}, {"id": "1706.05563", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Abu Sebastian, Irem Boybat, Manuel Le Gallo, Tomas\n  Tuma, Evangelos Eleftheriou", "title": "Fatiguing STDP: Learning from Spike-Timing Codes in the Presence of Rate\n  Codes", "comments": "8 pages, 8 figures, presented at IJCNN in May 2017", "journal-ref": "2017 International Joint Conference on Neural Networks (IJCNN),\n  Anchorage, AK, 2017, pp. 1823-1830", "doi": "10.1109/IJCNN.2017.7966072", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) could play a key role in unsupervised machine\nlearning applications, by virtue of strengths related to learning from the fine\ntemporal structure of event-based signals. However, some spike-timing-related\nstrengths of SNNs are hindered by the sensitivity of spike-timing-dependent\nplasticity (STDP) rules to input spike rates, as fine temporal correlations may\nbe obstructed by coarser correlations between firing rates. In this article, we\npropose a spike-timing-dependent learning rule that allows a neuron to learn\nfrom the temporally-coded information despite the presence of rate codes. Our\nlong-term plasticity rule makes use of short-term synaptic fatigue dynamics. We\nshow analytically that, in contrast to conventional STDP rules, our fatiguing\nSTDP (FSTDP) helps learn the temporal code, and we derive the necessary\nconditions to optimize the learning process. We showcase the effectiveness of\nFSTDP in learning spike-timing correlations among processes of different rates\nin synthetic data. Finally, we use FSTDP to detect correlations in real-world\nweather data from the United States in an experimental realization of the\nalgorithm that uses a neuromorphic hardware platform comprising phase-change\nmemristive devices. Taken together, our analyses and demonstrations suggest\nthat FSTDP paves the way for the exploitation of the spike-based strengths of\nSNNs in real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 17:11:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Moraitis", "Timoleon", ""], ["Sebastian", "Abu", ""], ["Boybat", "Irem", ""], ["Gallo", "Manuel Le", ""], ["Tuma", "Tomas", ""], ["Eleftheriou", "Evangelos", ""]]}, {"id": "1706.05565", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Chong Wang, Sitao Huang, Dengyong Zhou, Li Deng", "title": "Towards Neural Phrase-based Machine Translation", "comments": "in International Conference on Learning Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Neural Phrase-based Machine Translation (NPMT). Our\nmethod explicitly models the phrase structures in output sequences using\nSleep-WAke Networks (SWAN), a recently proposed segmentation-based sequence\nmodeling method. To mitigate the monotonic alignment requirement of SWAN, we\nintroduce a new layer to perform (soft) local reordering of input sequences.\nDifferent from existing neural machine translation (NMT) approaches, NPMT does\nnot use attention-based decoding mechanisms. Instead, it directly outputs\nphrases in a sequential order and can decode in linear time. Our experiments\nshow that NPMT achieves superior performances on IWSLT 2014\nGerman-English/English-German and IWSLT 2015 English-Vietnamese machine\ntranslation tasks compared with strong NMT baselines. We also observe that our\nmethod produces meaningful phrases in output languages.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 17:36:23 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 00:42:37 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 18:01:35 GMT"}, {"version": "v4", "created": "Sat, 28 Oct 2017 02:56:01 GMT"}, {"version": "v5", "created": "Mon, 29 Jan 2018 23:31:39 GMT"}, {"version": "v6", "created": "Wed, 18 Apr 2018 22:57:38 GMT"}, {"version": "v7", "created": "Wed, 18 Jul 2018 21:57:45 GMT"}, {"version": "v8", "created": "Mon, 24 Sep 2018 10:34:16 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Huang", "Po-Sen", ""], ["Wang", "Chong", ""], ["Huang", "Sitao", ""], ["Zhou", "Dengyong", ""], ["Deng", "Li", ""]]}, {"id": "1706.05585", "submitter": "Tom Hope", "authors": "Tom Hope, Joel Chan, Aniket Kittur, Dafna Shahaf", "title": "Accelerating Innovation Through Analogy Mining", "comments": "KDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large idea repositories (e.g., the U.S. patent database)\ncould significantly accelerate innovation and discovery by providing people\nwith inspiration from solutions to analogous problems. However, finding useful\nanalogies in these large, messy, real-world repositories remains a persistent\nchallenge for either human or automated methods. Previous approaches include\ncostly hand-created databases that have high relational structure (e.g.,\npredicate calculus representations) but are very sparse. Simpler\nmachine-learning/information-retrieval similarity metrics can scale to large,\nnatural-language datasets, but struggle to account for structural similarity,\nwhich is central to analogy. In this paper we explore the viability and value\nof learning simpler structural representations, specifically, \"problem\nschemas\", which specify the purpose of a product and the mechanisms by which it\nachieves that purpose. Our approach combines crowdsourcing and recurrent neural\nnetworks to extract purpose and mechanism vector representations from product\ndescriptions. We demonstrate that these learned vectors allow us to find\nanalogies with higher precision and recall than traditional\ninformation-retrieval methods. In an ideation experiment, analogies retrieved\nby our models significantly increased people's likelihood of generating\ncreative ideas compared to analogies retrieved by traditional methods. Our\nresults suggest a promising approach to enabling computational analogy at scale\nis to learn and leverage weaker structural representations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 22:29:37 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Hope", "Tom", ""], ["Chan", "Joel", ""], ["Kittur", "Aniket", ""], ["Shahaf", "Dafna", ""]]}, {"id": "1706.05598", "submitter": "Tengyu Ma", "authors": "Rong Ge and Tengyu Ma", "title": "On the Optimization Landscape of Tensor Decompositions", "comments": "Best paper in the NIPS 2016 Workshop on Nonconvex Optimization for\n  Machine Learning: Theory and Practice. In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-convex optimization with local search heuristics has been widely used in\nmachine learning, achieving many state-of-art results. It becomes increasingly\nimportant to understand why they can work for these NP-hard problems on typical\ndata. The landscape of many objective functions in learning has been\nconjectured to have the geometric property that \"all local optima are\n(approximately) global optima\", and thus they can be solved efficiently by\nlocal search algorithms. However, establishing such property can be very\ndifficult.\n  In this paper, we analyze the optimization landscape of the random\nover-complete tensor decomposition problem, which has many applications in\nunsupervised learning, especially in learning latent variable models. In\npractice, it can be efficiently solved by gradient ascent on a non-convex\nobjective. We show that for any small constant $\\epsilon > 0$, among the set of\npoints with function values $(1+\\epsilon)$-factor larger than the expectation\nof the function, all the local maxima are approximate global maxima.\nPreviously, the best-known result only characterizes the geometry in small\nneighborhoods around the true components. Our result implies that even with an\ninitialization that is barely better than the random guess, the gradient ascent\nalgorithm is guaranteed to solve this problem.\n  Our main technique uses Kac-Rice formula and random matrix theory. To our\nbest knowledge, this is the first time when Kac-Rice formula is successfully\napplied to counting the number of local minima of a highly-structured random\npolynomial with dependent coefficients.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 01:18:42 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Ge", "Rong", ""], ["Ma", "Tengyu", ""]]}, {"id": "1706.05599", "submitter": "Mohammadhossein Chaghazardi", "authors": "Mohammadhossein Chaghazardi, Shuchin Aeron", "title": "Sample, computation vs storage tradeoffs for classification using tensor\n  subspace models", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we exhibit the tradeoffs between the (training) sample,\ncomputation and storage complexity for the problem of supervised classification\nusing signal subspace estimation. Our main tool is the use of tensor subspaces,\ni.e. subspaces with a Kronecker structure, for embedding the data into lower\ndimensions. Among the subspaces with a Kronecker structure, we show that using\nsubspaces with a hierarchical structure for representing data leads to improved\ntradeoffs. One of the main reasons for the improvement is that embedding data\ninto these hierarchical Kronecker structured subspaces prevents overfitting at\nhigher latent dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 01:36:20 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 07:18:15 GMT"}, {"version": "v3", "created": "Tue, 27 Jun 2017 16:40:44 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Chaghazardi", "Mohammadhossein", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1706.05612", "submitter": "Hamed Masnadi-Shirazi", "authors": "Hamed Masnadi-Shirazi", "title": "Kernel Two-Sample Hypothesis Testing Using Kernel Set Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-sample hypothesis testing problem is studied for the challenging\nscenario of high dimensional data sets with small sample sizes. We show that\nthe two-sample hypothesis testing problem can be posed as a one-class set\nclassification problem. In the set classification problem the goal is to\nclassify a set of data points that are assumed to have a common class. We prove\nthat the average probability of error given a set is less than or equal to the\nBayes error and decreases as a power of $n$ number of sample data points in the\nset. We use the positive definite Set Kernel for directly mapping sets of data\nto an associated Reproducing Kernel Hilbert Space, without the need to learn a\nprobability distribution. We specifically solve the two-sample hypothesis\ntesting problem using a one-class SVM in conjunction with the proposed Set\nKernel. We compare the proposed method with the Maximum Mean Discrepancy,\nF-Test and T-Test methods on a number of challenging simulated high dimensional\nand small sample size data. We also perform two-sample hypothesis testing\nexperiments on six cancer gene expression data sets and achieve zero type-I and\ntype-II error results on all data sets.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 06:51:06 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 12:41:33 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Masnadi-Shirazi", "Hamed", ""]]}, {"id": "1706.05683", "submitter": "Alfred Bourely", "authors": "Alfred Bourely, John Patrick Boueri, Krzysztof Choromonski", "title": "Sparse Neural Networks Topologies", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Sparse Neural Network architectures that are based on random or\nstructured bipartite graph topologies. Sparse architectures provide compression\nof the models learned and speed-ups of computations, they can also surpass\ntheir unstructured or fully connected counterparts. As we show, even more\ncompact topologies of the so-called SNN (Sparse Neural Network) can be achieved\nwith the use of structured graphs of connections between consecutive layers of\nneurons. In this paper, we investigate how the accuracy and training speed of\nthe models depend on the topology and sparsity of the neural network. Previous\napproaches using sparcity are all based on fully connected neural network\nmodels and create sparcity during training phase, instead we explicitly define\na sparse architectures of connections before the training. Building compact\nneural network models is coherent with empirical observations showing that\nthere is much redundancy in learned neural network models. We show\nexperimentally that the accuracy of the models learned with neural networks\ndepends on expander-like properties of the underlying topologies such as the\nspectral gap and algebraic connectivity rather than the density of the graphs\nof connections.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 16:30:25 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Bourely", "Alfred", ""], ["Boueri", "John Patrick", ""], ["Choromonski", "Krzysztof", ""]]}, {"id": "1706.05730", "submitter": "Ivica Obadi\\'c", "authors": "Ivica Obadi\\'c, Gjorgji Madjarov (1), Ivica Dimitrovski (1), Dejan\n  Gjorgjevikj (1) ((1) Faculty of Computer Science and Engineering, Ss. Cyril\n  and Methodius University, Skopje, Macedonia)", "title": "Addressing Item-Cold Start Problem in Recommendation Systems using Model\n  Based Approach and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional recommendation systems rely on past usage data in order to\ngenerate new recommendations. Those approaches fail to generate sensible\nrecommendations for new users and items into the system due to missing\ninformation about their past interactions. In this paper, we propose a solution\nfor successfully addressing item-cold start problem which uses model-based\napproach and recent advances in deep learning. In particular, we use latent\nfactor model for recommendation, and predict the latent factors from item's\ndescriptions using convolutional neural network when they cannot be obtained\nfrom usage data. Latent factors obtained by applying matrix factorization to\nthe available usage data are used as ground truth to train the convolutional\nneural network. To create latent factor representations for the new items, the\nconvolutional neural network uses their textual description. The results from\nthe experiments reveal that the proposed approach significantly outperforms\nseveral baseline estimators.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 21:51:10 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Obadi\u0107", "Ivica", ""], ["Madjarov", "Gjorgji", ""], ["Dimitrovski", "Ivica", ""], ["Gjorgjevikj", "Dejan", ""]]}, {"id": "1706.05736", "submitter": "Joel Tropp", "authors": "Joel A. Tropp, Alp Yurtsever, Madeleine Udell, Volkan Cevher", "title": "Fixed-Rank Approximation of a Positive-Semidefinite Matrix from\n  Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several important applications, such as streaming PCA and semidefinite\nprogramming, involve a large-scale positive-semidefinite (psd) matrix that is\npresented as a sequence of linear updates. Because of storage limitations, it\nmay only be possible to retain a sketch of the psd matrix. This paper develops\na new algorithm for fixed-rank psd approximation from a sketch. The approach\ncombines the Nystrom approximation with a novel mechanism for rank truncation.\nTheoretical analysis establishes that the proposed method can achieve any\nprescribed relative error in the Schatten 1-norm and that it exploits the\nspectral decay of the input matrix. Computer experiments show that the proposed\nmethod dominates alternative techniques for fixed-rank psd matrix approximation\nacross a wide range of examples.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 22:13:45 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Tropp", "Joel A.", ""], ["Yurtsever", "Alp", ""], ["Udell", "Madeleine", ""], ["Cevher", "Volkan", ""]]}, {"id": "1706.05749", "submitter": "Nick Erickson", "authors": "Nick Erickson and Qi Zhao", "title": "Dex: Incremental Learning for Complex Environments in Deep Reinforcement\n  Learning", "comments": "NIPS 2017 submission, 10 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Dex, a reinforcement learning environment toolkit\nspecialized for training and evaluation of continual learning methods as well\nas general reinforcement learning problems. We also present the novel continual\nlearning method of incremental learning, where a challenging environment is\nsolved using optimal weight initialization learned from first solving a similar\neasier environment. We show that incremental learning can produce vastly\nsuperior results than standard methods by providing a strong baseline method\nacross ten Dex environments. We finally develop a saliency method for\nqualitative analysis of reinforcement learning, which shows the impact\nincremental learning has on network attention.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 00:16:24 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Erickson", "Nick", ""], ["Zhao", "Qi", ""]]}, {"id": "1706.05801", "submitter": "Karim Abou-Moustafa", "authors": "Karim Abou-Moustafa and Csaba Szepesvari", "title": "An a Priori Exponential Tail Bound for k-Folds Cross-Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a priori generalization bounds developed in terms of\ncross-validation estimates and the stability of learners. In particular, we\nfirst derive an exponential Efron-Stein type tail inequality for the\nconcentration of a general function of n independent random variables. Next,\nunder some reasonable notion of stability, we use this exponential tail bound\nto analyze the concentration of the k-fold cross-validation (KFCV) estimate\naround the true risk of a hypothesis generated by a general learning rule.\nWhile the accumulated literature has often attributed this concentration to the\nbias and variance of the estimator, our bound attributes this concentration to\nthe stability of the learning rule and the number of folds k. This insight\nraises valid concerns related to the practical use of KFCV and suggests\nresearch directions to obtain reliable empirical estimates of the actual risk.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 06:38:55 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Abou-Moustafa", "Karim", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1706.05806", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein", "title": "SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning\n  Dynamics and Interpretability", "comments": "Accepted to NIPS 2017, code: https://github.com/google/svcca/ , new\n  plots on Imagenet", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new technique, Singular Vector Canonical Correlation Analysis\n(SVCCA), a tool for quickly comparing two representations in a way that is both\ninvariant to affine transform (allowing comparison between different layers and\nnetworks) and fast to compute (allowing more comparisons to be calculated than\nwith previous methods). We deploy this tool to measure the intrinsic\ndimensionality of layers, showing in some cases needless over-parameterization;\nto probe learning dynamics throughout training, finding that networks converge\nto final representations from the bottom up; to show where class-specific\ninformation in networks is formed; and to suggest new training regimes that\nsimultaneously save computation and overfit less. Code:\nhttps://github.com/google/svcca/\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 07:09:20 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 08:36:27 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Raghu", "Maithra", ""], ["Gilmer", "Justin", ""], ["Yosinski", "Jason", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1706.05928", "submitter": "Carlos M. Ala\\'iz", "authors": "Carlos M. Ala\\'iz and Johan A. K. Suykens", "title": "Modified Frank-Wolfe Algorithm for Enhanced Sparsity in Support Vector\n  Machine Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a new algorithm for training a re-weighted L2 Support\nVector Machine (SVM), inspired on the re-weighted Lasso algorithm of Cand\\`es\net al. and on the equivalence between Lasso and SVM shown recently by Jaggi. In\nparticular, the margin required for each training vector is set independently,\ndefining a new weighted SVM model. These weights are selected to be binary, and\nthey are automatically adapted during the training of the model, resulting in a\nvariation of the Frank-Wolfe optimization algorithm with essentially the same\ncomputational complexity as the original algorithm. As shown experimentally,\nthis algorithm is computationally cheaper to apply since it requires less\niterations to converge, and it produces models with a sparser representation in\nterms of support vectors and which are more stable with respect to the\nselection of the regularization hyper-parameter.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 13:31:09 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 13:28:15 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Ala\u00edz", "Carlos M.", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1706.05940", "submitter": "Samuel Perreault", "authors": "Samuel Perreault, Thierry Duchesne and Johanna G. Ne\\v{s}lehov\\'a", "title": "Detection of Block-Exchangeable Structure in Large-Scale Correlation\n  Matrices", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmva.2018.10.009", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation matrices are omnipresent in multivariate data analysis. When the\nnumber d of variables is large, the sample estimates of correlation matrices\nare typically noisy and conceal underlying dependence patterns. We consider the\ncase when the variables can be grouped into K clusters with exchangeable\ndependence; this assumption is often made in applications, e.g., in finance and\neconometrics. Under this partial exchangeability condition, the corresponding\ncorrelation matrix has a block structure and the number of unknown parameters\nis reduced from d(d-1)/2 to at most K(K+1)/2. We propose a robust algorithm\nbased on Kendall's rank correlation to identify the clusters without assuming\nthe knowledge of K a priori or anything about the margins except continuity.\nThe corresponding block-structured estimator performs considerably better than\nthe sample Kendall rank correlation matrix when K < d. The new estimator can\nalso be much more efficient in finite samples even in the unstructured case K =\nd, although there is no gain asymptotically. When the distribution of the data\nis elliptical, the results extend to linear correlation matrices and their\ninverses. The procedure is illustrated on financial stock returns.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 13:45:21 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 16:39:19 GMT"}, {"version": "v3", "created": "Wed, 24 Oct 2018 15:01:54 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Perreault", "Samuel", ""], ["Duchesne", "Thierry", ""], ["Ne\u0161lehov\u00e1", "Johanna G.", ""]]}, {"id": "1706.05966", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa, Michael Weisz, and Mihaela van der Schaar", "title": "Deep Counterfactual Networks with Propensity-Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for inferring the individualized causal effects\nof a treatment (intervention) from observational data. Our approach\nconceptualizes causal inference as a multitask learning problem; we model a\nsubject's potential outcomes using a deep multitask network with a set of\nshared layers among the factual and counterfactual outcomes, and a set of\noutcome-specific layers. The impact of selection bias in the observational data\nis alleviated via a propensity-dropout regularization scheme, in which the\nnetwork is thinned for every training example via a dropout probability that\ndepends on the associated propensity score. The network is trained in\nalternating phases, where in each phase we use the training examples of one of\nthe two potential outcomes (treated and control populations) to update the\nweights of the shared layers and the respective outcome-specific layers.\nExperiments conducted on data based on a real-world observational study show\nthat our algorithm outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 14:12:12 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["Weisz", "Michael", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1706.06060", "submitter": "Scott Lundberg", "authors": "Scott M. Lundberg and Su-In Lee", "title": "Consistent feature attribution for tree ensembles", "comments": "presented at 2017 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2017), Sydney, NSW, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Note that a newer expanded version of this paper is now available at:\narXiv:1802.03888\n  It is critical in many applications to understand what features are important\nfor a model, and why individual predictions were made. For tree ensemble\nmethods these questions are usually answered by attributing importance values\nto input features, either globally or for a single prediction. Here we show\nthat current feature attribution methods are inconsistent, which means changing\nthe model to rely more on a given feature can actually decrease the importance\nassigned to that feature. To address this problem we develop fast exact\nsolutions for SHAP (SHapley Additive exPlanation) values, which were recently\nshown to be the unique additive feature attribution method based on conditional\nexpectations that is both consistent and locally accurate. We integrate these\nimprovements into the latest version of XGBoost, demonstrate the\ninconsistencies of current methods, and show how using SHAP values results in\nsignificantly improved supervised clustering performance. Feature importance\nvalues are a key part of understanding widely used models such as gradient\nboosting trees and random forests, so improvements to them have broad practical\nimplications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 17:03:46 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 19:28:56 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 21:33:01 GMT"}, {"version": "v4", "created": "Tue, 8 Aug 2017 01:18:43 GMT"}, {"version": "v5", "created": "Sun, 11 Feb 2018 21:44:49 GMT"}, {"version": "v6", "created": "Sat, 17 Feb 2018 01:11:50 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Lundberg", "Scott M.", ""], ["Lee", "Su-In", ""]]}, {"id": "1706.06066", "submitter": "Tuo Zhao", "authors": "Xingguo Li, Lin F. Yang, Jason Ge, Jarvis Haupt, Tong Zhang, Tuo Zhao", "title": "On Quadratic Convergence of DC Proximal Newton Algorithm for Nonconvex\n  Sparse Learning in High Dimensions", "comments": "36 pages, 5 figures, 1 table, Accepted at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a DC proximal Newton algorithm for solving nonconvex regularized\nsparse learning problems in high dimensions. Our proposed algorithm integrates\nthe proximal Newton algorithm with multi-stage convex relaxation based on the\ndifference of convex (DC) programming, and enjoys both strong computational and\nstatistical guarantees. Specifically, by leveraging a sophisticated\ncharacterization of sparse modeling structures/assumptions (i.e., local\nrestricted strong convexity and Hessian smoothness), we prove that within each\nstage of convex relaxation, our proposed algorithm achieves (local) quadratic\nconvergence, and eventually obtains a sparse approximate local optimum with\noptimal statistical properties after only a few convex relaxations. Numerical\nexperiments are provided to support our theory.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 17:15:47 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 19:54:38 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 16:30:14 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Li", "Xingguo", ""], ["Yang", "Lin F.", ""], ["Ge", "Jason", ""], ["Haupt", "Jarvis", ""], ["Zhang", "Tong", ""], ["Zhao", "Tuo", ""]]}, {"id": "1706.06083", "submitter": "Dimitris Tsipras", "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris\n  Tsipras, Adrian Vladu", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "comments": "ICLR'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated that deep neural networks are vulnerable to\nadversarial examples---inputs that are almost indistinguishable from natural\ndata and yet classified incorrectly by the network. In fact, some of the latest\nfindings suggest that the existence of adversarial attacks may be an inherent\nweakness of deep learning models. To address this problem, we study the\nadversarial robustness of neural networks through the lens of robust\noptimization. This approach provides us with a broad and unifying view on much\nof the prior work on this topic. Its principled nature also enables us to\nidentify methods for both training and attacking neural networks that are\nreliable and, in a certain sense, universal. In particular, they specify a\nconcrete security guarantee that would protect against any adversary. These\nmethods let us train networks with significantly improved resistance to a wide\nrange of adversarial attacks. They also suggest the notion of security against\na first-order adversary as a natural and broad security guarantee. We believe\nthat robustness against such well-defined classes of adversaries is an\nimportant stepping stone towards fully resistant deep learning models. Code and\npre-trained models are available at https://github.com/MadryLab/mnist_challenge\nand https://github.com/MadryLab/cifar10_challenge.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 17:53:11 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 17:34:00 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 01:16:40 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 18:53:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Madry", "Aleksander", ""], ["Makelov", "Aleksandar", ""], ["Schmidt", "Ludwig", ""], ["Tsipras", "Dimitris", ""], ["Vladu", "Adrian", ""]]}, {"id": "1706.06136", "submitter": "Alexander Gates", "authors": "Alexander J. Gates, Ian B. Wood, William P. Hetrick and Yong-Yeol Ahn", "title": "Element-centric clustering comparison unifies overlaps and hierarchy", "comments": null, "journal-ref": "Scientific Reports 9, 8574 (2019)", "doi": "10.1038/s41598-019-44892-y", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most universal approaches for understanding complex\ndata. A pivotal aspect of clustering analysis is quantitatively comparing\nclusterings; clustering comparison is the basis for many tasks such as\nclustering evaluation, consensus clustering, and tracking the temporal\nevolution of clusters. In particular, the extrinsic evaluation of clustering\nmethods requires comparing the uncovered clusterings to planted clusterings or\nknown metadata. Yet, as we demonstrate, existing clustering comparison measures\nhave critical biases which undermine their usefulness, and no measure\naccommodates both overlapping and hierarchical clusterings. Here we unify the\ncomparison of disjoint, overlapping, and hierarchically structured clusterings\nby proposing a new element-centric framework: elements are compared based on\nthe relationships induced by the cluster structure, as opposed to the\ntraditional cluster-centric philosophy. We demonstrate that, in contrast to\nstandard clustering similarity measures, our framework does not suffer from\ncritical biases and naturally provides unique insights into how the clusterings\ndiffer. We illustrate the strengths of our framework by revealing new insights\ninto the organization of clusters in two applications: the improved\nclassification of schizophrenia based on the overlapping and hierarchical\ncommunity structure of fMRI brain networks, and the disentanglement of various\nsocial homophily factors in Facebook social networks. The universality of\nclustering suggests far-reaching impact of our framework throughout all areas\nof science.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 18:51:43 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 15:08:09 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Gates", "Alexander J.", ""], ["Wood", "Ian B.", ""], ["Hetrick", "William P.", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "1706.06150", "submitter": "Cole Brokamp", "authors": "Cole Brokamp, MB Rao, Patrick Ryan, Roman Jandarov", "title": "A Comparison of Resampling and Recursive Partitioning Methods in Random\n  Forest for Estimating the Asymptotic Variance Using the Infinitesimal\n  Jackknife", "comments": null, "journal-ref": "A comparison of resampling and recursive partitioning methods in\n  random forest for estimating the asymptotic variance using the infinitesimal\n  jackknife. Stat. 6(1). 360-372. 2017", "doi": "10.1002/sta4.162", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infinitesimal jackknife (IJ) has recently been applied to the random\nforest to estimate its prediction variance. These theorems were verified under\na traditional random forest framework which uses classification and regression\ntrees (CART) and bootstrap resampling. However, random forests using\nconditional inference (CI) trees and subsampling have been found to be not\nprone to variable selection bias. Here, we conduct simulation experiments using\na novel approach to explore the applicability of the IJ to random forests using\nvariations on the resampling method and base learner. Test data points were\nsimulated and each trained using random forest on one hundred simulated\ntraining data sets using different combinations of resampling and base\nlearners. Using CI trees instead of traditional CART trees as well as using\nsubsampling instead of bootstrap sampling resulted in a much more accurate\nestimation of prediction variance when using the IJ. The random forest\nvariations here have been incorporated into an open source software package for\nthe R programming language.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 19:32:05 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 19:53:16 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Brokamp", "Cole", ""], ["Rao", "MB", ""], ["Ryan", "Patrick", ""], ["Jandarov", "Roman", ""]]}, {"id": "1706.06178", "submitter": "Jan Reubold", "authors": "Jan Reubold, Thorsten Strufe and Ulf Brefeld", "title": "Infinite Mixture Model of Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian nonparametric mixture model for prediction- and\ninformation extraction tasks with an efficient inference scheme. It models\ncategorical-valued time series that exhibit dynamics from multiple underlying\npatterns (e.g. user behavior traces). We simplify the idea of capturing these\npatterns by hierarchical hidden Markov models (HHMMs) - and extend the existing\napproaches by the additional representation of structural information. Our\nempirical results are based on both synthetic- and real world data. They\nindicate that the results are easily interpretable, and that the model excels\nat segmentation and prediction performance: it successfully identifies the\ngenerating patterns and can be used for effective prediction of future\nobservations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 21:08:51 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Reubold", "Jan", ""], ["Strufe", "Thorsten", ""], ["Brefeld", "Ulf", ""]]}, {"id": "1706.06195", "submitter": "Ivo Gon\\c{c}alves", "authors": "Ivo Gon\\c{c}alves, Sara Silva, Carlos M. Fonseca, Mauro Castelli", "title": "Unsure When to Stop? Ask Your Semantic Neighbors", "comments": null, "journal-ref": null, "doi": "10.1145/3071178.3071328", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In iterative supervised learning algorithms it is common to reach a point in\nthe search where no further induction seems to be possible with the available\ndata. If the search is continued beyond this point, the risk of overfitting\nincreases significantly. Following the recent developments in inductive\nsemantic stochastic methods, this paper studies the feasibility of using\ninformation gathered from the semantic neighborhood to decide when to stop the\nsearch. Two semantic stopping criteria are proposed and experimentally assessed\nin Geometric Semantic Genetic Programming (GSGP) and in the Semantic Learning\nMachine (SLM) algorithm (the equivalent algorithm for neural networks). The\nexperiments are performed on real-world high-dimensional regression datasets.\nThe results show that the proposed semantic stopping criteria are able to\ndetect stopping points that result in a competitive generalization for both\nGSGP and SLM. This approach also yields computationally efficient algorithms as\nit allows the evolution of neural networks in less than 3 seconds on average,\nand of GP trees in at most 10 seconds. The usage of the proposed semantic\nstopping criteria in conjunction with the computation of optimal\nmutation/learning steps also results in small trees and neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 22:29:08 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Gon\u00e7alves", "Ivo", ""], ["Silva", "Sara", ""], ["Fonseca", "Carlos M.", ""], ["Castelli", "Mauro", ""]]}, {"id": "1706.06216", "submitter": "Yujia Li", "authors": "Yujia Li, Alexander Schwing, Kuan-Chieh Wang, Richard Zemel", "title": "Dualing GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GANs) are a promising technique for modeling a\ndistribution from samples. It is however well known that GAN training suffers\nfrom instability due to the nature of its maximin formulation. In this paper,\nwe explore ways to tackle the instability problem by dualizing the\ndiscriminator. We start from linear discriminators in which case conjugate\nduality provides a mechanism to reformulate the saddle point objective into a\nmaximization problem, such that both the generator and the discriminator of\nthis 'dualing GAN' act in concert. We then demonstrate how to extend this\nintuition to non-linear formulations. For GANs with linear discriminators our\napproach is able to remove the instability in training, while for GANs with\nnonlinear discriminators our approach provides an alternative to the commonly\nused GAN training algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 23:28:49 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Li", "Yujia", ""], ["Schwing", "Alexander", ""], ["Wang", "Kuan-Chieh", ""], ["Zemel", "Richard", ""]]}, {"id": "1706.06230", "submitter": "Gaurav Thakur", "authors": "Gaurav Thakur", "title": "A Bayesian algorithm for detecting identity matches and fraud in image\n  databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A statistical algorithm for categorizing different types of matches and fraud\nin image databases is presented. The approach is based on a generative model of\na graph representing images and connections between pairs of identities,\ntrained using properties of a matching algorithm between images.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 00:43:22 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Thakur", "Gaurav", ""]]}, {"id": "1706.06296", "submitter": "Bharath Sriperumbudur", "authors": "Bharath Sriperumbudur and Nicholas Sterge", "title": "Approximate Kernel PCA Using Random Features: Computational vs.\n  Statistical Trade-off", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are powerful learning methodologies that provide a simple way\nto construct nonlinear algorithms from linear ones. Despite their popularity,\nthey suffer from poor scalability in big data scenarios. Various approximation\nmethods, including random feature approximation, have been proposed to\nalleviate the problem. However, the statistical consistency of most of these\napproximate kernel methods is not well understood except for kernel ridge\nregression wherein it has been shown that the random feature approximation is\nnot only computationally efficient but also statistically consistent with a\nminimax optimal rate of convergence. In this paper, we investigate the efficacy\nof random feature approximation in the context of kernel principal component\nanalysis (KPCA) by studying the trade-off between computational and statistical\nbehaviors of approximate KPCA. We show that the approximate KPCA is both\ncomputationally and statistically efficient compared to KPCA in terms of the\nerror associated with reconstructing a kernel function based on its projection\nonto the corresponding eigenspaces. The analysis hinges on Bernstein-type\ninequalities for the operator and Hilbert-Schmidt norms of a self-adjoint\nHilbert-Schmidt operator-valued U-statistics, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 07:36:13 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 13:19:25 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 20:51:19 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Sriperumbudur", "Bharath", ""], ["Sterge", "Nicholas", ""]]}, {"id": "1706.06341", "submitter": "Yao Wang", "authors": "Kaidong Wang, Yao Wang, Qian Zhao, Deyu Meng and Zongben Xu", "title": "SPLBoost: An Improved Robust Boosting Algorithm Based on Self-paced\n  Learning", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that Boosting can be interpreted as a gradient descent technique\nto minimize an underlying loss function. Specifically, the underlying loss\nbeing minimized by the traditional AdaBoost is the exponential loss, which is\nproved to be very sensitive to random noise/outliers. Therefore, several\nBoosting algorithms, e.g., LogitBoost and SavageBoost, have been proposed to\nimprove the robustness of AdaBoost by replacing the exponential loss with some\ndesigned robust loss functions. In this work, we present a new way to robustify\nAdaBoost, i.e., incorporating the robust learning idea of Self-paced Learning\n(SPL) into Boosting framework. Specifically, we design a new robust Boosting\nalgorithm based on SPL regime, i.e., SPLBoost, which can be easily implemented\nby slightly modifying off-the-shelf Boosting packages. Extensive experiments\nand a theoretical characterization are also carried out to illustrate the\nmerits of the proposed SPLBoost.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 09:31:30 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 14:04:46 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Wang", "Kaidong", ""], ["Wang", "Yao", ""], ["Zhao", "Qian", ""], ["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}, {"id": "1706.06348", "submitter": "Han Zhao", "authors": "Han Zhao, Geoff Gordon", "title": "Frank-Wolfe Optimization for Symmetric-NMF under Simplicial Constraint", "comments": "In Proceedings of the Thirty-Fourth Conference on Uncertainty in\n  Artificial Intelligence, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric nonnegative matrix factorization has found abundant applications in\nvarious domains by providing a symmetric low-rank decomposition of nonnegative\nmatrices. In this paper we propose a Frank-Wolfe (FW) solver to optimize the\nsymmetric nonnegative matrix factorization problem under a simplicial\nconstraint, which has recently been proposed for probabilistic clustering.\nCompared with existing solutions, this algorithm is simple to implement, and\nhas no hyperparameters to be tuned. Building on the recent advances of FW\nalgorithms in nonconvex optimization, we prove an $O(1/\\varepsilon^2)$\nconvergence rate to $\\varepsilon$-approximate KKT points, via a tight bound\n$\\Theta(n^2)$ on the curvature constant, which matches the best known result in\nunconstrained nonconvex setting using gradient methods. Numerical results\ndemonstrate the effectiveness of our algorithm. As a side contribution, we\nconstruct a simple nonsmooth convex problem where the FW algorithm fails to\nconverge to the optimum. This result raises an interesting question about\nnecessary conditions of the success of the FW algorithm on convex problems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 10:03:29 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 06:05:16 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 04:12:29 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Zhao", "Han", ""], ["Gordon", "Geoff", ""]]}, {"id": "1706.06383", "submitter": "Misha Denil", "authors": "Misha Denil, Sergio G\\'omez Colmenarejo, Serkan Cabi, David Saxton,\n  Nando de Freitas", "title": "Programmable Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build deep RL agents that execute declarative programs expressed in formal\nlanguage. The agents learn to ground the terms in this language in their\nenvironment, and can generalize their behavior at test time to execute new\nprograms that refer to objects that were not referenced during training. The\nagents develop disentangled interpretable representations that allow them to\ngeneralize to a wide variety of zero-shot semantic tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 12:19:34 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Denil", "Misha", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Cabi", "Serkan", ""], ["Saxton", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1706.06428", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu, Dieterich Lawson, Yuping Luo, George Tucker, Kevin\n  Swersky, Ilya Sutskever, Navdeep Jaitly", "title": "An online sequence-to-sequence model for noisy speech recognition", "comments": "arXiv admin note: substantial text overlap with arXiv:1608.01281", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have long been the dominant approach for speech\nrecognition. The success of these models however relies on the use of\nsophisticated recipes and complicated machinery that is not easily accessible\nto non-practitioners. Recent innovations in Deep Learning have given rise to an\nalternative - discriminative models called Sequence-to-Sequence models, that\ncan almost match the accuracy of state of the art generative models. While\nthese models are easy to train as they can be trained end-to-end in a single\nstep, they have a practical limitation that they can only be used for offline\nrecognition. This is because the models require that the entirety of the input\nsequence be available at the beginning of inference, an assumption that is not\nvalid for instantaneous speech recognition. To address this problem, online\nsequence-to-sequence models were recently introduced. These models are able to\nstart producing outputs as data arrives, and the model feels confident enough\nto output partial transcripts. These models, like sequence-to-sequence are\ncausal - the output produced by the model until any time, $t$, affects the\nfeatures that are computed subsequently. This makes the model inherently more\npowerful than generative models that are unable to change features that are\ncomputed from the data. This paper highlights two main contributions - an\nimprovement to online sequence-to-sequence model training, and its application\nto noisy settings with mixed speech from two speakers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 20:58:43 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Lawson", "Dieterich", ""], ["Luo", "Yuping", ""], ["Tucker", "George", ""], ["Swersky", "Kevin", ""], ["Sutskever", "Ilya", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1706.06491", "submitter": "Sanket Kamthe", "authors": "Sanket Kamthe and Marc Peter Deisenroth", "title": "Data-Efficient Reinforcement Learning with Probabilistic Model\n  Predictive Control", "comments": "Accepted at AISTATS 2018,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Trial-and-error based reinforcement learning (RL) has seen rapid advancements\nin recent times, especially with the advent of deep neural networks. However,\nthe majority of autonomous RL algorithms require a large number of interactions\nwith the environment. A large number of interactions may be impractical in many\nreal-world applications, such as robotics, and many practical systems have to\nobey limitations in the form of state space or control constraints. To reduce\nthe number of system interactions while simultaneously handling constraints, we\npropose a model-based RL framework based on probabilistic Model Predictive\nControl (MPC). In particular, we propose to learn a probabilistic transition\nmodel using Gaussian Processes (GPs) to incorporate model uncertainty into\nlong-term predictions, thereby, reducing the impact of model errors. We then\nuse MPC to find a control sequence that minimises the expected long-term cost.\nWe provide theoretical guarantees for first-order optimality in the GP-based\ntransition models with deterministic approximate inference for long-term\nplanning. We demonstrate that our approach does not only achieve\nstate-of-the-art data efficiency, but also is a principled way for RL in\nconstrained environments.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 14:44:25 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 15:40:40 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Kamthe", "Sanket", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1706.06516", "submitter": "Justin Eldridge", "authors": "Justin Eldridge, Mikhail Belkin, Yusu Wang", "title": "Unperturbed: spectral analysis beyond Davis-Kahan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical matrix perturbation results, such as Weyl's theorem for eigenvalues\nand the Davis-Kahan theorem for eigenvectors, are general purpose. These\nclassical bounds are tight in the worst case, but in many settings sub-optimal\nin the typical case. In this paper, we present perturbation bounds which\nconsider the nature of the perturbation and its interaction with the\nunperturbed structure in order to obtain significant improvements over the\nclassical theory in many scenarios, such as when the perturbation is random. We\ndemonstrate the utility of these new results by analyzing perturbations in the\nstochastic blockmodel where we derive much tighter bounds than provided by the\nclassical theory. We use our new perturbation theory to show that a very simple\nand natural clustering algorithm -- whose analysis was difficult using the\nclassical tools -- nevertheless recovers the communities of the blockmodel\nexactly even in very sparse graphs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 15:26:45 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Eldridge", "Justin", ""], ["Belkin", "Mikhail", ""], ["Wang", "Yusu", ""]]}, {"id": "1706.06529", "submitter": "Justin Domke", "authors": "Justin Domke", "title": "A Divergence Bound for Hybrids of MCMC and Variational Inference and an\n  Application to Langevin Dynamics and SGVI", "comments": "International Conference on Machine Learning (ICML) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two popular classes of methods for approximate inference are Markov chain\nMonte Carlo (MCMC) and variational inference. MCMC tends to be accurate if run\nfor a long enough time, while variational inference tends to give better\napproximations at shorter time horizons. However, the amount of time needed for\nMCMC to exceed the performance of variational methods can be quite high,\nmotivating more fine-grained tradeoffs. This paper derives a distribution over\nvariational parameters, designed to minimize a bound on the divergence between\nthe resulting marginal distribution and the target, and gives an example of how\nto sample from this distribution in a way that interpolates between the\nbehavior of existing methods based on Langevin dynamics and stochastic gradient\nvariational inference (SGVI).\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 16:06:50 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Domke", "Justin", ""]]}, {"id": "1706.06544", "submitter": "Taylor Killian", "authors": "Taylor Killian, Samuel Daulton, George Konidaris, Finale Doshi-Velez", "title": "Robust and Efficient Transfer Learning with Hidden-Parameter Markov\n  Decision Processes", "comments": "To appear at NIPS 2017, selected for an oral presentation. 17 pages\n  (incl references and appendix). Example code can be found at\n  http://github.com/dtak/hip-mdp-public", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new formulation of the Hidden Parameter Markov Decision\nProcess (HiP-MDP), a framework for modeling families of related tasks using\nlow-dimensional latent embeddings. Our new framework correctly models the joint\nuncertainty in the latent parameters and the state space. We also replace the\noriginal Gaussian Process-based model with a Bayesian Neural Network, enabling\nmore scalable inference. Thus, we expand the scope of the HiP-MDP to\napplications with higher dimensions and more complex dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 16:51:46 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 01:35:08 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 02:50:56 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Killian", "Taylor", ""], ["Daulton", "Samuel", ""], ["Konidaris", "George", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1706.06549", "submitter": "Sundeep Rangan", "authors": "Alyson K. Fletcher and Sundeep Rangan", "title": "Inference in Deep Networks in High Dimensions", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative networks provide a powerful tool for modeling complex data in\na wide range of applications. In inverse problems that use these networks as\ngenerative priors on data, one must often perform inference of the inputs of\nthe networks from the outputs. Inference is also required for sampling during\nstochastic training on these generative models. This paper considers inference\nin a deep stochastic neural network where the parameters (e.g., weights, biases\nand activation functions) are known and the problem is to estimate the values\nof the input and hidden units from the output. While several approximate\nalgorithms have been proposed for this task, there are few analytic tools that\ncan provide rigorous guarantees in the reconstruction error. This work presents\na novel and computationally tractable output-to-input inference method called\nMulti-Layer Vector Approximate Message Passing (ML-VAMP). The proposed\nalgorithm, derived from expectation propagation, extends earlier AMP methods\nthat are known to achieve the replica predictions for optimality in simple\nlinear inverse problems. Our main contribution shows that the mean-squared\nerror (MSE) of ML-VAMP can be exactly predicted in a certain large system limit\n(LSL) where the numbers of layers is fixed and weight matrices are random and\northogonally-invariant with dimensions that grow to infinity. ML-VAMP is thus a\nprincipled method for output-to-input inference in deep networks with a\nrigorous and precise performance achievability result in high dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 17:04:33 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Fletcher", "Alyson K.", ""], ["Rangan", "Sundeep", ""]]}, {"id": "1706.06551", "submitter": "Karl Moritz Hermann", "authors": "Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan\n  Faulkner, Hubert Soyer, David Szepesvari, Wojciech Marian Czarnecki, Max\n  Jaderberg, Denis Teplyashin, Marcus Wainwright, Chris Apps, Demis Hassabis,\n  Phil Blunsom", "title": "Grounded Language Learning in a Simulated 3D World", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are increasingly surrounded by artificially intelligent technology that\ntakes decisions and executes actions on our behalf. This creates a pressing\nneed for general means to communicate with, instruct and guide artificial\nagents, with human language the most compelling means for such communication.\nTo achieve this in a scalable fashion, agents must be able to relate language\nto the world and to actions; that is, their understanding of language must be\ngrounded and embodied. However, learning grounded language is a notoriously\nchallenging problem in artificial intelligence research. Here we present an\nagent that learns to interpret language in a simulated 3D environment where it\nis rewarded for the successful execution of written instructions. Trained via a\ncombination of reinforcement and unsupervised learning, and beginning with\nminimal prior knowledge, the agent learns to relate linguistic symbols to\nemergent perceptual representations of its physical surroundings and to\npertinent sequences of actions. The agent's comprehension of language extends\nbeyond its prior experience, enabling it to apply familiar language to\nunfamiliar situations and to interpret entirely novel instructions. Moreover,\nthe speed with which this agent learns new words increases as its semantic\nknowledge grows. This facility for generalising and bootstrapping semantic\nknowledge indicates the potential of the present approach for reconciling\nambiguous natural language with the complexity of the physical world.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 17:09:29 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 09:47:36 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Hermann", "Karl Moritz", ""], ["Hill", "Felix", ""], ["Green", "Simon", ""], ["Wang", "Fumin", ""], ["Faulkner", "Ryan", ""], ["Soyer", "Hubert", ""], ["Szepesvari", "David", ""], ["Czarnecki", "Wojciech Marian", ""], ["Jaderberg", "Max", ""], ["Teplyashin", "Denis", ""], ["Wainwright", "Marcus", ""], ["Apps", "Chris", ""], ["Hassabis", "Demis", ""], ["Blunsom", "Phil", ""]]}, {"id": "1706.06569", "submitter": "Tomer Koren", "authors": "Vineet Gupta, Tomer Koren, Yoram Singer", "title": "A Unified Approach to Adaptive Regularization in Online and Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a framework for deriving and analyzing online optimization\nalgorithms that incorporate adaptive, data-dependent regularization, also\ntermed preconditioning. Such algorithms have been proven useful in stochastic\noptimization by reshaping the gradients according to the geometry of the data.\nOur framework captures and unifies much of the existing literature on adaptive\nonline methods, including the AdaGrad and Online Newton Step algorithms as well\nas their diagonal versions. As a result, we obtain new convergence proofs for\nthese algorithms that are substantially simpler than previous analyses. Our\nframework also exposes the rationale for the different preconditioned updates\nused in common stochastic optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 17:51:00 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Gupta", "Vineet", ""], ["Koren", "Tomer", ""], ["Singer", "Yoram", ""]]}, {"id": "1706.06617", "submitter": "Olivier Pietquin", "authors": "Diana Borsa, Bilal Piot, R\\'emi Munos and Olivier Pietquin", "title": "Observational Learning by Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational learning is a type of learning that occurs as a function of\nobserving, retaining and possibly replicating or imitating the behaviour of\nanother agent. It is a core mechanism appearing in various instances of social\nlearning and has been found to be employed in several intelligent species,\nincluding humans. In this paper, we investigate to what extent the explicit\nmodelling of other agents is necessary to achieve observational learning\nthrough machine learning. Especially, we argue that observational learning can\nemerge from pure Reinforcement Learning (RL), potentially coupled with memory.\nThrough simple scenarios, we demonstrate that an RL agent can leverage the\ninformation provided by the observations of an other agent performing a task in\na shared environment. The other agent is only observed through the effect of\nits actions on the environment and never explicitly modeled. Two key aspects\nare borrowed from observational learning: i) the observer behaviour needs to\nchange as a result of viewing a 'teacher' (another agent) and ii) the observer\nneeds to be motivated somehow to engage in making use of the other agent's\nbehaviour. The later is naturally modeled by RL, by correlating the learning\nagent's reward with the teacher agent's behaviour.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 18:44:49 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Borsa", "Diana", ""], ["Piot", "Bilal", ""], ["Munos", "R\u00e9mi", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1706.06619", "submitter": "Abraham Heifets", "authors": "Izhar Wallach and Abraham Heifets", "title": "Most Ligand-Based Classification Benchmarks Reward Memorization Rather\n  than Generalization", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jcim.7b00403", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undetected overfitting can occur when there are significant redundancies\nbetween training and validation data. We describe AVE, a new measure of\ntraining-validation redundancy for ligand-based classification problems that\naccounts for the similarity amongst inactive molecules as well as active. We\ninvestigated seven widely-used benchmarks for virtual screening and\nclassification, and show that the amount of AVE bias strongly correlates with\nthe performance of ligand-based predictive methods irrespective of the\npredicted property, chemical fingerprint, similarity measure, or\npreviously-applied unbiasing techniques. Therefore, it may be that the\npreviously-reported performance of most ligand-based methods can be explained\nby overfitting to benchmarks rather than good prospective accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 18:47:46 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 20:59:37 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wallach", "Izhar", ""], ["Heifets", "Abraham", ""]]}, {"id": "1706.06664", "submitter": "Anshumali Shrivastava", "authors": "Chen Luo, Anshumali Shrivastava", "title": "Arrays of (locality-sensitive) Count Estimators (ACE): High-Speed\n  Anomaly Detection via Cache Lookups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is one of the frequent and important subroutines deployed\nin large-scale data processing systems. Even being a well-studied topic,\nexisting techniques for unsupervised anomaly detection require storing\nsignificant amounts of data, which is prohibitive from memory and latency\nperspective. In the big-data world existing methods fail to address the new set\nof memory and latency constraints. In this paper, we propose ACE (Arrays of\n(locality-sensitive) Count Estimators) algorithm that can be 60x faster than\nthe ELKI package~\\cite{DBLP:conf/ssd/AchtertBKSZ09}, which has the fastest\nimplementation of the unsupervised anomaly detection algorithms. ACE algorithm\nrequires less than $4MB$ memory, to dynamically compress the full data\ninformation into a set of count arrays. These tiny $4MB$ arrays of counts are\nsufficient for unsupervised anomaly detection. At the core of the ACE\nalgorithm, there is a novel statistical estimator which is derived from the\nsampling view of Locality Sensitive Hashing(LSH). This view is significantly\ndifferent and efficient than the widely popular view of LSH for near-neighbor\nsearch. We show the superiority of ACE algorithm over 11 popular baselines on 3\nbenchmark datasets, including the KDD-Cup99 data which is the largest available\nbenchmark comprising of more than half a million entries with ground truth\nanomaly labels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 21:09:22 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Luo", "Chen", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1706.06689", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas,\n  Nathan Baker", "title": "Chemception: A Deep Neural Network with Minimal Chemistry Knowledge\n  Matches the Performance of Expert-developed QSAR/QSPR Models", "comments": "Submitted to a chemistry peer-reviewed journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, we have seen the transformative impact of deep\nlearning in many applications, particularly in speech recognition and computer\nvision. Inspired by Google's Inception-ResNet deep convolutional neural network\n(CNN) for image classification, we have developed \"Chemception\", a deep CNN for\nthe prediction of chemical properties, using just the images of 2D drawings of\nmolecules. We develop Chemception without providing any additional explicit\nchemistry knowledge, such as basic concepts like periodicity, or advanced\nfeatures like molecular descriptors and fingerprints. We then show how\nChemception can serve as a general-purpose neural network architecture for\npredicting toxicity, activity, and solvation properties when trained on a\nmodest database of 600 to 40,000 compounds. When compared to multi-layer\nperceptron (MLP) deep neural networks trained with ECFP fingerprints,\nChemception slightly outperforms in activity and solvation prediction and\nslightly underperforms in toxicity prediction. Having matched the performance\nof expert-developed QSAR/QSPR deep learning models, our work demonstrates the\nplausibility of using deep neural networks to assist in computational chemistry\nresearch, where the feature engineering process is performed primarily by a\ndeep learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 22:25:57 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Goh", "Garrett B.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""], ["Hodas", "Nathan O.", ""], ["Baker", "Nathan", ""]]}, {"id": "1706.06691", "submitter": "Gabriele Tolomei", "authors": "Gabriele Tolomei, Fabrizio Silvestri, Andrew Haines, Mounia Lalmas", "title": "Interpretable Predictions of Tree-based Ensembles via Actionable Feature\n  Tweaking", "comments": "10 pages, KDD 2017", "journal-ref": null, "doi": "10.1145/3097983.3098039", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learned models are often described as \"black boxes\". In many\nreal-world applications however, models may have to sacrifice predictive power\nin favour of human-interpretability. When this is the case, feature engineering\nbecomes a crucial task, which requires significant and time-consuming human\neffort. Whilst some features are inherently static, representing properties\nthat cannot be influenced (e.g., the age of an individual), others capture\ncharacteristics that could be adjusted (e.g., the daily amount of carbohydrates\ntaken). Nonetheless, once a model is learned from the data, each prediction it\nmakes on new instances is irreversible - assuming every instance to be a static\npoint located in the chosen feature space. There are many circumstances however\nwhere it is important to understand (i) why a model outputs a certain\nprediction on a given instance, (ii) which adjustable features of that instance\nshould be modified, and finally (iii) how to alter such a prediction when the\nmutated instance is input back to the model. In this paper, we present a\ntechnique that exploits the internals of a tree-based ensemble classifier to\noffer recommendations for transforming true negative instances into positively\npredicted ones. We demonstrate the validity of our approach using an online\nadvertising application. First, we design a Random Forest classifier that\neffectively separates between two types of ads: low (negative) and high\n(positive) quality ads (instances). Then, we introduce an algorithm that\nprovides recommendations that aim to transform a low quality ad (negative\ninstance) into a high quality one (positive instance). Finally, we evaluate our\napproach on a subset of the active inventory of a large ad network, Yahoo\nGemini.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 22:32:02 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Tolomei", "Gabriele", ""], ["Silvestri", "Fabrizio", ""], ["Haines", "Andrew", ""], ["Lalmas", "Mounia", ""]]}, {"id": "1706.06838", "submitter": "Federico Cabitza", "authors": "Federico Cabitza, Davide Ciucci, Raffaele Rasoini", "title": "A giant with feet of clay: on the validity of the data that feed machine\n  learning in medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers the use of Machine Learning (ML) in medicine by focusing\non the main problem that this computational approach has been aimed at solving\nor at least minimizing: uncertainty. To this aim, we point out how uncertainty\nis so ingrained in medicine that it biases also the representation of clinical\nphenomena, that is the very input of ML models, thus undermining the clinical\nsignificance of their output. Recognizing this can motivate both medical\ndoctors, in taking more responsibility in the development and use of these\ndecision aids, and the researchers, in pursuing different ways to assess the\nvalue of these systems. In so doing, both designers and users could take this\nintrinsic characteristic of medicine more seriously and consider alternative\napproaches that do not \"sweep uncertainty under the rug\" within an objectivist\nfiction, which everyone can come up by believing as true.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 11:45:44 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 16:12:37 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 14:43:01 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Cabitza", "Federico", ""], ["Ciucci", "Davide", ""], ["Rasoini", "Raffaele", ""]]}, {"id": "1706.06859", "submitter": "Kazuyuki Hara", "authors": "Kazuyuki Hara, Daisuke Saitoh, and Hayaru Shouno", "title": "Analysis of dropout learning regarded as ensemble learning", "comments": "9 pages, 8 figures, submitted to Conference", "journal-ref": "A. E. P. VIlla et al. (Eds.): ICANN 2016 ( Part II, LNCS 9887, pp.\n  1-8, 2016)", "doi": "10.1007/978-3-319-44781-0_9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is the state-of-the-art in fields such as visual object\nrecognition and speech recognition. This learning uses a large number of\nlayers, huge number of units, and connections. Therefore, overfitting is a\nserious problem. To avoid this problem, dropout learning is proposed. Dropout\nlearning neglects some inputs and hidden units in the learning process with a\nprobability, p, and then, the neglected inputs and hidden units are combined\nwith the learned network to express the final output. We find that the process\nof combining the neglected hidden units with the learned network can be\nregarded as ensemble learning, so we analyze dropout learning from this point\nof view.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 04:19:57 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Hara", "Kazuyuki", ""], ["Saitoh", "Daisuke", ""], ["Shouno", "Hayaru", ""]]}, {"id": "1706.06878", "submitter": "Lorenzo Nespoli", "authors": "Lorenzo Nespoli and Vasco Medici", "title": "An Unsupervised Method for Estimating the Global Horizontal Irradiance\n  from Photovoltaic Power Measurements", "comments": null, "journal-ref": "Solar Energy Volume 158, December 2017, Pages 701-710", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method to determine the global horizontal\nirradiance (GHI) from the power measurements of one or more PV systems, located\nin the same neighborhood. The method is completely unsupervised and is based on\na physical model of a PV plant. The precise assessment of solar irradiance is\npivotal for the forecast of the electric power generated by photovoltaic (PV)\nplants. However, on-ground measurements are expensive and are generally not\nperformed for small and medium-sized PV plants. Satellite-based services\nrepresent a valid alternative to on site measurements, but their space-time\nresolution is limited. Results from two case studies located in Switzerland are\npresented. The performance of the proposed method at assessing GHI is compared\nwith that of free and commercial satellite services. Our results show that the\npresented method is generally better than satellite-based services, especially\nat high temporal resolutions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 13:06:57 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 14:47:52 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 12:47:37 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Nespoli", "Lorenzo", ""], ["Medici", "Vasco", ""]]}, {"id": "1706.06941", "submitter": "Daniele Zambon", "authors": "Daniele Zambon, Cesare Alippi, Lorenzo Livi", "title": "Concept Drift and Anomaly Detection in Graph Streams", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (Volume:\n  29, Issue: 11, Nov. 2018)", "doi": "10.1109/TNNLS.2018.2804443", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representations offer powerful and intuitive ways to describe data in a\nmultitude of application domains. Here, we consider stochastic processes\ngenerating graphs and propose a methodology for detecting changes in\nstationarity of such processes. The methodology is general and considers a\nprocess generating attributed graphs with a variable number of vertices/edges,\nwithout the need to assume one-to-one correspondence between vertices at\ndifferent time steps. The methodology acts by embedding every graph of the\nstream into a vector domain, where a conventional multivariate change detection\nprocedure can be easily applied. We ground the soundness of our proposal by\nproving several theoretical results. In addition, we provide a specific\nimplementation of the methodology and evaluate its effectiveness on several\ndetection problems involving attributed graphs representing biological\nmolecules and drawings. Experimental results are contrasted with respect to\nsuitable baseline methods, demonstrating the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 14:52:01 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 11:11:12 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 17:09:17 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zambon", "Daniele", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1706.06953", "submitter": "Kazuyuki Hara", "authors": "Kazuyuki Hara, Kentaro Katahira, and Masato Okada", "title": "Statistical Mechanics of Node-perturbation Learning with Noisy Baseline", "comments": "16 pages, 7 figures, submitted to JPSJ", "journal-ref": "Journal of the Physical Society of Japan 86, 024002 (2017)", "doi": "10.7566/JPSJ.86.024002", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node-perturbation learning is a type of statistical gradient descent\nalgorithm that can be applied to problems where the objective function is not\nexplicitly formulated, including reinforcement learning. It estimates the\ngradient of an objective function by using the change in the object function in\nresponse to the perturbation. The value of the objective function for an\nunperturbed output is called a baseline. Cho et al. proposed node-perturbation\nlearning with a noisy baseline. In this paper, we report on building the\nstatistical mechanics of Cho's model and on deriving coupled differential\nequations of order parameters that depict learning dynamics. We also show how\nto derive the generalization error by solving the differential equations of\norder parameters. On the basis of the results, we show that Cho's results are\nalso apply in general cases and show some general performances of Cho's model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 04:46:56 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Hara", "Kazuyuki", ""], ["Katahira", "Kentaro", ""], ["Okada", "Masato", ""]]}, {"id": "1706.06969", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, David H. J. Janssen, Heiko H. Sch\\\"utt, Jonas Rauber,\n  Matthias Bethge, Felix A. Wichmann", "title": "Comparing deep neural networks against humans: object recognition when\n  the signal gets weaker", "comments": "updated article with reference to resulting publication (Geirhos et\n  al, NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human visual object recognition is typically rapid and seemingly effortless,\nas well as largely independent of viewpoint and object orientation. Until very\nrecently, animate visual systems were the only ones capable of this remarkable\ncomputational feat. This has changed with the rise of a class of computer\nvision algorithms called deep neural networks (DNNs) that achieve human-level\nclassification performance on object recognition tasks. Furthermore, a growing\nnumber of studies report similarities in the way DNNs and the human visual\nsystem process objects, suggesting that current DNNs may be good models of\nhuman visual object recognition. Yet there clearly exist important\narchitectural and processing differences between state-of-the-art DNNs and the\nprimate visual system. The potential behavioural consequences of these\ndifferences are not well understood. We aim to address this issue by comparing\nhuman and DNN generalisation abilities towards image degradations. We find the\nhuman visual system to be more robust to image manipulations like contrast\nreduction, additive noise or novel eidolon-distortions. In addition, we find\nprogressively diverging classification error-patterns between humans and DNNs\nwhen the signal gets weaker, indicating that there may still be marked\ndifferences in the way humans and current DNNs perform visual object\nrecognition. We envision that our findings as well as our carefully measured\nand freely available behavioural datasets provide a new useful benchmark for\nthe computer vision community to improve the robustness of DNNs and a\nmotivation for neuroscientists to search for mechanisms in the brain that could\nfacilitate this robustness.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 15:46:52 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 17:06:24 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Geirhos", "Robert", ""], ["Janssen", "David H. J.", ""], ["Sch\u00fctt", "Heiko H.", ""], ["Rauber", "Jonas", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "1706.06971", "submitter": "Jabed Tomal", "authors": "Jabed H Tomal and William J Welch and Ruben H Zamar", "title": "Ensembles of phalanxes across assessment metrics for robust ranking of\n  homologous proteins", "comments": "29 pages, 4 figures, 8 tables and 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two proteins are homologous if they have a common evolutionary origin, and\nthe binary classification problem is to identify proteins in a candidate set\nthat are homologous to a particular native protein. The feature (explanatory)\nvariables available for classification are various measures of similarity of\nproteins. There are multiple classification problems of this type for different\nnative proteins and their respective candidate sets. Homologous proteins are\nrare in a single candidate set, giving a highly unbalanced two-class problem.\nThe goal is to rank proteins in a candidate set according to the probability of\nbeing homologous to the set's native protein. An ideal classifier will place\nall the homologous proteins at the head of such a list. Our approach uses an\nensemble of models in a classifier and an ensemble of assessment metrics. For a\ngiven metric a classifier combines models, each based on a subset of the\navailable feature variables which we call phalanxes. The proposed ensemble of\nphalanxes identifies strong and diverse subsets of feature variables. A second\nphase of ensembling aggregates classifiers based on diverse evaluation metrics.\nThe overall result is called an ensemble of phalanxes and metrics. It provide\nrobustness against both close and distant homologues.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 15:49:14 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 02:21:32 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Tomal", "Jabed H", ""], ["Welch", "William J", ""], ["Zamar", "Ruben H", ""]]}, {"id": "1706.06974", "submitter": "Jon Kleinberg", "authors": "Jon Kleinberg, Annie Liang, Sendhil Mullainathan", "title": "The Theory is Predictive, but is it Complete? An Application to Human\n  Perception of Randomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we test a theory using data, it is common to focus on correctness: do\nthe predictions of the theory match what we see in the data? But we also care\nabout completeness: how much of the predictable variation in the data is\ncaptured by the theory? This question is difficult to answer, because in\ngeneral we do not know how much \"predictable variation\" there is in the\nproblem. In this paper, we consider approaches motivated by machine learning\nalgorithms as a means of constructing a benchmark for the best attainable level\nof prediction.\n  We illustrate our methods on the task of predicting human-generated random\nsequences. Relative to an atheoretical machine learning algorithm benchmark, we\nfind that existing behavioral models explain roughly 15 percent of the\npredictable variation in this problem. This fraction is robust across several\nvariations on the problem. We also consider a version of this approach for\nanalyzing field data from domains in which human perception and generation of\nrandomness has been used as a conceptual framework; these include sequential\ndecision-making and repeated zero-sum games. In these domains, our framework\nfor testing the completeness of theories provides a way of assessing their\neffectiveness over different contexts; we find that despite some differences,\nthe existing theories are fairly stable across our field domains in their\nperformance relative to the benchmark. Overall, our results indicate that (i)\nthere is a significant amount of structure in this problem that existing models\nhave yet to capture and (ii) there are rich domains in which machine learning\nmay provide a viable approach to testing completeness.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 15:56:06 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Kleinberg", "Jon", ""], ["Liang", "Annie", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1706.06978", "submitter": "Xiaoqiang Zhu", "authors": "Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma,\n  Yanghui Yan, Junqi Jin, Han Li, Kun Gai", "title": "Deep Interest Network for Click-Through Rate Prediction", "comments": "Accepted by KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate prediction is an essential task in industrial\napplications, such as online advertising. Recently deep learning based models\nhave been proposed, which follow a similar Embedding\\&MLP paradigm. In these\nmethods large scale sparse input features are first mapped into low dimensional\nembedding vectors, and then transformed into fixed-length vectors in a\ngroup-wise manner, finally concatenated together to fed into a multilayer\nperceptron (MLP) to learn the nonlinear relations among features. In this way,\nuser features are compressed into a fixed-length representation vector, in\nregardless of what candidate ads are. The use of fixed-length vector will be a\nbottleneck, which brings difficulty for Embedding\\&MLP methods to capture\nuser's diverse interests effectively from rich historical behaviors. In this\npaper, we propose a novel model: Deep Interest Network (DIN) which tackles this\nchallenge by designing a local activation unit to adaptively learn the\nrepresentation of user interests from historical behaviors with respect to a\ncertain ad. This representation vector varies over different ads, improving the\nexpressive ability of model greatly. Besides, we develop two techniques:\nmini-batch aware regularization and data adaptive activation function which can\nhelp training industrial deep networks with hundreds of millions of parameters.\nExperiments on two public datasets as well as an Alibaba real production\ndataset with over 2 billion samples demonstrate the effectiveness of proposed\napproaches, which achieve superior performance compared with state-of-the-art\nmethods. DIN now has been successfully deployed in the online display\nadvertising system in Alibaba, serving the main traffic.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 16:05:17 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 08:12:12 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 13:06:07 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2018 04:37:06 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Zhou", "Guorui", ""], ["Song", "Chengru", ""], ["Zhu", "Xiaoqiang", ""], ["Fan", "Ying", ""], ["Zhu", "Han", ""], ["Ma", "Xiao", ""], ["Yan", "Yanghui", ""], ["Jin", "Junqi", ""], ["Li", "Han", ""], ["Gai", "Kun", ""]]}, {"id": "1706.07001", "submitter": "Jialei Wang", "authors": "Jialei Wang, Tong Zhang", "title": "Improved Optimization of Finite Sums with Minibatch Stochastic Variance\n  Reduced Proximal Iterations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel minibatch stochastic optimization methods for empirical risk\nminimization problems, the methods efficiently leverage variance reduced\nfirst-order and sub-sampled higher-order information to accelerate the\nconvergence speed. For quadratic objectives, we prove improved iteration\ncomplexity over state-of-the-art under reasonable assumptions. We also provide\nempirical evidence of the advantages of our method compared to existing\napproaches in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 16:48:45 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 04:42:08 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Wang", "Jialei", ""], ["Zhang", "Tong", ""]]}, {"id": "1706.07094", "submitter": "Ben Letham", "authors": "Benjamin Letham, Brian Karrer, Guilherme Ottoni, Eytan Bakshy", "title": "Constrained Bayesian Optimization with Noisy Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments are the gold standard for evaluating the effects of\nchanges to real-world systems. Data in these tests may be difficult to collect\nand outcomes may have high variance, resulting in potentially large measurement\nerror. Bayesian optimization is a promising technique for efficiently\noptimizing multiple continuous parameters, but existing approaches degrade in\nperformance when the noise level is high, limiting its applicability to many\nrandomized experiments. We derive an expression for expected improvement under\ngreedy batch optimization with noisy observations and noisy constraints, and\ndevelop a quasi-Monte Carlo approximation that allows it to be efficiently\noptimized. Simulations with synthetic functions show that optimization\nperformance on noisy, constrained problems outperforms existing methods. We\nfurther demonstrate the effectiveness of the method with two real-world\nexperiments conducted at Facebook: optimizing a ranking system, and optimizing\nserver compiler flags.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 19:29:14 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 17:06:00 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Letham", "Benjamin", ""], ["Karrer", "Brian", ""], ["Ottoni", "Guilherme", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1706.07101", "submitter": "Anthony Gamst", "authors": "Anthony Collins Gamst and Alden Walker", "title": "The energy landscape of a simple neural network", "comments": "17 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the energy landscape of a simple neural network. In particular, we\nexpand upon previous work demonstrating that the empirical complexity of fitted\nneural networks is vastly less than a naive parameter count would suggest and\nthat this implicit regularization is actually beneficial for generalization\nfrom fitted models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 19:51:43 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Gamst", "Anthony Collins", ""], ["Walker", "Alden", ""]]}, {"id": "1706.07147", "submitter": "Kevin Feigelis", "authors": "Kevin T. Feigelis and Daniel L. K. Yamins", "title": "A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional\n  Visual Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals (especially humans) have an amazing ability to learn new tasks\nquickly, and switch between them flexibly. How brains support this ability is\nlargely unknown, both neuroscientifically and algorithmically. One reasonable\nsupposition is that modules drawing on an underlying general-purpose sensory\nrepresentation are dynamically allocated on a per-task basis. Recent results\nfrom neuroscience and artificial intelligence suggest the role of the general\npurpose visual representation may be played by a deep convolutional neural\nnetwork, and give some clues how task modules based on such a representation\nmight be discovered and constructed. In this work, we investigate module\narchitectures in an embodied two-dimensional touchscreen environment, in which\nan agent's learning must occur via interactions with an environment that emits\nimages and rewards, and accepts touches as input. This environment is designed\nto capture the physical structure of the task environments that are commonly\ndeployed in visual neuroscience and psychophysics. We show that in this\ncontext, very simple changes in the nonlinear activations used by such a module\ncan significantly influence how fast it is at learning visual tasks and how\nsuitable it is for switching to new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 02:07:14 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Feigelis", "Kevin T.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1706.07180", "submitter": "Remi Gribonval", "authors": "R\\'emi Gribonval (PANAMA, DANTE), Gilles Blanchard (DATASHAPE, LMO),\n  Nicolas Keriven (PANAMA, GIPSA-GAIA), Yann Traonmilin (PANAMA, IMB)", "title": "Compressive Statistical Learning with Random Feature Moments", "comments": "Main novelties between version 1 and version 2: improved\n  concentration bounds, improved sketch sizes for compressive k-means and\n  compressive GMM that now scale linearly with the ambient dimensionMain\n  novelties of version 3: all content on compressive clustering and compressive\n  GMM is now developed in the companion paper hal-02536818; improved\n  statistical guarantees in a generic framework with illustration of the\n  improvements on compressive PCA. Mathematical Statistics and Learning, EMS\n  Publishing House, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general framework -- compressive statistical learning -- for\nresource-efficient large-scale learning: the training collection is compressed\nin one pass into a low-dimensional sketch (a vector of random empirical\ngeneralized moments) that captures the information relevant to the considered\nlearning task. A near-minimizer of the risk is computed from the sketch through\nthe solution of a nonlinear least squares problem. We investigate sufficient\nsketch sizes to control the generalization error of this procedure. The\nframework is illustrated on compressive PCA, compressive clustering, and\ncompressive Gaussian mixture Modeling with fixed known variance. The latter two\nare further developed in a companion paper.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 06:59:19 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 09:38:07 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 15:25:47 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 08:26:13 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Gribonval", "R\u00e9mi", "", "PANAMA, DANTE"], ["Blanchard", "Gilles", "", "DATASHAPE, LMO"], ["Keriven", "Nicolas", "", "PANAMA, GIPSA-GAIA"], ["Traonmilin", "Yann", "", "PANAMA, IMB"]]}, {"id": "1706.07193", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos and Daniel Sanz-Alonso", "title": "Continuum Limit of Posteriors in Graph Bayesian Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.AP math.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a function input of a differential\nequation formulated on an unknown domain $M$. We assume to have access to a\ndiscrete domain $M_n=\\{x_1, \\dots, x_n\\} \\subset M$, and to noisy measurements\nof the output solution at $p\\le n$ of those points. We introduce a graph-based\nBayesian inverse problem, and show that the graph-posterior measures over\nfunctions in $M_n$ converge, in the large $n$ limit, to a posterior over\nfunctions in $M$ that solves a Bayesian inverse problem with known domain.\n  The proofs rely on the variational formulation of the Bayesian update, and on\na new topology for the study of convergence of measures over functions on point\nclouds to a measure over functions on the continuum. Our framework, techniques,\nand results may serve to lay the foundations of robust uncertainty\nquantification of graph-based tasks in machine learning. The ideas are\npresented in the concrete setting of recovering the initial condition of the\nheat equation on an unknown manifold.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 07:39:51 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Sanz-Alonso", "Daniel", ""]]}, {"id": "1706.07206", "submitter": "Wojciech Samek", "authors": "Leila Arras, Gr\\'egoire Montavon, Klaus-Robert M\\\"uller, Wojciech\n  Samek", "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis", "comments": "9 pages, 4 figures, accepted for EMNLP'17 Workshop on Computational\n  Approaches to Subjectivity, Sentiment & Social Media Analysis (WASSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown\nto deliver insightful explanations in the form of input space relevances for\nunderstanding feed-forward neural network classification decisions. In the\npresent work, we extend the usage of LRP to recurrent neural networks. We\npropose a specific propagation rule applicable to multiplicative connections as\nthey arise in recurrent network architectures such as LSTMs and GRUs. We apply\nour technique to a word-based bi-directional LSTM model on a five-class\nsentiment prediction task, and evaluate the resulting LRP relevances both\nqualitatively and quantitatively, obtaining better results than a\ngradient-based related method which was used in previous work.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 08:24:59 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 20:01:33 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Arras", "Leila", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1706.07258", "submitter": "Daniel Hern\\'andez-Lobato", "authors": "Carlos Villacampa-Calvo and Daniel Hern\\'andez-Lobato", "title": "Scalable Multi-Class Gaussian Process Classification using Expectation\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an expectation propagation (EP) method for multi-class\nclassification with Gaussian processes that scales well to very large datasets.\nIn such a method the estimate of the log-marginal-likelihood involves a sum\nacross the data instances. This enables efficient training using stochastic\ngradients and mini-batches. When this type of training is used, the\ncomputational cost does not depend on the number of data instances $N$.\nFurthermore, extra assumptions in the approximate inference process make the\nmemory cost independent of $N$. The consequence is that the proposed EP method\ncan be used on datasets with millions of instances. We compare empirically this\nmethod with alternative approaches that approximate the required computations\nusing variational inference. The results show that it performs similar or even\nbetter than these techniques, which sometimes give significantly worse\npredictive distributions in terms of the test log-likelihood. Besides this, the\ntraining process of the proposed approach also seems to converge in a smaller\nnumber of iterations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 11:18:15 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Villacampa-Calvo", "Carlos", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "1706.07450", "submitter": "Soledad Villar", "authors": "Alex Nowak, Soledad Villar, Afonso S. Bandeira, Joan Bruna", "title": "Revised Note on Learning Algorithms for Quadratic Assignment with Graph\n  Neural Networks", "comments": "Revised note to arXiv:1706.07450v1 that appeared in IEEE Data Science\n  Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems correspond to a certain type of optimization problems\nformulated over appropriate input distributions. Recently, there has been a\ngrowing interest in understanding the computational hardness of these\noptimization problems, not only in the worst case, but in an average-complexity\nsense under this same input distribution.\n  In this revised note, we are interested in studying another aspect of\nhardness, related to the ability to learn how to solve a problem by simply\nobserving a collection of previously solved instances. These 'planted\nsolutions' are used to supervise the training of an appropriate predictive\nmodel that parametrizes a broad class of algorithms, with the hope that the\nresulting model will provide good accuracy-complexity tradeoffs in the average\nsense.\n  We illustrate this setup on the Quadratic Assignment Problem, a fundamental\nproblem in Network Science. We observe that data-driven models based on Graph\nNeural Networks offer intriguingly good performance, even in regimes where\nstandard relaxation based techniques appear to suffer.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 18:18:58 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 20:27:20 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Nowak", "Alex", ""], ["Villar", "Soledad", ""], ["Bandeira", "Afonso S.", ""], ["Bruna", "Joan", ""]]}, {"id": "1706.07510", "submitter": "Arya Mazumdar", "authors": "Arya Mazumdar, Barna Saha", "title": "Clustering with Noisy Queries", "comments": "Prior versions of some of the results have appeared before in\n  arXiv:1604.01839. In this version we rewrote several proofs for clarity, and\n  included many new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we initiate a rigorous theoretical study of clustering with\nnoisy queries (or a faulty oracle). Given a set of $n$ elements, our goal is to\nrecover the true clustering by asking minimum number of pairwise queries to an\noracle. Oracle can answer queries of the form : \"do elements $u$ and $v$ belong\nto the same cluster?\" -- the queries can be asked interactively (adaptive\nqueries), or non-adaptively up-front, but its answer can be erroneous with\nprobability $p$. In this paper, we provide the first information theoretic\nlower bound on the number of queries for clustering with noisy oracle in both\nsituations. We design novel algorithms that closely match this query complexity\nlower bound, even when the number of clusters is unknown. Moreover, we design\ncomputationally efficient algorithms both for the adaptive and non-adaptive\nsettings. The problem captures/generalizes multiple application scenarios. It\nis directly motivated by the growing body of work that use crowdsourcing for\n{\\em entity resolution}, a fundamental and challenging data mining task aimed\nto identify all records in a database referring to the same entity. Here crowd\nrepresents the noisy oracle, and the number of queries directly relates to the\ncost of crowdsourcing. Another application comes from the problem of {\\em sign\nedge prediction} in social network, where social interactions can be both\npositive and negative, and one must identify the sign of all pair-wise\ninteractions by querying a few pairs. Furthermore, clustering with noisy oracle\nis intimately connected to correlation clustering, leading to improvement\ntherein. Finally, it introduces a new direction of study in the popular {\\em\nstochastic block model} where one has an incomplete stochastic block model\nmatrix to recover the clusters.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 22:22:04 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Mazumdar", "Arya", ""], ["Saha", "Barna", ""]]}, {"id": "1706.07535", "submitter": "Hemanth Venkateswara", "authors": "Hemanth Venkateswara, Prasanth Lade, Binbin Lin, Jieping Ye,\n  Sethuraman Panchanathan", "title": "Efficient Approximate Solutions to Mutual Information Based Global\n  Feature Selection", "comments": "ICDM 2015 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual Information (MI) is often used for feature selection when developing\nclassifier models. Estimating the MI for a subset of features is often\nintractable. We demonstrate, that under the assumptions of conditional\nindependence, MI between a subset of features can be expressed as the\nConditional Mutual Information (CMI) between pairs of features. But selecting\nfeatures with the highest CMI turns out to be a hard combinatorial problem. In\nthis work, we have applied two unique global methods, Truncated Power Method\n(TPower) and Low Rank Bilinear Approximation (LowRank), to solve the feature\nselection problem. These algorithms provide very good approximations to the\nNP-hard CMI based feature selection problem. We experimentally demonstrate the\neffectiveness of these procedures across multiple datasets and compare them\nwith existing MI based global and iterative feature selection procedures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 01:08:59 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Venkateswara", "Hemanth", ""], ["Lade", "Prasanth", ""], ["Lin", "Binbin", ""], ["Ye", "Jieping", ""], ["Panchanathan", "Sethuraman", ""]]}, {"id": "1706.07561", "submitter": "Jiaming Song", "authors": "Jiaming Song and Shengjia Zhao and Stefano Ermon", "title": "A-NICE-MC: Adversarial Training for MCMC", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Markov Chain Monte Carlo (MCMC) methods are either based on\ngeneral-purpose and domain-agnostic schemes which can lead to slow convergence,\nor hand-crafting of problem-specific proposals by an expert. We propose\nA-NICE-MC, a novel method to train flexible parametric Markov chain kernels to\nproduce samples with desired properties. First, we propose an efficient\nlikelihood-free adversarial training method to train a Markov chain and mimic a\ngiven data distribution. Then, we leverage flexible volume preserving flows to\nobtain parametric kernels for MCMC. Using a bootstrap approach, we show how to\ntrain efficient Markov chains to sample from a prescribed posterior\ndistribution by iteratively improving the quality of both the model and the\nsamples. A-NICE-MC provides the first framework to automatically design\nefficient domain-specific MCMC proposals. Empirical results demonstrate that\nA-NICE-MC combines the strong guarantees of MCMC with the expressiveness of\ndeep neural networks, and is able to significantly outperform competing methods\nsuch as Hamiltonian Monte Carlo.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 04:19:04 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 18:20:40 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 19:23:42 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Song", "Jiaming", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1706.07581", "submitter": "Gael Varoquaux", "authors": "Ga\\\"el Varoquaux (PARIETAL)", "title": "Cross-validation failure: small sample sizes lead to large error bars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models ground many state-of-the-art developments in statistical\nbrain image analysis: decoding, MVPA, searchlight, or extraction of biomarkers.\nThe principled approach to establish their validity and usefulness is\ncross-validation, testing prediction on unseen data. Here, I would like to\nraise awareness on error bars of cross-validation, which are often\nunderestimated. Simple experiments show that sample sizes of many neuroimaging\nstudies inherently lead to large error bars, eg $\\pm$10% for 100 samples. The\nstandard error across folds strongly underestimates them. These large error\nbars compromise the reliability of conclusions drawn with predictive models,\nsuch as biomarkers or methods developments where, unlike with cognitive\nneuroimaging MVPA approaches, more samples cannot be acquired by repeating the\nexperiment across many subjects. Solutions to increase sample size must be\ninvestigated, tackling possible increases in heterogeneity of the data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 06:47:16 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Varoquaux", "Ga\u00ebl", "", "PARIETAL"]]}, {"id": "1706.07642", "submitter": "Yazhou Yang", "authors": "Yazhou Yang, Marco Loog", "title": "A Variance Maximization Criterion for Active Learning", "comments": "Accepted by Pattern Recognition Journal", "journal-ref": "Pattern Recognition 78C (2018) pp. 358-370", "doi": "10.1016/j.patcog.2018.01.017", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to train a classifier as fast as possible with as few\nlabels as possible. The core element in virtually any active learning strategy\nis the criterion that measures the usefulness of the unlabeled data based on\nwhich new points to be labeled are picked. We propose a novel approach which we\nrefer to as maximizing variance for active learning or MVAL for short. MVAL\nmeasures the value of unlabeled instances by evaluating the rate of change of\noutput variables caused by changes in the next sample to be queried and its\npotential labelling. In a sense, this criterion measures how unstable the\nclassifier's output is for the unlabeled data points under perturbations of the\ntraining data. MVAL maintains, what we refer to as, retraining information\nmatrices to keep track of these output scores and exploits two kinds of\nvariance to measure the informativeness and representativeness, respectively.\nBy fusing these variances, MVAL is able to select the instances which are both\ninformative and representative. We employ our technique both in combination\nwith logistic regression and support vector machines and demonstrate that MVAL\nachieves state-of-the-art performance in experiments on a large number of\nstandard benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 11:38:00 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 13:01:51 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Yang", "Yazhou", ""], ["Loog", "Marco", ""]]}, {"id": "1706.07719", "submitter": "Arya Mazumdar", "authors": "Arya Mazumdar, Barna Saha", "title": "Query Complexity of Clustering with Side Information", "comments": "A prior version of this work appeared in arxiv previously, see\n  arxiv:1604.01839. This paper contains a new efficient Monte Carlo algorithm\n  that has not appeared before, and a stronger lower bound. Some proofs have\n  been rewritten for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose, we are given a set of $n$ elements to be clustered into $k$\n(unknown) clusters, and an oracle/expert labeler that can interactively answer\npair-wise queries of the form, \"do two elements $u$ and $v$ belong to the same\ncluster?\". The goal is to recover the optimum clustering by asking the minimum\nnumber of queries. In this paper, we initiate a rigorous theoretical study of\nthis basic problem of query complexity of interactive clustering, and provide\nstrong information theoretic lower bounds, as well as nearly matching upper\nbounds. Most clustering problems come with a similarity matrix, which is used\nby an automated process to cluster similar points together. Our main\ncontribution in this paper is to show the dramatic power of side information\naka similarity matrix on reducing the query complexity of clustering. A\nsimilarity matrix represents noisy pair-wise relationships such as one computed\nby some function on attributes of the elements. A natural noisy model is where\nsimilarity values are drawn independently from some arbitrary probability\ndistribution $f_+$ when the underlying pair of elements belong to the same\ncluster, and from some $f_-$ otherwise. We show that given such a similarity\nmatrix, the query complexity reduces drastically from $\\Theta(nk)$ (no\nsimilarity matrix) to $O(\\frac{k^2\\log{n}}{\\cH^2(f_+\\|f_-)})$ where $\\cH^2$\ndenotes the squared Hellinger divergence. Moreover, this is also\ninformation-theoretic optimal within an $O(\\log{n})$ factor. Our algorithms are\nall efficient, and parameter free, i.e., they work without any knowledge of $k,\nf_+$ and $f_-$, and only depend logarithmically with $n$. Along the way, our\nwork also reveals intriguing connection to popular community detection models\nsuch as the {\\em stochastic block model}, significantly generalizes them, and\nopens up many venues for interesting future research.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 14:24:32 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Mazumdar", "Arya", ""], ["Saha", "Barna", ""]]}, {"id": "1706.07834", "submitter": "Mohammad Golbabaee", "authors": "Mohammad Golbabaee, Zhouye Chen, Yves Wiaux, Mike E. Davies", "title": "Cover Tree Compressed Sensing for Fast MR Fingerprint Recovery", "comments": null, "journal-ref": null, "doi": "10.1109/MLSP.2017.8168167", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adopt data structure in the form of cover trees and iteratively apply\napproximate nearest neighbour (ANN) searches for fast compressed sensing\nreconstruction of signals living on discrete smooth manifolds. Levering on the\nrecent stability results for the inexact Iterative Projected Gradient (IPG)\nalgorithm and by using the cover tree's ANN searches, we decrease the\nprojection cost of the IPG algorithm to be logarithmically growing with data\npopulation for low dimensional smooth manifolds. We apply our results to\nquantitative MRI compressed sensing and in particular within the Magnetic\nResonance Fingerprinting (MRF) framework. For a similar (or sometimes better)\nreconstruction accuracy, we report 2-3 orders of magnitude reduction in\ncomputations compared to the standard iterative method which uses brute-force\nsearches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 18:57:17 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 16:32:51 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Golbabaee", "Mohammad", ""], ["Chen", "Zhouye", ""], ["Wiaux", "Yves", ""], ["Davies", "Mike E.", ""]]}, {"id": "1706.07841", "submitter": "Madhuri Suthar", "authors": "Bahram Jalali, Madhuri Suthar, Mohamad Asghari and Ata Mahjoubfar", "title": "Time Stretch Inspired Computational Imaging", "comments": "This work has been published in the PHOTOPTICS 2017 - 5th\n  International Conference on Photonics, Optics and Laser Technology, Volume 1,\n  ISBN 978-989-758-223-3, pages 340-345", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.data-an physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that dispersive propagation of light followed by phase detection has\nproperties that can be exploited for extracting features from the waveforms.\nThis discovery is spearheading development of a new class of physics-inspired\nalgorithms for feature extraction from digital images with unique properties\nand superior dynamic range compared to conventional algorithms. In certain\ncases, these algorithms have the potential to be an energy efficient and\nscalable substitute to synthetically fashioned computational techniques in\npractice today.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 12:41:50 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Jalali", "Bahram", ""], ["Suthar", "Madhuri", ""], ["Asghari", "Mohamad", ""], ["Mahjoubfar", "Ata", ""]]}, {"id": "1706.07880", "submitter": "Aditya Balu", "authors": "Zhanhong Jiang, Aditya Balu, Chinmay Hegde and Soumik Sarkar", "title": "Collaborative Deep Learning in Fixed Topology Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is significant recent interest to parallelize deep learning algorithms\nin order to handle the enormous growth in data and model sizes. While most\nadvances focus on model parallelization and engaging multiple computing agents\nvia using a central parameter server, aspect of data parallelization along with\ndecentralized computation has not been explored sufficiently. In this context,\nthis paper presents a new consensus-based distributed SGD (CDSGD) (and its\nmomentum variant, CDMSGD) algorithm for collaborative deep learning over fixed\ntopology networks that enables data parallelization as well as decentralized\ncomputation. Such a framework can be extremely useful for learning agents with\naccess to only local/private data in a communication constrained environment.\nWe analyze the convergence properties of the proposed algorithm with strongly\nconvex and nonconvex objective functions with fixed and diminishing step sizes\nusing concepts of Lyapunov function construction. We demonstrate the efficacy\nof our algorithms in comparison with the baseline centralized SGD and the\nrecently proposed federated averaging algorithm (that also enables data\nparallelism) based on benchmark datasets such as MNIST, CIFAR-10 and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 22:30:17 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Jiang", "Zhanhong", ""], ["Balu", "Aditya", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1706.07881", "submitter": "Ting Chen", "authors": "Ting Chen, Yizhou Sun, Yue Shi, Liangjie Hong", "title": "On Sampling Strategies for Neural Network-based Collaborative Filtering", "comments": "This is a longer version (with supplementary attached) of the KDD'17\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural networks have inspired people to design hybrid\nrecommendation algorithms that can incorporate both (1) user-item interaction\ninformation and (2) content information including image, audio, and text.\nDespite their promising results, neural network-based recommendation algorithms\npose extensive computational costs, making it challenging to scale and improve\nupon. In this paper, we propose a general neural network-based recommendation\nframework, which subsumes several existing state-of-the-art recommendation\nalgorithms, and address the efficiency issue by investigating sampling\nstrategies in the stochastic gradient descent training for the framework. We\ntackle this issue by first establishing a connection between the loss functions\nand the user-item interaction bipartite graph, where the loss function terms\nare defined on links while major computation burdens are located at nodes. We\ncall this type of loss functions \"graph-based\" loss functions, for which varied\nmini-batch sampling strategies can have different computational costs. Based on\nthe insight, three novel sampling strategies are proposed, which can\nsignificantly improve the training efficiency of the proposed framework (up to\n$\\times 30$ times speedup in our experiments), as well as improving the\nrecommendation performance. Theoretical analysis is also provided for both the\ncomputational cost and the convergence. We believe the study of sampling\nstrategies have further implications on general graph-based loss functions, and\nwould also enable more research under the neural network-based recommendation\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 22:56:40 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Chen", "Ting", ""], ["Sun", "Yizhou", ""], ["Shi", "Yue", ""], ["Hong", "Liangjie", ""]]}, {"id": "1706.07888", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Marcin Szubert, Josh C. Bongard, Christian Skalka", "title": "Evolving Spatially Aggregated Features from Satellite Imagery for\n  Regional Modeling", "comments": null, "journal-ref": "Parallel Problem Solving from Nature - PPSN XIV. PPSN 2016.\n  Lecture Notes in Computer Science, vol 9921. Springer, Cham", "doi": "10.1007/978-3-319-45823-6_66", "report-no": null, "categories": "stat.ML cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite imagery and remote sensing provide explanatory variables at\nrelatively high resolutions for modeling geospatial phenomena, yet regional\nsummaries are often desirable for analysis and actionable insight. In this\npaper, we propose a novel method of inducing spatial aggregations as a\ncomponent of the machine learning process, yielding regional model features\nwhose construction is driven by model prediction performance rather than prior\nassumptions. Our results demonstrate that Genetic Programming is particularly\nwell suited to this type of feature construction because it can automatically\nsynthesize appropriate aggregations, as well as better incorporate them into\npredictive models compared to other regression methods we tested. In our\nexperiments we consider a specific problem instance and real-world dataset\nrelevant to predicting snow properties in high-mountain Asia.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 01:25:12 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 17:42:18 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Kriegman", "Sam", ""], ["Szubert", "Marcin", ""], ["Bongard", "Josh C.", ""], ["Skalka", "Christian", ""]]}, {"id": "1706.07896", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "Reservoir Computing on the Hypersphere", "comments": "12 pages, 6 figures, Int. J. Mod. Phys. C, 2017", "journal-ref": null, "doi": "10.1142/S0129183117500954", "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) refers to a Recurrent Neural Networks (RNNs)\nframework, frequently used for sequence learning and time series prediction.\nThe RC system consists of a random fixed-weight RNN (the input-hidden reservoir\nlayer) and a classifier (the hidden-output readout layer). Here we focus on the\nsequence learning problem, and we explore a different approach to RC. More\nspecifically, we remove the non-linear neural activation function, and we\nconsider an orthogonal reservoir acting on normalized states on the unit\nhypersphere. Surprisingly, our numerical results show that the system's memory\ncapacity exceeds the dimensionality of the reservoir, which is the upper bound\nfor the typical RC approach based on Echo State Networks (ESNs). We also show\nhow the proposed system can be applied to symmetric cryptography problems, and\nwe include a numerical implementation.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 02:10:53 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1706.07979", "submitter": "Gr\\'egoire Montavon", "authors": "Gr\\'egoire Montavon, Wojciech Samek, Klaus-Robert M\\\"uller", "title": "Methods for Interpreting and Understanding Deep Neural Networks", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.dsp.2017.10.011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an entry point to the problem of interpreting a deep\nneural network model and explaining its predictions. It is based on a tutorial\ngiven at ICASSP 2017. It introduces some recently proposed techniques of\ninterpretation, along with theory, tricks and recommendations, to make most\nefficient use of these techniques on real data. It also discusses a number of\npractical applications.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 16:25:06 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1706.08001", "submitter": "Zizhuang (Prince K) Wang Mr", "authors": "Zizhuang Wang", "title": "Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of\n  learning relational order via reinforcement learning procedure?", "comments": "Keywords: Convolutional-Restricted-Boltzmann-Machine, Reinforcement\n  learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we extend the conventional framework of\nconvolutional-Restricted-Boltzmann-Machine to learn highly abstract features\namong abitrary number of time related input maps by constructing a layer of\nmultiplicative units, which capture the relations among inputs. In many cases,\nmore than two maps are strongly related, so it is wise to make multiplicative\nunit learn relations among more input maps, in other words, to find the optimal\nrelational-order of each unit. In order to enable our machine to learn\nrelational order, we developed a reinforcement-learning method whose optimality\nis proven to train the network.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 20:56:27 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Wang", "Zizhuang", ""]]}, {"id": "1706.08082", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Marco Loog", "title": "Target contrastive pessimistic risk for robust domain adaptation", "comments": "35 pages, 3 figures, 6 tables, 2 algorithms, 1 theorem", "journal-ref": null, "doi": "10.1016/j.patrec.2021.05.005", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domain adaptation, classifiers with information from a source domain adapt\nto generalize to a target domain. However, an adaptive classifier can perform\nworse than a non-adaptive classifier due to invalid assumptions, increased\nsensitivity to estimation errors or model misspecification. Our goal is to\ndevelop a domain-adaptive classifier that is robust in the sense that it does\nnot rely on restrictive assumptions on how the source and target domains relate\nto each other and that it does not perform worse than the non-adaptive\nclassifier. We formulate a conservative parameter estimator that only deviates\nfrom the source classifier when a lower risk is guaranteed for all possible\nlabellings of the given target samples. We derive the classical least-squares\nand discriminant analysis cases and show that these perform on par with\nstate-of-the-art domain adaptive classifiers in sample selection bias settings,\nwhile outperforming them in more general domain adaptation settings.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 11:48:09 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Loog", "Marco", ""]]}, {"id": "1706.08110", "submitter": "Yunfei Ye", "authors": "Yunfei Ye", "title": "The Matrix Hilbert Space and Its Application to Matrix Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical studies have proven that the Hilbert space has remarkable\nperformance in many fields of applications. Frames in tensor product of Hilbert\nspaces were introduced to generalize the inner product to high-order tensors.\nHowever, these techniques require tensor decomposition which could lead to the\nloss of information and it is a NP-hard problem to determine the rank of\ntensors. Here, we present a new framework, namely matrix Hilbert space to\nperform a matrix inner product space when data observations are represented as\nmatrices. We preserve the structure of initial data and multi-way correlation\namong them is captured in the process. In addition, we extend the reproducing\nkernel Hilbert space (RKHS) to reproducing kernel matrix Hilbert space (RKMHS)\nand propose an equivalent condition of the space uses of the certain kernel\nfunction. A new family of kernels is introduced in our framework to apply the\nclassifier of Support Tensor Machine(STM) and comparative experiments are\nperformed on a number of real-world datasets to support our contributions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 14:07:44 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 08:57:33 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ye", "Yunfei", ""]]}, {"id": "1706.08137", "submitter": "Rick Farouni", "authors": "Rick Farouni", "title": "A Contemporary Overview of Probabilistic Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we provide a conceptual overview of latent variable models\nwithin a probabilistic modeling framework, an overview that emphasizes the\ncompositional nature and the interconnectedness of the seemingly disparate\nmodels commonly encountered in statistical practice.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 16:37:38 GMT"}, {"version": "v2", "created": "Sun, 9 Jul 2017 18:21:33 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Farouni", "Rick", ""]]}, {"id": "1706.08141", "submitter": "Bin Hu", "authors": "Bin Hu, Peter Seiler, Anders Rantzer", "title": "A Unified Analysis of Stochastic Optimization Methods Using Jump System\n  Theory and Quadratic Constraints", "comments": "To Appear in Proceedings of the Annual Conference on Learning Theory\n  (COLT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a simple routine unifying the analysis of several important\nrecently-developed stochastic optimization methods including SAGA, Finito, and\nstochastic dual coordinate ascent (SDCA). First, we show an intrinsic\nconnection between stochastic optimization methods and dynamic jump systems,\nand propose a general jump system model for stochastic optimization methods.\nOur proposed model recovers SAGA, SDCA, Finito, and SAG as special cases. Then\nwe combine jump system theory with several simple quadratic inequalities to\nderive sufficient conditions for convergence rate certifications of the\nproposed jump system model under various assumptions (with or without\nindividual convexity, etc). The derived conditions are linear matrix\ninequalities (LMIs) whose sizes roughly scale with the size of the training\nset. We make use of the symmetry in the stochastic optimization methods and\nreduce these LMIs to some equivalent small LMIs whose sizes are at most 3 by 3.\nWe solve these small LMIs to provide analytical proofs of new convergence rates\nfor SAGA, Finito and SDCA (with or without individual convexity). We also\nexplain why our proposed LMI fails in analyzing SAG. We reveal a key difference\nbetween SAG and other methods, and briefly discuss how to extend our LMI\nanalysis for SAG. An advantage of our approach is that the proposed analysis\ncan be automated for a large class of stochastic methods under various\nassumptions (with or without individual convexity, etc).\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 16:55:12 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Hu", "Bin", ""], ["Seiler", "Peter", ""], ["Rantzer", "Anders", ""]]}, {"id": "1706.08146", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Kai Sheng Tai, Peter Bailis, Gregory Valiant", "title": "Compressed Factorization: Fast and Accurate Low-Rank Factorization of\n  Compressively-Sensed Data", "comments": "Updates for ICML'19 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What learning algorithms can be run directly on compressively-sensed data? In\nthis work, we consider the question of accurately and efficiently computing\nlow-rank matrix or tensor factorizations given data compressed via random\nprojections. We examine the approach of first performing factorization in the\ncompressed domain, and then reconstructing the original high-dimensional\nfactors from the recovered (compressed) factors. In both the matrix and tensor\nsettings, we establish conditions under which this natural approach will\nprovably recover the original factors. While it is well-known that random\nprojections preserve a number of geometric properties of a dataset, our work\ncan be viewed as showing that they can also preserve certain solutions of\nnon-convex, NP-Hard problems like non-negative matrix factorization. We support\nthese theoretical results with experiments on synthetic data and demonstrate\nthe practical applicability of compressed factorization on real-world gene\nexpression and EEG time series datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 17:47:16 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 09:13:19 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 08:27:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sharan", "Vatsal", ""], ["Tai", "Kai Sheng", ""], ["Bailis", "Peter", ""], ["Valiant", "Gregory", ""]]}, {"id": "1706.08171", "submitter": "Pierre Ablin", "authors": "Pierre Ablin, Jean-Fran\\c{c}ois Cardoso and Alexandre Gramfort", "title": "Faster independent component analysis by preconditioning with Hessian\n  approximations", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2844203", "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) is a technique for unsupervised\nexploration of multi-channel data that is widely used in observational\nsciences. In its classic form, ICA relies on modeling the data as linear\nmixtures of non-Gaussian independent sources. The maximization of the\ncorresponding likelihood is a challenging problem if it has to be completed\nquickly and accurately on large sets of real data. We introduce the\nPreconditioned ICA for Real Data (Picard) algorithm, which is a relative L-BFGS\nalgorithm preconditioned with sparse Hessian approximations. Extensive\nnumerical comparisons to several algorithms of the same class demonstrate the\nsuperior performance of the proposed technique, especially on real data, for\nwhich the ICA model does not necessarily hold.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 20:47:33 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 00:51:32 GMT"}, {"version": "v3", "created": "Fri, 8 Sep 2017 16:43:28 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Ablin", "Pierre", ""], ["Cardoso", "Jean-Fran\u00e7ois", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1706.08203", "submitter": "Ladislav Rampasek", "authors": "Ladislav Rampasek, Daniel Hidru, Petr Smirnov, Benjamin Haibe-Kains\n  and Anna Goldenberg", "title": "Dr.VAE: Drug Response Variational Autoencoder", "comments": "submitted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two deep generative models based on Variational Autoencoders to\nimprove the accuracy of drug response prediction. Our models, Perturbation\nVariational Autoencoder and its semi-supervised extension, Drug Response\nVariational Autoencoder (Dr.VAE), learn latent representation of the underlying\ngene states before and after drug application that depend on: (i) drug-induced\nbiological change of each gene and (ii) overall treatment response outcome. Our\nVAE-based models outperform the current published benchmarks in the field by\nanywhere from 3 to 11% AUROC and 2 to 30% AUPR. In addition, we found that\nbetter reconstruction accuracy does not necessarily lead to improvement in\nclassification accuracy and that jointly trained models perform better than\nmodels that minimize reconstruction error independently.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 01:41:04 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 14:59:22 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Rampasek", "Ladislav", ""], ["Hidru", "Daniel", ""], ["Smirnov", "Petr", ""], ["Haibe-Kains", "Benjamin", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1706.08217", "submitter": "Shujiao Huang", "authors": "Zhenzhen Zhong, Shujiao Huang, Cheng Zhan, Licheng Zhang, Zhiwei Xiao,\n  Chang-Chun Wang, Pei Yang", "title": "An Effective Way to Improve YouTube-8M Classification Accuracy in Google\n  Cloud Platform", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale datasets have played a significant role in progress of neural\nnetwork and deep learning areas. YouTube-8M is such a benchmark dataset for\ngeneral multi-label video classification. It was created from over 7 million\nYouTube videos (450,000 hours of video) and includes video labels from a\nvocabulary of 4716 classes (3.4 labels/video on average). It also comes with\npre-extracted audio & visual features from every second of video (3.2 billion\nfeature vectors in total). Google cloud recently released the datasets and\norganized 'Google Cloud & YouTube-8M Video Understanding Challenge' on Kaggle.\nCompetitors are challenged to develop classification algorithms that assign\nvideo-level labels using the new and improved Youtube-8M V2 dataset. Inspired\nby the competition, we started exploration of audio understanding and\nclassification using deep learning algorithms and ensemble methods. We built\nseveral baseline predictions according to the benchmark paper and public github\ntensorflow code. Furthermore, we improved global prediction accuracy (GAP) from\nbase level 77% to 80.7% through approaches of ensemble.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 03:50:51 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Zhong", "Zhenzhen", ""], ["Huang", "Shujiao", ""], ["Zhan", "Cheng", ""], ["Zhang", "Licheng", ""], ["Xiao", "Zhiwei", ""], ["Wang", "Chang-Chun", ""], ["Yang", "Pei", ""]]}, {"id": "1706.08222", "submitter": "Edward Chen", "authors": "Edward Chen", "title": "YouTube-8M Video Understanding Challenge Approach and Applications", "comments": "YouTube-8M Workshop submission, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the YouTube-8M Video Understanding Challenge hosted as\na Kaggle competition and also describes my approach to experimenting with\nvarious models. For each of my experiments, I provide the score result as well\nas possible improvements to be made. Towards the end of the paper, I discuss\nthe various ensemble learning techniques that I applied on the dataset which\nsignificantly boosted my overall competition score. At last, I discuss the\nexciting future of video understanding research and also the many applications\nthat such research could significantly improve.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 04:15:55 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Chen", "Edward", ""]]}, {"id": "1706.08263", "submitter": "Didong Li", "authors": "Didong Li, Minerva Mukhopadhyay and David B. Dunson", "title": "Efficient Manifold and Subspace Approximations with Spherelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data lying in a high dimensional ambient space are commonly thought to have a\nmuch lower intrinsic dimension. In particular, the data may be concentrated\nnear a lower-dimensional subspace or manifold. There is an immense literature\nfocused on approximating the unknown subspace, and in exploiting such\napproximations in clustering, data compression, and building of predictive\nmodels. Most of the literature relies on approximating subspaces using a\nlocally linear, and potentially multiscale, dictionary. In this article, we\npropose a simple and general alternative, which instead uses pieces of spheres,\nor spherelets, to locally approximate the unknown subspace. Theory is developed\nshowing that spherelets can produce lower covering numbers and MSEs for many\nmanifolds. We develop spherical principal components analysis (SPCA). Results\nrelative to state-of-the-art competitors show gains in ability to accurately\napproximate the subspace with fewer components. In addition, unlike most\ncompetitors, our approach can be used for data denoising and can efficiently\nembed new data without retraining. The methods are illustrated with standard\ntoy manifold learning examples, and applications to multiple real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 07:45:55 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 21:57:21 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 17:30:25 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Li", "Didong", ""], ["Mukhopadhyay", "Minerva", ""], ["Dunson", "David B.", ""]]}, {"id": "1706.08269", "submitter": "Torsten Hothorn", "authors": "Torsten Hothorn", "title": "Top-down Transformation Choice", "comments": null, "journal-ref": "Statistical Modelling 2018", "doi": "10.1177/1471082X17748081", "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simple models are preferred over complex models, but over-simplistic models\ncould lead to erroneous interpretations. The classical approach is to start\nwith a simple model, whose shortcomings are assessed in residual-based model\ndiagnostics. Eventually, one increases the complexity of this initial overly\nsimple model and obtains a better-fitting model. I illustrate how\ntransformation analysis can be used as an alternative approach to model choice.\nInstead of adding complexity to simple models, step-wise complexity reduction\nis used to help identify simpler and better-interpretable models. As an\nexample, body mass index distributions in Switzerland are modelled by means of\ntransformation models to understand the impact of sex, age, smoking and other\nlifestyle factors on a person's body mass index. In this process, I searched\nfor a compromise between model fit and model interpretability. Special emphasis\nis given to the understanding of the connections between transformation models\nof increasing complexity. The models used in this analysis ranged from\nevergreens, such as the normal linear regression model with constant variance,\nto novel models with extremely flexible conditional distribution functions,\nsuch as transformation trees and transformation forests.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 08:08:01 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 13:09:24 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hothorn", "Torsten", ""]]}, {"id": "1706.08344", "submitter": "Felix Abramovich", "authors": "Felix Abramovich and Vadim Grinshtein", "title": "High-dimensional classification by sparse logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high-dimensional binary classification by sparse logistic\nregression. We propose a model/feature selection procedure based on penalized\nmaximum likelihood with a complexity penalty on the model size and derive the\nnon-asymptotic bounds for the resulting misclassification excess risk. The\nbounds can be reduced under the additional low-noise condition. The proposed\ncomplexity penalty is remarkably related to the VC-dimension of a set of sparse\nlinear classifiers. Implementation of any complexity penalty-based criterion,\nhowever, requires a combinatorial search over all possible models. To find a\nmodel selection procedure computationally feasible for high-dimensional data,\nwe extend the Slope estimator for logistic regression and show that under an\nadditional weighted restricted eigenvalue condition it is rate-optimal in the\nminimax sense.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 12:42:42 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 08:49:45 GMT"}, {"version": "v3", "created": "Sun, 18 Nov 2018 10:18:24 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Abramovich", "Felix", ""], ["Grinshtein", "Vadim", ""]]}, {"id": "1706.08359", "submitter": "Huan Zhang", "authors": "Huan Zhang, Si Si, Cho-Jui Hsieh", "title": "GPU-acceleration for Large-scale Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel massively parallel algorithm for\naccelerating the decision tree building procedure on GPUs (Graphics Processing\nUnits), which is a crucial step in Gradient Boosted Decision Tree (GBDT) and\nrandom forests training. Previous GPU based tree building algorithms are based\non parallel multi-scan or radix sort to find the exact tree split, and thus\nsuffer from scalability and performance issues. We show that using a histogram\nbased algorithm to approximately find the best split is more efficient and\nscalable on GPU. By identifying the difference between classical GPU-based\nimage histogram construction and the feature histogram construction in decision\ntree training, we develop a fast feature histogram building kernel on GPU with\ncarefully designed computational and memory access sequence to reduce atomic\nupdate conflict and maximize GPU utilization. Our algorithm can be used as a\ndrop-in replacement for histogram construction in popular tree boosting systems\nto improve their scalability. As an example, to train GBDT on epsilon dataset,\nour method using a main-stream GPU is 7-8 times faster than histogram based\nalgorithm on CPU in LightGBM and 25 times faster than the exact-split finding\nalgorithm in XGBoost on a dual-socket 28-core Xeon server, while achieving\nsimilar prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 13:27:29 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Zhang", "Huan", ""], ["Si", "Si", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1706.08457", "submitter": "Karl Kumbier", "authors": "Sumanta Basu, Karl Kumbier, James B. Brown, Bin Yu", "title": "Iterative Random Forests to detect predictive and stable high-order\n  interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genomics has revolutionized biology, enabling the interrogation of whole\ntranscriptomes, genome-wide binding sites for proteins, and many other\nmolecular processes. However, individual genomic assays measure elements that\ninteract in vivo as components of larger molecular machines. Understanding how\nthese high-order interactions drive gene expression presents a substantial\nstatistical challenge. Building on Random Forests (RF), Random Intersection\nTrees (RITs), and through extensive, biologically inspired simulations, we\ndeveloped the iterative Random Forest algorithm (iRF). iRF trains a\nfeature-weighted ensemble of decision trees to detect stable, high-order\ninteractions with same order of computational cost as RF. We demonstrate the\nutility of iRF for high-order interaction discovery in two prediction problems:\nenhancer activity in the early Drosophila embryo and alternative splicing of\nprimary transcripts in human derived cell lines. In Drosophila, among the 20\npairwise transcription factor interactions iRF identifies as stable (returned\nin more than half of bootstrap replicates), 80% have been previously reported\nas physical interactions. Moreover, novel third-order interactions, e.g.\nbetween Zelda (Zld), Giant (Gt), and Twist (Twi), suggest high-order\nrelationships that are candidates for follow-up experiments. In human-derived\ncells, iRF re-discovered a central role of H3K36me3 in chromatin-mediated\nsplicing regulation, and identified novel 5th and 6th order interactions,\nindicative of multi-valent nucleosomes with specific roles in splicing\nregulation. By decoupling the order of interactions from the computational cost\nof identification, iRF opens new avenues of inquiry into the molecular\nmechanisms underlying genome biology.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 16:17:41 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 17:10:04 GMT"}, {"version": "v3", "created": "Thu, 26 Oct 2017 18:30:41 GMT"}, {"version": "v4", "created": "Sat, 23 Dec 2017 17:27:28 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Basu", "Sumanta", ""], ["Kumbier", "Karl", ""], ["Brown", "James B.", ""], ["Yu", "Bin", ""]]}, {"id": "1706.08470", "submitter": "Carlo Baldassi", "authors": "Carlo Baldassi, Riccardo Zecchina", "title": "Efficiency of quantum versus classical annealing in non-convex learning\n  problems", "comments": "31 pages, 10 figures", "journal-ref": "Proceedings of the National Academy of Sciences Jan 2018,\n  201711456", "doi": "10.1073/pnas.1711456115", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum annealers aim at solving non-convex optimization problems by\nexploiting cooperative tunneling effects to escape local minima. The underlying\nidea consists in designing a classical energy function whose ground states are\nthe sought optimal solutions of the original optimization problem and add a\ncontrollable quantum transverse field to generate tunneling processes. A key\nchallenge is to identify classes of non-convex optimization problems for which\nquantum annealing remains efficient while thermal annealing fails. We show that\nthis happens for a wide class of problems which are central to machine\nlearning. Their energy landscapes is dominated by local minima that cause\nexponential slow down of classical thermal annealers while simulated quantum\nannealing converges efficiently to rare dense regions of optimal solutions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 16:43:49 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 09:00:51 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 21:57:11 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Baldassi", "Carlo", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1706.08491", "submitter": "Lev Givon", "authors": "Lev E. Givon (1), Laura J. Mariano (1), David O'Dowd (1), John M.\n  Irvine (1), Abraham R. Schneider (1) ((1) The Charles Stark Draper\n  Laboratory, Inc.)", "title": "Cognitive Subscore Trajectory Prediction in Alzheimer's Disease", "comments": "Accepted for presentation in BioImage Informatics Conference 2017\n  (9/19/2017) and SIIM Conference on Machine Learning in Medical Imaging\n  (C-MIMI) 2017 (9/26/2017). Data used in the preparation of this article were\n  obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database\n  (http://adni.loni.usc.edu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate diagnosis of Alzheimer's Disease (AD) entails clinical evaluation of\nmultiple cognition metrics and biomarkers. Metrics such as the Alzheimer's\nDisease Assessment Scale - Cognitive test (ADAS-cog) comprise multiple\nsubscores that quantify different aspects of a patient's cognitive state such\nas learning, memory, and language production/comprehension. Although\ncomputer-aided diagnostic techniques for classification of a patient's current\ndisease state exist, they provide little insight into the relationship between\nchanges in brain structure and different aspects of a patient's cognitive state\nthat occur over time in AD. We have developed a Convolutional Neural Network\narchitecture that can concurrently predict the trajectories of the 13 subscores\ncomprised by a subject's ADAS-cog examination results from a current minimally\npreprocessed structural MRI scan up to 36 months from image acquisition time\nwithout resorting to manual feature extraction. Mean performance metrics are\nwithin range of those of existing techniques that require manual feature\nselection and are limited to predicting aggregate scores.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:29:42 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 14:24:28 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Givon", "Lev E.", ""], ["Mariano", "Laura J.", ""], ["O'Dowd", "David", ""], ["Irvine", "John M.", ""], ["Schneider", "Abraham R.", ""]]}, {"id": "1706.08495", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Jos\\'e Miguel Hern\\'andez-Lobato, Finale Doshi-Velez,\n  Steffen Udluft", "title": "Uncertainty Decomposition in Bayesian Neural Networks with Latent\n  Variables", "comments": "This article is superseded by arXiv:1710.07283", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) with latent variables are probabilistic\nmodels which can automatically identify complex stochastic patterns in the\ndata. We describe and study in these models a decomposition of predictive\nuncertainty into its epistemic and aleatoric components. First, we show how\nsuch a decomposition arises naturally in a Bayesian active learning scenario by\nfollowing an information theoretic approach. Second, we use a similar\ndecomposition to develop a novel risk sensitive objective for safe\nreinforcement learning (RL). This objective minimizes the effect of model bias\nin environments whose stochastic dynamics are described by BNNs with latent\nvariables. Our experiments illustrate the usefulness of the resulting\ndecomposition in active learning and safe RL settings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:36:28 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 19:05:43 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Depeweg", "Stefan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Doshi-Velez", "Finale", ""], ["Udluft", "Steffen", ""]]}, {"id": "1706.08498", "submitter": "Matus Telgarsky", "authors": "Peter Bartlett, Dylan J. Foster, Matus Telgarsky", "title": "Spectrally-normalized margin bounds for neural networks", "comments": "Comparison to arXiv v1: 1-norm in main bound refined to\n  (2,1)-group-norm. Comparison to NIPS camera ready: typo fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a margin-based multiclass generalization bound for neural\nnetworks that scales with their margin-normalized \"spectral complexity\": their\nLipschitz constant, meaning the product of the spectral norms of the weight\nmatrices, times a certain correction factor. This bound is empirically\ninvestigated for a standard AlexNet network trained with SGD on the mnist and\ncifar10 datasets, with both original and random labels; the bound, the\nLipschitz constants, and the excess risks are all in direct correlation,\nsuggesting both that SGD selects predictors whose complexity scales with the\ndifficulty of the learning task, and secondly that the presented bound is\nsensitive to this complexity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:43:48 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 06:08:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Bartlett", "Peter", ""], ["Foster", "Dylan J.", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1706.08500", "submitter": "Martin Heusel", "authors": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler,\n  Sepp Hochreiter", "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash\n  Equilibrium", "comments": "Implementations are available at: https://github.com/bioinf-jku/TTUR", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS 2017)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) excel at creating realistic images\nwith complex models for which maximum likelihood is infeasible. However, the\nconvergence of GAN training has still not been proved. We propose a two\ntime-scale update rule (TTUR) for training GANs with stochastic gradient\ndescent on arbitrary GAN loss functions. TTUR has an individual learning rate\nfor both the discriminator and the generator. Using the theory of stochastic\napproximation, we prove that the TTUR converges under mild assumptions to a\nstationary local Nash equilibrium. The convergence carries over to the popular\nAdam optimization, for which we prove that it follows the dynamics of a heavy\nball with friction and thus prefers flat minima in the objective landscape. For\nthe evaluation of the performance of GANs at image generation, we introduce the\n\"Fr\\'echet Inception Distance\" (FID) which captures the similarity of generated\nimages to real ones better than the Inception Score. In experiments, TTUR\nimproves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP)\noutperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN\nBedrooms, and the One Billion Word Benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:45:23 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 15:06:08 GMT"}, {"version": "v3", "created": "Wed, 28 Jun 2017 16:36:56 GMT"}, {"version": "v4", "created": "Thu, 13 Jul 2017 09:15:29 GMT"}, {"version": "v5", "created": "Wed, 8 Nov 2017 16:25:21 GMT"}, {"version": "v6", "created": "Fri, 12 Jan 2018 14:05:44 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Heusel", "Martin", ""], ["Ramsauer", "Hubert", ""], ["Unterthiner", "Thomas", ""], ["Nessler", "Bernhard", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1706.08519", "submitter": "Ruofei Zhao", "authors": "Ya'acov Ritov, Yuekai Sun, Ruofei Zhao", "title": "On conditional parity as a notion of non-discrimination in machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify conditional parity as a general notion of non-discrimination in\nmachine learning. In fact, several recently proposed notions of\nnon-discrimination, including a few counterfactual notions, are instances of\nconditional parity. We show that conditional parity is amenable to statistical\nanalysis by studying randomization as a general mechanism for achieving\nconditional parity and a kernel-based test of conditional parity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:41:20 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Ritov", "Ya'acov", ""], ["Sun", "Yuekai", ""], ["Zhao", "Ruofei", ""]]}, {"id": "1706.08566", "submitter": "Kristof Sch\\\"utt", "authors": "Kristof T. Sch\\\"utt, Pieter-Jan Kindermans, Huziel E. Sauceda, Stefan\n  Chmiela, Alexandre Tkatchenko, Klaus-Robert M\\\"uller", "title": "SchNet: A continuous-filter convolutional neural network for modeling\n  quantum interactions", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 30 (2017), pp.\n  992-1002", "doi": null, "report-no": null, "categories": "stat.ML physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has the potential to revolutionize quantum chemistry as it is\nideally suited to learn representations for structured data and speed up the\nexploration of chemical space. While convolutional neural networks have proven\nto be the first choice for images, audio and video data, the atoms in molecules\nare not restricted to a grid. Instead, their precise locations contain\nessential physical information, that would get lost if discretized. Thus, we\npropose to use continuous-filter convolutional layers to be able to model local\ncorrelations without requiring the data to lie on a grid. We apply those layers\nin SchNet: a novel deep learning architecture modeling quantum interactions in\nmolecules. We obtain a joint model for the total energy and interatomic forces\nthat follows fundamental quantum-chemical principles. This includes\nrotationally invariant energy predictions and a smooth, differentiable\npotential energy surface. Our architecture achieves state-of-the-art\nperformance for benchmarks of equilibrium molecules and molecular dynamics\ntrajectories. Finally, we introduce a more challenging benchmark with chemical\nand structural variations that suggests the path for further work.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 19:12:37 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 12:42:44 GMT"}, {"version": "v3", "created": "Fri, 7 Jul 2017 12:15:46 GMT"}, {"version": "v4", "created": "Fri, 20 Oct 2017 11:20:40 GMT"}, {"version": "v5", "created": "Tue, 19 Dec 2017 19:44:04 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Sch\u00fctt", "Kristof T.", ""], ["Kindermans", "Pieter-Jan", ""], ["Sauceda", "Huziel E.", ""], ["Chmiela", "Stefan", ""], ["Tkatchenko", "Alexandre", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1706.08580", "submitter": "Angelos Katharopoulos", "authors": "Angelos Katharopoulos, Despoina Paschalidou, Christos Diou and\n  Anastasios Delopoulos", "title": "Learning Local Feature Aggregation Functions with Backpropagation", "comments": "In Proceedings of the 25th European Signal Processing Conference\n  (EUSIPCO 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a family of local feature aggregation functions and a\nnovel method to estimate their parameters, such that they generate optimal\nrepresentations for classification (or any task that can be expressed as a cost\nfunction minimization problem). To achieve that, we compose the local feature\naggregation function with the classifier cost function and we backpropagate the\ngradient of this cost function in order to update the local feature aggregation\nfunction parameters. Experiments on synthetic datasets indicate that our method\ndiscovers parameters that model the class-relevant information in addition to\nthe local feature space. Further experiments on a variety of motion and visual\ndescriptors, both on image and video datasets, show that our method outperforms\nother state-of-the-art local feature aggregation functions, such as Bag of\nWords, Fisher Vectors and VLAD, by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 20:13:41 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Katharopoulos", "Angelos", ""], ["Paschalidou", "Despoina", ""], ["Diou", "Christos", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "1706.08606", "submitter": "David Barrett", "authors": "Samuel Ritter, David G.T. Barrett, Adam Santoro and Matt M. Botvinick", "title": "Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved unprecedented performance on a wide\nrange of complex tasks, rapidly outpacing our understanding of the nature of\ntheir solutions. This has caused a recent surge of interest in methods for\nrendering modern neural systems more interpretable. In this work, we propose to\naddress the interpretability problem in modern DNNs using the rich history of\nproblem descriptions, theories and experimental methods developed by cognitive\npsychologists to study the human mind. To explore the potential value of these\ntools, we chose a well-established analysis from developmental psychology that\nexplains how children learn word labels for objects, and applied that analysis\nto DNNs. Using datasets of stimuli inspired by the original cognitive\npsychology experiments, we find that state-of-the-art one shot learning models\ntrained on ImageNet exhibit a similar bias to that observed in humans: they\nprefer to categorize objects according to shape rather than color. The\nmagnitude of this shape bias varies greatly among architecturally identical,\nbut differently seeded models, and even fluctuates within seeds throughout\ntraining, despite nearly equivalent classification performance. These results\ndemonstrate the capability of tools from cognitive psychology for exposing\nhidden computational properties of DNNs, while concurrently providing us with a\ncomputational model for human word learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 21:31:18 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 17:52:55 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Ritter", "Samuel", ""], ["Barrett", "David G. T.", ""], ["Santoro", "Adam", ""], ["Botvinick", "Matt M.", ""]]}, {"id": "1706.08672", "submitter": "Tselil Schramm", "authors": "Tselil Schramm and David Steurer", "title": "Fast and robust tensor decomposition with applications to dictionary\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop fast spectral algorithms for tensor decomposition that match the\nrobustness guarantees of the best known polynomial-time algorithms for this\nproblem based on the sum-of-squares (SOS) semidefinite programming hierarchy.\n  Our algorithms can decompose a 4-tensor with $n$-dimensional orthonormal\ncomponents in the presence of error with constant spectral norm (when viewed as\nan $n^2$-by-$n^2$ matrix). The running time is $n^5$ which is close to linear\nin the input size $n^4$.\n  We also obtain algorithms with similar running time to learn sparsely-used\northogonal dictionaries even when feature representations have constant\nrelative sparsity and non-independent coordinates.\n  The only previous polynomial-time algorithms to solve these problem are based\non solving large semidefinite programs. In contrast, our algorithms are easy to\nimplement directly and are based on spectral projections and tensor-mode\nrearrangements.\n  Or work is inspired by recent of Hopkins, Schramm, Shi, and Steurer (STOC'16)\nthat shows how fast spectral algorithms can achieve the guarantees of SOS for\naverage-case problems. In this work, we introduce general techniques to capture\nthe guarantees of SOS for worst-case problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 05:12:39 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Schramm", "Tselil", ""], ["Steurer", "David", ""]]}, {"id": "1706.08699", "submitter": "Mohsen Mahoor", "authors": "Mohana Alanazi and Mohsen Mahoor and Amin Khodaei", "title": "Two-Stage Hybrid Day-Ahead Solar Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power supply from renewable resources is on a global rise where it is\nforecasted that renewable generation will surpass other types of generation in\na foreseeable future. Increased generation from renewable resources, mainly\nsolar and wind, exposes the power grid to more vulnerabilities, conceivably due\nto their variable generation, thus highlighting the importance of accurate\nforecasting methods. This paper proposes a two-stage day-ahead solar\nforecasting method that breaks down the forecasting into linear and nonlinear\nparts, determines subsequent forecasts, and accordingly, improves accuracy of\nthe obtained results. To further reduce the error resulted from nonstationarity\nof the historical solar radiation data, a data processing approach, including\npre-process and post-process levels, is integrated with the proposed method.\nNumerical simulations on three test days with different weather conditions\nexhibit the effectiveness of the proposed two-stage model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 07:37:27 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Alanazi", "Mohana", ""], ["Mahoor", "Mohsen", ""], ["Khodaei", "Amin", ""]]}, {"id": "1706.08811", "submitter": "Magda Gregorova", "authors": "Magda Gregorov\\'a, Alexandros Kalousis, and St\\'ephane\n  Marchand-Maillet", "title": "Forecasting and Granger Modelling with Non-linear Dynamical Dependencies", "comments": "Accepted for ECML-PKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional linear methods for forecasting multivariate time series are not\nable to satisfactorily model the non-linear dependencies that may exist in\nnon-Gaussian series. We build on the theory of learning vector-valued functions\nin the reproducing kernel Hilbert space and develop a method for learning\nprediction functions that accommodate such non-linearities. The method not only\nlearns the predictive function but also the matrix-valued kernel underlying the\nfunction search space directly from the data. Our approach is based on learning\nmultiple matrix-valued kernels, each of those composed of a set of input\nkernels and a set of output kernels learned in the cone of positive\nsemi-definite matrices. In addition to superior predictive performance in the\npresence of strong non-linearities, our method also recovers the hidden dynamic\nrelationships between the series and thus is a new alternative to existing\ngraphical Granger techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 12:19:39 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Gregorov\u00e1", "Magda", ""], ["Kalousis", "Alexandros", ""], ["Marchand-Maillet", "St\u00e9phane", ""]]}, {"id": "1706.08839", "submitter": "NhatHai Phan", "authors": "NhatHai Phan, Xintao Wu, and Dejing Dou", "title": "Preserving Differential Privacy in Convolutional Deep Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable development of deep learning in medicine and healthcare domain\npresents obvious privacy issues, when deep neural networks are built on users'\npersonal and highly sensitive data, e.g., clinical records, user profiles,\nbiomedical images, etc. However, only a few scientific studies on preserving\nprivacy in deep learning have been conducted. In this paper, we focus on\ndeveloping a private convolutional deep belief network (pCDBN), which\nessentially is a convolutional deep belief network (CDBN) under differential\nprivacy. Our main idea of enforcing epsilon-differential privacy is to leverage\nthe functional mechanism to perturb the energy-based objective functions of\ntraditional CDBNs, rather than their results. One key contribution of this work\nis that we propose the use of Chebyshev expansion to derive the approximate\npolynomial representation of objective functions. Our theoretical analysis\nshows that we can further derive the sensitivity and error bounds of the\napproximate polynomial representation. As a result, preserving differential\nprivacy in CDBNs is feasible. We applied our model in a health social network,\ni.e., YesiWell data, and in a handwriting digit dataset, i.e., MNIST data, for\nhuman behavior prediction, human behavior classification, and handwriting digit\nrecognition tasks. Theoretical analysis and rigorous experimental evaluations\nshow that the pCDBN is highly effective. It significantly outperforms existing\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 22:29:23 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 02:55:39 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Phan", "NhatHai", ""], ["Wu", "Xintao", ""], ["Dou", "Dejing", ""]]}, {"id": "1706.08884", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi and Rachid Guerraoui", "title": "When Neurons Fail", "comments": "2017 IEEE International Parallel and Distributed Processing\n  Symposium, Orlando, Florida", "journal-ref": null, "doi": "10.1109/IPDPS.2017.66", "report-no": null, "categories": "stat.ML cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view a neural network as a distributed system of which neurons can fail\nindependently, and we evaluate its robustness in the absence of any (recovery)\nlearning phase. We give tight bounds on the number of neurons that can fail\nwithout harming the result of a computation. To determine our bounds, we\nleverage the fact that neural activation functions are Lipschitz-continuous.\nOur bound is on a quantity, we call the \\textit{Forward Error Propagation},\ncapturing how much error is propagated by a neural network when a given number\nof components is failing, computing this quantity only requires looking at the\ntopology of the network, while experimentally assessing the robustness of a\nnetwork requires the costly experiment of looking at all the possible inputs\nand testing all the possible configurations of the network corresponding to\ndifferent failure situations, facing a discouraging combinatorial explosion.\n  We distinguish the case of neurons that can fail and stop their activity\n(crashed neurons) from the case of neurons that can fail by transmitting\narbitrary values (Byzantine neurons). Interestingly, as we show in the paper,\nour bound can easily be extended to the case where synapses can fail.\n  We show how our bound can be leveraged to quantify the effect of memory cost\nreduction on the accuracy of a neural network, to estimate the amount of\ninformation any neuron needs from its preceding layer, enabling thereby a\nboosting scheme that prevents neurons from waiting for unnecessary signals. We\nfinally discuss the trade-off between neural networks robustness and learning\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 14:31:09 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""]]}, {"id": "1706.08894", "submitter": "Mohamed Laib", "authors": "Mohamed Laib and Mikhail Kanevski", "title": "Unsupervised Feature Selection Based on Space Filling Concept", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with the adaptation of a new measure for the unsupervised\nfeature selection problems. The proposed measure is based on space filling\nconcept and is called the coverage measure. This measure was used for judging\nthe quality of an experimental space filling design. In the present work, the\ncoverage measure is adapted for selecting the smallest informative subset of\nvariables by reducing redundancy in data. This paper proposes a simple analogy\nto apply this measure. It is implemented in a filter algorithm for unsupervised\nfeature selection problems.\n  The proposed filter algorithm is robust with high dimensional data and can be\nimplemented without extra parameters. Further, it is tested with simulated data\nand real world case studies including environmental data and hyperspectral\nimage. Finally, the results are evaluated by using random forest algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 14:48:39 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Laib", "Mohamed", ""], ["Kanevski", "Mikhail", ""]]}, {"id": "1706.08934", "submitter": "Carlo Ciliberto", "authors": "Carlo Ciliberto, Dimitris Stamos and Massimiliano Pontil", "title": "Reexamining Low Rank Matrix Factorization for Trace Norm Regularization", "comments": "22 pages, 4 figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trace norm regularization is a widely used approach for learning low rank\nmatrices. A standard optimization strategy is based on formulating the problem\nas one of low rank matrix factorization which, however, leads to a non-convex\nproblem. In practice this approach works well, and it is often computationally\nfaster than standard convex solvers such as proximal gradient methods.\nNevertheless, it is not guaranteed to converge to a global optimum, and the\noptimization can be trapped at poor stationary points. In this paper we show\nthat it is possible to characterize all critical points of the non-convex\nproblem. This allows us to provide an efficient criterion to determine whether\na critical point is also a global minimizer. Our analysis suggests an iterative\nmeta-algorithm that dynamically expands the parameter space and allows the\noptimization to escape any non-global critical point, thereby converging to a\nglobal minimizer. The algorithm can be applied to problems such as matrix\ncompletion or multitask learning, and our analysis holds for any random\ninitialization of the factor matrices. Finally, we confirm the good performance\nof the algorithm on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 16:43:31 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 12:04:31 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 08:51:17 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Ciliberto", "Carlo", ""], ["Stamos", "Dimitris", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1706.08936", "submitter": "Mohammadreza Soltani", "authors": "Mohammadreza Soltani and Chinmay Hegde", "title": "Fast Algorithms for Learning Latent Variables in Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning latent variables in Gaussian graphical\nmodels. Existing methods for this problem assume that the precision matrix of\nthe observed variables is the superposition of a sparse and a low-rank\ncomponent. In this paper, we focus on the estimation of the low-rank component,\nwhich encodes the effect of marginalization over the latent variables. We\nintroduce fast, proper learning algorithms for this problem. In contrast with\nexisting approaches, our algorithms are manifestly non-convex. We support their\nefficacy via a rigorous theoretical analysis, and show that our algorithms\nmatch the best possible in terms of sample complexity, while achieving\ncomputational speed-ups over existing methods. We complement our theory with\nseveral numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 16:44:56 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 15:24:38 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Soltani", "Mohammadreza", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1706.08984", "submitter": "Greg Ver Steeg", "authors": "Greg Ver Steeg", "title": "Unsupervised Learning via Total Correlation Explanation", "comments": "Invited contribution for IJCAI 2017 Early Career Spotlight. 5 pages,\n  1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning by children and animals occurs effortlessly and largely without\nobvious supervision. Successes in automating supervised learning have not\ntranslated to the more ambiguous realm of unsupervised learning where goals and\nlabels are not provided. Barlow (1961) suggested that the signal that brains\nleverage for unsupervised learning is dependence, or redundancy, in the sensory\nenvironment. Dependence can be characterized using the information-theoretic\nmultivariate mutual information measure called total correlation. The principle\nof Total Cor-relation Ex-planation (CorEx) is to learn representations of data\nthat \"explain\" as much dependence in the data as possible. We review some\nmanifestations of this principle along with successes in unsupervised learning\nproblems across diverse domains including human behavior, biology, and\nlanguage.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 18:02:34 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Steeg", "Greg Ver", ""]]}, {"id": "1706.09060", "submitter": "Jonathan Schneider", "authors": "Mark Braverman, Jieming Mao, Jon Schneider, S. Matthew Weinberg", "title": "Multi-armed Bandit Problems with Strategic Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a strategic version of the multi-armed bandit problem, where each\narm is an individual strategic agent and we, the principal, pull one arm each\nround. When pulled, the arm receives some private reward $v_a$ and can choose\nan amount $x_a$ to pass on to the principal (keeping $v_a-x_a$ for itself). All\nnon-pulled arms get reward $0$. Each strategic arm tries to maximize its own\nutility over the course of $T$ rounds. Our goal is to design an algorithm for\nthe principal incentivizing these arms to pass on as much of their private\nrewards as possible.\n  When private rewards are stochastically drawn each round ($v_a^t \\leftarrow\nD_a$), we show that:\n  - Algorithms that perform well in the classic adversarial multi-armed bandit\nsetting necessarily perform poorly: For all algorithms that guarantee low\nregret in an adversarial setting, there exist distributions $D_1,\\ldots,D_k$\nand an approximate Nash equilibrium for the arms where the principal receives\nreward $o(T)$.\n  - Still, there exists an algorithm for the principal that induces a game\namong the arms where each arm has a dominant strategy. When each arm plays its\ndominant strategy, the principal sees expected reward $\\mu'T - o(T)$, where\n$\\mu'$ is the second-largest of the means $\\mathbb{E}[D_{a}]$. This algorithm\nmaintains its guarantee if the arms are non-strategic ($x_a = v_a$), and also\nif there is a mix of strategic and non-strategic arms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 21:58:00 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Braverman", "Mark", ""], ["Mao", "Jieming", ""], ["Schneider", "Jon", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "1706.09090", "submitter": "Huitian Lei", "authors": "Huitian Lei, Ambuj Tewari, Susan A. Murphy", "title": "An Actor-Critic Contextual Bandit Algorithm for Personalized Mobile\n  Health Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing technological sophistication and widespread use of smartphones and\nwearable devices provide opportunities for innovative and highly personalized\nhealth interventions. A Just-In-Time Adaptive Intervention (JITAI) uses\nreal-time data collection and communication capabilities of modern mobile\ndevices to deliver interventions in real-time that are adapted to the\nin-the-moment needs of the user. The lack of methodological guidance in\nconstructing data-based JITAIs remains a hurdle in advancing JITAI research\ndespite the increasing popularity of JITAIs among clinical scientists. In this\narticle, we make a first attempt to bridge this methodological gap by\nformulating the task of tailoring interventions in real-time as a contextual\nbandit problem. Interpretability requirements in the domain of mobile health\nlead us to formulate the problem differently from existing formulations\nintended for web applications such as ad or news article placement. Under the\nassumption of linear reward function, we choose the reward function (the\n\"critic\") parameterization separately from a lower dimensional parameterization\nof stochastic policies (the \"actor\"). We provide an online actor-critic\nalgorithm that guides the construction and refinement of a JITAI. Asymptotic\nproperties of the actor-critic algorithm are developed and backed up by\nnumerical experiments. Additional numerical experiments are conducted to test\nthe robustness of the algorithm when idealized assumptions used in the analysis\nof contextual bandit algorithm are breached.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 00:56:22 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Lei", "Huitian", ""], ["Tewari", "Ambuj", ""], ["Murphy", "Susan A.", ""]]}, {"id": "1706.09152", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Guanlin Li, Shuo Ren, Shujie Liu, Zhirui Zhang, Mu Li,\n  Ming Zhou", "title": "Generative Bridging Network in Neural Sequence Prediction", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to alleviate data sparsity and overfitting problems in maximum\nlikelihood estimation (MLE) for sequence prediction tasks, we propose the\nGenerative Bridging Network (GBN), in which a novel bridge module is introduced\nto assist the training of the sequence prediction model (the generator\nnetwork). Unlike MLE directly maximizing the conditional likelihood, the bridge\nextends the point-wise ground truth to a bridge distribution conditioned on it,\nand the generator is optimized to minimize their KL-divergence. Three different\nGBNs, namely uniform GBN, language-model GBN and coaching GBN, are proposed to\npenalize confidence, enhance language smoothness and relieve learning burden.\nExperiments conducted on two recognized sequence prediction tasks (machine\ntranslation and abstractive text summarization) show that our proposed GBNs can\nyield significant improvements over strong baselines. Furthermore, by analyzing\nsamples drawn from different bridges, expected influences on the generator are\nverified.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 07:44:17 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 16:24:41 GMT"}, {"version": "v3", "created": "Sun, 20 Aug 2017 11:17:13 GMT"}, {"version": "v4", "created": "Tue, 31 Oct 2017 17:49:11 GMT"}, {"version": "v5", "created": "Sat, 17 Mar 2018 22:03:58 GMT"}, {"version": "v6", "created": "Thu, 29 Nov 2018 22:29:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chen", "Wenhu", ""], ["Li", "Guanlin", ""], ["Ren", "Shuo", ""], ["Liu", "Shujie", ""], ["Zhang", "Zhirui", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""]]}, {"id": "1706.09200", "submitter": "Jaeyoon Yoo", "authors": "Jaeyoon Yoo, Heonseok Ha, Jihun Yi, Jongha Ryu, Chanju Kim, Jung-Woo\n  Ha, Young-Han Kim, and Sungroh Yoon", "title": "Energy-Based Sequence GANs for Recommendation and Their Connection to\n  Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems aim to find an accurate and efficient mapping from\nhistoric data of user-preferred items to a new item that is to be liked by a\nuser. Towards this goal, energy-based sequence generative adversarial nets\n(EB-SeqGANs) are adopted for recommendation by learning a generative model for\nthe time series of user-preferred items. By recasting the energy function as\nthe feature function, the proposed EB-SeqGANs is interpreted as an instance of\nmaximum-entropy imitation learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 10:12:01 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Yoo", "Jaeyoon", ""], ["Ha", "Heonseok", ""], ["Yi", "Jihun", ""], ["Ryu", "Jongha", ""], ["Kim", "Chanju", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Young-Han", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1706.09231", "submitter": "Benjamin Stucky", "authors": "Benjamin Stucky, Sara van de Geer", "title": "Asymptotic Confidence Regions for High-dimensional Structured Sparsity", "comments": "28 pages, 4 figures, 1 table", "journal-ref": null, "doi": "10.1109/TSP.2018.2807399", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of high-dimensional linear regression models, we propose two\nframeworks for constructing pointwise and group confidence sets for penalized\nestimators which incorporate prior knowledge about the organization of the\nnon-zero coefficients. This is done by desparsifying the estimator as in van de\nGeer et al. [18] and van de Geer and Stucky [17], then using an appropriate\nestimator for the precision matrix $\\Theta$. In order to estimate the precision\nmatrix a corresponding structured matrix norm penalty has to be introduced.\n  After normalization the result is an asymptotic pivot.\n  The asymptotic behavior is studied and simulations are added to study the\ndifferences between the two schemes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 12:01:17 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Stucky", "Benjamin", ""], ["van de Geer", "Sara", ""]]}, {"id": "1706.09302", "submitter": "Rodrigo Berriel", "authors": "Rodrigo F. Berriel, Andre Teixeira Lopes, Alberto F. de Souza, Thiago\n  Oliveira-Santos", "title": "Deep Learning Based Large-Scale Automatic Satellite Crosswalk\n  Classification", "comments": "5 pages, 3 figures, accepted by IEEE Geoscience and Remote Sensing\n  Letters", "journal-ref": null, "doi": "10.1109/LGRS.2017.2719863", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-resolution satellite imagery have been increasingly used on remote\nsensing classification problems. One of the main factors is the availability of\nthis kind of data. Even though, very little effort has been placed on the zebra\ncrossing classification problem. In this letter, crowdsourcing systems are\nexploited in order to enable the automatic acquisition and annotation of a\nlarge-scale satellite imagery database for crosswalks related tasks. Then, this\ndataset is used to train deep-learning-based models in order to accurately\nclassify satellite images that contains or not zebra crossings. A novel dataset\nwith more than 240,000 images from 3 continents, 9 countries and more than 20\ncities was used in the experiments. Experimental results showed that freely\navailable crowdsourcing data can be used to accurately (97.11%) train robust\nmodels to perform crosswalk classification on a global scale.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 14:06:24 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 12:58:35 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Berriel", "Rodrigo F.", ""], ["Lopes", "Andre Teixeira", ""], ["de Souza", "Alberto F.", ""], ["Oliveira-Santos", "Thiago", ""]]}, {"id": "1706.09367", "submitter": "F\\'abio Pinto", "authors": "F\\'abio Pinto, V\\'itor Cerqueira, Carlos Soares, Jo\\~ao Mendes-Moreira", "title": "autoBagging: Learning to Rank Bagging Workflows with Metalearning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has been successfully applied to a wide range of\ndomains and applications. One of the techniques behind most of these successful\napplications is Ensemble Learning (EL), the field of ML that gave birth to\nmethods such as Random Forests or Boosting. The complexity of applying these\ntechniques together with the market scarcity on ML experts, has created the\nneed for systems that enable a fast and easy drop-in replacement for ML\nlibraries. Automated machine learning (autoML) is the field of ML that attempts\nto answers these needs. Typically, these systems rely on optimization\ntechniques such as bayesian optimization to lead the search for the best model.\nOur approach differs from these systems by making use of the most recent\nadvances on metalearning and a learning to rank approach to learn from\nmetadata. We propose autoBagging, an autoML system that automatically ranks 63\nbagging workflows by exploiting past performance and dataset characterization.\nResults on 140 classification datasets from the OpenML platform show that\nautoBagging can yield better performance than the Average Rank method and\nachieve results that are not statistically different from an ideal model that\nsystematically selects the best workflow for each dataset. For the purpose of\nreproducibility and generalizability, autoBagging is publicly available as an R\npackage on CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 17:13:47 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Pinto", "F\u00e1bio", ""], ["Cerqueira", "V\u00edtor", ""], ["Soares", "Carlos", ""], ["Mendes-Moreira", "Jo\u00e3o", ""]]}, {"id": "1706.09395", "submitter": "Amirhossein Javaheri", "authors": "Amirhossein Javaheri, Hadi Zayyani, Farokh Marvasti", "title": "Recovery of Missing Samples Using Sparse Approximation via a Convex\n  Similarity Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the missing sample recovery problem using methods\nbased on sparse approximation. In this regard, we investigate the algorithms\nused for solving the inverse problem associated with the restoration of missed\nsamples of image signal. This problem is also known as inpainting in the\ncontext of image processing and for this purpose, we suggest an iterative\nsparse recovery algorithm based on constrained $l_1$-norm minimization with a\nnew fidelity metric. The proposed metric called Convex SIMilarity (CSIM) index,\nis a simplified version of the Structural SIMilarity (SSIM) index, which is\nconvex and error-sensitive. The optimization problem incorporating this\ncriterion, is then solved via Alternating Direction Method of Multipliers\n(ADMM). Simulation results show the efficiency of the proposed method for\nmissing sample recovery of 1D patch vectors and inpainting of 2D image signals.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 17:59:33 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Javaheri", "Amirhossein", ""], ["Zayyani", "Hadi", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1706.09396", "submitter": "Andrew Long", "authors": "Andrew W. Long (1) and Andrew L. Ferguson (1 and 2) ((1) Department of\n  Materials Science and Engineering, University of Illinois at\n  Urbana-Champaign, (2) Department of Chemical and Biomolecular Engineering,\n  University of Illinois at Urbana-Champaign)", "title": "Landmark Diffusion Maps (L-dMaps): Accelerated manifold learning\n  out-of-sample extension", "comments": "Submitted", "journal-ref": null, "doi": "10.1016/j.acha.2017.08.004", "report-no": null, "categories": "stat.ML cond-mat.soft", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion maps are a nonlinear manifold learning technique based on harmonic\nanalysis of a diffusion process over the data. Out-of-sample extensions with\ncomputational complexity $\\mathcal{O}(N)$, where $N$ is the number of points\ncomprising the manifold, frustrate applications to online learning applications\nrequiring rapid embedding of high-dimensional data streams. We propose landmark\ndiffusion maps (L-dMaps) to reduce the complexity to $\\mathcal{O}(M)$, where $M\n\\ll N$ is the number of landmark points selected using pruned spanning trees or\nk-medoids. Offering $(N/M)$ speedups in out-of-sample extension, L-dMaps\nenables the application of diffusion maps to high-volume and/or high-velocity\nstreaming data. We illustrate our approach on three datasets: the Swiss roll,\nmolecular simulations of a C$_{24}$H$_{50}$ polymer chain, and biomolecular\nsimulations of alanine dipeptide. We demonstrate up to 50-fold speedups in\nout-of-sample extension for the molecular systems with less than 4% errors in\nmanifold reconstruction fidelity relative to calculations over the full\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 17:59:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Long", "Andrew W.", "", "1 and 2"], ["Ferguson", "Andrew L.", "", "1 and 2"]]}, {"id": "1706.09410", "submitter": "Kiryung Lee", "authors": "Marius Junge, Kiryung Lee", "title": "Generalized notions of sparsity and restricted isometry property. Part\n  I: A unified framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted isometry property (RIP) is an integral tool in the analysis of\nvarious inverse problems with sparsity models. Motivated by the applications of\ncompressed sensing and dimensionality reduction of low-rank tensors, we propose\ngeneralized notions of sparsity and provide a unified framework for the\ncorresponding RIP, in particular when combined with isotropic group actions.\nOur results extend an approach by Rudelson and Vershynin to a much broader\ncontext including commutative and noncommutative function spaces. Moreover, our\nBanach space notion of sparsity applies to affine group actions. The\ngeneralized approach in particular applies to high order tensor products.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 15:46:36 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 00:35:30 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Junge", "Marius", ""], ["Lee", "Kiryung", ""]]}, {"id": "1706.09411", "submitter": "Kiryung Lee", "authors": "Marius Junge, Kiryung Lee", "title": "Generalized notions of sparsity and restricted isometry property. Part\n  II: Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted isometry property (RIP) is a universal tool for data recovery.\nWe explore the implication of the RIP in the framework of generalized sparsity\nand group measurements introduced in the Part I paper. It turns out that for a\ngiven measurement instrument the number of measurements for RIP can be improved\nby optimizing over families of Banach spaces. Second, we investigate the\npreservation of difference of two sparse vectors, which is not trivial in\ngeneralized models. Third, we extend the RIP of partial Fourier measurements at\noptimal scaling of number of measurements with random sign to far more general\ngroup structured measurements. Lastly, we also obtain RIP in infinite dimension\nin the context of Fourier measurement concepts with sparsity naturally replaced\nby smoothness assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 15:48:00 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 00:37:54 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Junge", "Marius", ""], ["Lee", "Kiryung", ""]]}, {"id": "1706.09451", "submitter": "Bryan Ostdiek", "authors": "Timothy Cohen, Marat Freytsis, and Bryan Ostdiek", "title": "(Machine) Learning to Do More with Less", "comments": "32 pages, 12 figures. Example code is provided at\n  https://github.com/bostdiek/PublicWeaklySupervised . v3: Version published in\n  JHEP, discussion added", "journal-ref": null, "doi": "10.1007/JHEP02(2018)034", "report-no": null, "categories": "hep-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the best method for training a machine learning algorithm is\ncritical to maximizing its ability to classify data. In this paper, we compare\nthe standard \"fully supervised\" approach (that relies on knowledge of\nevent-by-event truth-level labels) with a recent proposal that instead utilizes\nclass ratios as the only discriminating information provided during training.\nThis so-called \"weakly supervised\" technique has access to less information\nthan the fully supervised method and yet is still able to yield impressive\ndiscriminating power. In addition, weak supervision seems particularly well\nsuited to particle physics since quantum mechanics is incompatible with the\nnotion of mapping an individual event onto any single Feynman diagram. We\nexamine the technique in detail -- both analytically and numerically -- with a\nfocus on the robustness to issues of mischaracterizing the training samples.\nWeakly supervised networks turn out to be remarkably insensitive to systematic\nmismodeling. Furthermore, we demonstrate that the event level outputs for\nweakly versus fully supervised networks are probing different kinematics, even\nthough the numerical quality metrics are essentially identical. This implies\nthat it should be possible to improve the overall classification ability by\ncombining the output from the two types of networks. For concreteness, we apply\nthis technology to a signature of beyond the Standard Model physics to\ndemonstrate that all these impressive features continue to hold in a scenario\nof relevance to the LHC.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 19:28:52 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 22:13:29 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 16:37:35 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Cohen", "Timothy", ""], ["Freytsis", "Marat", ""], ["Ostdiek", "Bryan", ""]]}, {"id": "1706.09627", "submitter": "Giancarlo Nicola", "authors": "Paola Cerchiello, Giancarlo Nicola, Samuel Ronnqvist, Peter Sarlin", "title": "Deep learning bank distress from news and numerical financial data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus our attention on the exploitation of the information\ncontained in financial news to enhance the performance of a classifier of bank\ndistress. Such information should be analyzed and inserted into the predictive\nmodel in the most efficient way and this task deals with all the issues related\nto text analysis and specifically analysis of news media. Among the different\nmodels proposed for such purpose, we investigate one of the possible deep\nlearning approaches, based on a doc2vec representation of the textual data, a\nkind of neural network able to map the sequential and symbolic text input onto\na reduced latent semantic space. Afterwards, a second supervised neural network\nis trained combining news data with standard financial figures to classify\nbanks whether in distressed or tranquil states, based on a small set of known\ndistress events. Then the final aim is not only the improvement of the\npredictive performance of the classifier but also to assess the importance of\nnews data in the classification process. Does news data really bring more\nuseful information not contained in standard financial variables? Our results\nseem to confirm such hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 08:42:44 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 18:06:14 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 09:08:43 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Cerchiello", "Paola", ""], ["Nicola", "Giancarlo", ""], ["Ronnqvist", "Samuel", ""], ["Sarlin", "Peter", ""]]}, {"id": "1706.09693", "submitter": "Elizabeth Newman", "authors": "Elizabeth Newman, Misha Kilmer, and Lior Horesh", "title": "Image classification using local tensor singular value decompositions", "comments": "Submitted to IEEE CAMSAP 2017 Conference, 5 pages, 9 figures and\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From linear classifiers to neural networks, image classification has been a\nwidely explored topic in mathematics, and many algorithms have proven to be\neffective classifiers. However, the most accurate classifiers typically have\nsignificantly high storage costs, or require complicated procedures that may be\ncomputationally expensive. We present a novel (nonlinear) classification\napproach using truncation of local tensor singular value decompositions (tSVD)\nthat robustly offers accurate results, while maintaining manageable storage\ncosts. Our approach takes advantage of the optimality of the representation\nunder the tensor algebra described to determine to which class an image\nbelongs. We extend our approach to a method that can determine specific\npairwise match scores, which could be useful in, for example, object\nrecognition problems where pose/position are different. We demonstrate the\npromise of our new techniques on the MNIST data set.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 11:45:54 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Newman", "Elizabeth", ""], ["Kilmer", "Misha", ""], ["Horesh", "Lior", ""]]}, {"id": "1706.09751", "submitter": "Jonathan Gordon Mr", "authors": "Jonathan Gordon and Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Bayesian Semisupervised Learning with Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based generative models with discriminative components are a\npowerful approach for semi-supervised learning. However, these techniques a)\ncannot account for model uncertainty in the estimation of the model's\ndiscriminative component and b) lack flexibility to capture complex stochastic\npatterns in the label generation process. To avoid these problems, we first\npropose to use a discriminative component with stochastic inputs for increased\nnoise flexibility. We show how an efficient Gibbs sampling procedure can\nmarginalize the stochastic inputs when inferring missing labels in this model.\nFollowing this, we extend the discriminative component to be fully Bayesian and\nproduce estimates of uncertainty in its parameter values. This opens the door\nfor semi-supervised Bayesian active learning.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 13:41:05 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Gordon", "Jonathan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1706.09773", "submitter": "Osbert Bastani", "authors": "Osbert Bastani and Carolyn Kim and Hamsa Bastani", "title": "Interpretability via Model Extraction", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to interpret machine learning models has become increasingly\nimportant now that machine learning is used to inform consequential decisions.\nWe propose an approach called model extraction for interpreting complex,\nblackbox models. Our approach approximates the complex model using a much more\ninterpretable model; as long as the approximation quality is good, then\nstatistical properties of the complex model are reflected in the interpretable\nmodel. We show how model extraction can be used to understand and debug random\nforests and neural nets trained on several datasets from the UCI Machine\nLearning Repository, as well as control policies learned for several classical\nreinforcement learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 14:30:40 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 02:02:44 GMT"}, {"version": "v3", "created": "Sun, 11 Mar 2018 02:08:24 GMT"}, {"version": "v4", "created": "Tue, 13 Mar 2018 00:56:59 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Bastani", "Osbert", ""], ["Kim", "Carolyn", ""], ["Bastani", "Hamsa", ""]]}, {"id": "1706.09795", "submitter": "Sophie Jan", "authors": "Nicolas Couellan and Sophie Jan", "title": "Feature uncertainty bounding schemes for large robust nonlinear SVM\n  classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the binary classification problem when data are large and subject\nto unknown but bounded uncertainties. We address the problem by formulating the\nnonlinear support vector machine training problem with robust optimization. To\ndo so, we analyze and propose two bounding schemes for uncertainties associated\nto random approximate features in low dimensional spaces. The proposed\ntechniques are based on Random Fourier Features and the Nystr\\\"om methods. The\nresulting formulations can be solved with efficient stochastic approximation\ntechniques such as stochastic (sub)-gradient, stochastic proximal gradient\ntechniques or their variants.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 15:08:26 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Couellan", "Nicolas", ""], ["Jan", "Sophie", ""]]}, {"id": "1706.09847", "submitter": "Suresh Venkatasubramanian", "authors": "Danielle Ensign, Sorelle A. Friedler, Scott Neville, Carlos\n  Scheidegger and Suresh Venkatasubramanian", "title": "Runaway Feedback Loops in Predictive Policing", "comments": "Extended version accepted to the 1st Conference on Fairness,\n  Accountability and Transparency, 2018. Adds further treatment of reported as\n  well as discovered incidents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive policing systems are increasingly used to determine how to\nallocate police across a city in order to best prevent crime. Discovered crime\ndata (e.g., arrest counts) are used to help update the model, and the process\nis repeated. Such systems have been empirically shown to be susceptible to\nrunaway feedback loops, where police are repeatedly sent back to the same\nneighborhoods regardless of the true crime rate.\n  In response, we develop a mathematical model of predictive policing that\nproves why this feedback loop occurs, show empirically that this model exhibits\nsuch problems, and demonstrate how to change the inputs to a predictive\npolicing system (in a black-box manner) so the runaway feedback loop does not\noccur, allowing the true crime rate to be learned. Our results are\nquantitative: we can establish a link (in our model) between the degree to\nwhich runaway feedback causes problems and the disparity in crime rates between\nareas. Moreover, we can also demonstrate the way in which \\emph{reported}\nincidents of crime (those reported by residents) and \\emph{discovered}\nincidents of crime (i.e. those directly observed by police officers dispatched\nas a result of the predictive policing algorithm) interact: in brief, while\nreported incidents can attenuate the degree of runaway feedback, they cannot\nentirely remove it without the interventions we suggest.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 16:50:22 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 00:06:15 GMT"}, {"version": "v3", "created": "Fri, 22 Dec 2017 04:49:24 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Ensign", "Danielle", ""], ["Friedler", "Sorelle A.", ""], ["Neville", "Scott", ""], ["Scheidegger", "Carlos", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1706.09865", "submitter": "C.H. Bryan Liu", "authors": "C.H. Bryan Liu, Benjamin Paul Chamberlain, Duncan A. Little, Angelo\n  Cardoso", "title": "Generalising Random Forest Parameter Optimisation to Include Stability\n  and Cost", "comments": "To appear in ECML-PKDD 2017", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2017. LNCS vol 10536, pp. 102-113 (2017)", "doi": "10.1007/978-3-319-71273-4_9", "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are among the most popular classification and regression\nmethods used in industrial applications. To be effective, the parameters of\nrandom forests must be carefully tuned. This is usually done by choosing values\nthat minimize the prediction error on a held out dataset. We argue that error\nreduction is only one of several metrics that must be considered when\noptimizing random forest parameters for commercial applications. We propose a\nnovel metric that captures the stability of random forests predictions, which\nwe argue is key for scenarios that require successive predictions. We motivate\nthe need for multi-criteria optimization by showing that in practical\napplications, simply choosing the parameters that lead to the lowest error can\nintroduce unnecessary costs and produce predictions that are not stable across\nindependent runs. To optimize this multi-criteria trade-off, we present a new\nframework that efficiently finds a principled balance between these three\nconsiderations using Bayesian optimisation. The pitfalls of optimising forest\nparameters purely for error reduction are demonstrated using two publicly\navailable real world datasets. We show that our framework leads to parameter\nsettings that are markedly different from the values discovered by error\nreduction metrics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 17:23:44 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 15:43:33 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Liu", "C. H. Bryan", ""], ["Chamberlain", "Benjamin Paul", ""], ["Little", "Duncan A.", ""], ["Cardoso", "Angelo", ""]]}, {"id": "1706.09880", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "A Fixed-Point of View on Gradient Methods for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting gradient methods as fixed-point iterations, we provide a\ndetailed analysis of those methods for minimizing convex objective functions.\nDue to their conceptual and algorithmic simplicity, gradient methods are widely\nused in machine learning for massive data sets (big data). In particular,\nstochastic gradient methods are considered the de- facto standard for training\ndeep neural networks. Studying gradient methods within the realm of fixed-point\ntheory provides us with powerful tools to analyze their convergence properties.\nIn particular, gradient methods using inexact or noisy gradients, such as\nstochastic gradient descent, can be studied conveniently using well-known\nresults on inexact fixed-point iterations. Moreover, as we demonstrate in this\npaper, the fixed-point approach allows an elegant derivation of accelerations\nfor basic gradient methods. In particular, we will show how gradient descent\ncan be accelerated by a fixed-point preserving transformation of an operator\nassociated with the objective function.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 17:46:50 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 09:17:37 GMT"}, {"version": "v3", "created": "Wed, 26 Jul 2017 17:33:58 GMT"}, {"version": "v4", "created": "Tue, 15 Aug 2017 14:32:40 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1706.09916", "submitter": "Zhenpeng Zhou", "authors": "Zhenpeng Zhou, and Xiaocheng Li", "title": "Graph Convolution: A High-Order and Adaptive Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we presented a novel convolutional neural network framework\nfor graph modeling, with the introduction of two new modules specially designed\nfor graph-structured data: the $k$-th order convolution operator and the\nadaptive filtering module. Importantly, our framework of High-order and\nAdaptive Graph Convolutional Network (HA-GCN) is a general-purposed\narchitecture that fits various applications on both node and graph centrics, as\nwell as graph generative models. We conducted extensive experiments on\ndemonstrating the advantages of our framework. Particularly, our HA-GCN\noutperforms the state-of-the-art models on node classification and molecule\nproperty prediction tasks. It also generates 32% more real molecules on the\nmolecule generation task, both of which will significantly benefit real-world\napplications such as material design and drug screening.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 18:33:06 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 04:25:23 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Zhou", "Zhenpeng", ""], ["Li", "Xiaocheng", ""]]}, {"id": "1706.09985", "submitter": "Rikiya Takahashi", "authors": "Rikiya Takahashi and Shunan Zhang", "title": "Towards Bursting Filter Bubble via Contextual Risks and Uncertainties", "comments": "The filter bubble problem; Uncertainty-aware scoring; Empirical-Bayes\n  method; Low-rank Laplace's method", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rising topic in computational journalism is how to enhance the diversity in\nnews served to subscribers to foster exploration behavior in news reading.\nDespite the success of preference learning in personalized news recommendation,\ntheir over-exploitation causes filter bubble that isolates readers from\nopposing viewpoints and hurts long-term user experiences with lack of\nserendipity. Since news providers can recommend neither opposite nor\ndiversified opinions if unpopularity of these articles is surely predicted,\nthey can only bet on the articles whose forecasts of click-through rate involve\nhigh variability (risks) or high estimation errors (uncertainties). We propose\na novel Bayesian model of uncertainty-aware scoring and ranking for news\narticles. The Bayesian binary classifier models probability of success (defined\nas a news click) as a Beta-distributed random variable conditional on a vector\nof the context (user features, article features, and other contextual\nfeatures). The posterior of the contextual coefficients can be computed\nefficiently using a low-rank version of Laplace's method via thin Singular\nValue Decomposition. Efficiencies in personalized targeting of exceptional\narticles, which are chosen by each subscriber in test period, are evaluated on\nreal-world news datasets. The proposed estimator slightly outperformed existing\ntraining and scoring algorithms, in terms of efficiency in identifying\nsuccessful outliers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 00:33:35 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Takahashi", "Rikiya", ""], ["Zhang", "Shunan", ""]]}, {"id": "1706.10003", "submitter": "Sivaraman Balakrishnan", "authors": "Sivaraman Balakrishnan and Larry Wasserman", "title": "Hypothesis Testing For Densities and High-Dimensional Multinomials:\n  Sharp Local Minimax Rates", "comments": "60 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the goodness-of-fit testing problem of distinguishing whether the\ndata are drawn from a specified distribution, versus a composite alternative\nseparated from the null in the total variation metric. In the discrete case, we\nconsider goodness-of-fit testing when the null distribution has a possibly\ngrowing or unbounded number of categories. In the continuous case, we consider\ntesting a Lipschitz density, with possibly unbounded support, in the\nlow-smoothness regime where the Lipschitz parameter is not assumed to be\nconstant. In contrast to existing results, we show that the minimax rate and\ncritical testing radius in these settings depend strongly, and in a precise\nway, on the null distribution being tested and this motivates the study of the\n(local) minimax rate as a function of the null distribution. For multinomials\nthe local minimax rate was recently studied in the work of Valiant and Valiant.\nWe re-visit and extend their results and develop two modifications to the\nchi-squared test whose performance we characterize. For testing Lipschitz\ndensities, we show that the usual binning tests are inadequate in the\nlow-smoothness regime and we design a spatially adaptive partitioning scheme\nthat forms the basis for our locally minimax optimal tests. Furthermore, we\nprovide the first local minimax lower bounds for this problem which yield a\nsharp characterization of the dependence of the critical radius on the null\nhypothesis being tested. In the low-smoothness regime we also provide adaptive\ntests, that adapt to the unknown smoothness parameter. We illustrate our\nresults with a variety of simulations that demonstrate the practical utility of\nour proposed tests.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 02:34:12 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Balakrishnan", "Sivaraman", ""], ["Wasserman", "Larry", ""]]}, {"id": "1706.10029", "submitter": "Cheng Ju", "authors": "Cheng Ju and Richard Wyss and Jessica M. Franklin and Sebastian\n  Schneeweiss and Jenny H\\\"aggstr\\\"om and Mark J. van der Laan", "title": "Collaborative-controlled LASSO for Constructing Propensity Score-based\n  Estimators in High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propensity score (PS) based estimators are increasingly used for causal\ninference in observational studies. However, model selection for PS estimation\nin high-dimensional data has received little attention. In these settings, PS\nmodels have traditionally been selected based on the goodness-of-fit for the\ntreatment mechanism itself, without consideration of the causal parameter of\ninterest. Collaborative minimum loss-based estimation (C-TMLE) is a novel\nmethodology for causal inference that takes into account information on the\ncausal parameter of interest when selecting a PS model. This \"collaborative\nlearning\" considers variable associations with both treatment and outcome when\nselecting a PS model in order to minimize a bias-variance trade off in the\nestimated treatment effect. In this study, we introduce a novel approach for\ncollaborative model selection when using the LASSO estimator for PS estimation\nin high-dimensional covariate settings. To demonstrate the importance of\nselecting the PS model collaboratively, we designed quasi-experiments based on\na real electronic healthcare database, where only the potential outcomes were\nmanually generated, and the treatment and baseline covariates remained\nunchanged. Results showed that the C-TMLE algorithm outperformed other\ncompeting estimators for both point estimation and confidence interval\ncoverage. In addition, the PS model selected by C-TMLE could be applied to\nother PS-based estimators, which also resulted in substantive improvement for\nboth point estimation and confidence interval coverage. We illustrate the\ndiscussed concepts through an empirical example comparing the effects of\nnon-selective nonsteroidal anti-inflammatory drugs with selective COX-2\ninhibitors on gastrointestinal complications in a population of Medicare\nbeneficiaries.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 05:44:00 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Ju", "Cheng", ""], ["Wyss", "Richard", ""], ["Franklin", "Jessica M.", ""], ["Schneeweiss", "Sebastian", ""], ["H\u00e4ggstr\u00f6m", "Jenny", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1706.10031", "submitter": "Sotetsu Koyamada", "authors": "Sotetsu Koyamada, Yuta Kikuchi, Atsunori Kanemura, Shin-ichi Maeda,\n  Shin Ishii", "title": "Neural Sequence Model Training via $\\alpha$-divergence Minimization", "comments": "2017 ICML Workshop on Learning to Generate Natural Language (LGNL\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new neural sequence model training method in which the objective\nfunction is defined by $\\alpha$-divergence. We demonstrate that the objective\nfunction generalizes the maximum-likelihood (ML)-based and reinforcement\nlearning (RL)-based objective functions as special cases (i.e., ML corresponds\nto $\\alpha \\to 0$ and RL to $\\alpha \\to1$). We also show that the gradient of\nthe objective function can be considered a mixture of ML- and RL-based\nobjective gradients. The experimental results of a machine translation task\nshow that minimizing the objective function with $\\alpha > 0$ outperforms\n$\\alpha \\to 0$, which corresponds to ML-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 06:09:47 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Koyamada", "Sotetsu", ""], ["Kikuchi", "Yuta", ""], ["Kanemura", "Atsunori", ""], ["Maeda", "Shin-ichi", ""], ["Ishii", "Shin", ""]]}, {"id": "1706.10062", "submitter": "Bruno Cernuschi-Frias", "authors": "Bruno Cernuschi-Frias", "title": "Barankin Vector Locally Best Unbiased Estimates", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Barankin bound is generalized to the vector case in the mean square error\nsense. Necessary and sufficient conditions are obtained to achieve the lower\nbound. To obtain the result, a simple finite dimensional real vector valued\ngeneralization of the Riesz representation theorem for Hilbert spaces is given.\nThe bound has the form of a linear matrix inequality where the covariances of\nany unbiased estimator, if these exist, are lower bounded by matrices depending\nonly on the parametrized probability distributions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 08:38:30 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Cernuschi-Frias", "Bruno", ""]]}, {"id": "1706.10172", "submitter": "M\\'arton Karsai", "authors": "Yongjun Liao, Wei Du, M\\'arton Karsai, Carlos Sarraute, Martin Minnoni\n  and Eric Fleury", "title": "Prepaid or Postpaid? That is the question. Novel Methods of Subscription\n  Type Prediction in Mobile Phone Services", "comments": "17 pages, 4 figures; chapter to appear in Lecture Notes in Social\n  Networks; Eds. R. Alhajj, U. Gl\\\"asser, Springer Nature (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the behavioural differences between mobile phone\ncustomers with prepaid and postpaid subscriptions. Our study reveals that (a)\npostpaid customers are more active in terms of service usage and (b) there are\nstrong structural correlations in the mobile phone call network as connections\nbetween customers of the same subscription type are much more frequent than\nthose between customers of different subscription types. Based on these\nobservations we provide methods to detect the subscription type of customers by\nusing information about their personal call statistics, and also their\negocentric networks simultaneously. The key of our first approach is to cast\nthis classification problem as a problem of graph labelling, which can be\nsolved by max-flow min-cut algorithms. Our experiments show that, by using both\nuser attributes and relationships, the proposed graph labelling approach is\nable to achieve a classification accuracy of $\\sim 87\\%$, which outperforms by\n$\\sim 7\\%$ supervised learning methods using only user attributes. In our\nsecond problem we aim to infer the subscription type of customers of external\noperators. We propose via approximate methods to solve this problem by using\nnode attributes, and a two-ways indirect inference method based on observed\nhomophilic structural correlations. Our results have straightforward\napplications in behavioural prediction and personal marketing.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 12:27:11 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Liao", "Yongjun", ""], ["Du", "Wei", ""], ["Karsai", "M\u00e1rton", ""], ["Sarraute", "Carlos", ""], ["Minnoni", "Martin", ""], ["Fleury", "Eric", ""]]}, {"id": "1706.10207", "submitter": "Frank E. Curtis", "authors": "Frank E. Curtis and Katya Scheinberg", "title": "Optimization Methods for Supervised Machine Learning: From Linear Models\n  to Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this tutorial is to introduce key models, algorithms, and open\nquestions related to the use of optimization methods for solving problems\narising in machine learning. It is written with an INFORMS audience in mind,\nspecifically those readers who are familiar with the basics of optimization\nalgorithms, but less familiar with machine learning. We begin by deriving a\nformulation of a supervised learning problem and show how it leads to various\noptimization problems, depending on the context and underlying assumptions. We\nthen discuss some of the distinctive features of these optimization problems,\nfocusing on the examples of logistic regression and the training of deep neural\nnetworks. The latter half of the tutorial focuses on optimization algorithms,\nfirst for convex logistic regression, for which we discuss the use of\nfirst-order methods, the stochastic gradient method, variance reducing\nstochastic methods, and second-order methods. Finally, we discuss how these\napproaches can be employed to the training of deep neural networks, emphasizing\nthe difficulties that arise from the complex, nonconvex structure of these\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 14:09:44 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Curtis", "Frank E.", ""], ["Scheinberg", "Katya", ""]]}, {"id": "1706.10208", "submitter": "Nina Grgi\\'c-Hla\\v{c}a", "authors": "Nina Grgi\\'c-Hla\\v{c}a, Muhammad Bilal Zafar, Krishna P. Gummadi,\n  Adrian Weller", "title": "On Fairness, Diversity and Randomness in Algorithmic Decision Making", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a binary decision making process where a single machine learning\nclassifier replaces a multitude of humans. We raise questions about the\nresulting loss of diversity in the decision making process. We study the\npotential benefits of using random classifier ensembles instead of a single\nclassifier in the context of fairness-aware learning and demonstrate various\nattractive properties: (i) an ensemble of fair classifiers is guaranteed to be\nfair, for several different measures of fairness, (ii) an ensemble of unfair\nclassifiers can still achieve fair outcomes, and (iii) an ensemble of\nclassifiers can achieve better accuracy-fairness trade-offs than a single\nclassifier. Finally, we introduce notions of distributional fairness to\ncharacterize further potential benefits of random classifier ensembles.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 14:10:34 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Grgi\u0107-Hla\u010da", "Nina", ""], ["Zafar", "Muhammad Bilal", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""]]}, {"id": "1706.10234", "submitter": "Paul Rubenstein", "authors": "Paul K. Rubenstein, Ilya Tolstikhin, Philipp Hennig, Bernhard\n  Schoelkopf", "title": "Probabilistic Active Learning of Functions in Structural Causal Models", "comments": "9 pages main text + 4 pages supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the functions computing children from\nparents in a Structural Causal Model once the underlying causal graph has been\nidentified. This is in some sense the second step after causal discovery.\nTaking a probabilistic approach to estimating these functions, we derive a\nnatural myopic active learning scheme that identifies the intervention which is\noptimally informative about all of the unknown functions jointly, given\npreviously observed data. We test the derived algorithms on simple examples, to\ndemonstrate that they produce a structured exploration policy that\nsignificantly improves on unstructured base-lines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 15:06:57 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Rubenstein", "Paul K.", ""], ["Tolstikhin", "Ilya", ""], ["Hennig", "Philipp", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1706.10239", "submitter": "Lei Wu", "authors": "Lei Wu, Zhanxing Zhu, Weinan E", "title": "Towards Understanding Generalization of Deep Learning: Perspective of\n  Loss Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  It is widely observed that deep learning models with learned parameters\ngeneralize well, even with much more model parameters than the number of\ntraining samples. We systematically investigate the underlying reasons why deep\nneural networks often generalize well, and reveal the difference between the\nminima (with the same training error) that generalize well and those they\ndon't. We show that it is the characteristics the landscape of the loss\nfunction that explains the good generalization capability. For the landscape of\nloss function for deep networks, the volume of basin of attraction of good\nminima dominates over that of poor minima, which guarantees optimization\nmethods with random initialization to converge to good minima. We theoretically\njustify our findings through analyzing 2-layer neural networks; and show that\nthe low-complexity solutions have a small norm of Hessian matrix with respect\nto model parameters. For deeper networks, extensive numerical evidence helps to\nsupport our arguments.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 15:30:21 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 02:40:04 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Wu", "Lei", ""], ["Zhu", "Zhanxing", ""], ["E", "Weinan", ""]]}, {"id": "1706.10272", "submitter": "Scott Powers", "authors": "Scott Powers, Trevor Hastie and Robert Tibshirani", "title": "Nuclear penalized multinomial regression with an application to\n  predicting at bat outcomes in baseball", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the nuclear norm penalty as an alternative to the ridge penalty\nfor regularized multinomial regression. This convex relaxation of reduced-rank\nmultinomial regression has the advantage of leveraging underlying structure\namong the response categories to make better predictions. We apply our method,\nnuclear penalized multinomial regression (NPMR), to Major League Baseball\nplay-by-play data to predict outcome probabilities based on batter-pitcher\nmatchups. The interpretation of the results meshes well with subject-area\nexpertise and also suggests a novel understanding of what differentiates\nplayers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 16:58:25 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Powers", "Scott", ""], ["Hastie", "Trevor", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1706.10283", "submitter": "Davis Blalock", "authors": "Davis W Blalock, John V Guttag", "title": "Bolt: Accelerated Data Mining with Fast Vector Compression", "comments": "Research track paper at KDD 2017", "journal-ref": null, "doi": "10.1145/3097983.3098195", "report-no": null, "categories": "cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vectors of data are at the heart of machine learning and data mining.\nRecently, vector quantization methods have shown great promise in reducing both\nthe time and space costs of operating on vectors. We introduce a vector\nquantization algorithm that can compress vectors over 12x faster than existing\ntechniques while also accelerating approximate vector operations such as\ndistance and dot product computations by up to 10x. Because it can encode over\n2GB of vectors per second, it makes vector quantization cheap enough to employ\nin many more circumstances. For example, using our technique to compute\napproximate dot products in a nested loop can multiply matrices faster than a\nstate-of-the-art BLAS implementation, even when our algorithm must first\ncompress the matrices.\n  In addition to showing the above speedups, we demonstrate that our approach\ncan accelerate nearest neighbor search and maximum inner product search by over\n100x compared to floating point operations and up to 10x compared to other\nvector quantization methods. Our approximate Euclidean distance and dot product\ncomputations are not only faster than those of related algorithms with slower\nencodings, but also faster than Hamming distance computations, which have\ndirect hardware support on the tested platforms. We also assess the errors of\nour algorithm's approximate distances and dot products, and find that it is\ncompetitive with existing, slower vector quantization algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 17:31:59 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Blalock", "Davis W", ""], ["Guttag", "John V", ""]]}, {"id": "1706.10295", "submitter": "Charles Blundell", "authors": "Meire Fortunato, Mohammad Gheshlaghi Azar, Bilal Piot, Jacob Menick,\n  Ian Osband, Alex Graves, Vlad Mnih, Remi Munos, Demis Hassabis, Olivier\n  Pietquin, Charles Blundell, Shane Legg", "title": "Noisy Networks for Exploration", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce NoisyNet, a deep reinforcement learning agent with parametric\nnoise added to its weights, and show that the induced stochasticity of the\nagent's policy can be used to aid efficient exploration. The parameters of the\nnoise are learned with gradient descent along with the remaining network\nweights. NoisyNet is straightforward to implement and adds little computational\noverhead. We find that replacing the conventional exploration heuristics for\nA3C, DQN and dueling agents (entropy reward and $\\epsilon$-greedy respectively)\nwith NoisyNet yields substantially higher scores for a wide range of Atari\ngames, in some cases advancing the agent from sub to super-human performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 17:56:19 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 16:00:54 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 09:57:23 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Fortunato", "Meire", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Piot", "Bilal", ""], ["Menick", "Jacob", ""], ["Osband", "Ian", ""], ["Graves", "Alex", ""], ["Mnih", "Vlad", ""], ["Munos", "Remi", ""], ["Hassabis", "Demis", ""], ["Pietquin", "Olivier", ""], ["Blundell", "Charles", ""], ["Legg", "Shane", ""]]}]