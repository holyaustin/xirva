[{"id": "2002.00008", "submitter": "Inaki Estella", "authors": "Abdellatif Zaidi, Inaki Estella Aguerri and Shlomo Shamai (Shitz)", "title": "On the Information Bottleneck Problems: Models, Connections,\n  Applications and Information Theoretic Views", "comments": "To be published in Entropy as part of the Special Issue Information\n  Theory for Data Communications and Processing. 51 pages. arXiv admin note:\n  text overlap with arXiv:1807.04193", "journal-ref": null, "doi": "10.3390/e22020151", "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial paper focuses on the variants of the bottleneck problem taking\nan information theoretic perspective and discusses practical methods to solve\nit, as well as its connection to coding and learning aspects. The intimate\nconnections of this setting to remote source-coding under logarithmic loss\ndistortion measure, information combining, common reconstruction, the\nWyner-Ahlswede-Korner problem, the efficiency of investment information, as\nwell as, generalization, variational inference, representation learning,\nautoencoders, and others are highlighted. We discuss its extension to the\ndistributed information bottleneck problem with emphasis on the Gaussian model\nand highlight the basic connections to the uplink Cloud Radio Access Networks\n(CRAN) with oblivious processing. For this model, the optimal trade-offs\nbetween relevance (i.e., information) and complexity (i.e., rates) in the\ndiscrete and vector Gaussian frameworks is determined. In the concluding\noutlook, some interesting problems are mentioned such as the characterization\nof the optimal inputs (\"features\") distributions under power limitations\nmaximizing the \"relevance\" for the Gaussian information bottleneck, under\n\"complexity\" constraints.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:23:19 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zaidi", "Abdellatif", "", "Shitz"], ["Aguerri", "Inaki Estella", "", "Shitz"], ["Shamai", "Shlomo", "", "Shitz"]]}, {"id": "2002.00022", "submitter": "Jun-Jie Huang", "authors": "Jun-Jie Huang and Pier Luigi Dragotti", "title": "Learning Deep Analysis Dictionaries -- Part II: Convolutional\n  Dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a Deep Convolutional Analysis Dictionary Model\n(DeepCAM) by learning convolutional dictionaries instead of unstructured\ndictionaries as in the case of deep analysis dictionary model introduced in the\ncompanion paper. Convolutional dictionaries are more suitable for processing\nhigh-dimensional signals like for example images and have only a small number\nof free parameters. By exploiting the properties of a convolutional dictionary,\nwe present an efficient convolutional analysis dictionary learning approach. A\nL-layer DeepCAM consists of L layers of convolutional analysis dictionary and\nelement-wise soft-thresholding pairs and a single layer of convolutional\nsynthesis dictionary. Similar to DeepAM, each convolutional analysis dictionary\nis composed of a convolutional Information Preserving Analysis Dictionary\n(IPAD) and a convolutional Clustering Analysis Dictionary (CAD). The IPAD and\nthe CAD are learned using variations of the proposed learning algorithm. We\ndemonstrate that DeepCAM is an effective multilayer convolutional model and, on\nsingle image super-resolution, achieves performance comparable with other\nmethods while also showing good generalization capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:02:10 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Huang", "Jun-Jie", ""], ["Dragotti", "Pier Luigi", ""]]}, {"id": "2002.00025", "submitter": "Tankut Can", "authors": "Tankut Can, Kamesh Krishnamurthy, David J. Schwab", "title": "Gating creates slow modes and controls phase-space complexity in GRUs\n  and LSTMs", "comments": "18+18 pages, 4 figures, to appear in Proceedings of Machine Learning\n  Research Vol. 107, 2020, 1st Annual Conference on Mathematical and Scientific\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful dynamical models for data with\ncomplex temporal structure. However, training RNNs has traditionally proved\nchallenging due to exploding or vanishing of gradients. RNN models such as\nLSTMs and GRUs (and their variants) significantly mitigate these issues\nassociated with training by introducing various types of gating units into the\narchitecture. While these gates empirically improve performance, how the\naddition of gates influences the dynamics and trainability of GRUs and LSTMs is\nnot well understood. Here, we take the perspective of studying randomly\ninitialized LSTMs and GRUs as dynamical systems, and ask how the salient\ndynamical properties are shaped by the gates. We leverage tools from random\nmatrix theory and mean-field theory to study the state-to-state Jacobians of\nGRUs and LSTMs. We show that the update gate in the GRU and the forget gate in\nthe LSTM can lead to an accumulation of slow modes in the dynamics. Moreover,\nthe GRU update gate can poise the system at a marginally stable point. The\nreset gate in the GRU and the output and input gates in the LSTM control the\nspectral radius of the Jacobian, and the GRU reset gate also modulates the\ncomplexity of the landscape of fixed-points. Furthermore, for the GRU we obtain\na phase diagram describing the statistical properties of fixed-points. We also\nprovide a preliminary comparison of training performance to the various\ndynamical regimes realized by varying hyperparameters. Looking to the future,\nwe have introduced a powerful set of techniques which can be adapted to a broad\nclass of RNNs, to study the influence of various architectural choices on\ndynamics, and potentially motivate the principled discovery of novel\narchitectures.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:09:37 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 23:14:05 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Can", "Tankut", ""], ["Krishnamurthy", "Kamesh", ""], ["Schwab", "David J.", ""]]}, {"id": "2002.00027", "submitter": "Marcos Eduardo Valle", "authors": "Marcos Eduardo Valle and Rodolfo Anibal Lobo", "title": "Hypercomplex-Valued Recurrent Correlation Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.12.034", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent correlation neural networks (RCNNs), introduced by Chiueh and\nGoodman as an improved version of the bipolar correlation-based Hopfield neural\nnetwork, can be used to implement high-capacity associative memories. In this\npaper, we extend the bipolar RCNNs for processing hypercomplex-valued data.\nPrecisely, we present the mathematical background for a broad class of\nhypercomplex-valued RCNNs. Then, we provide the necessary conditions which\nensure that a hypercomplex-valued RCNN always settles at an equilibrium using\neither synchronous or asynchronous update modes. Examples with bipolar,\ncomplex, hyperbolic, quaternion, and octonion-valued RCNNs are given to\nillustrate the theoretical results. Finally, computational experiments confirm\nthe potential application of hypercomplex-valued RCNNs as associative memories\ndesigned for the storage and recall of gray-scale images.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:14:19 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Valle", "Marcos Eduardo", ""], ["Lobo", "Rodolfo Anibal", ""]]}, {"id": "2002.00041", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Ben Poole", "title": "On Implicit Regularization in $\\beta$-VAEs", "comments": "ICML 2020; Final version, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the impact of variational inference (VI) on posterior inference in a\nfixed generative model is well-characterized, its role in regularizing a\nlearned generative model when used in variational autoencoders (VAEs) is poorly\nunderstood. We study the regularizing effects of variational distributions on\nlearning in generative models from two perspectives. First, we analyze the role\nthat the choice of variational family plays in imparting uniqueness to the\nlearned model by restricting the set of optimal generative models. Second, we\nstudy the regularization effect of the variational family on the local geometry\nof the decoding model. This analysis uncovers the regularizer implicit in the\n$\\beta$-VAE objective, and leads to an approximation consisting of a\ndeterministic autoencoding objective plus analytic regularizers that depend on\nthe Hessian or Jacobian of the decoding model, unifying VAEs with recent\nheuristics proposed for training regularized autoencoders. We empirically\nverify these findings, observing that the proposed deterministic objective\nexhibits similar behavior to the $\\beta$-VAE in terms of objective value and\nsample quality.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:57:52 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 16:24:19 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 05:30:42 GMT"}, {"version": "v4", "created": "Mon, 28 Dec 2020 22:36:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kumar", "Abhishek", ""], ["Poole", "Ben", ""]]}, {"id": "2002.00053", "submitter": "Jo\\~ao E. Batista", "authors": "Jo\\~ao E. Batista, Sara Silva", "title": "Improving the Detection of Burnt Areas in Remote Sensing using\n  Hyper-features Evolved by M3GP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One problem found when working with satellite images is the radiometric\nvariations across the image and different images. Intending to improve remote\nsensing models for the classification of burnt areas, we set two objectives.\nThe first is to understand the relationship between feature spaces and the\npredictive ability of the models, allowing us to explain the differences\nbetween learning and generalization when training and testing in different\ndatasets. We find that training on datasets built from more than one image\nprovides models that generalize better. These results are explained by\nvisualizing the dispersion of values on the feature space. The second objective\nis to evolve hyper-features that improve the performance of different\nclassifiers on a variety of test sets. We find the hyper-features to be\nbeneficial, and obtain the best models with XGBoost, even if the hyper-features\nare optimized for a different method.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 20:42:15 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Batista", "Jo\u00e3o E.", ""], ["Silva", "Sara", ""]]}, {"id": "2002.00057", "submitter": "Noah Golowich", "authors": "Noah Golowich, Sarath Pattathil, Constantinos Daskalakis, Asuman\n  Ozdaglar", "title": "Last Iterate is Slower than Averaged Iterate in Smooth Convex-Concave\n  Saddle Point Problems", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the smooth convex-concave saddle point problem.\nSpecifically, we analyze the last iterate convergence properties of the\nExtragradient (EG) algorithm. It is well known that the ergodic (averaged)\niterates of EG converge at a rate of $O(1/T)$ (Nemirovski, 2004). In this\npaper, we show that the last iterate of EG converges at a rate of\n$O(1/\\sqrt{T})$. To the best of our knowledge, this is the first paper to\nprovide a convergence rate guarantee for the last iterate of EG for the smooth\nconvex-concave saddle point problem. Moreover, we show that this rate is tight\nby proving a lower bound of $\\Omega(1/\\sqrt{T})$ for the last iterate. This\nlower bound therefore shows a quadratic separation of the convergence rates of\nergodic and last iterates in smooth convex-concave saddle point problems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:05:29 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 03:20:34 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Golowich", "Noah", ""], ["Pattathil", "Sarath", ""], ["Daskalakis", "Constantinos", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.00059", "submitter": "Santiago Gonzalez", "authors": "Santiago Gonzalez and Risto Miikkulainen", "title": "Optimizing Loss Functions Through Multivariate Taylor Polynomial\n  Parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metalearning of deep neural network (DNN) architectures and hyperparameters\nhas become an increasingly important area of research. Loss functions are a\ntype of metaknowledge that is crucial to effective training of DNNs, however,\ntheir potential role in metalearning has not yet been fully explored. Whereas\nearly work focused on genetic programming (GP) on tree representations, this\npaper proposes continuous CMA-ES optimization of multivariate Taylor polynomial\nparameterizations. This approach, TaylorGLO, makes it possible to represent and\nsearch useful loss functions more effectively. In MNIST, CIFAR-10, and SVHN\nbenchmark tasks, TaylorGLO finds new loss functions that outperform functions\npreviously discovered through GP, as well as the standard cross-entropy loss,\nin fewer generations. These functions serve to regularize the learning task by\ndiscouraging overfitting to the labels, which is particularly useful in tasks\nwhere limited training data is available. The results thus demonstrate that\nloss function optimization is a productive new avenue for metalearning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:25:37 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 17:28:04 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 05:44:27 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 05:29:18 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gonzalez", "Santiago", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.00066", "submitter": "Ville Rimpil\\\"ainen", "authors": "Alexandra Koulouri and Ville Rimpilainen", "title": "Simultaneous Skull Conductivity and Focal Source Imaging from EEG\n  Recordings with the help of Bayesian Uncertainty Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electroencephalography (EEG) source imaging problem is very sensitive to\nthe electrical modelling of the skull of the patient under examination.\nUnfortunately, the currently available EEG devices and their embedded software\ndo not take this into account; instead, it is common to use a literature-based\nskull conductivity parameter. In this paper, we propose a statistical method\nbased on the Bayesian approximation error approach to compensate for source\nimaging errors due to the unknown skull conductivity and, simultaneously, to\ncompute a low-order estimate for the actual skull conductivity value. By using\nsimulated EEG data that corresponds to focal source activity, we demonstrate\nthe potential of the method to reconstruct the underlying focal sources and\nlow-order errors induced by the unknown skull conductivity. Subsequently, the\nestimated errors are used to approximate the skull conductivity. The results\nindicate clear improvements in the source localization accuracy and feasible\nskull conductivity estimates.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:33:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Koulouri", "Alexandra", ""], ["Rimpilainen", "Ville", ""]]}, {"id": "2002.00072", "submitter": "Alessandro Lameiras Koerich", "authors": "Steve Tsham Mpinda Ataky and Jonathan de Matos and Alceu de S. Britto\n  Jr. and Luiz E. S. Oliveira and Alessandro L. Koerich", "title": "Data Augmentation for Histopathological Images Based on\n  Gaussian-Laplacian Pyramid Blending", "comments": "8 pages", "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN\n  2020), Glasgow, UK", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data imbalance is a major problem that affects several machine learning (ML)\nalgorithms. Such a problem is troublesome because most of the ML algorithms\nattempt to optimize a loss function that does not take into account the data\nimbalance. Accordingly, the ML algorithm simply generates a trivial model that\nis biased toward predicting the most frequent class in the training data. In\nthe case of histopathologic images (HIs), both low-level and high-level data\naugmentation (DA) techniques still present performance issues when applied in\nthe presence of inter-patient variability; whence the model tends to learn\ncolor representations, which is related to the staining process. In this paper,\nwe propose a novel approach capable of not only augmenting HI dataset but also\ndistributing the inter-patient variability by means of image blending using the\nGaussian-Laplacian pyramid. The proposed approach consists of finding the\nGaussian pyramids of two images of different patients and finding the Laplacian\npyramids thereof. Afterwards, the left-half side and the right-half side of\ndifferent HIs are joined in each level of the Laplacian pyramid, and from the\njoint pyramids, the original image is reconstructed. This composition combines\nthe stain variation of two patients, avoiding that color differences mislead\nthe learning process. Experimental results on the BreakHis dataset have shown\npromising gains vis-a-vis the majority of DA techniques presented in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:02:57 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 16:25:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ataky", "Steve Tsham Mpinda", ""], ["de Matos", "Jonathan", ""], ["Britto", "Alceu de S.", "Jr."], ["Oliveira", "Luiz E. S.", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "2002.00079", "submitter": "Duzhe Wang", "authors": "Duzhe Wang, Haoda Fu, Po-Ling Loh", "title": "Boosting Algorithms for Estimating Optimal Individualized Treatment\n  Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present nonparametric algorithms for estimating optimal individualized\ntreatment rules. The proposed algorithms are based on the XGBoost algorithm,\nwhich is known as one of the most powerful algorithms in the machine learning\nliterature. Our main idea is to model the conditional mean of clinical outcome\nor the decision rule via additive regression trees, and use the boosting\ntechnique to estimate each single tree iteratively. Our approaches overcome the\nchallenge of correct model specification, which is required in current\nparametric methods. The major contribution of our proposed algorithms is\nproviding efficient and accurate estimation of the highly nonlinear and complex\noptimal individualized treatment rules that often arise in practice. Finally,\nwe illustrate the superior performance of our algorithms by extensive\nsimulation studies and conclude with an application to the real data from a\ndiabetes Phase III trial.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:26:38 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Duzhe", ""], ["Fu", "Haoda", ""], ["Loh", "Po-Ling", ""]]}, {"id": "2002.00082", "submitter": "Sahin Lale", "authors": "Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, Anima Anandkumar", "title": "Regret Minimization in Partially Observable Linear Quadratic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of regret minimization in partially observable linear\nquadratic control systems when the model dynamics are unknown a priori. We\npropose ExpCommit, an explore-then-commit algorithm that learns the model\nMarkov parameters and then follows the principle of optimism in the face of\nuncertainty to design a controller. We propose a novel way to decompose the\nregret and provide an end-to-end sublinear regret upper bound for partially\nobservable linear quadratic control. Finally, we provide stability guarantees\nand establish a regret upper bound of $\\tilde{\\mathcal{O}}(T^{2/3})$ for\nExpCommit, where $T$ is the time horizon of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:35:08 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 02:35:18 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lale", "Sahin", ""], ["Azizzadenesheli", "Kamyar", ""], ["Hassibi", "Babak", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2002.00097", "submitter": "Xinyue Hu", "authors": "Xinyue Hu, Haoji Hu, Saurabh Verma, Zhi-Li Zhang", "title": "Physics-Guided Deep Neural Networks for Power Flow Analysis", "comments": "9 pages", "journal-ref": null, "doi": "10.1109/TPWRS.2020.3029557", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving power flow (PF) equations is the basis of power flow analysis, which\nis important in determining the best operation of existing systems, performing\nsecurity analysis, etc. However, PF equations can be out-of-date or even\nunavailable due to system dynamics and uncertainties, making traditional\nnumerical approaches infeasible. To address these concerns, researchers have\nproposed data-driven approaches to solve the PF problem by learning the mapping\nrules from historical system operation data. Nevertheless, prior data-driven\napproaches suffer from poor performance and generalizability, due to overly\nsimplified assumptions of the PF problem or ignorance of physical laws\ngoverning power systems. In this paper, we propose a physics-guided neural\nnetwork to solve the PF problem, with an auxiliary task to rebuild the PF\nmodel. By encoding different granularity of Kirchhoff's laws and system\ntopology into the rebuilt PF model, our neural-network based PF solver is\nregularized by the auxiliary task and constrained by the physical laws. The\nsimulation results show that our physics-guided neural network methods achieve\nbetter performance and generalizability compared to existing unconstrained\ndata-driven approaches. Furthermore, we demonstrate that the weight matrices of\nour physics-guided neural networks embody power system physics by showing their\nsimilarities with the bus admittance matrices.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:24:30 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 01:06:44 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Hu", "Xinyue", ""], ["Hu", "Haoji", ""], ["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "2002.00100", "submitter": "Dean Eckles", "authors": "Madhav Kumar, Dean Eckles, Sinan Aral", "title": "Scalable bundling via dense product embeddings", "comments": "47 pages, 14 figures, 22 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bundling, the practice of jointly selling two or more products at a discount,\nis a widely used strategy in industry and a well examined concept in academia.\nHistorically, the focus has been on theoretical studies in the context of\nmonopolistic firms and assumed product relationships, e.g., complementarity in\nusage. We develop a new machine-learning-driven methodology for designing\nbundles in a large-scale, cross-category retail setting. We leverage historical\npurchases and consideration sets created from clickstream data to generate\ndense continuous representations of products called embeddings. We then put\nminimal structure on these embeddings and develop heuristics for\ncomplementarity and substitutability among products. Subsequently, we use the\nheuristics to create multiple bundles for each product and test their\nperformance using a field experiment with a large retailer. We combine the\nresults from the experiment with product embeddings using a hierarchical model\nthat maps bundle features to their purchase likelihood, as measured by the\nadd-to-cart rate. We find that our embeddings-based heuristics are strong\npredictors of bundle success, robust across product categories, and generalize\nwell to the retailer's entire assortment.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:34:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kumar", "Madhav", ""], ["Eckles", "Dean", ""], ["Aral", "Sinan", ""]]}, {"id": "2002.00102", "submitter": "Marco Podda", "authors": "Davide Bacciu, Alessio Micheli, Marco Podda", "title": "Edge-based sequential graph generation with recurrent neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.112", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generation with Machine Learning is an open problem with applications\nin various research fields. In this work, we propose to cast the generative\nprocess of a graph into a sequential one, relying on a node ordering procedure.\nWe use this sequential process to design a novel generative model composed of\ntwo recurrent neural networks that learn to predict the edges of graphs: the\nfirst network generates one endpoint of each edge, while the second network\ngenerates the other endpoint conditioned on the state of the first. We test our\napproach extensively on five different datasets, comparing with two well-known\nbaselines coming from graph literature, and two recurrent approaches, one of\nwhich holds state of the art performances. Evaluation is conducted considering\nquantitative and qualitative characteristics of the generated samples. Results\nshow that our approach is able to yield novel, and unique graphs originating\nfrom very different distributions, while retaining structural properties very\nsimilar to those in the training sample. Under the proposed evaluation\nframework, our approach is able to reach performances comparable to the current\nstate of the art on the graph generation task.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:44:25 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""], ["Podda", "Marco", ""]]}, {"id": "2002.00107", "submitter": "Adam B. Block", "authors": "Adam Block, Youssef Mroueh, and Alexander Rakhlin", "title": "Generative Modeling with Denoising Auto-Encoders and Langevin Sampling", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study convergence of a generative modeling method that first estimates the\nscore function of the distribution using Denoising Auto-Encoders (DAE) or\nDenoising Score Matching (DSM) and then employs Langevin diffusion for\nsampling. We show that both DAE and DSM provide estimates of the score of the\nGaussian smoothed population density, allowing us to apply the machinery of\nEmpirical Processes.\n  We overcome the challenge of relying only on $L^2$ bounds on the score\nestimation error and provide finite-sample bounds in the Wasserstein distance\nbetween the law of the population distribution and the law of this sampling\nscheme. We then apply our results to the homotopy method of arXiv:1907.05600\nand provide theoretical justification for its empirical success.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:50:03 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 01:11:46 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:49:19 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Block", "Adam", ""], ["Mroueh", "Youssef", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "2002.00120", "submitter": "Lori Dalton", "authors": "Ali Foroughi pour and Lori A. Dalton", "title": "On the Consistency of Optimal Bayesian Feature Selection in the Presence\n  of Correlations", "comments": "33 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Bayesian feature selection (OBFS) is a multivariate supervised\nscreening method designed from the ground up for biomarker discovery. In this\nwork, we prove that Gaussian OBFS is strongly consistent under mild conditions,\nand provide rates of convergence for key posteriors in the framework. These\nresults are of enormous importance, since they identify precisely what features\nare selected by OBFS asymptotically, characterize the relative rates of\nconvergence for posteriors on different types of features, provide conditions\nthat guarantee convergence, justify the use of OBFS when its internal\nassumptions are invalid, and set the stage for understanding the asymptotic\nbehavior of other algorithms based on the OBFS framework.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:41:08 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["pour", "Ali Foroughi", ""], ["Dalton", "Lori A.", ""]]}, {"id": "2002.00178", "submitter": "Pierre Wolinski", "authors": "Pierre Wolinski, Guillaume Charpiat, Yann Ollivier", "title": "An Equivalence between Bayesian Priors and Penalties in Variational\n  Inference", "comments": "17 pages, 2 columns, including 2 pages of references and 7 pages of\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, it is common to optimize the parameters of a\nprobabilistic model, modulated by an ad hoc regularization term that penalizes\nsome values of the parameters. Regularization terms appear naturally in\nVariational Inference (VI), a tractable way to approximate Bayesian posteriors:\nthe loss to optimize contains a Kullback--Leibler divergence term between the\napproximate posterior and a Bayesian prior. We fully characterize which\nregularizers can arise this way, and provide a systematic way to compute the\ncorresponding prior. This viewpoint also provides a prediction for useful\nvalues of the regularization factor in neural networks. We apply this framework\nto regularizers such as L2, L1 or group-Lasso.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:48:51 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 10:11:57 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Wolinski", "Pierre", ""], ["Charpiat", "Guillaume", ""], ["Ollivier", "Yann", ""]]}, {"id": "2002.00189", "submitter": "Tomas Vaskevicius", "authors": "Tomas Va\\v{s}kevi\\v{c}ius, Varun Kanade, Patrick Rebeschini", "title": "The Statistical Complexity of Early-Stopped Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a surge of interest in understanding implicit\nregularization properties of iterative gradient-based optimization algorithms.\nIn this paper, we study the statistical guarantees on the excess risk achieved\nby early-stopped unconstrained mirror descent algorithms applied to the\nunregularized empirical risk with the squared loss for linear models and kernel\nmethods. By completing an inequality that characterizes convexity for the\nsquared loss, we identify an intrinsic link between offset Rademacher\ncomplexities and potential-based convergence analysis of mirror descent\nmethods. Our observation immediately yields excess risk guarantees for the path\ntraced by the iterates of mirror descent in terms of offset complexities of\ncertain function classes depending only on the choice of the mirror map,\ninitialization point, step-size, and the number of iterations. We apply our\ntheory to recover, in a clean and elegant manner via rather short proofs, some\nof the recent results in the implicit regularization literature, while also\nshowing how to improve upon them in some settings.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 11:05:08 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 15:45:06 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Kanade", "Varun", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "2002.00208", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Berger-Wolf", "title": "Variable-lag Granger Causality and Transfer Entropy for Time Series\n  Analysis", "comments": "This preprint is the extension of the work [arXiv:1912.10829]\n  entitled \"Variable-lag Granger Causality for Time Series Analysis\" by the\n  same authors. The revision was made based on reviewers' suggestions. The R\n  package is available at https://github.com/DarkEyes/VLTimeSeriesCausality", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 15(4),\n  67 (2021)", "doi": "10.1145/3441452", "report-no": null, "categories": "cs.LG econ.EM physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality is a fundamental technique for causal inference in time\nseries data, commonly used in the social and biological sciences. Typical\noperationalizations of Granger causality make a strong assumption that every\ntime point of the effect time series is influenced by a combination of other\ntime series with a fixed time delay. The assumption of fixed time delay also\nexists in Transfer Entropy, which is considered to be a non-linear version of\nGranger causality. However, the assumption of the fixed time delay does not\nhold in many applications, such as collective behavior, financial markets, and\nmany natural phenomena. To address this issue, we develop Variable-lag Granger\ncausality and Variable-lag Transfer Entropy, generalizations of both Granger\ncausality and Transfer Entropy that relax the assumption of the fixed time\ndelay and allow causes to influence effects with arbitrary time delays. In\naddition, we propose methods for inferring both variable-lag Granger causality\nand Transfer Entropy relations. In our approaches, we utilize an optimal\nwarping path of Dynamic Time Warping (DTW) to infer variable-lag causal\nrelations. We demonstrate our approaches on an application for studying\ncoordinated collective behavior and other real-world casual-inference datasets\nand show that our proposed approaches perform better than several existing\nmethods in both simulated and real-world datasets. Our approaches can be\napplied in any domain of time series analysis. The software of this work is\navailable in the R-CRAN package: VLTimeCausality.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:03:01 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 03:26:47 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 09:24:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Zheleva", "Elena", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "2002.00211", "submitter": "Suyi Li", "authors": "Suyi Li, Yong Cheng, Wei Wang, Yang Liu, Tianjian Chen", "title": "Learning to Detect Malicious Clients for Robust Federated Learning", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning systems are vulnerable to attacks from malicious clients.\nAs the central server in the system cannot govern the behaviors of the clients,\na rogue client may initiate an attack by sending malicious model updates to the\nserver, so as to degrade the learning performance or enforce targeted model\npoisoning attacks (a.k.a. backdoor attacks). Therefore, timely detecting these\nmalicious model updates and the underlying attackers becomes critically\nimportant. In this work, we propose a new framework for robust federated\nlearning where the central server learns to detect and remove the malicious\nmodel updates using a powerful detection model, leading to targeted defense. We\nevaluate our solution in both image classification and sentiment analysis tasks\nwith a variety of machine learning models. Experimental results show that our\nsolution ensures robust federated learning that is resilient to both the\nByzantine attacks and the targeted model poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:09:48 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Suyi", ""], ["Cheng", "Yong", ""], ["Wang", "Wei", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""]]}, {"id": "2002.00212", "submitter": "Yu-Siang Huang", "authors": "Yu-Siang Huang, Yi-Hsuan Yang", "title": "Pop Music Transformer: Beat-based Modeling and Generation of Expressive\n  Pop Piano Compositions", "comments": "Accepted at ACM Multimedia 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great number of deep learning based models have been recently proposed for\nautomatic music composition. Among these models, the Transformer stands out as\na prominent approach for generating expressive classical piano performance with\na coherent structure of up to one minute. The model is powerful in that it\nlearns abstractions of data on its own, without much human-imposed domain\nknowledge or constraints. In contrast with this general approach, this paper\nshows that Transformers can do even better for music modeling, when we improve\nthe way a musical score is converted into the data fed to a Transformer model.\nIn particular, we seek to impose a metrical structure in the input data, so\nthat Transformers can be more easily aware of the beat-bar-phrase hierarchical\nstructure in music. The new data representation maintains the flexibility of\nlocal tempo changes, and provides hurdles to control the rhythmic and harmonic\nstructure of music. With this approach, we build a Pop Music Transformer that\ncomposes Pop piano music with better rhythmic structure than existing\nTransformer models.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:12:35 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 15:05:24 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 07:27:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Huang", "Yu-Siang", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2002.00228", "submitter": "Thanuja Ambegoda", "authors": "Thanuja D. Ambegoda, Julien N. P. Martel, Jozef Adamcik, Matthew Cook,\n  Richard H. R. Hahnloser", "title": "Estimation of Z-Thickness and XY-Anisotropy of Electron Microscopy\n  Images using Gaussian Processes", "comments": null, "journal-ref": "Journal of Neuroinformatics and Neuroimaging. 2018;2(2):15-22", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serial section electron microscopy (ssEM) is a widely used technique for\nobtaining volumetric information of biological tissues at nanometer scale.\nHowever, accurate 3D reconstructions of identified cellular structures and\nvolumetric quantifications require precise estimates of section thickness and\nanisotropy (or stretching) along the XY imaging plane. In fact, many image\nprocessing algorithms simply assume isotropy within the imaging plane. To\nameliorate this problem, we present a method for estimating thickness and\nstretching of electron microscopy sections using non-parametric Bayesian\nregression of image statistics. We verify our thickness and stretching\nestimates using direct measurements obtained by atomic force microscopy (AFM)\nand show that our method has a lower estimation error compared to a recent\nindirect thickness estimation method as well as a relative Z coordinate\nestimation method. Furthermore, we have made the first dataset of ssSEM images\nwith directly measured section thickness values publicly available for the\nevaluation of indirect thickness estimation methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 15:18:55 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 21:32:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ambegoda", "Thanuja D.", ""], ["Martel", "Julien N. P.", ""], ["Adamcik", "Jozef", ""], ["Cook", "Matthew", ""], ["Hahnloser", "Richard H. R.", ""]]}, {"id": "2002.00232", "submitter": "Qiuyu Zhu", "authors": "Qiuyu Zhu and Vincent Y. F. Tan", "title": "Thompson Sampling Algorithms for Mean-Variance Bandits", "comments": "26 pages, 10 figures, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit (MAB) problem is a classical learning task that\nexemplifies the exploration-exploitation tradeoff. However, standard\nformulations do not take into account {\\em risk}. In online decision making\nsystems, risk is a primary concern. In this regard, the mean-variance risk\nmeasure is one of the most common objective functions. Existing algorithms for\nmean-variance optimization in the context of MAB problems have unrealistic\nassumptions on the reward distributions. We develop Thompson Sampling-style\nalgorithms for mean-variance MAB and provide comprehensive regret analyses for\nGaussian and Bernoulli bandits with fewer assumptions. Our algorithms achieve\nthe best known regret bounds for mean-variance MABs and also attain the\ninformation-theoretic bounds in some parameter regimes. Empirical simulations\nshow that our algorithms significantly outperform existing LCB-based algorithms\nfor all risk tolerances.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 15:33:50 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 14:07:38 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 13:34:15 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhu", "Qiuyu", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2002.00240", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Molecule Property Prediction and Classification with Graph Hypernetworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks are currently leading the performance charts in\nlearning-based molecule property prediction and classification. Computational\nchemistry has, therefore, become the a prominent testbed for generic graph\nneural networks, as well as for specialized message passing methods. In this\nwork, we demonstrate that the replacement of the underlying networks with\nhypernetworks leads to a boost in performance, obtaining state of the art\nresults in various benchmarks. A major difficulty in the application of\nhypernetworks is their lack of stability. We tackle this by combining the\ncurrent message and the first message. A recent work has tackled the training\ninstability of hypernetworks in the context of error correcting codes, by\nreplacing the activation function of the message passing network with a\nlow-order Taylor approximation of it. We demonstrate that our generic solution\ncan replace this domain-specific solution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 16:44:34 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.00253", "submitter": "Karthik Abinav Sankararaman", "authors": "Karthik Abinav Sankararaman and Aleksandrs Slivkins", "title": "Bandits with Knapsacks beyond the Worst-Case", "comments": "The initial version, titled \"Advances in Bandits with Knapsacks\", was\n  published on arxiv.org in Jan'20. The present version improves both upper and\n  lower bounds, deriving Theorem 3.2(ii) and Theorem 4.2. Moreover, it\n  simplifies the algorithm and analysis in the main result, and fixes several\n  issues in the lower bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandits with Knapsacks (BwK) is a general model for multi-armed bandits under\nsupply/budget constraints. While worst-case regret bounds for BwK are\nwell-understood, we present three results that go beyond the worst-case\nperspective. First, we provide upper and lower bounds which amount to a full\ncharacterization for logarithmic, instance-dependent regret rates. Second, we\nconsider \"simple regret\" in BwK, which tracks algorithm's performance in a\ngiven round, and prove that it is small in all but a few rounds. Third, we\nprovide a general \"reduction\" from BwK to bandits which takes advantage of some\nknown helpful structure, and apply this reduction to combinatorial\nsemi-bandits, linear contextual bandits, and multinomial-logit bandits. Our\nresults build on the BwK algorithm from \\citet{AgrawalDevanur-ec14}, providing\nnew analyses thereof.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 18:50:44 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 22:45:16 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 06:05:07 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 16:29:16 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 17:18:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sankararaman", "Karthik Abinav", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "2002.00254", "submitter": "Nikolai Zolotykh", "authors": "V. V. Kuznetsov and V. A. Moskalenko and N. Yu. Zolotykh", "title": "Electrocardiogram Generation and Feature Extraction Using a Variational\n  Autoencoder", "comments": "6 pages, 6 figures Submitted to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for generating an electrocardiogram (ECG) signal for one\ncardiac cycle using a variational autoencoder. Using this method we extracted a\nvector of new 25 features, which in many cases can be interpreted. The\ngenerated ECG has quite natural appearance. The low value of the Maximum Mean\nDiscrepancy metric, 0.00383, indicates good quality of ECG generation too. The\nextracted new features will help to improve the quality of automatic\ndiagnostics of cardiovascular diseases. Also, generating new synthetic ECGs\nwill allow us to solve the issue of the lack of labeled ECG for use them in\nsupervised learning.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 19:01:11 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kuznetsov", "V. V.", ""], ["Moskalenko", "V. A.", ""], ["Zolotykh", "N. Yu.", ""]]}, {"id": "2002.00269", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "A Tutorial on Learning With Bayesian Networks", "comments": "Previous arXiv submission hid all references--now fixed", "journal-ref": "Original version published in Learning in Graphical Models, M.\n  Jordan, ed., MIT Press, Cambridge, MA, 1999", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a graphical model that encodes probabilistic\nrelationships among variables of interest. When used in conjunction with\nstatistical techniques, the graphical model has several advantages for data\nanalysis. One, because the model encodes dependencies among all variables, it\nreadily handles situations where some data entries are missing. Two, a Bayesian\nnetwork can be used to learn causal relationships, and hence can be used to\ngain understanding about a problem domain and to predict the consequences of\nintervention. Three, because the model has both a causal and probabilistic\nsemantics, it is an ideal representation for combining prior knowledge (which\noften comes in causal form) and data. Four, Bayesian statistical methods in\nconjunction with Bayesian networks offer an efficient and principled approach\nfor avoiding the overfitting of data. In this paper, we discuss methods for\nconstructing Bayesian networks from prior knowledge and summarize Bayesian\nstatistical methods for using data to improve these models. With regard to the\nlatter task, we describe methods for learning both the parameters and structure\nof a Bayesian network, including techniques for learning with incomplete data.\nIn addition, we relate Bayesian-network methods for learning to techniques for\nsupervised and unsupervised learning. We illustrate the graphical-modeling\napproach using a real-world case study.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:03:21 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 22:18:01 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "2002.00274", "submitter": "Dheeraj Nagaraj", "authors": "Guy Bresler and Dheeraj Nagaraj", "title": "A Corrective View of Neural Networks: Representation, Memorization and\n  Learning", "comments": "Contains 2 figures (you heard that right!), V2 removes dimension\n  dependence in memorization bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a corrective mechanism for neural network approximation: the total\navailable non-linear units are divided into multiple groups and the first group\napproximates the function under consideration, the second group approximates\nthe error in approximation produced by the first group and corrects it, the\nthird group approximates the error produced by the first and second groups\ntogether and so on. This technique yields several new representation and\nlearning results for neural networks. First, we show that two-layer neural\nnetworks in the random features regime (RF) can memorize arbitrary labels for\narbitrary points under under Euclidean distance separation condition using\n$\\tilde{O}(n)$ ReLUs which is optimal in $n$ up to logarithmic factors. Next,\nwe give a powerful representation result for two-layer neural networks with\nReLUs and smoothed ReLUs which can achieve a squared error of at most\n$\\epsilon$ with $O(C(a,d)\\epsilon^{-1/(a+1)})$ for $a \\in \\mathbb{N}\\cup\\{0\\}$\nwhen the function is smooth enough (roughly when it has $\\Theta(ad)$ bounded\nderivatives). In certain cases $d$ can be replaced with effective dimension $q\n\\ll d$. Previous results of this type implement Taylor series approximation\nusing deep architectures. We also consider three-layer neural networks and show\nthat the corrective mechanism yields faster representation rates for smooth\nradial functions. Lastly, we obtain the first $O(\\mathrm{subpoly}(1/\\epsilon))$\nupper bound on the number of neurons required for a two layer network to learn\nlow degree polynomials up to squared error $\\epsilon$ via gradient descent.\nEven though deep networks can express these polynomials with\n$O(\\mathrm{polylog}(1/\\epsilon))$ neurons, the best learning bounds on this\nproblem require $\\mathrm{poly}(1/\\epsilon)$ neurons.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:51:09 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 02:37:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bresler", "Guy", ""], ["Nagaraj", "Dheeraj", ""]]}, {"id": "2002.00276", "submitter": "Mike Wu", "authors": "Mike Wu, Richard L. Davis, Benjamin W. Domingue, Chris Piech, Noah\n  Goodman", "title": "Variational Item Response Theory: Fast, Accurate, and Expressive", "comments": "10 pages of content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item Response Theory (IRT) is a ubiquitous model for understanding humans\nbased on their responses to questions, used in fields as diverse as education,\nmedicine and psychology. Large modern datasets offer opportunities to capture\nmore nuances in human behavior, potentially improving test scoring and better\ninforming public policy. Yet larger datasets pose a difficult speed / accuracy\nchallenge to contemporary algorithms for fitting IRT models. We introduce a\nvariational Bayesian inference algorithm for IRT, and show that it is fast and\nscaleable without sacrificing accuracy. Using this inference approach we then\nextend classic IRT with expressive Bayesian models of responses. Applying this\nmethod to five large-scale item response datasets from cognitive science and\neducation yields higher log likelihoods and improvements in imputing missing\ndata. The algorithm implementation is open-source, and easily usable.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:54:02 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 17:19:23 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wu", "Mike", ""], ["Davis", "Richard L.", ""], ["Domingue", "Benjamin W.", ""], ["Piech", "Chris", ""], ["Goodman", "Noah", ""]]}, {"id": "2002.00287", "submitter": "Julia Olkhovskaya", "authors": "Gergely Neu, Julia Olkhovskaya", "title": "Efficient and Robust Algorithms for Adversarial Linear Contextual\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an adversarial variant of the classic $K$-armed linear contextual\nbandit problem where the sequence of loss functions associated with each arm\nare allowed to change without restriction over time. Under the assumption that\nthe $d$-dimensional contexts are generated i.i.d.~at random from a known\ndistributions, we develop computationally efficient algorithms based on the\nclassic Exp3 algorithm. Our first algorithm, RealLinExp3, is shown to achieve a\nregret guarantee of $\\widetilde{O}(\\sqrt{KdT})$ over $T$ rounds, which matches\nthe best available bound for this problem. Our second algorithm, RobustLinExp3,\nis shown to be robust to misspecification, in that it achieves a regret bound\nof $\\widetilde{O}((Kd)^{1/3}T^{2/3}) + \\varepsilon \\sqrt{d} T$ if the true\nreward function is linear up to an additive nonlinear error uniformly bounded\nin absolute value by $\\varepsilon$. To our knowledge, our performance\nguarantees constitute the very first results on this problem setting.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 22:49:46 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 20:00:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Neu", "Gergely", ""], ["Olkhovskaya", "Julia", ""]]}, {"id": "2002.00288", "submitter": "Yu Wang", "authors": "Yu Wang, Byoungwook Jang, Alfred Hero", "title": "The Sylvester Graphical Lasso (SyGlasso)", "comments": "Accepted in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces the Sylvester graphical lasso (SyGlasso) that captures\nmultiway dependencies present in tensor-valued data. The model is based on the\nSylvester equation that defines a generative model. The proposed model\ncomplements the tensor graphical lasso (Greenewald et al., 2019) that imposes a\nKronecker sum model for the inverse covariance matrix by providing an\nalternative Kronecker sum model that is generative and interpretable. A\nnodewise regression approach is adopted for estimating the conditional\nindependence relationships among variables. The statistical convergence of the\nmethod is established, and empirical studies are provided to demonstrate the\nrecovery of meaningful conditional dependency graphs. We apply the SyGlasso to\nan electroencephalography (EEG) study to compare the brain connectivity of\nalcoholic and nonalcoholic subjects. We demonstrate that our model can\nsimultaneously estimate both the brain connectivity and its temporal\ndependencies.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 22:57:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Yu", ""], ["Jang", "Byoungwook", ""], ["Hero", "Alfred", ""]]}, {"id": "2002.00291", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Peter L. Bartlett, Philip M. Long", "title": "Oracle Lower Bounds for Stochastic Gradient Sampling Algorithms", "comments": "21 pages; accepted for publication at Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling from a strongly log-concave density in\n$\\mathbb{R}^d$, and prove an information theoretic lower bound on the number of\nstochastic gradient queries of the log density needed. Several popular sampling\nalgorithms (including many Markov chain Monte Carlo methods) operate by using\nstochastic gradients of the log density to generate a sample; our results\nestablish an information theoretic limit for all these algorithms.\n  We show that for every algorithm, there exists a well-conditioned strongly\nlog-concave target density for which the distribution of points generated by\nthe algorithm would be at least $\\varepsilon$ away from the target in total\nvariation distance if the number of gradient queries is less than\n$\\Omega(\\sigma^2 d/\\varepsilon^2)$, where $\\sigma^2 d$ is the variance of the\nstochastic gradient. Our lower bound follows by combining the ideas of Le Cam\ndeficiency routinely used in the comparison of statistical experiments along\nwith standard information theoretic tools used in lower bounding Bayes risk\nfunctions. To the best of our knowledge our results provide the first\nnontrivial dimension-dependent lower bound for this problem.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 23:46:35 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 20:35:47 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 04:12:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Bartlett", "Peter L.", ""], ["Long", "Philip M.", ""]]}, {"id": "2002.00306", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi and Walid Saad", "title": "Brainstorming Generative Adversarial Networks (BGANs): Towards\n  Multi-Agent Generative Models with Distributed Private Datasets", "comments": "13 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve a high learning accuracy, generative adversarial networks (GANs)\nmust be fed by large datasets that adequately represent the data space.\nHowever, in many scenarios, the available datasets may be limited and\ndistributed across multiple agents, each of which is seeking to learn the\ndistribution of the data on its own. In such scenarios, the local datasets are\ninherently private and agents often do not wish to share them. In this paper,\nto address this multi-agent GAN problem, a novel brainstorming GAN (BGAN)\narchitecture is proposed using which multiple agents can generate real-like\ndata samples while operating in a fully distributed manner and preserving their\ndata privacy. BGAN allows the agents to gain information from other agents\nwithout sharing their real datasets but by \"brainstorming\" via the sharing of\ntheir generated data samples. In contrast to existing distributed GAN\nsolutions, the proposed BGAN architecture is designed to be fully distributed,\nand it does not need any centralized controller. Moreover, BGANs are shown to\nbe scalable and not dependent on the hyperparameters of the agents' deep neural\nnetworks (DNNs) thus enabling the agents to have different DNN architectures.\nTheoretically, the interactions between BGAN agents are analyzed as a game\nwhose unique Nash equilibrium is derived. Experimental results show that BGAN\ncan generate real-like data samples with higher quality and lower\nJensen-Shannon divergence (JSD) and Fr\\'echet Inception distance (FID) compared\nto other distributed GAN architectures.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 02:58:32 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 02:49:06 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "2002.00315", "submitter": "Mengxiao Zhang", "authors": "Chung-Wei Lee, Haipeng Luo, Mengxiao Zhang", "title": "A Closer Look at Small-loss Bounds for Bandits with Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study small-loss bounds for adversarial multi-armed bandits with graph\nfeedback, that is, adaptive regret bounds that depend on the loss of the best\narm or related quantities, instead of the total number of rounds. We derive the\nfirst small-loss bound for general strongly observable graphs, resolving an\nopen problem of Lykouris et al. (2018). Specifically, we develop an algorithm\nwith regret $\\mathcal{\\tilde{O}}(\\sqrt{\\kappa L_*})$ where $\\kappa$ is the\nclique partition number and $L_*$ is the loss of the best arm, and for the\nspecial case of self-aware graphs where every arm has a self-loop, we improve\nthe regret to $\\mathcal{\\tilde{O}}(\\min\\{\\sqrt{\\alpha T}, \\sqrt{\\kappa L_*}\\})$\nwhere $\\alpha \\leq \\kappa$ is the independence number. Our results\nsignificantly improve and extend those by Lykouris et al. (2018) who only\nconsider self-aware undirected graphs.\n  Furthermore, we also take the first attempt at deriving small-loss bounds for\nweakly observable graphs. We first prove that no typical small-loss bounds are\nachievable in this case, and then propose algorithms with alternative\nsmall-loss bounds in terms of the loss of some specific subset of arms. A\nsurprising side result is that $\\mathcal{\\tilde{O}}(\\sqrt{T})$ regret is\nachievable even for weakly observable graphs as long as the best arm has a\nself-loop.\n  Our algorithms are based on the Online Mirror Descent framework but require a\nsuite of novel techniques that might be of independent interest. Moreover, all\nour algorithms can be made parameter-free without the knowledge of the\nenvironment.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 03:48:01 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:06:49 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lee", "Chung-Wei", ""], ["Luo", "Haipeng", ""], ["Zhang", "Mengxiao", ""]]}, {"id": "2002.00329", "submitter": "Jeongyeol Kwon", "authors": "Jeongyeol Kwon, Constantine Caramanis", "title": "The EM Algorithm gives Sample-Optimality for Learning Mixtures of\n  Well-Separated Gaussians", "comments": "Accepted to COLT 2020; Title changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of spherical Gaussian Mixture models with $k \\geq 3$\ncomponents when the components are well separated. A fundamental previous\nresult established that separation of $\\Omega(\\sqrt{\\log k})$ is necessary and\nsufficient for identifiability of the parameters with polynomial sample\ncomplexity (Regev and Vijayaraghavan, 2017). In the same context, we show that\n$\\tilde{O} (kd/\\epsilon^2)$ samples suffice for any $\\epsilon \\lesssim 1/k$,\nclosing the gap from polynomial to linear, and thus giving the first optimal\nsample upper bound for the parameter estimation of well-separated Gaussian\nmixtures. We accomplish this by proving a new result for the\nExpectation-Maximization (EM) algorithm: we show that EM converges locally,\nunder separation $\\Omega(\\sqrt{\\log k})$. The previous best-known guarantee\nrequired $\\Omega(\\sqrt{k})$ separation (Yan, et al., 2017). Unlike prior work,\nour results do not assume or use prior knowledge of the (potentially different)\nmixing weights or variances of the Gaussian components. Furthermore, our\nresults show that the finite-sample error of EM does not depend on\nnon-universal quantities such as pairwise distances between means of Gaussian\ncomponents.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 05:09:26 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:36:40 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kwon", "Jeongyeol", ""], ["Caramanis", "Constantine", ""]]}, {"id": "2002.00343", "submitter": "Sungho Shin", "authors": "Sungho Shin, Yoonho Boo, Wonyong Sung", "title": "SQWA: Stochastic Quantized Weight Averaging for Improving the\n  Generalization Capability of Low-Precision Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a deep neural network (DNN) with good generalization capability is\na complex process especially when the weights are severely quantized. Model\naveraging is a promising approach for achieving the good generalization\ncapability of DNNs, especially when the loss surface for training contains many\nsharp minima. We present a new quantized neural network optimization approach,\nstochastic quantized weight averaging (SQWA), to design low-precision DNNs with\ngood generalization capability using model averaging. The proposed approach\nincludes (1) floating-point model training, (2) direct quantization of weights,\n(3) capturing multiple low-precision models during retraining with cyclical\nlearning rates, (4) averaging the captured models, and (5) re-quantizing the\naveraged model and fine-tuning it with low-learning rates. Additionally, we\npresent a loss-visualization technique on the quantized weight domain to\nclearly elucidate the behavior of the proposed method. Visualization results\nindicate that a quantized DNN (QDNN) optimized with the proposed approach is\nlocated near the center of the flat minimum in the loss surface. With SQWA\ntraining, we achieved state-of-the-art results for 2-bit QDNNs on CIFAR-100 and\nImageNet datasets. Although we only employed a uniform quantization scheme for\nthe sake of implementation in VLSI or low-precision neural processing units,\nthe performance achieved exceeded those of previous studies employing\nnon-uniform quantization.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 07:02:51 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shin", "Sungho", ""], ["Boo", "Yoonho", ""], ["Sung", "Wonyong", ""]]}, {"id": "2002.00372", "submitter": "C Anantaram", "authors": "Rupam Patir, Shubham Singhal, C. Anantaram, Vikram Goyal", "title": "Interpretability of Blackbox Machine Learning Models through Dataview\n  Extraction and Shadow Model creation", "comments": "13 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models trained using massive amounts of data tend to capture\none view of the data and its associated mapping. Different deep learning models\nbuilt on the same training data may capture different views of the data based\non the underlying techniques used. For explaining the decisions arrived by\nblackbox deep learning models, we argue that it is essential to reproduce that\nmodel's view of the training data faithfully. This faithful reproduction can\nthen be used for explanation generation. We investigate two methods for data\nview extraction: hill-climbing approach and a GAN-driven approach. We then use\nthis synthesized data for creating shadow models for explanation generation:\nDecision-Tree model and Formal Concept Analysis based model. We evaluate these\napproaches on a Blackbox model trained on public datasets and show its\nusefulness in explanation generation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 11:47:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Patir", "Rupam", ""], ["Singhal", "Shubham", ""], ["Anantaram", "C.", ""], ["Goyal", "Vikram", ""]]}, {"id": "2002.00401", "submitter": "Liang-Chi Huang Mr.", "authors": "Jwo-Yuh Wu, Wen-Hsuan Li, Liang-Chi Huang, Yen-Ping Lin, Chun-Hung Liu\n  and Rung-Hung Gau", "title": "Provable Noisy Sparse Subspace Clustering using Greedy Neighbor\n  Selection: A Coherence-Based Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse subspace clustering (SSC) using greedy-based neighbor selection, such\nas matching pursuit (MP) and orthogonal matching pursuit (OMP), has been known\nas a popular computationally-efficient alternative to the conventional\nL1-minimization based methods. Under deterministic bounded noise corruption, in\nthis paper we derive coherence-based sufficient conditions guaranteeing correct\nneighbor identification using MP/OMP. Our analyses exploit the maximum/minimum\ninner product between two noisy data points subject to a known upper bound on\nthe noise level. The obtained sufficient condition clearly reveals the impact\nof noise on greedy-based neighbor recovery. Specifically, it asserts that, as\nlong as noise is sufficiently small so that the resultant perturbed residual\nvectors stay close to the desired subspace, both MP and OMP succeed in\nreturning a correct neighbor subset. A striking finding is that, when the\nground truth subspaces are well-separated from each other and noise is not\nlarge, MP-based iterations, while enjoying lower algorithmic complexity, yield\nsmaller perturbation of residuals, thereby better able to identify correct\nneighbors and, in turn, achieving higher global data clustering accuracy.\nExtensive numerical experiments are used to corroborate our theoretical study.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:28:35 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wu", "Jwo-Yuh", ""], ["Li", "Wen-Hsuan", ""], ["Huang", "Liang-Chi", ""], ["Lin", "Yen-Ping", ""], ["Liu", "Chun-Hung", ""], ["Gau", "Rung-Hung", ""]]}, {"id": "2002.00412", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Chitwan Saharia, Leonard Boussioux, David Yu-Tung Hui,\n  Maxime Chevalier-Boisvert, Dzmitry Bahdanau and Yoshua Bengio", "title": "Combating False Negatives in Adversarial Imitation Learning", "comments": "This is an extended version of the student abstract published at 34th\n  AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial imitation learning, a discriminator is trained to\ndifferentiate agent episodes from expert demonstrations representing the\ndesired behavior. However, as the trained policy learns to be more successful,\nthe negative examples (the ones produced by the agent) become increasingly\nsimilar to expert ones. Despite the fact that the task is successfully\naccomplished in some of the agent's trajectories, the discriminator is trained\nto output low values for them. We hypothesize that this inconsistent training\nsignal for the discriminator can impede its learning, and consequently leads to\nworse overall performance of the agent. We show experimental evidence for this\nhypothesis and that the 'False Negatives' (i.e. successful agent episodes)\nsignificantly hinder adversarial imitation learning, which is the first\ncontribution of this paper. Then, we propose a method to alleviate the impact\nof false negatives and test it on the BabyAI environment. This method\nconsistently improves sample efficiency over the baselines by at least an order\nof magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:56:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zolna", "Konrad", ""], ["Saharia", "Chitwan", ""], ["Boussioux", "Leonard", ""], ["Hui", "David Yu-Tung", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.00413", "submitter": "Yiyan Qi", "authors": "Yiyan Qi, Pinghui Wang, Yuanming Zhang, Junzhou Zhao, Guangjian Tian,\n  and Xiaohong Guan", "title": "Fast Generating A Large Number of Gumbel-Max Variables", "comments": "Accepted by WebConf2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Gumbel-Max Trick for sampling elements from a categorical\ndistribution (or more generally a nonnegative vector) and its variants have\nbeen widely used in areas such as machine learning and information retrieval.\nTo sample a random element $i$ (or a Gumbel-Max variable $i$) in proportion to\nits positive weight $v_i$, the Gumbel-Max Trick first computes a Gumbel random\nvariable $g_i$ for each positive weight element $i$, and then samples the\nelement $i$ with the largest value of $g_i+\\ln v_i$. Recently, applications\nincluding similarity estimation and graph embedding require to generate $k$\nindependent Gumbel-Max variables from high dimensional vectors. However, it is\ncomputationally expensive for a large $k$ (e.g., hundreds or even thousands)\nwhen using the traditional Gumbel-Max Trick. To solve this problem, we propose\na novel algorithm, \\emph{FastGM}, that reduces the time complexity from\n$O(kn^+)$ to $O(k \\ln k + n^+)$, where $n^+$ is the number of positive elements\nin the vector of interest. Instead of computing $k$ independent Gumbel random\nvariables directly, we find that there exists a technique to generate these\nvariables in descending order. Using this technique, our method FastGM computes\nvariables $g_i+\\ln v_i$ for all positive elements $i$ in descending order. As a\nresult, FastGM significantly reduces the computation time because we can stop\nthe procedure of Gumbel random variables computing for many elements especially\nfor those with small weights. Experiments on a variety of real-world datasets\nshow that FastGM is orders of magnitude faster than state-of-the-art methods\nwithout sacrificing accuracy and incurring additional expenses.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 15:15:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Qi", "Yiyan", ""], ["Wang", "Pinghui", ""], ["Zhang", "Yuanming", ""], ["Zhao", "Junzhou", ""], ["Tian", "Guangjian", ""], ["Guan", "Xiaohong", ""]]}, {"id": "2002.00416", "submitter": "Vladimir Krasnopolsky", "authors": "Vladimir Krasnopolsky", "title": "Using Machine Learning for Model Physics: an Overview", "comments": "50 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the overview, a generic mathematical object (mapping) is introduced, and\nits relation to model physics parameterization is explained. Machine learning\n(ML) tools that can be used to emulate and/or approximate mappings are\nintroduced. Applications of ML to emulate existing parameterizations, to\ndevelop new parameterizations, to ensure physical constraints, and control the\naccuracy of developed applications are described. Some ML approaches that allow\ndevelopers to go beyond the standard parameterization paradigm are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 15:29:23 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Krasnopolsky", "Vladimir", ""]]}, {"id": "2002.00421", "submitter": "Kiran Tomlinson", "authors": "Kiran Tomlinson and Austin R. Benson", "title": "Choice Set Optimization Under Discrete Choice Models of Group Decisions", "comments": "19 pages, 7 figures. ICML 2020. This is an updated version after\n  reviews", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The way that people make choices or exhibit preferences can be strongly\naffected by the set of available alternatives, often called the choice set.\nFurthermore, there are usually heterogeneous preferences, either at an\nindividual level within small groups or within sub-populations of large groups.\nGiven the availability of choice data, there are now many models that capture\nthis behavior in order to make effective predictions--however, there is little\nwork in understanding how directly changing the choice set can be used to\ninfluence the preferences of a collection of decision-makers. Here, we use\ndiscrete choice modeling to develop an optimization framework of such\ninterventions for several problems of group influence, namely maximizing\nagreement or disagreement and promoting a particular choice. We show that these\nproblems are NP-hard in general, but imposing restrictions reveals a\nfundamental boundary: promoting a choice can be easier than encouraging\nconsensus or sowing discord. We design approximation algorithms for the hard\nproblems and show that they work well on real-world choice data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 15:59:58 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 00:54:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tomlinson", "Kiran", ""], ["Benson", "Austin R.", ""]]}, {"id": "2002.00469", "submitter": "Stephan Rasp", "authors": "Stephan Rasp, Peter D. Dueben, Sebastian Scher, Jonathan A. Weyn,\n  Soukayna Mouatadid, Nils Thuerey", "title": "WeatherBench: A benchmark dataset for data-driven weather forecasting", "comments": "Github repository: https://github.com/pangeo-data/WeatherBench; Data\n  download: https://mediatum.ub.tum.de/1524895", "journal-ref": null, "doi": "10.1029/2020MS002203", "report-no": null, "categories": "physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven approaches, most prominently deep learning, have become powerful\ntools for prediction in many domains. A natural question to ask is whether\ndata-driven methods could also be used to predict global weather patterns days\nin advance. First studies show promise but the lack of a common dataset and\nevaluation metrics make inter-comparison between studies difficult. Here we\npresent a benchmark dataset for data-driven medium-range weather forecasting, a\ntopic of high scientific interest for atmospheric and computer scientists\nalike. We provide data derived from the ERA5 archive that has been processed to\nfacilitate the use in machine learning models. We propose simple and clear\nevaluation metrics which will enable a direct comparison between different\nmethods. Further, we provide baseline scores from simple linear regression\ntechniques, deep learning models, as well as purely physical forecasting\nmodels. The dataset is publicly available at\nhttps://github.com/pangeo-data/WeatherBench and the companion code is\nreproducible with tutorials for getting started. We hope that this dataset will\naccelerate research in data-driven weather forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 19:20:46 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:45:27 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 19:13:22 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Rasp", "Stephan", ""], ["Dueben", "Peter D.", ""], ["Scher", "Sebastian", ""], ["Weyn", "Jonathan A.", ""], ["Mouatadid", "Soukayna", ""], ["Thuerey", "Nils", ""]]}, {"id": "2002.00492", "submitter": "Peizhong Ju", "authors": "Peizhong Ju, Xiaojun Lin, Jia Liu", "title": "Overfitting Can Be Harmless for Basis Pursuit, But Only to a Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been significant interests in studying the so-called\n\"double-descent\" of the generalization error of linear regression models under\nthe overparameterized and overfitting regime, with the hope that such analysis\nmay provide the first step towards understanding why overparameterized deep\nneural networks (DNN) still generalize well. However, to date most of these\nstudies focused on the min $\\ell_2$-norm solution that overfits the data. In\ncontrast, in this paper we study the overfitting solution that minimizes the\n$\\ell_1$-norm, which is known as Basis Pursuit (BP) in the compressed sensing\nliterature. Under a sparse true linear regression model with $p$ i.i.d.\nGaussian features, we show that for a large range of $p$ up to a limit that\ngrows exponentially with the number of samples $n$, with high probability the\nmodel error of BP is upper bounded by a value that decreases with $p$. To the\nbest of our knowledge, this is the first analytical result in the literature\nestablishing the double-descent of overfitting BP for finite $n$ and $p$.\nFurther, our results reveal significant differences between the double-descent\nof BP and min $\\ell_2$-norm solutions. Specifically, the double-descent\nupper-bound of BP is independent of the signal strength, and for high SNR and\nsparse models the descent-floor of BP can be much lower and wider than that of\nmin $\\ell_2$-norm solutions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 20:48:39 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 23:29:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ju", "Peizhong", ""], ["Lin", "Xiaojun", ""], ["Liu", "Jia", ""]]}, {"id": "2002.00495", "submitter": "Andrew Wagenmaker", "authors": "Andrew Wagenmaker and Kevin Jamieson", "title": "Active Learning for Identification of Linear Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to actively estimate the parameters of a linear\ndynamical system. Given complete control over the system's input, our algorithm\nadaptively chooses the inputs to accelerate estimation. We show a finite time\nbound quantifying the estimation rate our algorithm attains and prove matching\nupper and lower bounds which guarantee its asymptotic optimality, up to\nconstants. In addition, we show that this optimal rate is unattainable when\nusing Gaussian noise to excite the system, even with optimally tuned\ncovariance, and analyze several examples where our algorithm provably improves\nover rates obtained by playing noise. Our analysis critically relies on a novel\nresult quantifying the error in estimating the parameters of a dynamical system\nwhen arbitrary periodic inputs are being played. We conclude with numerical\nexamples that illustrate the effectiveness of our algorithm in practice.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:30:38 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 15:57:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wagenmaker", "Andrew", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2002.00497", "submitter": "Karl Kurzer", "authors": "Karl Kurzer, Marcus Fechner and J. Marius Z\\\"ollner", "title": "Accelerating Cooperative Planning for Automated Vehicles with Learned\n  Heuristics and Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient driving in urban traffic scenarios requires foresight. The\nobservation of other traffic participants and the inference of their possible\nnext actions depending on the own action is considered cooperative prediction\nand planning. Humans are well equipped with the capability to predict the\nactions of multiple interacting traffic participants and plan accordingly,\nwithout the need to directly communicate with others. Prior work has shown that\nit is possible to achieve effective cooperative planning without the need for\nexplicit communication. However, the search space for cooperative plans is so\nlarge that most of the computational budget is spent on exploring the search\nspace in unpromising regions that are far away from the solution. To accelerate\nthe planning process, we combined learned heuristics with a cooperative\nplanning method to guide the search towards regions with promising actions,\nyielding better solutions at lower computational costs.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:41:35 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 14:46:05 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kurzer", "Karl", ""], ["Fechner", "Marcus", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2002.00498", "submitter": "Nisara Sriwattanaworachai", "authors": "Roxana Pamfil, Nisara Sriwattanaworachai, Shaan Desai, Philip\n  Pilgerstorfer, Paul Beaumont, Konstantinos Georgatzis, Bryon Aragam", "title": "DYNOTEARS: Structure Learning from Time-Series Data", "comments": "23 pages, 13 figures, accepted to AISTATS 2020, corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the structure learning problem for dynamic Bayesian networks and\npropose a method that simultaneously estimates contemporaneous (intra-slice)\nand time-lagged (inter-slice) relationships between variables in a time-series.\nOur approach is score-based, and revolves around minimizing a penalized loss\nsubject to an acyclicity constraint. To solve this problem, we leverage a\nrecent algebraic result characterizing the acyclicity constraint as a smooth\nequality constraint. The resulting algorithm, which we call DYNOTEARS,\noutperforms other methods on simulated data, especially in high-dimensions as\nthe number of variables increases. We also apply this algorithm on real\ndatasets from two different domains, finance and molecular biology, and analyze\nthe resulting output. Compared to state-of-the-art methods for learning dynamic\nBayesian networks, our method is both scalable and accurate on real data. The\nsimple formulation and competitive performance of our method make it suitable\nfor a variety of problems where one seeks to learn connections between\nvariables across time.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:47:48 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 18:06:04 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Pamfil", "Roxana", ""], ["Sriwattanaworachai", "Nisara", ""], ["Desai", "Shaan", ""], ["Pilgerstorfer", "Philip", ""], ["Beaumont", "Paul", ""], ["Georgatzis", "Konstantinos", ""], ["Aragam", "Bryon", ""]]}, {"id": "2002.00526", "submitter": "Wenbo Guo", "authors": "Yang Lu, Wenbo Guo, Xinyu Xing, William Stafford Noble", "title": "DANCE: Enhancing saliency maps using decoys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods can make deep neural network predictions more interpretable\nby identifying a set of critical features in an input sample, such as pixels\nthat contribute most strongly to a prediction made by an image classifier.\nUnfortunately, recent evidence suggests that many saliency methods poorly\nperform, especially in situations where gradients are saturated, inputs contain\nadversarial perturbations, or predictions rely upon inter-feature dependence.\nTo address these issues, we propose a framework that improves the robustness of\nsaliency methods by following a two-step procedure. First, we introduce a\nperturbation mechanism that subtly varies the input sample without changing its\nintermediate representations. Using this approach, we can gather a corpus of\nperturbed data samples while ensuring that the perturbed and original input\nsamples follow the same distribution. Second, we compute saliency maps for the\nperturbed samples and propose a new method to aggregate saliency maps. With\nthis design, we offset the gradient saturation influence upon interpretation.\nFrom a theoretical perspective, we show the aggregated saliency map could not\nonly capture inter-feature dependence but, more importantly, robustify\ninterpretation against previously described adversarial perturbation methods.\nFollowing our theoretical analysis, we present experimental results suggesting\nthat, both qualitatively and quantitatively, our saliency method outperforms\nexisting methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 01:21:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 21:26:14 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 15:31:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lu", "Yang", ""], ["Guo", "Wenbo", ""], ["Xing", "Xinyu", ""], ["Noble", "William Stafford", ""]]}, {"id": "2002.00557", "submitter": "Amol Kelkar", "authors": "Amol Kelkar, Rohan Relan, Vaishali Bhardwaj, Saurabh Vaichal, Chandra\n  Khatri, Peter Relan", "title": "Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker", "comments": "Accepted at WeCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To access data stored in relational databases, users need to understand the\ndatabase schema and write a query using a query language such as SQL. To\nsimplify this task, text-to-SQL models attempt to translate a user's natural\nlanguage question to corresponding SQL query. Recently, several generative\ntext-to-SQL models have been developed. We propose a novel discriminative\nre-ranker to improve the performance of generative text-to-SQL models by\nextracting the best SQL query from the beam output predicted by the text-to-SQL\ngenerator, resulting in improved performance in the cases where the best query\nwas in the candidate list, but not at the top of the list. We build the\nre-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative\nstrengths of the text-to-SQL and re-ranker models across different query\nhardness levels, and suggest how to combine the two models for optimal\nperformance. We demonstrate the effectiveness of the re-ranker by applying it\nto two state-of-the-art text-to-SQL models, and achieve top 4 score on the\nSpider leaderboard at the time of writing this article.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 04:52:47 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:22:57 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kelkar", "Amol", ""], ["Relan", "Rohan", ""], ["Bhardwaj", "Vaishali", ""], ["Vaichal", "Saurabh", ""], ["Khatri", "Chandra", ""], ["Relan", "Peter", ""]]}, {"id": "2002.00573", "submitter": "Wei-Lun Chao", "authors": "Wei-Lun Chao, Han-Jia Ye, De-Chuan Zhan, Mark Campbell, Kilian Q.\n  Weinberger", "title": "Revisiting Meta-Learning as Supervised Learning", "comments": "An extended version of the paper titled \"A Meta Understanding of\n  Meta-Learning\" presented in ICML 2019 Workshop on Adaptive and Multitask\n  Learning: Algorithms & Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed an abundance of new publications and approaches\non meta-learning. This community-wide enthusiasm has sparked great insights but\nhas also created a plethora of seemingly different frameworks, which can be\nhard to compare and evaluate. In this paper, we aim to provide a principled,\nunifying framework by revisiting and strengthening the connection between\nmeta-learning and traditional supervised learning. By treating pairs of\ntask-specific data sets and target models as (feature, label) samples, we can\nreduce many meta-learning algorithms to instances of supervised learning. This\nview not only unifies meta-learning into an intuitive and practical framework\nbut also allows us to transfer insights from supervised learning directly to\nimprove meta-learning. For example, we obtain a better understanding of\ngeneralization properties, and we can readily transfer well-understood\ntechniques, such as model ensemble, pre-training, joint training, data\naugmentation, and even nearest neighbor based methods. We provide an intuitive\nanalogy of these methods in the context of meta-learning and show that they\ngive rise to significant improvements in model performance on few-shot\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 06:13:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Chao", "Wei-Lun", ""], ["Ye", "Han-Jia", ""], ["Zhan", "De-Chuan", ""], ["Campbell", "Mark", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.00577", "submitter": "Kangying Lin", "authors": "Huawei Huang, Kangying Lin, Song Guo, Pan Zhou, Zibin Zheng", "title": "Prophet: Proactive Candidate-Selection for Federated Learning by\n  Predicting the Qualities of Training and Reporting Phases", "comments": "We found significant technique errors in our previous version. The\n  proposed DRL-based algorithm cannot solve the large-scale scheduling for\n  federated learning. For the health of relevant research communities, we\n  decide to withdraw our submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the challenge of the device connection is much relieved in 5G\nnetworks, the training latency is still an obstacle preventing Federated\nLearning (FL) from being largely adopted. One of the most fundamental problems\nthat lead to large latency is the bad candidate-selection for FL. In the\ndynamic environment, the mobile devices selected by the existing reactive\ncandidate-selection algorithms very possibly fail to complete the training and\nreporting phases of FL, because the FL parameter server only knows the\ncurrently-observed resources of all candidates. To this end, we study the\nproactive candidate-selection for FL in this paper. We first let each candidate\ndevice predict the qualities of both its training and reporting phases locally\nusing LSTM. Then, the proposed candidateselection algorithm is implemented by\nthe Deep Reinforcement Learning (DRL) framework. Finally, the real-world\ntrace-driven experiments prove that the proposed approach outperforms the\nexisting reactive algorithms\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 06:40:04 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:55:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Huang", "Huawei", ""], ["Lin", "Kangying", ""], ["Guo", "Song", ""], ["Zhou", "Pan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2002.00585", "submitter": "Eran Malach", "authors": "Eran Malach, Gilad Yehudai, Shai Shalev-Shwartz, Ohad Shamir", "title": "Proving the Lottery Ticket Hypothesis: Pruning is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lottery ticket hypothesis (Frankle and Carbin, 2018), states that a\nrandomly-initialized network contains a small subnetwork such that, when\ntrained in isolation, can compete with the performance of the original network.\nWe prove an even stronger hypothesis (as was also conjectured in Ramanujan et\nal., 2019), showing that for every bounded distribution and every target\nnetwork with bounded weights, a sufficiently over-parameterized neural network\nwith random weights contains a subnetwork with roughly the same accuracy as the\ntarget network, without any further training.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 07:23:11 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Malach", "Eran", ""], ["Yehudai", "Gilad", ""], ["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""]]}, {"id": "2002.00632", "submitter": "Jack Parker-Holder", "authors": "Jack Parker-Holder and Aldo Pacchiano and Krzysztof Choromanski and\n  Stephen Roberts", "title": "Effective Diversity in Population Based Reinforcement Learning", "comments": "Camera-ready version, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a key problem in reinforcement learning, since agents can only\nlearn from data they acquire in the environment. With that in mind, maintaining\na population of agents is an attractive method, as it allows data be collected\nwith a diverse set of behaviors. This behavioral diversity is often boosted via\nmulti-objective loss functions. However, those approaches typically leverage\nmean field updates based on pairwise distances, which makes them susceptible to\ncycling behaviors and increased redundancy. In addition, explicitly boosting\ndiversity often has a detrimental impact on optimizing already fruitful\nbehaviors for rewards. As such, the reward-diversity trade off typically relies\non heuristics. Finally, such methods require behavioral representations, often\nhandcrafted and domain specific. In this paper, we introduce an approach to\noptimize all members of a population simultaneously. Rather than using pairwise\ndistance, we measure the volume of the entire population in a behavioral\nmanifold, defined by task-agnostic behavioral embeddings. In addition, our\nalgorithm Diversity via Determinants (DvD), adapts the degree of diversity\nduring training using online learning techniques. We introduce both\nevolutionary and gradient-based instantiations of DvD and show they effectively\nimprove exploration without reducing performance when better exploration is not\nrequired.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 10:09:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 05:49:56 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 16:03:39 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Parker-Holder", "Jack", ""], ["Pacchiano", "Aldo", ""], ["Choromanski", "Krzysztof", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.00643", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Kate Lin, Emily Fertig, Sharad Vikram, Max Hinne,\n  Dave Moore, Marcel van Gerven", "title": "Automatic structured variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference offers an attractive option as a default\nmethod for differentiable probabilistic programming. However, the performance\nof the variational approach depends on the choice of an appropriate variational\nfamily. Here, we introduce automatic structured variational inference (ASVI), a\nfully automated method for constructing structured variational families,\ninspired by the closed-form update in conjugate Bayesian models. These\nconvex-update families incorporate the forward pass of the input probabilistic\nprogram and can therefore capture complex statistical dependencies.\nConvex-update families have the same space and time complexity as the input\nprobabilistic program and are therefore tractable for a very large family of\nmodels including both continuous and discrete variables. We validate our\nautomatic variational method on a wide range of low- and high-dimensional\ninference problems. We find that ASVI provides a clear improvement in\nperformance when compared with other popular approaches such as the mean-field\napproach and inverse autoregressive flows. We provide an open source\nimplementation of ASVI in TensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 10:52:30 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 11:44:50 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 18:52:08 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Ambrogioni", "Luca", ""], ["Lin", "Kate", ""], ["Fertig", "Emily", ""], ["Vikram", "Sharad", ""], ["Hinne", "Max", ""], ["Moore", "Dave", ""], ["van Gerven", "Marcel", ""]]}, {"id": "2002.00655", "submitter": "Alexander Renz-Wieland", "authors": "Alexander Renz-Wieland, Rainer Gemulla, Steffen Zeuch, Volker Markl", "title": "Dynamic Parameter Allocation in Parameter Servers", "comments": null, "journal-ref": "PVLDB, 13(11): 1877-1890, 2020", "doi": "10.14778/3407790.3407796", "report-no": null, "categories": "cs.LG cs.DB cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To keep up with increasing dataset sizes and model complexity, distributed\ntraining has become a necessity for large machine learning tasks. Parameter\nservers ease the implementation of distributed parameter management---a key\nconcern in distributed training---, but can induce severe communication\noverhead. To reduce communication overhead, distributed machine learning\nalgorithms use techniques to increase parameter access locality (PAL),\nachieving up to linear speed-ups. We found that existing parameter servers\nprovide only limited support for PAL techniques, however, and therefore prevent\nefficient training. In this paper, we explore whether and to what extent PAL\ntechniques can be supported, and whether such support is beneficial. We propose\nto integrate dynamic parameter allocation into parameter servers, describe an\nefficient implementation of such a parameter server called Lapse, and\nexperimentally compare its performance to existing parameter servers across a\nnumber of machine learning tasks. We found that Lapse provides near-linear\nscaling and can be orders of magnitude faster than existing parameter servers.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:37:54 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:05:58 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 12:52:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Renz-Wieland", "Alexander", ""], ["Gemulla", "Rainer", ""], ["Zeuch", "Steffen", ""], ["Markl", "Volker", ""]]}, {"id": "2002.00658", "submitter": "Marine Le Morvan", "authors": "Marine Le Morvan (PARIETAL, IJCLab), Nicolas Prost (CMAP, XPOP), Julie\n  Josse (CMAP, XPOP), Erwan Scornet (CMAP), Ga\\\"el Varoquaux (PARIETAL, MILA)", "title": "Linear predictor on linearly-generated data with missing values: non\n  consistency and solutions", "comments": null, "journal-ref": "Proceedings of Machine Learning Research, PMLR, In press", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider building predictors when the data have missing values. We study\nthe seemingly-simple case where the target to predict is a linear function of\nthe fully-observed data and we show that, in the presence of missing values,\nthe optimal predictor may not be linear. In the particular Gaussian case, it\ncan be written as a linear function of multiway interactions between the\nobserved data and the various missing-value indicators. Due to its intrinsic\ncomplexity, we study a simple approximation and prove generalization bounds\nwith finite samples, highlighting regimes for which each method performs best.\nWe then show that multilayer perceptrons with ReLU activation functions can be\nconsistent, and can explore good trade-offs between the true model and\napproximations. Our study highlights the interesting family of models that are\nbeneficial to fit with missing values depending on the amount of data\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:49:35 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 16:48:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Morvan", "Marine Le", "", "PARIETAL, IJCLab"], ["Prost", "Nicolas", "", "CMAP, XPOP"], ["Josse", "Julie", "", "CMAP, XPOP"], ["Scornet", "Erwan", "", "CMAP"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, MILA"]]}, {"id": "2002.00695", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis, Besnik Fetahu, Eirini Ntoutsi", "title": "FAE: A Fairness-Aware Ensemble Framework", "comments": "6 pages", "journal-ref": "IEEE International Conference on Big Data, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated decision making based on big data and machine learning (ML)\nalgorithms can result in discriminatory decisions against certain protected\ngroups defined upon personal data like gender, race, sexual orientation etc.\nSuch algorithms designed to discover patterns in big data might not only pick\nup any encoded societal biases in the training data, but even worse, they might\nreinforce such biases resulting in more severe discrimination. The majority of\nthus far proposed fairness-aware machine learning approaches focus solely on\nthe pre-, in- or post-processing steps of the machine learning process, that\nis, input data, learning algorithms or derived models, respectively. However,\nthe fairness problem cannot be isolated to a single step of the ML process.\nRather, discrimination is often a result of complex interactions between big\ndata and algorithms, and therefore, a more holistic approach is required. The\nproposed FAE (Fairness-Aware Ensemble) framework combines fairness-related\ninterventions at both pre- and postprocessing steps of the data analysis\nprocess. In the preprocessing step, we tackle the problems of\nunder-representation of the protected group (group imbalance) and of\nclass-imbalance by generating balanced training samples. In the post-processing\nstep, we tackle the problem of class overlapping by shifting the decision\nboundary in the direction of fairness.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:05:18 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Fetahu", "Besnik", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2002.00717", "submitter": "Xinze Zhang", "authors": "Xinze Zhang, Kun He, Yukun Bao", "title": "Error-feedback Stochastic Configuration Strategy on Convolutional Neural\n  Networks for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the superiority of convolutional neural networks demonstrated in time\nseries modeling and forecasting, it has not been fully explored on the design\nof the neural network architecture as well as the tuning of the\nhyper-parameters. Inspired by the iterative construction strategy for building\na random multilayer perceptron, we propose a novel Error-feedback Stochastic\nConfiguration (ESC) strategy to construct a random Convolutional Neural Network\n(ESC-CNN) for time series forecasting task, which builds the network\narchitecture adaptively. The ESC strategy suggests that random filters and\nneurons of the error-feedback fully connected layer are incrementally added in\na manner that they can steadily compensate the prediction error during the\nconstruction process, and a filter selection strategy is introduced to secure\nthat ESC-CNN holds the universal approximation property, providing helpful\ninformation at each iterative process for the prediction. The performance of\nESC-CNN is justified on its prediction accuracy for one-step-ahead and\nmulti-step-ahead forecasting tasks. Comprehensive experiments on a synthetic\ndataset and two real-world datasets show that the proposed ESC-CNN not only\noutperforms the state-of-art random neural networks, but also exhibits strong\npredictive power in comparison to trained Convolution Neural Networks and Long\nShort-Term Memory models, demonstrating the effectiveness of ESC-CNN in time\nseries forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:30:29 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zhang", "Xinze", ""], ["He", "Kun", ""], ["Bao", "Yukun", ""]]}, {"id": "2002.00721", "submitter": "Nikolai Zolotykh", "authors": "Evgeny Dolotov and Nikolai Zolotykh", "title": "Evolutionary algorithms for constructing an ensemble of decision trees", "comments": "7 pages, 2 tables AIST 2019, accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most decision tree induction algorithms are based on a greedy top-down\nrecursive partitioning strategy for tree growth. In this paper, we propose\nseveral methods for induction of decision trees and their ensembles based on\nevolutionary algorithms. The main difference of our approach is using\nreal-valued vector representation of decision tree that allows to use a large\nnumber of different optimization algorithms, as well as optimize the whole tree\nor ensemble for avoiding local optima. Differential evolution and evolution\nstrategies were chosen as optimization algorithms, as they have good results in\nreinforcement learning problems. We test the predictive performance of this\nmethods using several public UCI data sets, and the proposed methods show\nbetter quality than classical methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:38:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Dolotov", "Evgeny", ""], ["Zolotykh", "Nikolai", ""]]}, {"id": "2002.00727", "submitter": "Tomoki Yoshida", "authors": "Tomoki Yoshida, Ichiro Takeuchi, Masayuki Karasuyama", "title": "Distance Metric Learning for Graph Structured Data", "comments": "38 pages, 11 figures. This is a pre-print of an article published in\n  Machine Learning Journal. The final authenticated version is available online\n  at: https://doi.org/10.1007/s10994-021-06009-3", "journal-ref": null, "doi": "10.1007/s10994-021-06009-3", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are versatile tools for representing structured data. As a result, a\nvariety of machine learning methods have been studied for graph data analysis.\nAlthough many such learning methods depend on the measurement of differences\nbetween input graphs, defining an appropriate distance metric for graphs\nremains a controversial issue. Hence, we propose a supervised distance metric\nlearning method for the graph classification problem. Our method, named\ninterpretable graph metric learning (IGML), learns discriminative metrics in a\nsubgraph-based feature space, which has a strong graph representation\ncapability. By introducing a sparsity-inducing penalty on the weight of each\nsubgraph, IGML can identify a small number of important subgraphs that can\nprovide insight into the given classification task. Because our formulation has\na large number of optimization variables, an efficient algorithm that uses\npruning techniques based on safe screening and working set selection methods is\nalso proposed. An important property of IGML is that solution optimality is\nguaranteed because the problem is formulated as a convex problem and our\npruning strategies only discard unnecessary subgraphs. Furthermore, we show\nthat IGML is also applicable to other structured data such as itemset and\nsequence data, and that it can incorporate vertex-label similarity by using a\ntransportation-based subgraph feature. We empirically evaluate the\ncomputational efficiency and classification performance of IGML on several\nbenchmark datasets and provide some illustrative examples of how IGML\nidentifies important subgraphs from a given graph dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:42:43 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 06:22:00 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yoshida", "Tomoki", ""], ["Takeuchi", "Ichiro", ""], ["Karasuyama", "Masayuki", ""]]}, {"id": "2002.00733", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi, George Han, Celine Liang", "title": "Generation-Distillation for Efficient Natural Language Understanding in\n  Low-Data Settings", "comments": "EMNLP 2019 Workshop on Deep Learning for Low-resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past year, the emergence of transfer learning with large-scale\nlanguage models (LM) has led to dramatic performance improvements across a\nbroad range of natural language understanding tasks. However, the size and\nmemory footprint of these large LMs makes them difficult to deploy in many\nscenarios (e.g. on mobile phones). Recent research points to knowledge\ndistillation as a potential solution, showing that when training data for a\ngiven task is abundant, it is possible to distill a large (teacher) LM into a\nsmall task-specific (student) network with minimal loss of performance.\nHowever, when such data is scarce, there remains a significant performance gap\nbetween large pretrained LMs and smaller task-specific models, even when\ntraining via distillation. In this paper, we bridge this gap with a novel\ntraining approach, called generation-distillation, that leverages large\nfinetuned LMs in two ways: (1) to generate new (unlabeled) training examples,\nand (2) to distill their knowledge into a small network using these examples.\nAcross three low-resource text classification datsets, we achieve comparable\nperformance to BERT while using 300x fewer parameters, and we outperform prior\napproaches to distillation for text classification while using 3x fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:20:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Melas-Kyriazi", "Luke", ""], ["Han", "George", ""], ["Liang", "Celine", ""]]}, {"id": "2002.00743", "submitter": "Kshitij Jain", "authors": "Xin Lian, Kshitij Jain, Jakub Truszkowski, Pascal Poupart, and\n  Yaoliang Yu", "title": "Unsupervised Multilingual Alignment using Wasserstein Barycenter", "comments": "Code is available at https://github.com/alixxxin/multi-lang", "journal-ref": "Proceedings of International Joint Conference on Artificial\n  Intelligence (IJCAI), 2020", "doi": "10.24963/ijcai.2020/512", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study unsupervised multilingual alignment, the problem of finding\nword-to-word translations between multiple languages without using any parallel\ndata. One popular strategy is to reduce multilingual alignment to the much\nsimplified bilingual setting, by picking one of the input languages as the\npivot language that we transit through. However, it is well-known that\ntransiting through a poorly chosen pivot language (such as English) may\nseverely degrade the translation quality, since the assumed transitive\nrelations among all pairs of languages may not be enforced in the training\nprocess. Instead of going through a rather arbitrarily chosen pivot language,\nwe propose to use the Wasserstein barycenter as a more informative \"mean\"\nlanguage: it encapsulates information from all languages and minimizes all\npairwise transportation costs. We evaluate our method on standard benchmarks\nand demonstrate state-of-the-art performances.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:22:07 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 23:42:33 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Lian", "Xin", ""], ["Jain", "Kshitij", ""], ["Truszkowski", "Jakub", ""], ["Poupart", "Pascal", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2002.00745", "submitter": "Zihao Wang", "authors": "Zihao Wang, Yong Zhang, Hao Wu", "title": "Structural-Aware Sentence Similarity with Recursive Optimal Transport", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Measuring sentence similarity is a classic topic in natural language\nprocessing. Light-weighted similarities are still of particular practical\nsignificance even when deep learning models have succeeded in many other tasks.\nSome light-weighted similarities with more theoretical insights have been\ndemonstrated to be even stronger than supervised deep learning approaches.\nHowever, the successful light-weighted models such as Word Mover's Distance\n[Kusner et al., 2015] or Smooth Inverse Frequency [Arora et al., 2017] failed\nto detect the difference from the structure of sentences, i.e. order of words.\nTo address this issue, we present Recursive Optimal Transport (ROT) framework\nto incorporate the structural information with the classic OT. Moreover, we\nfurther develop Recursive Optimal Similarity (ROTS) for sentences with the\nvaluable semantic insights from the connections between cosine similarity of\nweighted average of word vectors and optimal transport. ROTS is\nstructural-aware and with low time complexity compared to optimal transport.\nOur experiments over 20 sentence textural similarity (STS) datasets show the\nclear advantage of ROTS over all weakly supervised approaches. Detailed\nablation study demonstrate the effectiveness of ROT and the semantic insights.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 09:07:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Zihao", ""], ["Zhang", "Yong", ""], ["Wu", "Hao", ""]]}, {"id": "2002.00751", "submitter": "Johannes Hofmanninger", "authors": "Johannes Hofmanninger, Sebastian Roehrich, Helmut Prosch and Georg\n  Langs", "title": "Separation of target anatomical structure and occlusions in chest\n  radiographs", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiographs are commonly performed low-cost exams for screening and\ndiagnosis. However, radiographs are 2D representations of 3D structures causing\nconsiderable clutter impeding visual inspection and automated image analysis.\nHere, we propose a Fully Convolutional Network to suppress, for a specific\ntask, undesired visual structure from radiographs while retaining the relevant\nimage information such as lung-parenchyma. The proposed algorithm creates\nreconstructed radiographs and ground-truth data from high resolution CT-scans.\nResults show that removing visual variation that is irrelevant for a\nclassification task improves the performance of a classifier when only limited\ntraining data are available. This is particularly relevant because a low number\nof ground-truth cases is common in medical imaging.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:01:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hofmanninger", "Johannes", ""], ["Roehrich", "Sebastian", ""], ["Prosch", "Helmut", ""], ["Langs", "Georg", ""]]}, {"id": "2002.00758", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger, Nariman Farsad, Yonina C. Eldar, and Andrea J.\n  Goldsmith", "title": "Data-Driven Factor Graphs for Deep Symbol Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important schemes in signal processing and communications, ranging from\nthe BCJR algorithm to the Kalman filter, are instances of factor graph methods.\nThis family of algorithms is based on recursive message passing-based\ncomputations carried out over graphical models, representing a factorization of\nthe underlying statistics. Consequently, in order to implement these\nalgorithms, one must have accurate knowledge of the statistical model of the\nconsidered signals. In this work we propose to implement factor graph methods\nin a data-driven manner. In particular, we propose to use machine learning (ML)\ntools to learn the factor graph, instead of the overall system task, which in\nturn is used for inference by message passing over the learned graph. We apply\nthe proposed approach to learn the factor graph representing a finite-memory\nchannel, demonstrating the resulting ability to implement BCJR detection in a\ndata-driven fashion. We demonstrate that the proposed system, referred to as\nBCJRNet, learns to implement the BCJR algorithm from a small training set, and\nthat the resulting receiver exhibits improved robustness to inaccurate training\ncompared to the conventional channel-model-based receiver operating under the\nsame level of uncertainty. Our results indicate that by utilizing ML tools to\nlearn factor graphs from labeled data, one can implement a broad range of\nmodel-based algorithms, which traditionally require full knowledge of the\nunderlying statistics, in a data-driven fashion.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:23:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Shlezinger", "Nir", ""], ["Farsad", "Nariman", ""], ["Eldar", "Yonina C.", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "2002.00761", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Francisco Guzm\\'an", "title": "Massively Multilingual Document Alignment with Cross-lingual\n  Sentence-Mover's Distance", "comments": "In Proceedings of AACL-IJCNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document alignment aims to identify pairs of documents in two distinct\nlanguages that are of comparable content or translations of each other. Such\naligned data can be used for a variety of NLP tasks from training cross-lingual\nrepresentations to mining parallel data for machine translation. In this paper\nwe develop an unsupervised scoring function that leverages cross-lingual\nsentence embeddings to compute the semantic distance between documents in\ndifferent languages. These semantic distances are then used to guide a document\nalignment algorithm to properly pair cross-lingual web documents across a\nvariety of low, mid, and high-resource language pairs. Recognizing that our\nproposed scoring function and other state of the art methods are\ncomputationally intractable for long web documents, we utilize a more tractable\ngreedy algorithm that performs comparably. We experimentally demonstrate that\nour distance metric performs better alignment than current baselines\noutperforming them by 7% on high-resource language pairs, 15% on mid-resource\nlanguage pairs, and 22% on low-resource language pairs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:14:16 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 05:26:32 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Guzm\u00e1n", "Francisco", ""]]}, {"id": "2002.00784", "submitter": "Craig Innes", "authors": "Craig Innes, Subramanian Ramamoorthy", "title": "Elaborating on Learned Demonstrations with Temporal Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current methods for learning from demonstrations assume that those\ndemonstrations alone are sufficient to learn the underlying task. This is often\nuntrue, especially if extra safety specifications exist which were not present\nin the original demonstrations. In this paper, we allow an expert to elaborate\non their original demonstration with additional specification information using\nlinear temporal logic (LTL). Our system converts LTL specifications into a\ndifferentiable loss. This loss is then used to learn a dynamic movement\nprimitive that satisfies the underlying specification, while remaining close to\nthe original demonstration. Further, by leveraging adversarial training, our\nsystem learns to robustly satisfy the given LTL specification on unseen inputs,\nnot just those seen in training. We show that our method is expressive enough\nto work across a variety of common movement specification patterns such as\nobstacle avoidance, patrolling, keeping steady, and speed limitation. In\naddition, we show that our system can modify a base demonstration with complex\nspecifications by incrementally composing multiple simpler specifications. We\nalso implement our system on a PR-2 robot to show how a demonstrator can start\nwith an initial (sub-optimal) demonstration, then interactively improve task\nsuccess by including additional specifications enforced with our differentiable\nLTL loss.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:33:38 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 19:53:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Innes", "Craig", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2002.00790", "submitter": "Joseph Bakarji", "authors": "Joseph Bakarji, Daniel M. Tartakovsky", "title": "Data-Driven Discovery of Coarse-Grained Equations", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2021.110219", "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical (machine learning) tools for equation discovery require large\namounts of data that are typically computer generated rather than\nexperimentally observed. Multiscale modeling and stochastic simulations are two\nareas where learning on simulated data can lead to such discovery. In both, the\ndata are generated with a reliable but impractical model, e.g., molecular\ndynamics simulations, while a model on the scale of interest is uncertain,\nrequiring phenomenological constitutive relations and ad-hoc approximations. We\nreplace the human discovery of such models, which typically involves\nspatial/stochastic averaging or coarse-graining, with a machine-learning\nstrategy based on sparse regression that can be executed in two modes. The\nfirst, direct equation-learning, discovers a differential operator from the\nwhole dictionary. The second, constrained equation-learning, discovers only\nthose terms in the differential operator that need to be discovered, i.e.,\nlearns closure approximations. We illustrate our approach by learning a\ndeterministic equation that governs the spatiotemporal evolution of the\nprobability density function of a system state whose dynamics are described by\na nonlinear partial differential equation with random inputs. A series of\nexamples demonstrates the accuracy, robustness, and limitations of our approach\nto equation discovery.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 23:41:37 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 22:31:41 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 20:40:05 GMT"}, {"version": "v4", "created": "Sat, 23 May 2020 00:32:44 GMT"}, {"version": "v5", "created": "Mon, 27 Jul 2020 16:57:59 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Bakarji", "Joseph", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "2002.00793", "submitter": "Junning Deng", "authors": "Junning Deng, Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "Explainable Subgraphs with Surprising Densities: A Subgroup Discovery\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectivity structure of graphs is typically related to the attributes\nof the nodes. In social networks for example, the probability of a friendship\nbetween two people depends on their attributes, such as their age, address, and\nhobbies. The connectivity of a graph can thus possibly be understood in terms\nof patterns of the form 'the subgroup of individuals with properties X are\noften (or rarely) friends with individuals in another subgroup with properties\nY'. Such rules present potentially actionable and generalizable insights into\nthe graph. We present a method that finds pairs of node subgroups between which\nthe edge density is interestingly high or low, using an information-theoretic\ndefinition of interestingness. This interestingness is quantified subjectively,\nto contrast with prior information an analyst may have about the graph. This\nview immediately enables iterative mining of such patterns. Our work\ngeneralizes prior work on dense subgraph mining (i.e. subgraphs induced by a\nsingle subgroup). Moreover, not only is the proposed method more general, we\nalso demonstrate considerable practical advantages for the single subgroup\nspecial case.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 14:25:20 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Deng", "Junning", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.00797", "submitter": "Eliza O'Reilly", "authors": "Eliza O'Reilly and Ngoc Tran", "title": "Stochastic geometry to generalize the Mondrian Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mondrian process is a stochastic process that produces a recursive\npartition of space with random axis-aligned cuts. Random forests and Laplace\nkernel approximations built from the Mondrian process have led to efficient\nonline learning methods and Bayesian optimization. By viewing the Mondrian\nprocess as a special case of the stable under iterated tessellation (STIT)\nprocess, we utilize tools from stochastic geometry to resolve some fundamental\nquestions concerning the Mondrian process in machine learning. First, we show\nthat the Mondrian process with general cut directions can be efficiently\nsimulated by lifting to a higher dimensional axis-aligned Mondrian process.\nSecond, we characterize all possible kernels that generalizations of the\nMondrian process can approximate with fixed parameters as well as additional\nkernels obtained from mixtures of STIT processes. This includes, for instance,\nvarious forms of the weighted Laplace kernel and the exponential kernel.\nLastly, we give an explicit formula for the density estimator arising from a\nMondrian forest. This allows for precise comparisons between the Mondrian\nforest, the Mondrian kernel and the Laplace kernel in density estimation. Our\npaper calls for further developments at the novel intersection of stochastic\ngeometry and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:47:26 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:47:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["O'Reilly", "Eliza", ""], ["Tran", "Ngoc", ""]]}, {"id": "2002.00818", "submitter": "Markus Lange-Hegermann", "authors": "Markus Lange-Hegermann", "title": "Linearly Constrained Gaussian Processes with Boundary Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SC math.AC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One goal in Bayesian machine learning is to encode prior knowledge into prior\ndistributions, to model data efficiently. We consider prior knowledge from\nsystems of linear partial differential equations together with their boundary\nconditions. We construct multi-output Gaussian process priors with realizations\nin the solution set of such systems, in particular only such solutions can be\nrepresented by Gaussian process regression. The construction is fully\nalgorithmic via Gr\\\"obner bases and it does not employ any approximation. It\nbuilds these priors combining two parametrizations via a pullback: the first\nparametrizes the solutions for the system of differential equations and the\nsecond parametrizes all functions adhering to the boundary conditions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:19:03 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 14:24:03 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 11:34:34 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lange-Hegermann", "Markus", ""]]}, {"id": "2002.00819", "submitter": "Donatella Firmani", "authors": "Andrea Rossi, Donatella Firmani, Antonio Matinata, Paolo Merialdo,\n  Denilson Barbosa", "title": "Knowledge Graph Embedding for Link Prediction: A Comparative Analysis", "comments": "Andrea Rossi, Donatella Firmani, Antonio Matinata, Paolo Merialdo,\n  Denilson Barbosa. 2020. Knowledge Graph Embedding for Link Prediction: A\n  Comparative Analysis. In ACM Transactions on Knowledge Discovery from Data.\n  January 2021. (TKDD 2021). ACM, New York, NY, USA", "journal-ref": null, "doi": "10.1145/3424672", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) have found many applications in industry and academic\nsettings, which in turn, have motivated considerable research efforts towards\nlarge-scale information extraction from a variety of sources. Despite such\nefforts, it is well known that even state-of-the-art KGs suffer from\nincompleteness. Link Prediction (LP), the task of predicting missing facts\namong entities already a KG, is a promising and widely studied task aimed at\naddressing KG incompleteness. Among the recent LP techniques, those based on KG\nembeddings have achieved very promising performances in some benchmarks.\nDespite the fast growing literature in the subject, insufficient attention has\nbeen paid to the effect of the various design choices in those methods.\nMoreover, the standard practice in this area is to report accuracy by\naggregating over a large number of test facts in which some entities are\nover-represented; this allows LP methods to exhibit good performance by just\nattending to structural properties that include such entities, while ignoring\nthe remaining majority of the KG. This analysis provides a comprehensive\ncomparison of embedding-based LP methods, extending the dimensions of analysis\nbeyond what is commonly available in the literature. We experimentally compare\neffectiveness and efficiency of 16 state-of-the-art methods, consider a\nrule-based baseline, and report detailed analysis over the most popular\nbenchmarks in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:21:25 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:32:38 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 22:13:48 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 21:15:36 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Rossi", "Andrea", ""], ["Firmani", "Donatella", ""], ["Matinata", "Antonio", ""], ["Merialdo", "Paolo", ""], ["Barbosa", "Denilson", ""]]}, {"id": "2002.00833", "submitter": "Steven Thompson Mr", "authors": "Steven Thompson, Paul Fergus, Carl Chalmers, and Denis Reilly", "title": "Detection of Obstructive Sleep Apnoea Using Features Extracted from\n  Segmented Time-Series ECG Signals Using a One Dimensional Convolutional\n  Neural Network", "comments": "8 pages, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study in this paper presents a one-dimensional convolutional neural\nnetwork (1DCNN) model, designed for the automated detection of obstructive\nSleep Apnoea (OSA) captured from single-channel electrocardiogram (ECG)\nsignals. The system provides mechanisms in clinical practice that help diagnose\npatients suffering with OSA. Using the state-of-the-art in 1DCNNs, a model is\nconstructed using convolutional, max pooling layers and a fully connected\nMultilayer Perceptron (MLP) consisting of a hidden layer and SoftMax output for\nclassification. The 1DCNN extracts prominent features, which are used to train\nan MLP. The model is trained using segmented ECG signals grouped into 5 unique\ndatasets of set window sizes. 35 ECG signal recordings were selected from an\nannotated database containing 70 night-time ECG recordings. (Group A = a01 to\na20 (Apnoea breathing), Group B = b01 to b05 (moderate), and Group C = c01 to\nc10 (normal). A total of 6514 minutes of Apnoea was recorded. Evaluation of the\nmodel is performed using a set of standard metrics which show the proposed\nmodel achieves high classification results in both training and validation\nusing our windowing strategy, particularly W=500 (Sensitivity 0.9705,\nSpecificity 0.9725, F1 Score 0.9717, Kappa Score 0.9430, Log Loss 0.0836,\nROCAUC 0.9945). This demonstrates the model can identify the presence of Apnoea\nwith a high degree of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:47:00 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Thompson", "Steven", ""], ["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Reilly", "Denis", ""]]}, {"id": "2002.00837", "submitter": "Enyan Dai", "authors": "Enyan Dai, Yiwei Sun, Suhang Wang", "title": "Ginger Cannot Cure Cancer: Battling Fake Health News with a\n  Comprehensive Data Repository", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Internet is a primary source of attaining health information.\nMassive fake health news which is spreading over the Internet, has become a\nsevere threat to public health. Numerous studies and research works have been\ndone in fake news detection domain, however, few of them are designed to cope\nwith the challenges in health news. For instance, the development of\nexplainable is required for fake health news detection. To mitigate these\nproblems, we construct a comprehensive repository, FakeHealth, which includes\nnews contents with rich features, news reviews with detailed explanations,\nsocial engagements and a user-user social network. Moreover, exploratory\nanalyses are conducted to understand the characteristics of the datasets,\nanalyze useful patterns and validate the quality of the datasets for health\nfake news detection. We also discuss the novel and potential future research\ndirections for the health fake news detection.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:27:58 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 06:08:08 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dai", "Enyan", ""], ["Sun", "Yiwei", ""], ["Wang", "Suhang", ""]]}, {"id": "2002.00838", "submitter": "Bo Ni", "authors": "Bo Ni, Zhichun Guo, Jianing Li, Meng Jiang", "title": "Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 00:44:59 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ni", "Bo", ""], ["Guo", "Zhichun", ""], ["Li", "Jianing", ""], ["Jiang", "Meng", ""]]}, {"id": "2002.00839", "submitter": "Xiao Guo", "authors": "Hai Zhang and Xiao Guo and Xiangyu Chang", "title": "Randomized Spectral Clustering in Large-Scale Stochastic Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering has been one of the widely used methods for community\ndetection in networks. However, large-scale networks bring computational\nchallenge to it. In this paper, we study spectral clustering using randomized\nsketching algorithms from a statistical perspective, where we typically assume\nthe network data are generated from a stochastic block model. To do this, we\nfirst use the recent developed sketching algorithms to derive two randomized\nspectral clustering algorithms, namely, the random projection-based and the\nrandom sampling-based spectral clustering. Then we study the theoretical bounds\nof the resulting algorithms in terms of the approximation error for the\npopulation adjacency matrix, the misclustering error, and the estimation error\nfor the link probability matrix. It turns out that, under mild conditions, the\nrandomized spectral clustering algorithms perform similarly to the original\none. We also conduct numerical experiments to support the theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:15:25 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:59:32 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Hai", ""], ["Guo", "Xiao", ""], ["Chang", "Xiangyu", ""]]}, {"id": "2002.00841", "submitter": "Carl Yang", "authors": "Carl Yang, Mengxiong Liu, Frank He, Jian Peng, Jiawei Han", "title": "cube2net: Efficient Query-Specific Network Construction with Data Cube\n  Organization", "comments": "Full paper of the extended abstract published in ICDMW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are widely used to model objects with interactions and have enabled\nvarious downstream applications. However, in the real world, network mining is\noften done on particular query sets of objects, which does not require the\nconstruction and computation of networks including all objects in the datasets.\nIn this work, for the first time, we propose to address the problem of\nquery-specific network construction, to break the efficiency bottlenecks of\nexisting network mining algorithms and facilitate various downstream tasks. To\ndeal with real-world massive networks with complex attributes, we propose to\nleverage the well-developed data cube technology to organize network objects\nw.r.t. their essential attributes. An efficient reinforcement learning\nalgorithm is then developed to automatically explore the data cube structures\nand construct the optimal query-specific networks. With extensive experiments\nof two classic network mining tasks on different real-world large datasets, we\nshow that our proposed cube2net pipeline is general, and much more effective\nand efficient in query-specific network construction, compared with other\nmethods without the leverage of data cube or reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:53:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yang", "Carl", ""], ["Liu", "Mengxiong", ""], ["He", "Frank", ""], ["Peng", "Jian", ""], ["Han", "Jiawei", ""]]}, {"id": "2002.00843", "submitter": "Fran\\c{c}ois Th\\'eberge", "authors": "Bogumi{\\l} Kami\\'nski and Pawe{\\l} Pra{\\l}at and Fran\\c{c}ois\n  Th\\'eberge", "title": "Artificial Benchmark for Community Detection (ABCD): Fast Random Graph\n  Model with Community Structure", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": "10.1017/nws.2020.45", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current complex networks that are of interest to practitioners\npossess a certain community structure that plays an important role in\nunderstanding the properties of these networks. Moreover, many machine learning\nalgorithms and tools that are developed for complex networks try to take\nadvantage of the existence of communities to improve their performance or\nspeed. As a result, there are many competing algorithms for detecting\ncommunities in large networks. Unfortunately, these algorithms are often quite\nsensitive and so they cannot be fine-tuned for a given, but a constantly\nchanging, real-world network at hand. It is therefore important to test these\nalgorithms for various scenarios that can only be done using synthetic graphs\nthat have built-in community structure, power-law degree distribution, and\nother typical properties observed in complex networks. The standard and\nextensively used method for generating artificial networks is the LFR graph\ngenerator. Unfortunately, this model has some scalability limitations and it is\nchallenging to analyze it theoretically. Finally, the mixing parameter $\\mu$,\nthe main parameter of the model guiding the strength of the communities, has a\nnon-obvious interpretation and so can lead to unnaturally-defined networks. In\nthis paper, we provide an alternative random graph model with community\nstructure and power-law distribution for both degrees and community sizes, the\nArtificial Benchmark for Community Detection (ABCD). We show that the new model\nsolves the three issues identified above and more. The conclusion is that these\nmodels produce comparable graphs but ABCD is fast, simple, and can be easily\ntuned to allow the user to make a smooth transition between the two extremes:\npure (independent) communities and random graph with no community structure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:20:27 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kami\u0144ski", "Bogumi\u0142", ""], ["Pra\u0142at", "Pawe\u0142", ""], ["Th\u00e9berge", "Fran\u00e7ois", ""]]}, {"id": "2002.00844", "submitter": "Peijie Sun", "authors": "Le Wu, Junwei Li, Peijie Sun, Richang Hong, Yong Ge, Meng Wang", "title": "DiffNet++: A Neural Influence and Interest Diffusion Network for Social\n  Recommendation", "comments": "This paper has been accepted by IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social recommendation has emerged to leverage social connections among users\nfor predicting users' unknown preferences, which could alleviate the data\nsparsity issue in collaborative filtering based recommendation. Early\napproaches relied on utilizing each user's first-order social neighbors'\ninterests for better user modeling and failed to model the social influence\ndiffusion process from the global social network structure. Recently, we\npropose a preliminary work of a neural influence diffusion network (i.e.,\nDiffNet) for social recommendation (Diffnet), which models the recursive social\ndiffusion process to capture the higher-order relationships for each user.\nHowever, we argue that, as users play a central role in both user-user social\nnetwork and user-item interest network, only modeling the influence diffusion\nprocess in the social network would neglect the users' latent collaborative\ninterests in the user-item interest network. In this paper, we propose\nDiffNet++, an improved algorithm of DiffNet that models the neural influence\ndiffusion and interest diffusion in a unified framework. By reformulating the\nsocial recommendation as a heterogeneous graph with social network and interest\nnetwork as input, DiffNet++ advances DiffNet by injecting these two network\ninformation for user embedding learning at the same time. This is achieved by\niteratively aggregating each user's embedding from three aspects: the user's\nprevious embedding, the influence aggregation of social neighbors from the\nsocial network, and the interest aggregation of item neighbors from the\nuser-item interest network. Furthermore, we design a multi-level attention\nnetwork that learns how to attentively aggregate user embeddings from these\nthree aspects. Finally, extensive experimental results on two real-world\ndatasets clearly show the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:45:34 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 22:55:40 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 22:20:14 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 09:34:56 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wu", "Le", ""], ["Li", "Junwei", ""], ["Sun", "Peijie", ""], ["Hong", "Richang", ""], ["Ge", "Yong", ""], ["Wang", "Meng", ""]]}, {"id": "2002.00846", "submitter": "Samantha Ajovalasit", "authors": "Samantha Ajovalasit (1), Veronica Dorgali (2), Angelo Mazza (1),\n  Alberto D'Onofrio (3), Piero Manfredi (4) ((1) University of Messina, (2)\n  University of Florence, (3) University of Strathclyde, (4) University of\n  Pisa)", "title": "Evidence of disorientation towards immunization on online social media\n  after contrasting political communication on vaccines. Results from an\n  analysis of Twitter data in Italy", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. In Italy, in recent years, vaccination coverage for key\nimmunizations as MMR has been declining to worryingly low levels. In 2017, the\nItalian Gov't expanded the number of mandatory immunizations introducing\npenalties to unvaccinated children's families. During the 2018 general\nelections campaign, immunization policy entered the political debate with the\nGov't in charge blaming oppositions for fuelling vaccine scepticism. A new\nGov't established in 2018 temporarily relaxed penalties. Objectives and\nMethods. Using a sentiment analysis on tweets posted in Italian during 2018, we\naimed to: (i) characterize the temporal flow of vaccines communication on\nTwitter (ii) evaluate the polarity of vaccination opinions and usefulness of\nTwitter data to estimate vaccination parameters, and (iii) investigate whether\nthe contrasting announcements at the highest political level might have\noriginated disorientation amongst the Italian public. Results. Vaccine-relevant\ntweeters interactions peaked in response to main political events. Out of\nretained tweets, 70.0% resulted favourable to vaccination, 16.5% unfavourable,\nand 13.6% undecided, respectively. The smoothed time series of polarity\nproportions exhibit frequent large changes in the favourable proportion,\nenhanced by an up and down trend synchronized with the switch between gov't\nsuggesting evidence of disorientation among the public. Conclusion. The\nreported evidence of disorientation documents that critical immunization\ntopics, should never be used for political consensus. This is especially true\ngiven the increasing role of online social media as information source, which\nmight yield to social pressures eventually harmful for vaccine uptake, and is\nworsened by the lack of institutional presence on Twitter, calling for efforts\nto contrast misinformation and the ensuing spread of hesitancy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 11:03:18 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 12:29:37 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 16:30:12 GMT"}, {"version": "v4", "created": "Sat, 28 Nov 2020 20:57:14 GMT"}, {"version": "v5", "created": "Sun, 4 Apr 2021 22:02:29 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ajovalasit", "Samantha", ""], ["Dorgali", "Veronica", ""], ["Mazza", "Angelo", ""], ["D'Onofrio", "Alberto", ""], ["Manfredi", "Piero", ""]]}, {"id": "2002.00850", "submitter": "Aron Szanto", "authors": "Nir Rosenfeld, Aron Szanto, David C. Parkes", "title": "A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion\n  Pattern Alone", "comments": "Published at The Web Conference (WWW) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380180", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work in the domain of misinformation detection has leveraged rich\nsignals in the text and user identities associated with content on social\nmedia. But text can be strategically manipulated and accounts reopened under\ndifferent aliases, suggesting that these approaches are inherently brittle. In\nthis work, we investigate an alternative modality that is naturally robust: the\npattern in which information propagates. Can the veracity of an unverified\nrumor spreading online be discerned solely on the basis of its pattern of\ndiffusion through the social network?\n  Using graph kernels to extract complex topological information from Twitter\ncascade structures, we train accurate predictive models that are blind to\nlanguage, user identities, and time, demonstrating for the first time that such\n\"sanitized\" diffusion patterns are highly informative of veracity. Our results\nindicate that, with proper aggregation, the collective sharing pattern of the\ncrowd may reveal powerful signals of rumor truth or falsehood, even in the\nearly stages of propagation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:56:03 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:30:49 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Rosenfeld", "Nir", ""], ["Szanto", "Aron", ""], ["Parkes", "David C.", ""]]}, {"id": "2002.00852", "submitter": "Quentin Paris", "authors": "Quentin Paris", "title": "The exponentially weighted average forecaster in geodesic spaces of\n  non-positive curvature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.GT cs.LG math.MG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of prediction with expert advice for\noutcomes in a geodesic space with non-positive curvature in the sense of\nAlexandrov. Via geometric considerations, and in particular the notion of\nbarycenters, we extend to this setting the definition and analysis of the\nclassical exponentially weighted average forecaster. We also adapt the\nprinciple of online to batch conversion to this setting. We shortly discuss the\napplication of these results in the context of aggregation and for the problem\nof barycenter estimation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:59:42 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Paris", "Quentin", ""]]}, {"id": "2002.00865", "submitter": "Kalliopi Basioti", "authors": "Kalliopi Basioti and George V. Moustakides", "title": "Designing GANs: A Likelihood Ratio Approach", "comments": "Accepted to \"The Joint International Conference on Neural Networks\n  (IJCNN 2021)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the design of generative networks. The training of these\nmathematical structures is mostly performed with the help of adversarial\n(min-max) optimization problems. We propose a simple methodology for\nconstructing such problems assuring, at the same time, consistency of the\ncorresponding solution. We give characteristic examples developed by our\nmethod, some of which can be recognized from other applications, and some are\nintroduced here for the first time. We present a new metric, the likelihood\nratio, that can be employed online to examine the convergence and stability\nduring the training of different Generative Adversarial Networks (GANs).\nFinally, we compare various possibilities by applying them to well-known\ndatasets using neural networks of different configurations and sizes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:19:08 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 02:06:22 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:50:33 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Basioti", "Kalliopi", ""], ["Moustakides", "George V.", ""]]}, {"id": "2002.00874", "submitter": "Zaiwei Chen", "authors": "Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, and Karthikeyan\n  Shanmugam", "title": "Finite-Sample Analysis of Stochastic Approximation Using Smooth Convex\n  Envelopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic Approximation (SA) is a popular approach for solving fixed-point\nequations where the information is corrupted by noise. In this paper, we\nconsider an SA involving a contraction mapping with respect to an arbitrary\nnorm, and show its finite-sample error bounds while using different stepsizes.\nThe idea is to construct a smooth Lyapunov function using the generalized\nMoreau envelope, and show that the iterates of SA have negative drift with\nrespect to that Lyapunov function. Our result is applicable in Reinforcement\nLearning (RL). In particular, we use it to establish the first-known\nconvergence rate of the V-trace algorithm for off-policy TD-learning. Moreover,\nwe also use it to study TD-learning in the on-policy setting, and recover the\nexisting state-of-the-art results for $Q$-learning. Importantly, our\nconstruction results in only a logarithmic dependence of the convergence bound\non the size of the state-space.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:42:01 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 14:31:15 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 02:01:51 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 20:35:15 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 20:14:34 GMT"}, {"version": "v6", "created": "Wed, 30 Jun 2021 13:09:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Chen", "Zaiwei", ""], ["Maguluri", "Siva Theja", ""], ["Shakkottai", "Sanjay", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "2002.00876", "submitter": "Alexander M. Rush", "authors": "Alexander M. Rush", "title": "Torch-Struct: Deep Structured Prediction Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on structured prediction for NLP describes a rich collection\nof distributions and algorithms over sequences, segmentations, alignments, and\ntrees; however, these algorithms are difficult to utilize in deep learning\nframeworks. We introduce Torch-Struct, a library for structured prediction\ndesigned to take advantage of and integrate with vectorized,\nauto-differentiation based frameworks. Torch-Struct includes a broad collection\nof probabilistic structures accessed through a simple and flexible\ndistribution-based API that connects to any deep learning model. The library\nutilizes batched, vectorized operations and exploits auto-differentiation to\nproduce readable, fast, and testable code. Internally, we also include a number\nof general-purpose optimizations to provide cross-algorithm efficiency.\nExperiments show significant performance gains over fast baselines and\ncase-studies demonstrate the benefits of the library. Torch-Struct is available\nat https://github.com/harvardnlp/pytorch-struct.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:43:02 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Rush", "Alexander M.", ""]]}, {"id": "2002.00897", "submitter": "Hossein Pourmeidani", "authors": "Paul Wood, Hossein Pourmeidani, and Ronald F. DeMara", "title": "Modular Simulation Framework for Process Variation Analysis of\n  MRAM-based Deep Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic Random-Access Memory (MRAM) based p-bit neuromorphic computing\ndevices are garnering increasing interest as a means to compactly and\nefficiently realize machine learning operations in Restricted Boltzmann\nMachines (RBMs). When embedded within an RBM resistive crossbar array, the\np-bit based neuron realizes a tunable sigmoidal activation function. Since the\nstochasticity of activation is dependent on the energy barrier of the MRAM\ndevice, it is essential to assess the impact of process variation on the\nvoltage-dependent behavior of the sigmoid function. Other influential\nperformance factors arise from varying energy barriers on power consumption\nrequiring a simulation environment to facilitate the multi-objective\noptimization of device and network parameters. Herein, transportable Python\nscripts are developed to analyze the output variation under changes in device\ndimensions on the accuracy of machine learning applications. Evaluation with\nRBM circuits using the MNIST dataset reveal impacts and limits for processing\nvariation of device fabrication in terms of the resulting energy vs. accuracy\ntradeoffs, and the resulting simulation framework is available via a Creative\nCommons license.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:20:21 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wood", "Paul", ""], ["Pourmeidani", "Hossein", ""], ["DeMara", "Ronald F.", ""]]}, {"id": "2002.00901", "submitter": "Zheng Yu", "authors": "Zheng Yu, Xuhui Fan, Marcin Pietrasik, Marek Reformat", "title": "Fragmentation Coagulation Based Mixed Membership Stochastic Blockmodel", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mixed-Membership Stochastic Blockmodel~(MMSB) is proposed as one of the\nstate-of-the-art Bayesian relational methods suitable for learning the complex\nhidden structure underlying the network data. However, the current formulation\nof MMSB suffers from the following two issues: (1), the prior information~(e.g.\nentities' community structural information) can not be well embedded in the\nmodelling; (2), community evolution can not be well described in the\nliterature. Therefore, we propose a non-parametric fragmentation coagulation\nbased Mixed Membership Stochastic Blockmodel (fcMMSB). Our model performs\nentity-based clustering to capture the community information for entities and\nlinkage-based clustering to derive the group information for links\nsimultaneously. Besides, the proposed model infers the network structure and\nmodels community evolution, manifested by appearances and disappearances of\ncommunities, using the discrete fragmentation coagulation process (DFCP). By\nintegrating the community structure with the group compatibility matrix we\nderive a generalized version of MMSB. An efficient Gibbs sampling scheme with\nPolya Gamma (PG) approach is implemented for posterior inference. We validate\nour model on synthetic and real world data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:02:23 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yu", "Zheng", ""], ["Fan", "Xuhui", ""], ["Pietrasik", "Marcin", ""], ["Reformat", "Marek", ""]]}, {"id": "2002.00909", "submitter": "Mikail Yayla", "authors": "Sebastian Buschj\\\"ager, Jian-Jia Chen, Kuan-Hsun Chen, Mario G\\\"unzel,\n  Christian Hakert, Katharina Morik, Rodion Novkin, Lukas Pfahler, Mikail Yayla", "title": "Towards Explainable Bit Error Tolerance of Resistive RAM-Based Binarized\n  Neural Networks", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-volatile memory, such as resistive RAM (RRAM), is an emerging\nenergy-efficient storage, especially for low-power machine learning models on\nthe edge. It is reported, however, that the bit error rate of RRAMs can be up\nto 3.3% in the ultra low-power setting, which might be crucial for many use\ncases. Binary neural networks (BNNs), a resource efficient variant of neural\nnetworks (NNs), can tolerate a certain percentage of errors without a loss in\naccuracy and demand lower resources in computation and storage. The bit error\ntolerance (BET) in BNNs can be achieved by flipping the weight signs during\ntraining, as proposed by Hirtzlin et al., but their method has a significant\ndrawback, especially for fully connected neural networks (FCNN): The FCNNs\noverfit to the error rate used in training, which leads to low accuracy under\nlower error rates. In addition, the underlying principles of BET are not\ninvestigated. In this work, we improve the training for BET of BNNs and aim to\nexplain this property. We propose straight-through gradient approximation to\nimprove the weight-sign-flip training, by which BNNs adapt less to the bit\nerror rates. To explain the achieved robustness, we define a metric that aims\nto measure BET without fault injection. We evaluate the metric and find that it\ncorrelates with accuracy over error rate for all FCNNs tested. Finally, we\nexplore the influence of a novel regularizer that optimizes with respect to\nthis metric, with the aim of providing a configurable trade-off in accuracy and\nBET.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:38:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Buschj\u00e4ger", "Sebastian", ""], ["Chen", "Jian-Jia", ""], ["Chen", "Kuan-Hsun", ""], ["G\u00fcnzel", "Mario", ""], ["Hakert", "Christian", ""], ["Morik", "Katharina", ""], ["Novkin", "Rodion", ""], ["Pfahler", "Lukas", ""], ["Yayla", "Mikail", ""]]}, {"id": "2002.00915", "submitter": "Mathieu Barr\\'e", "authors": "Mathieu Barr\\'e, Adrien Taylor, Alexandre d'Aspremont", "title": "Complexity Guarantees for Polyak Steps with Momentum", "comments": "Accepted to COLT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In smooth strongly convex optimization, knowledge of the strong convexity\nparameter is critical for obtaining simple methods with accelerated rates. In\nthis work, we study a class of methods, based on Polyak steps, where this\nknowledge is substituted by that of the optimal value, $f_*$. We first show\nslightly improved convergence bounds than previously known for the classical\ncase of simple gradient descent with Polyak steps, we then derive an\naccelerated gradient method with Polyak steps and momentum, along with\nconvergence guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:50:28 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 15:31:22 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Barr\u00e9", "Mathieu", ""], ["Taylor", "Adrien", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "2002.00937", "submitter": "Alexandre Sablayrolles", "authors": "Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Herv\\'e\n  J\\'egou", "title": "Radioactive data: tracing through training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to detect whether a particular image dataset has been used to train a\nmodel. We propose a new technique, \\emph{radioactive data}, that makes\nimperceptible changes to this dataset such that any model trained on it will\nbear an identifiable mark. The mark is robust to strong variations such as\ndifferent architectures or optimization methods. Given a trained model, our\ntechnique detects the use of radioactive data and provides a level of\nconfidence (p-value). Our experiments on large-scale benchmarks (Imagenet),\nusing standard architectures (Resnet-18, VGG-16, Densenet-121) and training\nprocedures, show that we can detect usage of radioactive data with high\nconfidence (p<10^-4) even when only 1% of the data used to trained our model is\nradioactive. Our method is robust to data augmentation and the stochasticity of\ndeep network optimization. As a result, it offers a much higher signal-to-noise\nratio than data poisoning and backdoor methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:41:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Sablayrolles", "Alexandre", ""], ["Douze", "Matthijs", ""], ["Schmid", "Cordelia", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "2002.00941", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Sampada Deglurkar, Anca\n  D. Dragan", "title": "Quantifying Hypothesis Space Misspecification in Learning from\n  Human-Robot Demonstrations and Physical Corrections", "comments": "20 pages. 12 figures, 1 table. IEEE Transactions on Robotics, 2020", "journal-ref": null, "doi": "10.1109/TRO.2020.2971415", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human input has enabled autonomous systems to improve their capabilities and\nachieve complex behaviors that are otherwise challenging to generate\nautomatically. Recent work focuses on how robots can use such input - like\ndemonstrations or corrections - to learn intended objectives. These techniques\nassume that the human's desired objective already exists within the robot's\nhypothesis space. In reality, this assumption is often inaccurate: there will\nalways be situations where the person might care about aspects of the task that\nthe robot does not know about. Without this knowledge, the robot cannot infer\nthe correct objective. Hence, when the robot's hypothesis space is\nmisspecified, even methods that keep track of uncertainty over the objective\nfail because they reason about which hypothesis might be correct, and not\nwhether any of the hypotheses are correct. In this paper, we posit that the\nrobot should reason explicitly about how well it can explain human inputs given\nits hypothesis space and use that situational confidence to inform how it\nshould incorporate human input. We demonstrate our method on a 7\ndegree-of-freedom robot manipulator in learning from two important types of\nhuman input: demonstrations of manipulation tasks, and physical corrections\nduring the robot's task execution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:59:23 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 23:59:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bobu", "Andreea", ""], ["Bajcsy", "Andrea", ""], ["Fisac", "Jaime F.", ""], ["Deglurkar", "Sampada", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2002.00949", "submitter": "Bart Baesens", "authors": "Tine Van Calster, Filip Van den Bossche, Bart Baesens, Wilfried\n  Lemahieu", "title": "Profit-oriented sales forecasting: a comparison of forecasting\n  techniques from a business perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing the technique that is the best at forecasting your data, is a\nproblem that arises in any forecasting application. Decades of research have\nresulted into an enormous amount of forecasting methods that stem from\nstatistics, econometrics and machine learning (ML), which leads to a very\ndifficult and elaborate choice to make in any forecasting exercise. This paper\naims to facilitate this process for high-level tactical sales forecasts by\ncomparing a large array of techniques for 35 times series that consist of both\nindustry data from the Coca-Cola Company and publicly available datasets.\nHowever, instead of solely focusing on the accuracy of the resulting forecasts,\nthis paper introduces a novel and completely automated profit-driven approach\nthat takes into account the expected profit that a technique can create during\nboth the model building and evaluation process. The expected profit function\nthat is used for this purpose, is easy to understand and adaptable to any\nsituation by combining forecasting accuracy with business expertise.\nFurthermore, we examine the added value of ML techniques, the inclusion of\nexternal factors and the use of seasonal models in order to ascertain which\ntype of model works best in tactical sales forecasting. Our findings show that\nsimple seasonal time series models consistently outperform other methodologies\nand that the profit-driven approach can lead to selecting a different\nforecasting model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:50:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Van Calster", "Tine", ""], ["Bossche", "Filip Van den", ""], ["Baesens", "Bart", ""], ["Lemahieu", "Wilfried", ""]]}, {"id": "2002.00952", "submitter": "Maria Ines Meyer", "authors": "Mattias Billast, Maria Ines Meyer, Diana M. Sima and David Robben", "title": "Improved inter-scanner MS lesion segmentation by adversarial training on\n  longitudinal data", "comments": "Added link to final authenticated publication\n  (https://doi.org/10.1007/978-3-030-46640-4_10)", "journal-ref": "Crimi A., Bakas S. (eds) Brainlesion: Glioma, Multiple Sclerosis,\n  Stroke and Traumatic Brain Injuries. BrainLes 2019. Lecture Notes in Computer\n  Science, vol 11992. Springer, Cham", "doi": "10.1007/978-3-030-46640-4_10", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of white matter lesion progression is an important biomarker\nin the follow-up of MS patients and plays a crucial role when deciding the\ncourse of treatment. Current automated lesion segmentation algorithms are\nsusceptible to variability in image characteristics related to MRI scanner or\nprotocol differences. We propose a model that improves the consistency of MS\nlesion segmentations in inter-scanner studies. First, we train a CNN base model\nto approximate the performance of icobrain, an FDA-approved clinically\navailable lesion segmentation software. A discriminator model is then trained\nto predict if two lesion segmentations are based on scans acquired using the\nsame scanner type or not, achieving a 78% accuracy in this task. Finally, the\nbase model and the discriminator are trained adversarially on multi-scanner\nlongitudinal data to improve the inter-scanner consistency of the base model.\nThe performance of the models is evaluated on an unseen dataset containing\nmanual delineations. The inter-scanner variability is evaluated on test-retest\ndata, where the adversarial network produces improved results over the base\nmodel and the FDA-approved solution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:56:05 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 11:11:26 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Billast", "Mattias", ""], ["Meyer", "Maria Ines", ""], ["Sima", "Diana M.", ""], ["Robben", "David", ""]]}, {"id": "2002.00995", "submitter": "Soham Dan", "authors": "Soham Dan, Han Bao, Masashi Sugiyama", "title": "Learning from Noisy Similar and Dissimilar Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of machine learning for classification, it becomes\nincreasingly important to be able to use weaker kinds of supervision for tasks\nin which it is hard to obtain standard labeled data. One such kind of\nsupervision is provided pairwise---in the form of Similar (S) pairs (if two\nexamples belong to the same class) and Dissimilar (D) pairs (if two examples\nbelong to different classes). This kind of supervision is realistic in\nprivacy-sensitive domains. Although this problem has been looked at recently,\nit is unclear how to learn from such supervision under label noise, which is\nvery common when the supervision is crowd-sourced. In this paper, we close this\ngap and demonstrate how to learn a classifier from noisy S and D labeled data.\nWe perform a detailed investigation of this problem under two realistic noise\nmodels and propose two algorithms to learn from noisy S-D data. We also show\nimportant connections between learning from such pairwise supervision data and\nlearning from ordinary class-labeled data. Finally, we perform experiments on\nsynthetic and real world datasets and show our noise-informed algorithms\noutperform noise-blind baselines in learning from noisy pairwise data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:59:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Dan", "Soham", ""], ["Bao", "Han", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.01020", "submitter": "Haotian Wang", "authors": "Haotian Wang, Min Xian, Aleksandar Vakanski", "title": "Bending Loss Regularized Network for Nuclei Segmentation in\n  Histopathology Images", "comments": "4 pages, 5 figures, 2020 IEEE 17th International Symposium on\n  Biomedical Imaging (ISBI), accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating overlapped nuclei is a major challenge in histopathology image\nanalysis. Recently published approaches have achieved promising overall\nperformance on public datasets; however, their performance in segmenting\noverlapped nuclei are limited. To address the issue, we propose the bending\nloss regularized network for nuclei segmentation. The proposed bending loss\ndefines high penalties to contour points with large curvatures, and applies\nsmall penalties to contour points with small curvature. Minimizing the bending\nloss can avoid generating contours that encompass multiple nuclei. The proposed\napproach is validated on the MoNuSeg dataset using five quantitative metrics.\nIt outperforms six state-of-the-art approaches on the following metrics:\nAggregate Jaccard Index, Dice, Recognition Quality, and Pan-optic Quality.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 21:20:50 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wang", "Haotian", ""], ["Xian", "Min", ""], ["Vakanski", "Aleksandar", ""]]}, {"id": "2002.01029", "submitter": "Olivier Pannekoucke", "authors": "Olivier Pannekoucke and Ronan Fablet", "title": "PDE-NetGen 1.0: from symbolic PDE representations of physical processes\n  to trainable neural network representations", "comments": null, "journal-ref": null, "doi": "10.5194/gmd-13-3373-2020", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bridging physics and deep learning is a topical challenge. While deep\nlearning frameworks open avenues in physical science, the design of\nphysically-consistent deep neural network architectures is an open issue. In\nthe spirit of physics-informed NNs, PDE-NetGen package provides new means to\nautomatically translate physical equations, given as PDEs, into neural network\narchitectures. PDE-NetGen combines symbolic calculus and a neural network\ngenerator. The later exploits NN-based implementations of PDE solvers using\nKeras. With some knowledge of a problem, PDE-NetGen is a plug-and-play tool to\ngenerate physics-informed NN architectures. They provide\ncomputationally-efficient yet compact representations to address a variety of\nissues, including among others adjoint derivation, model calibration,\nforecasting, data assimilation as well as uncertainty quantification. As an\nillustration, the workflow is first presented for the 2D diffusion equation,\nthen applied to the data-driven and physics-informed identification of\nuncertainty dynamics for the Burgers equation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:11:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Pannekoucke", "Olivier", ""], ["Fablet", "Ronan", ""]]}, {"id": "2002.01044", "submitter": "Ardhendu Shekhar Tripathy", "authors": "Matthew L. Malloy, Ardhendu Tripathy, Robert D. Nowak", "title": "Optimal Confidence Regions for the Multinomial Parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Construction of tight confidence regions and intervals is central to\nstatistical inference and decision making. This paper develops new theory\nshowing minimum average volume confidence regions for categorical data. More\nprecisely, consider an empirical distribution $\\widehat{\\boldsymbol{p}}$\ngenerated from $n$ iid realizations of a random variable that takes one of $k$\npossible values according to an unknown distribution $\\boldsymbol{p}$. This is\nanalogous to a single draw from a multinomial distribution. A confidence region\nis a subset of the probability simplex that depends on\n$\\widehat{\\boldsymbol{p}}$ and contains the unknown $\\boldsymbol{p}$ with a\nspecified confidence. This paper shows how one can construct minimum average\nvolume confidence regions, answering a long standing question. We also show the\noptimality of the regions directly translates to optimal confidence intervals\nof linear functionals such as the mean, implying sample complexity and regret\nimprovements for adaptive machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:00:16 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:58:14 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Malloy", "Matthew L.", ""], ["Tripathy", "Ardhendu", ""], ["Nowak", "Robert D.", ""]]}, {"id": "2002.01059", "submitter": "Albert Zhan", "authors": "Albert Zhan, Stas Tiomkin, Pieter Abbeel", "title": "Preventing Imitation Learning with Adversarial Policy Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning can reproduce policies by observing experts, which poses a\nproblem regarding policy privacy. Policies, such as human, or policies on\ndeployed robots, can all be cloned without consent from the owners. How can we\nprotect against external observers cloning our proprietary policies? To answer\nthis question we introduce a new reinforcement learning framework, where we\ntrain an ensemble of near-optimal policies, whose demonstrations are guaranteed\nto be useless for an external observer. We formulate this idea by a constrained\noptimization problem, where the objective is to improve proprietary policies,\nand at the same time deteriorate the virtual policy of an eventual external\nobserver. We design a tractable algorithm to solve this new optimization\nproblem by modifying the standard policy gradient algorithm. Our formulation\ncan be interpreted in lenses of confidentiality and adversarial behaviour,\nwhich enables a broader perspective of this work. We demonstrate the existence\nof \"non-clonable\" ensembles, providing a solution to the above optimization\nproblem, which is calculated by our modified policy gradient algorithm. To our\nknowledge, this is the first work regarding the protection of policies in\nReinforcement Learning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:57:16 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 23:15:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhan", "Albert", ""], ["Tiomkin", "Stas", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2002.01060", "submitter": "Chase Dowling", "authors": "Chase P. Dowling and Baosen Zhang", "title": "Transfer Learning for HVAC System Fault Detection", "comments": "7 pages, 4 figures, accepted to American Control Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faults in HVAC systems degrade thermal comfort and energy efficiency in\nbuildings and have received significant attention from the research community,\nwith data driven methods gaining in popularity. Yet the lack of labeled data,\nsuch as normal versus faulty operational status, has slowed the application of\nmachine learning to HVAC systems. In addition, for any particular building,\nthere may be an insufficient number of observed faults over a reasonable amount\nof time for training. To overcome these challenges, we present a transfer\nmethodology for a novel Bayesian classifier designed to distinguish between\nnormal operations and faulty operations. The key is to train this classifier on\na building with a large amount of sensor and fault data (for example, via\nsimulation or standard test data) then transfer the classifier to a new\nbuilding using a small amount of normal operations data from the new building.\nWe demonstrate a proof-of-concept for transferring a classifier between\narchitecturally similar buildings in different climates and show few samples\nare required to maintain classification precision and recall.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:06:48 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Dowling", "Chase P.", ""], ["Zhang", "Baosen", ""]]}, {"id": "2002.01066", "submitter": "Parth Kashyap Thaker", "authors": "Parth Thaker, Gautam Dasarathy, and Angelia Nedi\\'c", "title": "On the Sample Complexity and Optimization Landscape for Quadratic\n  Feasibility Problems", "comments": "21 pages", "journal-ref": null, "doi": "10.1109/ISIT44484.2020.9174368", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a complex vector $\\mathbf{x}\\in\n\\mathbb{C}^n$ from $m$ quadratic measurements $\\{\\langle A_i\\mathbf{x},\n\\mathbf{x}\\rangle\\}_{i=1}^m$. This problem, known as quadratic feasibility,\nencompasses the well known phase retrieval problem and has applications in a\nwide range of important areas including power system state estimation and x-ray\ncrystallography. In general, not only is the the quadratic feasibility problem\nNP-hard to solve, but it may in fact be unidentifiable. In this paper, we\nestablish conditions under which this problem becomes {identifiable}, and\nfurther prove isometry properties in the case when the matrices\n$\\{A_i\\}_{i=1}^m$ are Hermitian matrices sampled from a complex Gaussian\ndistribution. Moreover, we explore a nonconvex {optimization} formulation of\nthis problem, and establish salient features of the associated optimization\nlandscape that enables gradient algorithms with an arbitrary initialization to\nconverge to a \\emph{globally optimal} point with a high probability. Our\nresults also reveal sample complexity requirements for successfully identifying\na feasible solution in these contexts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:35:09 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 19:10:15 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Thaker", "Parth", ""], ["Dasarathy", "Gautam", ""], ["Nedi\u0107", "Angelia", ""]]}, {"id": "2002.01093", "submitter": "Abhinav Gupta", "authors": "Ryan Lowe, Abhinav Gupta, Jakob Foerster, Douwe Kiela, Joelle Pineau", "title": "On the interaction between supervision and self-play in emergent\n  communication", "comments": "The first two authors contributed equally. Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising approach for teaching artificial agents to use natural language\ninvolves using human-in-the-loop training. However, recent work suggests that\ncurrent machine learning methods are too data inefficient to be trained in this\nway from scratch. In this paper, we investigate the relationship between two\ncategories of learning signals with the ultimate goal of improving sample\nefficiency: imitating human language data via supervised learning, and\nmaximizing reward in a simulated multi-agent environment via self-play (as done\nin emergent communication), and introduce the term supervised self-play (S2P)\nfor algorithms using both of these signals. We find that first training agents\nvia supervised learning on human data followed by self-play outperforms the\nconverse, suggesting that it is not beneficial to emerge languages from\nscratch. We then empirically investigate various S2P schedules that begin with\nsupervised learning in two environments: a Lewis signaling game with symbolic\ninputs, and an image-based referential game with natural language descriptions.\nLastly, we introduce population based approaches to S2P, which further improves\nthe performance over single-agent methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:35:19 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:48:08 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lowe", "Ryan", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Kiela", "Douwe", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.01100", "submitter": "Marco Carmosino", "authors": "Mark Bun, Marco Leandro Carmosino, Jessica Sorrell", "title": "Efficient, Noise-Tolerant, and Private Learning via Boosting", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple framework for designing private boosting algorithms. We\ngive natural conditions under which these algorithms are differentially\nprivate, efficient, and noise-tolerant PAC learners. To demonstrate our\nframework, we use it to construct noise-tolerant and private PAC learners for\nlarge-margin halfspaces whose sample complexity does not depend on the\ndimension.\n  We give two sample complexity bounds for our large-margin halfspace learner.\nOne bound is based only on differential privacy, and uses this guarantee as an\nasset for ensuring generalization. This first bound illustrates a general\nmethodology for obtaining PAC learners from privacy, which may be of\nindependent interest. The second bound uses standard techniques from the theory\nof large-margin classification (the fat-shattering dimension) to match the best\nknown sample complexity for differentially private learning of large-margin\nhalfspaces, while additionally tolerating random label noise.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 03:16:37 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Bun", "Mark", ""], ["Carmosino", "Marco Leandro", ""], ["Sorrell", "Jessica", ""]]}, {"id": "2002.01113", "submitter": "Jun Li", "authors": "Jun Li, Li Fuxin, Sinisa Todorovic", "title": "Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley\n  Transform", "comments": "ICLR 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strictly enforcing orthonormality constraints on parameter matrices has been\nshown advantageous in deep learning. This amounts to Riemannian optimization on\nthe Stiefel manifold, which, however, is computationally expensive. To address\nthis challenge, we present two main contributions: (1) A new efficient\nretraction map based on an iterative Cayley transform for optimization updates,\nand (2) An implicit vector transport mechanism based on the combination of a\nprojection of the momentum and the Cayley transform on the Stiefel manifold. We\nspecify two new optimization algorithms: Cayley SGD with momentum, and Cayley\nADAM on the Stiefel manifold. Convergence of Cayley SGD is theoretically\nanalyzed. Our experiments for CNN training demonstrate that both algorithms:\n(a) Use less running time per iteration relative to existing approaches that\nenforce orthonormality of CNN parameters; and (b) Achieve faster convergence\nrates than the baseline SGD and ADAM algorithms without compromising the\nperformance of the CNN. Cayley SGD and Cayley ADAM are also shown to reduce the\ntraining time for optimizing the unitary transition matrices in RNNs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 04:01:51 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Li", "Jun", ""], ["Fuxin", "Li", ""], ["Todorovic", "Sinisa", ""]]}, {"id": "2002.01119", "submitter": "Wei Zhang", "authors": "Wei Zhang, Xiaodong Cui, Abdullah Kayi, Mingrui Liu, Ulrich Finkler,\n  Brian Kingsbury, George Saon, Youssef Mroueh, Alper Buyuktosunoglu, Payel\n  Das, David Kung, Michael Picheny", "title": "Improving Efficiency in Large-Scale Decentralized Distributed Training", "comments": null, "journal-ref": "45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP'2020) Oral", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized Parallel SGD (D-PSGD) and its asynchronous variant Asynchronous\nParallel SGD (AD-PSGD) is a family of distributed learning algorithms that have\nbeen demonstrated to perform well for large-scale deep learning tasks. One\ndrawback of (A)D-PSGD is that the spectral gap of the mixing matrix decreases\nwhen the number of learners in the system increases, which hampers convergence.\nIn this paper, we investigate techniques to accelerate (A)D-PSGD based training\nby improving the spectral gap while minimizing the communication cost. We\ndemonstrate the effectiveness of our proposed techniques by running experiments\non the 2000-hour Switchboard speech recognition task and the ImageNet computer\nvision task. On an IBM P9 supercomputer, our system is able to train an LSTM\nacoustic model in 2.28 hours with 7.5% WER on the Hub5-2000 Switchboard (SWB)\ntest set and 13.3% WER on the CallHome (CH) test set using 64 V100 GPUs and in\n1.98 hours with 7.7% WER on SWB and 13.3% WER on CH using 128 V100 GPUs, the\nfastest training time reported to date.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 04:29:09 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Kayi", "Abdullah", ""], ["Liu", "Mingrui", ""], ["Finkler", "Ulrich", ""], ["Kingsbury", "Brian", ""], ["Saon", "George", ""], ["Mroueh", "Youssef", ""], ["Buyuktosunoglu", "Alper", ""], ["Das", "Payel", ""], ["Kung", "David", ""], ["Picheny", "Michael", ""]]}, {"id": "2002.01129", "submitter": "Sareh Nabi", "authors": "Sareh Nabi, Houssam Nassif, Joseph Hong, Hamed Mamani, Guido Imbens", "title": "Bayesian Meta-Prior Learning Using Empirical Bayes", "comments": "Expanded discussions on applications and extended literature review\n  section. Forthcoming in the Management Science Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding domain knowledge to a learning system is known to improve results. In\nmulti-parameter Bayesian frameworks, such knowledge is incorporated as a prior.\nOn the other hand, various model parameters can have different learning rates\nin real-world problems, especially with skewed data. Two often-faced challenges\nin Operation Management and Management Science applications are the absence of\ninformative priors, and the inability to control parameter learning rates. In\nthis study, we propose a hierarchical Empirical Bayes approach that addresses\nboth challenges, and that can generalize to any Bayesian framework. Our method\nlearns empirical meta-priors from the data itself and uses them to decouple the\nlearning rates of first-order and second-order features (or any other given\nfeature grouping) in a Generalized Linear Model. As the first-order features\nare likely to have a more pronounced effect on the outcome, focusing on\nlearning first-order weights first is likely to improve performance and\nconvergence time. Our Empirical Bayes method clamps features in each group\ntogether and uses the deployed model's observed data to empirically compute a\nhierarchical prior in hindsight. We report theoretical results for the\nunbiasedness, strong consistency, and optimal frequentist cumulative regret\nproperties of our meta-prior variance estimator. We apply our method to a\nstandard supervised learning optimization problem, as well as an online\ncombinatorial optimization problem in a contextual bandit setting implemented\nin an Amazon production system. Both during simulations and live experiments,\nour method shows marked improvements, especially in cases of small traffic. Our\nfindings are promising, as optimizing over sparse data is often a challenge.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 05:08:17 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 23:00:22 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 21:18:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Nabi", "Sareh", ""], ["Nassif", "Houssam", ""], ["Hong", "Joseph", ""], ["Mamani", "Hamed", ""], ["Imbens", "Guido", ""]]}, {"id": "2002.01136", "submitter": "Tianyu Guo", "authors": "Tianyu Guo, Chang Xu, Jiajun Huang, Yunhe Wang, Boxin Shi, Chao Xu,\n  Dacheng Tao", "title": "On Positive-Unlabeled Classification in GAN", "comments": null, "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a positive and unlabeled classification problem for\nstandard GANs, which then leads to a novel technique to stabilize the training\nof the discriminator in GANs. Traditionally, real data are taken as positive\nwhile generated data are negative. This positive-negative classification\ncriterion was kept fixed all through the learning process of the discriminator\nwithout considering the gradually improved quality of generated data, even if\nthey could be more realistic than real data at times. In contrast, it is more\nreasonable to treat the generated data as unlabeled, which could be positive or\nnegative according to their quality. The discriminator is thus a classifier for\nthis positive and unlabeled classification problem, and we derive a new\nPositive-Unlabeled GAN (PUGAN). We theoretically discuss the global optimality\nthe proposed model will achieve and the equivalent optimization goal.\nEmpirically, we find that PUGAN can achieve comparable or even better\nperformance than those sophisticated discriminator stabilization methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 05:59:37 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Guo", "Tianyu", ""], ["Xu", "Chang", ""], ["Huang", "Jiajun", ""], ["Wang", "Yunhe", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Tao", "Dacheng", ""]]}, {"id": "2002.01169", "submitter": "Zhen Peng", "authors": "Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang\n  Xu, Junzhou Huang", "title": "Graph Representation Learning via Graphical Mutual Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The richness in the content of various information networks such as social\nnetworks and communication networks provides the unprecedented potential for\nlearning high-quality expressive representations without external supervision.\nThis paper investigates how to preserve and extract the abundant information\nfrom graph-structured data into embedding space in an unsupervised manner. To\nthis end, we propose a novel concept, Graphical Mutual Information (GMI), to\nmeasure the correlation between input graphs and high-level hidden\nrepresentations. GMI generalizes the idea of conventional mutual information\ncomputations from vector space to the graph domain where measuring mutual\ninformation from two aspects of node features and topological structure is\nindispensable. GMI exhibits several benefits: First, it is invariant to the\nisomorphic transformation of input graphs---an inevitable constraint in many\nexisting graph representation learning algorithms; Besides, it can be\nefficiently estimated and maximized by current mutual information estimation\nmethods such as MINE; Finally, our theoretical analysis confirms its\ncorrectness and rationality. With the aid of GMI, we develop an unsupervised\nlearning model trained by maximizing GMI between the input and output of a\ngraph neural encoder. Considerable experiments on transductive as well as\ninductive node classification and link prediction demonstrate that our method\noutperforms state-of-the-art unsupervised counterparts, and even sometimes\nexceeds the performance of supervised ones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 08:33:49 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Peng", "Zhen", ""], ["Huang", "Wenbing", ""], ["Luo", "Minnan", ""], ["Zheng", "Qinghua", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "2002.01171", "submitter": "Aung Aung Phyo Wai", "authors": "Aung Aung Phyo Wai, Yangsong Zhang, Heng Guo, Ying Chi, Lei Zhang,\n  Xian-Sheng Hua, Seong Whan Lee and Cuntai Guan", "title": "Towards a Fast Steady-State Visual Evoked Potentials (SSVEP)\n  Brain-Computer Interface (BCI)", "comments": "Further improvements or modifications required to algorithm design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady-state visual evoked potentials (SSVEP) brain-computer interface (BCI)\nprovides reliable responses leading to high accuracy and information\nthroughput. But achieving high accuracy typically requires a relatively long\ntime window of one second or more. Various methods were proposed to improve\nsub-second response accuracy through subject-specific training and calibration.\nSubstantial performance improvements were achieved with tedious calibration and\nsubject-specific training; resulting in the user's discomfort. So, we propose a\ntraining-free method by combining spatial-filtering and temporal alignment\n(CSTA) to recognize SSVEP responses in sub-second response time. CSTA exploits\nlinear correlation and non-linear similarity between steady-state responses and\nstimulus templates with complementary fusion to achieve desirable performance\nimprovements. We evaluated the performance of CSTA in terms of accuracy and\nInformation Transfer Rate (ITR) in comparison with both training-based and\ntraining-free methods using two SSVEP data-sets. We observed that CSTA achieves\nthe maximum mean accuracy of 97.43$\\pm$2.26 % and 85.71$\\pm$13.41 % with\nfour-class and forty-class SSVEP data-sets respectively in sub-second response\ntime in offline analysis. CSTA yields significantly higher mean performance\n(p<0.001) than the training-free method on both data-sets. Compared with\ntraining-based methods, CSTA shows 29.33$\\pm$19.65 % higher mean accuracy with\nstatistically significant differences in time window less than 0.5 s. In longer\ntime windows, CSTA exhibits either better or comparable performance though not\nstatistically significantly better than training-based methods. We show that\nthe proposed method brings advantages of subject-independent SSVEP\nclassification without requiring training while enabling high target\nrecognition performance in sub-second response time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 08:48:36 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 05:40:04 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wai", "Aung Aung Phyo", ""], ["Zhang", "Yangsong", ""], ["Guo", "Heng", ""], ["Chi", "Ying", ""], ["Zhang", "Lei", ""], ["Hua", "Xian-Sheng", ""], ["Lee", "Seong Whan", ""], ["Guan", "Cuntai", ""]]}, {"id": "2002.01180", "submitter": "Arun Pandey", "authors": "Arun Pandey, Joachim Schreurs, Johan A. K. Suykens", "title": "Robust Generative Restricted Kernel Machines using Weighted Conjugate\n  Feature Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in generative models has grown tremendously in the past decade.\nHowever, their training performance can be adversely affected by contamination,\nwhere outliers are encoded in the representation of the model. This results in\nthe generation of noisy data. In this paper, we introduce weighted conjugate\nfeature duality in the framework of Restricted Kernel Machines (RKMs). The RKM\nformulation allows for an easy integration of methods from classical robust\nstatistics. This formulation is used to fine-tune the latent space of\ngenerative RKMs using a weighting function based on the Minimum Covariance\nDeterminant, which is a highly robust estimator of multivariate location and\nscatter. Experiments show that the weighted RKM is capable of generating clean\nimages when contamination is present in the training data. We further show that\nthe robust method also preserves uncorrelated feature learning through\nqualitative and quantitative experiments on standard datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:23:25 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 17:53:39 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 14:35:30 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Pandey", "Arun", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2002.01182", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "Learning bounded subsets of $L_p$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning problems in which the underlying class is a bounded subset\nof $L_p$ and the target $Y$ belongs to $L_p$. Previously, minimax sample\ncomplexity estimates were known under such boundedness assumptions only when\n$p=\\infty$. We present a sharp sample complexity estimate that holds for any $p\n> 4$. It is based on a learning procedure that is suited for heavy-tailed\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:25:34 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "2002.01184", "submitter": "Junpeng Lao", "authors": "Junpeng Lao, Christopher Suter, Ian Langmore, Cyril Chimisov, Ashish\n  Saxena, Pavel Sountsov, Dave Moore, Rif A. Saurous, Matthew D. Hoffman, and\n  Joshua V. Dillon", "title": "tfp.mcmc: Modern Markov Chain Monte Carlo Tools Built for Modern\n  Hardware", "comments": "Based on extended abstract submitted to PROBPROG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.PL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Markov chain Monte Carlo (MCMC) is widely regarded as one of the most\nimportant algorithms of the 20th century. Its guarantees of asymptotic\nconvergence, stability, and estimator-variance bounds using only unnormalized\nprobability functions make it indispensable to probabilistic programming. In\nthis paper, we introduce the TensorFlow Probability MCMC toolkit, and discuss\nsome of the considerations that motivated its design.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:27:26 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lao", "Junpeng", ""], ["Suter", "Christopher", ""], ["Langmore", "Ian", ""], ["Chimisov", "Cyril", ""], ["Saxena", "Ashish", ""], ["Sountsov", "Pavel", ""], ["Moore", "Dave", ""], ["Saurous", "Rif A.", ""], ["Hoffman", "Matthew D.", ""], ["Dillon", "Joshua V.", ""]]}, {"id": "2002.01197", "submitter": "Etienne Boursier", "authors": "Etienne Boursier and Vianney Perchet", "title": "Selfish Robustness and Equilibria in Multi-Player Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cognitive radios, stochastic multi-player multi-armed bandits\ngained a lot of interest recently. In this class of problems, several players\nsimultaneously pull arms and encounter a collision - with 0 reward - if some of\nthem pull the same arm at the same time. While the cooperative case where\nplayers maximize the collective reward (obediently following some fixed\nprotocol) has been mostly considered, robustness to malicious players is a\ncrucial and challenging concern. Existing approaches consider only the case of\nadversarial jammers whose objective is to blindly minimize the collective\nreward. We shall consider instead the more natural class of selfish players\nwhose incentives are to maximize their individual rewards, potentially at the\nexpense of the social welfare. We provide the first algorithm robust to selfish\nplayers (a.k.a. Nash equilibrium) with a logarithmic regret, when the arm\nperformance is observed. When collisions are also observed, Grim Trigger type\nof strategies enable some implicit communication-based algorithms and we\nconstruct robust algorithms in two different settings: the homogeneous (with a\nregret comparable to the centralized optimal one) and heterogeneous cases (for\nan adapted and relevant notion of regret). We also provide impossibility\nresults when only the reward is observed or when arm means vary arbitrarily\namong players.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:50:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 08:02:43 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Boursier", "Etienne", ""], ["Perchet", "Vianney", ""]]}, {"id": "2002.01227", "submitter": "Xi Chen", "authors": "Xi Chen, Bo Kang, Jefrey Lijffijt and Tijl De Bie", "title": "ALPINE: Active Link Prediction using Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems can be formalized as predicting links in a partially\nobserved network. Examples include Facebook friendship suggestions,\nconsumer-product recommendations, and the identification of hidden interactions\nbetween actors in a crime network. Several link prediction algorithms, notably\nthose recently introduced using network embedding, are capable of doing this by\njust relying on the observed part of the network. Often, the link status of a\nnode pair can be queried, which can be used as additional information by the\nlink prediction algorithm. Unfortunately, such queries can be expensive or\ntime-consuming, mandating the careful consideration of which node pairs to\nquery. In this paper we estimate the improvement in link prediction accuracy\nafter querying any particular node pair, to use in an active learning setup.\nSpecifically, we propose ALPINE (Active Link Prediction usIng Network\nEmbedding), the first method to achieve this for link prediction based on\nnetwork embedding. To this end, we generalized the notion of V-optimality from\nexperimental design to this setting, as well as more basic active learning\nheuristics originally developed in standard classification settings. Empirical\nresults on real data show that ALPINE is scalable, and boosts link prediction\naccuracy with far fewer queries.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:09:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Chen", "Xi", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.01244", "submitter": "Othniel Konan", "authors": "Othniel J.E.Y. Konan, Amit Kumar Mishra, Stefan Lotz", "title": "Machine Learning Techniques to Detect and Characterise Whistler Radio\n  Waves", "comments": "20 pages, 13 tables, 26 figures, Preliminary work presented at the\n  Machine Learning in Heliophysics hosted in September 2019 in Amsterdam\n  (https://ml-helio.github.io/). Code can be found at\n  (https://github.com/Kojey/MSc-whistler-waves-detector)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lightning strokes create powerful electromagnetic pulses that routinely cause\nvery low frequency (VLF) waves to propagate across hemispheres along\ngeomagnetic field lines. VLF antenna receivers can be used to detect these\nwhistler waves generated by these lightning strokes. The particular\ntime/frequency dependence of the received whistler wave enables the estimation\nof electron density in the plasmasphere region of the magnetosphere. Therefore\nthe identification and characterisation of whistlers are important tasks to\nmonitor the plasmasphere in real-time and to build large databases of events to\nbe used for statistical studies. The current state of the art in detecting\nwhistler is the Automatic Whistler Detection (AWD) method developed by\nLichtenberger (2009). This method is based on image correlation in 2 dimensions\nand requires significant computing hardware situated at the VLF receiver\nantennas (e.g. in Antarctica). The aim of this work is to develop a machine\nlearning-based model capable of automatically detecting whistlers in the data\nprovided by the VLF receivers. The approach is to use a combination of image\nclassification and localisation on the spectrogram data generated by the VLF\nreceivers to identify and localise each whistler. The data at hand has around\n2300 events identified by AWD at SANAE and Marion and will be used as training,\nvalidation, and testing data. Three detector designs have been proposed. The\nfirst one using a similar method to AWD, the second using image classification\non regions of interest extracted from a spectrogram, and the last one using\nYOLO, the current state of the art in object detection. It has been shown that\nthese detectors can achieve a misdetection and false alarm of less than 15% on\nMarion's dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:05:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Konan", "Othniel J. E. Y.", ""], ["Mishra", "Amit Kumar", ""], ["Lotz", "Stefan", ""]]}, {"id": "2002.01245", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Morten Goodwin", "title": "A Regression Tsetlin Machine with Integer Weighted Clauses for Compact\n  Pattern Representation", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Regression Tsetlin Machine (RTM) addresses the lack of interpretability\nimpeding state-of-the-art nonlinear regression models. It does this by using\nconjunctive clauses in propositional logic to capture the underlying non-linear\nfrequent patterns in the data. These, in turn, are combined into a continuous\noutput through summation, akin to a linear regression function, however, with\nnon-linear components and unity weights. Although the RTM has solved non-linear\nregression problems with competitive accuracy, the resolution of the output is\nproportional to the number of clauses employed. This means that computation\ncost increases with resolution. To reduce this problem, we here introduce\ninteger weighted RTM clauses. Our integer weighted clause is a compact\nrepresentation of multiple clauses that capture the same sub-pattern-N\nrepeating clauses are turned into one, with an integer weight N. This reduces\ncomputation cost N times, and increases interpretability through a sparser\nrepresentation. We further introduce a novel learning scheme that allows us to\nsimultaneously learn both the clauses and their weights, taking advantage of\nso-called stochastic searching on the line. We evaluate the potential of the\ninteger weighted RTM empirically using six artificial datasets. The results\nshow that the integer weighted RTM is able to acquire on par or better accuracy\nusing significantly less computational resources compared to regular RTMs. We\nfurther show that integer weights yield improved accuracy over real-valued\nones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:06:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "2002.01256", "submitter": "Blerta Lindqvist", "authors": "Blerta Lindqvist, Rauf Izmailov", "title": "Minimax Defense against Gradient-based Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art adversarial attacks are aimed at neural network classifiers.\nBy default, neural networks use gradient descent to minimize their loss\nfunction. The gradient of a classifier's loss function is used by\ngradient-based adversarial attacks to generate adversarially perturbed images.\nWe pose the question whether another type of optimization could give neural\nnetwork classifiers an edge. Here, we introduce a novel approach that uses\nminimax optimization to foil gradient-based adversarial attacks. Our minimax\nclassifier is the discriminator of a generative adversarial network (GAN) that\nplays a minimax game with the GAN generator. In addition, our GAN generator\nprojects all points onto a manifold that is different from the original\nmanifold since the original manifold might be the cause of adversarial attacks.\nTo measure the performance of our minimax defense, we use adversarial attacks -\nCarlini Wagner (CW), DeepFool, Fast Gradient Sign Method (FGSM) - on three\ndatasets: MNIST, CIFAR-10 and German Traffic Sign (TRAFFIC). Against CW\nattacks, our minimax defense achieves 98.07% (MNIST-default 98.93%), 73.90%\n(CIFAR-10-default 83.14%) and 94.54% (TRAFFIC-default 96.97%). Against DeepFool\nattacks, our minimax defense achieves 98.87% (MNIST), 76.61% (CIFAR-10) and\n94.57% (TRAFFIC). Against FGSM attacks, we achieve 97.01% (MNIST), 76.79%\n(CIFAR-10) and 81.41% (TRAFFIC). Our Minimax adversarial approach presents a\nsignificant shift in defense strategy for neural network classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:33:13 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lindqvist", "Blerta", ""], ["Izmailov", "Rauf", ""]]}, {"id": "2002.01268", "submitter": "Alexey Naumov", "authors": "Maxim Kaledin, Eric Moulines, Alexey Naumov, Vladislav Tadic, Hoi-To\n  Wai", "title": "Finite Time Analysis of Linear Two-timescale Stochastic Approximation\n  with Markovian Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear two-timescale stochastic approximation (SA) scheme is an important\nclass of algorithms which has become popular in reinforcement learning (RL),\nparticularly for the policy evaluation problem. Recently, a number of works\nhave been devoted to establishing the finite time analysis of the scheme,\nespecially under the Markovian (non-i.i.d.) noise settings that are ubiquitous\nin practice. In this paper, we provide a finite-time analysis for linear two\ntimescale SA. Our bounds show that there is no discrepancy in the convergence\nrate between Markovian and martingale noise, only the constants are affected by\nthe mixing time of the Markov chain. With an appropriate step size schedule,\nthe transient term in the expected error bound is $o(1/k^c)$ and the\nsteady-state term is ${\\cal O}(1/k)$, where $c>1$ and $k$ is the iteration\nnumber. Furthermore, we present an asymptotic expansion of the expected error\nwith a matching lower bound of $\\Omega(1/k)$. A simple numerical experiment is\npresented to support our theory.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 13:03:17 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kaledin", "Maxim", ""], ["Moulines", "Eric", ""], ["Naumov", "Alexey", ""], ["Tadic", "Vladislav", ""], ["Wai", "Hoi-To", ""]]}, {"id": "2002.01322", "submitter": "Kevin Kilgour", "authors": "James Lin, Kevin Kilgour, Dominik Roblek, Matthew Sharifi", "title": "Training Keyword Spotters with Limited and Synthesized Speech Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of low power speech-enabled devices, there is a growing demand\nto quickly produce models for recognizing arbitrary sets of keywords. As with\nmany machine learning tasks, one of the most challenging parts in the model\ncreation process is obtaining a sufficient amount of training data. In this\npaper, we explore the effectiveness of synthesized speech data in training\nsmall, spoken term detection models of around 400k parameters. Instead of\ntraining such models directly on the audio or low level features such as MFCCs,\nwe use a pre-trained speech embedding model trained to extract useful features\nfor keyword spotting models. Using this speech embedding, we show that a model\nwhich detects 10 keywords when trained on only synthetic speech is equivalent\nto a model trained on over 500 real examples. We also show that a model without\nour speech embeddings would need to be trained on over 4000 real examples to\nreach the same accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:50:42 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lin", "James", ""], ["Kilgour", "Kevin", ""], ["Roblek", "Dominik", ""], ["Sharifi", "Matthew", ""]]}, {"id": "2002.01323", "submitter": "Vikramjit Mitra", "authors": "Vasudha Kowtha, Vikramjit Mitra, Chris Bartels, Erik Marchi, Sue\n  Booker, William Caruso, Sachin Kajarekar, Devang Naik", "title": "Detecting Emotion Primitives from Speech and their use in discerning\n  Categorical Emotions", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion plays an essential role in human-to-human communication, enabling us\nto convey feelings such as happiness, frustration, and sincerity. While modern\nspeech technologies rely heavily on speech recognition and natural language\nunderstanding for speech content understanding, the investigation of vocal\nexpression is increasingly gaining attention. Key considerations for building\nrobust emotion models include characterizing and improving the extent to which\na model, given its training data distribution, is able to generalize to unseen\ndata conditions. This work investigated a long-shot-term memory (LSTM) network\nand a time convolution - LSTM (TC-LSTM) to detect primitive emotion attributes\nsuch as valence, arousal, and dominance, from speech. It was observed that\ntraining with multiple datasets and using robust features improved the\nconcordance correlation coefficient (CCC) for valence, by 30\\% with respect to\nthe baseline system. Additionally, this work investigated how emotion\nprimitives can be used to detect categorical emotions such as happiness,\ndisgust, contempt, anger, and surprise from neutral speech, and results\nindicated that arousal, followed by dominance was a better detector of such\nemotions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:11:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kowtha", "Vasudha", ""], ["Mitra", "Vikramjit", ""], ["Bartels", "Chris", ""], ["Marchi", "Erik", ""], ["Booker", "Sue", ""], ["Caruso", "William", ""], ["Kajarekar", "Sachin", ""], ["Naik", "Devang", ""]]}, {"id": "2002.01335", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden, Christopher Pal", "title": "Structural Inductive Biases in Emergent Communication", "comments": "The first two authors contributed equally. Poster presented at CogSci\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:59:08 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 18:57:45 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 22:05:34 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 04:13:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""], ["Pal", "Christopher", ""]]}, {"id": "2002.01368", "submitter": "Emile Engelbrecht Mr.", "authors": "Emile R. Engelbrecht, Johan A. du Preez", "title": "Semi-supervised learning with an open augmenting unknown class for\n  cost-effective training and reliable classifications", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to (a) train off partially labelled datasets and (b) ensure\nresulting networks separate data outside the domain of interest hugely expands\nthe practical and cost-effective applicability of neural network classifiers.\nWe design a classifier based off generative adversarial networks (GANs) that\ntrains off a practical and cost-saving semi-supervised criteria which,\nspecifically, allows novel classes within the unlabelled training set.\nFurthermore, we ensure the resulting classifier is capable of absolute novel\nclass detection, be these from the semi-supervised unlabelled training set or a\nso-called open set. Results are both state-of-the-art and a first of its kind.\nWe argue this technique greatly decreases training cost in respect to labelling\nwhile greatly improving the reliability of classifications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:32:23 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 11:39:19 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 09:31:35 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Engelbrecht", "Emile R.", ""], ["Preez", "Johan A. du", ""]]}, {"id": "2002.01370", "submitter": "Wenzel Pilar Von Pilchau", "authors": "Wenzel Baron Pilar von Pilchau and Anthony Stein and J\\\"org H\\\"ahner", "title": "Bootstrapping a DQN Replay Memory with Synthetic Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important component of many Deep Reinforcement Learning algorithms is the\nExperience Replay which serves as a storage mechanism or memory of made\nexperiences. These experiences are used for training and help the agent to\nstably find the perfect trajectory through the problem space. The classic\nExperience Replay however makes only use of the experiences it actually made,\nbut the stored samples bear great potential in form of knowledge about the\nproblem that can be extracted. We present an algorithm that creates synthetic\nexperiences in a nondeterministic discrete environment to assist the learner.\nThe Interpolated Experience Replay is evaluated on the FrozenLake environment\nand we show that it can support the agent to learn faster and even better than\nthe classic version.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:36:36 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["von Pilchau", "Wenzel Baron Pilar", ""], ["Stein", "Anthony", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.01408", "submitter": "Eran Kaufman Dr.", "authors": "Lee-Ad Gottlieb, Eran Kaufman, Aryeh Kontorovich", "title": "Apportioned Margin Approach for Cost Sensitive Large Margin Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of cost sensitive multiclass classification, where we\nwould like to increase the sensitivity of an important class at the expense of\na less important one. We adopt an {\\em apportioned margin} framework to address\nthis problem, which enables an efficient margin shift between classes that\nshare the same boundary. The decision boundary between all pairs of classes\ndivides the margin between them in accordance to a given prioritization vector,\nwhich yields a tighter error bound for the important classes while also\nreducing the overall out-of-sample error. In addition to demonstrating an\nefficient implementation of our framework, we derive generalization bounds,\ndemonstrate Fisher consistency, adapt the framework to Mercer's kernel and to\nneural networks, and report promising empirical results on all accounts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:00:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kaufman", "Eran", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "2002.01427", "submitter": "Giles Strong", "authors": "Giles Chatham Strong", "title": "On the impact of selected modern deep-learning techniques to the\n  performance and celerity of classification models in an experimental\n  high-energy physics use case", "comments": "Preprint V4: Fixing typographical error and correcting two plots.\n  Mach. Learn.: Sci. Technol (2020)", "journal-ref": null, "doi": "10.1088/2632-2153/ab983a", "report-no": null, "categories": "physics.data-an cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beginning from a basic neural-network architecture, we test the potential\nbenefits offered by a range of advanced techniques for machine learning, in\nparticular deep learning, in the context of a typical classification problem\nencountered in the domain of high-energy physics, using a well-studied dataset:\nthe 2014 Higgs ML Kaggle dataset. The advantages are evaluated in terms of both\nperformance metrics and the time required to train and apply the resulting\nmodels. Techniques examined include domain-specific data-augmentation, learning\nrate and momentum scheduling, (advanced) ensembling in both model-space and\nweight-space, and alternative architectures and connection methods. Following\nthe investigation, we arrive at a model which achieves equal performance to the\nwinning solution of the original Kaggle challenge, whilst being significantly\nquicker to train and apply, and being suitable for use with both GPU and CPU\nhardware setups. These reductions in timing and hardware requirements\npotentially allow the use of more powerful algorithms in HEP analyses, where\nmodels must be retrained frequently, sometimes at short notice, by small groups\nof researchers with limited hardware resources. Additionally, a new wrapper\nlibrary for PyTorch called LUMIN is presented, which incorporates all of the\ntechniques studied.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:29:59 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 16:20:14 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 14:54:56 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 10:29:13 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Strong", "Giles Chatham", ""]]}, {"id": "2002.01428", "submitter": "Vincent Pacelli", "authors": "Vincent Pacelli and Anirudha Majumdar", "title": "Learning Task-Driven Control Policies via Information Bottlenecks", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a reinforcement learning approach to synthesizing\ntask-driven control policies for robotic systems equipped with rich sensory\nmodalities (e.g., vision or depth). Standard reinforcement learning algorithms\ntypically produce policies that tightly couple control actions to the entirety\nof the system's state and rich sensor observations. As a consequence, the\nresulting policies can often be sensitive to changes in task-irrelevant\nportions of the state or observations (e.g., changing background colors). In\ncontrast, the approach we present here learns to create a task-driven\nrepresentation that is used to compute control actions. Formally, this is\nachieved by deriving a policy gradient-style algorithm that creates an\ninformation bottleneck between the states and the task-driven representation;\nthis constrains actions to only depend on task-relevant information. We\ndemonstrate our approach in a thorough set of simulation results on multiple\nexamples including a grasping task that utilizes depth images and a\nball-catching task that utilizes RGB images. Comparisons with a standard policy\ngradient approach demonstrate that the task-driven policies produced by our\nalgorithm are often significantly more robust to sensor noise and\ntask-irrelevant changes in the environment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:50:06 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Pacelli", "Vincent", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2002.01431", "submitter": "Martino Trassinelli", "authors": "M. Trassinelli (INSP-E10, INSP), Pierre Ciccodicola (INSP-E10, INSP)", "title": "Mean shift cluster recognition method implementation in the nested\n  sampling algorithm", "comments": null, "journal-ref": null, "doi": "10.3390/e22020185", "report-no": null, "categories": "stat.CO astro-ph.IM physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested sampling is an efficient algorithm for the calculation of the Bayesian\nevidence and posterior parameter probability distributions. It is based on the\nstep-by-step exploration of the parameter space by Monte Carlo sampling with a\nseries of values sets called live points that evolve towards the region of\ninterest, i.e. where the likelihood function is maximal. In presence of several\nlocal likelihood maxima, the algorithm converges with difficulty. Some\nsystematic errors can also be introduced by unexplored parameter volume\nregions. In order to avoid this, different methods are proposed in the\nliterature for an efficient search of new live points, even in presence of\nlocal maxima. Here we present a new solution based on the mean shift cluster\nrecognition method implemented in a random walk search algorithm. The\nclustering recognition is integrated within the Bayesian analysis program\nNestedFit. It is tested with the analysis of some difficult cases. Compared to\nthe analysis results without cluster recognition, the computation time is\nconsiderably reduced. At the same time, the entire parameter space is\nefficiently explored, which translates into a smaller uncertainty of the\nextracted value of the Bayesian evidence.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:04:30 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Trassinelli", "M.", "", "INSP-E10, INSP"], ["Ciccodicola", "Pierre", "", "INSP-E10, INSP"]]}, {"id": "2002.01441", "submitter": "Alireza Rezazadeh", "authors": "Alireza Rezazadeh", "title": "A Generalized Flow for B2B Sales Predictive Modeling: An Azure Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": "10.3390/forecast2030015", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the outcome of sales opportunities is a core part of successful\nbusiness management. Conventionally, making this prediction has relied mostly\non subjective human evaluations in the process of sales decision making. In\nthis paper, we addressed the problem of forecasting the outcome of business to\nbusiness (B2B) sales by proposing a thorough data-driven Machine Learning (ML)\nworkflow on a cloud-based computing platform: Microsoft Azure Machine Learning\nService (Azure ML). This workflow consists of two pipelines: (1) An ML pipeline\nto train probabilistic predictive models on the historical sales opportunities\ndata. In this pipeline, data is enriched with an extensive feature enhancement\nstep and then used to train an ensemble of ML classification models in\nparallel. (2) A prediction pipeline to utilize the trained ML model and infer\nthe likelihood of winning new sales opportunities along with calculating\noptimal decision boundaries. The effectiveness of the proposed workflow was\nevaluated on a real sales dataset of a major global B2B consulting firm. Our\nresults implied that decision-making based on the ML predictions is more\naccurate and brings a higher monetary value.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:01:24 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 01:00:22 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Rezazadeh", "Alireza", ""]]}, {"id": "2002.01444", "submitter": "Jakub Marecek", "authors": "Quan Zhou and Jakub Marecek", "title": "Proper Learning of Linear Dynamical Systems as a Non-Commutative\n  Polynomial Optimisation Problem", "comments": "27 pages, 6 figures, with additional experiments exploiting sparsity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent progress in forecasting the next observation of a\nlinear dynamical system (LDS), which is known as the improper learning, as well\nas in the estimation of its system matrices, which is known as the proper\nlearning of LDS. We present an approach to proper learning of LDS, which in\nspite of the non-convexity of the problem, guarantees global convergence of\nnumerical solutions to a least-squares estimator. We present promising\ncomputational results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:08:49 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 21:07:10 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 14:16:42 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Zhou", "Quan", ""], ["Marecek", "Jakub", ""]]}, {"id": "2002.01464", "submitter": "Jiayuan Mao", "authors": "Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu", "title": "Visual Concept-Metaconcept Learning", "comments": "NeurIPS 2019. First two authors contributed equally. Project page:\n  http://vcml.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans reason with concepts and metaconcepts: we recognize red and green from\nvisual input; we also understand that they describe the same property of\nobjects (i.e., the color). In this paper, we propose the visual\nconcept-metaconcept learner (VCML) for joint learning of concepts and\nmetaconcepts from images and associated question-answer pairs. The key is to\nexploit the bidirectional connection between visual concepts and metaconcepts.\nVisual representations provide grounding cues for predicting relations between\nunseen pairs of concepts. Knowing that red and green describe the same property\nof objects, we generalize to the fact that cube and sphere also describe the\nsame property of objects, since they both categorize the shape of objects.\nMeanwhile, knowledge about metaconcepts empowers visual concept learning from\nlimited, noisy, and even biased data. From just a few examples of purple cubes\nwe can understand a new color purple, which resembles the hue of the cubes\ninstead of the shape of them. Evaluation on both synthetic and real-world\ndatasets validates our claims.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:42:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Han", "Chi", ""], ["Mao", "Jiayuan", ""], ["Gan", "Chuang", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "2002.01523", "submitter": "Satyen Kale", "authors": "Naman Agarwal and Pranjal Awasthi and Satyen Kale", "title": "A Deep Conditioning Treatment of Neural Networks", "comments": "In proceedings of ALT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of depth in training randomly initialized overparameterized\nneural networks. We give a general result showing that depth improves\ntrainability of neural networks by improving the conditioning of certain kernel\nmatrices of the input data. This result holds for arbitrary non-linear\nactivation functions under a certain normalization. We provide versions of the\nresult that hold for training just the top layer of the neural network, as well\nas for training all layers, via the neural tangent kernel. As applications of\nthese general results, we provide a generalization of the results of Das et al.\n(2019) showing that learnability of deep random neural networks with a large\nclass of non-linear activations degrades exponentially with depth. We also show\nhow benign overfitting can occur in deep neural networks via the results of\nBartlett et al. (2019b). We also give experimental evidence that normalized\nversions of ReLU are a viable alternative to more complex operations like Batch\nNormalization in training deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 20:21:36 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 18:44:14 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 14:06:52 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Agarwal", "Naman", ""], ["Awasthi", "Pranjal", ""], ["Kale", "Satyen", ""]]}, {"id": "2002.01547", "submitter": "Gustavo Malkomes", "authors": "Trevor J. Larsen, Gustavo Malkomes, Dennis L. Barbour", "title": "Accelerating Psychometric Screening Tests With Bayesian Active\n  Differential Selection", "comments": "Extended Abstract accepted to ML4H: Machine Learning for Health\n  Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical methods for psychometric function estimation either require\nexcessive measurements or produce only a low-resolution approximation of the\ntarget psychometric function. In this paper, we propose a novel solution for\nrapid screening for a change in the psychometric function estimation of a given\npatient. We use Bayesian active model selection to perform an automated\npure-tone audiogram test with the goal of quickly finding if the current\naudiogram will be different from a previous audiogram. We validate our approach\nusing audiometric data from the National Institute for Occupational Safety and\nHealth NIOSH. Initial results show that with a few tones we can detect if the\npatient's audiometric function has changed between the two test sessions with\nhigh confidence.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:35:03 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Larsen", "Trevor J.", ""], ["Malkomes", "Gustavo", ""], ["Barbour", "Dennis L.", ""]]}, {"id": "2002.01568", "submitter": "Leila Saadatifard", "authors": "Leila Saadatifard, Aryan Mobiny, Pavel Govyadinov, Hien Nguyen, David\n  Mayerich", "title": "DVNet: A Memory-Efficient Three-Dimensional CNN for Large-Scale\n  Neurovascular Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maps of brain microarchitecture are important for understanding neurological\nfunction and behavior, including alterations caused by chronic conditions such\nas neurodegenerative disease. Techniques such as knife-edge scanning microscopy\n(KESM) provide the potential for whole organ imaging at sub-cellular\nresolution. However, multi-terabyte data sizes make manual annotation\nimpractical and automatic segmentation challenging. Densely packed cells\ncombined with interconnected microvascular networks are a challenge for current\nsegmentation algorithms. The massive size of high-throughput microscopy data\nnecessitates fast and largely unsupervised algorithms. In this paper, we\ninvestigate a fully-convolutional, deep, and densely-connected encoder-decoder\nfor pixel-wise semantic segmentation. The excessive memory complexity often\nencountered with deep and dense networks is mitigated using skip connections,\nresulting in fewer parameters and enabling a significant performance increase\nover prior architectures. The proposed network provides superior performance\nfor semantic segmentation problems applied to open-source benchmarks. We\nfinally demonstrate our network for cellular and microvascular segmentation,\nenabling quantitative metrics for organ-scale neurovascular analysis.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 22:39:58 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Saadatifard", "Leila", ""], ["Mobiny", "Aryan", ""], ["Govyadinov", "Pavel", ""], ["Nguyen", "Hien", ""], ["Mayerich", "David", ""]]}, {"id": "2002.01569", "submitter": "Wenjia Wang", "authors": "Rui Tuo, Wenjia Wang", "title": "Uncertainty Quantification for Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a class of global optimization techniques. It\nregards the underlying objective function as a realization of a Gaussian\nprocess. Although the outputs of Bayesian optimization are random according to\nthe Gaussian process assumption, quantification of this uncertainty is rarely\nstudied in the literature. In this work, we propose a novel approach to assess\nthe output uncertainty of Bayesian optimization algorithms, in terms of\nconstructing confidence regions of the maximum point or value of the objective\nfunction. These regions can be computed efficiently, and their confidence\nlevels are guaranteed by newly developed uniform error bounds for sequential\nGaussian process regression. Our theory provides a unified uncertainty\nquantification framework for all existing sequential sampling policies and\nstopping criteria.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 22:48:07 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Tuo", "Rui", ""], ["Wang", "Wenjia", ""]]}, {"id": "2002.01576", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Bin Gu, Heng Huang", "title": "Large Batch Training Does Not Need Warmup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks using a large batch size has shown promising\nresults and benefits many real-world applications. However, the optimizer\nconverges slowly at early epochs and there is a gap between large-batch deep\nlearning optimization heuristics and theoretical underpinnings. In this paper,\nwe propose a novel Complete Layer-wise Adaptive Rate Scaling (CLARS) algorithm\nfor large-batch training. We also analyze the convergence rate of the proposed\nmethod by introducing a new fine-grained analysis of gradient-based methods.\nBased on our analysis, we bridge the gap and illustrate the theoretical\ninsights for three popular large-batch training techniques, including linear\nlearning rate scaling, gradual warmup, and layer-wise adaptive rate scaling.\nExtensive experiments demonstrate that the proposed algorithm outperforms\ngradual warmup technique by a large margin and defeats the convergence of the\nstate-of-the-art large-batch optimizer in training advanced deep neural\nnetworks (ResNet, DenseNet, MobileNet) on ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 23:03:12 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "2002.01584", "submitter": "Matthew McDermott", "authors": "Matthew B.A. McDermott (1), Emily Alsentzer (1 and 2), Sam Finlayson\n  (1 and 2), Michael Oberst (1), Fabian Falck (3), Tristan Naumann (4), Brett\n  K. Beaulieu-Jones (2), Adrian V. Dalca (2 and 1) ((1) Massachusetts Institute\n  of Technology, (2) Harvard Medical School, (3) Carnegie Mellon University,\n  (4) Microsoft Research)", "title": "ML4H Abstract Track 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collection of the accepted abstracts for the Machine Learning for Health\n(ML4H) workshop at NeurIPS 2019. This index is not complete, as some accepted\nabstracts chose to opt-out of inclusion.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:18:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["McDermott", "Matthew B. A.", "", "1 and 2"], ["Alsentzer", "Emily", "", "1 and 2"], ["Finlayson", "Sam", "", "1 and 2"], ["Oberst", "Michael", "", "2 and 1"], ["Falck", "Fabian", "", "2 and 1"], ["Naumann", "Tristan", "", "2 and 1"], ["Beaulieu-Jones", "Brett K.", "", "2 and 1"], ["Dalca", "Adrian V.", "", "2 and 1"]]}, {"id": "2002.01586", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang and Pragya Sur", "title": "A Precise High-Dimensional Asymptotic Theory for Boosting and\n  Minimum-$\\ell_1$-Norm Interpolated Classifiers", "comments": "68 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a precise high-dimensional asymptotic theory for\nboosting on separable data, taking statistical and computational perspectives.\nWe consider a high-dimensional setting where the number of features (weak\nlearners) $p$ scales with the sample size $n$, in an overparametrized regime.\nUnder a class of statistical models, we provide an exact analysis of the\ngeneralization error of boosting when the algorithm interpolates the training\ndata and maximizes the empirical $\\ell_1$-margin. Further, we explicitly pin\ndown the relation between the boosting test error and the optimal Bayes error,\nas well as the proportion of active features at interpolation (with zero\ninitialization). In turn, these precise characterizations answer certain\nquestions raised in \\cite{breiman1999prediction, schapire1998boosting}\nsurrounding boosting, under assumed data generating processes. At the heart of\nour theory lies an in-depth study of the maximum-$\\ell_1$-margin, which can be\naccurately described by a new system of non-linear equations; to analyze this\nmargin, we rely on Gaussian comparison techniques and develop a novel uniform\ndeviation argument. Our statistical and computational arguments can handle (1)\nany finite-rank spiked covariance model for the feature distribution and (2)\nvariants of boosting corresponding to general $\\ell_q$-geometry, $q \\in [1,\n2]$. As a final component, via the Lindeberg principle, we establish a\nuniversality result showcasing that the scaled $\\ell_1$-margin (asymptotically)\nremains the same, whether the covariates used for boosting arise from a\nnon-linear random feature model or an appropriately linearized model with\nmatching moments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:24:53 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 20:49:20 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 20:55:22 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liang", "Tengyuan", ""], ["Sur", "Pragya", ""]]}, {"id": "2002.01600", "submitter": "Johannes Hendriks", "authors": "Johannes Hendriks, Carl Jidling, Adrian Wills and Thomas Sch\\\"on", "title": "Linearly Constrained Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to modelling and learning vector fields from\nphysical systems using neural networks that explicitly satisfy known linear\noperator constraints. To achieve this, the target function is modelled as a\nlinear transformation of an underlying potential field, which is in turn\nmodelled by a neural network. This transformation is chosen such that any\nprediction of the target function is guaranteed to satisfy the constraints. The\napproach is demonstrated on both simulated and real data examples.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 01:27:29 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 23:38:01 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 01:24:06 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 01:43:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Hendriks", "Johannes", ""], ["Jidling", "Carl", ""], ["Wills", "Adrian", ""], ["Sch\u00f6n", "Thomas", ""]]}, {"id": "2002.01605", "submitter": "Zhi-Hua Zhou", "authors": "Yu-Jie Zhang and Peng Zhao and Zhi-Hua Zhou", "title": "Exploratory Machine Learning with Unknown Unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional supervised learning, a training dataset is given with\nground-truth labels from a known label set, and the learned model will classify\nunseen instances to the known labels. In this paper, we study a new problem\nsetting in which there are unknown classes in the training dataset misperceived\nas other labels, and thus their existence appears unknown from the given\nsupervision. We attribute the unknown unknowns to the fact that the training\ndataset is badly advised by the incompletely perceived label space due to the\ninsufficient feature information. To this end, we propose the exploratory\nmachine learning, which examines and investigates the training dataset by\nactively augmenting the feature space to discover potentially unknown labels.\nOur approach consists of three ingredients including rejection model, feature\nacquisition, and model cascade. The effectiveness is validated on both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 02:06:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Yu-Jie", ""], ["Zhao", "Peng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2002.01615", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Marco Cuturi, Makoto Yamada, Hisashi Kashima", "title": "Fast and Robust Comparison of Probability Measures in Heterogeneous\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing two probability measures supported on heterogeneous spaces is an\nincreasingly important problem in machine learning. Such problems arise when\ncomparing for instance two populations of biological cells, each described with\nits own set of features, or when looking at families of word embeddings trained\nacross different corpora/languages. For such settings, the Gromov Wasserstein\n(GW) distance is often presented as the gold standard. GW is intuitive, as it\nquantifies whether one measure can be isomorphically mapped to the other.\nHowever, its exact computation is intractable, and most algorithms that claim\nto approximate it remain expensive. Building on \\cite{memoli-2011}, who\nproposed to represent each point in each distribution as the 1D distribution of\nits distances to all other points, we introduce in this paper the Anchor Energy\n(AE) and Anchor Wasserstein (AW) distances, which are respectively the energy\nand Wasserstein distances instantiated on such representations. Our main\ncontribution is to propose a sweep line algorithm to compute AE \\emph{exactly}\nin log-quadratic time, where a naive implementation would be cubic. This is\nquasi-linear w.r.t. the description of the problem itself. Our second\ncontribution is the proposal of robust variants of AE and AW that uses rank\nstatistics rather than the original distances. We show that AE and AW perform\nwell in various experimental settings at a fraction of the computational cost\nof popular GW approximations. Code is available at\n\\url{https://github.com/joisino/anchor-energy}.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:09:23 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 12:35:24 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 09:47:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sato", "Ryoma", ""], ["Cuturi", "Marco", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.01622", "submitter": "Jiangsheng You Dr.", "authors": "Jason You", "title": "Revisit to the Inverse Exponential Radon Transform", "comments": "This review was first written in 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.IT cs.LG cs.NA math.IT math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This revisit gives a survey on the analytical methods for the inverse\nexponential Radon transform which has been investigated in the past three\ndecades from both mathematical interests and medical applications such as\nnuclear medicine emission imaging. The derivation of the classical inversion\nformula is through the recent argument developed for the inverse attenuated\nRadon transform. That derivation allows the exponential parameter to be a\ncomplex constant, which is useful to other applications such as magnetic\nresonance imaging and tensor field imaging. The survey also includes the new\ntechnique of using the finite Hilbert transform to handle the exact\nreconstruction from 180 degree data. Special treatment has been paid on two\npractically important subjects. One is the exact reconstruction from partial\nmeasurements such as half-scan and truncated-scan data, and the other is the\nreconstruction from diverging-beam data. The noise propagation in the\nreconstruction is touched upon with more heuristic discussions than\nmathematical inference. The numerical realizations of several classical\nreconstruction algorithms are included. In the conclusion, several topics are\ndiscussed for more investigations in the future.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:32:00 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["You", "Jason", ""]]}, {"id": "2002.01628", "submitter": "Zijian Lei", "authors": "Zijian Lei and Liang Lan", "title": "Improved Subsampled Randomized Hadamard Transform for Linear SVM", "comments": "AAAI-20", "journal-ref": null, "doi": "10.1609/aaai.v34i04.5880", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampled Randomized Hadamard Transform (SRHT), a popular random projection\nmethod that can efficiently project a $d$-dimensional data into $r$-dimensional\nspace ($r \\ll d$) in $O(dlog(d))$ time, has been widely used to address the\nchallenge of high-dimensionality in machine learning. SRHT works by rotating\nthe input data matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ by Randomized\nWalsh-Hadamard Transform followed with a subsequent uniform column sampling on\nthe rotated matrix. Despite the advantages of SRHT, one limitation of SRHT is\nthat it generates the new low-dimensional embedding without considering any\nspecific properties of a given dataset. Therefore, this data-independent random\nprojection method may result in inferior and unstable performance when used for\na particular machine learning task, e.g., classification. To overcome this\nlimitation, we analyze the effect of using SRHT for random projection in the\ncontext of linear SVM classification. Based on our analysis, we propose\nimportance sampling and deterministic top-$r$ sampling to produce effective\nlow-dimensional embedding instead of uniform sampling SRHT. In addition, we\nalso proposed a new supervised non-uniform sampling method. Our experimental\nresults have demonstrated that our proposed methods can achieve higher\nclassification accuracies than SRHT and other random projection methods on six\nreal-life datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 04:09:23 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lei", "Zijian", ""], ["Lan", "Liang", ""]]}, {"id": "2002.01633", "submitter": "Deyu Bo", "authors": "Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu and Peng Cui", "title": "Structural Deep Clustering Network", "comments": "Published at The Web Conference (WWW) 2020, full paper", "journal-ref": null, "doi": "10.1145/3366423.3380214", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental task in data analysis. Recently, deep clustering,\nwhich derives inspiration primarily from deep learning approaches, achieves\nstate-of-the-art performance and has attracted considerable attention. Current\ndeep clustering methods usually boost the clustering results by means of the\npowerful representation ability of deep learning, e.g., autoencoder, suggesting\nthat learning an effective representation for clustering is a crucial\nrequirement. The strength of deep clustering methods is to extract the useful\nrepresentations from the data itself, rather than the structure of data, which\nreceives scarce attention in representation learning. Motivated by the great\nsuccess of Graph Convolutional Network (GCN) in encoding the graph structure,\nwe propose a Structural Deep Clustering Network (SDCN) to integrate the\nstructural information into deep clustering. Specifically, we design a delivery\noperator to transfer the representations learned by autoencoder to the\ncorresponding GCN layer, and a dual self-supervised mechanism to unify these\ntwo different deep neural architectures and guide the update of the whole\nmodel. In this way, the multiple structures of data, from low-order to\nhigh-order, are naturally combined with the multiple representations learned by\nautoencoder. Furthermore, we theoretically analyze the delivery operator, i.e.,\nwith the delivery operator, GCN improves the autoencoder-specific\nrepresentation as a high-order graph regularization constraint and autoencoder\nhelps alleviate the over-smoothing problem in GCN. Through comprehensive\nexperiments, we demonstrate that our propose model can consistently perform\nbetter over the state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 04:33:40 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 01:38:08 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 13:27:06 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Bo", "Deyu", ""], ["Wang", "Xiao", ""], ["Shi", "Chuan", ""], ["Zhu", "Meiqi", ""], ["Lu", "Emiao", ""], ["Cui", "Peng", ""]]}, {"id": "2002.01645", "submitter": "Jes\\'us Daniel Arroyo Reli\\'on", "authors": "Jes\\'us Arroyo, Elizaveta Levina", "title": "Simultaneous prediction and community detection for networks with\n  application to neuroimaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community structure in networks is observed in many different domains, and\nunsupervised community detection has received a lot of attention in the\nliterature. Increasingly the focus of network analysis is shifting towards\nusing network information in some other prediction or inference task rather\nthan just analyzing the network itself. In particular, in neuroimaging\napplications brain networks are available for multiple subjects and the goal is\noften to predict a phenotype of interest. Community structure is well known to\nbe a feature of brain networks, typically corresponding to different regions of\nthe brain responsible for different functions. There are standard parcellations\nof the brain into such regions, usually obtained by applying clustering methods\nto brain connectomes of healthy subjects. However, when the goal is predicting\na phenotype or distinguishing between different conditions, these static\ncommunities from an unrelated set of healthy subjects may not be the most\nuseful for prediction. Here we present a method for supervised community\ndetection, aiming to find a partition of the network into communities that is\nmost useful for predicting a particular response. We use a block-structured\nregularization penalty combined with a prediction loss function, and compute\nthe solution with a combination of a spectral method and an ADMM optimization\nalgorithm. We show that the spectral clustering method recovers the correct\ncommunities under a weighted stochastic block model. The method performs well\non both simulated and real brain networks, providing support for the idea of\ntask-dependent brain regions.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:15:55 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 04:46:27 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Arroyo", "Jes\u00fas", ""], ["Levina", "Elizaveta", ""]]}, {"id": "2002.01648", "submitter": "Jes\\'us Daniel Arroyo Reli\\'on", "authors": "Jes\\'us Arroyo, Carey E. Priebe, Vince Lyzinski", "title": "Graph matching between bipartite and unipartite networks: to collapse,\n  or not to collapse, that is the question", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching consists of aligning the vertices of two unlabeled graphs in\norder to maximize the shared structure across networks; when the graphs are\nunipartite, this is commonly formulated as minimizing their edge disagreements.\nIn this paper, we address the common setting in which one of the graphs to\nmatch is a bipartite network and one is unipartite. Commonly, the bipartite\nnetworks are collapsed or projected into a unipartite graph, and graph matching\nproceeds as in the classical setting. This potentially leads to noisy edge\nestimates and loss of information. We formulate the graph matching problem\nbetween a bipartite and a unipartite graph using an undirected graphical model,\nand introduce methods to find the alignment with this model without collapsing.\nWe theoretically demonstrate that our methodology is consistent, and provide\nnon-asymptotic conditions that ensure exact recovery of the matching solution.\nIn simulations and real data examples, we show how our methods can result in a\nmore accurate matching than the naive approach of transforming the bipartite\nnetworks into unipartite, and we demonstrate the performance gains achieved by\nour method in simulated and real data networks, including a\nco-authorship-citation network pair, and brain structural and functional data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:24:54 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 21:30:45 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 17:35:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Arroyo", "Jes\u00fas", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "2002.01650", "submitter": "Zhi Chen", "authors": "Zhi Chen, Yijie Bei and Cynthia Rudin", "title": "Concept Whitening for Interpretable Image Recognition", "comments": "Authors' pre-publication version of a 2020 Nature Machine\n  Intelligence article", "journal-ref": "Nature Machine Intelligence, Vol 2, Dec 2020, 772-782", "doi": "10.1038/s42256-020-00265-z", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does a neural network encode about a concept as we traverse through the\nlayers? Interpretability in machine learning is undoubtedly important, but the\ncalculations of neural networks are very challenging to understand. Attempts to\nsee inside their hidden layers can either be misleading, unusable, or rely on\nthe latent space to possess properties that it may not have. In this work,\nrather than attempting to analyze a neural network posthoc, we introduce a\nmechanism, called concept whitening (CW), to alter a given layer of the network\nto allow us to better understand the computation leading up to that layer. When\na concept whitening module is added to a CNN, the axes of the latent space are\naligned with known concepts of interest. By experiment, we show that CW can\nprovide us a much clearer understanding for how the network gradually learns\nconcepts over layers. CW is an alternative to a batch normalization layer in\nthat it normalizes, and also decorrelates (whitens) the latent space. CW can be\nused in any layer of the network without hurting predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:28:09 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 16:55:49 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 05:06:19 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 14:13:19 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 19:09:35 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Chen", "Zhi", ""], ["Bei", "Yijie", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2002.01690", "submitter": "Xiaofu Wu Dr", "authors": "Xiaofu Wu, Suofei hang, Quan Zhou, Zhen Yang, Chunming Zhao, Longin\n  Jan Latecki", "title": "Entropy Minimization vs. Diversity Maximization for Domain Adaptation", "comments": "submitted to IEEE T-IP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy minimization has been widely used in unsupervised domain adaptation\n(UDA). However, existing works reveal that entropy minimization only may result\ninto collapsed trivial solutions. In this paper, we propose to avoid trivial\nsolutions by further introducing diversity maximization. In order to achieve\nthe possible minimum target risk for UDA, we show that diversity maximization\nshould be elaborately balanced with entropy minimization, the degree of which\ncan be finely controlled with the use of deep embedded validation in an\nunsupervised manner. The proposed minimal-entropy diversity maximization (MEDM)\ncan be directly implemented by stochastic gradient descent without use of\nadversarial learning. Empirical evidence demonstrates that MEDM outperforms the\nstate-of-the-art methods on four popular domain adaptation datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 09:13:19 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wu", "Xiaofu", ""], ["hang", "Suofei", ""], ["Zhou", "Quan", ""], ["Yang", "Zhen", ""], ["Zhao", "Chunming", ""], ["Latecki", "Longin Jan", ""]]}, {"id": "2002.01697", "submitter": "Zhaoqiang Liu", "authors": "Zhaoqiang Liu, Selwyn Gomes, Avtansh Tiwari, Jonathan Scarlett", "title": "Sample Complexity Bounds for 1-bit Compressive Sensing and Binary Stable\n  Embeddings with Generative Priors", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of standard 1-bit compressive sensing is to accurately recover an\nunknown sparse vector from binary-valued measurements, each indicating the sign\nof a linear function of the vector. Motivated by recent advances in compressive\nsensing with generative models, where a generative modeling assumption replaces\nthe usual sparsity assumption, we study the problem of 1-bit compressive\nsensing with generative models. We first consider noiseless 1-bit measurements,\nand provide sample complexity bounds for approximate recovery under\ni.i.d.~Gaussian measurements and a Lipschitz continuous generative prior, as\nwell as a near-matching algorithm-independent lower bound. Moreover, we\ndemonstrate that the Binary $\\epsilon$-Stable Embedding property, which\ncharacterizes the robustness of the reconstruction to measurement errors and\nnoise, also holds for 1-bit compressive sensing with Lipschitz continuous\ngenerative models with sufficiently many Gaussian measurements. In addition, we\napply our results to neural network generative models, and provide a\nproof-of-concept numerical experiment demonstrating significant improvements\nover sparsity-based approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 09:44:10 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:47:05 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 04:57:09 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Liu", "Zhaoqiang", ""], ["Gomes", "Selwyn", ""], ["Tiwari", "Avtansh", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2002.01706", "submitter": "Aleksandar Kolev", "authors": "Aleksandar A. Kolev, Gordon J. Ross", "title": "Semiparametric Bayesian Forecasting of Spatial Earthquake Occurrences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-exciting Hawkes processes are used to model events which cluster in time\nand space, and have been widely studied in seismology under the name of the\nEpidemic Type Aftershock Sequence (ETAS) model. In the ETAS framework, the\noccurrence of the mainshock earthquakes in a geographical region is assumed to\nfollow an inhomogeneous spatial point process, and aftershock events are then\nmodelled via a separate triggering kernel. Most previous studies of the ETAS\nmodel have relied on point estimates of the model parameters due to the\ncomplexity of the likelihood function, and the difficulty in estimating an\nappropriate mainshock distribution. In order to take estimation uncertainty\ninto account, we instead propose a fully Bayesian formulation of the ETAS model\nwhich uses a nonparametric Dirichlet process mixture prior to capture the\nspatial mainshock process. Direct inference for the resulting model is\nproblematic due to the strong correlation of the parameters for the mainshock\nand triggering processes, so we instead use an auxiliary latent variable\nroutine to perform efficient inference.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 10:11:26 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Kolev", "Aleksandar A.", ""], ["Ross", "Gordon J.", ""]]}, {"id": "2002.01711", "submitter": "Chengchun Shi", "authors": "Chengchun Shi, Xiaoyu Wang, Shikai Luo, Rui Song, Hongtu Zhu, Jieping\n  Ye", "title": "A Reinforcement Learning Framework for Time-Dependent Causal Effects\n  Evaluation in A/B Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A/B testing, or online experiment is a standard business strategy to compare\na new product with an old one in pharmaceutical, technological, and traditional\nindustries. Major challenges arise in online experiments where there is only\none unit that receives a sequence of treatments over time. In those\nexperiments, the treatment at a given time impacts current outcome as well as\nfuture outcomes. The aim of this paper is to introduce a reinforcement learning\nframework for carrying A/B testing, while characterizing the long-term\ntreatment effects. Our proposed testing procedure allows for sequential\nmonitoring and online updating, so it is generally applicable to a variety of\ntreatment designs in different industries. In addition, we systematically\ninvestigate the theoretical properties (e.g., asymptotic distribution and\npower) of our testing procedure. Finally, we apply our framework to both\nsynthetic datasets and a real-world data example obtained from a ride-sharing\ncompany to illustrate its usefulness.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 10:25:02 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 15:57:41 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 15:57:52 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 08:49:39 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shi", "Chengchun", ""], ["Wang", "Xiaoyu", ""], ["Luo", "Shikai", ""], ["Song", "Rui", ""], ["Zhu", "Hongtu", ""], ["Ye", "Jieping", ""]]}, {"id": "2002.01751", "submitter": "Chengchun Shi", "authors": "Chengchun Shi, Runzhe Wan, Rui Song, Wenbin Lu, Ling Leng", "title": "Does the Markov Decision Process Fit the Data: Testing for the Markov\n  Property in Sequential Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Markov assumption (MA) is fundamental to the empirical validity of\nreinforcement learning. In this paper, we propose a novel Forward-Backward\nLearning procedure to test MA in sequential decision making. The proposed test\ndoes not assume any parametric form on the joint distribution of the observed\ndata and plays an important role for identifying the optimal policy in\nhigh-order Markov decision processes and partially observable MDPs. We apply\nour test to both synthetic datasets and a real data example from mobile health\nstudies to illustrate its usefulness.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 12:29:10 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Shi", "Chengchun", ""], ["Wan", "Runzhe", ""], ["Song", "Rui", ""], ["Lu", "Wenbin", ""], ["Leng", "Ling", ""]]}, {"id": "2002.01768", "submitter": "Mihail Bogojeski", "authors": "Mihail Bogojeski, Simeon Sauer, Franziska Horn, Klaus-Robert M\\\"uller", "title": "Forecasting Industrial Aging Processes with Machine Learning Methods", "comments": "30 pages (41 including appendix), 13 figures, accepted in Computers\n  and Chemical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting industrial aging processes makes it possible to\nschedule maintenance events further in advance, ensuring a cost-efficient and\nreliable operation of the plant. So far, these degradation processes were\nusually described by mechanistic or simple empirical prediction models. In this\npaper, we evaluate a wider range of data-driven models, comparing some\ntraditional stateless models (linear and kernel ridge regression, feed-forward\nneural networks) to more complex recurrent neural networks (echo state networks\nand LSTMs). We first examine how much historical data is needed to train each\nof the models on a synthetic dataset with known dynamics. Next, the models are\ntested on real-world data from a large scale chemical plant. Our results show\nthat recurrent models produce near perfect predictions when trained on larger\ndatasets, and maintain a good performance even when trained on smaller datasets\nwith domain shifts, while the simpler models only performed comparably on the\nsmaller datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:06:44 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:00:44 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Bogojeski", "Mihail", ""], ["Sauer", "Simeon", ""], ["Horn", "Franziska", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2002.01771", "submitter": "Se-In Jang", "authors": "Se-In Jang", "title": "Online Passive-Aggressive Total-Error-Rate Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new online learning algorithm which utilizes online\npassive-aggressive learning (PA) and total-error-rate minimization (TER) for\nbinary classification. The PA learning establishes not only large margin\ntraining but also the capacity to handle non-separable data. The TER learning\non the other hand minimizes an approximated classification error based\nobjective function. We propose an online PATER algorithm which combines those\nuseful properties. In addition, we also present a weighted PATER algorithm to\nimprove the ability to cope with data imbalance problems. Experimental results\ndemonstrate that the proposed PATER algorithms achieves better performances in\nterms of efficiency and effectiveness than the existing state-of-the-art online\nlearning algorithms in real-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:10:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Jang", "Se-In", ""]]}, {"id": "2002.01775", "submitter": "Inseop Chung", "authors": "Inseop Chung, SeongUk Park, Jangho Kim, Nojun Kwak", "title": "Feature-map-level Online Adversarial Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature maps contain rich information about image intensity and spatial\ncorrelation. However, previous online knowledge distillation methods only\nutilize the class probabilities. Thus in this paper, we propose an online\nknowledge distillation method that transfers not only the knowledge of the\nclass probabilities but also that of the feature map using the adversarial\ntraining framework. We train multiple networks simultaneously by employing\ndiscriminators to distinguish the feature map distributions of different\nnetworks. Each network has its corresponding discriminator which discriminates\nthe feature map from its own as fake while classifying that of the other\nnetwork as real. By training a network to fool the corresponding discriminator,\nit can learn the other network's feature map distribution. We show that our\nmethod performs better than the conventional direct alignment method such as L1\nand is more suitable for online distillation. Also, we propose a novel cyclic\nlearning scheme for training more than two networks together. We have applied\nour method to various network architectures on the classification task and\ndiscovered a significant improvement of performance especially in the case of\ntraining a pair of a small network and a large one.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:16:37 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 17:58:38 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 18:15:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chung", "Inseop", ""], ["Park", "SeongUk", ""], ["Kim", "Jangho", ""], ["Kwak", "Nojun", ""]]}, {"id": "2002.01793", "submitter": "Yacov Hel-Or", "authors": "Inbal Lav, Shai Avidan, Yoram Singer, Yacov Hel-Or", "title": "Proximity Preserving Binary Code using Signed Graph-Cut", "comments": null, "journal-ref": "AAAI Conference on Artificial Intelligence , Feb. 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a binary embedding framework, called Proximity Preserving Code\n(PPC), which learns similarity and dissimilarity between data points to create\na compact and affinity-preserving binary code. This code can be used to apply\nfast and memory-efficient approximation to nearest-neighbor searches. Our\nframework is flexible, enabling different proximity definitions between data\npoints. In contrast to previous methods that extract binary codes based on\nunsigned graph partitioning, our system models the attractive and repulsive\nforces in the data by incorporating positive and negative graph weights. The\nproposed framework is shown to boil down to finding the minimal cut of a signed\ngraph, a problem known to be NP-hard. We offer an efficient approximation and\nachieve superior results by constructing the code bit after bit. We show that\nthe proposed approximation is superior to the commonly used spectral methods\nwith respect to both accuracy and complexity. Thus, it is useful for many other\nproblems that can be translated into signed graph cut.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:58:41 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Lav", "Inbal", ""], ["Avidan", "Shai", ""], ["Singer", "Yoram", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2002.01800", "submitter": "Mehmet Caner", "authors": "Mehmet Caner, Marcelo Medeiros, and Gabriel Vasconcelos", "title": "Residual-Based Nodewise Regression in Factor Models with Ultra-High\n  Dimensions: Analysis of Mean-Variance Portfolio Efficiency and Estimation of\n  Out-of-Sample and Constrained Maximum Sharpe Ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM econ.EM math.ST q-fin.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new theory for nodewise regression when the residuals from a\nfitted factor model are used to apply our results to the analysis of the\nmaximum Sharpe ratio when the number of assets in a portfolio is larger than\nits time span. We introduce a new hybrid model where factor models are combined\nwith feasible nodewise regression. Returns are generated from an increasing\nnumber of factors plus idiosyncratic components (errors). The precision matrix\nof the idiosyncratic terms is assumed to be sparse, but the respective\ncovariance matrix can be non-sparse. Since the nodewise regression is not\nfeasible due to the unknown nature of errors, we provide a\nfeasible-residual-based nodewise regression to estimate the precision matrix of\nerrors as a new method. Next, we show that the residual-based nodewise\nregression provides a consistent estimate for the precision matrix of errors.\nIn another new development, we also show that the precision matrix of returns\ncan be estimated consistently, even with an increasing number of factors.\nBenefiting from the consistency of the precision matrix estimate of returns, we\nshow that: (1) the portfolios in high dimensions are mean-variance efficient;\n(2) maximum out-of-sample Sharpe ratio estimator is consistent and the number\nof assets slows the convergence up to a logarithmic factor; (3) the maximum\nSharpe ratio estimator is consistent when the portfolio weights sum to one; and\n(4) the Sharpe ratio estimators are consistent in global minimum-variance and\nmean-variance portfolios.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:16:30 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:27:37 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 19:19:00 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Caner", "Mehmet", ""], ["Medeiros", "Marcelo", ""], ["Vasconcelos", "Gabriel", ""]]}, {"id": "2002.01810", "submitter": "Felix Assion", "authors": "David Mickisch, Felix Assion, Florens Gre{\\ss}ner, Wiebke G\\\"unther,\n  Mariele Motta", "title": "Understanding the Decision Boundary of Deep Neural Networks: An\n  Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving remarkable performance on many image classification tasks,\nstate-of-the-art machine learning (ML) classifiers remain vulnerable to small\ninput perturbations. Especially, the existence of adversarial examples raises\nconcerns about the deployment of ML models in safety- and security-critical\nenvironments, like autonomous driving and disease detection. Over the last few\nyears, numerous defense methods have been published with the goal of improving\nadversarial as well as corruption robustness. However, the proposed measures\nsucceeded only to a very limited extent. This limited progress is partly due to\nthe lack of understanding of the decision boundary and decision regions of deep\nneural networks. Therefore, we study the minimum distance of data points to the\ndecision boundary and how this margin evolves over the training of a deep\nneural network. By conducting experiments on MNIST, FASHION-MNIST, and\nCIFAR-10, we observe that the decision boundary moves closer to natural images\nover training. This phenomenon even remains intact in the late epochs of\ntraining, where the classifier already obtains low training and test error\nrates. On the other hand, adversarial training appears to have the potential to\nprevent this undesired convergence of the decision boundary.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:34:22 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Mickisch", "David", ""], ["Assion", "Felix", ""], ["Gre\u00dfner", "Florens", ""], ["G\u00fcnther", "Wiebke", ""], ["Motta", "Mariele", ""]]}, {"id": "2002.01873", "submitter": "George De Ath", "authors": "George De Ath, Richard M. Everson, Jonathan E. Fieldsend, Alma A. M.\n  Rahat", "title": "$\\epsilon$-shotgun: $\\epsilon$-greedy Batch Bayesian Optimisation", "comments": "Genetic and Evolutionary Computation Conference 2020 (GECCO '20). 9\n  pages (main paper) + 11 pages (supplementary material). Code avaliable at\n  https://github.com/georgedeath/eshotgun", "journal-ref": null, "doi": "10.1145/3377930.3390154", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular, surrogate model-based approach for\noptimising expensive black-box functions. Given a surrogate model, the next\nlocation to expensively evaluate is chosen via maximisation of a cheap-to-query\nacquisition function. We present an $\\epsilon$-greedy procedure for Bayesian\noptimisation in batch settings in which the black-box function can be evaluated\nmultiple times in parallel. Our $\\epsilon$-shotgun algorithm leverages the\nmodel's prediction, uncertainty, and the approximated rate of change of the\nlandscape to determine the spread of batch solutions to be distributed around a\nputative location. The initial target location is selected either in an\nexploitative fashion on the mean prediction, or -- with probability $\\epsilon$\n-- from elsewhere in the design space. This results in locations that are more\ndensely sampled in regions where the function is changing rapidly and in\nlocations predicted to be good (i.e close to predicted optima), with more\nscattered samples in regions where the function is flatter and/or of poorer\nquality. We empirically evaluate the $\\epsilon$-shotgun methods on a range of\nsynthetic functions and two real-world problems, finding that they perform at\nleast as well as state-of-the-art batch methods and in many cases exceed their\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:24:39 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 15:25:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard M.", ""], ["Fieldsend", "Jonathan E.", ""], ["Rahat", "Alma A. M.", ""]]}, {"id": "2002.01878", "submitter": "Henri De Plaen", "authors": "Henri De Plaen, Micha\\\"el Fanuel and Johan A. K. Suykens", "title": "Wasserstein Exponential Kernels", "comments": "9 pages, 3 figures and 1 table", "journal-ref": null, "doi": null, "report-no": "Internal Report 20-12, ESAT-STADIUS, KU Leuven (Leuven, Belgium)", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of kernel methods, the similarity between data points is\nencoded by the kernel function which is often defined thanks to the Euclidean\ndistance, a common example being the squared exponential kernel. Recently,\nother distances relying on optimal transport theory - such as the Wasserstein\ndistance between probability distributions - have shown their practical\nrelevance for different machine learning techniques. In this paper, we study\nthe use of exponential kernels defined thanks to the regularized Wasserstein\ndistance and discuss their positive definiteness. More specifically, we define\nWasserstein feature maps and illustrate their interest for supervised learning\nproblems involving shapes and images. Empirically, Wasserstein squared\nexponential kernels are shown to yield smaller classification errors on small\ntraining sets of shapes, compared to analogous classifiers using Euclidean\ndistances.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:31:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["De Plaen", "Henri", ""], ["Fanuel", "Micha\u00ebl", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2002.01882", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Nicol\\`o Cesa-Bianchi", "title": "Locally-Adaptive Nonparametric Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main strengths of online algorithms is their ability to adapt to\narbitrary data sequences. This is especially important in nonparametric\nsettings, where performance is measured against rich classes of comparator\nfunctions that are able to fit complex environments. Although such hard\ncomparators and complex environments may exhibit local regularities, efficient\nalgorithms, which can provably take advantage of these local patterns, are\nhardly known. We fill this gap by introducing efficient online algorithms\n(based on a single versatile master algorithm) each adapting to one of the\nfollowing regularities: (i) local Lipschitzness of the competitor function,\n(ii) local metric dimension of the instance sequence, (iii) local performance\nof the predictor across different regions of the instance space. Extending\nprevious approaches, we design algorithms that dynamically grow hierarchical\n$\\epsilon$-nets on the instance space whose prunings correspond to different\n\"locality profiles\" for the problem at hand. Using a technique based on tree\nexperts, we simultaneously and efficiently compete against all such prunings,\nand prove regret bounds each scaling with a quantity associated with a\ndifferent type of local regularity. When competing against \"simple\" locality\nprofiles, our technique delivers regret bounds that are significantly better\nthan those proven using the previous approach. On the other hand, the time\ndependence of our bounds is not worse than that obtained by ignoring any local\nregularities.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:42:04 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 14:37:18 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""]]}, {"id": "2002.01883", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Neev Parikh, Ronald E. Parr, George D. Konidaris,\n  Michael L. Littman", "title": "Deep Radial-Basis Value Functions for Continuous Control", "comments": "In Proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core operation in reinforcement learning (RL) is finding an action that is\noptimal with respect to a learned value function. This operation is often\nchallenging when the learned value function takes continuous actions as input.\nWe introduce deep radial-basis value functions (RBVFs): value functions learned\nusing a deep network with a radial-basis function (RBF) output layer. We show\nthat the maximum action-value with respect to a deep RBVF can be approximated\neasily and accurately. Moreover, deep RBVFs can represent any true value\nfunction owing to their support for universal function approximation. We extend\nthe standard DQN algorithm to continuous control by endowing the agent with a\ndeep RBVF. We show that the resultant agent, called RBF-DQN, significantly\noutperforms value-function-only baselines, and is competitive with\nstate-of-the-art actor-critic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:44:16 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 01:29:44 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Asadi", "Kavosh", ""], ["Parikh", "Neev", ""], ["Parr", "Ronald E.", ""], ["Konidaris", "George D.", ""], ["Littman", "Michael L.", ""]]}, {"id": "2002.01889", "submitter": "Tatjana Petrov", "authors": "Tatjana Petrov and Denis Repin", "title": "Automated Deep Abstractions for Stochastic Chemical Reaction Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting stochastic cellular dynamics as emerging from the mechanistic\nmodels of molecular interactions is a long-standing challenge in systems\nbiology: low-level chemical reaction network (CRN) models give raise to a\nhighly-dimensional continuous-time Markov chain (CTMC) which is computationally\ndemanding and often prohibitive to analyse in practice. A recently proposed\nabstraction method uses deep learning to replace this CTMC with a discrete-time\ncontinuous-space process, by training a mixture density deep neural network\nwith traces sampled at regular time intervals (which can obtained either by\nsimulating a given CRN or as time-series data from experiment). The major\nadvantage of such abstraction is that it produces a computational model that is\ndramatically cheaper to execute, while preserving the statistical features of\nthe training data. In general, the abstraction accuracy improves with the\namount of training data. However, depending on a CRN, the overall quality of\nthe method -- the efficiency gain and abstraction accuracy -- will also depend\non the choice of neural network architecture given by hyper-parameters such as\nthe layer types and connections between them. As a consequence, in practice,\nthe modeller would have to take care of finding the suitable architecture\nmanually, for each given CRN, through a tedious and time-consuming\ntrial-and-error cycle. In this paper, we propose to further automatise deep\nabstractions for stochastic CRNs, through learning the optimal neural network\narchitecture along with learning the transition kernel of the abstract process.\nAutomated search of the architecture makes the method applicable directly to\nany given CRN, which is time-saving for deep learning experts and crucial for\nnon-specialists. We implement the method and demonstrate its performance on a\nnumber of representative CRNs with multi-modal emergent phenotypes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:49:58 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Petrov", "Tatjana", ""], ["Repin", "Denis", ""]]}, {"id": "2002.01890", "submitter": "Thais Fonseca Dr", "authors": "Victhor S. Sart\\'orio and Tha\\'is C. O. Fonseca", "title": "Dynamic clustering of time series data", "comments": "27 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for clustering multivariate time-series data based on\nDynamic Linear Models. Whereas usual time-series clustering methods obtain\nstatic membership parameters, our proposal allows each time-series to\ndynamically change their cluster memberships over time. In this context, a\nmixture model is assumed for the time series and a flexible Dirichlet evolution\nfor mixture weights allows for smooth membership changes over time. Posterior\nestimates and predictions can be obtained through Gibbs sampling, but a more\nefficient method for obtaining point estimates is presented, based on\nStochastic Expectation-Maximization and Gradient Descent. Finally, two\napplications illustrate the usefulness of our proposed model to model both\nunivariate and multivariate time-series: World Bank indicators for the\nrenewable energy consumption of EU nations and the famous Gapminder dataset\ncontaining life-expectancy and GDP per capita for various countries.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:01:28 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Sart\u00f3rio", "Victhor S.", ""], ["Fonseca", "Tha\u00eds C. O.", ""]]}, {"id": "2002.01891", "submitter": "Yasuhiko Tachibana", "authors": "Yasuhiko Tachibana, Masataka Nishimori, Naoyuki Kitamura, Kensuke\n  Umehara, Junko Ota, Takayuki Obata, and Tatsuya Higashi", "title": "A neural network model that learns differences in diagnosis strategies\n  among radiologists has an improved area under the curve for aneurysm status\n  classification in magnetic resonance angiography image series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To construct a neural network model that can learn the different\ndiagnosing strategies of radiologists to better classify aneurysm status in\nmagnetic resonance angiography images. Materials and methods: This\nretrospective study included 3423 time-of-flight brain magnetic resonance\nangiography image series (subjects: male 1843 [mean age, 50.2 +/- 11.7 years],\nfemale 1580 [50.8 +/- 11.3 years]) recorded from November 2017 through January\n2019. The image series were read independently for aneurysm status by one of\nfour board-certified radiologists, who were assisted by an established deep\nlearning-based computer-assisted diagnosis (CAD) system. The constructed neural\nnetworks were trained to classify the aneurysm status of zero to five\naneurysm-suspicious areas suggested by the CAD system for each image series,\nand any additional aneurysm areas added by the radiologists, and this\nclassification was compared with the judgment of the annotating radiologist.\nImage series were randomly allocated to training and testing data in an 8:2\nratio. The accuracy of the classification was compared by receiver operating\ncharacteristic analysis between the control model that accepted only image data\nas input and the proposed model that additionally accepted the information of\nwho the annotating radiologist was. The DeLong test was used to compare areas\nunder the curves (P < 0.05 was considered significant). Results: The area under\nthe curve was larger in the proposed model (0.845) than in the control model\n(0.793), and the difference was significant (P < 0.0001). Conclusion: The\nproposed model improved classification accuracy by learning the diagnosis\nstrategies of individual annotating radiologists.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:19:57 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Tachibana", "Yasuhiko", ""], ["Nishimori", "Masataka", ""], ["Kitamura", "Naoyuki", ""], ["Umehara", "Kensuke", ""], ["Ota", "Junko", ""], ["Obata", "Takayuki", ""], ["Higashi", "Tatsuya", ""]]}, {"id": "2002.01893", "submitter": "Houpu Yao", "authors": "Houpu Yao, Yi Gao, Yongming Liu", "title": "FEA-Net: A Physics-guided Data-driven Model for Efficient Mechanical\n  Response Prediction", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.112892", "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An innovative physics-guided learning algorithm for predicting the mechanical\nresponse of materials and structures is proposed in this paper. The key concept\nof the proposed study is based on the fact that physics models are governed by\nPartial Differential Equation (PDE), and its loading/ response mapping can be\nsolved using Finite Element Analysis (FEA). Based on this, a special type of\ndeep convolutional neural network (DCNN) is proposed that takes advantage of\nour prior knowledge in physics to build data-driven models whose architectures\nare of physics meaning. This type of network is named as FEA-Net and is used to\nsolve the mechanical response under external loading. Thus, the identification\nof a mechanical system parameters and the computation of its responses are\ntreated as the learning and inference of FEA-Net, respectively. Case studies on\nmulti-physics (e.g., coupled mechanical-thermal analysis) and multi-phase\nproblems (e.g., composite materials with random micro-structures) are used to\ndemonstrate and verify the theoretical and computational advantages of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:37:44 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yao", "Houpu", ""], ["Gao", "Yi", ""], ["Liu", "Yongming", ""]]}, {"id": "2002.01910", "submitter": "Guillaume Salha-Galvan", "authors": "Guillaume Salha and Romain Hennequin and Jean-Baptiste Remy and Manuel\n  Moussallam and Michalis Vazirgiannis", "title": "FastGAE: Scalable Graph Autoencoders with Stochastic Subgraph Decoding", "comments": "Accepted for publication in Elsevier's Neural Networks journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph autoencoders (AE) and variational autoencoders (VAE) are powerful node\nembedding methods, but suffer from scalability issues. In this paper, we\nintroduce FastGAE, a general framework to scale graph AE and VAE to large\ngraphs with millions of nodes and edges. Our strategy, based on an effective\nstochastic subgraph decoding scheme, significantly speeds up the training of\ngraph AE and VAE while preserving or even improving performances. We\ndemonstrate the effectiveness of FastGAE on various real-world graphs,\noutperforming the few existing approaches to scale graph AE and VAE by a wide\nmargin.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:27:39 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 16:54:02 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 14:05:07 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 12:42:24 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 15:37:01 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""], ["Remy", "Jean-Baptiste", ""], ["Moussallam", "Manuel", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2002.01927", "submitter": "Changyu Deng", "authors": "Changyu Deng, Yizhou Wang, Can Qin, Wei Lu", "title": "Self-Directed Online Machine Learning for Topology Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology optimization by optimally distributing materials in a given domain\nrequires gradient-free optimizers to solve highly complicated problems.\nHowever, with hundreds of design variables or more involved, solving such\nproblems would require millions of Finite Element Method (FEM) calculations\nwhose computational cost is huge and impractical. Here we report a\nSelf-directed Online Learning Optimization (SOLO) which integrates Deep Neural\nNetwork (DNN) with FEM calculations. A DNN learns and substitutes the objective\nas a function of design variables. A small amount of training data is generated\ndynamically based on the DNN's prediction of the global optimum. The DNN adapts\nto the new training data and gives better prediction in the region of interest\nuntil convergence. Our algorithm was tested by compliance minimization problems\nand fluid-structure optimization problems. It reduced the computational time by\n2~5 orders of magnitude compared with directly using heuristic methods, and\noutperformed all state-of-the-art algorithms tested in our experiments. This\napproach enables solving large multi-dimensional optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 20:00:28 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 21:25:57 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 14:40:54 GMT"}, {"version": "v4", "created": "Sat, 12 Sep 2020 18:58:11 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 00:53:37 GMT"}, {"version": "v6", "created": "Mon, 4 Jan 2021 16:12:25 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Deng", "Changyu", ""], ["Wang", "Yizhou", ""], ["Qin", "Can", ""], ["Lu", "Wei", ""]]}, {"id": "2002.01953", "submitter": "Henry Moss", "authors": "Henry B.Moss, Vatsal Aggarwal, Nishant Prateek, Javier Gonz\\'alez,\n  Roberto Barra-Chicote", "title": "BOFFIN TTS: Few-Shot Speaker Adaptation by Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BOFFIN TTS (Bayesian Optimization For FIne-tuning Neural Text To\nSpeech), a novel approach for few-shot speaker adaptation. Here, the task is to\nfine-tune a pre-trained TTS model to mimic a new speaker using a small corpus\nof target utterances. We demonstrate that there does not exist a\none-size-fits-all adaptation strategy, with convincing synthesis requiring a\ncorpus-specific configuration of the hyper-parameters that control fine-tuning.\nBy using Bayesian optimization to efficiently optimize these hyper-parameter\nvalues for a target speaker, we are able to perform adaptation with an average\n30% improvement in speaker similarity over standard techniques. Results\nindicate, across multiple corpora, that BOFFIN TTS can learn to synthesize new\nspeakers using less than ten minutes of audio, achieving the same naturalness\nas produced for the speakers used to train the base model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 16:37:52 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Moss", "Henry B.", ""], ["Aggarwal", "Vatsal", ""], ["Prateek", "Nishant", ""], ["Gonz\u00e1lez", "Javier", ""], ["Barra-Chicote", "Roberto", ""]]}, {"id": "2002.01963", "submitter": "Rui Zhao", "authors": "Rui Zhao, Yang Gao, Pieter Abbeel, Volker Tresp, Wei Xu", "title": "Mutual Information-based State-Control for Intrinsically Motivated\n  Reinforcement Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, an agent learns to reach a set of goals by means\nof an external reward signal. In the natural world, intelligent organisms learn\nfrom internal drives, bypassing the need for external signals, which is\nbeneficial for a wide range of tasks. Motivated by this observation, we propose\nto formulate an intrinsic objective as the mutual information between the goal\nstates and the controllable states. This objective encourages the agent to take\ncontrol of its environment. Subsequently, we derive a surrogate objective of\nthe proposed reward function, which can be optimized efficiently. Lastly, we\nevaluate the developed framework in different robotic manipulation and\nnavigation tasks and demonstrate the efficacy of our approach. A video showing\nexperimental results is available at https://youtu.be/CT4CKMWBYz0\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:21:20 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 19:07:38 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhao", "Rui", ""], ["Gao", "Yang", ""], ["Abbeel", "Pieter", ""], ["Tresp", "Volker", ""], ["Xu", "Wei", ""]]}, {"id": "2002.01987", "submitter": "Maxim Raginsky", "authors": "Belinda Tzen and Maxim Raginsky", "title": "A mean-field theory of lazy training in two-layer neural nets: entropic\n  regularization and controlled McKean-Vlasov dynamics", "comments": "fixed a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of universal approximation of functions by two-layer\nneural nets with random weights that are \"nearly Gaussian\" in the sense of\nKullback-Leibler divergence. This problem is motivated by recent works on lazy\ntraining, where the weight updates generated by stochastic gradient descent do\nnot move appreciably from the i.i.d. Gaussian initialization. We first consider\nthe mean-field limit, where the finite population of neurons in the hidden\nlayer is replaced by a continual ensemble, and show that our problem can be\nphrased as global minimization of a free-energy functional on the space of\nprobability measures over the weights. This functional trades off the $L^2$\napproximation risk against the KL divergence with respect to a centered\nGaussian prior. We characterize the unique global minimizer and then construct\na controlled nonlinear dynamics in the space of probability measures over\nweights that solves a McKean--Vlasov optimal control problem. This control\nproblem is closely related to the Schr\\\"odinger bridge (or entropic optimal\ntransport) problem, and its value is proportional to the minimum of the free\nenergy. Finally, we show that SGD in the lazy training regime (which can be\nensured by jointly tuning the variance of the Gaussian prior and the entropic\nregularization parameter) serves as a greedy approximation to the optimal\nMcKean--Vlasov distributional dynamics and provide quantitative guarantees on\nthe $L^2$ approximation error.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 20:50:33 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:11:07 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 21:47:47 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Tzen", "Belinda", ""], ["Raginsky", "Maxim", ""]]}, {"id": "2002.01999", "submitter": "Eran Kaufman Dr.", "authors": "Lee-Ad Gottlieb, Eran Kaufman, Aryeh Kontorovich, Gabriel Nivasch, and\n  Ofir Pele", "title": "Nested Barycentric Coordinate System as an Explicit Feature Map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new embedding method which is particularly well-suited for\nsettings where the sample size greatly exceeds the ambient dimension. Our\ntechnique consists of partitioning the space into simplices and then embedding\nthe data points into features corresponding to the simplices' barycentric\ncoordinates. We then train a linear classifier in the rich feature space\nobtained from the simplices. The decision boundary may be highly non-linear,\nthough it is linear within each simplex (and hence piecewise-linear overall).\nFurther, our method can approximate any convex body. We give generalization\nbounds based on empirical margin and a novel hybrid sample compression\ntechnique. An extensive empirical evaluation shows that our method consistently\noutperforms a range of popular kernel embedding methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:27:06 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kaufman", "Eran", ""], ["Kontorovich", "Aryeh", ""], ["Nivasch", "Gabriel", ""], ["Pele", "Ofir", ""]]}, {"id": "2002.02007", "submitter": "Shuo Wang", "authors": "Shuo Wang, Tianle Chen, Surya Nepal, Carsten Rudolph, Marthie Grobler,\n  Shangyu Chen", "title": "Defending Adversarial Attacks via Semantic Feature Manipulation", "comments": "arXiv admin note: text overlap with arXiv:2001.06640 and text overlap\n  with arXiv:1705.09064 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have demonstrated vulnerability to adversarial\nattacks, more specifically misclassification of adversarial examples. In this\npaper, we propose a one-off and attack-agnostic Feature Manipulation\n(FM)-Defense to detect and purify adversarial examples in an interpretable and\nefficient manner. The intuition is that the classification result of a normal\nimage is generally resistant to non-significant intrinsic feature changes,\ne.g., varying thickness of handwritten digits. In contrast, adversarial\nexamples are sensitive to such changes since the perturbation lacks\ntransferability. To enable manipulation of features, a combo-variational\nautoencoder is applied to learn disentangled latent codes that reveal semantic\nfeatures. The resistance to classification change over the morphs, derived by\nvarying and reconstructing latent codes, is used to detect suspicious inputs.\nFurther, combo-VAE is enhanced to purify the adversarial examples with good\nquality by considering both class-shared and class-unique features. We\nempirically demonstrate the effectiveness of detection and the quality of\npurified instance. Our experiments on three datasets show that FM-Defense can\ndetect nearly $100\\%$ of adversarial examples produced by different\nstate-of-the-art adversarial attacks. It achieves more than $99\\%$ overall\npurification accuracy on the suspicious instances that close the manifold of\nnormal examples.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:24:32 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 13:14:48 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Tianle", ""], ["Nepal", "Surya", ""], ["Rudolph", "Carsten", ""], ["Grobler", "Marthie", ""], ["Chen", "Shangyu", ""]]}, {"id": "2002.02008", "submitter": "Bryan Lim", "authors": "Bryan Lim, Stefan Zohren, Stephen Roberts", "title": "Detecting Changes in Asset Co-Movement Using the Autoencoder\n  Reconstruction Ratio", "comments": null, "journal-ref": "Risk 2020", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting changes in asset co-movements is of much importance to financial\npractitioners, with numerous risk management benefits arising from the timely\ndetection of breakdowns in historical correlations. In this article, we propose\na real-time indicator to detect temporary increases in asset co-movements, the\nAutoencoder Reconstruction Ratio, which measures how well a basket of asset\nreturns can be modelled using a lower-dimensional set of latent variables. The\nARR uses a deep sparse denoising autoencoder to perform the dimensionality\nreduction on the returns vector, which replaces the PCA approach of the\nstandard Absorption Ratio, and provides a better model for non-Gaussian\nreturns. Through a systemic risk application on forecasting on the CRSP US\nTotal Market Index, we show that lower ARR values coincide with higher\nvolatility and larger drawdowns, indicating that increased asset co-movement\ndoes correspond with periods of market weakness. We also demonstrate that\nshort-term (i.e. 5-min and 1-hour) predictors for realised volatility and\nmarket crashes can be improved by including additional ARR inputs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:33:54 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 14:14:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.02013", "submitter": "Benwei Shi", "authors": "Benwei Shi and Jeff M. Phillips", "title": "A Deterministic Streaming Sketch for Ridge Regression", "comments": "Fix a few typos. To be published in AISTATS 2021", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics, PMLR 130:586-594, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a deterministic space-efficient algorithm for estimating ridge\nregression. For $n$ data points with $d$ features and a large enough\nregularization parameter, we provide a solution within $\\varepsilon$ L$_2$\nerror using only $O(d/\\varepsilon)$ space. This is the first $o(d^2)$ space\ndeterministic streaming algorithm with guaranteed solution error and risk bound\nfor this classic problem. The algorithm sketches the covariance matrix by\nvariants of Frequent Directions, which implies it can operate in insertion-only\nstreams and a variety of distributed data settings. In comparisons to\nrandomized sketching algorithms on synthetic and real-world datasets, our\nalgorithm has less empirical error using less space and similar time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:08:29 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 01:54:24 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 00:12:56 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 07:47:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Shi", "Benwei", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "2002.02040", "submitter": "Zachary Ross", "authors": "Xiaotian Zhang, Zhe Jia, Zachary E. Ross, and Robert W. Clayton", "title": "Extracting dispersion curves from ambient noise correlations using deep\n  learning", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2020.2992043", "report-no": null, "categories": "cs.LG eess.IV physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine-learning approach to classifying the phases of surface\nwave dispersion curves. Standard FTAN analysis of surfaces observed on an array\nof receivers is converted to an image, of which, each pixel is classified as\nfundamental mode, first overtone, or noise. We use a convolutional neural\nnetwork (U-net) architecture with a supervised learning objective and\nincorporate transfer learning. The training is initially performed with\nsynthetic data to learn coarse structure, followed by fine-tuning of the\nnetwork using approximately 10% of the real data based on human classification.\nThe results show that the machine classification is nearly identical to the\nhuman picked phases. Expanding the method to process multiple images at once\ndid not improve the performance. The developed technique will faciliate\nautomated processing of large dispersion curve datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 23:41:12 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Zhang", "Xiaotian", ""], ["Jia", "Zhe", ""], ["Ross", "Zachary E.", ""], ["Clayton", "Robert W.", ""]]}, {"id": "2002.02046", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic", "title": "Supervised Learning on Relational Databases with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of data scientists and machine learning practitioners use\nrelational data in their work [State of ML and Data Science 2017, Kaggle,\nInc.]. But training machine learning models on data stored in relational\ndatabases requires significant data extraction and feature engineering efforts.\nThese efforts are not only costly, but they also destroy potentially important\nrelational structure in the data. We introduce a method that uses Graph Neural\nNetworks to overcome these challenges. Our proposed method outperforms\nstate-of-the-art automatic feature engineering methods on two out of three\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 00:57:39 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cvitkovic", "Milan", ""]]}, {"id": "2002.02050", "submitter": "Jiechao Guan", "authors": "Jiechao Guan, Zhiwu Lu, Tao Xiang, Ji-Rong Wen", "title": "Few-Shot Learning as Domain Adaptation: Algorithm and Analysis", "comments": "There exist some mistakes in the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To recognize the unseen classes with only few samples, few-shot learning\n(FSL) uses prior knowledge learned from the seen classes. A major challenge for\nFSL is that the distribution of the unseen classes is different from that of\nthose seen, resulting in poor generalization even when a model is meta-trained\non the seen classes. This class-difference-caused distribution shift can be\nconsidered as a special case of domain shift. In this paper, for the first\ntime, we propose a domain adaptation prototypical network with attention\n(DAPNA) to explicitly tackle such a domain shift problem in a meta-learning\nframework. Specifically, armed with a set transformer based attention module,\nwe construct each episode with two sub-episodes without class overlap on the\nseen classes to simulate the domain shift between the seen and unseen classes.\nTo align the feature distributions of the two sub-episodes with limited\ntraining samples, a feature transfer network is employed together with a margin\ndisparity discrepancy (MDD) loss. Importantly, theoretical analysis is provided\nto give the learning bound of our DAPNA. Extensive experiments show that our\nDAPNA outperforms the state-of-the-art FSL alternatives, often by significant\nmargins.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:04:53 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:17:01 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 06:26:34 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Guan", "Jiechao", ""], ["Lu", "Zhiwu", ""], ["Xiang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2002.02054", "submitter": "Xiaomeng Ju", "authors": "Xiaomeng Ju, Mat\\'ias Salibi\\'an-Barrera", "title": "Robust Boosting for Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosting algorithms construct a regression predictor using a linear\ncombination of ``base learners''. Boosting also offers an approach to obtaining\nrobust non-parametric regression estimators that are scalable to applications\nwith many explanatory variables. The robust boosting algorithm is based on a\ntwo-stage approach, similar to what is done for robust linear regression: it\nfirst minimizes a robust residual scale estimator, and then improves it by\noptimizing a bounded loss function. Unlike previous robust boosting proposals\nthis approach does not require computing an ad-hoc residual scale estimator in\neach boosting iteration. Since the loss functions involved in this robust\nboosting algorithm are typically non-convex, a reliable initialization step is\nrequired, such as an L1 regression tree, which is also fast to compute. A\nrobust variable importance measure can also be calculated via a permutation\nprocedure. Thorough simulation studies and several data analyses show that,\nwhen no atypical observations are present, the robust boosting approach works\nas well as the standard gradient boosting with a squared loss. Furthermore,\nwhen the data contain outliers, the robust boosting estimator outperforms the\nalternatives in terms of prediction error and variable selection accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:12:45 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 21:09:17 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ju", "Xiaomeng", ""], ["Salibi\u00e1n-Barrera", "Mat\u00edas", ""]]}, {"id": "2002.02064", "submitter": "Holden Lee", "authors": "Udaya Ghai, Holden Lee, Karan Singh, Cyril Zhang, Yi Zhang", "title": "No-Regret Prediction in Marginally Stable Systems", "comments": "43 pages. Appears in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online prediction in a marginally stable linear\ndynamical system subject to bounded adversarial or (non-isotropic) stochastic\nperturbations. This poses two challenges. Firstly, the system is in general\nunidentifiable, so recent and classical results on parameter recovery do not\napply. Secondly, because we allow the system to be marginally stable, the state\ncan grow polynomially with time; this causes standard regret bounds in online\nconvex optimization to be vacuous. In spite of these challenges, we show that\nthe online least-squares algorithm achieves sublinear regret (improvable to\npolylogarithmic in the stochastic setting), with polynomial dependence on the\nsystem's parameters. This requires a refined regret analysis, including a\nstructural lemma showing the current state of the system to be a small linear\ncombination of past states, even if the state grows polynomially. By applying\nour techniques to learning an autoregressive filter, we also achieve\nlogarithmic regret in the partially observed setting under Gaussian noise, with\npolynomial dependence on the memory of the associated Kalman filter.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:53:34 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 19:48:51 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 19:08:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ghai", "Udaya", ""], ["Lee", "Holden", ""], ["Singh", "Karan", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "2002.02068", "submitter": "Shota Yasui", "authors": "Shota Yasui, Gota Morishita, Komei Fujita, Masashi Shibata", "title": "A Feedback Shift Correction in Predicting Conversion Rates under Delayed\n  Feedback", "comments": "The Web Conference 2020 (WWW '20)", "journal-ref": null, "doi": "10.1145/3366423.3380032", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In display advertising, predicting the conversion rate, that is, the\nprobability that a user takes a predefined action on an advertiser's website,\nsuch as purchasing goods is fundamental in estimating the value of displaying\nthe advertisement. However, there is a relatively long time delay between a\nclick and its resultant conversion. Because of the delayed feedback, some\npositive instances at the training period are labeled as negative because some\nconversions have not yet occurred when training data are gathered. As a result,\nthe conditional label distributions differ between the training data and the\nproduction environment. This situation is referred to as a feedback shift. We\naddress this problem by using an importance weight approach typically used for\ncovariate shift correction. We prove its consistency for the feedback shift.\nResults in both offline and online experiments show that our proposed method\noutperforms the existing method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:05:07 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Yasui", "Shota", ""], ["Morishita", "Gota", ""], ["Fujita", "Komei", ""], ["Shibata", "Masashi", ""]]}, {"id": "2002.02071", "submitter": "Jiangsheng You Dr.", "authors": "Jason You", "title": "Finite Hilbert Transform in Weighted L2 Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several new properties of weighted Hilbert transform are obtained. If mu is\nzero, two Plancherel-like equations and the isotropic properties are derived.\nFor mu is real number, a coerciveness is derived and two iterative sequences\nare constructed to find the inversion. The proposed iterative sequences are\napplicable to the case of pure imaginary constant mu=i*eta with |eta|<pi/4 .\nFor mu=0.0 and 3.0 , we present the computer simulation results by using the\nChebyshev series representation of finite Hilbert transform. The results in\nthis paper are useful to the half scan in several imaging applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:13:18 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:47:58 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["You", "Jason", ""]]}, {"id": "2002.02073", "submitter": "Jiangsheng You Dr.", "authors": "Jason You", "title": "Truncated Hilbert Transform: Uniqueness and a Chebyshev series Expansion\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.FA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a stronger uniqueness result if a function with compact support and\nits truncated Hilbert transform are known on the same interval by using the\nSokhotski-Plemelj formulas. To find a function from its truncated Hilbert\ntransform, we express them in the Chebyshev polynomial series and then suggest\ntwo methods to numerically estimate the coefficients. We present computer\nsimulation results to show that the extrapolative procedure numerically works\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:26:19 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 04:01:18 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["You", "Jason", ""]]}, {"id": "2002.02078", "submitter": "Sudam Surasinghe", "authors": "Sudam Surasinghe and Erik M. Bollt", "title": "On Geometry of Information Flow for Causal Inference", "comments": null, "journal-ref": "Entropy 2020, 22, 396", "doi": "10.3390/e22040396", "report-no": null, "categories": "cs.IT cs.CG math.DS math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is perhaps one of the most fundamental concepts in science,\nbeginning originally from the works of some of the ancient philosophers,\nthrough today, but also weaved strongly in current work from statisticians,\nmachine learning experts, and scientists from many other fields. This paper\ntakes the perspective of information flow, which includes the Nobel prize\nwinning work on Granger-causality, and the recently highly popular transfer\nentropy, these being probabilistic in nature. Our main contribution will be to\ndevelop analysis tools that will allow a geometric interpretation of\ninformation flow as a causal inference indicated by positive transfer entropy.\nWe will describe the effective dimensionality of an underlying manifold as\nprojected into the outcome space that summarizes information flow. Therefore\ncontrasting the probabilistic and geometric perspectives, we will introduce a\nnew measure of causal inference based on the fractal correlation dimension\nconditionally applied to competing explanations of future forecasts, which we\nwill write $GeoC_{y\\rightarrow x}$. This avoids some of the boundedness issues\nthat we show exist for the transfer entropy, $T_{y\\rightarrow x}$. We will\nhighlight our discussions with data developed from synthetic models of\nsuccessively more complex nature: then include the H\\'{e}non map example, and\nfinally a real physiological example relating breathing and heart rate\nfunction.\n  Keywords: Causal Inference; Transfer Entropy; Differential Entropy;\nCorrelation Dimension; Pinsker's Inequality; Frobenius-Perron operator.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:46:48 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 16:53:45 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Surasinghe", "Sudam", ""], ["Bollt", "Erik M.", ""]]}, {"id": "2002.02081", "submitter": "Nan Jiang", "authors": "Nan Jiang, Jiawei Huang", "title": "Minimax Value Interval for Off-Policy Evaluation and Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimax methods for off-policy evaluation (OPE) using value\nfunctions and marginalized importance weights. Despite that they hold promises\nof overcoming the exponential variance in traditional importance sampling,\nseveral key problems remain:\n  (1) They require function approximation and are generally biased. For the\nsake of trustworthy OPE, is there anyway to quantify the biases?\n  (2) They are split into two styles (\"weight-learning\" vs \"value-learning\").\nCan we unify them?\n  In this paper we answer both questions positively. By slightly altering the\nderivation of previous methods (one from each style; Uehara et al., 2020), we\nunify them into a single value interval that comes with a special type of\ndouble robustness: when either the value-function or the importance-weight\nclass is well specified, the interval is valid and its length quantifies the\nmisspecification of the other class. Our interval also provides a unified view\nof and new insights to some recent methods, and we further explore the\nimplications of our results on exploration and exploitation in off-policy\npolicy optimization with insufficient data coverage.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:54:11 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:56:55 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 13:55:25 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 00:41:22 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 05:12:58 GMT"}, {"version": "v6", "created": "Wed, 4 Nov 2020 23:43:32 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Jiang", "Nan", ""], ["Huang", "Jiawei", ""]]}, {"id": "2002.02085", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Shiyin Lu, Tianbao Yang", "title": "Minimizing Dynamic Regret and Adaptive Regret Simultaneously", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization is treated as the golden rule in the traditional study of\nonline learning. However, regret minimization algorithms tend to converge to\nthe static optimum, thus being suboptimal for changing environments. To address\nthis limitation, new performance measures, including dynamic regret and\nadaptive regret have been proposed to guide the design of online algorithms.\nThe former one aims to minimize the global regret with respect to a sequence of\nchanging comparators, and the latter one attempts to minimize every local\nregret with respect to a fixed comparator. Existing algorithms for dynamic\nregret and adaptive regret are developed independently, and only target one\nperformance measure. In this paper, we bridge this gap by proposing novel\nonline algorithms that are able to minimize the dynamic regret and adaptive\nregret simultaneously. In fact, our theoretical guarantee is even stronger in\nthe sense that one algorithm is able to minimize the dynamic regret over any\ninterval.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:32:37 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Zhang", "Lijun", ""], ["Lu", "Shiyin", ""], ["Yang", "Tianbao", ""]]}, {"id": "2002.02088", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Liang Li, Bingzhe Wu, Cheng Hong, Li Wang, Jun Zhou", "title": "Secure Social Recommendation based on Secret Sharing", "comments": "Accepted by ECAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, privacy preserving machine learning has been drawing much attention\nin both industry and academy. Meanwhile, recommender systems have been\nextensively adopted by many commercial platforms (e.g. Amazon) and they are\nmainly built based on user-item interactions. Besides, social platforms (e.g.\nFacebook) have rich resources of user social information. It is well known that\nsocial information, which is rich on social platforms such as Facebook, are\nuseful to recommender systems. It is anticipated to combine the social\ninformation with the user-item ratings to improve the overall recommendation\nperformance. Most existing recommendation models are built based on the\nassumptions that the social information are available. However, different\nplatforms are usually reluctant to (or cannot) share their data due to certain\nconcerns. In this paper, we first propose a SEcure SOcial RECommendation\n(SeSoRec) framework which can (1) collaboratively mine knowledge from social\nplatform to improve the recommendation performance of the rating platform, and\n(2) securely keep the raw data of both platforms. We then propose a Secret\nSharing based Matrix Multiplication (SSMM) protocol to optimize SeSoRec and\nprove its correctness and security theoretically. By applying minibatch\ngradient descent, SeSoRec has linear time complexities in terms of both\ncomputation and communication. The comprehensive experimental results on three\nreal-world datasets demonstrate the effectiveness of our proposed SeSoRec and\nSSMM.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:49:51 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 06:43:35 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Chen", "Chaochao", ""], ["Li", "Liang", ""], ["Wu", "Bingzhe", ""], ["Hong", "Cheng", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""]]}, {"id": "2002.02090", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Qian Yang, Bin Gu, Lawrence Carin. Heng Huang", "title": "Faster On-Device Training Using New Federated Momentum Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile crowdsensing has gained significant attention in recent years and has\nbecome a critical paradigm for emerging Internet of Things applications. The\nsensing devices continuously generate a significant quantity of data, which\nprovide tremendous opportunities to develop innovative intelligent\napplications. To utilize these data to train machine learning models while not\ncompromising user privacy, federated learning has become a promising solution.\nHowever, there is little understanding of whether federated learning algorithms\nare guaranteed to converge. We reconsider model averaging in federated learning\nand formulate it as a gradient-based method with biased gradients. This novel\nperspective assists analysis of its convergence rate and provides a new\ndirection for more acceleration. We prove for the first time that the federated\naveraging algorithm is guaranteed to converge for non-convex problems, without\nimposing additional assumptions. We further propose a novel accelerated\nfederated learning algorithm and provide a convergence guarantee. Simulated\nfederated learning experiments are conducted to train deep neural networks on\nbenchmark datasets, and experimental results show that our proposed method\nconverges faster than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:12:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Yang", "Qian", ""], ["Gu", "Bin", ""], ["Huang", "Lawrence Carin. Heng", ""]]}, {"id": "2002.02096", "submitter": "Sen Wang", "authors": "Sen Wang, J.Morris Chang", "title": "Privacy-Preserving Boosting in the Local Setting", "comments": "12 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, boosting is one of the most popular methods that\ndesigned to combine multiple base learners to a superior one. The well-known\nBoosted Decision Tree classifier, has been widely adopted in many areas. In the\nbig data era, the data held by individual and entities, like personal images,\nbrowsing history and census information, are more likely to contain sensitive\ninformation. The privacy concern raises when such data leaves the hand of the\nowners and be further explored or mined. Such privacy issue demands that the\nmachine learning algorithm should be privacy aware. Recently, Local\nDifferential Privacy is proposed as an effective privacy protection approach,\nwhich offers a strong guarantee to the data owners, as the data is perturbed\nbefore any further usage, and the true values never leave the hands of the\nowners. Thus the machine learning algorithm with the private data instances is\nof great value and importance. In this paper, we are interested in developing\nthe privacy-preserving boosting algorithm that a data user is allowed to build\na classifier without knowing or deriving the exact value of each data samples.\nOur experiments demonstrate the effectiveness of the proposed boosting\nalgorithm and the high utility of the learned classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:48:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Wang", "Sen", ""], ["Chang", "J. Morris", ""]]}, {"id": "2002.02112", "submitter": "Hyungrok Ham", "authors": "Hyungrok Ham, Tae Joon Jun, Daeyoung Kim", "title": "Unbalanced GANs: Pre-training the Generator of Generative Adversarial\n  Network using Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Unbalanced GANs, which pre-trains the generator of the generative\nadversarial network (GAN) using variational autoencoder (VAE). We guarantee the\nstable training of the generator by preventing the faster convergence of the\ndiscriminator at early epochs. Furthermore, we balance between the generator\nand the discriminator at early epochs and thus maintain the stabilized training\nof GANs. We apply Unbalanced GANs to well known public datasets and find that\nUnbalanced GANs reduce mode collapses. We also show that Unbalanced GANs\noutperform ordinary GANs in terms of stabilized learning, faster convergence\nand better image quality at early epochs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 06:03:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ham", "Hyungrok", ""], ["Jun", "Tae Joon", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2002.02117", "submitter": "Yuma Kinoshita", "authors": "Yuma Kinoshita and Hitoshi Kiya", "title": "Fixed smooth convolutional layer for avoiding checkerboard artifacts in\n  CNNs", "comments": "5 pages, to appear in IEEE International Conference on Acoustics,\n  Speech, and Signal Processing 2020 (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fixed convolutional layer with an order of\nsmoothness not only for avoiding checkerboard artifacts in convolutional neural\nnetworks (CNNs) but also for enhancing the performance of CNNs, where the\nsmoothness of its filter kernel can be controlled by a parameter. It is\nwell-known that a number of CNNs generate checkerboard artifacts in both of two\nprocess: forward-propagation of upsampling layers and backward-propagation of\nstrided convolutional layers. The proposed layer can perfectly prevent\ncheckerboard artifacts caused by strided convolutional layers or upsampling\nlayers including transposed convolutional layers. In an image-classification\nexperiment with four CNNs: a simple CNN, VGG8, ResNet-18, and ResNet-101,\napplying the fixed layers to these CNNs is shown to improve the classification\nperformance of all CNNs. In addition, the fixed layer are applied to generative\nadversarial networks (GANs), for the first time. From image-generation results,\na smoother fixed convolutional layer is demonstrated to enable us to improve\nthe quality of images generated with GANs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 06:36:45 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2002.02158", "submitter": "Yasuhiro Katsura", "authors": "Yasuhiro Katsura, Masato Uchida", "title": "Bridging Ordinary-Label Learning and Complementary-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A supervised learning framework has been proposed for the situation where\neach training data is provided with a complementary label that represents a\nclass to which the pattern does not belong. In the existing literature,\ncomplementary-label learning has been studied independently from ordinary-label\nlearning, which assumes that each training data is provided with a label\nrepresenting the class to which the pattern belongs. However, providing a\ncomplementary label should be treated as equivalent to providing the rest of\nall the labels as the candidates of the one true class. In this paper, we focus\non the fact that the loss functions for one-versus-all and pairwise\nclassification corresponding to ordinary-label learning and complementary-label\nlearning satisfy certain additivity and duality, and provide a framework which\ndirectly bridge those existing supervised learning frameworks. Further, we\nderive classification risk and error bound for any loss functions which satisfy\nadditivity and duality.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:54:19 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 11:48:24 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 09:11:41 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 14:06:03 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 07:56:56 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Katsura", "Yasuhiro", ""], ["Uchida", "Masato", ""]]}, {"id": "2002.02164", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Francisco Herrera", "title": "LUNAR: Cellular Automata for Drifting Data Streams", "comments": "36 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of huges volumes of data produced in the form of fast\nstreams, real-time machine learning has become a challenge of relevance\nemerging in a plethora of real-world applications. Processing such fast streams\noften demands high memory and processing resources. In addition, they can be\naffected by non-stationary phenomena (concept drift), by which learning methods\nhave to detect changes in the distribution of streaming data, and adapt to\nthese evolving conditions. A lack of efficient and scalable solutions is\nparticularly noted in real-time scenarios where computing resources are\nseverely constrained, as it occurs in networks of small, numerous,\ninterconnected processing units (such as the so-called Smart Dust, Utility Fog,\nor Swarm Robotics paradigms). In this work we propose LUNAR, a streamified\nversion of cellular automata devised to successfully meet the aforementioned\nrequirements. It is able to act as a real incremental learner while adapting to\ndrifting conditions. Extensive simulations with synthetic and real data will\nprovide evidence of its competitive behavior in terms of classification\nperformance when compared to long-established and successful online learning\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:10:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.02176", "submitter": "Guy Amit", "authors": "Guy Amit, Ishai Rosenberg, Moshe Levy, Ron Bitton, Asaf Shabtai, and\n  Yuval Elovici", "title": "GIM: Gaussian Isolation Machines", "comments": "Submitted to IJCNN2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, neural network classifiers are likely to be exposed to input\ndata that is outside of their training distribution data. Samples from outside\nthe distribution may be classified as an existing class with high probability\nby softmax-based classifiers; such incorrect classifications affect the\nperformance of the classifiers and the applications/systems that depend on\nthem. Previous research aimed at distinguishing training distribution data from\nout-of-distribution data (OOD) has proposed detectors that are external to the\nclassification method. We present Gaussian isolation machine (GIM), a novel\nhybrid (generative-discriminative) classifier aimed at solving the problem\narising when OOD data is encountered. The GIM is based on a neural network and\nutilizes a new loss function that imposes a distribution on each of the trained\nclasses in the neural network's output space, which can be approximated by a\nGaussian. The proposed GIM's novelty lies in its discriminative performance and\ngenerative capabilities, a combination of characteristics not usually seen in a\nsingle classifier. The GIM achieves state-of-the-art classification results on\nimage recognition and sentiment analysis benchmarking datasets and can also\ndeal with OOD inputs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:51:47 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:39:02 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Amit", "Guy", ""], ["Rosenberg", "Ishai", ""], ["Levy", "Moshe", ""], ["Bitton", "Ron", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.02184", "submitter": "Francisco Jesus Martinez-Murcia", "authors": "F.J. Martinez-Murcia, A. Ortiz, Marco A. Formoso, M. Lopez-Zamora,\n  J.L. Luque, A. Gim\\'enez", "title": "A Neural Approach to Ordinal Regression for the Preventive Assessment of\n  Developmental Dyslexia", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": "10.1007/978-3-030-61705-9_51", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developmental Dyslexia (DD) is a learning disability related to the\nacquisition of reading skills that affects about 5% of the population. DD can\nhave an enormous impact on the intellectual and personal development of\naffected children, so early detection is key to implementing preventive\nstrategies for teaching language. Research has shown that there may be\nbiological underpinnings to DD that affect phoneme processing, and hence these\nsymptoms may be identifiable before reading ability is acquired, allowing for\nearly intervention. In this paper we propose a new methodology to assess the\nrisk of DD before students learn to read. For this purpose, we propose a mixed\nneural model that calculates risk levels of dyslexia from tests that can be\ncompleted at the age of 5 years. Our method first trains an auto-encoder, and\nthen combines the trained encoder with an optimized ordinal regression neural\nnetwork devised to ensure consistency of predictions. Our experiments show that\nthe system is able to detect unaffected subjects two years before it can assess\nthe risk of DD based mainly on phonological processing, giving a specificity of\n0.969 and a correct rate of more than 0.92. In addition, the trained encoder\ncan be used to transform test results into an interpretable subject spatial\ndistribution that facilitates risk assessment and validates methodology.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:08:41 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 10:49:21 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Martinez-Murcia", "F. J.", ""], ["Ortiz", "A.", ""], ["Formoso", "Marco A.", ""], ["Lopez-Zamora", "M.", ""], ["Luque", "J. L.", ""], ["Gim\u00e9nez", "A.", ""]]}, {"id": "2002.02196", "submitter": "Tao Bai", "authors": "Tao Bai, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, Bo Li, Alex\n  Kot", "title": "AI-GAN: Attack-Inspired Generation of Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples, which are\ncrafted by adding imperceptible perturbations to inputs. Recently different\nattacks and strategies have been proposed, but how to generate adversarial\nexamples perceptually realistic and more efficiently remains unsolved. This\npaper proposes a novel framework called Attack-Inspired GAN (AI-GAN), where a\ngenerator, a discriminator, and an attacker are trained jointly. Once trained,\nit can generate adversarial perturbations efficiently given input images and\ntarget classes. Through extensive experiments on several popular datasets \\eg\nMNIST and CIFAR-10, AI-GAN achieves high attack success rates and reduces\ngeneration time significantly in various settings. Moreover, for the first\ntime, AI-GAN successfully scales to complicated datasets \\eg CIFAR-100 with\naround $90\\%$ success rates among all classes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:57:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 06:22:17 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bai", "Tao", ""], ["Zhao", "Jun", ""], ["Zhu", "Jinlin", ""], ["Han", "Shoudong", ""], ["Chen", "Jiefeng", ""], ["Li", "Bo", ""], ["Kot", "Alex", ""]]}, {"id": "2002.02250", "submitter": "Agust\\'in Somacal", "authors": "Agust\\'in Somacal, Yamila Barrera, Leonardo Boechi, Matthieu\n  Jonckheere, Vincent Lefieux, Dominique Picard and Ezequiel Smucler", "title": "Uncovering differential equations from data with hidden variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG nlin.CD physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SINDy is a method for learning system of differential equations from data by\nsolving a sparse linear regression optimization problem [Brunton et al., 2016].\nIn this article, we propose an extension of the SINDy method that learns\nsystems of differential equations in cases where some of the variables are not\nobserved. Our extension is based on regressing a higher order time derivative\nof a target variable onto a dictionary of functions that includes lower order\ntime derivatives of the target variable. We evaluate our method by measuring\nthe prediction accuracy of the learned dynamical systems on synthetic data and\non a real data-set of temperature time series provided by the R\\'eseau de\nTransport d'\\'Electricit\\'e (RTE). Our method provides high quality short-term\nforecasts and it is orders of magnitude faster than competing methods for\nlearning differential equations with latent variables.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:33:18 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 15:43:26 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Somacal", "Agust\u00edn", ""], ["Barrera", "Yamila", ""], ["Boechi", "Leonardo", ""], ["Jonckheere", "Matthieu", ""], ["Lefieux", "Vincent", ""], ["Picard", "Dominique", ""], ["Smucler", "Ezequiel", ""]]}, {"id": "2002.02265", "submitter": "Evin Pinar Ornek", "authors": "Evin Pinar Ornek", "title": "Zero-Shot Activity Recognition with Videos", "comments": "This is a research report done during master's studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examined the zero-shot activity recognition task with the\nusage of videos. We introduce an auto-encoder based model to construct a\nmultimodal joint embedding space between the visual and textual manifolds. On\nthe visual side, we used activity videos and a state-of-the-art 3D\nconvolutional action recognition network to extract the features. On the\ntextual side, we worked with GloVe word embeddings. The zero-shot recognition\nresults are evaluated by top-n accuracy. Then, the manifold learning ability is\nmeasured by mean Nearest Neighbor Overlap. In the end, we provide an extensive\ndiscussion over the results and the future directions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:33:10 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ornek", "Evin Pinar", ""]]}, {"id": "2002.02271", "submitter": "Dmitry Efimov", "authors": "Dmitry Efimov, Di Xu, Luyang Kong, Alexey Nefedov and Archana\n  Anandakrishnan", "title": "Using generative adversarial networks to synthesize artificial financial\n  datasets", "comments": null, "journal-ref": "Robust AI in FS 2019 : NeurIPS 2019 Workshop on Robust AI in\n  Financial Services: Data, Fairness, Explainability, Trustworthiness, and\n  Privacy, December 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) became very popular for generation of\nrealistically looking images. In this paper, we propose to use GANs to\nsynthesize artificial financial data for research and benchmarking purposes. We\ntest this approach on three American Express datasets, and show that properly\ntrained GANs can replicate these datasets with high fidelity. For our\nexperiments, we define a novel type of GAN, and suggest methods for data\npreprocessing that allow good training and testing performance of GANs. We also\ndiscuss methods for evaluating the quality of generated data, and their\ncomparison with the original real data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:25:08 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Efimov", "Dmitry", ""], ["Xu", "Di", ""], ["Kong", "Luyang", ""], ["Nefedov", "Alexey", ""], ["Anandakrishnan", "Archana", ""]]}, {"id": "2002.02274", "submitter": "Sara Ahmadian", "authors": "Sara Ahmadian, Alessandro Epasto, Ravi Kumar, Mohammad Mahdian", "title": "Fair Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study correlation clustering under fairness constraints.\nFair variants of $k$-median and $k$-center clustering have been studied\nrecently, and approximation algorithms using a notion called fairlet\ndecomposition have been proposed. We obtain approximation algorithms for fair\ncorrelation clustering under several important types of fairness constraints.\n  Our results hinge on obtaining a fairlet decomposition for correlation\nclustering by introducing a novel combinatorial optimization problem. We define\na fairlet decomposition with cost similar to the $k$-median cost and this\nallows us to obtain approximation algorithms for a wide range of fairness\nconstraints.\n  We complement our theoretical results with an in-depth analysis of our\nalgorithms on real graphs where we show that fair solutions to correlation\nclustering can be obtained with limited increase in cost compared to the\nstate-of-the-art (unfair) algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:28:21 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 22:27:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ahmadian", "Sara", ""], ["Epasto", "Alessandro", ""], ["Kumar", "Ravi", ""], ["Mahdian", "Mohammad", ""]]}, {"id": "2002.02302", "submitter": "Ziping Xu", "authors": "Ziping Xu and Ambuj Tewari", "title": "Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms and\n  Tighter Regret Bounds for the Non-Episodic Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning in non-episodic factored Markov decision\nprocesses (FMDPs). We propose two near-optimal and oracle-efficient algorithms\nfor FMDPs. Assuming oracle access to an FMDP planner, they enjoy a Bayesian and\na frequentist regret bound respectively, both of which reduce to the\nnear-optimal bound $\\widetilde{O}(DS\\sqrt{AT})$ for standard non-factored MDPs.\nWe propose a tighter connectivity measure, factored span, for FMDPs and prove a\nlower bound that depends on the factored span rather than the diameter $D$. In\norder to decrease the gap between lower and upper bounds, we propose an\nadaptation of the REGAL.C algorithm whose regret bound depends on the factored\nspan. Our oracle-efficient algorithms outperform previously proposed\nnear-optimal algorithms on computer network administration simulations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:19:53 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 03:30:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Xu", "Ziping", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2002.02318", "submitter": "Kun Ouyang", "authors": "Kun Ouyang, Yuxuan Liang, Ye Liu, Zekun Tong, Sijie Ruan, Yu Zheng,\n  and David S. Rosenblum", "title": "Fine-Grained Urban Flow Inference", "comments": "16 pages. arXiv admin note: substantial text overlap with\n  arXiv:1902.05377", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ubiquitous deployment of monitoring devices in urban flow monitoring\nsystems induces a significant cost for maintenance and operation. A technique\nis required to reduce the number of deployed devices, while preventing the\ndegeneration of data accuracy and granularity. In this paper, we present an\napproach for inferring the real-time and fine-grained crowd flows throughout a\ncity based on coarse-grained observations. This task exhibits two challenges:\nthe spatial correlations between coarse- and fine-grained urban flows, and the\ncomplexities of external impacts. To tackle these issues, we develop a model\nentitled UrbanFM which consists of two major parts: 1) an inference network to\ngenerate fine-grained flow distributions from coarse-grained inputs that uses a\nfeature extraction module and a novel distributional upsampling module; 2) a\ngeneral fusion subnet to further boost the performance by considering the\ninfluence of different external factors. This structure provides outstanding\neffectiveness and efficiency for small scale upsampling. However, the\nsingle-pass upsampling used by UrbanFM is insufficient at higher upscaling\nrates. Therefore, we further present UrbanPy, a cascading model for progressive\ninference of fine-grained urban flows by decomposing the original tasks into\nmultiple subtasks. Compared to UrbanFM, such an enhanced structure demonstrates\nfavorable performance for larger-scale inference tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 01:11:24 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ouyang", "Kun", ""], ["Liang", "Yuxuan", ""], ["Liu", "Ye", ""], ["Tong", "Zekun", ""], ["Ruan", "Sijie", ""], ["Zheng", "Yu", ""], ["Rosenblum", "David S.", ""]]}, {"id": "2002.02354", "submitter": "Abdollah Shafieezadeh", "authors": "Chi Zhang, Zeyu Wang, and Abdollah Shafieezadeh", "title": "Value of Information Analysis via Active Learning and Knowledge Sharing\n  in Error-Controlled Adaptive Kriging", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.2980228", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large uncertainties in many phenomena have challenged decision making.\nCollecting additional information to better characterize reducible\nuncertainties is among decision alternatives. Value of information (VoI)\nanalysis is a mathematical decision framework that quantifies expected\npotential benefits of new data and assists with optimal allocation of resources\nfor information collection. However, analysis of VoI is computational very\ncostly because of the underlying Bayesian inference especially for\nequality-type information. This paper proposes the first surrogate-based\nframework for VoI analysis. Instead of modeling the limit state functions\ndescribing events of interest for decision making, which is commonly pursued in\nsurrogate model-based reliability methods, the proposed framework models system\nresponses. This approach affords sharing equality-type information from\nobservations among surrogate models to update likelihoods of multiple events of\ninterest. Moreover, two knowledge sharing schemes called model and training\npoints sharing are proposed to most effectively take advantage of the knowledge\noffered by costly model evaluations. Both schemes are integrated with an error\nrate-based adaptive training approach to efficiently generate accurate Kriging\nsurrogate models. The proposed VoI analysis framework is applied for an optimal\ndecision-making problem involving load testing of a truss bridge. While\nstate-of-the-art methods based on importance sampling and adaptive Kriging\nMonte Carlo simulation are unable to solve this problem, the proposed method is\nshown to offer accurate and robust estimates of VoI with a limited number of\nmodel evaluations. Therefore, the proposed method facilitates the application\nof VoI for complex decision problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:58:27 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 02:30:25 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zhang", "Chi", ""], ["Wang", "Zeyu", ""], ["Shafieezadeh", "Abdollah", ""]]}, {"id": "2002.02374", "submitter": "Yun Yuan", "authors": "Yun Yuan, Xianfeng Terry Yang, Zhao Zhang, Shandian Zhe", "title": "Macroscopic Traffic Flow Modeling with Physics Regularized Gaussian\n  Process: A New Insight into Machine Learning Applications", "comments": "30 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wide implementation of machine learning (ML) techniques in\ntraffic flow modeling recently, those data-driven approaches often fall short\nof accuracy in the cases with a small or noisy dataset. To address this issue,\nthis study presents a new modeling framework, named physics regularized machine\nlearning (PRML), to encode classical traffic flow models (referred as physical\nmodels) into the ML architecture and to regularize the ML training process.\nMore specifically, a stochastic physics regularized Gaussian process (PRGP)\nmodel is developed and a Bayesian inference algorithm is used to estimate the\nmean and kernel of the PRGP. A physical regularizer based on macroscopic\ntraffic flow models is also developed to augment the estimation via a shadow GP\nand an enhanced latent force model is used to encode physical knowledge into\nstochastic processes. Based on the posterior regularization inference\nframework, an efficient stochastic optimization algorithm is also developed to\nmaximize the evidence lowerbound of the system likelihood. To prove the\neffectiveness of the proposed model, this paper conducts empirical studies on a\nreal-world dataset which is collected from a stretch of I-15 freeway, Utah.\nResults show the new PRGP model can outperform the previous compatible methods,\nsuch as calibrated pure physical models and pure machine learning methods, in\nestimation precision and input robustness.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:22:20 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Yuan", "Yun", ""], ["Yang", "Xianfeng Terry", ""], ["Zhang", "Zhao", ""], ["Zhe", "Shandian", ""]]}, {"id": "2002.02383", "submitter": "Dario Zanca", "authors": "Dario Zanca, Alessandra Rufa", "title": "1-D Convlutional Neural Networks for the Analysis of Pupil Size\n  Variations in Scotopic Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that a systematic analysis of the pupil size variations,\nrecorded by means of an eye-tracker, is a rich source of information about a\nsubject's arousal and cognitive state. Current methods for pupil analysis are\nlimited to descriptive statistics, struggle in handling the wide inter-subjects\nvariability and must be coupled with a long series of pre-processing signal\noperations. In this we present a data-driven approach in which 1-D\nConvolutional Neural Networks are applied directly to the raw pupil size data.\nTo test its effectiveness, we apply our method in a binary classification task\nwith two different groups of subjects: a group of elderly patients with\nParkinson disease (PDs), a condition in which pupil abnormalities have been\nextensively reported, and a group of healthy adults subjects (HCs). Long-range\nregistration (10 minutes) of the pupil size were collected in scotopic\nconditions (complete darkness, 0 lux). 1-D convolutional neural network models\nare trained for classification of short-range sequences (10 to 60 seconds of\nregistration). The model provides prediction with high average accuracy on a\nhold out test set. Dataset and codes are released for reproducibility and\nbenchmarking purposes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:25:37 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 15:49:51 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zanca", "Dario", ""], ["Rufa", "Alessandra", ""]]}, {"id": "2002.02385", "submitter": "Adam Marblestone", "authors": "Adam Marblestone, Yan Wu, Greg Wayne", "title": "Product Kanerva Machines: Factorized Bayesian Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ideal cognitively-inspired memory system would compress and organize\nincoming items. The Kanerva Machine (Wu et al, 2018) is a Bayesian model that\nnaturally implements online memory compression. However, the organization of\nthe Kanerva Machine is limited by its use of a single Gaussian random matrix\nfor storage. Here we introduce the Product Kanerva Machine, which dynamically\ncombines many smaller Kanerva Machines. Its hierarchical structure provides a\nprincipled way to abstract invariant features and gives scaling and capacity\nadvantages over single Kanerva Machines. We show that it can exhibit\nunsupervised clustering, find sparse and combinatorial allocation patterns, and\ndiscover spatial tunings that approximately factorize simple images by object.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:29:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Marblestone", "Adam", ""], ["Wu", "Yan", ""], ["Wayne", "Greg", ""]]}, {"id": "2002.02390", "submitter": "Sebastien Gerchinovitz", "authors": "Cl\\'ement Bouttier, Tommaso Cesari (ANITI, TSE, UNIMI), S\\'ebastien\n  Gerchinovitz (IMT)", "title": "Regret analysis of the Piyavskii-Shubert algorithm for global Lipschitz\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a non-concave Lipschitz multivariate\nfunction f over a compact domain. We provide regret guarantees (i.e.,\noptimization error bounds) for a very natural algorithm originally designed by\nPiyavskii and Shubert in 1972. Our results hold in a general setting in which\nvalues of f can only be accessed approximately. In particular, they yield\nstate-of-the-art regret bounds both when f is observed exactly and when\nevaluations are perturbed by an independent subgaussian noise.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:31:27 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Bouttier", "Cl\u00e9ment", "", "ANITI, TSE, UNIMI"], ["Cesari", "Tommaso", "", "ANITI, TSE, UNIMI"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"]]}, {"id": "2002.02400", "submitter": "Brian Kim", "authors": "Brian Kim and Yalin E. Sagduyu and Kemal Davaslioglu and Tugba Erpek\n  and Sennur Ulukus", "title": "Over-the-Air Adversarial Attacks on Deep Learning Based Modulation\n  Classifier over Wireless Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless communication system that consists of a transmitter, a\nreceiver, and an adversary. The transmitter transmits signals with different\nmodulation types, while the receiver classifies its received signals to\nmodulation types using a deep learning-based classifier. In the meantime, the\nadversary makes over-the-air transmissions that are received as superimposed\nwith the transmitter's signals to fool the classifier at the receiver into\nmaking errors. While this evasion attack has received growing interest\nrecently, the channel effects from the adversary to the receiver have been\nignored so far such that the previous attack mechanisms cannot be applied under\nrealistic channel effects. In this paper, we present how to launch a realistic\nevasion attack by considering channels from the adversary to the receiver. Our\nresults show that modulation classification is vulnerable to an adversarial\nattack over a wireless channel that is modeled as Rayleigh fading with path\nloss and shadowing. We present various adversarial attacks with respect to\navailability of information about channel, transmitter input, and classifier\narchitecture. First, we present two types of adversarial attacks, namely a\ntargeted attack (with minimum power) and non-targeted attack that aims to\nchange the classification to a target label or to any other label other than\nthe true label, respectively. Both are white-box attacks that are transmitter\ninput-specific and use channel information. Then we introduce an algorithm to\ngenerate adversarial attacks using limited channel information where the\nadversary only knows the channel distribution. Finally, we present a black-box\nuniversal adversarial perturbation (UAP) attack where the adversary has limited\nknowledge about both channel and transmitter input.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:45:43 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 17:35:34 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2002.02402", "submitter": "Hang Zhao", "authors": "Hang Zhao", "title": "Neural network with data augmentation in multi-objective prediction of\n  multi-stage pump", "comments": "13 pages, 13figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-objective prediction method of multi-stage pump method based on\nneural network with data augmentation is proposed. In order to study the highly\nnonlinear relationship between key design variables and centrifugal pump\nexternal characteristic values (head and power), the neural network model (NN)\nis built in comparison with the quadratic response surface model (RSF), the\nradial basis Gaussian response surface model (RBF), and the Kriging model\n(KRG). The numerical model validation experiment of another type of single\nstage centrifugal pump showed that numerical model based on CFD is quite\naccurate and fair. All of prediction models are trained by 60 samples under the\ndifferent combination of three key variables in design range respectively. The\naccuracy of the head and power based on the four predictions models are\nanalyzed comparing with the CFD simulation values. The results show that the\nneural network model has better performance in all external characteristic\nvalues comparing with other three surrogate models. Finally, a neural network\nmodel based on data augmentation (NNDA) is proposed for the reason that\nsimulation cost is too high and data is scarce in mechanical simulation field\nespecially in CFD problems. The model with data augmentation can triple the\ndata by interpolation at each sample point of different attributes. It shows\nthat the performance of neural network model with data augmentation is better\nthan former neural network model. Therefore, the prediction ability of NN is\nenhanced without more simulation costs. With data augmentation it can be a\nbetter prediction model used in solving the optimization problems of multistage\npump for next optimization and generalized to finite element analysis\noptimization problems in future.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:23:42 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Zhao", "Hang", ""]]}, {"id": "2002.02405", "submitter": "Sebastian Nowozin", "authors": "Florian Wenzel, Kevin Roth, Bastiaan S. Veeling, Jakub\n  \\'Swi\\k{a}tkowski, Linh Tran, Stephan Mandt, Jasper Snoek, Tim Salimans,\n  Rodolphe Jenatton, Sebastian Nowozin", "title": "How Good is the Bayes Posterior in Deep Neural Networks Really?", "comments": "Full version (main paper and appendix) of the ICML 2020 publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past five years the Bayesian deep learning community has developed\nincreasingly accurate and efficient approximate inference procedures that allow\nfor Bayesian inference in deep neural networks. However, despite this\nalgorithmic progress and the promise of improved uncertainty quantification and\nsample efficiency there are---as of early 2020---no publicized deployments of\nBayesian neural networks in industrial practice. In this work we cast doubt on\nthe current understanding of Bayes posteriors in popular deep neural networks:\nwe demonstrate through careful MCMC sampling that the posterior predictive\ninduced by the Bayes posterior yields systematically worse predictions compared\nto simpler methods including point estimates obtained from SGD. Furthermore, we\ndemonstrate that predictive performance is improved significantly through the\nuse of a \"cold posterior\" that overcounts evidence. Such cold posteriors\nsharply deviate from the Bayesian paradigm but are commonly used as heuristic\nin Bayesian deep learning papers. We put forward several hypotheses that could\nexplain cold posteriors and evaluate the hypotheses through experiments. Our\nwork questions the goal of accurate posterior approximations in Bayesian deep\nlearning: If the true Bayes posterior is poor, what is the use of more accurate\napproximations? Instead, we argue that it is timely to focus on understanding\nthe origin of the improved performance of cold posteriors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:38:48 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 22:18:12 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wenzel", "Florian", ""], ["Roth", "Kevin", ""], ["Veeling", "Bastiaan S.", ""], ["\u015awi\u0105tkowski", "Jakub", ""], ["Tran", "Linh", ""], ["Mandt", "Stephan", ""], ["Snoek", "Jasper", ""], ["Salimans", "Tim", ""], ["Jenatton", "Rodolphe", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "2002.02417", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Chi Jin and Michael. I. Jordan", "title": "Near-Optimal Algorithms for Minimax Optimization", "comments": "Accepted by COLT 2020; Improve the writing and fix some confusing\n  parts in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper resolves a longstanding open question pertaining to the design of\nnear-optimal first-order algorithms for smooth and\nstrongly-convex-strongly-concave minimax problems. Current state-of-the-art\nfirst-order algorithms find an approximate Nash equilibrium using\n$\\tilde{O}(\\kappa_{\\mathbf x}+\\kappa_{\\mathbf y})$ or\n$\\tilde{O}(\\min\\{\\kappa_{\\mathbf x}\\sqrt{\\kappa_{\\mathbf y}},\n\\sqrt{\\kappa_{\\mathbf x}}\\kappa_{\\mathbf y}\\})$ gradient evaluations, where\n$\\kappa_{\\mathbf x}$ and $\\kappa_{\\mathbf y}$ are the condition numbers for the\nstrong-convexity and strong-concavity assumptions. A gap still remains between\nthese results and the best existing lower bound\n$\\tilde{\\Omega}(\\sqrt{\\kappa_{\\mathbf x}\\kappa_{\\mathbf y}})$. This paper\npresents the first algorithm with $\\tilde{O}(\\sqrt{\\kappa_{\\mathbf\nx}\\kappa_{\\mathbf y}})$ gradient complexity, matching the lower bound up to\nlogarithmic factors. Our algorithm is designed based on an accelerated proximal\npoint method and an accelerated solver for minimax proximal steps. It can be\neasily extended to the settings of strongly-convex-concave, convex-concave,\nnonconvex-strongly-concave, and nonconvex-concave functions. This paper also\npresents algorithms that match or outperform all existing methods in these\nsettings in terms of gradient complexity, up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:49:09 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:00:36 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:15:15 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 01:40:41 GMT"}, {"version": "v5", "created": "Sun, 14 Jun 2020 20:00:53 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 17:48:41 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Tianyi", ""], ["Jin", "Chi", ""], ["Jordan", "Michael. I.", ""]]}, {"id": "2002.02428", "submitter": "George Papamakarios", "authors": "Danilo Jimenez Rezende, George Papamakarios, S\\'ebastien Racani\\`ere,\n  Michael S. Albergo, Gurtej Kanwar, Phiala E. Shanahan, Kyle Cranmer", "title": "Normalizing Flows on Tori and Spheres", "comments": "Accepted to the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a powerful tool for building expressive distributions\nin high dimensions. So far, most of the literature has concentrated on learning\nflows on Euclidean spaces. Some problems however, such as those involving\nangles, are defined on spaces with more complex geometries, such as tori or\nspheres. In this paper, we propose and compare expressive and numerically\nstable flows on such spaces. Our flows are built recursively on the dimension\nof the space, starting from flows on circles, closed intervals or spheres.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:24:06 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 16:48:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Papamakarios", "George", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Albergo", "Michael S.", ""], ["Kanwar", "Gurtej", ""], ["Shanahan", "Phiala E.", ""], ["Cranmer", "Kyle", ""]]}, {"id": "2002.02431", "submitter": "Ilqar Ramazanli", "authors": "Ilqar ramazanli, Barnabas Poczos", "title": "Optimal Adaptive Matrix Completion", "comments": "-", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of exact completion for $m \\times n$ sized matrix of\nrank r with the adaptive sampling method. We introduce a relation of the exact\ncompletion problem with the sparsest vector of column and row spaces (which we\ncall sparsity-number here). Using this relation, we propose matrix completion\nalgorithms that exactly recovers the target matrix. These algorithms are\nsuperior to previous works in two important ways. First, our algorithms exactly\nrecover $\\mu_0$-coherent column space matrices by probability at least\n$1-\\epsilon$ using much smaller observations complexity than -\n$\\mathcal{O}(\\mu_0 rn \\mathrm{log}\\frac{r}{\\epsilon})$ - the state of art.\nSpecifically, many of the previous adaptive sampling methods require to observe\nthe entire matrix when the column space is highly coherent. However, we show\nthat our method is still able to recover this type of matrices by observing a\nsmall fraction of entries under many scenarios. Second, we propose an exact\ncompletion algorithm, which requires minimal pre-information as either row or\ncolumn space is not being highly coherent. We provide an extension of these\nalgorithms that is robust to sparse random noise. Besides, we propose an\nadditional low-rank estimation algorithm that is robust to any small noise by\nadaptively studying the shape of column space. At the end of the paper, we\nprovide experimental results that illustrate the strength of the algorithms\nproposed here.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:31:47 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["ramazanli", "Ilqar", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2002.02450", "submitter": "Pavel Gulyaev", "authors": "Pavel Gulyaev, Eugenia Elistratova, Vasily Konovalov, Yuri Kuratov,\n  Leonid Pugachev, Mikhail Burtsev", "title": "Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue State Tracking (DST) is a core component of virtual assistants such\nas Alexa or Siri. To accomplish various tasks, these assistants need to support\nan increasing number of services and APIs. The Schema-Guided State Tracking\ntrack of the 8th Dialogue System Technology Challenge highlighted the DST\nproblem for unseen services. The organizers introduced the Schema-Guided\nDialogue (SGD) dataset with multi-domain conversations and released a zero-shot\ndialogue state tracking model. In this work, we propose a GOaL-Oriented\nMulti-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures\nfor reading comprehension question answering systems. The model \"queries\"\ndialogue history with descriptions of slots and services as well as possible\nvalues of slots. This allows to transfer slot values in multi-domain dialogues\nand have a capability to scale to unseen slot types. Our model achieves a joint\ngoal accuracy of 53.97% on the SGD dataset, outperforming the baseline model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:56:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Gulyaev", "Pavel", ""], ["Elistratova", "Eugenia", ""], ["Konovalov", "Vasily", ""], ["Kuratov", "Yuri", ""], ["Pugachev", "Leonid", ""], ["Burtsev", "Mikhail", ""]]}, {"id": "2002.02460", "submitter": "Ezequiel Alvarez", "authors": "Ezequiel Alvarez (ICAS), Federico Lamagna (CAB), Cesar Miquel\n  (Easytech) and Manuel Szewc (ICAS)", "title": "Intelligent Arxiv: Sort daily papers by learning users topics preference", "comments": "We are open to new ideas and to scientists and institutions wishing\n  to collaborate and/or partner in further improvements for this service. With\n  this tool the time a paper is sent is irrelevant for its order of appearance", "journal-ref": null, "doi": null, "report-no": "ICAS 047/20", "categories": "cs.LG astro-ph.HE gr-qc hep-ph hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current daily paper releases are becoming increasingly large and areas of\nresearch are growing in diversity. This makes it harder for scientists to keep\nup to date with current state of the art and identify relevant work within\ntheir lines of interest. The goal of this article is to address this problem\nusing Machine Learning techniques. We model a scientific paper to be built as a\ncombination of different scientific knowledge from diverse topics into a new\nproblem. In light of this, we implement the unsupervised Machine Learning\ntechnique of Latent Dirichlet Allocation (LDA) on the corpus of papers in a\ngiven field to: i) define and extract underlying topics in the corpus; ii) get\nthe topics weight vector for each paper in the corpus; and iii) get the topics\nweight vector for new papers. By registering papers preferred by a user, we\nbuild a user vector of weights using the information of the vectors of the\nselected papers. Hence, by performing an inner product between the user vector\nand each paper in the daily Arxiv release, we can sort the papers according to\nthe user preference on the underlying topics.\n  We have created the website IArxiv.org where users can read sorted daily\nArxiv releases (and more) while the algorithm learns each users preference,\nyielding a more accurate sorting every day. Current IArxiv.org version runs on\nArxiv categories astro-ph, gr-qc, hep-ph and hep-th and we plan to extend to\nothers. We propose several new useful and relevant implementations to be\nadditionally developed as well as new Machine Learning techniques beyond LDA to\nfurther improve the accuracy of this new tool.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 19:00:02 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Alvarez", "Ezequiel", "", "ICAS"], ["Lamagna", "Federico", "", "CAB"], ["Miquel", "Cesar", "", "Easytech"], ["Szewc", "Manuel", "", "ICAS"]]}, {"id": "2002.02492", "submitter": "Sean Welleck", "authors": "Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang,\n  Kyunghyun Cho", "title": "Consistency of a Recurrent Language Model With Respect to Incomplete\n  Decoding", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite strong performance on a variety of tasks, neural sequence models\ntrained with maximum likelihood have been shown to exhibit issues such as\nlength bias and degenerate repetition. We study the related issue of receiving\ninfinite-length sequences from a recurrent language model when using common\ndecoding algorithms. To analyze this issue, we first define inconsistency of a\ndecoding algorithm, meaning that the algorithm can yield an infinite-length\nsequence that has zero probability under the model. We prove that commonly used\nincomplete decoding algorithms - greedy search, beam search, top-k sampling,\nand nucleus sampling - are inconsistent, despite the fact that recurrent\nlanguage models are trained to produce sequences of finite length. Based on\nthese insights, we propose two remedies which address inconsistency: consistent\nvariants of top-k and nucleus sampling, and a self-terminating recurrent\nlanguage model. Empirical results show that inconsistency occurs in practice,\nand that the proposed methods prevent inconsistency.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 19:56:15 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 22:36:49 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Welleck", "Sean", ""], ["Kulikov", "Ilia", ""], ["Kim", "Jaedeok", ""], ["Pang", "Richard Yuanzhe", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2002.02497", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Mohammad Hashir and Rupert Brooks and Hadrien\n  Bertrand", "title": "On the limits of cross-domain generalization in automated X-ray\n  prediction", "comments": "Full paper at MIDL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This large scale study focuses on quantifying what X-rays diagnostic\nprediction tasks generalize well across multiple different datasets. We present\nevidence that the issue of generalization is not due to a shift in the images\nbut instead a shift in the labels. We study the cross-domain performance,\nagreement between models, and model representations. We find interesting\ndiscrepancies between performance and agreement where models which both achieve\ngood performance disagree in their predictions as well as models which agree\nyet achieve poor performance. We also test for concept similarity by\nregularizing a network to group tasks across multiple datasets together and\nobserve variation across the tasks. All code is made available online and data\nis publicly available: https://github.com/mlmed/torchxrayvision\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:07:54 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 21:40:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Hashir", "Mohammad", ""], ["Brooks", "Rupert", ""], ["Bertrand", "Hadrien", ""]]}, {"id": "2002.02508", "submitter": "Victoria Kostina", "authors": "Chung-Yi Lin, Victoria Kostina, and Babak Hassibi", "title": "Differentially Quantized Gradient Methods", "comments": "Extended version of the paper accepted to ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers quantized distributed optimization algorithms in the\nparameter server framework of distributed training. We introduce the principle\nwe call Differential Quantization (DQ) that prescribes that the past\nquantization errors should be compensated in such a way as to direct the\ndescent trajectory of a quantized algorithm towards that of its unquantized\ncounterpart. Assuming that the objective function is smooth and strongly\nconvex, we prove that in the limit of large problem dimension, Differentially\nQuantized Gradient Descent (DQ-GD) attains a linear contraction factor of\n$\\max\\{\\sigma_{\\mathrm{GD}}, 2^{-R}\\}$, where $\\sigma_{\\mathrm{GD}}$ is the\ncontraction factor of unquantized gradient descent (GD). Thus at any\n$R\\geq\\log_2 1 /\\sigma_{\\mathrm{GD}}$ bits, the contraction factor of DQ-GD is\nthe same as that of unquantized GD, i.e., there is no loss due to quantization.\nWe show a converse demonstrating that no quantized gradient descent algorithm\ncan converge faster than $\\max\\{\\sigma_{\\mathrm{GD}}, 2^{-R}\\}$. In contrast,\nnaively quantized GD where the worker directly quantizes the gradient barely\nattains $\\sigma_{\\mathrm{GD}} + 2^{-R}$. The principle of differential\nquantization continues to apply to gradient methods with momentum such as\nNesterov's accelerated gradient descent, and Polyak's heavy ball method. For\nthese algorithms as well, if the rate is above a certain threshold, there is no\nloss in contraction factor obtained by the differentially quantized algorithm\ncompared to its unquantized counterpart, and furthermore, the differentially\nquantized heavy ball method attains the optimal contraction achievable among\nall (even unquantized) gradient methods. Experimental results on both simulated\nand real-world least-squares problems validate our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:40:53 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 21:03:45 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 21:00:33 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lin", "Chung-Yi", ""], ["Kostina", "Victoria", ""], ["Hassibi", "Babak", ""]]}, {"id": "2002.02515", "submitter": "Fenglei Fan", "authors": "Feng-Lei Fan, Rongjie Lai, Ge Wang", "title": "Quasi-Equivalence of Width and Depth of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classic studies proved that wide networks allow universal\napproximation, recent research and successes of deep learning demonstrate the\npower of the network depth. Based on a symmetric consideration, we investigate\nif the design of artificial neural networks should have a directional\npreference, and what the mechanism of interaction is between the width and\ndepth of a network. We address this fundamental question by establishing a\nquasi-equivalence between the width and depth of ReLU networks. Specifically,\nwe formulate a transformation from an arbitrary ReLU network to a wide network\nand a deep network for either regression or classification so that an\nessentially same capability of the original network can be implemented. That\nis, a deep regression/classification ReLU network has a wide equivalent, and\nvice versa, subject to an arbitrarily small error. Interestingly, the\nquasi-equivalence between wide and deep classification ReLU networks is a\ndata-driven version of the De Morgan law.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:17:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 21:40:03 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 13:08:47 GMT"}, {"version": "v4", "created": "Sun, 20 Sep 2020 01:50:47 GMT"}, {"version": "v5", "created": "Sun, 4 Oct 2020 21:16:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Fan", "Feng-Lei", ""], ["Lai", "Rongjie", ""], ["Wang", "Ge", ""]]}, {"id": "2002.02518", "submitter": "Jack Parker-Holder", "authors": "Jack Parker-Holder and Vu Nguyen and Stephen Roberts", "title": "Provably Efficient Online Hyperparameter Optimization with\n  Population-Based Bandits", "comments": "Camera-ready version, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the recent triumphs in machine learning are dependent on well-tuned\nhyperparameters. This is particularly prominent in reinforcement learning (RL)\nwhere a small change in the configuration can lead to failure. Despite the\nimportance of tuning hyperparameters, it remains expensive and is often done in\na naive and laborious way. A recent solution to this problem is Population\nBased Training (PBT) which updates both weights and hyperparameters in a single\ntraining run of a population of agents. PBT has been shown to be particularly\neffective in RL, leading to widespread use in the field. However, PBT lacks\ntheoretical guarantees since it relies on random heuristics to explore the\nhyperparameter space. This inefficiency means it typically requires vast\ncomputational resources, which is prohibitive for many small and medium sized\nlabs. In this work, we introduce the first provably efficient PBT-style\nalgorithm, Population-Based Bandits (PB2). PB2 uses a probabilistic model to\nguide the search in an efficient way, making it possible to discover high\nperforming hyperparameter configurations with far fewer agents than typically\nrequired by PBT. We show in a series of RL experiments that PB2 is able to\nachieve high performance with a modest computational budget.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:27:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 20:34:18 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 09:18:31 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 17:12:31 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Parker-Holder", "Jack", ""], ["Nguyen", "Vu", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.02525", "submitter": "Seth Strimas-Mackey", "authors": "Florentina Bunea, Seth Strimas-Mackey, Marten Wegkamp", "title": "Interpolating Predictors in High-Dimensional Factor Regression", "comments": "47 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies finite-sample properties of the risk of the minimum-norm\ninterpolating predictor in high-dimensional regression models. If the effective\nrank of the covariance matrix $\\Sigma$ of the $p$ regression features is much\nlarger than the sample size $n$, we show that the min-norm interpolating\npredictor is not desirable, as its risk approaches the risk of trivially\npredicting the response by 0. However, our detailed finite-sample analysis\nreveals, surprisingly, that this behavior is not present when the regression\nresponse and the features are {\\it jointly} low-dimensional, following a widely\nused factor regression model. Within this popular model class, and when the\neffective rank of $\\Sigma$ is smaller than $n$, while still allowing for $p \\gg\nn$, both the bias and the variance terms of the excess risk can be controlled,\nand the risk of the minimum-norm interpolating predictor approaches optimal\nbenchmarks. Moreover, through a detailed analysis of the bias term, we exhibit\nmodel classes under which our upper bound on the excess risk approaches zero,\nwhile the corresponding upper bound in the recent work arXiv:1906.11300\ndiverges. Furthermore, we show that the minimum-norm interpolating predictor\nanalyzed under the factor regression model, despite being model-agnostic and\ndevoid of tuning parameters, can have similar risk to predictors based on\nprincipal components regression and ridge regression, and can improve over\nLASSO based predictors, in the high-dimensional regime.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 22:08:36 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 16:52:54 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 22:48:52 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Bunea", "Florentina", ""], ["Strimas-Mackey", "Seth", ""], ["Wegkamp", "Marten", ""]]}, {"id": "2002.02527", "submitter": "Antoine Delplace", "authors": "Antoine Delplace", "title": "Synthetic Magnetic Resonance Images with Generative Adversarial Networks", "comments": "4 pages, 1 figure, UQ Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is essential for medical research to increase the size of\ntraining datasets and achieve better results. In this work, we experiment three\nGAN architectures with different loss functions to generate new brain MRIs. The\nresults show the importance of hyperparameter tuning and the use of mini-batch\nsimilarity layer in the Discriminator and gradient penalty in the loss function\nto achieve convergence with high quality and realism. Moreover, huge\ncomputation time is needed to generate indistinguishable images from the\noriginal dataset.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 11:00:32 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Delplace", "Antoine", ""]]}, {"id": "2002.02528", "submitter": "Zhen Chen", "authors": "Zhen Chen and Dongbin Xiu", "title": "On generalized residue network for deep learning of unknown dynamical\n  systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2021.110362", "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general numerical approach for learning unknown dynamical\nsystems using deep neural networks (DNNs). Our method is built upon recent\nstudies that identified the residue network (ResNet) as an effective neural\nnetwork structure. In this paper, we present a generalized ResNet framework and\nbroadly define residue as the discrepancy between observation data and\nprediction made by another model, which can be an existing coarse model or\nreduced-order model. In this case, the generalized ResNet serves as a model\ncorrection to the existing model and recovers the unresolved dynamics. When an\nexisting coarse model is not available, we present numerical strategies for\nfast creation of coarse models, to be used in conjunction with the generalized\nResNet. These coarse models are constructed using the same data set and thus do\nnot require additional resources. The generalized ResNet is capable of learning\nthe underlying unknown equations and producing predictions with accuracy higher\nthan the standard ResNet structure. This is demonstrated via several numerical\nexamples, including long-term prediction of a chaotic system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:50:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chen", "Zhen", ""], ["Xiu", "Dongbin", ""]]}, {"id": "2002.02533", "submitter": "Burak \\c{C}akmak", "authors": "Manfred Opper and Burak \\c{C}akmak", "title": "Understanding the dynamics of message passing algorithms: a free\n  probability heuristics", "comments": "11 pages, 2 figures. Presented at the conference \"Random Matrix\n  Theory: Applications in the Information Era'' 2019 Krak\\'{o}w", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use freeness assumptions of random matrix theory to analyze the dynamical\nbehavior of inference algorithms for probabilistic models with dense coupling\nmatrices in the limit of large systems. For a toy Ising model, we are able to\nrecover previous results such as the property of vanishing effective memories\nand the analytical convergence rate of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:50:31 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Opper", "Manfred", ""], ["\u00c7akmak", "Burak", ""]]}, {"id": "2002.02547", "submitter": "Didrik Nielsen", "authors": "Didrik Nielsen, Ole Winther", "title": "Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow models have recently made great progress at modeling ordinal discrete\ndata such as images and audio. Due to the continuous nature of flow models,\ndequantization is typically applied when using them for such discrete data,\nresulting in lower bound estimates of the likelihood. In this paper, we\nintroduce subset flows, a class of flows that can tractably transform finite\nvolumes and thus allow exact computation of likelihoods for discrete data.\nBased on subset flows, we identify ordinal discrete autoregressive models,\nincluding WaveNets, PixelCNNs and Transformers, as single-layer flows. We use\nthe flow formulation to compare models trained and evaluated with either the\nexact likelihood or its dequantization lower bound. Finally, we study\nmultilayer flows composed of PixelCNNs and non-autoregressive coupling layers\nand demonstrate state-of-the-art results on CIFAR-10 for flow models trained\nwith dequantization.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 22:58:51 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:04:08 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 17:05:37 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Nielsen", "Didrik", ""], ["Winther", "Ole", ""]]}, {"id": "2002.02557", "submitter": "Amila Silva", "authors": "Amila Silva and Pei-Chi Lo and Ee-Peng Lim", "title": "JPLink: On Linking Jobs to Vocational Interest Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking job seekers with relevant jobs requires matching based on not only\nskills, but also personality types. Although the Holland Code also known as\nRIASEC has frequently been used to group people by their suitability for six\ndifferent categories of occupations, the RIASEC category labels of individual\njobs are often not found in job posts. This is attributed to significant manual\nefforts required for assigning job posts with RIASEC labels. To cope with\nassigning massive number of jobs with RIASEC labels, we propose JPLink, a\nmachine learning approach using the text content in job titles and job\ndescriptions. JPLink exploits domain knowledge available in an\noccupation-specific knowledge base known as O*NET to improve feature\nrepresentation of job posts. To incorporate relative ranking of RIASEC labels\nof each job, JPLink proposes a listwise loss function inspired by learning to\nrank. Both our quantitative and qualitative evaluations show that JPLink\noutperforms conventional baselines. We conduct an error analysis on JPLink's\npredictions to show that it can uncover label errors in existing job posts.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 23:56:46 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Silva", "Amila", ""], ["Lo", "Pei-Chi", ""], ["Lim", "Ee-Peng", ""]]}, {"id": "2002.02561", "submitter": "Blake Bordelon", "authors": "Blake Bordelon, Abdulkadir Canatar, Cengiz Pehlevan", "title": "Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural\n  Networks", "comments": "ICML 2020 Update: Updated section on asymptotics generalization error\n  for power law spectra, finding agreement with Spigler, Geiger, Wyart 2019\n  arXiv:1905.10843. Added a section on Discrete measures and an MNIST\n  Experiment. Eigenvalue problem can be approximated by Kernel PCA. Typo fixed\n  on 2/25/2021", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:1024-1034, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive analytical expressions for the generalization performance of kernel\nregression as a function of the number of training samples using theoretical\nmethods from Gaussian processes and statistical physics. Our expressions apply\nto wide neural networks due to an equivalence between training them and kernel\nregression with the Neural Tangent Kernel (NTK). By computing the decomposition\nof the total generalization error due to different spectral components of the\nkernel, we identify a new spectral principle: as the size of the training set\ngrows, kernel machines and neural networks fit successively higher spectral\nmodes of the target function. When data are sampled from a uniform distribution\non a high-dimensional hypersphere, dot product kernels, including NTK, exhibit\nlearning stages where different frequency modes of the target function are\nlearned. We verify our theory with simulations on synthetic data and MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:03:40 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 02:38:09 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 21:32:34 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 00:06:11 GMT"}, {"version": "v5", "created": "Thu, 13 Aug 2020 21:05:27 GMT"}, {"version": "v6", "created": "Thu, 27 Aug 2020 17:13:23 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 18:40:10 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Bordelon", "Blake", ""], ["Canatar", "Abdulkadir", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2002.02568", "submitter": "Wei Li", "authors": "Wei Li (1), Amin Kiaghadi (1), Clint N. Dawson (1) ((1) Oden Institute\n  for Computational Engineering and Sciences, The University of Texas at\n  Austin, Austin, TX)", "title": "High Temporal Resolution Rainfall Runoff Modelling Using\n  Long-Short-Term-Memory (LSTM) Networks", "comments": null, "journal-ref": null, "doi": "10.1007/s00521-020-05010-6", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient models for rainfall runoff (RR) simulations are\ncrucial for flood risk management. Most rainfall models in use today are\nprocess-driven; i.e. they solve either simplified empirical formulas or some\nvariation of the St. Venant (shallow water) equations. With the development of\nmachine-learning techniques, we may now be able to emulate rainfall models\nusing, for example, neural networks. In this study, a data-driven RR model\nusing a sequence-to-sequence Long-short-Term-Memory (LSTM) network was\nconstructed. The model was tested for a watershed in Houston, TX, known for\nsevere flood events. The LSTM network's capability in learning long-term\ndependencies between the input and output of the network allowed modeling RR\nwith high resolution in time (15 minutes). Using 10-years precipitation from\n153 rainfall gages and river channel discharge data (more than 5.3 million data\npoints), and by designing several numerical tests the developed model\nperformance in predicting river discharge was tested. The model results were\nalso compared with the output of a process-driven model Gridded Surface\nSubsurface Hydrologic Analysis (GSSHA). Moreover, physical consistency of the\nLSTM model was explored. The model results showed that the LSTM model was able\nto efficiently predict discharge and achieve good model performance. When\ncompared to GSSHA, the data-driven model was more efficient and robust in terms\nof prediction and calibration. Interestingly, the performance of the LSTM model\nimproved (test Nash-Sutcliffe model efficiency from 0.666 to 0.942) when a\nselected subset of rainfall gages based on the model performance, were used as\ninput instead of all rainfall gages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:38:03 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 01:21:07 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Li", "Wei", ""], ["Kiaghadi", "Amin", ""], ["Dawson", "Clint N.", ""]]}, {"id": "2002.02572", "submitter": "Enmao Diao", "authors": "Enmao Diao, Jie Ding, Vahid Tarokh", "title": "Multimodal Controller for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-conditional generative models are crucial tools for data generation\nfrom user-specified class labels. Existing approaches for class-conditional\ngenerative models require nontrivial modifications of backbone generative\narchitectures to model conditional information fed into the model. This paper\nintroduces a plug-and-play module named `multimodal controller' to generate\nmultimodal data without introducing additional learning parameters. In the\nabsence of the controllers, our model reduces to non-conditional generative\nmodels. We test the efficacy of multimodal controllers on CIFAR10, COIL100, and\nOmniglot benchmark datasets. We demonstrate that multimodal controlled\ngenerative models (including VAE, PixelCNN, Glow, and GAN) can generate\nclass-conditional images of significantly better quality when compared with the\nstate-of-the-art conditional generative models. Moreover, we show that\nmultimodal controlled models can also create novel modalities of images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:55:10 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:24:54 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 15:04:30 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 22:44:57 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 14:43:11 GMT"}, {"version": "v6", "created": "Mon, 29 Mar 2021 00:08:28 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2002.02581", "submitter": "Lei Lei", "authors": "Lei Lei, Yue Tan, Glenn Dahlenburg, Wei Xiang, Kan Zheng", "title": "Dynamic Energy Dispatch Based on Deep Reinforcement Learning in\n  IoT-Driven Smart Isolated Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microgrids (MGs) are small, local power grids that can operate independently\nfrom the larger utility grid. Combined with the Internet of Things (IoT), a\nsmart MG can leverage the sensory data and machine learning techniques for\nintelligent energy management. This paper focuses on deep reinforcement\nlearning (DRL)-based energy dispatch for IoT-driven smart isolated MGs with\ndiesel generators (DGs), photovoltaic (PV) panels, and a battery. A\nfinite-horizon Partial Observable Markov Decision Process (POMDP) model is\nformulated and solved by learning from historical data to capture the\nuncertainty in future electricity consumption and renewable power generation.\nIn order to deal with the instability problem of DRL algorithms and unique\ncharacteristics of finite-horizon models, two novel DRL algorithms, namely,\nfinite-horizon deep deterministic policy gradient (FH-DDPG) and finite-horizon\nrecurrent deterministic policy gradient (FH-RDPG), are proposed to derive\nenergy dispatch policies with and without fully observable state information. A\ncase study using real isolated MG data is performed, where the performance of\nthe proposed algorithms are compared with the other baseline DRL and non-DRL\nalgorithms. Moreover, the impact of uncertainties on MG performance is\ndecoupled into two levels and evaluated respectively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:44:18 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 15:50:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lei", "Lei", ""], ["Tan", "Yue", ""], ["Dahlenburg", "Glenn", ""], ["Xiang", "Wei", ""], ["Zheng", "Kan", ""]]}, {"id": "2002.02582", "submitter": "Mohammad Hashir", "authors": "Mohammad Hashir, Hadrien Bertrand and Joseph Paul Cohen", "title": "Quantifying the Value of Lateral Views in Deep Learning for Chest X-rays", "comments": "Under review at MIDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning models in chest X-ray prediction utilize the\nposteroanterior (PA) view due to the lack of other views available. PadChest is\na large-scale chest X-ray dataset that has almost 200 labels and multiple views\navailable. In this work, we use PadChest to explore multiple approaches to\nmerging the PA and lateral views for predicting the radiological labels\nassociated with the X-ray image. We find that different methods of merging the\nmodel utilize the lateral view differently. We also find that including the\nlateral view increases performance for 32 labels in the dataset, while being\nneutral for the others. The increase in overall performance is comparable to\nthe one obtained by using only the PA view with twice the amount of patients in\nthe training set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:48:13 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Hashir", "Mohammad", ""], ["Bertrand", "Hadrien", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "2002.02584", "submitter": "Shuhang Chen", "authors": "Shuhang Chen, Adithya M. Devraj, Ana Bu\\v{s}i\\'c, Sean Meyn", "title": "Explicit Mean-Square Error Bounds for Monte-Carlo and Linear Stochastic\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG cs.SY eess.SY math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns error bounds for recursive equations subject to Markovian\ndisturbances. Motivating examples abound within the fields of Markov chain\nMonte Carlo (MCMC) and Reinforcement Learning (RL), and many of these\nalgorithms can be interpreted as special cases of stochastic approximation\n(SA). It is argued that it is not possible in general to obtain a Hoeffding\nbound on the error sequence, even when the underlying Markov chain is\nreversible and geometrically ergodic, such as the M/M/1 queue. This is\nmotivation for the focus on mean square error bounds for parameter estimates.\nIt is shown that mean square error achieves the optimal rate of $O(1/n)$,\nsubject to conditions on the step-size sequence. Moreover, the exact constants\nin the rate are obtained, which is of great value in algorithm design.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:52:21 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Chen", "Shuhang", ""], ["Devraj", "Adithya M.", ""], ["Bu\u0161i\u0107", "Ana", ""], ["Meyn", "Sean", ""]]}, {"id": "2002.02592", "submitter": "Nicholas James", "authors": "Nick James, Max Menzies", "title": "Equivalence relations and $L^p$ distances between time series", "comments": "Equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for defining equivalence and measuring\ndistances between time series, and a first concrete method for doing so. We\nprove the existence of equivalence relations on the space of time series, such\nthat the quotient spaces can be equipped with a metrizable topology. We\nillustrate algorithmically how to calculate such distances among a collection\nof time series, and perform clustering analysis based on these distances. We\napply these insights to analyse the recent bushfires in NSW, Australia. There,\nwe introduce a new method to analyse time series in a cross-contextual setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 02:32:33 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["James", "Nick", ""], ["Menzies", "Max", ""]]}, {"id": "2002.02600", "submitter": "Jiequn Han", "authors": "Jiequn Han, Jianfeng Lu, Mo Zhou", "title": "Solving high-dimensional eigenvalue problems using deep neural networks:\n  A diffusion Monte Carlo like approach", "comments": "18 pages, 6 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109792", "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to solve eigenvalue problems for linear and\nsemilinear second order differential operators in high dimensions based on deep\nneural networks. The eigenvalue problem is reformulated as a fixed point\nproblem of the semigroup flow induced by the operator, whose solution can be\nrepresented by Feynman-Kac formula in terms of forward-backward stochastic\ndifferential equations. The method shares a similar spirit with diffusion Monte\nCarlo but augments a direct approximation to the eigenfunction through\nneural-network ansatz. The criterion of fixed point provides a natural loss\nfunction to search for parameters via optimization. Our approach is able to\nprovide accurate eigenvalue and eigenfunction approximations in several\nnumerical examples, including Fokker-Planck operator and the linear and\nnonlinear Schr\\\"odinger operators in high dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:08:31 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 03:34:03 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Han", "Jiequn", ""], ["Lu", "Jianfeng", ""], ["Zhou", "Mo", ""]]}, {"id": "2002.02601", "submitter": "Eric Lock", "authors": "Eric F. Lock, Jun Young Park, and Katherine A. Hoadley", "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer\n  analysis", "comments": "46 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:11:44 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Lock", "Eric F.", ""], ["Park", "Jun Young", ""], ["Hoadley", "Katherine A.", ""]]}, {"id": "2002.02610", "submitter": "Marianna Pensky", "authors": "Majid Noroozi and Marianna Pensky", "title": "The Hierarchy of Block Models", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist various types of network block models such as the Stochastic\nBlock Model (SBM), the Degree Corrected Block Model (DCBM), and the Popularity\nAdjusted Block Model (PABM). While this leads to a variety of choices, the\nblock models do not have a nested structure. In addition, there is a\nsubstantial jump in the number of parameters from the DCBM to the PABM. The\nobjective of this paper is formulation of a hierarchy of block model which does\nnot rely on arbitrary identifiability conditions. We propose a Nested Block\nModel (NBM) that treats the SBM, the DCBM and the PABM as its particular cases\nwith specific parameter values, and, in addition, allows a multitude of\nversions that are more complicated than DCBM but have fewer unknown parameters\nthan the PABM. The latter allows one to carry out clustering and estimation\nwithout preliminary testing, to see which block model is really true.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:47:15 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 22:11:59 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Noroozi", "Majid", ""], ["Pensky", "Marianna", ""]]}, {"id": "2002.02620", "submitter": "Jarrad Courts", "authors": "Jarrad Courts, Adrian Wills and Thomas B. Sch\\\"on", "title": "Gaussian Variational State Estimation for Nonlinear State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of state estimation, in the context of both\nfiltering and smoothing, for nonlinear state-space models is considered. Due to\nthe nonlinear nature of the models, the state estimation problem is generally\nintractable as it involves integrals of general nonlinear functions and the\nfiltered and smoothed state distributions lack closed-form solutions. As such,\nit is common to approximate the state estimation problem. In this paper, we\ndevelop an assumed Gaussian solution based on variational inference, which\noffers the key advantage of a flexible, but principled, mechanism for\napproximating the required distributions. Our main contribution lies in a new\nformulation of the state estimation problem as an optimisation problem, which\ncan then be solved using standard optimisation routines that employ exact\nfirst- and second-order derivatives. The resulting state estimation approach\ninvolves a minimal number of assumptions and applies directly to nonlinear\nsystems with both Gaussian and non-Gaussian probabilistic models. The\nperformance of our approach is demonstrated on several examples; a challenging\nscalar system, a model of a simple robotic system, and a target tracking\nproblem using a von Mises-Fisher distribution and outperforms alternative\nassumed Gaussian approaches to state estimation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 04:46:14 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 03:43:29 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 05:21:20 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Courts", "Jarrad", ""], ["Wills", "Adrian", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "2002.02644", "submitter": "Tim Leathart", "authors": "Tim Leathart and Maksymilian Polaczuk", "title": "Temporal Probability Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, accurate class probability estimates are required, but\nmany types of models produce poor quality probability estimates despite\nachieving acceptable classification accuracy. Even though probability\ncalibration has been a hot topic of research in recent times, the majority of\nthis has investigated non-sequential data. In this paper, we consider\ncalibrating models that produce class probability estimates from sequences of\ndata, focusing on the case where predictions are obtained from incomplete\nsequences. We show that traditional calibration techniques are not sufficiently\nexpressive for this task, and propose methods that adapt calibration schemes\ndepending on the length of an input sequence. Experimental evaluation shows\nthat the proposed methods are often substantially more effective at calibrating\nprobability estimates from modern sequential architectures for incomplete\nsequences across a range of application domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 06:59:05 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 02:43:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Leathart", "Tim", ""], ["Polaczuk", "Maksymilian", ""]]}, {"id": "2002.02645", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Arjun Balasubramanian, Shivaram Venkataraman, Aditya\n  Akella", "title": "Accelerating Deep Learning Inference via Freezing", "comments": "11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, Deep Neural Networks (DNNs) have become ubiquitous\nowing to their high accuracy on real-world tasks. However, this increase in\naccuracy comes at the cost of computationally expensive models leading to\nhigher prediction latencies. Prior efforts to reduce this latency such as\nquantization, model distillation, and any-time prediction models typically\ntrade-off accuracy for performance. In this work, we observe that caching\nintermediate layer outputs can help us avoid running all the layers of a DNN\nfor a sizeable fraction of inference requests. We find that this can\npotentially reduce the number of effective layers by half for 91.58% of\nCIFAR-10 requests run on ResNet-18. We present Freeze Inference, a system that\nintroduces approximate caching at each intermediate layer and we discuss\ntechniques to reduce the cache size and improve the cache hit rate. Finally, we\ndiscuss some of the open research challenges in realizing such a design.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 07:03:58 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kumar", "Adarsh", ""], ["Balasubramanian", "Arjun", ""], ["Venkataraman", "Shivaram", ""], ["Akella", "Aditya", ""]]}, {"id": "2002.02655", "submitter": "Jakub Swiatkowski", "authors": "Jakub Swiatkowski, Kevin Roth, Bastiaan S. Veeling, Linh Tran, Joshua\n  V. Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Rodolphe Jenatton,\n  Sebastian Nowozin", "title": "The k-tied Normal Distribution: A Compact Parameterization of Gaussian\n  Mean Field Posteriors in Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian Inference is a popular methodology for approximating\nposterior distributions over Bayesian neural network weights. Recent work\ndeveloping this class of methods has explored ever richer parameterizations of\nthe approximate posterior in the hope of improving performance. In contrast,\nhere we share a curious experimental finding that suggests instead restricting\nthe variational distribution to a more compact parameterization. For a variety\nof deep Bayesian neural networks trained using Gaussian mean-field variational\ninference, we find that the posterior standard deviations consistently exhibit\nstrong low-rank structure after convergence. This means that by decomposing\nthese variational parameters into a low-rank factorization, we can make our\nvariational approximation more compact without decreasing the models'\nperformance. Furthermore, we find that such factorized parameterizations\nimprove the signal-to-noise ratio of stochastic gradient estimates of the\nvariational lower bound, resulting in faster convergence.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 07:33:15 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 19:05:09 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Swiatkowski", "Jakub", ""], ["Roth", "Kevin", ""], ["Veeling", "Bastiaan S.", ""], ["Tran", "Linh", ""], ["Dillon", "Joshua V.", ""], ["Snoek", "Jasper", ""], ["Mandt", "Stephan", ""], ["Salimans", "Tim", ""], ["Jenatton", "Rodolphe", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "2002.02664", "submitter": "Ellen de Mello Koch Ms", "authors": "Ellen de Melllo Koch, Anita de Mello Koch, Nicholas Kastanos, Ling\n  Cheng", "title": "Short sighted deep learning", "comments": null, "journal-ref": "Phys. Rev. E 102, 013307 (2020)", "doi": "10.1103/PhysRevE.102.013307", "report-no": null, "categories": "cs.LG cond-mat.stat-mech physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theory explaining how deep learning works is yet to be developed. Previous\nwork suggests that deep learning performs a coarse graining, similar in spirit\nto the renormalization group (RG). This idea has been explored in the setting\nof a local (nearest neighbor interactions) Ising spin lattice. We extend the\ndiscussion to the setting of a long range spin lattice. Markov Chain Monte\nCarlo (MCMC) simulations determine both the critical temperature and scaling\ndimensions of the system. The model is used to train both a single RBM\n(restricted Boltzmann machine) network, as well as a stacked RBM network.\nFollowing earlier Ising model studies, the trained weights of a single layer\nRBM network define a flow of lattice models. In contrast to results for nearest\nneighbor Ising, the RBM flow for the long ranged model does not converge to the\ncorrect values for the spin and energy scaling dimension. Further, correlation\nfunctions between visible and hidden nodes exhibit key differences between the\nstacked RBM and RG flows. The stacked RBM flow appears to move towards low\ntemperatures whereas the RG flow moves towards high temperature. This again\ndiffers from results obtained for nearest neighbor Ising.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 08:33:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Koch", "Ellen de Melllo", ""], ["Koch", "Anita de Mello", ""], ["Kastanos", "Nicholas", ""], ["Cheng", "Ling", ""]]}, {"id": "2002.02669", "submitter": "Ziyi Yang", "authors": "Ziyi Yang, Teng Zhang, Iman Soltani Bozchalooi, Eric Darve", "title": "Memory Augmented Generative Adversarial Networks for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a memory-augmented algorithm for anomaly detection.\nClassical anomaly detection algorithms focus on learning to model and generate\nnormal data, but typically guarantees for detecting anomalous data are weak.\nThe proposed Memory Augmented Generative Adversarial Networks (MEMGAN)\ninteracts with a memory module for both the encoding and generation processes.\nOur algorithm is such that most of the \\textit{encoded} normal data are inside\nthe convex hull of the memory units, while the abnormal data are isolated\noutside. Such a remarkable property leads to good (resp.\\ poor) reconstruction\nfor normal (resp.\\ abnormal) data and therefore provides a strong guarantee for\nanomaly detection. Decoded memory units in MEMGAN are more interpretable and\ndisentangled than previous methods, which further demonstrates the\neffectiveness of the memory mechanism. Experimental results on twenty anomaly\ndetection datasets of CIFAR-10 and MNIST show that MEMGAN demonstrates\nsignificant improvements over previous anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 08:46:26 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Yang", "Ziyi", ""], ["Zhang", "Teng", ""], ["Bozchalooi", "Iman Soltani", ""], ["Darve", "Eric", ""]]}, {"id": "2002.02675", "submitter": "Thomas Lim", "authors": "Idris Kharroubi (LPSM UMR 8001), Thomas Lim (LaMME, ENSIIE), Xavier\n  Warin (EDF)", "title": "Discretization and Machine Learning Approximation of BSDEs with a\n  Constraint on the Gains-Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of backward stochastic differential equations\n(BSDEs for short) with a constraint on the gains process. We first discretize\nthe constraint by applying a so-called facelift operator at times of a grid. We\nshow that this discretely constrained BSDE converges to the continuously\nconstrained one as the mesh grid converges to zero. We then focus on the\napproximation of the discretely constrained BSDE. For that we adopt a machine\nlearning approach. We show that the facelift can be approximated by an\noptimization problem over a class of neural networks under constraints on the\nneural network and its derivative. We then derive an algorithm converging to\nthe discretely constrained BSDE as the number of neurons goes to infinity. We\nend by numerical experiments. Mathematics Subject Classification (2010): 65C30,\n65M75, 60H35, 93E20, 49L25.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:11:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kharroubi", "Idris", "", "LPSM UMR 8001"], ["Lim", "Thomas", "", "LaMME, ENSIIE"], ["Warin", "Xavier", "", "EDF"]]}, {"id": "2002.02693", "submitter": "Jack Parker-Holder", "authors": "Philip Ball and Jack Parker-Holder and Aldo Pacchiano and Krzysztof\n  Choromanski and Stephen Roberts", "title": "Ready Policy One: World Building Through Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-Based Reinforcement Learning (MBRL) offers a promising direction for\nsample efficient learning, often achieving state of the art results for\ncontinuous control tasks. However, many existing MBRL methods rely on combining\ngreedy policies with exploration heuristics, and even those which utilize\nprincipled exploration bonuses construct dual objectives in an ad hoc fashion.\nIn this paper we introduce Ready Policy One (RP1), a framework that views MBRL\nas an active learning problem, where we aim to improve the world model in the\nfewest samples possible. RP1 achieves this by utilizing a hybrid objective\nfunction, which crucially adapts during optimization, allowing the algorithm to\ntrade off reward v.s. exploration at different stages of learning. In addition,\nwe introduce a principled mechanism to terminate sample collection once we have\na rich enough trajectory batch to improve the model. We rigorously evaluate our\nmethod on a variety of continuous control tasks, and demonstrate statistically\nsignificant gains over existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:57:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ball", "Philip", ""], ["Parker-Holder", "Jack", ""], ["Pacchiano", "Aldo", ""], ["Choromanski", "Krzysztof", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.02701", "submitter": "Henry Wilde", "authors": "Henry Wilde, Vincent Knight, Jonathan Gillard", "title": "A novel initialisation based on hospital-resident assignment for the\n  k-modes algorithm", "comments": "23 pages, 11 figures (31 panels)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new way of selecting an initial solution for the\nk-modes algorithm that allows for a notion of mathematical fairness and a\nleverage of the data that the common initialisations from literature do not.\nThe method, which utilises the Hospital-Resident Assignment Problem to find the\nset of initial cluster centroids, is compared with the current initialisations\non both benchmark datasets and a body of newly generated artificial datasets.\nBased on this analysis, the proposed method is shown to outperform the other\ninitialisations in the majority of cases, especially when the number of\nclusters is optimised. In addition, we find that our method outperforms the\nleading established method specifically for low-density data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:20:49 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Wilde", "Henry", ""], ["Knight", "Vincent", ""], ["Gillard", "Jonathan", ""]]}, {"id": "2002.02702", "submitter": "Martin Trapp", "authors": "Mohamed Tarek, Kai Xu, Martin Trapp, Hong Ge, Zoubin Ghahramani", "title": "DynamicPPL: Stan-like Speed for Dynamic Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the preliminary high-level design and features of DynamicPPL.jl, a\nmodular library providing a lightning-fast infrastructure for probabilistic\nprogramming. Besides a computational performance that is often close to or\nbetter than Stan, DynamicPPL provides an intuitive DSL that allows the rapid\ndevelopment of complex dynamic probabilistic programs. Being entirely written\nin Julia, a high-level dynamic programming language for numerical computing,\nDynamicPPL inherits a rich set of features available through the Julia\necosystem. Since DynamicPPL is a modular, stand-alone library, any\nprobabilistic programming system written in Julia, such as Turing.jl, can use\nDynamicPPL to specify models and trace their model parameters. The main\nfeatures of DynamicPPL are: 1) a meta-programming based DSL for specifying\ndynamic models using an intuitive tilde-based notation; 2) a tracing\ndata-structure for tracking RVs in dynamic probabilistic models; 3) a rich\ncontextual dispatch system allowing tailored behaviour during model execution;\nand 4) a user-friendly syntax for probabilistic queries. Finally, we show in a\nvariety of experiments that DynamicPPL, in combination with Turing.jl, achieves\ncomputational performance that is often close to or better than Stan.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:21:49 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Tarek", "Mohamed", ""], ["Xu", "Kai", ""], ["Trapp", "Martin", ""], ["Ge", "Hong", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2002.02705", "submitter": "Christian Haase-Sch\\\"utz", "authors": "Christian Haase-Sch\\\"utz, Rainer Stal, Heinz Hertlein and Bernhard\n  Sick", "title": "Iterative Label Improvement: Robust Training by Confidence Based\n  Filtering and Dataset Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art, high capacity deep neural networks not only require large\namounts of labelled training data, they are also highly susceptible to label\nerrors in this data, typically resulting in large efforts and costs and\ntherefore limiting the applicability of deep learning. To alleviate this issue,\nwe propose a novel meta training and labelling scheme that is able to use\ninexpensive unlabelled data by taking advantage of the generalization power of\ndeep neural networks. We show experimentally that by solely relying on one\nnetwork architecture and our proposed scheme of iterative training and\nprediction steps, both label quality and resulting model accuracy can be\nimproved significantly. Our method achieves state-of-the-art results, while\nbeing architecture agnostic and therefore broadly applicable. Compared to other\nmethods dealing with erroneous labels, our approach does neither require\nanother network to be trained, nor does it necessarily need an additional,\nhighly accurate reference label set. Instead of removing samples from a\nlabelled set, our technique uses additional sensor data without the need for\nmanual labelling. Furthermore, our approach can be used for semi-supervised\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:42:26 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:00:16 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 10:13:54 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Haase-Sch\u00fctz", "Christian", ""], ["Stal", "Rainer", ""], ["Hertlein", "Heinz", ""], ["Sick", "Bernhard", ""]]}, {"id": "2002.02717", "submitter": "Dmitry V. Dylov", "authors": "Nikolay Shvetsov and Nazar Buzun and Dmitry V. Dylov", "title": "Unsupervised non-parametric change point detection in quasi-periodic\n  signals", "comments": "8 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1145/3400903.3400917", "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new unsupervised and non-parametric method to detect change\npoints in intricate quasi-periodic signals. The detection relies on optimal\ntransport theory combined with topological analysis and the bootstrap\nprocedure. The algorithm is designed to detect changes in virtually any\nharmonic or a partially harmonic signal and is verified on three different\nsources of physiological data streams. We successfully find abnormal or\nirregular cardiac cycles in the waveforms for the six of the most frequent\ntypes of clinical arrhythmias using a single algorithm. The validation and the\nefficiency of the method are shown both on synthetic and on real time series.\nOur unsupervised approach reaches the level of performance of the supervised\nstate-of-the-art techniques. We provide conceptual justification for the\nefficiency of the method and prove the convergence of the bootstrap procedure\ntheoretically.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 11:24:50 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Shvetsov", "Nikolay", ""], ["Buzun", "Nazar", ""], ["Dylov", "Dmitry V.", ""]]}, {"id": "2002.02730", "submitter": "Thomas Baumhauer", "authors": "Thomas Baumhauer and Pascal Sch\\\"ottle and Matthias Zeppelzauer", "title": "Machine Unlearning: Linear Filtration for Logit-based Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently enacted legislation grants individuals certain rights to decide in\nwhat fashion their personal data may be used, and in particular a \"right to be\nforgotten\". This poses a challenge to machine learning: how to proceed when an\nindividual retracts permission to use data which has been part of the training\nprocess of a model? From this question emerges the field of machine unlearning,\nwhich could be broadly described as the investigation of how to \"delete\ntraining data from models\". Our work complements this direction of research for\nthe specific setting of class-wide deletion requests for classification models\n(e.g. deep neural networks). As a first step, we propose linear filtration as a\nintuitive, computationally efficient sanitization method. Our experiments\ndemonstrate benefits in an adversarial setting over naive deletion schemes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:16:06 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 06:30:40 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Baumhauer", "Thomas", ""], ["Sch\u00f6ttle", "Pascal", ""], ["Zeppelzauer", "Matthias", ""]]}, {"id": "2002.02741", "submitter": "Moshe Kravchik", "authors": "Moshe Kravchik, Asaf Shabtai", "title": "Can't Boil This Frog: Robustness of Online-Trained Autoencoder-Based\n  Anomaly Detectors to Adversarial Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a variety of effective neural network-based methods for\nanomaly and cyber attack detection in industrial control systems (ICSs) have\nbeen demonstrated in the literature. Given their successful implementation and\nwidespread use, there is a need to study adversarial attacks on such detection\nmethods to better protect the systems that depend upon them. The extensive\nresearch performed on adversarial attacks on image and malware classification\nhas little relevance to the physical system state prediction domain, which most\nof the ICS attack detection systems belong to. Moreover, such detection systems\nare typically retrained using new data collected from the monitored system,\nthus the threat of adversarial data poisoning is significant, however this\nthreat has not yet been addressed by the research community. In this paper, we\npresent the first study focused on poisoning attacks on online-trained\nautoencoder-based attack detectors. We propose two algorithms for generating\npoison samples, an interpolation-based algorithm and a back-gradient\noptimization-based algorithm, which we evaluate on both synthetic and\nreal-world ICS data. We demonstrate that the proposed algorithms can generate\npoison samples that cause the target attack to go undetected by the autoencoder\ndetector, however the ability to poison the detector is limited to a small set\nof attack types and magnitudes. When the poison-generating algorithms are\napplied to the popular SWaT dataset, we show that the autoencoder detector\ntrained on the physical system state data is resilient to poisoning in the face\nof all ten of the relevant attacks in the dataset. This finding suggests that\nneural network-based attack detectors used in the cyber-physical domain are\nmore robust to poisoning than in other problem domains, such as malware\ndetection and image processing.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:41:28 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kravchik", "Moshe", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2002.02753", "submitter": "Tobias Alt", "authors": "Tobias Alt, Joachim Weickert, Pascal Peter", "title": "Translating Diffusion, Wavelets, and Regularisation into Residual\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) often perform well, but their stability\nis poorly understood. To address this problem, we consider the simple\nprototypical problem of signal denoising, where classical approaches such as\nnonlinear diffusion, wavelet-based methods and regularisation offer provable\nstability guarantees. To transfer such guarantees to CNNs, we interpret\nnumerical approximations of these classical methods as a specific residual\nnetwork (ResNet) architecture. This leads to a dictionary which allows to\ntranslate diffusivities, shrinkage functions, and regularisers into activation\nfunctions, and enables a direct communication between the four research\ncommunities. On the CNN side, it does not only inspire new families of\nnonmonotone activation functions, but also introduces intrinsically stable\narchitectures for an arbitrary number of layers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:07:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 06:28:08 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 08:51:13 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Alt", "Tobias", ""], ["Weickert", "Joachim", ""], ["Peter", "Pascal", ""]]}, {"id": "2002.02758", "submitter": "Parth Shah", "authors": "Parth Shah, Vishvajit Bakrola", "title": "Neural Machine Translation System of Indic Languages -- An Attention\n  based Approach", "comments": null, "journal-ref": "2019 Second International Conference on Advanced Computational and\n  Communication Paradigms (ICACCP), Gangtok, India, 2019, pp. 1-5", "doi": "10.1109/ICACCP.2019.8882969", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is a recent and effective technique which\nled to remarkable improvements in comparison of conventional machine\ntranslation techniques. Proposed neural machine translation model developed for\nthe Gujarati language contains encoder-decoder with attention mechanism. In\nIndia, almost all the languages are originated from their ancestral language -\nSanskrit. They are having inevitable similarities including lexical and named\nentity similarity. Translating into Indic languages is always be a challenging\ntask. In this paper, we have presented the neural machine translation system\n(NMT) that can efficiently translate Indic languages like Hindi and Gujarati\nthat together covers more than 58.49 percentage of total speakers in the\ncountry. We have compared the performance of our NMT model with automatic\nevaluation matrices such as BLEU, perplexity and TER matrix. The comparison of\nour network with Google translate is also presented where it outperformed with\na margin of 6 BLEU score on English-Gujarati translation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 07:15:18 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Shah", "Parth", ""], ["Bakrola", "Vishvajit", ""]]}, {"id": "2002.02770", "submitter": "Yaliang Li", "authors": "Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, Aidong Zhang", "title": "A Survey on Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is a critical research topic across many domains, such as\nstatistics, computer science, education, public policy and economics, for\ndecades. Nowadays, estimating causal effect from observational data has become\nan appealing research direction owing to the large amount of available data and\nlow budget requirement, compared with randomized controlled trials. Embraced\nwith the rapidly developed machine learning area, various causal effect\nestimation methods for observational data have sprung up. In this survey, we\nprovide a comprehensive review of causal inference methods under the potential\noutcome framework, one of the well known causal inference framework. The\nmethods are divided into two categories depending on whether they require all\nthree assumptions of the potential outcome framework or not. For each category,\nboth the traditional statistical methods and the recent machine learning\nenhanced methods are discussed and compared. The plausible applications of\nthese methods are also presented, including the applications in advertising,\nrecommendation, medicine and so on. Moreover, the commonly used benchmark\ndatasets as well as the open-source codes are also summarized, which facilitate\nresearchers and practitioners to explore, evaluate and apply the causal\ninference methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:35:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Yao", "Liuyi", ""], ["Chu", "Zhixuan", ""], ["Li", "Sheng", ""], ["Li", "Yaliang", ""], ["Gao", "Jing", ""], ["Zhang", "Aidong", ""]]}, {"id": "2002.02778", "submitter": "Jisu Kim", "authors": "Kwangho Kim, Jisu Kim, Manzil Zaheer, Joon Sik Kim, Frederic Chazal,\n  and Larry Wasserman", "title": "PLLay: Efficient Topological Layer based on Persistence Landscapes", "comments": "29 pages, 7 figures", "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PLLay, a novel topological layer for general deep learning models\nbased on persistence landscapes, in which we can efficiently exploit the\nunderlying topological features of the input data structure. In this work, we\nshow differentiability with respect to layer inputs, for a general persistent\nhomology with arbitrary filtration. Thus, our proposed layer can be placed\nanywhere in the network and feed critical information on the topological\nfeatures of input data into subsequent layers to improve the learnability of\nthe networks toward a given task. A task-optimal structure of PLLay is learned\nduring training via backpropagation, without requiring any input featurization\nor data preprocessing. We provide a novel adaptation for the DTM function-based\nfiltration, and show that the proposed layer is robust against noise and\noutliers through a stability analysis. We demonstrate the effectiveness of our\napproach by classification experiments on various datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:34:22 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 07:05:55 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 04:43:37 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 00:44:49 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kim", "Kwangho", ""], ["Kim", "Jisu", ""], ["Zaheer", "Manzil", ""], ["Kim", "Joon Sik", ""], ["Chazal", "Frederic", ""], ["Wasserman", "Larry", ""]]}, {"id": "2002.02779", "submitter": "Charles Fisher", "authors": "Jonathan R. Walsh, Aaron M. Smith, Yannick Pouliot, David Li-Bland,\n  Anton Loukianov, and Charles K. Fisher", "title": "Generating Digital Twins with Multiple Sclerosis Using Probabilistic\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Sclerosis (MS) is a neurodegenerative disorder characterized by a\ncomplex set of clinical assessments. We use an unsupervised machine learning\nmodel called a Conditional Restricted Boltzmann Machine (CRBM) to learn the\nrelationships between covariates commonly used to characterize subjects and\ntheir disease progression in MS clinical trials. A CRBM is capable of\ngenerating digital twins, which are simulated subjects having the same baseline\ndata as actual subjects. Digital twins allow for subject-level statistical\nanalyses of disease progression. The CRBM is trained using data from 2395\nsubjects enrolled in the placebo arms of clinical trials across the three\nprimary subtypes of MS. We discuss how CRBMs are trained and show that digital\ntwins generated by the model are statistically indistinguishable from their\nactual subject counterparts along a number of measures.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:57:08 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 17:39:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Walsh", "Jonathan R.", ""], ["Smith", "Aaron M.", ""], ["Pouliot", "Yannick", ""], ["Li-Bland", "David", ""], ["Loukianov", "Anton", ""], ["Fisher", "Charles K.", ""]]}, {"id": "2002.02782", "submitter": "Mario Wieser", "authors": "Mario Wieser, Sonali Parbhoo, Aleksander Wieczorek, Volker Roth", "title": "Inverse Learning of Symmetries", "comments": "Accepted for publication at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Symmetry transformations induce invariances which are frequently described\nwith deep latent variable models. In many complex domains, such as the chemical\nspace, invariances can be observed, yet the corresponding symmetry\ntransformation cannot be formulated analytically. We propose to learn the\nsymmetry transformation with a model consisting of two latent subspaces, where\nthe first subspace captures the target and the second subspace the remaining\ninvariant information. Our approach is based on the deep information bottleneck\nin combination with a continuous mutual information regulariser. Unlike\nprevious methods, we focus on the challenging task of minimising mutual\ninformation in continuous domains. To this end, we base the calculation of\nmutual information on correlation matrices in combination with a bijective\nvariable transformation. Extensive experiments demonstrate that our model\noutperforms state-of-the-art methods on artificial and molecular datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:48:52 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:46:53 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wieser", "Mario", ""], ["Parbhoo", "Sonali", ""], ["Wieczorek", "Aleksander", ""], ["Roth", "Volker", ""]]}, {"id": "2002.02794", "submitter": "Tiancheng Yu", "authors": "Chi Jin, Akshay Krishnamurthy, Max Simchowitz, Tiancheng Yu", "title": "Reward-Free Exploration for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is widely regarded as one of the most challenging aspects of\nreinforcement learning (RL), with many naive approaches succumbing to\nexponential sample complexity. To isolate the challenges of exploration, we\npropose a new \"reward-free RL\" framework. In the exploration phase, the agent\nfirst collects trajectories from an MDP $\\mathcal{M}$ without a pre-specified\nreward function. After exploration, it is tasked with computing near-optimal\npolicies under for $\\mathcal{M}$ for a collection of given reward functions.\nThis framework is particularly suitable when there are many reward functions of\ninterest, or when the reward function is shaped by an external agent to elicit\ndesired behavior.\n  We give an efficient algorithm that conducts\n$\\tilde{\\mathcal{O}}(S^2A\\mathrm{poly}(H)/\\epsilon^2)$ episodes of exploration\nand returns $\\epsilon$-suboptimal policies for an arbitrary number of reward\nfunctions. We achieve this by finding exploratory policies that visit each\n\"significant\" state with probability proportional to its maximum visitation\nprobability under any possible policy. Moreover, our planning procedure can be\ninstantiated by any black-box approximate planner, such as value iteration or\nnatural policy gradient. We also give a nearly-matching\n$\\Omega(S^2AH^2/\\epsilon^2)$ lower bound, demonstrating the near-optimality of\nour algorithm in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:03:38 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Jin", "Chi", ""], ["Krishnamurthy", "Akshay", ""], ["Simchowitz", "Max", ""], ["Yu", "Tiancheng", ""]]}, {"id": "2002.02797", "submitter": "Javier Antor\\'an", "authors": "Javier Antor\\'an, James Urquhart Allingham, Jos\\'e Miguel\n  Hern\\'andez-Lobato", "title": "Variational Depth Search in ResNets", "comments": "Appearing at the 1st ICLR workshop on Neural Architecture Search 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot neural architecture search allows joint learning of weights and\nnetwork architecture, reducing computational cost. We limit our search space to\nthe depth of residual networks and formulate an analytically tractable\nvariational objective that allows for obtaining an unbiased approximate\nposterior over depths in one-shot. We propose a heuristic to prune our networks\nbased on this distribution. We compare our proposed method against manual\nsearch over network depths on the MNIST, Fashion-MNIST, SVHN datasets. We find\nthat pruned networks do not incur a loss in predictive performance, obtaining\naccuracies competitive with unpruned networks. Marginalising over depth allows\nus to obtain better-calibrated test-time uncertainty estimates than regular\nnetworks, in a single forward pass.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:00:03 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:12:58 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 10:58:12 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 17:59:13 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Antor\u00e1n", "Javier", ""], ["Allingham", "James Urquhart", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2002.02798", "submitter": "Chris Finlay", "authors": "Chris Finlay, J\\\"orn-Henrik Jacobsen, Levon Nurbekyan, Adam M Oberman", "title": "How to train your neural ODE: the world of Jacobian and kinetic\n  regularization", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural ODEs on large datasets has not been tractable due to the\nnecessity of allowing the adaptive numerical ODE solver to refine its step size\nto very small values. In practice this leads to dynamics equivalent to many\nhundreds or even thousands of layers. In this paper, we overcome this apparent\ndifficulty by introducing a theoretically-grounded combination of both optimal\ntransport and stability regularizations which encourage neural ODEs to prefer\nsimpler dynamics out of all the dynamics that solve a problem well. Simpler\ndynamics lead to faster convergence and to fewer discretizations of the solver,\nconsiderably decreasing wall-clock time without loss in performance. Our\napproach allows us to train neural ODE-based generative models to the same\nperformance as the unregularized dynamics, with significant reductions in\ntraining time. This brings neural ODEs closer to practical relevance in\nlarge-scale applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:15:02 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 18:38:51 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 15:54:19 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Finlay", "Chris", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Nurbekyan", "Levon", ""], ["Oberman", "Adam M", ""]]}, {"id": "2002.02801", "submitter": "Ekram Hossain", "authors": "Yasser Al-Eryani, Mohamed Akrout, and Ekram Hossain", "title": "Multiple Access in Dynamic Cell-Free Networks: Outage Performance and\n  Deep Reinforcement Learning-Based Design", "comments": "This article has been submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future cell-free (or cell-less) wireless networks, a large number of\ndevices in a geographical area will be served simultaneously in non-orthogonal\nmultiple access scenarios by a large number of distributed access points (APs),\nwhich coordinate with a centralized processing pool. For such a centralized\ncell-free network with static predefined beamforming design, we first derive a\nclosed-form expression of the uplink per-user probability of outage. To\nsignificantly reduce the complexity of joint processing of users' signals in\npresence of a large number of devices and APs, we propose a novel dynamic\ncell-free network architecture. In this architecture, the distributed APs are\npartitioned (i.e. clustered) among a set of subgroups with each subgroup acting\nas a virtual AP equipped with a distributed antenna system (DAS). The\nconventional static cell-free network is a special case of this dynamic\ncell-free network when the cluster size is one. For this dynamic cell-free\nnetwork, we propose a successive interference cancellation (SIC)-enabled signal\ndetection method and an inter-user-interference (IUI)-aware DAS's receive\ndiversity combining scheme. We then formulate the general problem of clustering\nAPs and designing the beamforming vectors with an objective to maximizing the\nsum rate or maximizing the minimum rate. To this end, we propose a hybrid deep\nreinforcement learning (DRL) model, namely, a deep deterministic policy\ngradient (DDPG)-deep double Q-network (DDQN) model, to solve the optimization\nproblem for online implementation with low complexity. The DRL model for\nsum-rate optimization significantly outperforms that for maximizing the minimum\nrate in terms of average per-user rate performance. Also, in our system\nsetting, the proposed DDPG-DDQN scheme is found to achieve around $78\\%$ of the\nrate achievable through an exhaustive search-based design.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 03:00:22 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 04:49:40 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Al-Eryani", "Yasser", ""], ["Akrout", "Mohamed", ""], ["Hossain", "Ekram", ""]]}, {"id": "2002.02804", "submitter": "Luis Larios-C\\'ardenas", "authors": "Luis \\'Angel Larios-C\\'ardenas and Frederic Gibou", "title": "A Deep Learning Approach for the Computation of Curvature in the\n  Level-Set Method", "comments": "To appear in SIAM Journal on Scientific Computing", "journal-ref": null, "doi": "10.1137/20M1316755", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep learning strategy to estimate the mean curvature of\ntwo-dimensional implicit interfaces in the level-set method. Our approach is\nbased on fitting feed-forward neural networks to synthetic data sets\nconstructed from circular interfaces immersed in uniform grids of various\nresolutions. These multilayer perceptrons process the level-set values from\nmesh points next to the free boundary and output the dimensionless curvature at\ntheir closest locations on the interface. Accuracy analyses involving irregular\ninterfaces, in both uniform and adaptive grids, show that our models are\ncompetitive with traditional numerical schemes in the $L^1$ and $L^2$ norms. In\nparticular, our neural networks approximate curvature with comparable precision\nin coarse resolutions, when the interface features steep curvature regions, and\nwhen the number of iterations to reinitialize the level-set function is small.\nAlthough the conventional numerical approach is more robust than our framework,\nour results have unveiled the potential of machine learning for dealing with\ncomputational tasks where the level-set method is known to experience\ndifficulties. We also establish that an application-dependent map of local\nresolutions to neural models can be devised to estimate mean curvature more\neffectively than a universal neural network.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:49:47 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 04:46:47 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 03:14:39 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Larios-C\u00e1rdenas", "Luis \u00c1ngel", ""], ["Gibou", "Frederic", ""]]}, {"id": "2002.02805", "submitter": "Nicklas Hansen", "authors": "Ali Mohebbi, Alexander R. Johansen, Nicklas Hansen, Peter E.\n  Christensen, Jens M. Tarp, Morten L. Jensen, Henrik Bengtsson and Morten\n  M{\\o}rup", "title": "Short Term Blood Glucose Prediction based on Continuous Glucose\n  Monitoring Data", "comments": "Accepted to EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Glucose Monitoring (CGM) has enabled important opportunities for\ndiabetes management. This study explores the use of CGM data as input for\ndigital decision support tools. We investigate how Recurrent Neural Networks\n(RNNs) can be used for Short Term Blood Glucose (STBG) prediction and compare\nthe RNNs to conventional time-series forecasting using Autoregressive\nIntegrated Moving Average (ARIMA). A prediction horizon up to 90 min into the\nfuture is considered. In this context, we evaluate both population-based and\npatient-specific RNNs and contrast them to patient-specific ARIMA models and a\nsimple baseline predicting future observations as the last observed. We find\nthat the population-based RNN model is the best performing model across the\nconsidered prediction horizons without the need of patient-specific data. This\ndemonstrates the potential of RNNs for STBG prediction in diabetes patients\ntowards detecting/mitigating severe events in the STBG, in particular\nhypoglycemic events. However, further studies are needed in regards to the\nrobustness and practical use of the investigated STBG prediction models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:39:44 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 20:18:33 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Mohebbi", "Ali", ""], ["Johansen", "Alexander R.", ""], ["Hansen", "Nicklas", ""], ["Christensen", "Peter E.", ""], ["Tarp", "Jens M.", ""], ["Jensen", "Morten L.", ""], ["Bengtsson", "Henrik", ""], ["M\u00f8rup", "Morten", ""]]}, {"id": "2002.02820", "submitter": "Lukas P. Fr\\\"ohlich", "authors": "Lukas P. Fr\\\"ohlich, Edgar D. Klenske, Julia Vinogradska, Christian\n  Daniel, Melanie N. Zeilinger", "title": "Noisy-Input Entropy Search for Efficient Robust Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust optimization within the well-established\nBayesian optimization (BO) framework. While BO is intrinsically robust to noisy\nevaluations of the objective function, standard approaches do not consider the\ncase of uncertainty about the input parameters. In this paper, we propose\nNoisy-Input Entropy Search (NES), a novel information-theoretic acquisition\nfunction that is designed to find robust optima for problems with both input\nand measurement noise. NES is based on the key insight that the robust\nobjective in many cases can be modeled as a Gaussian process, however, it\ncannot be observed directly. We evaluate NES on several benchmark problems from\nthe optimization literature and from engineering. The results show that NES\nreliably finds robust optima, outperforming existing methods from the\nliterature on all benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:48:16 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Fr\u00f6hlich", "Lukas P.", ""], ["Klenske", "Edgar D.", ""], ["Vinogradska", "Julia", ""], ["Daniel", "Christian", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "2002.02826", "submitter": "Chi-Ken Lu", "authors": "Chi-Ken Lu, Patrick Shafto", "title": "Deep Moment Matching Kernel for Multi-source Gaussian Processes", "comments": "Revised version, title changed, experiments on high dimensional\n  multi-fidelity data added, related works revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human learners have the ability to solve new tasks efficiently if previous\nknowledge is relevant, which has motivated research into few-shot learning and\ntransfer learning. We formalize the integration of relevant knowledge as\nmulti-source regression in which the target function is inferred using Gaussian\nProcess (GP) with the deep moment matching (DMM) kernel. We obtain a\nnon-stationary DMM kernel from prior relevant data by analytically calculating\nthe covariance of the target function. We interpret the data-informed DMM\nkernel, which serves as prior for target function, as: (1) a refined similarity\ndetermined by squared distance in the latent space and (2) as propagating\nuncertainty measured in RKHS defined by the posterior covariance from the prior\nlearning. In comparison with the autoregressive models, variational DGP models\nand others, results show GP regression with the DMM kernels is effective when\napplying to the standard synthetic and real-world multi-fidelity data sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:56:11 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:07:01 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Lu", "Chi-Ken", ""], ["Shafto", "Patrick", ""]]}, {"id": "2002.02829", "submitter": "Zhimin Hou", "authors": "Zhimin Hou and Kuangen Zhang and Yi Wan and Dongyu Li and Chenglong Fu\n  and Haoyong Yu", "title": "Off-policy Maximum Entropy Reinforcement Learning : Soft Actor-Critic\n  with Advantage Weighted Mixture Policy(SAC-AWMP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal policy of a reinforcement learning problem is often discontinuous\nand non-smooth. I.e., for two states with similar representations, their\noptimal policies can be significantly different. In this case, representing the\nentire policy with a function approximator (FA) with shared parameters for all\nstates maybe not desirable, as the generalization ability of parameters sharing\nmakes representing discontinuous, non-smooth policies difficult. A common way\nto solve this problem, known as Mixture-of-Experts, is to represent the policy\nas the weighted sum of multiple components, where different components perform\nwell on different parts of the state space. Following this idea and inspired by\na recent work called advantage-weighted information maximization, we propose to\nlearn for each state weights of these components, so that they entail the\ninformation of the state itself and also the preferred action learned so far\nfor the state. The action preference is characterized via the advantage\nfunction. In this case, the weight of each component would only be large for\ncertain groups of states whose representations are similar and preferred action\nrepresentations are also similar. Therefore each component is easy to be\nrepresented. We call a policy parameterized in this way an Advantage Weighted\nMixture Policy (AWMP) and apply this idea to improve soft-actor-critic (SAC),\none of the most competitive continuous control algorithm. Experimental results\ndemonstrate that SAC with AWMP clearly outperforms SAC in four commonly used\ncontinuous control tasks and achieve stable performance across different random\nseeds.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:01:20 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Hou", "Zhimin", ""], ["Zhang", "Kuangen", ""], ["Wan", "Yi", ""], ["Li", "Dongyu", ""], ["Fu", "Chenglong", ""], ["Yu", "Haoyong", ""]]}, {"id": "2002.02836", "submitter": "Ivo Danihelka", "authors": "Danilo J. Rezende, Ivo Danihelka, George Papamakarios, Nan Rosemary\n  Ke, Ray Jiang, Theophane Weber, Karol Gregor, Hamza Merzic, Fabio Viola, Jane\n  Wang, Jovana Mitrovic, Frederic Besse, Ioannis Antonoglou, Lars Buesing", "title": "Causally Correct Partial Models for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, we can learn a model of future observations and\nrewards, and use it to plan the agent's next actions. However, jointly modeling\nfuture observations can be computationally expensive or even intractable if the\nobservations are high-dimensional (e.g. images). For this reason, previous\nworks have considered partial models, which model only part of the observation.\nIn this paper, we show that partial models can be causally incorrect: they are\nconfounded by the observations they don't model, and can therefore lead to\nincorrect planning. To address this, we introduce a general family of partial\nmodels that are provably causally correct, yet remain fast because they do not\nneed to fully model future observations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:18:15 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Rezende", "Danilo J.", ""], ["Danihelka", "Ivo", ""], ["Papamakarios", "George", ""], ["Ke", "Nan Rosemary", ""], ["Jiang", "Ray", ""], ["Weber", "Theophane", ""], ["Gregor", "Karol", ""], ["Merzic", "Hamza", ""], ["Viola", "Fabio", ""], ["Wang", "Jane", ""], ["Mitrovic", "Jovana", ""], ["Besse", "Frederic", ""], ["Antonoglou", "Ioannis", ""], ["Buesing", "Lars", ""]]}, {"id": "2002.02842", "submitter": "Satya Narayan Shukla", "authors": "Meet P. Vadera, Satya Narayan Shukla, Brian Jalaian and Benjamin M.\n  Marlin", "title": "Assessing the Adversarial Robustness of Monte Carlo and Distillation\n  Methods for Deep Bayesian Neural Network Classification", "comments": "Presented at SafeAI Workshop, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of assessing the adversarial\nrobustness of deep neural network models under both Markov chain Monte Carlo\n(MCMC) and Bayesian Dark Knowledge (BDK) inference approximations. We\ncharacterize the robustness of each method to two types of adversarial attacks:\nthe fast gradient sign method (FGSM) and projected gradient descent (PGD). We\nshow that full MCMC-based inference has excellent robustness, significantly\noutperforming standard point estimation-based learning. On the other hand, BDK\nprovides marginal improvements. As an additional contribution, we present a\nstorage-efficient approach to computing adversarial examples for large Monte\nCarlo ensembles using both the FGSM and PGD attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:29:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Vadera", "Meet P.", ""], ["Shukla", "Satya Narayan", ""], ["Jalaian", "Brian", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2002.02844", "submitter": "Shuisheng Zhou", "authors": "Li Chen, Shuizheng Zhou, Jiajun Ma", "title": "Stable Sparse Subspace Embedding for Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse random projection (RP) is a popular tool for dimensionality reduction\nthat shows promising performance with low computational complexity. However, in\nthe existing sparse RP matrices, the positions of non-zero entries are usually\nrandomly selected. Although they adopt uniform sampling with replacement, due\nto large sampling variance, the number of non-zeros is uneven among rows of the\nprojection matrix which is generated in one trial, and more data information\nmay be lost after dimension reduction. To break this bottleneck, based on\nrandom sampling without replacement in statistics, this paper builds a stable\nsparse subspace embedded matrix (S-SSE), in which non-zeros are uniformly\ndistributed. It is proved that the S-SSE is stabler than the existing matrix,\nand it can maintain Euclidean distance between points well after dimension\nreduction. Our empirical studies corroborate our theoretical findings and\ndemonstrate that our approach can indeed achieve satisfactory performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:30:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Chen", "Li", ""], ["Zhou", "Shuizheng", ""], ["Ma", "Jiajun", ""]]}, {"id": "2002.02846", "submitter": "Shuisheng Zhou", "authors": "Li Chen, Shuisheng Zhou, Jiajun Ma", "title": "Fast Kernel k-means Clustering Using Incomplete Cholesky Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based clustering algorithm can identify and capture the non-linear\nstructure in datasets, and thereby it can achieve better performance than\nlinear clustering. However, computing and storing the entire kernel matrix\noccupy so large memory that it is difficult for kernel-based clustering to deal\nwith large-scale datasets. In this paper, we employ incomplete Cholesky\nfactorization to accelerate kernel clustering and save memory space. The key\nidea of the proposed kernel $k$-means clustering using incomplete Cholesky\nfactorization is that we approximate the entire kernel matrix by the product of\na low-rank matrix and its transposition. Then linear $k$-means clustering is\napplied to columns of the transpose of the low-rank matrix. We show both\nanalytically and empirically that the performance of the proposed algorithm is\nsimilar to that of the kernel $k$-means clustering algorithm, but our method\ncan deal with large-scale datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:32:14 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Chen", "Li", ""], ["Zhou", "Shuisheng", ""], ["Ma", "Jiajun", ""]]}, {"id": "2002.02862", "submitter": "Yuling Jiao", "authors": "Yuan Gao and Jian Huang and Yuling Jiao and Jin Liu", "title": "Learning Implicit Generative Models with Theoretical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a \\textbf{uni}fied \\textbf{f}ramework for \\textbf{i}mplicit\n\\textbf{ge}nerative \\textbf{m}odeling (UnifiGem) with theoretical guarantees by\nintegrating approaches from optimal transport, numerical ODE, density-ratio\n(density-difference) estimation and deep neural networks. First, the problem of\nimplicit generative learning is formulated as that of finding the optimal\ntransport map between the reference distribution and the target distribution,\nwhich is characterized by a totally nonlinear Monge-Amp\\`{e}re equation.\nInterpreting the infinitesimal linearization of the Monge-Amp\\`{e}re equation\nfrom the perspective of gradient flows in measure spaces leads to the\ncontinuity equation or the McKean-Vlasov equation. We then solve the\nMcKean-Vlasov equation numerically using the forward Euler iteration, where the\nforward Euler map depends on the density ratio (density difference) between the\ndistribution at current iteration and the underlying target distribution. We\nfurther estimate the density ratio (density difference) via deep density-ratio\n(density-difference) fitting and derive explicit upper bounds on the estimation\nerror. Experimental results on both synthetic datasets and real benchmark\ndatasets support our theoretical findings and demonstrate the effectiveness of\nUnifiGem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:55:48 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 14:26:17 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Yuan", ""], ["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Liu", "Jin", ""]]}, {"id": "2002.02863", "submitter": "Bogdan Mazoure", "authors": "Bogdan Mazoure, Thang Doan, Tianyu Li, Vladimir Makarenkov, Joelle\n  Pineau, Doina Precup, Guillaume Rabusseau", "title": "Representation of Reinforcement Learning Policies in Reproducing Kernel\n  Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for policy representation for reinforcement\nlearning tasks. This framework involves finding a low-dimensional embedding of\nthe policy on a reproducing kernel Hilbert space (RKHS). The usage of RKHS\nbased methods allows us to derive strong theoretical guarantees on the expected\nreturn of the reconstructed policy. Such guarantees are typically lacking in\nblack-box models, but are very desirable in tasks requiring stability. We\nconduct several experiments on classic RL domains. The results confirm that the\npolicies can be robustly embedded in a low-dimensional space while the embedded\npolicy incurs almost no decrease in return.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:57:57 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 16:00:19 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mazoure", "Bogdan", ""], ["Doan", "Thang", ""], ["Li", "Tianyu", ""], ["Makarenkov", "Vladimir", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2002.02868", "submitter": "Younghan Jeon", "authors": "Younghan Jeon, Minsik Lee, Jin Young Choi", "title": "Differentiable Forward and Backward Fixed-Point Iteration Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies proposed methods to utilize some classes of\noptimization problems in designing deep neural networks to encode constraints\nthat conventional layers cannot capture. However, these methods are still in\ntheir infancy and require special treatments, such as analyzing the KKT\ncondition, for deriving the backpropagation formula. In this paper, we propose\na new layer formulation called the fixed-point iteration (FPI) layer that\nfacilitates the use of more complicated operations in deep networks. The\nbackward FPI layer is also proposed for backpropagation, which is motivated by\nthe recurrent back-propagation (RBP) algorithm. But in contrast to RBP, the\nbackward FPI layer yields the gradient by a small network module without an\nexplicit calculation of the Jacobian. In actual applications, both the forward\nand backward FPI layers can be treated as nodes in the computational graphs.\nAll components in the proposed method are implemented at a high level of\nabstraction, which allows efficient higher-order differentiations on the nodes.\nIn addition, we present two practical methods of the FPI layer, FPI_NN and\nFPI_GD, where the update operations of FPI are a small neural network module\nand a single gradient descent step based on a learnable cost function,\nrespectively. FPI\\_NN is intuitive, simple, and fast to train, while FPI_GD can\nbe used for efficient training of energy networks that have been recently\nstudied. While RBP and its related studies have not been applied to practical\nexamples, our experiments show the FPI layer can be successfully applied to\nreal-world problems such as image denoising, optical flow, and multi-label\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:02:44 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 15:16:24 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 03:35:21 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 02:36:24 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jeon", "Younghan", ""], ["Lee", "Minsik", ""], ["Choi", "Jin Young", ""]]}, {"id": "2002.02870", "submitter": "Faezeh Nejati Hatamian", "authors": "Faezeh Nejati Hatamian, Nishant Ravikumar, Sulaiman Vesal, Felix P.\n  Kemeth, Matthias Struck, Andreas Maier", "title": "The Effect of Data Augmentation on Classification of Atrial Fibrillation\n  in Short Single-Lead ECG Signals Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cardiovascular diseases are the most common cause of mortality worldwide.\nDetection of atrial fibrillation (AF) in the asymptomatic stage can help\nprevent strokes. It also improves clinical decision making through the delivery\nof suitable treatment such as, anticoagulant therapy, in a timely manner. The\nclinical significance of such early detection of AF in electrocardiogram (ECG)\nsignals has inspired numerous studies in recent years, of which many aim to\nsolve this task by leveraging machine learning algorithms. ECG datasets\ncontaining AF samples, however, usually suffer from severe class imbalance,\nwhich if unaccounted for, affects the performance of classification algorithms.\nData augmentation is a popular solution to tackle this problem.\n  In this study, we investigate the impact of various data augmentation\nalgorithms, e.g., oversampling, Gaussian Mixture Models (GMMs) and Generative\nAdversarial Networks (GANs), on solving the class imbalance problem. These\nalgorithms are quantitatively and qualitatively evaluated, compared and\ndiscussed in detail. The results show that deep learning-based AF signal\nclassification methods benefit more from data augmentation using GANs and GMMs,\nthan oversampling. Furthermore, the GAN results in circa $3\\%$ better AF\nclassification accuracy in average while performing comparably to the GMM in\nterms of f1-score.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:08:19 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:45:16 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Hatamian", "Faezeh Nejati", ""], ["Ravikumar", "Nishant", ""], ["Vesal", "Sulaiman", ""], ["Kemeth", "Felix P.", ""], ["Struck", "Matthias", ""], ["Maier", "Andreas", ""]]}, {"id": "2002.02878", "submitter": "Jason  Weston", "authors": "Shrimai Prabhumoye and Margaret Li and Jack Urbanek and Emily Dinan\n  and Douwe Kiela and Jason Weston and Arthur Szlam", "title": "I love your chain mail! Making knights smile in a fantasy game world:\n  Open-domain goal-oriented dialogue agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue research tends to distinguish between chit-chat and goal-oriented\ntasks. While the former is arguably more naturalistic and has a wider use of\nlanguage, the latter has clearer metrics and a straightforward learning signal.\nHumans effortlessly combine the two, for example engaging in chit-chat with the\ngoal of exchanging information or eliciting a specific response. Here, we\nbridge the divide between these two domains in the setting of a rich\nmulti-player text-based fantasy environment where agents and humans engage in\nboth actions and dialogue. Specifically, we train a goal-oriented model with\nreinforcement learning against an imitation-learned ``chit-chat'' model with\ntwo approaches: the policy either learns to pick a topic or learns to pick an\nutterance given the top-K utterances from the chit-chat model. We show that\nboth models outperform an inverse model baseline and can converse naturally\nwith their dialogue partner in order to achieve goals.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:22:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:45:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Li", "Margaret", ""], ["Urbanek", "Jack", ""], ["Dinan", "Emily", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""], ["Szlam", "Arthur", ""]]}, {"id": "2002.02879", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and Pranjul Yadav and Khoa Doan and S. Sathiya\n  Keerthi", "title": "Targeted display advertising: the case of preferential attachment", "comments": "IEEE BigData 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An average adult is exposed to hundreds of digital advertisements daily\n(https://www.mediadynamicsinc.com/uploads/files/PR092214-Note-only-150-Ads-2mk.pdf),\nmaking the digital advertisement industry a classic example of a\nbig-data-driven platform. As such, the ad-tech industry relies on historical\nengagement logs (clicks or purchases) to identify potentially interested users\nfor the advertisement campaign of a partner (a seller who wants to target users\nfor its products). The number of advertisements that are shown for a partner,\nand hence the historical campaign data available for a partner depends upon the\nbudget constraints of the partner. Thus, enough data can be collected for the\nhigh-budget partners to make accurate predictions, while this is not the case\nwith the low-budget partners. This skewed distribution of the data leads to\n\"preferential attachment\" of the targeted display advertising platforms towards\nthe high-budget partners. In this paper, we develop \"domain-adaptation\"\napproaches to address the challenge of predicting interested users for the\npartners with insufficient data, i.e., the tail partners. Specifically, we\ndevelop simple yet effective approaches that leverage the similarity among the\npartners to transfer information from the partners with sufficient data to\ncold-start partners, i.e., partners without any campaign data. Our approaches\nreadily adapt to the new campaign data by incremental fine-tuning, and hence\nwork at varying points of a campaign, and not just the cold-start. We present\nan experimental analysis on the historical logs of a major display advertising\nplatform (https://www.criteo.com/). Specifically, we evaluate our approaches\nacross 149 partners, at varying points of their campaigns. Experimental results\nshow that the proposed approaches outperform the other \"domain-adaptation\"\napproaches at different time points of the campaigns.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:23:17 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Manchanda", "Saurav", ""], ["Yadav", "Pranjul", ""], ["Doan", "Khoa", ""], ["Keerthi", "S. Sathiya", ""]]}, {"id": "2002.02883", "submitter": "Roger David Soberanis-Mukul", "authors": "Maxime Kayser, Roger D. Soberanis-Mukul, Anna-Maria Zvereva (M.D.),\n  Peter Klare (M.D.), Nassir Navab, Shadi Albarqouni", "title": "Understanding the effects of artifacts on automated polyp detection and\n  incorporating that knowledge via learning without forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival rates for colorectal cancer are higher when polyps are detected at\nan early stage and can be removed before they develop into malignant tumors.\nAutomated polyp detection, which is dominated by deep learning based methods,\nseeks to improve early detection of polyps. However, current efforts rely\nheavily on the size and quality of the training datasets. The quality of these\ndatasets often suffers from various image artifacts that affect the visibility\nand hence, the detection rate. In this work, we conducted a systematic analysis\nto gain a better understanding of how artifacts affect automated polyp\ndetection. We look at how six different artifact classes, and their location in\nan image, affect the performance of a RetinaNet based polyp detection model. We\nfound that, depending on the artifact class, they can either benefit or harm\nthe polyp detector. For instance, bubbles are often misclassified as polyps,\nwhile specular reflections inside of a polyp region can improve detection\ncapabilities. We then investigated different strategies, such as a learning\nwithout forgetting framework, to leverage artifact knowledge to improve\nautomated polyp detection. Our results show that such models can mitigate some\nof the harmful effects of artifacts, but require more work to significantly\nimprove polyp detection capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:34:14 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:54:17 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 09:57:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kayser", "Maxime", "", "M.D."], ["Soberanis-Mukul", "Roger D.", "", "M.D."], ["Zvereva", "Anna-Maria", "", "M.D."], ["Klare", "Peter", "", "M.D."], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "2002.02884", "submitter": "Mark Santolucito", "authors": "Kairo Morton, William Hallahan, Elven Shum, Ruzica Piskac, Mark\n  Santolucito", "title": "Grammar Filtering For Syntax-Guided Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming-by-example (PBE) is a synthesis paradigm that allows users to\ngenerate functions by simply providing input-output examples. While a promising\ninteraction paradigm, synthesis is still too slow for realtime interaction and\nmore widespread adoption. Existing approaches to PBE synthesis have used\nautomated reasoning tools, such as SMT solvers, as well as works applying\nmachine learning techniques. At its core, the automated reasoning approach\nrelies on highly domain specific knowledge of programming languages. On the\nother hand, the machine learning approaches utilize the fact that when working\nwith program code, it is possible to generate arbitrarily large training\ndatasets. In this work, we propose a system for using machine learning in\ntandem with automated reasoning techniques to solve Syntax Guided Synthesis\n(SyGuS) style PBE problems. By preprocessing SyGuS PBE problems with a neural\nnetwork, we can use a data driven approach to reduce the size of the search\nspace, then allow automated reasoning-based solvers to more quickly find a\nsolution analytically. Our system is able to run atop existing SyGuS PBE\nsynthesis tools, decreasing the runtime of the winner of the 2019 SyGuS\nCompetition for the PBE Strings track by 47.65% to outperform all of the\ncompeting tools.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:35:50 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Morton", "Kairo", ""], ["Hallahan", "William", ""], ["Shum", "Elven", ""], ["Piskac", "Ruzica", ""], ["Santolucito", "Mark", ""]]}, {"id": "2002.02885", "submitter": "Rui Liu", "authors": "Rui Liu, Sanjay Krishnan, Aaron J. Elmore, Michael J. Franklin", "title": "Understanding and Optimizing Packed Neural Network Training for\n  Hyper-Parameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks are increasingly employed in machine learning practice,\nhow to efficiently share limited training resources among a diverse set of\nmodel training tasks becomes a crucial issue. To achieve better utilization of\nthe shared resources, we explore the idea of jointly training multiple neural\nnetwork models on a single GPU in this paper. We realize this idea by proposing\na primitive, called pack. We further present a comprehensive empirical study of\npack and end-to-end experiments that suggest significant improvements for\nhyperparameter tuning. The results suggest: (1) packing two models can bring up\nto 40% performance improvement over unpacked setups for a single training step\nand the improvement increases when packing more models; (2) the benefit of the\npack primitive largely depends on a number of factors including memory\ncapacity, chip architecture, neural network structure, and batch size; (3)\nthere exists a trade-off between packing and unpacking when training multiple\nneural network models on limited resources; (4) a pack-aware Hyperband is up to\n2.7x faster than the original Hyperband, with this improvement growing as\nmemory size increases and subsequently the density of models packed.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:36:06 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 02:54:36 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 22:07:33 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 02:31:03 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Liu", "Rui", ""], ["Krishnan", "Sanjay", ""], ["Elmore", "Aaron J.", ""], ["Franklin", "Michael J.", ""]]}, {"id": "2002.02886", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Ben Poole, Gunnar R\\\"atsch, Bernhard Sch\\\"olkopf,\n  Olivier Bachem, Michael Tschannen", "title": "Weakly-Supervised Disentanglement Without Compromises", "comments": "We updated the description of the generation of the dataset compared\n  to the ICML version", "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents should be able to learn useful representations by\nobserving changes in their environment. We model such observations as pairs of\nnon-i.i.d. images sharing at least one of the underlying factors of variation.\nFirst, we theoretically show that only knowing how many factors have changed,\nbut not which ones, is sufficient to learn disentangled representations.\nSecond, we provide practical algorithms that learn disentangled representations\nfrom pairs of images without requiring annotation of groups, individual\nfactors, or the number of factors that have changed. Third, we perform a\nlarge-scale empirical study and show that such pairs of observations are\nsufficient to reliably learn disentangled representations on several benchmark\ndata sets. Finally, we evaluate our learned representations and find that they\nare simultaneously useful on a diverse suite of tasks, including generalization\nunder covariate shifts, fairness, and abstract reasoning. Overall, our results\ndemonstrate that weak supervision enables learning of useful disentangled\nrepresentations in realistic scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:39:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 20:58:49 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 15:24:40 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 15:22:16 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Locatello", "Francesco", ""], ["Poole", "Ben", ""], ["R\u00e4tsch", "Gunnar", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""], ["Tschannen", "Michael", ""]]}, {"id": "2002.02887", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio", "title": "Meta-learning framework with applications to zero-shot time-series\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can meta-learning discover generic ways of processing time series (TS) from a\ndiverse dataset so as to greatly improve generalization on new TS coming from\ndifferent datasets? This work provides positive evidence to this using a broad\nmeta-learning framework which we show subsumes many existing meta-learning\nalgorithms. Our theoretical analysis suggests that residual connections act as\na meta-learning adaptation mechanism, generating a subset of task-specific\nparameters based on a given TS input, thus gradually expanding the expressive\npower of the architecture on-the-fly. The same mechanism is shown via\nlinearization analysis to have the interpretation of a sequential update of the\nfinal linear layer. Our empirical results on a wide range of data emphasize the\nimportance of the identified meta-learning mechanisms for successful zero-shot\nunivariate forecasting, suggesting that it is viable to train a neural network\non a source TS dataset and deploy it on a different target TS dataset without\nretraining, resulting in performance that is at least as good as that of\nstate-of-practice univariate forecasting models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:39:43 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 02:42:54 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 19:33:05 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Carpov", "Dmitri", ""], ["Chapados", "Nicolas", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.02892", "submitter": "Nicolas Keriven", "authors": "Nicolas Keriven, Samuel Vaiter", "title": "Sparse and Smooth: improved guarantees for Spectral Clustering in the\n  Dynamic Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyse classical variants of the Spectral Clustering (SC)\nalgorithm in the Dynamic Stochastic Block Model (DSBM). Existing results show\nthat, in the relatively sparse case where the expected degree grows\nlogarithmically with the number of nodes, guarantees in the static case can be\nextended to the dynamic case and yield improved error bounds when the DSBM is\nsufficiently smooth in time, that is, the communities do not change too much\nbetween two time steps. We improve over these results by drawing a new link\nbetween the sparsity and the smoothness of the DSBM: the more regular the DSBM\nis, the more sparse it can be, while still guaranteeing consistent recovery. In\nparticular, a mild condition on the smoothness allows to treat the sparse case\nwith bounded degree. We also extend these guarantees to the normalized\nLaplacian, and as a by-product of our analysis, we obtain to our knowledge the\nbest spectral concentration bound available for the normalized Laplacian of\nmatrices with independent Bernoulli entries.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:49:25 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 15:46:24 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Keriven", "Nicolas", ""], ["Vaiter", "Samuel", ""]]}, {"id": "2002.02897", "submitter": "Yu Zhang", "authors": "Yu Zhang, Tao Gu, Xi Zhang", "title": "MDLdroid: a ChainSGD-reduce Approach to Mobile Deep Learning for\n  Personal Mobile Sensing", "comments": "Published in the International Conference on Information Processing\n  in Sensor Networks (IPSN), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal mobile sensing is fast permeating our daily lives to enable activity\nmonitoring, healthcare and rehabilitation. Combined with deep learning, these\napplications have achieved significant success in recent years. Different from\nconventional cloud-based paradigms, running deep learning on devices offers\nseveral advantages including data privacy preservation and low-latency response\nfor both model inference and update. Since data collection is costly in\nreality, Google's Federated Learning offers not only complete data privacy but\nalso better model robustness based on multiple user data. However, personal\nmobile sensing applications are mostly user-specific and highly affected by\nenvironment. As a result, continuous local changes may seriously affect the\nperformance of a global model generated by Federated Learning. In addition,\ndeploying Federated Learning on a local server, e.g., edge server, may quickly\nreach the bottleneck due to resource constraint and serious failure by attacks.\nTowards pushing deep learning on devices, we present MDLdroid, a novel\ndecentralized mobile deep learning framework to enable resource-aware on-device\ncollaborative learning for personal mobile sensing applications. To address\nresource limitation, we propose a ChainSGD-reduce approach which includes a\nnovel chain-directed Synchronous Stochastic Gradient Descent algorithm to\neffectively reduce overhead among multiple devices. We also design an\nagent-based multi-goal reinforcement learning mechanism to balance resources in\na fair and efficient manner. Our evaluations show that our model training on\noff-the-shelf mobile devices achieves 2x to 3.5x faster than single-device\ntraining, and 1.5x faster than the master-slave approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:55:21 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 14:34:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Yu", ""], ["Gu", "Tao", ""], ["Zhang", "Xi", ""]]}, {"id": "2002.02901", "submitter": "Azadeh Khaleghi", "authors": "Steffen Gr\\\"unew\\\"alder and Azadeh Khaleghi", "title": "Oblivious Data for Fairness with Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of algorithmic fairness in the case where\nsensitive and non-sensitive features are available and one aims to generate\nnew, `oblivious', features that closely approximate the non-sensitive features,\nand are only minimally dependent on the sensitive ones. We study this question\nin the context of kernel methods. We analyze a relaxed version of the Maximum\nMean Discrepancy criterion which does not guarantee full independence but makes\nthe optimization problem tractable. We derive a closed-form solution for this\nrelaxed optimization problem and complement the result with a study of the\ndependencies between the newly generated features and the sensitive ones. Our\nkey ingredient for generating such oblivious features is a Hilbert-space-valued\nconditional expectation, which needs to be estimated from data. We propose a\nplug-in approach and demonstrate how the estimation errors can be controlled.\nWhile our techniques help reduce the bias, we would like to point out that no\npost-processing of any dataset could possibly serve as an alternative to\nwell-designed experiments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:59:24 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 19:44:18 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Gr\u00fcnew\u00e4lder", "Steffen", ""], ["Khaleghi", "Azadeh", ""]]}, {"id": "2002.02903", "submitter": "Yiying Fan", "authors": "Yiying Fan and Jiayang Sun", "title": "Subsampling Winner Algorithm for Feature Selection in Large Regression\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection from a large number of covariates (aka features) in a\nregression analysis remains a challenge in data science, especially in terms of\nits potential of scaling to ever-enlarging data and finding a group of\nscientifically meaningful features. For example, to develop new, responsive\ndrug targets for ovarian cancer, the actual false discovery rate (FDR) of a\npractical feature selection procedure must also match the target FDR. The\npopular approach to feature selection, when true features are sparse, is to use\na penalized likelihood or a shrinkage estimation, such as a LASSO, SCAD,\nElastic Net, or MCP procedure (call them benchmark procedures). We present a\ndifferent approach using a new subsampling method, called the Subsampling\nWinner algorithm (SWA). The central idea of SWA is analogous to that used for\nthe selection of US national merit scholars. SWA uses a \"base procedure\" to\nanalyze each of the subsamples, computes the scores of all features according\nto the performance of each feature from all subsample analyses, obtains the\n\"semifinalist\" based on the resulting scores, and then determines the\n\"finalists,\" i.e., the most important features. Due to its subsampling nature,\nSWA can scale to data of any dimension in principle. The SWA also has the\nbest-controlled actual FDR in comparison with the benchmark procedures and the\nrandomForest, while having a competitive true-feature discovery rate. We also\nsuggest practical add-on strategies to SWA with or without a penalized\nbenchmark procedure to further assure the chance of \"true\" discovery. Our\napplication of SWA to the ovarian serous cystadenocarcinoma specimens from the\nBroad Institute revealed functionally important genes and pathways, which we\nverified by additional genomics tools. This second-stage investigation is\nessential in the current discussion of the proper use of P-values.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:01:59 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Fan", "Yiying", ""], ["Sun", "Jiayang", ""]]}, {"id": "2002.02912", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh", "title": "Universal Equivariant Multilayer Perceptrons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group invariant and equivariant Multilayer Perceptrons (MLP), also known as\nEquivariant Networks, have achieved remarkable success in learning on a variety\nof data structures, such as sequences, images, sets, and graphs. Using tools\nfrom group theory, this paper proves the universality of a broad class of\nequivariant MLPs with a single hidden layer. In particular, it is shown that\nhaving a hidden layer on which the group acts regularly is sufficient for\nuniversal equivariance (invariance). A corollary is unconditional universality\nof equivariant MLPs for Abelian groups, such as CNNs with a single hidden\nlayer. A second corollary is the universality of equivariant MLPs with a\nhigh-order hidden layer, where we give both group-agnostic bounds and means for\ncalculating group-specific bounds on the order of hidden layer that guarantees\nuniversal equivariance (invariance).\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:25:59 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 22:28:22 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Ravanbakhsh", "Siamak", ""]]}, {"id": "2002.02913", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Dixin Luo, Ricardo Henao, Svati Shah, Lawrence Carin", "title": "Learning Autoencoders with Relational Regularization", "comments": null, "journal-ref": "International conference on machine learning 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithmic framework is proposed for learning autoencoders of data\ndistributions. We minimize the discrepancy between the model and target\ndistributions, with a \\emph{relational regularization} on the learnable latent\nprior. This regularization penalizes the fused Gromov-Wasserstein (FGW)\ndistance between the latent prior and its corresponding posterior, allowing one\nto flexibly learn a structured prior distribution associated with the\ngenerative model. Moreover, it helps co-training of multiple autoencoders even\nif they have heterogeneous architectures and incomparable latent spaces. We\nimplement the framework with two scalable algorithms, making it applicable for\nboth probabilistic and deterministic autoencoders. Our relational regularized\nautoencoder (RAE) outperforms existing methods, $e.g.$, the variational\nautoencoder, Wasserstein autoencoder, and their variants, on generating images.\nAdditionally, our relational co-training strategy for autoencoders achieves\nencouraging results in both synthesis and real-world multi-view learning tasks.\nThe code is at https://github.com/HongtengXu/ Relational-AutoEncoders.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:27:30 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:46:10 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 01:40:48 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 01:05:36 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Henao", "Ricardo", ""], ["Shah", "Svati", ""], ["Carin", "Lawrence", ""]]}, {"id": "2002.02919", "submitter": "Qifan Song", "authors": "Qifan Song, Yan Sun, Mao Ye, Faming Liang", "title": "Extended Stochastic Gradient MCMC for Large-Scale Bayesian Variable\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Markov chain Monte Carlo (MCMC) algorithms have received\nmuch attention in Bayesian computing for big data problems, but they are only\napplicable to a small class of problems for which the parameter space has a\nfixed dimension and the log-posterior density is differentiable with respect to\nthe parameters. This paper proposes an extended stochastic gradient MCMC\nlgoriathm which, by introducing appropriate latent variables, can be applied to\nmore general large-scale Bayesian computing problems, such as those involving\ndimension jumping and missing data. Numerical studies show that the proposed\nalgorithm is highly scalable and much more efficient than traditional MCMC\nalgorithms. The proposed algorithms have much alleviated the pain of Bayesian\nmethods in big data computing.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:47:07 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Song", "Qifan", ""], ["Sun", "Yan", ""], ["Ye", "Mao", ""], ["Liang", "Faming", ""]]}, {"id": "2002.02923", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis and Nicol\\`o Fusi", "title": "Geometric Dataset Distances via Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of task similarity is at the core of various machine learning\nparadigms, such as domain adaptation and meta-learning. Current methods to\nquantify it are often heuristic, make strong assumptions on the label sets\nacross the tasks, and many are architecture-dependent, relying on task-specific\noptimal parameters (e.g., require training a model on each dataset). In this\nwork we propose an alternative notion of distance between datasets that (i) is\nmodel-agnostic, (ii) does not involve training, (iii) can compare datasets even\nif their label sets are completely disjoint and (iv) has solid theoretical\nfooting. This distance relies on optimal transport, which provides it with rich\ngeometry awareness, interpretable correspondences and well-understood\nproperties. Our results show that this novel distance provides meaningful\ncomparison of datasets, and correlates well with transfer learning hardness\nacross various experimental settings and datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:51:26 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Fusi", "Nicol\u00f2", ""]]}, {"id": "2002.02948", "submitter": "David E. Shaw", "authors": "Paul Maragakis, Hunter Nisonoff, Brian Cole, and David E. Shaw", "title": "A deep-learning view of chemical space designed to facilitate drug\n  discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug discovery projects entail cycles of design, synthesis, and testing that\nyield a series of chemically related small molecules whose properties, such as\nbinding affinity to a given target protein, are progressively tailored to a\nparticular drug discovery goal. The use of deep learning technologies could\naugment the typical practice of using human intuition in the design cycle, and\nthereby expedite drug discovery projects. Here we present DESMILES, a deep\nneural network model that advances the state of the art in machine learning\napproaches to molecular design. We applied DESMILES to a previously published\nbenchmark that assesses the ability of a method to modify input molecules to\ninhibit the dopamine receptor D2, and DESMILES yielded a 77% lower failure rate\ncompared to state-of-the-art models. To explain the ability of DESMILES to hone\nmolecular properties, we visualize a layer of the DESMILES network, and further\ndemonstrate this ability by using DESMILES to tailor the same molecules used in\nthe D2 benchmark test to dock more potently against seven different receptors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:32:44 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Maragakis", "Paul", ""], ["Nisonoff", "Hunter", ""], ["Cole", "Brian", ""], ["Shaw", "David E.", ""]]}, {"id": "2002.02949", "submitter": "Priyadarshini Panda", "authors": "Timothy Foldy-Porto, Yeshwanth Venkatesha, and Priyadarshini Panda", "title": "Activation Density driven Energy-Efficient Pruning in Training", "comments": "8 pages, 5 figures, 4 tables (Accepted in ICPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning with suitable retraining can yield networks with\nconsiderably fewer parameters than the original with comparable degrees of\naccuracy. Typical pruning methods require large, fully trained networks as a\nstarting point from which they perform a time-intensive iterative pruning and\nretraining procedure to regain the original accuracy. We propose a novel\npruning method that prunes a network real-time during training, reducing the\noverall training time to achieve an efficient compressed network. We introduce\nan activation density based analysis to identify the optimal relative sizing or\ncompression for each layer of the network. Our method is architecture agnostic,\nallowing it to be employed on a wide variety of systems. For VGG-19 and\nResNet18 on CIFAR-10, CIFAR-100, and TinyImageNet, we obtain exceedingly sparse\nnetworks (up to $200 \\times$ reduction in parameters and over $60 \\times$\nreduction in inference compute operations in the best case) with accuracy\ncomparable to the baseline network. By reducing the network size periodically\nduring training, we achieve total training times that are shorter than those of\npreviously proposed pruning methods. Furthermore, training compressed networks\nat different epochs with our proposed method yields considerable reduction in\ntraining compute complexity ($1.6\\times$ to $3.2\\times$ lower) at near\niso-accuracy as compared to a baseline network trained entirely from scratch.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:34:31 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:16:25 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Foldy-Porto", "Timothy", ""], ["Venkatesha", "Yeshwanth", ""], ["Panda", "Priyadarshini", ""]]}, {"id": "2002.02950", "submitter": "Gil Shamir", "authors": "Gil I. Shamir", "title": "Logistic Regression Regret: What's the Catch?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of the achievable regret rates with online logistic\nregression. We derive lower bounds with logarithmic regret under $L_1$, $L_2$,\nand $L_\\infty$ constraints on the parameter values. The bounds are dominated by\n$d/2 \\log T$, where $T$ is the horizon and $d$ is the dimensionality of the\nparameter space. We show their achievability for $d=o(T^{1/3})$ in all these\ncases with Bayesian methods, that achieve them up to a $d/2 \\log d$ term.\nInteresting different behaviors are shown for larger dimensionality.\nSpecifically, on the negative side, if $d = \\Omega(\\sqrt{T})$, any algorithm is\nguaranteed regret of $\\Omega(d \\log T)$ (greater than $\\Omega(\\sqrt{T})$) under\n$L_\\infty$ constraints on the parameters (and the example features). On the\npositive side, under $L_1$ constraints on the parameters, there exist\nalgorithms that can achieve regret that is sub-linear in $d$ for the\nasymptotically larger values of $d$. For $L_2$ constraints, it is shown that\nfor large enough $d$, the regret remains linear in $d$ but no longer\nlogarithmic in $T$. Adapting the redundancy-capacity theorem from information\ntheory, we demonstrate a principled methodology based on grids of parameters to\nderive lower bounds. Grids are also utilized to derive some upper bounds. Our\nresults strengthen results by Kakade and Ng (2005) and Foster et al. (2018) for\nupper bounds for this problem, introduce novel lower bounds, and adapt a\nmethodology that can be used to obtain such bounds for other related problems.\nThey also give a novel characterization of the asymptotic behavior when the\ndimension of the parameter space is allowed to grow with $T$. They additionally\nestablish connections to the information theory literature, demonstrating that\nthe actual regret for logistic regression depends on the richness of the\nparameter class, where even within this problem, richer classes lead to greater\nregret.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:36:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:27:53 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Shamir", "Gil I.", ""]]}, {"id": "2002.02959", "submitter": "Gamaleldin Elsayed", "authors": "Gamaleldin F. Elsayed, Prajit Ramachandran, Jonathon Shlens, Simon\n  Kornblith", "title": "Revisiting Spatial Invariance with Low-Rank Local Connectivity", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are among the most successful architectures in\ndeep learning with this success at least partially attributable to the efficacy\nof spatial invariance as an inductive bias. Locally connected layers, which\ndiffer from convolutional layers only in their lack of spatial invariance,\nusually perform poorly in practice. However, these observations still leave\nopen the possibility that some degree of relaxation of spatial invariance may\nyield a better inductive bias than either convolution or local connectivity. To\ntest this hypothesis, we design a method to relax the spatial invariance of a\nnetwork layer in a controlled manner; we create a \\textit{low-rank} locally\nconnected layer, where the filter bank applied at each position is constructed\nas a linear combination of basis set of filter banks with spatially varying\ncombining weights. By varying the number of basis filter banks, we can control\nthe degree of relaxation of spatial invariance. In experiments with small\nconvolutional networks, we find that relaxing spatial invariance improves\nclassification accuracy over both convolution and locally connected layers\nacross MNIST, CIFAR-10, and CelebA datasets, thus suggesting that spatial\ninvariance may be an overly restrictive prior.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:56:37 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:45:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Ramachandran", "Prajit", ""], ["Shlens", "Jonathon", ""], ["Kornblith", "Simon", ""]]}, {"id": "2002.02991", "submitter": "Zhibin Li PhD", "authors": "Chuanyu Yang, Kai Yuan, Wolfgang Merkt, Taku Komura, Sethu\n  Vijayakumar, Zhibin Li", "title": "Learning Whole-body Motor Skills for Humanoids", "comments": "2018 IEEE-RAS 18th International Conference on Humanoid Robots\n  (Humanoids)", "journal-ref": null, "doi": "10.1109/HUMANOIDS.2018.8625045", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hierarchical framework for Deep Reinforcement Learning\nthat acquires motor skills for a variety of push recovery and balancing\nbehaviors, i.e., ankle, hip, foot tilting, and stepping strategies. The policy\nis trained in a physics simulator with realistic setting of robot model and\nlow-level impedance control that are easy to transfer the learned skills to\nreal robots. The advantage over traditional methods is the integration of\nhigh-level planner and feedback control all in one single coherent policy\nnetwork, which is generic for learning versatile balancing and recovery motions\nagainst unknown perturbations at arbitrary locations (e.g., legs, torso).\nFurthermore, the proposed framework allows the policy to be learned quickly by\nmany state-of-the-art learning algorithms. By comparing our learned results to\nstudies of preprogrammed, special-purpose controllers in the literature,\nself-learned skills are comparable in terms of disturbance rejection but with\nadditional advantages of producing a wide range of adaptive, versatile and\nrobust behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 19:40:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yang", "Chuanyu", ""], ["Yuan", "Kai", ""], ["Merkt", "Wolfgang", ""], ["Komura", "Taku", ""], ["Vijayakumar", "Sethu", ""], ["Li", "Zhibin", ""]]}, {"id": "2002.02997", "submitter": "Sergul Aydore", "authors": "Liyan Chen, Philip Gautier, Sergul Aydore", "title": "DropCluster: A structured dropout for convolutional networks", "comments": "11 pages, 10 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout as a regularizer in deep neural networks has been less effective in\nconvolutional layers than in fully connected layers. This is due to the fact\nthat dropout drops features randomly. When features are spatially correlated as\nin the case of convolutional layers, information about the dropped pixels can\nstill propagate to the next layers via neighboring pixels. In order to address\nthis problem, more structured forms of dropout have been proposed. A drawback\nof these methods is that they do not adapt to the data. In this work, we\nintroduce a novel structured regularization for convolutional layers, which we\ncall DropCluster. Our regularizer relies on data-driven structure. It finds\nclusters of correlated features in convolutional layer outputs and drops the\nclusters randomly at each iteration. The clusters are learned and updated\nduring model training so that they adapt both to the data and to the model\nweights. Our experiments on the ResNet-50 architecture demonstrate that our\napproach achieves better performance than DropBlock or other existing\nstructured dropout variants. We also demonstrate the robustness of our approach\nwhen the size of training data is limited and when there is corruption in the\ndata at test time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:02:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Liyan", ""], ["Gautier", "Philip", ""], ["Aydore", "Sergul", ""]]}, {"id": "2002.02998", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Cha Zhang, Diana Marculescu", "title": "Renofeation: A Simple Transfer Learning Method for Improved Adversarial\n  Robustness", "comments": "2021 IEEE CVPR Workshop on Fair, Data Efficient and Trusted Computer\n  Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning through knowledge transfer from a pre-trained model on a\nlarge-scale dataset is a widely spread approach to effectively build models on\nsmall-scale datasets. In this work, we show that a recent adversarial attack\ndesigned for transfer learning via re-training the last linear layer can\nsuccessfully deceive models trained with transfer learning via end-to-end\nfine-tuning. This raises security concerns for many industrial applications. In\ncontrast, models trained with random initialization without transfer are much\nmore robust to such attacks, although these models often exhibit much lower\naccuracy. To this end, we propose noisy feature distillation, a new transfer\nlearning method that trains a network from random initialization while\nachieving clean-data performance competitive with fine-tuning. Code available\nat https://github.com/cmu-enyac/Renofeation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:07:22 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 14:46:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Zhang", "Cha", ""], ["Marculescu", "Diana", ""]]}, {"id": "2002.03014", "submitter": "Benjamin Stevens", "authors": "Ben Stevens, Tim Colonius", "title": "FiniteNet: A Fully Convolutional LSTM Network Architecture for\n  Time-Dependent Partial Differential Equations", "comments": "8 pages, 12 figures. Under review for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a machine learning approach for reducing the error\nwhen numerically solving time-dependent partial differential equations (PDE).\nWe use a fully convolutional LSTM network to exploit the spatiotemporal\ndynamics of PDEs. The neural network serves to enhance finite-difference and\nfinite-volume methods (FDM/FVM) that are commonly used to solve PDEs, allowing\nus to maintain guarantees on the order of convergence of our method. We train\nthe network on simulation data, and show that our network can reduce error by a\nfactor of 2 to 3 compared to the baseline algorithms. We demonstrate our method\non three PDEs that each feature qualitatively different dynamics. We look at\nthe linear advection equation, which propagates its initial conditions at a\nconstant speed, the inviscid Burgers' equation, which develops shockwaves, and\nthe Kuramoto-Sivashinsky (KS) equation, which is chaotic.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:18:46 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Stevens", "Ben", ""], ["Colonius", "Tim", ""]]}, {"id": "2002.03016", "submitter": "Aaron Kandel", "authors": "Aaron Kandel, Scott J. Moura", "title": "Safe Wasserstein Constrained Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distributionally robust Q-Learning algorithm (DrQ)\nwhich leverages Wasserstein ambiguity sets to provide probabilistic\nout-of-sample safety guarantees during online learning. First, we follow past\nwork by separating the constraint functions from the principal objective to\ncreate a hierarchy of machines which estimate the feasible state-action space\nwithin the constrained Markov decision process (CMDP). DrQ works within this\nframework by augmenting constraint costs with tightening offset variables\nobtained through Wasserstein distributionally robust optimization (DRO). These\noffset variables correspond to worst-case distributions of modeling error\ncharacterized by the TD-errors of the constraint Q-functions. This procedure\nallows us to safely approach the nominal constraint boundaries with strong\nprobabilistic safety guarantees. Using a case study of safe lithium-ion battery\nfast charging, we demonstrate dramatic improvements in safety and performance\nrelative to conventional methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:23:46 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 20:08:04 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kandel", "Aaron", ""], ["Moura", "Scott J.", ""]]}, {"id": "2002.03018", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, J. Zico Kolter", "title": "Certified Robustness to Label-Flipping Attacks via Randomized Smoothing", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are known to be susceptible to data poisoning\nattacks, where an adversary manipulates the training data to degrade\nperformance of the resulting classifier. In this work, we present a unifying\nview of randomized smoothing over arbitrary functions, and we leverage this\nnovel characterization to propose a new strategy for building classifiers that\nare pointwise-certifiably robust to general data poisoning attacks. As a\nspecific instantiation, we utilize our framework to build linear classifiers\nthat are robust to a strong variant of label flipping, where each test example\nis targeted independently. In other words, for each test point, our classifier\nincludes a certification that its prediction would be the same had some number\nof training labels been changed adversarially. Randomized smoothing has\npreviously been used to guarantee---with high probability---test-time\nrobustness to adversarial manipulation of the input to a classifier; we derive\na variant which provides a deterministic, analytical bound, sidestepping the\nprobabilistic certificates that traditionally result from the sampling\nsubprocedure. Further, we obtain these certified bounds with minimal additional\nruntime complexity over standard classification and no assumptions on the train\nor test distributions. We generalize our results to the multi-class case,\nproviding the first multi-class classification algorithm that is certifiably\nrobust to label-flipping attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:28:30 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:16:35 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 03:27:14 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 13:17:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Winston", "Ezra", ""], ["Ravikumar", "Pradeep", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2002.03035", "submitter": "Adil Salim", "authors": "Adil Salim, Anna Korba, Giulia Luise", "title": "The Wasserstein Proximal Gradient Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wasserstein gradient flows are continuous time dynamics that define curves of\nsteepest descent to minimize an objective function over the space of\nprobability measures (i.e., the Wasserstein space). This objective is typically\na divergence w.r.t. a fixed target distribution. In recent years, these\ncontinuous time dynamics have been used to study the convergence of machine\nlearning algorithms aiming at approximating a probability distribution.\nHowever, the discrete-time behavior of these algorithms might differ from the\ncontinuous time dynamics. Besides, although discretized gradient flows have\nbeen proposed in the literature, little is known about their minimization\npower. In this work, we propose a Forward Backward (FB) discretization scheme\nthat can tackle the case where the objective function is the sum of a smooth\nand a nonsmooth geodesically convex terms. Using techniques from convex\noptimization and optimal transport, we analyze the FB scheme as a minimization\nalgorithm on the Wasserstein space. More precisely, we show under mild\nassumptions that the FB scheme has convergence guarantees similar to the\nproximal gradient algorithm in Euclidean spaces.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 22:19:32 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 16:08:13 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 13:57:47 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Salim", "Adil", ""], ["Korba", "Anna", ""], ["Luise", "Giulia", ""]]}, {"id": "2002.03043", "submitter": "Goutham Ramakrishnan", "authors": "Goutham Ramakrishnan, Jordan Henkel, Zi Wang, Aws Albarghouthi, Somesh\n  Jha, Thomas Reps", "title": "Semantic Robustness of Models of Source Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples - small input\nperturbations that result in incorrect predictions. We study this problem for\nmodels of source code, where we want the network to be robust to source-code\nmodifications that preserve code functionality. (1) We define a powerful\nadversary that can employ sequences of parametric, semantics-preserving program\ntransformations; (2) we show how to perform adversarial training to learn\nmodels robust to such adversaries; (3) we conduct an evaluation on different\nlanguages and architectures, demonstrating significant quantitative gains in\nrobustness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 23:26:17 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:50:05 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ramakrishnan", "Goutham", ""], ["Henkel", "Jordan", ""], ["Wang", "Zi", ""], ["Albarghouthi", "Aws", ""], ["Jha", "Somesh", ""], ["Reps", "Thomas", ""]]}, {"id": "2002.03054", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Hidetoshi Shimodaira", "title": "Extrapolation Towards Imaginary $0$-Nearest Neighbour and Its Improved\n  Convergence Rate", "comments": "27 pages (with Supplementary Material), 4 figures, NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-nearest neighbour ($k$-NN) is one of the simplest and most widely-used\nmethods for supervised classification, that predicts a query's label by taking\nweighted ratio of observed labels of $k$ objects nearest to the query. The\nweights and the parameter $k \\in \\mathbb{N}$ regulate its bias-variance\ntrade-off, and the trade-off implicitly affects the convergence rate of the\nexcess risk for the $k$-NN classifier; several existing studies considered\nselecting optimal $k$ and weights to obtain faster convergence rate. Whereas\n$k$-NN with non-negative weights has been developed widely, it was also proved\nthat negative weights are essential for eradicating the bias terms and\nattaining optimal convergence rate. In this paper, we propose a novel\nmultiscale $k$-NN (MS-$k$-NN), that extrapolates unweighted $k$-NN estimators\nfrom several $k \\ge 1$ values to $k=0$, thus giving an imaginary 0-NN\nestimator. Our method implicitly computes optimal real-valued weights that are\nadaptive to the query and its neighbour points. We theoretically prove that the\nMS-$k$-NN attains the improved rate, which coincides with the existing optimal\nrate under some conditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 00:32:12 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 01:14:14 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Okuno", "Akifumi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "2002.03061", "submitter": "Rui Wang", "authors": "Rui Wang, Robin Walters, Rose Yu", "title": "Incorporating Symmetry into Deep Dynamics Models for Improved\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown deep learning can accelerate the prediction of physical\ndynamics relative to numerical solvers. However, limited physical accuracy and\nan inability to generalize under distributional shift limit its applicability\nto the real world. We propose to improve accuracy and generalization by\nincorporating symmetries into convolutional neural networks. Specifically, we\nemploy a variety of methods each tailored to enforce a different symmetry. Our\nmodels are both theoretically and experimentally robust to distributional shift\nby symmetry group transformations and enjoy favorable sample complexity. We\ndemonstrate the advantage of our approach on a variety of physical dynamics\nincluding Rayleigh B\\'enard convection and real-world ocean currents and\ntemperatures. Compared with image or text applications, our work is a\nsignificant step towards applying equivariant neural networks to\nhigh-dimensional systems with complex dynamics. We open-source our simulation,\ndata, and code at \\url{https://github.com/Rose-STL-Lab/Equivariant-Net}.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:28:17 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 21:29:31 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 15:16:10 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 23:00:39 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Wang", "Rui", ""], ["Walters", "Robin", ""], ["Yu", "Rose", ""]]}, {"id": "2002.03069", "submitter": "Botao Hao", "authors": "Botao Hao, Nevena Lazic, Yasin Abbasi-Yadkori, Pooria Joulani, Csaba\n  Szepesvari", "title": "Adaptive Approximate Policy Iteration", "comments": "Accepted at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning algorithms combined with value function\napproximation have recently achieved impressive performance in a variety of\napplication domains. However, the theoretical understanding of such algorithms\nis limited, and existing results are largely focused on episodic or discounted\nMarkov decision processes (MDPs). In this work, we present adaptive approximate\npolicy iteration (AAPI), a learning scheme which enjoys a $\\tilde{O}(T^{2/3})$\nregret bound for undiscounted, continuing learning in uniformly ergodic MDPs.\nThis is an improvement over the best existing bound of $\\tilde{O}(T^{3/4})$ for\nthe average-reward case with function approximation. Our algorithm and analysis\nrely on online learning techniques, where value functions are treated as\nlosses. The main technical novelty is the use of a data-dependent adaptive\nlearning rate coupled with a so-called optimistic prediction of upcoming\nlosses. In addition to theoretical guarantees, we demonstrate the advantages of\nour approach empirically on several environments.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:27:03 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 01:25:04 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2020 00:51:31 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 17:01:17 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hao", "Botao", ""], ["Lazic", "Nevena", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Joulani", "Pooria", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "2002.03072", "submitter": "Theofanis Karaletsos", "authors": "Christian F. Perez, Felipe Petroski Such, Theofanis Karaletsos", "title": "Generalized Hidden Parameter MDPs Transferable Model-based RL in a\n  Handful of Trials", "comments": "paper presented at AAAI 2020 as oral presentation, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is broad interest in creating RL agents that can solve many (related)\ntasks and adapt to new tasks and environments after initial training.\nModel-based RL leverages learned surrogate models that describe dynamics and\nrewards of individual tasks, such that planning in a good surrogate can lead to\ngood control of the true system. Rather than solving each task individually\nfrom scratch, hierarchical models can exploit the fact that tasks are often\nrelated by (unobserved) causal factors of variation in order to achieve\nefficient generalization, as in learning how the mass of an item affects the\nforce required to lift it can generalize to previously unobserved masses. We\npropose Generalized Hidden Parameter MDPs (GHP-MDPs) that describe a family of\nMDPs where both dynamics and reward can change as a function of hidden\nparameters that vary across tasks. The GHP-MDP augments model-based RL with\nlatent variables that capture these hidden parameters, facilitating transfer\nacross tasks. We also explore a variant of the model that incorporates explicit\nlatent structure mirroring the causal factors of variation across tasks (for\ninstance: agent properties, environmental factors, and goals). We\nexperimentally demonstrate state-of-the-art performance and sample-efficiency\non a new challenging MuJoCo task using reward and dynamics latent spaces, while\nbeating a previous state-of-the-art baseline with $>10\\times$ less data. Using\ntest-time inference of the latent variables, our approach generalizes in a\nsingle episode to novel combinations of dynamics and reward, and to novel\nrewards.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:49:33 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Perez", "Christian F.", ""], ["Such", "Felipe Petroski", ""], ["Karaletsos", "Theofanis", ""]]}, {"id": "2002.03080", "submitter": "Adam Dziedzic", "authors": "Adam Dziedzic, Sanjay Krishnan", "title": "Analysis of Random Perturbations for Robust Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has extensively shown that randomized perturbations of neural\nnetworks can improve robustness to adversarial attacks. The literature is,\nhowever, lacking a detailed compare-and-contrast of the latest proposals to\nunderstand what classes of perturbations work, when they work, and why they\nwork. We contribute a detailed evaluation that elucidates these questions and\nbenchmarks perturbation based defenses consistently. In particular, we show\nfive main results: (1) all input perturbation defenses, whether random or\ndeterministic, are equivalent in their efficacy, (2) attacks transfer between\nperturbation defenses so the attackers need not know the specific type of\ndefense -- only that it involves perturbations, (3) a tuned sequence of noise\nlayers across a network provides the best empirical robustness, (4)\nperturbation based defenses offer almost no robustness to adaptive attacks\nunless these perturbations are observed during training, and (5) adversarial\nexamples in a close neighborhood of original inputs show an elevated\nsensitivity to perturbations in first and second-order analyses.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:46:07 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 00:22:31 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 19:56:06 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 19:25:31 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dziedzic", "Adam", ""], ["Krishnan", "Sanjay", ""]]}, {"id": "2002.03090", "submitter": "Milo\\v{s} Nikoli\\'c", "authors": "Milo\\v{s} Nikoli\\'c, Ghouthi Boukli Hacene, Ciaran Bannon, Alberto\n  Delmas Lascorz, Matthieu Courbariaux, Yoshua Bengio, Vincent Gripon and\n  Andreas Moshovos", "title": "BitPruning: Learning Bitlengths for Aggressive and Accurate Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrably achieved state-of-the art accuracy using\nlow-bitlength integer quantization, yielding both execution time and energy\nbenefits on existing hardware designs that support short bitlengths. However,\nthe question of finding the minimum bitlength for a desired accuracy remains\nopen. We introduce a training method for minimizing inference bitlength at any\ngranularity while maintaining accuracy. Namely, we propose a regularizer that\npenalizes large bitlength representations throughout the architecture and show\nhow it can be modified to minimize other quantifiable criteria, such as number\nof operations or memory footprint. We demonstrate that our method learns\nthrifty representations while maintaining accuracy. With ImageNet, the method\nproduces an average per layer bitlength of 4.13, 3.76 and 4.36 bits on AlexNet,\nResNet18 and MobileNet V2 respectively, remaining within 2.0%, 0.5% and 0.5% of\nthe base TOP-1 accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 04:58:33 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 20:30:52 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Nikoli\u0107", "Milo\u0161", ""], ["Hacene", "Ghouthi Boukli", ""], ["Bannon", "Ciaran", ""], ["Lascorz", "Alberto Delmas", ""], ["Courbariaux", "Matthieu", ""], ["Bengio", "Yoshua", ""], ["Gripon", "Vincent", ""], ["Moshovos", "Andreas", ""]]}, {"id": "2002.03098", "submitter": "Christos Dimitrakakis", "authors": "Hannes Eriksson and Emilio Jorge and Christos Dimitrakakis and\n  Debabrota Basu and Divya Grover", "title": "Inferential Induction: A Novel Framework for Bayesian Reinforcement\n  Learning", "comments": "28 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian reinforcement learning (BRL) offers a decision-theoretic solution\nfor reinforcement learning. While \"model-based\" BRL algorithms have focused\neither on maintaining a posterior distribution on models or value functions and\ncombining this with approximate dynamic programming or tree search, previous\nBayesian \"model-free\" value function distribution approaches implicitly make\nstrong assumptions or approximations. We describe a novel Bayesian framework,\nInferential Induction, for correctly inferring value function distributions\nfrom data, which leads to the development of a new class of BRL algorithms. We\ndesign an algorithm, Bayesian Backwards Induction, with this framework. We\nexperimentally demonstrate that the proposed algorithm is competitive with\nrespect to the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 06:19:15 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 19:16:51 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Eriksson", "Hannes", ""], ["Jorge", "Emilio", ""], ["Dimitrakakis", "Christos", ""], ["Basu", "Debabrota", ""], ["Grover", "Divya", ""]]}, {"id": "2002.03113", "submitter": "Petrus Mikkola", "authors": "Petrus Mikkola, Milica Todorovi\\'c, Jari J\\\"arvi, Patrick Rinke,\n  Samuel Kaski", "title": "Projective Preferential Bayesian Optimization", "comments": "9 pages, 2 figures", "journal-ref": "In Proceedings of the 37th International Conference on Machine\n  Learning, ICML'20, pp. 4050-4058, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimization is an effective method for finding extrema of a\nblack-box function. We propose a new type of Bayesian optimization for learning\nuser preferences in high-dimensional spaces. The central assumption is that the\nunderlying objective function cannot be evaluated directly, but instead a\nminimizer along a projection can be queried, which we call a projective\npreferential query. The form of the query allows for feedback that is natural\nfor a human to give, and which enables interaction. This is demonstrated in a\nuser experiment in which the user feedback comes in the form of optimal\nposition and orientation of a molecule adsorbing to a surface. We demonstrate\nthat our framework is able to find a global minimum of a high-dimensional\nblack-box function, which is an infeasible task for existing preferential\nBayesian optimization frameworks that are based on pairwise comparisons.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 08:29:23 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 11:02:50 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 14:09:29 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 12:10:55 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Mikkola", "Petrus", ""], ["Todorovi\u0107", "Milica", ""], ["J\u00e4rvi", "Jari", ""], ["Rinke", "Patrick", ""], ["Kaski", "Samuel", ""]]}, {"id": "2002.03123", "submitter": "Alon Gonen", "authors": "Alon Gonen and Shachar Lovett and Michal Moshkovitz", "title": "Towards a combinatorial characterization of bounded memory learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial dimensions play an important role in the theory of machine\nlearning. For example, VC dimension characterizes PAC learning, SQ dimension\ncharacterizes weak learning with statistical queries, and Littlestone dimension\ncharacterizes online learning.\n  In this paper we aim to develop combinatorial dimensions that characterize\nbounded memory learning. We propose a candidate solution for the case of\nrealizable strong learning under a known distribution, based on the SQ\ndimension of neighboring distributions. We prove both upper and lower bounds\nfor our candidate solution, that match in some regime of parameters. In this\nparameter regime there is an equivalence between bounded memory and SQ\nlearning. We conjecture that our characterization holds in a much wider regime\nof parameters.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 09:04:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gonen", "Alon", ""], ["Lovett", "Shachar", ""], ["Moshkovitz", "Michal", ""]]}, {"id": "2002.03129", "submitter": "Yunsheng Bai", "authors": "Yunsheng Bai, Derek Xu, Yizhou Sun, Wei Wang", "title": "GLSearch: Maximum Common Subgraph Detection via Learning to Search", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting the Maximum Common Subgraph (MCS) between two input graphs is\nfundamental for applications in drug synthesis, malware detection, cloud\ncomputing, etc. However, MCS computation is NP-hard, and state-of-the-art MCS\nsolvers rely on heuristic search algorithms which in practice cannot find good\nsolution for large graph pairs given a limited computation budget. We propose\nGLSearch, a Graph Neural Network (GNN) based learning to search model. Our\nmodel is built upon the branch and bound algorithm, which selects one pair of\nnodes from the two input graphs to expand at a time. Instead of using\nheuristics, we propose a novel GNN-based Deep Q-Network (DQN) to select the\nnode pair, allowing the search process faster and more adaptive. To further\nenhance the training of DQN, we leverage the search process to provide\nsupervision in a pre-training stage and guide our agent during an imitation\nlearning stage. Experiments on synthetic and real-world large graph pairs\ndemonstrate that our model learns a search strategy that is able to detect\nsignificantly larger common subgraphs given the same computation budget. Our\nGLSearch can be potentially extended to solve many other combinatorial problems\nwith constraints on graphs.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 10:03:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:49:40 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 17:12:33 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Bai", "Yunsheng", ""], ["Xu", "Derek", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2002.03141", "submitter": "Yueru Chen", "authors": "Yueru Chen, Mozhdeh Rouhsedaghat, Suya You, Raghuveer Rao and C.-C.\n  Jay Kuo", "title": "PixelHop++: A Small Successive-Subspace-Learning-Based (SSL-based) Model\n  for Image Classification", "comments": "5 pages, 5 figures, 4 tables, Submitted to ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successive subspace learning (SSL) principle was developed and used to\ndesign an interpretable learning model, known as the PixelHop method,for image\nclassification in our prior work. Here, we propose an improved PixelHop method\nand call it PixelHop++. First, to make the PixelHop model size smaller, we\ndecouple a joint spatial-spectral input tensor to multiple spatial tensors (one\nfor each spectral component) under the spatial-spectral separability assumption\nand perform the Saab transform in a channel-wise manner, called the\nchannel-wise (c/w) Saab transform.Second, by performing this operation from one\nhop to another successively, we construct a channel-decomposed feature tree\nwhose leaf nodes contain features of one dimension (1D). Third, these 1D\nfeatures are ranked according to their cross-entropy values, which allows us to\nselect a subset of discriminant features for image classification. In\nPixelHop++, one can control the learning model size of\nfine-granularity,offering a flexible tradeoff between the model size and the\nclassification performance. We demonstrate the flexibility of PixelHop++ on\nMNIST, Fashion MNIST, and CIFAR-10 three datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:08:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Yueru", ""], ["Rouhsedaghat", "Mozhdeh", ""], ["You", "Suya", ""], ["Rao", "Raghuveer", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2002.03147", "submitter": "Taejoon Byun", "authors": "Taejoon Byun, Sanjai Rayadurgam", "title": "Manifold for Machine Learning Assurance", "comments": null, "journal-ref": null, "doi": "10.1145/3377816.3381734", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of machine-learning (ML) enabled systems in critical tasks\nfuels the quest for novel verification and validation techniques yet grounded\nin accepted system assurance principles. In traditional system development,\nmodel-based techniques have been widely adopted, where the central premise is\nthat abstract models of the required system provide a sound basis for judging\nits implementation. We posit an analogous approach for ML systems using an ML\ntechnique that extracts from the high-dimensional training data implicitly\ndescribing the required system, a low-dimensional underlying structure--a\nmanifold. It is then harnessed for a range of quality assurance tasks such as\ntest adequacy measurement, test input generation, and runtime monitoring of the\ntarget ML system. The approach is built on variational autoencoder, an\nunsupervised method for learning a pair of mutually near-inverse functions\nbetween a given high-dimensional dataset and a low-dimensional representation.\nPreliminary experiments establish that the proposed manifold-based approach,\nfor test adequacy drives diversity in test data, for test generation yields\nfault-revealing yet realistic test cases, and for runtime monitoring provides\nan independent means to assess trustability of the target system's output.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:39:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Byun", "Taejoon", ""], ["Rayadurgam", "Sanjai", ""]]}, {"id": "2002.03153", "submitter": "Hanan Shteingart", "authors": "Hanan Shteingart, Eran Marom, Igor Itkin, Gil Shabat, Michael\n  Kolomenkin, Moshe Salhov, and Liran Katzir", "title": "Majority Voting and the Condorcet's Jury Theorem", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a striking relationship between a three hundred years old Political\nScience theorem named \"Condorcet's jury theorem\" (1785), which states that\nmajorities are more likely to choose correctly when individual votes are often\ncorrect and independent, and a modern Machine Learning concept called \"Strength\nof Weak Learnability\" (1990), which describes a method for converting a weak\nlearning algorithm into one that achieves arbitrarily high accuracy and stands\nin the basis of Ensemble Learning. Albeit the intuitive statement of\nCondorcet's theorem, we could not find a compact and simple rigorous\nmathematical proof of the theorem neither in classical handbooks of Machine\nLearning nor in published papers. By all means we do not claim to discover or\nreinvent a theory nor a result. We humbly want to offer a more publicly\navailable simple derivation of the theorem. We will find joy in seeing more\nteachers of introduction-to-machine-learning courses use the proof we provide\nhere as an exercise to explain the motivation of ensemble learning.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:28:11 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:40:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Shteingart", "Hanan", ""], ["Marom", "Eran", ""], ["Itkin", "Igor", ""], ["Shabat", "Gil", ""], ["Kolomenkin", "Michael", ""], ["Salhov", "Moshe", ""], ["Katzir", "Liran", ""]]}, {"id": "2002.03155", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Random Features Strengthen Graph Neural Networks", "comments": "Accepted to SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are powerful machine learning models for various\ngraph learning tasks. Recently, the limitations of the expressive power of\nvarious GNN models have been revealed. For example, GNNs cannot distinguish\nsome non-isomorphic graphs and they cannot learn efficient graph algorithms. In\nthis paper, we demonstrate that GNNs become powerful just by adding a random\nfeature to each node. We prove that the random features enable GNNs to learn\nalmost optimal polynomial-time approximation algorithms for the minimum\ndominating set problem and maximum matching problem in terms of approximation\nratios. The main advantage of our method is that it can be combined with\noff-the-shelf GNN models with slight modifications. Through experiments, we\nshow that the addition of random features enables GNNs to solve various\nproblems that normal GNNs, including the graph convolutional networks (GCNs)\nand graph isomorphism networks (GINs), cannot solve.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:47:29 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 00:39:03 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 08:52:14 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.03176", "submitter": "Illia Horenko Dr.", "authors": "Illia Horenko", "title": "On a scalable entropic breaching of the overfitting barrier in machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting and treatment of \"small data\" are among the most challenging\nproblems in the machine learning (ML), when a relatively small data statistics\nsize $T$ is not enough to provide a robust ML fit for a relatively large data\nfeature dimension $D$. Deploying a massively-parallel ML analysis of generic\nclassification problems for different $D$ and $T$, existence of\nstatistically-significant linear overfitting barriers for common ML methods is\ndemonstrated. For example, these results reveal that for a robust\nclassification of bioinformatics-motivated generic problems with the Long\nShort-Term Memory deep learning classifier (LSTM) one needs in a best case a\nstatistics $T$ that is at least 13.8 times larger then the feature dimension\n$D$. It is shown that this overfitting barrier can be breached at a $10^{-12}$\nfraction of the computational cost by means of the entropy-optimal Scalable\nProbabilistic Approximations algorithm (eSPA), performing a joint solution of\nthe entropy-optimal Bayesian network inference and feature space segmentation\nproblems. Application of eSPA to experimental single cell RNA sequencing data\nexhibits a 30-fold classification performance boost when compared to standard\nbioinformatics tools - and a 7-fold boost when compared to the deep learning\nLSTM classifier.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:47:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Horenko", "Illia", ""]]}, {"id": "2002.03179", "submitter": "Jagarlapudi Saketha Nath", "authors": "J. Saketha Nath (IIT Hyderabad, INDIA) and Pratik Jawanpuria\n  (Microsoft IDC, INDIA)", "title": "Statistical Optimal Transport posed as Learning Kernel Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective in statistical Optimal Transport (OT) is to consistently\nestimate the optimal transport plan/map solely using samples from the given\nsource and target marginal distributions. This work takes the novel approach of\nposing statistical OT as that of learning the transport plan's kernel mean\nembedding from sample based estimates of marginal embeddings. The proposed\nestimator controls overfitting by employing maximum mean discrepancy based\nregularization, which is complementary to $\\phi$-divergence (entropy) based\nregularization popularly employed in existing estimators. A key result is that,\nunder very mild conditions, $\\epsilon$-optimal recovery of the transport plan\nas well as the Barycentric-projection based transport map is possible with a\nsample complexity that is completely dimension-free. Moreover, the implicit\nsmoothing in the kernel mean embeddings enables out-of-sample estimation. An\nappropriate representer theorem is proved leading to a kernelized convex\nformulation for the estimator, which can then be potentially used to perform OT\neven in non-standard domains. Empirical results illustrate the efficacy of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:58:53 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 04:55:15 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 18:04:18 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 13:57:02 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 03:55:01 GMT"}, {"version": "v6", "created": "Tue, 10 Nov 2020 08:41:48 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Nath", "J. Saketha", "", "IIT Hyderabad, INDIA"], ["Jawanpuria", "Pratik", "", "Microsoft IDC, INDIA"]]}, {"id": "2002.03181", "submitter": "Thomas Molnar", "authors": "Thomas Molnar and Eugenio Culurciello", "title": "Capsule Network Performance with Autonomous Navigation", "comments": "In IJAIA Vol.11, No.1 for January 2020; 15 pages, 9 figures", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol. 11, No. 1, January 2020", "doi": "10.5121/ijaia.2020.11101", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks (CapsNets) have been proposed as an alternative to\nConvolutional Neural Networks (CNNs). This paper showcases how CapsNets are\nmore capable than CNNs for autonomous agent exploration of realistic scenarios.\nIn real world navigation, rewards external to agents may be rare. In turn,\nreinforcement learning algorithms can struggle to form meaningful policy\nfunctions. This paper's approach Capsules Exploration Module (Caps-EM) pairs a\nCapsNets architecture with an Advantage Actor Critic algorithm. Other\napproaches for navigating sparse environments require intrinsic reward\ngenerators, such as the Intrinsic Curiosity Module (ICM) and Augmented\nCuriosity Modules (ACM). Caps-EM uses a more compact architecture without need\nfor intrinsic rewards. Tested using ViZDoom, the Caps-EM uses 44% and 83% fewer\ntrainable network parameters than the ICM and Depth-Augmented Curiosity Module\n(D-ACM), respectively, for 1141% and 437% average time improvement over the ICM\nand D-ACM, respectively, for converging to a policy function across \"My Way\nHome\" scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 15:21:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Molnar", "Thomas", ""], ["Culurciello", "Eugenio", ""]]}, {"id": "2002.03184", "submitter": "Vasileios Lioutas", "authors": "Vasileios Lioutas, Yuhong Guo", "title": "Time-aware Large Kernel Convolutions", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, most state-of-the-art sequence modeling architectures use attention\nto build generative models for language based tasks. Some of these models use\nall the available sequence tokens to generate an attention distribution which\nresults in time complexity of $O(n^2)$. Alternatively, they utilize depthwise\nconvolutions with softmax normalized kernels of size $k$ acting as a\nlimited-window self-attention, resulting in time complexity of $O(k{\\cdot}n)$.\nIn this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a\nnovel adaptive convolution operation that learns to predict the size of a\nsummation kernel instead of using a fixed-sized kernel matrix. This method\nyields a time complexity of $O(n)$, effectively making the sequence encoding\nprocess linear to the number of tokens. We evaluate the proposed method on\nlarge-scale standard machine translation, abstractive summarization and\nlanguage modeling datasets and show that TaLK Convolutions constitute an\nefficient improvement over other attention/convolution based approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 15:30:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:11:18 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Guo", "Yuhong", ""]]}, {"id": "2002.03203", "submitter": "Yingcheng Sun", "authors": "Yingcheng Sun and Richard Kolacinski and Kenneth Loparo", "title": "Eliminating Search Intent Bias in Learning to Rank", "comments": null, "journal-ref": "2020 IEEE 14th International Conference on Semantic Computing\n  (ICSC)", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through data has proven to be a valuable resource for improving\nsearch-ranking quality. Search engines can easily collect click data, but\nbiases introduced in the data can make it difficult to use the data\neffectively. In order to measure the effects of biases, many click models have\nbeen proposed in the literature. However, none of the models can explain the\nobservation that users with different search intent (e.g., informational,\nnavigational, etc.) have different click behaviors. In this paper, we study how\ndifferences in user search intent can influence click activities and determined\nthat there exists a bias between user search intent and the relevance of the\ndocument relevance. Based on this observation, we propose a search intent bias\nhypothesis that can be applied to most existing click models to improve their\nability to learn unbiased relevance. Experimental results demonstrate that\nafter adopting the search intent hypothesis, click models can better interpret\nuser clicks and substantially improve retrieval performance.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 17:07:37 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 23:11:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sun", "Yingcheng", ""], ["Kolacinski", "Richard", ""], ["Loparo", "Kenneth", ""]]}, {"id": "2002.03206", "submitter": "Chiyuan Zhang", "authors": "Ziheng Jiang, Chiyuan Zhang, Kunal Talwar, Michael C. Mozer", "title": "Characterizing Structural Regularities of Labeled Data in\n  Overparameterized Models", "comments": "17 pages, 20 figures, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are accustomed to environments that contain both regularities and\nexceptions. For example, at most gas stations, one pays prior to pumping, but\nthe occasional rural station does not accept payment in advance. Likewise, deep\nneural networks can generalize across instances that share common patterns or\nstructures, yet have the capacity to memorize rare or irregular forms. We\nanalyze how individual instances are treated by a model via a consistency\nscore. The score characterizes the expected accuracy for a held-out instance\ngiven training sets of varying size sampled from the data distribution. We\nobtain empirical estimates of this score for individual instances in multiple\ndata sets, and we show that the score identifies out-of-distribution and\nmislabeled examples at one end of the continuum and strongly regular examples\nat the other end. We identify computationally inexpensive proxies to the\nconsistency score using statistics collected during training. We show examples\nof potential applications to the analysis of deep-learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 17:39:46 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 23:28:09 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 17:22:27 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jiang", "Ziheng", ""], ["Zhang", "Chiyuan", ""], ["Talwar", "Kunal", ""], ["Mozer", "Michael C.", ""]]}, {"id": "2002.03214", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger, Rong Fu, and Yonina C. Eldar", "title": "DeepSIC: Deep Soft Interference Cancellation for Multiuser MIMO\n  Detection", "comments": "arXiv admin note: text overlap with arXiv:2002.07806", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital receivers are required to recover the transmitted symbols from their\nobserved channel output. In multiuser multiple-input multiple-output (MIMO)\nsetups, where multiple symbols are simultaneously transmitted, accurate symbol\ndetection is challenging. A family of algorithms capable of reliably recovering\nmultiple symbols is based on interference cancellation. However, these methods\nassume that the channel is linear, a model which does not reflect many relevant\nchannels, as well as require accurate channel state information (CSI), which\nmay not be available. In this work we propose a multiuser MIMO receiver which\nlearns to jointly detect in a data-driven fashion, without assuming a specific\nchannel model or requiring CSI. In particular, we propose a data-driven\nimplementation of the iterative soft interference cancellation (SIC) algorithm\nwhich we refer to as DeepSIC. The resulting symbol detector is based on\nintegrating dedicated machine-learning (ML) methods into the iterative SIC\nalgorithm. DeepSIC learns to carry out joint detection from a limited set of\ntraining samples without requiring the channel to be linear and its parameters\nto be known. Our numerical evaluations demonstrate that for linear channels\nwith full CSI, DeepSIC approaches the performance of iterative SIC, which is\ncomparable to the optimal performance, and outperforms previously proposed\nML-based MIMO receivers. Furthermore, in the presence of CSI uncertainty,\nDeepSIC significantly outperforms model-based approaches. Finally, we show that\nDeepSIC accurately detects symbols in non-linear channels, where conventional\niterative SIC fails even when accurate CSI is available.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 18:31:00 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 12:02:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Shlezinger", "Nir", ""], ["Fu", "Rong", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2002.03217", "submitter": "Kelly Zhang", "authors": "Kelly W. Zhang, Lucas Janson, Susan A. Murphy", "title": "Inference for Batched Bandits", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As bandit algorithms are increasingly utilized in scientific studies and\nindustrial applications, there is an associated increasing need for reliable\ninference methods based on the resulting adaptively-collected data. In this\nwork, we develop methods for inference on data collected in batches using a\nbandit algorithm. We first prove that the ordinary least squares estimator\n(OLS), which is asymptotically normal on independently sampled data, is not\nasymptotically normal on data collected using standard bandit algorithms when\nthere is no unique optimal arm. This asymptotic non-normality result implies\nthat the naive assumption that the OLS estimator is approximately normal can\nlead to Type-1 error inflation and confidence intervals with below-nominal\ncoverage probabilities. Second, we introduce the Batched OLS estimator (BOLS)\nthat we prove is (1) asymptotically normal on data collected from both\nmulti-arm and contextual bandits and (2) robust to non-stationarity in the\nbaseline reward.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 18:59:47 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 23:01:54 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 22:45:34 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhang", "Kelly W.", ""], ["Janson", "Lucas", ""], ["Murphy", "Susan A.", ""]]}, {"id": "2002.03218", "submitter": "Evrard Garcelon", "authors": "Evrard Garcelon, Mohammad Ghavamzadeh, Alessandro Lazaric, Matteo\n  Pirotta", "title": "Conservative Exploration in Reinforcement Learning", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learning in an unknown Markov Decision Process (MDP), an agent should\ntrade off exploration to discover new information about the MDP, and\nexploitation of the current knowledge to maximize the reward. Although the\nagent will eventually learn a good or optimal policy, there is no guarantee on\nthe quality of the intermediate policies. This lack of control is undesired in\nreal-world applications where a minimum requirement is that the executed\npolicies are guaranteed to perform at least as well as an existing baseline. In\nthis paper, we introduce the notion of conservative exploration for average\nreward and finite horizon problems. We present two optimistic algorithms that\nguarantee (w.h.p.) that the conservative constraint is never violated during\nlearning. We derive regret bounds showing that being conservative does not\nhinder the learning ability of these algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:09:51 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 12:51:27 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Garcelon", "Evrard", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2002.03221", "submitter": "Evrard Garcelon", "authors": "Evrard Garcelon, Mohammad Ghavamzadeh, Alessandro Lazaric, Matteo\n  Pirotta", "title": "Improved Algorithms for Conservative Exploration in Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields such as digital marketing, healthcare, finance, and robotics,\nit is common to have a well-tested and reliable baseline policy running in\nproduction (e.g., a recommender system). Nonetheless, the baseline policy is\noften suboptimal. In this case, it is desirable to deploy online learning\nalgorithms (e.g., a multi-armed bandit algorithm) that interact with the system\nto learn a better/optimal policy under the constraint that during the learning\nprocess the performance is almost never worse than the performance of the\nbaseline itself. In this paper, we study the conservative learning problem in\nthe contextual linear bandit setting and introduce a novel algorithm, the\nConservative Constrained LinUCB (CLUCB2). We derive regret bounds for CLUCB2\nthat match existing results and empirically show that it outperforms\nstate-of-the-art conservative bandit algorithms in a number of synthetic and\nreal-world problems. Finally, we consider a more realistic constraint where the\nperformance is verified only at predefined checkpoints (instead of at every\nstep) and show how this relaxed constraint favorably impacts the regret and\nempirical performance of CLUCB2.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:35:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Garcelon", "Evrard", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2002.03222", "submitter": "Yue Zhao", "authors": "Yue Zhao and Xueying Ding and Jianing Yang and Haoping Bai", "title": "SUOD: Toward Scalable Unsupervised Outlier Detection", "comments": "In AAAI-20 Workshop on Artificial Intelligence for Cyber Security\n  (AICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a key field of machine learning for identifying abnormal\ndata objects. Due to the high expense of acquiring ground truth, unsupervised\nmodels are often chosen in practice. To compensate for the unstable nature of\nunsupervised algorithms, practitioners from high-stakes fields like finance,\nhealth, and security, prefer to build a large number of models for further\ncombination and analysis. However, this poses scalability challenges in\nhigh-dimensional large datasets. In this study, we propose a three-module\nacceleration framework called SUOD to expedite the training and prediction with\na large number of unsupervised detection models. SUOD's Random Projection\nmodule can generate lower subspaces for high-dimensional datasets while\nreserving their distance relationship. Balanced Parallel Scheduling module can\nforecast the training and prediction cost of models with high confidence---so\nthe task scheduler could assign nearly equal amount of taskload among workers\nfor efficient parallelization. SUOD also comes with a Pseudo-supervised\nApproximation module, which can approximate fitted unsupervised models by lower\ntime complexity supervised regressors for fast prediction on unseen data. It\nmay be considered as an unsupervised model knowledge distillation process.\nNotably, all three modules are independent with great flexibility to \"mix and\nmatch\"; a combination of modules can be chosen based on use cases. Extensive\nexperiments on more than 30 benchmark datasets have shown the efficacy of SUOD,\nand a comprehensive future development plan is also presented.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:38:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhao", "Yue", ""], ["Ding", "Xueying", ""], ["Yang", "Jianing", ""], ["Bai", "Haoping", ""]]}, {"id": "2002.03223", "submitter": "Michelle Ngo", "authors": "Michelle N. Ngo, Dustin S. Pluta, Alexander N. Ngo, Babak Shahbaba", "title": "Conjoined Dirichlet Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is a class of techniques that simultaneously clusters the rows\nand columns of a matrix to sort heterogeneous data into homogeneous blocks.\nAlthough many algorithms have been proposed to find biclusters, existing\nmethods suffer from the pre-specification of the number of biclusters or place\nconstraints on the model structure. To address these issues, we develop a\nnovel, non-parametric probabilistic biclustering method based on Dirichlet\nprocesses to identify biclusters with strong co-occurrence in both rows and\ncolumns. The proposed method utilizes dual Dirichlet process mixture models to\nlearn row and column clusters, with the number of resulting clusters determined\nby the data rather than pre-specified. Probabilistic biclusters are identified\nby modeling the mutual dependence between the row and column clusters. We apply\nour method to two different applications, text mining and gene expression\nanalysis, and demonstrate that our method improves bicluster extraction in many\nsettings compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:41:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ngo", "Michelle N.", ""], ["Pluta", "Dustin S.", ""], ["Ngo", "Alexander N.", ""], ["Shahbaba", "Babak", ""]]}, {"id": "2002.03229", "submitter": "Marco Cuturi", "authors": "Marco Cuturi, Olivier Teboul, Jonathan Niles-Weed, Jean-Philippe Vert", "title": "Supervised Quantile Normalization for Low-rank Matrix Approximation", "comments": "new version with genomics experiments", "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank matrix factorization is a fundamental building block in machine\nlearning, used for instance to summarize gene expression profile data or\nword-document counts. To be robust to outliers and differences in scale across\nfeatures, a matrix factorization step is usually preceded by ad-hoc feature\nnormalization steps, such as \\texttt{tf-idf} scaling or data whitening. We\npropose in this work to learn these normalization operators jointly with the\nfactorization itself. More precisely, given a $d\\times n$ matrix $X$ of $d$\nfeatures measured on $n$ individuals, we propose to learn the parameters of\nquantile normalization operators that can operate row-wise on the values of $X$\nand/or of its factorization $UV$ to improve the quality of the low-rank\nrepresentation of $X$ itself. This optimization is facilitated by the\nintroduction of a new differentiable quantile normalization operator built\nusing optimal transport, providing new results on top of existing work by\n(Cuturi et al. 2019). We demonstrate the applicability of these techniques on\nsynthetic and genomics datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:06:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 18:48:33 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Cuturi", "Marco", ""], ["Teboul", "Olivier", ""], ["Niles-Weed", "Jonathan", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2002.03230", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Hierarchical Generation of Molecular Graphs using Structural Motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generation techniques are increasingly being adopted for drug\ndiscovery. Previous graph generation approaches have utilized relatively small\nmolecular building blocks such as atoms or simple cycles, limiting their\neffectiveness to smaller molecules. Indeed, as we demonstrate, their\nperformance degrades significantly for larger molecules. In this paper, we\npropose a new hierarchical graph encoder-decoder that employs significantly\nlarger and more flexible graph motifs as basic building blocks. Our encoder\nproduces a multi-resolution representation for each molecule in a\nfine-to-coarse fashion, from atoms to connected motifs. Each level integrates\nthe encoding of constituents below with the graph at that level. Our\nautoregressive coarse-to-fine decoder adds one motif at a time, interleaving\nthe decision of selecting a new motif with the process of resolving its\nattachments to the emerging molecule. We evaluate our model on multiple\nmolecule generation tasks, including polymers, and show that our model\nsignificantly outperforms previous state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:21:04 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:14:46 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.03231", "submitter": "Aditya Kusupati", "authors": "Aditya Kusupati, Vivek Ramanujan, Raghav Somani, Mitchell Wortsman,\n  Prateek Jain, Sham Kakade, Ali Farhadi", "title": "Soft Threshold Weight Reparameterization for Learnable Sparsity", "comments": "19 pages, 10 figures, Published at International Conference on\n  Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus\nof maximizing prediction accuracy given an overall parameter budget. Existing\nmethods rely on uniform or heuristic non-uniform sparsity budgets which have\nsub-optimal layer-wise parameter allocation resulting in a) lower prediction\naccuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold\nReparameterization (STR), a novel use of the soft-threshold operator on DNN\nweights. STR smoothly induces sparsity while learning pruning thresholds\nthereby obtaining a non-uniform sparsity budget. Our method achieves\nstate-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and\nMobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that\nempirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy\nover existing results by up to 10% in the ultra sparse (99%) regime and can\nalso be used to induce low-rank (structured sparsity) in RNNs. In short, STR is\na simple mechanism which learns effective sparsity budgets that contrast with\npopular heuristics. Code, pretrained models and sparsity budgets are at\nhttps://github.com/RAIVNLab/STR.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:31:25 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:57:06 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 10:11:37 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 09:57:20 GMT"}, {"version": "v5", "created": "Fri, 17 Apr 2020 12:57:04 GMT"}, {"version": "v6", "created": "Wed, 22 Apr 2020 02:16:28 GMT"}, {"version": "v7", "created": "Tue, 28 Apr 2020 01:12:37 GMT"}, {"version": "v8", "created": "Sun, 10 May 2020 02:39:39 GMT"}, {"version": "v9", "created": "Mon, 22 Jun 2020 23:37:12 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kusupati", "Aditya", ""], ["Ramanujan", "Vivek", ""], ["Somani", "Raghav", ""], ["Wortsman", "Mitchell", ""], ["Jain", "Prateek", ""], ["Kakade", "Sham", ""], ["Farhadi", "Ali", ""]]}, {"id": "2002.03237", "submitter": "Jos\\'e G. G\\'omez Garc\\'ia", "authors": "Jos\\'e G. G\\'omez Garc\\'ia, Jalal Fadili, Christophe Chesneau", "title": "Learning CHARME models with neural networks", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a model called CHARME (Conditional Heteroscedastic\nAutoregressive Mixture of Experts), a class of generalized mixture of nonlinear\nnonparametric AR-ARCH time series. Under certain Lipschitz-type conditions on\nthe autoregressive and volatility functions, we prove that this model is\nstationary, ergodic and $\\tau$-weakly dependent. These conditions are much\nweaker than those presented in the literature that treats this model. Moreover,\nthis result forms the theoretical basis for deriving an asymptotic theory of\nthe underlying (non)parametric estimation, which we present for this model. As\nan application, from the universal approximation property of neural networks\n(NN), we develop a learning theory for the NN-based autoregressive functions of\nthe model, where the strong consistency and asymptotic normality of the\nconsidered estimator of the NN weights and biases are guaranteed under weak\nconditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:51:02 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 17:54:08 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Garc\u00eda", "Jos\u00e9 G. G\u00f3mez", ""], ["Fadili", "Jalal", ""], ["Chesneau", "Christophe", ""]]}, {"id": "2002.03239", "submitter": "Aounon Kumar", "authors": "Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi", "title": "Curse of Dimensionality on Randomized Smoothing for Certifiable\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing, using just a simple isotropic Gaussian distribution,\nhas been shown to produce good robustness guarantees against $\\ell_2$-norm\nbounded adversaries. In this work, we show that extending the smoothing\ntechnique to defend against other attack models can be challenging, especially\nin the high-dimensional regime. In particular, for a vast class of\ni.i.d.~smoothing distributions, we prove that the largest $\\ell_p$-radius that\ncan be certified decreases as $O(1/d^{\\frac{1}{2} - \\frac{1}{p}})$ with\ndimension $d$ for $p > 2$. Notably, for $p \\geq 2$, this dependence on $d$ is\nno better than that of the $\\ell_p$-radius that can be certified using\nisotropic Gaussian smoothing, essentially putting a matching lower bound on the\nrobustness radius. When restricted to {\\it generalized} Gaussian smoothing,\nthese two bounds can be shown to be within a constant factor of each other in\nan asymptotic sense, establishing that Gaussian smoothing provides the best\npossible results, up to a constant factor, when $p \\geq 2$. We present\nexperimental results on CIFAR to validate our theory. For other smoothing\ndistributions, such as, a uniform distribution within an $\\ell_1$ or an\n$\\ell_\\infty$-norm ball, we show upper bounds of the form $O(1 / d)$ and $O(1 /\nd^{1 - \\frac{1}{p}})$ respectively, which have an even worse dependence on $d$.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:02:14 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:02:35 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kumar", "Aounon", ""], ["Levine", "Alexander", ""], ["Goldstein", "Tom", ""], ["Feizi", "Soheil", ""]]}, {"id": "2002.03240", "submitter": "Vincent Micheli", "authors": "Vincent Micheli, Karthigan Sinnathamby, Fran\\c{c}ois Fleuret", "title": "Multi-task Reinforcement Learning with a Planning Quasi-Metric", "comments": "Deep RL Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new reinforcement learning approach combining a planning\nquasi-metric (PQM) that estimates the number of steps required to go from any\nstate to another, with task-specific \"aimers\" that compute a target state to\nreach a given goal. This decomposition allows the sharing across tasks of a\ntask-agnostic model of the quasi-metric that captures the environment's\ndynamics and can be learned in a dense and unsupervised manner. We achieve\nmultiple-fold training speed-up compared to recently published methods on the\nstandard bit-flip problem and in the MuJoCo robotic arm simulator.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:12:59 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 09:02:31 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 14:21:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Micheli", "Vincent", ""], ["Sinnathamby", "Karthigan", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "2002.03244", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Multi-Objective Molecule Generation using Interpretable Substructures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug discovery aims to find novel compounds with specified chemical property\nprofiles. In terms of generative modeling, the goal is to learn to sample\nmolecules in the intersection of multiple property constraints. This task\nbecomes increasingly challenging when there are many property constraints. We\npropose to offset this complexity by composing molecules from a vocabulary of\nsubstructures that we call molecular rationales. These rationales are\nidentified from molecules as substructures that are likely responsible for each\nproperty of interest. We then learn to expand rationales into a full molecule\nusing graph generative models. Our final generative model composes molecules as\nmixtures of multiple rationale completions, and this mixture is fine-tuned to\npreserve the properties of interest. We evaluate our model on various drug\ndesign tasks and demonstrate significant improvements over state-of-the-art\nbaselines in terms of accuracy, diversity, and novelty of generated compounds.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:55:37 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:10:01 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 19:28:21 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.03261", "submitter": "Sen Wang", "authors": "Sen Wang, J.Morris Chang", "title": "Privacy-Preserving Image Classification in the Local Setting", "comments": "10 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image data has been greatly produced by individuals and commercial vendors in\nthe daily life, and it has been used across various domains, like advertising,\nmedical and traffic analysis. Recently, image data also appears to be greatly\nimportant in social utility, like emergency response. However, the privacy\nconcern becomes the biggest obstacle that prevents further exploration of image\ndata, due to that the image could reveal sensitive information, like the\npersonal identity and locations. The recent developed Local Differential\nPrivacy (LDP) brings us a promising solution, which allows the data owners to\nrandomly perturb their input to provide the plausible deniability of the data\nbefore releasing. In this paper, we consider a two-party image classification\nproblem, in which data owners hold the image and the untrustworthy data user\nwould like to fit a machine learning model with these images as input. To\nprotect the image privacy, we propose to locally perturb the image\nrepresentation before revealing to the data user. Subsequently, we analyze how\nthe perturbation satisfies {\\epsilon}-LDP and affect the data utility regarding\ncount-based and distance-based machine learning algorithm, and propose a\nsupervised image feature extractor, DCAConv, which produces an image\nrepresentation with scalable domain size. Our experiments show that DCAConv\ncould maintain a high data utility while preserving the privacy regarding\nmultiple image benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 01:25:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Sen", ""], ["Chang", "J. Morris", ""]]}, {"id": "2002.03272", "submitter": "Wonjoon Goo", "authors": "Wonjoon Goo, Scott Niekum", "title": "Local Nonparametric Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of meta-learning is to find a learning rule that enables fast\nadaptation across a set of tasks, by learning the appropriate inductive bias\nfor that set. Most meta-learning algorithms try to find a \\textit{global}\nlearning rule that encodes this inductive bias. However, a global learning rule\nrepresented by a fixed-size representation is prone to meta-underfitting or\n-overfitting since the right representational power for a task set is difficult\nto choose a priori. Even when chosen correctly, we show that global, fixed-size\nrepresentations often fail when confronted with certain types of\nout-of-distribution tasks, even when the same inductive bias is appropriate. To\naddress these problems, we propose a novel nonparametric meta-learning\nalgorithm that utilizes a meta-trained local learning rule, building on recent\nideas in attention-based and functional gradient-based meta-learning. In\nseveral meta-regression problems, we show improved meta-generalization results\nusing our local, nonparametric approach and achieve state-of-the-art results in\nthe robotics benchmark, Omnipush.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 03:28:27 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Goo", "Wonjoon", ""], ["Niekum", "Scott", ""]]}, {"id": "2002.03273", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani, Amit Daniely, Stefanie Jegelka, Hongzhou Lin", "title": "On the Complexity of Minimizing Convex Finite Sums Without Using the\n  Indices of the Individual Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in randomized incremental methods for minimizing $L$-smooth\n$\\mu$-strongly convex finite sums have culminated in tight complexity of\n$\\tilde{O}((n+\\sqrt{n L/\\mu})\\log(1/\\epsilon))$ and $O(n+\\sqrt{nL/\\epsilon})$,\nwhere $\\mu>0$ and $\\mu=0$, respectively, and $n$ denotes the number of\nindividual functions. Unlike incremental methods, stochastic methods for finite\nsums do not rely on an explicit knowledge of which individual function is being\naddressed at each iteration, and as such, must perform at least $\\Omega(n^2)$\niterations to obtain $O(1/n^2)$-optimal solutions. In this work, we exploit the\nfinite noise structure of finite sums to derive a matching $O(n^2)$-upper bound\nunder the global oracle model, showing that this lower bound is indeed tight.\nFollowing a similar approach, we propose a novel adaptation of SVRG which is\nboth \\emph{compatible with stochastic oracles}, and achieves complexity bounds\nof $\\tilde{O}((n^2+n\\sqrt{L/\\mu})\\log(1/\\epsilon))$ and\n$O(n\\sqrt{L/\\epsilon})$, for $\\mu>0$ and $\\mu=0$, respectively. Our bounds hold\nw.h.p. and match in part existing lower bounds of\n$\\tilde{\\Omega}(n^2+\\sqrt{nL/\\mu}\\log(1/\\epsilon))$ and\n$\\tilde{\\Omega}(n^2+\\sqrt{nL/\\epsilon})$, for $\\mu>0$ and $\\mu=0$,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 03:39:46 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Arjevani", "Yossi", ""], ["Daniely", "Amit", ""], ["Jegelka", "Stefanie", ""], ["Lin", "Hongzhou", ""]]}, {"id": "2002.03278", "submitter": "Kun Zhang", "authors": "Kun Zhang, Mingming Gong, Petar Stojanov, Biwei Huang, Qingsong Liu,\n  Clark Glymour", "title": "Domain Adaptation as a Problem of Inference on Graphical Models", "comments": "19 pages; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with data-driven unsupervised domain adaptation,\nwhere it is unknown in advance how the joint distribution changes across\ndomains, i.e., what factors or modules of the data distribution remain\ninvariant or change across domains. To develop an automated way of domain\nadaptation with multiple source domains, we propose to use a graphical model as\na compact way to encode the change property of the joint distribution, which\ncan be learned from data, and then view domain adaptation as a problem of\nBayesian inference on the graphical models. Such a graphical model\ndistinguishes between constant and varied modules of the distribution and\nspecifies the properties of the changes across domains, which serves as prior\nknowledge of the changing modules for the purpose of deriving the posterior of\nthe target variable $Y$ in the target domain. This provides an end-to-end\nframework of domain adaptation, in which additional knowledge about how the\njoint distribution changes, if available, can be directly incorporated to\nimprove the graphical representation. We discuss how causality-based domain\nadaptation can be put under this umbrella. Experimental results on both\nsynthetic and real data demonstrate the efficacy of the proposed framework for\ndomain adaptation. The code is available at https://github.com/mgong2/DA_Infer .\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:08:15 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 09:47:16 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 16:49:47 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 08:55:05 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Zhang", "Kun", ""], ["Gong", "Mingming", ""], ["Stojanov", "Petar", ""], ["Huang", "Biwei", ""], ["Liu", "Qingsong", ""], ["Glymour", "Clark", ""]]}, {"id": "2002.03282", "submitter": "Bo Peng", "authors": "Bo Peng and Jiahai Wang and Zizhen Zhang", "title": "A Deep Reinforcement Learning Algorithm Using Dynamic Attention Model\n  for Vehicle Routing Problems", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches show that machine learning has the potential to learn\nbetter heuristics than the one designed by human for solving combinatorial\noptimization problems. The deep neural network is used to characterize the\ninput instance for constructing a feasible solution incrementally. Recently, an\nattention model is proposed to solve routing problems. In this model, the state\nof an instance is represented by node features that are fixed over time.\nHowever, the fact is, the state of an instance is changed according to the\ndecision that the model made at different construction steps, and the node\nfeatures should be updated correspondingly. Therefore, this paper presents a\ndynamic attention model with dynamic encoder-decoder architecture, which\nenables the model to explore node features dynamically and exploit hidden\nstructure information effectively at different construction steps. This paper\nfocuses on a challenging NP-hard problem, vehicle routing problem. The\nexperiments indicate that our model outperforms the previous methods and also\nshows a good generalization performance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:51:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Peng", "Bo", ""], ["Wang", "Jiahai", ""], ["Zhang", "Zizhen", ""]]}, {"id": "2002.03283", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Segmented Graph-Bert for Graph Instance Modeling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In graph instance representation learning, both the diverse graph instance\nsizes and the graph node orderless property have been the major obstacles that\nrender existing representation learning models fail to work. In this paper, we\nwill examine the effectiveness of GRAPH-BERT on graph instance representation\nlearning, which was designed for node representation learning tasks originally.\nTo adapt GRAPH-BERT to the new problem settings, we re-design it with a\nsegmented architecture instead, which is also named as SEG-BERT (Segmented\nGRAPH-BERT) for reference simplicity in this paper. SEG-BERT involves no\nnode-order-variant inputs or functional components anymore, and it can handle\nthe graph node orderless property naturally. What's more, SEG-BERT has a\nsegmented architecture and introduces three different strategies to unify the\ngraph instance sizes, i.e., full-input, padding/pruning and segment shifting,\nrespectively. SEG-BERT is pre-trainable in an unsupervised manner, which can be\nfurther transferred to new tasks directly or with necessary fine-tuning. We\nhave tested the effectiveness of SEG-BERT with experiments on seven graph\ninstance benchmark datasets, and SEG-BERT can out-perform the comparison\nmethods on six out of them with significant performance advantages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:55:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2002.03293", "submitter": "Khiem Pham", "authors": "Khiem Pham and Khang Le and Nhat Ho and Tung Pham and Hung Bui", "title": "On Unbalanced Optimal Transport: An Analysis of Sinkhorn Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a computational complexity analysis for the Sinkhorn algorithm\nthat solves the entropic regularized Unbalanced Optimal Transport (UOT) problem\nbetween two measures of possibly different masses with at most $n$ components.\nWe show that the complexity of the Sinkhorn algorithm for finding an\n$\\varepsilon$-approximate solution to the UOT problem is of order\n$\\widetilde{\\mathcal{O}}(n^2/ \\varepsilon)$, which is near-linear time. To the\nbest of our knowledge, this complexity is better than the complexity of the\nSinkhorn algorithm for solving the Optimal Transport (OT) problem, which is of\norder $\\widetilde{\\mathcal{O}}(n^2/\\varepsilon^2)$. Our proof technique is\nbased on the geometric convergence of the Sinkhorn updates to the optimal dual\nsolution of the entropic regularized UOT problem and some properties of the\nprimal solution. It is also different from the proof for the complexity of the\nSinkhorn algorithm for approximating the OT problem since the UOT solution does\nnot have to meet the marginal constraints.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 06:03:36 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 04:02:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Pham", "Khiem", ""], ["Le", "Khang", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""]]}, {"id": "2002.03298", "submitter": "Hristo Paskov", "authors": "Hristo Paskov, Alex Paskov, Robert West", "title": "Learning High Order Feature Interactions with Fine Control Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a methodology for learning sparse statistical models that use as\nfeatures all possible multiplicative interactions among an underlying atomic\nset of features. While the resulting optimization problems are exponentially\nsized, our methodology leads to algorithms that can often solve these problems\nexactly or provide approximate solutions based on combining highly correlated\nfeatures. We also introduce an algorithmic paradigm, the Fine Control Kernel\nframework, so named because it is based on Fenchel Duality and is reminiscent\nof kernel methods. Its theory is tailored to large sparse learning problems,\nand it leads to efficient feature screening rules for interactions. These rules\nare inspired by the Apriori algorithm for market basket analysis -- which also\nfalls under the purview of Fine Control Kernels, and can be applied to a\nplurality of learning problems including the Lasso and sparse matrix\nestimation. Experiments on biomedical datasets demonstrate the efficacy of our\nmethodology in deriving algorithms that efficiently produce interactions models\nwhich achieve state-of-the-art accuracy and are interpretable.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 06:29:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Paskov", "Hristo", ""], ["Paskov", "Alex", ""], ["West", "Robert", ""]]}, {"id": "2002.03305", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Harsh Mehta", "title": "Momentum Improves Normalized SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an improved analysis of normalized SGD showing that adding\nmomentum provably removes the need for large batch sizes on non-convex\nobjectives. Then, we consider the case of objectives with bounded second\nderivative and show that in this case a small tweak to the momentum formula\nallows normalized SGD with momentum to find an $\\epsilon$-critical point in\n$O(1/\\epsilon^{3.5})$ iterations, matching the best-known rates without\naccruing any logarithmic factors or dependence on dimension. We also provide an\nadaptive method that automatically improves convergence rates when the variance\nin the gradients is small. Finally, we show that our method is effective when\nemployed on popular large scale tasks such as ResNet-50 and BERT pretraining,\nmatching the performance of the disparate methods used to get state-of-the-art\nresults on both tasks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 07:00:54 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 03:05:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Mehta", "Harsh", ""]]}, {"id": "2002.03309", "submitter": "Hieu Nguyen", "authors": "Han B. Kim, Hieu Nguyen, Qingchu Jin, Sharmila Tamby, Tatiana Gelaf\n  Romer, Eric Sung, Ran Liu, Joseph Greenstein, Jose I. Suarez, Christian\n  Storm, Raimond Winslow, Robert D. Stevens", "title": "A Physiology-Driven Computational Model for Post-Cardiac Arrest Outcome\n  Prediction", "comments": "51 pages, 7 figures, 4 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients resuscitated from cardiac arrest (CA) face a high risk of\nneurological disability and death, however pragmatic methods are lacking for\naccurate and reliable prognostication. The aim of this study was to build\ncomputational models to predict post-CA outcome by leveraging high-dimensional\npatient data available early after admission to the intensive care unit (ICU).\nWe hypothesized that model performance could be enhanced by integrating\nphysiological time series (PTS) data and by training machine learning (ML)\nclassifiers. We compared three models integrating features extracted from the\nelectronic health records (EHR) alone, features derived from PTS collected in\nthe first 24hrs after ICU admission (PTS24), and models integrating PTS24 and\nEHR. Outcomes of interest were survival and neurological outcome at ICU\ndischarge. Combined EHR-PTS24 models had higher discrimination (area under the\nreceiver operating characteristic curve [AUC]) than models which used either\nEHR or PTS24 alone, for the prediction of survival (AUC 0.85, 0.80 and 0.68\nrespectively) and neurological outcome (0.87, 0.83 and 0.78). The best ML\nclassifier achieved higher discrimination than the reference logistic\nregression model (APACHE III) for survival (AUC 0.85 vs 0.70) and neurological\noutcome prediction (AUC 0.87 vs 0.75). Feature analysis revealed previously\nunknown factors to be associated with post-CA recovery. Results attest to the\neffectiveness of ML models for post-CA predictive modeling and suggest that PTS\nrecorded in very early phase after resuscitation encode short-term outcome\nprobabilities.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 07:53:50 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 20:33:10 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kim", "Han B.", ""], ["Nguyen", "Hieu", ""], ["Jin", "Qingchu", ""], ["Tamby", "Sharmila", ""], ["Romer", "Tatiana Gelaf", ""], ["Sung", "Eric", ""], ["Liu", "Ran", ""], ["Greenstein", "Joseph", ""], ["Suarez", "Jose I.", ""], ["Storm", "Christian", ""], ["Winslow", "Raimond", ""], ["Stevens", "Robert D.", ""]]}, {"id": "2002.03327", "submitter": "Chen Tessler", "authors": "Chen Tessler and Shie Mannor", "title": "Reward Tweaking: Maximizing the Total Reward While Planning for Short\n  Horizons", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, the discount factor $\\gamma$ controls the agent's\neffective planning horizon. Traditionally, this parameter was considered part\nof the MDP; however, as deep reinforcement learning algorithms tend to become\nunstable when the effective planning horizon is long, recent works refer to\n$\\gamma$ as a hyper-parameter -- thus changing the underlying MDP and\npotentially leading the agent towards sub-optimal behavior on the original\ntask. In this work, we introduce \\emph{reward tweaking}. Reward tweaking learns\na surrogate reward function $\\tilde r$ for the discounted setting that induces\noptimal behavior on the original finite-horizon total reward task.\nTheoretically, we show that there exists a surrogate reward that leads to\noptimality in the original task and discuss the robustness of our approach.\nAdditionally, we perform experiments in high-dimensional continuous control\ntasks and show that reward tweaking guides the agent towards better\nlong-horizon returns although it plans for short horizons.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:50:07 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 12:45:09 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tessler", "Chen", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.03328", "submitter": "Yufeng Zhang", "authors": "Yufeng Zhang, Wanwei Liu, Zhenbang Chen, Ji Wang, Zhiming Liu, Kenli\n  Li, Hongmei Wei", "title": "Out-of-Distribution Detection with Distance Guarantee in Deep Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has revealed that deep generative models including flow-based\nmodels and Variational autoencoders may assign higher likelihood to\nout-of-distribution (OOD) data than in-distribution (ID) data. However, we\ncannot sample out OOD data from the model. This counterintuitive phenomenon has\nnot been satisfactorily explained. In this paper, we prove theorems to\ninvestigate the divergences in flow-based model and give two explanations to\nthe above phenomenon from divergence and geometric perspectives, respectively.\nBased on our analysis, we propose two group anomaly detection methods.\nFurthermore, we decompose the KL divergence and propose a point-wise anomaly\ndetection method. We have conducted extensive experiments on prevalent\nbenchmarks to evaluate our methods. For group anomaly detection (GAD), our\nmethod can achieve near 100\\% AUROC on all problems and has robustness against\ndata manipulations. On the contrary, the state-of-the-art (SOTA) GAD method\nperforms not better than random guessing for challenging problems and can be\nattacked by data manipulation in almost all cases. For point-wise anomaly\ndetection (PAD), our method is comparable to the SOTA PAD method on one\ncategory of problems and outperforms the baseline significantly on another\ncategory of problems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:54:12 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 11:56:54 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 13:56:04 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Yufeng", ""], ["Liu", "Wanwei", ""], ["Chen", "Zhenbang", ""], ["Wang", "Ji", ""], ["Liu", "Zhiming", ""], ["Li", "Kenli", ""], ["Wei", "Hongmei", ""]]}, {"id": "2002.03329", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Peter Richt\\'arik", "title": "Better Theory for SGD in the Nonconvex World", "comments": "33 pages, 3 figures, 4 theorems, and 4 propositions. V3 updates:\n  added several references on error conditions (Tseng, Solodov, Bottou and\n  Tsitsiklis, Grimmer), added a full proof of Corollary 1, cleaned up several\n  proofs, and made minor adjustments to text for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale nonconvex optimization problems are ubiquitous in modern machine\nlearning, and among practitioners interested in solving them, Stochastic\nGradient Descent (SGD) reigns supreme. We revisit the analysis of SGD in the\nnonconvex setting and propose a new variant of the recently introduced expected\nsmoothness assumption which governs the behaviour of the second moment of the\nstochastic gradient. We show that our assumption is both more general and more\nreasonable than assumptions made in all prior work. Moreover, our results yield\nthe optimal $\\mathcal{O}(\\varepsilon^{-4})$ rate for finding a stationary point\nof nonconvex smooth functions, and recover the optimal\n$\\mathcal{O}(\\varepsilon^{-1})$ rate for finding a global solution if the\nPolyak-{\\L}ojasiewicz condition is satisfied. We compare against convergence\nrates under convexity and prove a theorem on the convergence of SGD under\nQuadratic Functional Growth and convexity, which might be of independent\ninterest. Moreover, we perform our analysis in a framework which allows for a\ndetailed study of the effects of a wide array of sampling strategies and\nminibatch sizes for finite-sum optimization problems. We corroborate our\ntheoretical results with experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:56:06 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 18:03:10 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 15:03:18 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Khaled", "Ahmed", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.03335", "submitter": "Hila Levi", "authors": "Hila Levi, Shimon Ullman", "title": "Multi-Task Learning by a Top-Down Control Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the range of tasks performed by a general vision system expands, executing\nmultiple tasks accurately and efficiently in a single network has become an\nimportant and still open problem. Recent computer vision approaches address\nthis problem by branching networks, or by a channel-wise modulation of the\nnetwork feature-maps with task specific vectors. We present a novel\narchitecture that uses a dedicated top-down control network to modify the\nactivation of all the units in the main recognition network in a manner that\ndepends on the selected task, image content, and spatial location. We show the\neffectiveness of our scheme by achieving significantly better results than\nalternative state-of-the-art approaches on four datasets. We further\ndemonstrate our advantages in terms of task selectivity, scaling the number of\ntasks and interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 10:13:17 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 14:02:20 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 19:53:34 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Levi", "Hila", ""], ["Ullman", "Shimon", ""]]}, {"id": "2002.03339", "submitter": "Jiangchao Liu", "authors": "Jiangchao Liu, Liqian Chen, Antoine Mine and Ji Wang", "title": "Input Validation for Neural Networks via Runtime Local Robustness\n  Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local robustness verification can verify that a neural network is robust wrt.\nany perturbation to a specific input within a certain distance. We call this\ndistance Robustness Radius. We observe that the robustness radii of correctly\nclassified inputs are much larger than that of misclassified inputs which\ninclude adversarial examples, especially those from strong adversarial attacks.\nAnother observation is that the robustness radii of correctly classified inputs\noften follow a normal distribution. Based on these two observations, we propose\nto validate inputs for neural networks via runtime local robustness\nverification. Experiments show that our approach can protect neural networks\nfrom adversarial examples and improve their accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 10:24:29 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Jiangchao", ""], ["Chen", "Liqian", ""], ["Mine", "Antoine", ""], ["Wang", "Ji", ""]]}, {"id": "2002.03375", "submitter": "Jingyu He", "authors": "Jingyu He, P. Richard Hahn", "title": "Stochastic tree ensembles for regularized nonlinear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a novel stochastic tree ensemble method for nonlinear\nregression, which we refer to as XBART, short for Accelerated Bayesian Additive\nRegression Trees. By combining regularization and stochastic search strategies\nfrom Bayesian modeling with computationally efficient techniques from recursive\npartitioning approaches, the new method attains state-of-the-art performance:\nin many settings it is both faster and more accurate than the widely-used\nXGBoost algorithm. Via careful simulation studies, we demonstrate that our new\napproach provides accurate point-wise estimates of the mean function and does\nso faster than popular alternatives, such as BART, XGBoost and neural networks\n(using Keras). We also prove a number of basic theoretical results about the\nnew algorithm, including consistency of the single tree version of the model\nand stationarity of the Markov chain produced by the ensemble version.\nFurthermore, we demonstrate that initializing standard Bayesian additive\nregression trees Markov chain Monte Carlo (MCMC) at XBART-fitted trees\nconsiderably improves credible interval coverage and reduces total run-time.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 14:37:02 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 03:55:01 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 16:08:50 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 14:44:02 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["He", "Jingyu", ""], ["Hahn", "P. Richard", ""]]}, {"id": "2002.03387", "submitter": "Samir Passi", "authors": "Samir Passi, Steven J. Jackson", "title": "Data Vision: Learning to See Through Algorithmic Abstraction", "comments": null, "journal-ref": "In Proceedings of the 2017 ACM Conference on Computer Supported\n  Cooperative Work and Social Computing. ACM, New York, NY, USA, 2436-2447", "doi": "10.1145/2998181.2998331", "report-no": null, "categories": "cs.HC cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to see through data is central to contemporary forms of algorithmic\nknowledge production. While often represented as a mechanical application of\nrules, making algorithms work with data requires a great deal of situated work.\nThis paper examines how the often-divergent demands of mechanization and\ndiscretion manifest in data analytic learning environments. Drawing on research\nin CSCW and the social sciences, and ethnographic fieldwork in two data\nlearning environments, we show how an algorithm's application is seen sometimes\nas a mechanical sequence of rules and at other times as an array of situated\ndecisions. Casting data analytics as a rule-based (rather than rule-bound)\npractice, we show that effective data vision requires would-be analysts to\nstraddle the competing demands of formal abstraction and empirical contingency.\nWe conclude by discussing how the notion of data vision can help better\nleverage the role of human work in data analytic learning, research, and\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:46:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Passi", "Samir", ""], ["Jackson", "Steven J.", ""]]}, {"id": "2002.03388", "submitter": "Shushan Arakelyan", "authors": "Shushan Arakelyan, Sima Arasteh, Christophe Hauser, Erik Kline and\n  Aram Galstyan", "title": "Bin2vec: Learning Representations of Binary Executable Programs for\n  Security Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tackling binary program analysis problems has traditionally implied manually\ndefining rules and heuristics, a tedious and time-consuming task for human\nanalysts. In order to improve automation and scalability, we propose an\nalternative direction based on distributed representations of binary programs\nwith applicability to a number of downstream tasks. We introduce Bin2vec, a new\napproach leveraging Graph Convolutional Networks (GCN) along with computational\nprogram graphs in order to learn a high dimensional representation of binary\nexecutable programs. We demonstrate the versatility of this approach by using\nour representations to solve two semantically different binary analysis tasks -\nfunctional algorithm classification and vulnerability discovery. We compare the\nproposed approach to our own strong baseline as well as published results and\ndemonstrate improvement over state-of-the-art methods for both tasks. We\nevaluated Bin2vec on 49191 binaries for the functional algorithm classification\ntask, and on 30 different CWE-IDs including at least 100 CVE entries each for\nthe vulnerability discovery task. We set a new state-of-the-art result by\nreducing the classification error by 40% compared to the source-code-based\ninst2vec approach, while working on binary code. For almost every vulnerability\nclass in our dataset, our prediction accuracy is over 80% (and over 90% in\nmultiple classes).\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:46:43 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 17:27:57 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Arakelyan", "Shushan", ""], ["Arasteh", "Sima", ""], ["Hauser", "Christophe", ""], ["Kline", "Erik", ""], ["Galstyan", "Aram", ""]]}, {"id": "2002.03399", "submitter": "Felix Kuhnke", "authors": "Felix Kuhnke, Lars Rumberg, J\\\"orn Ostermann", "title": "Two-Stream Aural-Visual Affect Analysis in the Wild", "comments": "6 pages, 2 figures, Face and Gesture 2020 Workshop Paper (ABAW2020\n  competition)", "journal-ref": null, "doi": "10.1109/FG47880.2020.00056", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human affect recognition is an essential part of natural human-computer\ninteraction. However, current methods are still in their infancy, especially\nfor in-the-wild data. In this work, we introduce our submission to the\nAffective Behavior Analysis in-the-wild (ABAW) 2020 competition. We propose a\ntwo-stream aural-visual analysis model to recognize affective behavior from\nvideos. Audio and image streams are first processed separately and fed into a\nconvolutional neural network. Instead of applying recurrent architectures for\ntemporal analysis we only use temporal convolutions. Furthermore, the model is\ngiven access to additional features extracted during face-alignment. At\ntraining time, we exploit correlations between different emotion\nrepresentations to improve performance. Our model achieves promising results on\nthe challenging Aff-Wild2 database.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 16:59:56 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:59:01 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kuhnke", "Felix", ""], ["Rumberg", "Lars", ""], ["Ostermann", "J\u00f6rn", ""]]}, {"id": "2002.03425", "submitter": "Felix Wick", "authors": "Felix Wick and Ulrich Kerzel and Michael Feindt", "title": "Cyclic Boosting -- an explainable supervised machine learning algorithm", "comments": "added a discussion about causality", "journal-ref": "2019 18th IEEE International Conference On Machine Learning And\n  Applications (ICMLA)", "doi": "10.1109/ICMLA.2019.00067", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning algorithms have seen spectacular advances and\nsurpassed human level performance in a wide range of specific applications.\nHowever, using complex ensemble or deep learning algorithms typically results\nin black box models, where the path leading to individual predictions cannot be\nfollowed in detail. In order to address this issue, we propose the novel\n\"Cyclic Boosting\" machine learning algorithm, which allows to efficiently\nperform accurate regression and classification tasks while at the same time\nallowing a detailed understanding of how each individual prediction was made.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:52:42 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 13:50:31 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 16:17:14 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wick", "Felix", ""], ["Kerzel", "Ulrich", ""], ["Feindt", "Michael", ""]]}, {"id": "2002.03427", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Graph Neural Distance Metric Learning with Graph-Bert", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph distance metric learning serves as the foundation for many graph\nlearning problems, e.g., graph clustering, graph classification and graph\nmatching. Existing research works on graph distance metric (or graph kernels)\nlearning fail to maintain the basic properties of such metrics, e.g.,\nnon-negative, identity of indiscernibles, symmetry and triangle inequality,\nrespectively. In this paper, we will introduce a new graph neural network based\ndistance metric learning approaches, namely GB-DISTANCE (GRAPH-BERT based\nNeural Distance). Solely based on the attention mechanism, GB-DISTANCE can\nlearn graph instance representations effectively based on a pre-trained\nGRAPH-BERT model. Different from the existing supervised/unsupervised metrics,\nGB-DISTANCE can be learned effectively in a semi-supervised manner. In\naddition, GB-DISTANCE can also maintain the distance metric basic properties\nmentioned above. Extensive experiments have been done on several benchmark\ngraph datasets, and the results demonstrate that GB-DISTANCE can out-perform\nthe existing baseline methods, especially the recent graph neural network model\nbased graph metrics, with a significant gap in computing the graph distance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:58:31 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2002.03428", "submitter": "Elizabeth Liner", "authors": "Elizabeth Liner, Risto Miikkulainen", "title": "Improving Neural Network Learning Through Dual Variable Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and evaluates a novel training method for neural\nnetworks: Dual Variable Learning Rates (DVLR). Building on insights from\nbehavioral psychology, the dual learning rates are used to emphasize correct\nand incorrect responses differently, thereby making the feedback to the network\nmore specific. Further, the learning rates are varied as a function of the\nnetwork's performance, thereby making it more efficient. DVLR was implemented\non three types of networks: feedforward, convolutional, and residual, and two\ndomains: MNIST and CIFAR-10. The results suggest a consistently improved\naccuracy, demonstrating that DVLR is a promising, psychologically motivated\ntechnique for training neural network models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:01:05 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 04:29:17 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 21:22:12 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Liner", "Elizabeth", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.03432", "submitter": "Jeremy Bernstein", "authors": "Jeremy Bernstein, Arash Vahdat, Yisong Yue, Ming-Yu Liu", "title": "On the distance between two neural networks and the stability of\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper relates parameter distance to gradient breakdown for a broad class\nof nonlinear compositional functions. The analysis leads to a new distance\nfunction called deep relative trust and a descent lemma for neural networks.\nSince the resulting learning rule seems to require little to no learning rate\ntuning, it may unlock a simpler workflow for training deeper and more complex\nneural networks. The Python code used in this paper is here:\nhttps://github.com/jxbz/fromage.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:18:39 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:36:33 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 13:51:25 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Bernstein", "Jeremy", ""], ["Vahdat", "Arash", ""], ["Yue", "Yisong", ""], ["Liu", "Ming-Yu", ""]]}, {"id": "2002.03444", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Usman Roshan", "title": "Robust binary classification with the 01 loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The 01 loss is robust to outliers and tolerant to noisy data compared to\nconvex loss functions. We conjecture that the 01 loss may also be more robust\nto adversarial attacks. To study this empirically we have developed a\nstochastic coordinate descent algorithm for a linear 01 loss classifier and a\nsingle hidden layer 01 loss neural network. Due to the absence of the gradient\nwe iteratively update coordinates on random subsets of the data for fixed\nepochs. We show our algorithms to be fast and comparable in accuracy to the\nlinear support vector machine and logistic loss single hidden layer network for\nbinary classification on several image benchmarks, thus establishing that our\nmethod is on-par in test accuracy with convex losses. We then subject them to\naccurately trained substitute model black box attacks on the same image\nbenchmarks and find them to be more robust than convex counterparts. On CIFAR10\nbinary classification task between classes 0 and 1 with adversarial\nperturbation of 0.0625 we see that the MLP01 network loses 27\\% in accuracy\nwhereas the MLP-logistic counterpart loses 83\\%. Similarly on STL10 and\nImageNet binary classification between classes 0 and 1 the MLP01 network loses\n21\\% and 20\\% while MLP-logistic loses 67\\% and 45\\% respectively. On MNIST\nthat is a well-separable dataset we find MLP01 comparable to MLP-logistic and\nshow under simulation how and why our 01 loss solver is less robust there. We\nthen propose adversarial training for our linear 01 loss solver that\nsignificantly improves its robustness on MNIST and all other datasets and\nretains clean test accuracy. Finally we show practical applications of our\nmethod to deter traffic sign and facial recognition adversarial attacks. We\ndiscuss attacks with 01 loss, substitute model accuracy, and several future\navenues like multiclass, 01 loss convolutions, and further adversarial\ntraining.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 20:41:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Roshan", "Usman", ""]]}, {"id": "2002.03461", "submitter": "Piotr Koniusz", "authors": "Xianjing Wang, Flora D. Salim, Yongli Ren, Piotr Koniusz", "title": "Relation Embedding for Personalised POI Recommendation", "comments": "12 pages, 3 figures, Accepted in the 24th Pacific-Asia Conference on\n  Knowledge Discovery and Data Mining (PAKDD 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-47426-3_5", "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-of-Interest (POI) recommendation is one of the most important\nlocation-based services helping people discover interesting venues or services.\nHowever, the extreme user-POI matrix sparsity and the varying spatio-temporal\ncontext pose challenges for POI systems, which affects the quality of POI\nrecommendations. To this end, we propose a translation-based relation embedding\nfor POI recommendation. Our approach encodes the temporal and geographic\ninformation, as well as semantic contents effectively in a low-dimensional\nrelation space by using Knowledge Graph Embedding techniques. To further\nalleviate the issue of user-POI matrix sparsity, a combined matrix\nfactorization framework is built on a user-POI graph to enhance the inference\nof dynamic personal interests by exploiting the side-information. Experiments\non two real-world datasets demonstrate the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 22:26:52 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:40:48 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Xianjing", ""], ["Salim", "Flora D.", ""], ["Ren", "Yongli", ""], ["Koniusz", "Piotr", ""]]}, {"id": "2002.03469", "submitter": "Peng Chen", "authors": "Peng Chen, Omar Ghattas", "title": "Projected Stein Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality is a longstanding challenge in Bayesian inference\nin high dimensions. In this work, we propose a projected Stein variational\ngradient descent (pSVGD) method to overcome this challenge by exploiting the\nfundamental property of intrinsic low dimensionality of the data informed\nsubspace stemming from ill-posedness of such problems. We adaptively construct\nthe subspace using a gradient information matrix of the log-likelihood, and\napply pSVGD to the much lower-dimensional coefficients of the parameter\nprojection. The method is demonstrated to be more accurate and efficient than\nSVGD. It is also shown to be more scalable with respect to the number of\nparameters, samples, data points, and processor cores via experiments with\nparameters dimensions ranging from the hundreds to the tens of thousands.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 23:17:30 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:00:24 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Peng", ""], ["Ghattas", "Omar", ""]]}, {"id": "2002.03471", "submitter": "Felipe Tobar", "authors": "Taco de Wolff and Alejandro Cuevas and Felipe Tobar", "title": "MOGPTK: The Multi-Output Gaussian Process Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MOGPTK, a Python package for multi-channel data modelling using\nGaussian processes (GP). The aim of this toolkit is to make multi-output GP\n(MOGP) models accessible to researchers, data scientists, and practitioners\nalike. MOGPTK uses a Python front-end, relies on the GPflow suite and is built\non a TensorFlow back-end, thus enabling GPU-accelerated training. The toolkit\nfacilitates implementing the entire pipeline of GP modelling, including data\nloading, parameter initialization, model learning, parameter interpretation, up\nto data imputation and extrapolation. MOGPTK implements the main multi-output\ncovariance kernels from literature, as well as spectral-based parameter\ninitialization strategies. The source code, tutorials and examples in the form\nof Jupyter notebooks, together with the API documentation, can be found at\nhttp://github.com/GAMES-UChile/mogptk\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 23:34:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["de Wolff", "Taco", ""], ["Cuevas", "Alejandro", ""], ["Tobar", "Felipe", ""]]}, {"id": "2002.03478", "submitter": "Omer Gottesman", "authors": "Omer Gottesman, Joseph Futoma, Yao Liu, Sonali Parbhoo, Leo Anthony\n  Celi, Emma Brunskill, Finale Doshi-Velez", "title": "Interpretable Off-Policy Evaluation in Reinforcement Learning by\n  Highlighting Influential Transitions", "comments": "ICML final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation in reinforcement learning offers the chance of using\nobservational data to improve future outcomes in domains such as healthcare and\neducation, but safe deployment in high stakes settings requires ways of\nassessing its validity. Traditional measures such as confidence intervals may\nbe insufficient due to noise, limited data and confounding. In this paper we\ndevelop a method that could serve as a hybrid human-AI system, to enable human\nexperts to analyze the validity of policy evaluation estimates. This is\naccomplished by highlighting observations in the data whose removal will have a\nlarge effect on the OPE estimate, and formulating a set of rules for choosing\nwhich ones to present to domain experts for validation. We develop methods to\ncompute exactly the influence functions for fitted Q-evaluation with two\ndifferent function classes: kernel-based and linear least squares, as well as\nimportance sampling methods. Experiments on medical simulations and real-world\nintensive care unit data demonstrate that our method can be used to identify\nlimitations in the evaluation process and make evaluation more robust.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:26:43 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:40:16 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 06:51:45 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Gottesman", "Omer", ""], ["Futoma", "Joseph", ""], ["Liu", "Yao", ""], ["Parbhoo", "Sonali", ""], ["Celi", "Leo Anthony", ""], ["Brunskill", "Emma", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2002.03480", "submitter": "Jeremy Nixon", "authors": "Jeremy Nixon, Jeremiah Liu, David Berthelot", "title": "Semi-Supervised Class Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One promising approach to dealing with datapoints that are outside of the\ninitial training distribution (OOD) is to create new classes that capture\nsimilarities in the datapoints previously rejected as uncategorizable. Systems\nthat generate labels can be deployed against an arbitrary amount of data,\ndiscovering classification schemes that through training create a higher\nquality representation of data. We introduce the Dataset Reconstruction\nAccuracy, a new and important measure of the effectiveness of a model's ability\nto create labels. We introduce benchmarks against this Dataset Reconstruction\nmetric. We apply a new heuristic, class learnability, for deciding whether a\nclass is worthy of addition to the training dataset. We show that our class\ndiscovery system can be successfully applied to vision and language, and we\ndemonstrate the value of semi-supervised learning in automatically discovering\nnovel classes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:29:44 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 01:31:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Nixon", "Jeremy", ""], ["Liu", "Jeremiah", ""], ["Berthelot", "David", ""]]}, {"id": "2002.03485", "submitter": "Dhairya Dalal", "authors": "Dhairya Dalal and Byron V. Galbraith", "title": "Evaluating Sequence-to-Sequence Learning Models for If-Then Program\n  Synthesis", "comments": "AAAI IPA workshop submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing enterprise process automation often requires significant\ntechnical expertise and engineering effort. It would be beneficial for\nnon-technical users to be able to describe a business process in natural\nlanguage and have an intelligent system generate the workflow that can be\nautomatically executed. A building block of process automations are If-Then\nprograms. In the consumer space, sites like IFTTT and Zapier allow users to\ncreate automations by defining If-Then programs using a graphical interface. We\nexplore the efficacy of modeling If-Then programs as a sequence learning task.\nWe find Seq2Seq approaches have high potential (performing strongly on the\nZapier recipes) and can serve as a promising approach to more complex program\nsynthesis challenges.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:45:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dalal", "Dhairya", ""], ["Galbraith", "Byron V.", ""]]}, {"id": "2002.03494", "submitter": "Pan Danqing", "authors": "Danqing Pan, Tong Wang, Satoshi Hara", "title": "Interpretable Companions for Black-Box Models", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interpretable companion model for any pre-trained black-box\nclassifiers. The idea is that for any input, a user can decide to either\nreceive a prediction from the black-box model, with high accuracy but no\nexplanations, or employ a companion rule to obtain an interpretable prediction\nwith slightly lower accuracy. The companion model is trained from data and the\npredictions of the black-box model, with the objective combining area under the\ntransparency--accuracy curve and model complexity. Our model provides flexible\nchoices for practitioners who face the dilemma of choosing between always using\ninterpretable models and always using black-box models for a predictive task,\nso users can, for any given input, take a step back to resort to an\ninterpretable prediction if they find the predictive performance satisfying, or\nstick to the black-box model if the rules are unsatisfying. To show the value\nof companion models, we design a human evaluation on more than a hundred people\nto investigate the tolerable accuracy loss to gain interpretability for humans.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 01:39:16 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 05:38:05 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Pan", "Danqing", ""], ["Wang", "Tong", ""], ["Hara", "Satoshi", ""]]}, {"id": "2002.03495", "submitter": "Zeke Xie", "authors": "Zeke Xie, Issei Sato, and Masashi Sugiyama", "title": "A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient\n  Descent Exponentially Favors Flat Minima", "comments": "ICLR 2021; 28 pages; 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) and its variants are mainstream methods for\ntraining deep networks in practice. SGD is known to find a flat minimum that\noften generalizes well. However, it is mathematically unclear how deep learning\ncan select a flat minimum among so many minima. To answer the question\nquantitatively, we develop a density diffusion theory (DDT) to reveal how\nminima selection quantitatively depends on the minima sharpness and the\nhyperparameters. To the best of our knowledge, we are the first to\ntheoretically and empirically prove that, benefited from the Hessian-dependent\ncovariance of stochastic gradient noise, SGD favors flat minima exponentially\nmore than sharp minima, while Gradient Descent (GD) with injected white noise\nfavors flat minima only polynomially more than sharp minima. We also reveal\nthat either a small learning rate or large-batch training requires\nexponentially many iterations to escape from minima in terms of the ratio of\nthe batch size and learning rate. Thus, large-batch training cannot search flat\nminima efficiently in a realistic computational time.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:04:49 GMT"}, {"version": "v10", "created": "Mon, 29 Jun 2020 05:27:27 GMT"}, {"version": "v11", "created": "Sat, 4 Jul 2020 04:54:20 GMT"}, {"version": "v12", "created": "Sat, 26 Sep 2020 11:36:52 GMT"}, {"version": "v13", "created": "Tue, 24 Nov 2020 05:12:13 GMT"}, {"version": "v14", "created": "Fri, 15 Jan 2021 14:57:46 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 06:24:38 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 04:40:24 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2020 08:27:12 GMT"}, {"version": "v5", "created": "Thu, 5 Mar 2020 12:04:23 GMT"}, {"version": "v6", "created": "Tue, 14 Apr 2020 10:51:51 GMT"}, {"version": "v7", "created": "Mon, 4 May 2020 08:11:19 GMT"}, {"version": "v8", "created": "Thu, 21 May 2020 00:54:13 GMT"}, {"version": "v9", "created": "Mon, 22 Jun 2020 03:52:54 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Xie", "Zeke", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.03497", "submitter": "Takeshi Teshima", "authors": "Takeshi Teshima, Issei Sato, Masashi Sugiyama", "title": "Few-shot Domain Adaptation by Causal Mechanism Transfer", "comments": "33 pages, 3 figures. Camera-ready version for Thirty-seventh\n  International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study few-shot supervised domain adaptation (DA) for regression problems,\nwhere only a few labeled target domain data and many labeled source domain data\nare available. Many of the current DA methods base their transfer assumptions\non either parametrized distribution shift or apparent distribution\nsimilarities, e.g., identical conditionals or small distributional\ndiscrepancies. However, these assumptions may preclude the possibility of\nadaptation from intricately shifted and apparently very different\ndistributions. To overcome this problem, we propose mechanism transfer, a\nmeta-distributional scenario in which a data generating mechanism is invariant\namong domains. This transfer assumption can accommodate nonparametric shifts\nresulting in apparently different distributions while providing a solid\nstatistical basis for DA. We take the structural equations in causal modeling\nas an example and propose a novel DA method, which is shown to be useful both\ntheoretically and experimentally. Our method can be seen as the first attempt\nto fully leverage the structural causal models for DA.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:16:53 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:10:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Teshima", "Takeshi", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.03503", "submitter": "Ehsan Kazemi", "authors": "Ehsan Kazemi and Shervin Minaee and Moran Feldman and Amin Karbasi", "title": "Regularized Submodular Maximization at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose scalable methods for maximizing a regularized\nsubmodular function $f = g - \\ell$ expressed as the difference between a\nmonotone submodular function $g$ and a modular function $\\ell$. Indeed,\nsubmodularity is inherently related to the notions of diversity, coverage, and\nrepresentativeness. In particular, finding the mode of many popular\nprobabilistic models of diversity, such as determinantal point processes,\nsubmodular probabilistic models, and strongly log-concave distributions,\ninvolves maximization of (regularized) submodular functions. Since a\nregularized function $f$ can potentially take on negative values, the classic\ntheory of submodular maximization, which heavily relies on the non-negativity\nassumption of submodular functions, may not be applicable. To circumvent this\nchallenge, we develop the first one-pass streaming algorithm for maximizing a\nregularized submodular function subject to a $k$-cardinality constraint. It\nreturns a solution $S$ with the guarantee that $f(S)\\geq(\\phi^{-2}-\\epsilon)\n\\cdot g(OPT)-\\ell (OPT)$, where $\\phi$ is the golden ratio. Furthermore, we\ndevelop the first distributed algorithm that returns a solution $S$ with the\nguarantee that $\\mathbb{E}[f(S)] \\geq (1-\\epsilon) [(1-e^{-1}) \\cdot\ng(OPT)-\\ell(OPT)]$ in $O(1/ \\epsilon)$ rounds of MapReduce computation, without\nkeeping multiple copies of the entire dataset in each round (as it is usually\ndone). We should highlight that our result, even for the unregularized case\nwhere the modular term $\\ell$ is zero, improves the memory and communication\ncomplexity of the existing work by a factor of $O(1/ \\epsilon)$ while arguably\nprovides a simpler distributed algorithm and a unifying analysis. We also\nempirically study the performance of our scalable methods on a set of real-life\napplications, including finding the mode of distributions, data summarization,\nand product recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:37:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Minaee", "Shervin", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.03508", "submitter": "Sainyam Galhotra Mr", "authors": "Saba Ahmadi, Sainyam Galhotra, Barna Saha, Roy Schwartz", "title": "Fair Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study the problem of correlation clustering under fairness\nconstraints. In the classic correlation clustering problem, we are given a\ncomplete graph where each edge is labeled positive or negative. The goal is to\nobtain a clustering of the vertices that minimizes disagreements -- the number\nof negative edges trapped inside a cluster plus positive edges between\ndifferent clusters.\n  We consider two variations of fairness constraint for the problem of\ncorrelation clustering where each node has a color, and the goal is to form\nclusters that do not over-represent vertices of any color.\n  The first variant aims to generate clusters with minimum disagreements, where\nthe distribution of a feature (e.g. gender) in each cluster is same as the\nglobal distribution. For the case of two colors when the desired ratio of the\nnumber of colors in each cluster is $1:p$, we get\n$\\mathcal{O}(p^2)$-approximation algorithm. Our algorithm could be extended to\nthe case of multiple colors. We prove this problem is NP-hard.\n  The second variant considers relative upper and lower bounds on the number of\nnodes of any color in a cluster. The goal is to avoid violating upper and lower\nbounds corresponding to each color in each cluster while minimizing the total\nnumber of disagreements. Along with our theoretical results, we show the\neffectiveness of our algorithm to generate fair clusters by empirical\nevaluation on real world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:59:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ahmadi", "Saba", ""], ["Galhotra", "Sainyam", ""], ["Saha", "Barna", ""], ["Schwartz", "Roy", ""]]}, {"id": "2002.03513", "submitter": "Shaojun Ma", "authors": "Shaojun Ma, Shu Liu, Hongyuan Zha, Haomin Zhou", "title": "Learning Stochastic Behaviour from Aggregate Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning nonlinear dynamics from aggregate data is a challenging problem\nbecause the full trajectory of each individual is not available, namely, the\nindividual observed at one time may not be observed at the next time point, or\nthe identity of individual is unavailable. This is in sharp contrast to\nlearning dynamics with full trajectory data, on which the majority of existing\nmethods are based. We propose a novel method using the weak form of Fokker\nPlanck Equation (FPE) -- a partial differential equation -- to describe the\ndensity evolution of data in a sampled form, which is then combined with\nWasserstein generative adversarial network (WGAN) in the training process. In\nsuch a sample-based framework we are able to learn the nonlinear dynamics from\naggregate data without explicitly solving the partial differential equation\n(PDE) FPE. We demonstrate our approach in the context of a series of synthetic\nand real-world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:20:13 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 02:54:51 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 02:55:54 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 03:32:07 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2021 04:48:44 GMT"}, {"version": "v6", "created": "Sat, 29 May 2021 02:41:01 GMT"}, {"version": "v7", "created": "Mon, 7 Jun 2021 13:41:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ma", "Shaojun", ""], ["Liu", "Shu", ""], ["Zha", "Hongyuan", ""], ["Zhou", "Haomin", ""]]}, {"id": "2002.03516", "submitter": "Ren Liu", "authors": "Ren Liu, Xiaoqun Zhang", "title": "Semi-Implicit Back Propagation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network has attracted great attention for a long time and many\nresearchers are devoted to improve the effectiveness of neural network training\nalgorithms. Though stochastic gradient descent (SGD) and other explicit\ngradient-based methods are widely adopted, there are still many challenges such\nas gradient vanishing and small step sizes, which leads to slow convergence and\ninstability of SGD algorithms. Motivated by error back propagation (BP) and\nproximal methods, we propose a semi-implicit back propagation method for neural\nnetwork training. Similar to BP, the difference on the neurons are propagated\nin a backward fashion and the parameters are updated with proximal mapping. The\nimplicit update for both hidden neurons and parameters allows to choose large\nstep size in the training algorithm. Finally, we also show that any fixed point\nof convergent sequences produced by this algorithm is a stationary point of the\nobjective loss function. The experiments on both MNIST and CIFAR-10 demonstrate\nthat the proposed semi-implicit BP algorithm leads to better performance in\nterms of both loss decreasing and training/validation accuracy, compared to SGD\nand a similar algorithm ProxBP.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:26:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Ren", ""], ["Zhang", "Xiaoqun", ""]]}, {"id": "2002.03517", "submitter": "Hongyang Zhang", "authors": "Avrim Blum, Travis Dick, Naren Manoj, Hongyang Zhang", "title": "Random Smoothing Might be Unable to Certify $\\ell_\\infty$ Robustness for\n  High-Dimensional Images", "comments": "20 pages, 2 figures; Code is available at\n  https://github.com/hongyanz/TRADES-smoothing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a hardness result for random smoothing to achieve certified\nadversarial robustness against attacks in the $\\ell_p$ ball of radius\n$\\epsilon$ when $p>2$. Although random smoothing has been well understood for\nthe $\\ell_2$ case using the Gaussian distribution, much remains unknown\nconcerning the existence of a noise distribution that works for the case of\n$p>2$. This has been posed as an open problem by Cohen et al. (2019) and\nincludes many significant paradigms such as the $\\ell_\\infty$ threat model. In\nthis work, we show that any noise distribution $\\mathcal{D}$ over\n$\\mathbb{R}^d$ that provides $\\ell_p$ robustness for all base classifiers with\n$p>2$ must satisfy\n$\\mathbb{E}\\eta_i^2=\\Omega(d^{1-2/p}\\epsilon^2(1-\\delta)/\\delta^2)$ for 99% of\nthe features (pixels) of vector $\\eta\\sim\\mathcal{D}$, where $\\epsilon$ is the\nrobust radius and $\\delta$ is the score gap between the highest-scored class\nand the runner-up. Therefore, for high-dimensional images with pixel values\nbounded in $[0,255]$, the required noise will eventually dominate the useful\ninformation in the images, leading to trivial smoothed classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:26:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 02:02:22 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 17:16:41 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Blum", "Avrim", ""], ["Dick", "Travis", ""], ["Manoj", "Naren", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2002.03519", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran and Svetha Venkatesh", "title": "Self-Attentive Associative Memory", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heretofore, neural networks with external memory are restricted to single\nmemory with lossy representations of memory interactions. A rich representation\nof relationships between memory pieces urges a high-order and segregated\nrelational memory. In this paper, we propose to separate the storage of\nindividual experiences (item memory) and their occurring relationships\n(relational memory). The idea is implemented through a novel Self-attentive\nAssociative Memory (SAM) operator. Found upon outer product, SAM forms a set of\nassociative memories that represent the hypothetical high-order relationships\nbetween arbitrary pairs of memory elements, through which a relational memory\nis constructed from an item memory. The two memories are wired into a single\nsequential model capable of both memorization and relational reasoning. We\nachieve competitive results with our proposed two-memory model in a diversity\nof machine learning tasks, from challenging synthetic problems to practical\ntestbeds such as geometry, graph, reinforcement learning, and question\nanswering.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:27:48 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 02:32:37 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 04:56:52 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2002.03521", "submitter": "Shahriar Esmaeili", "authors": "Saeideh Roshanfekr, Shahriar Esmaeili, Hassan Ataeian, and Ali Amiri", "title": "UGRWO-Sampling: A modified random walk under-sampling approach based on\n  graphs to imbalanced data classification", "comments": "34 pages, 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a new RWO-Sampling (Random Walk Over-Sampling)\nbased on graphs for imbalanced datasets. In this method, two figures based on\nunder-sampling and over-sampling methods are introduced to keep the proximity\ninformation, which is robust to noises and outliers. After the construction of\nthe first graph on minority class, RWO-Sampling will be implemented on selected\nsamples, and the rest of them will remain unchanged. The second graph is\nconstructed for the majority class, and the samples in a low-density area\n(outliers) are removed. In the proposed method, examples of the majority class\nin a high-density area are selected, and the rest of them are eliminated.\nFurthermore, utilizing RWO-sampling, the boundary of minority class is\nincreased though, the outliers are not raised. This method is tested, and the\nnumber of evaluation measures is compared to previous methods on nine\ncontinuous attribute datasets with different over-sampling rates. The\nexperimental results were an indicator of the high efficiency and flexibility\nof the proposed method for the classification of imbalanced data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:29:24 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 20:55:49 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Roshanfekr", "Saeideh", ""], ["Esmaeili", "Shahriar", ""], ["Ataeian", "Hassan", ""], ["Amiri", "Ali", ""]]}, {"id": "2002.03523", "submitter": "Ehsan Kazemi", "authors": "Ashwinkumar Badanidiyuru and Amin Karbasi and Ehsan Kazemi and Jan\n  Vondrak", "title": "Submodular Maximization Through Barrier Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel technique for constrained submodular\nmaximization, inspired by barrier functions in continuous optimization. This\nconnection not only improves the running time for constrained submodular\nmaximization but also provides the state of the art guarantee. More precisely,\nfor maximizing a monotone submodular function subject to the combination of a\n$k$-matchoid and $\\ell$-knapsack constraint (for $\\ell\\leq k$), we propose a\npotential function that can be approximately minimized. Once we minimize the\npotential function up to an $\\epsilon$ error it is guaranteed that we have\nfound a feasible set with a $2(k+1+\\epsilon)$-approximation factor which can\nindeed be further improved to $(k+1+\\epsilon)$ by an enumeration technique. We\nextensively evaluate the performance of our proposed algorithm over several\nreal-world applications, including a movie recommendation system, summarization\ntasks for YouTube videos, Twitter feeds and Yelp business locations, and a set\ncover problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:32:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Badanidiyuru", "Ashwinkumar", ""], ["Karbasi", "Amin", ""], ["Kazemi", "Ehsan", ""], ["Vondrak", "Jan", ""]]}, {"id": "2002.03532", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Rakesh Shivanna, Zhe Zhao, Dong Lin, Anima Singh, Ed H.\n  Chi, Sagar Jain", "title": "Understanding and Improving Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a model-agnostic technique to improve model\nquality while having a fixed capacity budget. It is a commonly used technique\nfor model compression, where a larger capacity teacher model with better\nquality is used to train a more compact student model with better inference\nefficiency. Through distillation, one hopes to benefit from student's\ncompactness, without sacrificing too much on model quality. Despite the large\nsuccess of knowledge distillation, better understanding of how it benefits\nstudent model's training dynamics remains under-explored. In this paper, we\ncategorize teacher's knowledge into three hierarchical levels and study its\neffects on knowledge distillation: (1) knowledge of the `universe', where KD\nbrings a regularization effect through label smoothing; (2) domain knowledge,\nwhere teacher injects class relationships prior to student's logit layer\ngeometry; and (3) instance specific knowledge, where teacher rescales student\nmodel's per-instance gradients based on its measurement on the event\ndifficulty. Using systematic analyses and extensive empirical studies on both\nsynthetic and real-world datasets, we confirm that the aforementioned three\nfactors play a major role in knowledge distillation. Furthermore, based on our\nfindings, we diagnose some of the failure cases of applying KD from recent\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:21:41 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 23:31:44 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Tang", "Jiaxi", ""], ["Shivanna", "Rakesh", ""], ["Zhao", "Zhe", ""], ["Lin", "Dong", ""], ["Singh", "Anima", ""], ["Chi", "Ed H.", ""], ["Jain", "Sagar", ""]]}, {"id": "2002.03534", "submitter": "Yuguang Yue", "authors": "Yuguang Yue, Yunhao Tang, Mingzhang Yin, Mingyuan Zhou", "title": "Discrete Action On-Policy Learning with Action-Value Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in discrete action space is ubiquitous in\nreal-world applications, but its complexity grows exponentially with the\naction-space dimension, making it challenging to apply existing on-policy\ngradient based deep RL algorithms efficiently. To effectively operate in\nmultidimensional discrete action spaces, we construct a critic to estimate\naction-value functions, apply it on correlated actions, and combine these\ncritic estimated action values to control the variance of gradient estimation.\nWe follow rigorous statistical analysis to design how to generate and combine\nthese correlated actions, and how to sparsify the gradients by shutting down\nthe contributions from certain dimensions. These efforts result in a new\ndiscrete action on-policy RL algorithm that empirically outperforms related\non-policy algorithms relying on variance control techniques. We demonstrate\nthese properties on OpenAI Gym benchmark tasks, and illustrate how discretizing\nthe action space could benefit the exploration phase and hence facilitate\nconvergence to a better local optimal solution thanks to the flexibility of\ndiscrete policy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:23:09 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:28:01 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Yue", "Yuguang", ""], ["Tang", "Yunhao", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2002.03549", "submitter": "Rahul Soni", "authors": "Rahul Soni, Naresh Shah, Chua Tat Seng, Jimmy D. Moore", "title": "Adversarial TCAV -- Robust and Effective Interpretation of Intermediate\n  Layers in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting neural network decisions and the information learned in\nintermediate layers is still a challenge due to the opaque internal state and\nshared non-linear interactions. Although (Kim et al, 2017) proposed to\ninterpret intermediate layers by quantifying its ability to distinguish a\nuser-defined concept (from random examples), the questions of robustness\n(variation against the choice of random examples) and effectiveness (retrieval\nrate of concept images) remain. We investigate these two properties and propose\nimprovements to make concept activations reliable for practical use.\n  Effectiveness: If the intermediate layer has effectively learned a\nuser-defined concept, it should be able to recall --- at the testing step ---\nmost of the images containing the proposed concept. For instance, we observed\nthat the recall rate of Tiger shark and Great white shark from the ImageNet\ndataset with \"Fins\" as a user-defined concept was only 18.35% for VGG16. To\nincrease the effectiveness of concept learning, we propose A-CAV --- the\nAdversarial Concept Activation Vector --- this results in larger margins\nbetween user concepts and (negative) random examples. This approach improves\nthe aforesaid recall to 76.83% for VGG16.\n  For robustness, we define it as the ability of an intermediate layer to be\nconsistent in its recall rate (the effectiveness) for different random seeds.\nWe observed that TCAV has a large variance in recalling a concept across\ndifferent random seeds. For example, the recall of cat images (from a layer\nlearning the concept of tail) varies from 18% to 86% with 20.85% standard\ndeviation on VGG16. We propose a simple and scalable modification that employs\na Gram-Schmidt process to sample random noise from concepts and learn an\naverage \"concept classifier\". This approach improves the aforesaid standard\ndeviation from 20.85% to 6.4%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:15:03 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:15:30 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Soni", "Rahul", ""], ["Shah", "Naresh", ""], ["Seng", "Chua Tat", ""], ["Moore", "Jimmy D.", ""]]}, {"id": "2002.03553", "submitter": "Aaron Voelker", "authors": "Aaron R. Voelker and Daniel Rasmussen and Chris Eliasmith", "title": "A Spike in Performance: Training Hybrid-Spiking Neural Networks with\n  Quantized Activation Functions", "comments": "8 pages, 7 page supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community has become increasingly interested in the\nenergy efficiency of neural networks. The Spiking Neural Network (SNN) is a\npromising approach to energy-efficient computing, since its activation levels\nare quantized into temporally sparse, one-bit values (i.e., \"spike\" events),\nwhich additionally converts the sum over weight-activity products into a simple\naddition of weights (one weight for each spike). However, the goal of\nmaintaining state-of-the-art (SotA) accuracy when converting a non-spiking\nnetwork into an SNN has remained an elusive challenge, primarily due to spikes\nhaving only a single bit of precision. Adopting tools from signal processing,\nwe cast neural activation functions as quantizers with temporally-diffused\nerror, and then train networks while smoothly interpolating between the\nnon-spiking and spiking regimes. We apply this technique to the Legendre Memory\nUnit (LMU) to obtain the first known example of a hybrid SNN outperforming SotA\nrecurrent architectures -- including the LSTM, GRU, and NRU -- in accuracy,\nwhile reducing activities to at most 3.74 bits on average with 1.26 significant\nbits multiplying each weight. We discuss how these methods can significantly\nimprove the energy efficiency of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:24:27 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 22:02:28 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Voelker", "Aaron R.", ""], ["Rasmussen", "Daniel", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2002.03555", "submitter": "Richard Nock", "authors": "Richard Nock and Aditya Krishna Menon", "title": "Supervised Learning: No Loss No Cry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning requires the specification of a loss function to\nminimise. While the theory of admissible losses from both a computational and\nstatistical perspective is well-developed, these offer a panoply of different\nchoices. In practice, this choice is typically made in an \\emph{ad hoc} manner.\nIn hopes of making this procedure more principled, the problem of\n\\emph{learning the loss function} for a downstream task (e.g., classification)\nhas garnered recent interest. However, works in this area have been generally\nempirical in nature.\n  In this paper, we revisit the {\\sc SLIsotron} algorithm of Kakade et al.\n(2011) through a novel lens, derive a generalisation based on Bregman\ndivergences, and show how it provides a principled procedure for learning the\nloss. In detail, we cast {\\sc SLIsotron} as learning a loss from a family of\ncomposite square losses. By interpreting this through the lens of \\emph{proper\nlosses}, we derive a generalisation of {\\sc SLIsotron} based on Bregman\ndivergences. The resulting {\\sc BregmanTron} algorithm jointly learns the loss\nalong with the classifier. It comes equipped with a simple guarantee of\nconvergence for the loss it learns, and its set of possible outputs comes with\na guarantee of agnostic approximability of Bayes rule. Experiments indicate\nthat the {\\sc BregmanTron} substantially outperforms the {\\sc SLIsotron}, and\nthat the loss it learns can be minimized by other algorithms for different\ntasks, thereby opening the interesting problem of \\textit{loss transfer}\nbetween domains.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:30:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Nock", "Richard", ""], ["Menon", "Aditya Krishna", ""]]}, {"id": "2002.03575", "submitter": "Hongmin Zhu", "authors": "Hongmin Zhu, Fuli Feng, Xiangnan He, Xiang Wang, Yan Li, Kai Zheng,\n  Yongdong Zhang", "title": "Bilinear Graph Neural Network with Neighbor Interactions", "comments": "Accepted by IJCAI 2020. SOLE copyright holder is IJCAI (International\n  Joint Conferences on Artificial Intelligence), all rights reserved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Network (GNN) is a powerful model to learn representations and\nmake predictions on graph data. Existing efforts on GNN have largely defined\nthe graph convolution as a weighted sum of the features of the connected nodes\nto form the representation of the target node. Nevertheless, the operation of\nweighted sum assumes the neighbor nodes are independent of each other, and\nignores the possible interactions between them. When such interactions exist,\nsuch as the co-occurrence of two neighbor nodes is a strong signal of the\ntarget node's characteristics, existing GNN models may fail to capture the\nsignal. In this work, we argue the importance of modeling the interactions\nbetween neighbor nodes in GNN. We propose a new graph convolution operator,\nwhich augments the weighted sum with pairwise interactions of the\nrepresentations of neighbor nodes. We term this framework as Bilinear Graph\nNeural Network (BGNN), which improves GNN representation ability with bilinear\ninteractions between neighbor nodes. In particular, we specify two BGNN models\nnamed BGCN and BGAT, based on the well-known GCN and GAT, respectively.\nEmpirical results on three public benchmarks of semi-supervised node\nclassification verify the effectiveness of BGNN -- BGCN (BGAT) outperforms GCN\n(GAT) by 1.6% (1.5%) in classification accuracy.Codes are available at:\nhttps://github.com/zhuhm1996/bgnn.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 06:43:38 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:20:11 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 01:50:32 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 03:51:46 GMT"}, {"version": "v5", "created": "Sat, 30 May 2020 02:41:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zhu", "Hongmin", ""], ["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Wang", "Xiang", ""], ["Li", "Yan", ""], ["Zheng", "Kai", ""], ["Zhang", "Yongdong", ""]]}, {"id": "2002.03580", "submitter": "Haoyu Zhao", "authors": "Wei Chen, Liwei Wang, Haoyu Zhao, Kai Zheng", "title": "Combinatorial Semi-Bandit in the Non-Stationary Environment", "comments": "Accepted to UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the non-stationary combinatorial semi-bandit\nproblem, both in the switching case and in the dynamic case. In the general\ncase where (a) the reward function is non-linear, (b) arms may be\nprobabilistically triggered, and (c) only approximate offline oracle exists\n\\cite{wang2017improving}, our algorithm achieves\n$\\tilde{\\mathcal{O}}(\\sqrt{\\mathcal{S} T})$ distribution-dependent regret in\nthe switching case, and $\\tilde{\\mathcal{O}}(\\mathcal{V}^{1/3}T^{2/3})$ in the\ndynamic case, where $\\mathcal S$ is the number of switchings and $\\mathcal V$\nis the sum of the total ``distribution changes''. The regret bounds in both\nscenarios are nearly optimal, but our algorithm needs to know the parameter\n$\\mathcal S$ or $\\mathcal V$ in advance.\n  We further show that by employing another technique, our algorithm no longer\nneeds to know the parameters $\\mathcal S$ or $\\mathcal V$ but the regret bounds\ncould become suboptimal.\n  In a special case where the reward function is linear and we have an exact\noracle, we design a parameter-free algorithm that achieves nearly optimal\nregret both in the switching case and in the dynamic case without knowing the\nparameters in advance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:10:56 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 06:27:35 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Wei", ""], ["Wang", "Liwei", ""], ["Zhao", "Haoyu", ""], ["Zheng", "Kai", ""]]}, {"id": "2002.03585", "submitter": "Che Wang", "authors": "Che Wang, Keith Ross", "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for\n  Reinforcement Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple and natural algorithm for reinforcement learning is Monte Carlo\nExploring States (MCES), where the Q-function is estimated by averaging the\nMonte Carlo returns, and the policy is improved by choosing actions that\nmaximize the current estimate of the Q-function. Exploration is performed by\n\"exploring starts\", that is, each episode begins with a randomly chosen state\nand action and then follows the current policy. Establishing convergence for\nthis algorithm has been an open problem for more than 20 years. We make headway\nwith this problem by proving convergence for Optimal Policy Feed-Forward MDPs,\nwhich are MDPs whose states are not revisited within any episode for an optimal\npolicy. Such MDPs include all deterministic environments (including Cliff\nWalking and other gridworld examples) and a large class of stochastic\nenvironments (including Blackjack). The convergence results presented here make\nprogress for this long-standing open problem in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:54:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Che", ""], ["Ross", "Keith", ""]]}, {"id": "2002.03595", "submitter": "Xian Wu", "authors": "Xian Wu, Chao Huang, Pablo Roblesgranda, Nitesh Chawla", "title": "Representation Learning on Variable Length and Incomplete\n  Wearable-Sensory Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of wearable sensors (e.g., smart wristband) is creating\nunprecedented opportunities to not only inform health and wellness states of\nindividuals, but also assess and infer personal attributes, including\ndemographic and personality attributes. However, the data captured from\nwearables, such as heart rate or number of steps, present two key challenges:\n1) the time series is often of variable-length and incomplete due to different\ndata collection periods (e.g., wearing behavior varies by person); and 2)\ninter-individual variability to external factors like stress and environment.\nThis paper addresses these challenges and brings us closer to the potential of\npersonalized insights about an individual, taking the leap from quantified self\nto qualified self. Specifically, HeartSpace proposed in this paper encodes time\nseries data with variable-length and missing values via the integration of a\ntime series encoding module and a pattern aggregation network. Additionally,\nHeartSpace implements a Siamese-triplet network to optimize representations by\njointly capturing intra- and inter-series correlations during the embedding\nlearning process. The empirical evaluation over two different real-world data\npresents significant performance gains overstate-of-the-art baselines in a\nvariety of applications, including personality prediction, demographics\ninference, and user identification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:20:44 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 05:28:08 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 21:14:48 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Wu", "Xian", ""], ["Huang", "Chao", ""], ["Roblesgranda", "Pablo", ""], ["Chawla", "Nitesh", ""]]}, {"id": "2002.03600", "submitter": "Luca Scrucca", "authors": "Luca Scrucca", "title": "A fast and efficient Modal EM algorithm for Gaussian mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modal approach to clustering, clusters are defined as the local maxima\nof the underlying probability density function, where the latter can be\nestimated either non-parametrically or using finite mixture models. Thus,\nclusters are closely related to certain regions around the density modes, and\nevery cluster corresponds to a bump of the density. The Modal EM algorithm is\nan iterative procedure that can identify the local maxima of any density\nfunction. In this contribution, we propose a fast and efficient Modal EM\nalgorithm to be used when the density function is estimated through a finite\nmixture of Gaussian distributions with parsimonious component-covariance\nstructures. After describing the procedure, we apply the proposed Modal EM\nalgorithm on both simulated and real data examples, showing its high\nflexibility in several contexts.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:34:16 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 14:31:30 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Scrucca", "Luca", ""]]}, {"id": "2002.03624", "submitter": "Guillaume Richard", "authors": "Guillaume Richard, Beno\\^it Grossin, Guillaume Germaine, Georges\n  H\\'ebrail, Anne de Moliner", "title": "Autoencoder-based time series clustering with energy applications", "comments": null, "journal-ref": "Conf\\'erence sur l'Apprentissage Automatique 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series clustering is a challenging task due to the specific nature of\nthe data. Classical approaches do not perform well and need to be adapted\neither through a new distance measure or a data transformation. In this paper\nwe investigate the combination of a convolutional autoencoder and a k-medoids\nalgorithm to perfom time series clustering. The convolutional autoencoder\nallows to extract meaningful features and reduce the dimension of the data,\nleading to an improvement of the subsequent clustering. Using simulation and\nenergy related data to validate the approach, experimental results show that\nthe clustering is robust to outliers thus leading to finer clusters than with\nstandard methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:04:29 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Richard", "Guillaume", ""], ["Grossin", "Beno\u00eet", ""], ["Germaine", "Guillaume", ""], ["H\u00e9brail", "Georges", ""], ["de Moliner", "Anne", ""]]}, {"id": "2002.03629", "submitter": "Yang Song", "authors": "Yang Song, Chenlin Meng, Renjie Liao, Stefano Ermon", "title": "Accelerating Feedforward Computation via Parallel Nonlinear Equation\n  Solving", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward computation, such as evaluating a neural network or sampling from\nan autoregressive model, is ubiquitous in machine learning. The sequential\nnature of feedforward computation, however, requires a strict order of\nexecution and cannot be easily accelerated with parallel computing. To enable\nparallelization, we frame the task of feedforward computation as solving a\nsystem of nonlinear equations. We then propose to find the solution using a\nJacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods\nof both. Crucially, Jacobi updates operate independently on each equation and\ncan be executed in parallel. Our method is guaranteed to give exactly the same\nvalues as the original feedforward computation with a reduced (or equal) number\nof parallelizable iterations, and hence reduced time given sufficient parallel\ncomputing power. Experimentally, we demonstrate the effectiveness of our\napproach in accelerating (i) backpropagation of RNNs, (ii) evaluation of\nDenseNets, and (iii) autoregressive sampling of MADE and PixelCNN++, with\nspeedup factors between 2.1 and 26 under various settings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:11:31 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 21:44:07 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Song", "Yang", ""], ["Meng", "Chenlin", ""], ["Liao", "Renjie", ""], ["Ermon", "Stefano", ""]]}, {"id": "2002.03647", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Alexander Trott, Caiming Xiong, Richard Socher,\n  Xavier Giro-i-Nieto, Jordi Torres", "title": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering\n  Skills", "comments": "17 pages, 11 figures. Code is publicly available at\n  https://github.com/victorcampos7/edl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring abilities in the absence of a task-oriented reward function is at\nthe frontier of reinforcement learning research. This problem has been studied\nthrough the lens of empowerment, which draws a connection between option\ndiscovery and information theory. Information-theoretic skill discovery methods\nhave garnered much interest from the community, but little research has been\nconducted in understanding their limitations. Through theoretical analysis and\nempirical evidence, we show that existing algorithms suffer from a common\nlimitation -- they discover options that provide a poor coverage of the state\nspace. In light of this, we propose 'Explore, Discover and Learn' (EDL), an\nalternative approach to information-theoretic skill discovery. Crucially, EDL\noptimizes the same information-theoretic objective derived from the empowerment\nliterature, but addresses the optimization problem using different machinery.\nWe perform an extensive evaluation of skill discovery methods on controlled\nenvironments and show that EDL offers significant advantages, such as\novercoming the coverage problem, reducing the dependence of learned skills on\nthe initial state, and allowing the user to define a prior over which behaviors\nshould be learned. Code is publicly available at\nhttps://github.com/victorcampos7/edl.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:49:53 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:44:12 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 12:08:59 GMT"}, {"version": "v4", "created": "Mon, 3 Aug 2020 11:06:21 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Trott", "Alexander", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Giro-i-Nieto", "Xavier", ""], ["Torres", "Jordi", ""]]}, {"id": "2002.03665", "submitter": "Haoyi Fan", "authors": "Haoyi Fan, Fengbin Zhang, Zuoyong Li", "title": "AnomalyDAE: Dual autoencoder for anomaly detection on attributed\n  networks", "comments": "Accepted by ICASSP2020. Copyright (c) 2020 IEEE. The source codes are\n  publicly available: https://github.com/haoyfan/AnomalyDAE. Only personal use\n  of these materials is permitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection on attributed networks aims at finding nodes whose patterns\ndeviate significantly from the majority of reference nodes, which is pervasive\nin many applications such as network intrusion detection and social spammer\ndetection. However, most existing methods neglect the complex cross-modality\ninteractions between network structure and node attribute. In this paper, we\npropose a deep joint representation learning framework for anomaly detection\nthrough a dual autoencoder (AnomalyDAE), which captures the complex\ninteractions between network structure and node attribute for high-quality\nembeddings. Specifically, AnomalyDAE consists of a structure autoencoder and an\nattribute autoencoder to learn both node embedding and attribute embedding\njointly in latent space. Moreover, attention mechanism is employed in structure\nencoder to learn the importance between a node and its neighbors for an\neffective capturing of structure pattern, which is important to anomaly\ndetection. Besides, by taking both the node embedding and attribute embedding\nas inputs of attribute decoder, the cross-modality interactions between network\nstructure and node attribute are learned during the reconstruction of node\nattribute. Finally, anomalies can be detected by measuring the reconstruction\nerrors of nodes from both the structure and attribute perspectives. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:32:23 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 10:26:44 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Fan", "Haoyi", ""], ["Zhang", "Fengbin", ""], ["Li", "Zuoyong", ""]]}, {"id": "2002.03668", "submitter": "Rajarshi Roy", "authors": "Rajarshi Roy, Dana Fisman and Daniel Neider", "title": "Learning Interpretable Models in the Property Specification Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning human-interpretable descriptions of a\ncomplex system from a finite set of positive and negative examples of its\nbehavior. In contrast to most of the recent work in this area, which focuses on\ndescriptions expressed in Linear Temporal Logic (LTL), we develop a learning\nalgorithm for formulas in the IEEE standard temporal logic PSL (Property\nSpecification Language). Our work is motivated by the fact that many natural\nproperties, such as an event happening at every n-th point in time, cannot be\nexpressed in LTL, whereas it is easy to express such properties in PSL.\nMoreover, formulas in PSL can be more succinct and easier to interpret (due to\nthe use of regular expressions in PSL formulas) than formulas in LTL.\n  Our learning algorithm builds on top of an existing algorithm for learning\nLTL formulas. Roughly speaking, our algorithm reduces the learning task to a\nconstraint satisfaction problem in propositional logic and then uses a SAT\nsolver to search for a solution in an incremental fashion. We have implemented\nour algorithm and performed a comparative study between the proposed method and\nthe existing LTL learning algorithm. Our results illustrate the effectiveness\nof the proposed approach to provide succinct human-interpretable descriptions\nfrom examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:42:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Roy", "Rajarshi", ""], ["Fisman", "Dana", ""], ["Neider", "Daniel", ""]]}, {"id": "2002.03673", "submitter": "Tongliang Liu", "authors": "Yu Yao and Tongliang Liu and Bo Han and Mingming Gong and Gang Niu and\n  Masashi Sugiyama and Dacheng Tao", "title": "Towards Mixture Proportion Estimation without Irreducibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textit{Mixture proportion estimation} (MPE) is a fundamental problem of\npractical significance, where we are given data from only a \\textit{mixture}\nand one of its two \\textit{components} to identify the proportion of each\ncomponent. All existing MPE methods that are distribution-independent\nexplicitly or implicitly rely on the \\textit{irreducible} assumption---the\nunobserved component is not a mixture containing the observable component. If\nthis is not satisfied, those methods will lead to a critical estimation bias.\nIn this paper, we propose \\textit{Regrouping-MPE} that works without\nirreducible assumption: it builds a new irreducible MPE problem and solves the\nnew problem. It is worthwhile to change the problem: we prove that if the\nassumption holds, our method will not affect anything; if the assumption does\nnot hold, the bias from problem changing is less than the bias from violation\nof the irreducible assumption in the original problem. Experiments show that\nour method outperforms all state-of-the-art MPE methods on various real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:57:30 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yao", "Yu", ""], ["Liu", "Tongliang", ""], ["Han", "Bo", ""], ["Gong", "Mingming", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""], ["Tao", "Dacheng", ""]]}, {"id": "2002.03677", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on, Ana I. Rastrojo", "title": "Minimum adjusted Rand index for two clusterings of a given size", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adjusted Rand index (ARI) is commonly used in cluster analysis to measure\nthe degree of agreement between two data partitions. Since its introduction,\nexploring the situations of extreme agreement and disagreement under different\ncircumstances has been a subject of interest, in order to achieve a better\nunderstanding of this index. Here, an explicit formula for the lowest possible\nvalue of the ARI for two clusterings of given sizes is shown, and moreover a\nspecific pair of clusterings achieving such a bound is provided.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:16:49 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 08:31:06 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 08:35:33 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""], ["Rastrojo", "Ana I.", ""]]}, {"id": "2002.03689", "submitter": "Junhyung Park", "authors": "Junhyung Park and Krikamol Muandet", "title": "A Measure-Theoretic Approach to Kernel Conditional Mean Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an operator-free, measure-theoretic approach to the conditional\nmean embedding (CME) as a random variable taking values in a reproducing kernel\nHilbert space. While the kernel mean embedding of unconditional distributions\nhas been defined rigorously, the existing operator-based approach of the\nconditional version depends on stringent assumptions that hinder its analysis.\nWe overcome this limitation via a measure-theoretic treatment of CMEs. We\nderive a natural regression interpretation to obtain empirical estimates, and\nprovide a thorough theoretical analysis thereof, including universal\nconsistency. As natural by-products, we obtain the conditional analogues of the\nmaximum mean discrepancy and Hilbert-Schmidt independence criterion, and\ndemonstrate their behaviour via simulations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:44:12 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 10:47:43 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 08:31:36 GMT"}, {"version": "v4", "created": "Sat, 18 Apr 2020 15:51:42 GMT"}, {"version": "v5", "created": "Wed, 22 Apr 2020 09:03:33 GMT"}, {"version": "v6", "created": "Fri, 24 Apr 2020 12:14:10 GMT"}, {"version": "v7", "created": "Thu, 22 Oct 2020 11:43:47 GMT"}, {"version": "v8", "created": "Fri, 8 Jan 2021 14:55:23 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Park", "Junhyung", ""], ["Muandet", "Krikamol", ""]]}, {"id": "2002.03700", "submitter": "Antonia Godoy-Lorite Dr.", "authors": "Antonia Godoy-Lorite, Roger Guimera and Marta Sales-Pardo", "title": "Network-based models for social recommender systems", "comments": null, "journal-ref": "\"Business and Consumer Analytics: New Ideas\", edited by Moscato\n  P., de Vries N, (2019)", "doi": "10.1007/978-3-030-06222-4_11", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the overwhelming online products available in recent years, there is an\nincreasing need to filter and deliver relevant personalized advice for users.\nRecommender systems solve this problem by modeling and predicting individual\npreferences for a great variety of items such as movies, books or research\narticles. In this chapter, we explore rigorous network-based models that\noutperform leading approaches for recommendation. The network models we\nconsider are based on the explicit assumption that there are groups of\nindividuals and of items, and that the preferences of an individual for an item\nare determined only by their group memberships. The accurate prediction of\nindividual user preferences over items can be accomplished by different\nmethodologies, such as Monte Carlo sampling or Expectation-Maximization\nmethods, the latter resulting in a scalable algorithm which is suitable for\nlarge datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:06:22 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Godoy-Lorite", "Antonia", ""], ["Guimera", "Roger", ""], ["Sales-Pardo", "Marta", ""]]}, {"id": "2002.03704", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Lewis Smith, Yarin Gal", "title": "Liberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight\n  Posterior Approximations", "comments": "Advances In Neural Information Processing Systems. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We challenge the longstanding assumption that the mean-field approximation\nfor variational inference in Bayesian neural networks is severely restrictive,\nand show this is not the case in deep networks. We prove several results\nindicating that deep mean-field variational weight posteriors can induce\nsimilar distributions in function-space to those induced by shallower networks\nwith complex weight posteriors. We validate our theoretical contributions\nempirically, both through examination of the weight posterior using Hamiltonian\nMonte Carlo in small models and by comparing diagonal- to structured-covariance\nin large settings. Since complex variational posteriors are often expensive and\ncumbersome to implement, our results suggest that using mean-field variational\ninference in a deeper model is both a practical and theoretically justified\nalternative to structured approximations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:11:45 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 10:39:50 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 11:55:29 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 09:19:13 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Smith", "Lewis", ""], ["Gal", "Yarin", ""]]}, {"id": "2002.03712", "submitter": "Conor Durkan", "authors": "Conor Durkan, Iain Murray, George Papamakarios", "title": "On Contrastive Learning for Likelihood-free Inference", "comments": "Appeared at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free methods perform parameter inference in stochastic simulator\nmodels where evaluating the likelihood is intractable but sampling synthetic\ndata is possible. One class of methods for this likelihood-free problem uses a\nclassifier to distinguish between pairs of parameter-observation samples\ngenerated using the simulator and pairs sampled from some reference\ndistribution, which implicitly learns a density ratio proportional to the\nlikelihood. Another popular class of methods fits a conditional distribution to\nthe parameter posterior directly, and a particular recent variant allows for\nthe use of flexible neural density estimators for this task. In this work, we\nshow that both of these approaches can be unified under a general contrastive\nlearning scheme, and clarify how they should be run and compared.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:14:01 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 12:44:53 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Durkan", "Conor", ""], ["Murray", "Iain", ""], ["Papamakarios", "George", ""]]}, {"id": "2002.03722", "submitter": "Pierre Ablin", "authors": "Pierre Ablin, Gabriel Peyr\\'e and Thomas Moreau", "title": "Super-efficiency of automatic differentiation for functions defined as a\n  minimum", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In min-min optimization or max-min optimization, one has to compute the\ngradient of a function defined as a minimum. In most cases, the minimum has no\nclosed-form, and an approximation is obtained via an iterative algorithm. There\nare two usual ways of estimating the gradient of the function: using either an\nanalytic formula obtained by assuming exactness of the approximation, or\nautomatic differentiation through the algorithm. In this paper, we study the\nasymptotic error made by these estimators as a function of the optimization\nerror. We find that the error of the automatic estimator is close to the square\nof the error of the analytic estimator, reflecting a super-efficiency\nphenomenon. The convergence of the automatic estimator greatly depends on the\nconvergence of the Jacobian of the algorithm. We analyze it for gradient\ndescent and stochastic gradient descent and derive convergence rates for the\nestimators in these cases. Our analysis is backed by numerical experiments on\ntoy problems and on Wasserstein barycenter computation. Finally, we discuss the\ncomputational complexity of these estimators and give practical guidelines to\nchose between them.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:23:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ablin", "Pierre", ""], ["Peyr\u00e9", "Gabriel", ""], ["Moreau", "Thomas", ""]]}, {"id": "2002.03731", "submitter": "Ievgen Redko", "authors": "Ievgen Redko, Titouan Vayer, R\\'emi Flamary, Nicolas Courty", "title": "CO-Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) is a powerful geometric and probabilistic tool for\nfinding correspondences and measuring similarity between two distributions.\nYet, its original formulation relies on the existence of a cost function\nbetween the samples of the two distributions, which makes it impractical when\nthey are supported on different spaces. To circumvent this limitation, we\npropose a novel OT problem, named COOT for CO-Optimal Transport, that\nsimultaneously optimizes two transport maps between both samples and features,\ncontrary to other approaches that either discard the individual features by\nfocusing on pairwise distances between samples or need to model explicitly the\nrelations between them. We provide a thorough theoretical analysis of our\nproblem, establish its rich connections with other OT-based distances and\ndemonstrate its versatility with two machine learning applications in\nheterogeneous domain adaptation and co-clustering/data summarization, where\nCOOT leads to performance improvements over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:33:15 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 17:40:35 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 14:31:21 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Redko", "Ievgen", ""], ["Vayer", "Titouan", ""], ["Flamary", "R\u00e9mi", ""], ["Courty", "Nicolas", ""]]}, {"id": "2002.03735", "submitter": "G C Nandi", "authors": "Sayantan Chatterjee, Faheem H. Zunjani, Souvik Sen and Gora C. Nandi", "title": "Real-Time Object Detection and Recognition on Low-Compute Humanoid\n  Robots using Deep Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We envision that in the near future, humanoid robots would share home space\nand assist us in our daily and routine activities through object manipulations.\nOne of the fundamental technologies that need to be developed for robots is to\nenable them to detect objects and recognize them for effective manipulations\nand take real-time decisions involving those objects. In this paper, we\ndescribe a novel architecture that enables multiple low-compute NAO robots to\nperform real-time detection, recognition and localization of objects in its\ncamera view and take programmable actions based on the detected objects. The\nproposed algorithm for object detection and localization is an empirical\nmodification of YOLOv3, based on indoor experiments in multiple scenarios, with\na smaller weight size and lesser computational requirements. Quantization of\nthe weights and re-adjusting filter sizes and layer arrangements for\nconvolutions improved the inference time for low-resolution images from the\nrobot s camera feed. YOLOv3 was chosen after a comparative study of bounding\nbox algorithms was performed with an objective to choose one that strikes the\nperfect balance among information retention, low inference time and high\naccuracy for real-time object detection and localization. The architecture also\ncomprises of an effective end-to-end pipeline to feed the real-time frames from\nthe camera feed to the neural net and use its results for guiding the robot\nwith customizable actions corresponding to the detected class labels.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:24:58 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chatterjee", "Sayantan", ""], ["Zunjani", "Faheem H.", ""], ["Sen", "Souvik", ""], ["Nandi", "Gora C.", ""]]}, {"id": "2002.03736", "submitter": "Yaozu Ye", "authors": "Yaozu Ye, Kailun Yang, Kaite Xiang, Juan Wang and Kaiwei Wang", "title": "Universal Semantic Segmentation for Fisheye Urban Driving Images", "comments": "SMC2020 recieved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is a critical method in the field of autonomous\ndriving. When performing semantic image segmentation, a wider field of view\n(FoV) helps to obtain more information about the surrounding environment,\nmaking automatic driving safer and more reliable, which could be offered by\nfisheye cameras. However, large public fisheye datasets are not available, and\nthe fisheye images captured by the fisheye camera with large FoV comes with\nlarge distortion, so commonly-used semantic segmentation model cannot be\ndirectly utilized. In this paper, a seven degrees of freedom (DoF) augmentation\nmethod is proposed to transform rectilinear image to fisheye image in a more\ncomprehensive way. In the training process, rectilinear images are transformed\ninto fisheye images in seven DoF, which simulates the fisheye images taken by\ncameras of different positions, orientations and focal lengths. The result\nshows that training with the seven-DoF augmentation can improve the model's\naccuracy and robustness against different distorted fisheye data. This\nseven-DoF augmentation provides a universal semantic segmentation solution for\nfisheye cameras in different autonomous driving applications. Also, we provide\nspecific parameter settings of the augmentation for autonomous driving. At\nlast, we tested our universal semantic segmentation model on real fisheye\nimages and obtained satisfactory results. The code and configurations are\nreleased at https://github.com/Yaozhuwa/FisheyeSeg.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:19:00 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 13:02:09 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ye", "Yaozu", ""], ["Yang", "Kailun", ""], ["Xiang", "Kaite", ""], ["Wang", "Juan", ""], ["Wang", "Kaiwei", ""]]}, {"id": "2002.03749", "submitter": "Hartmut Feld", "authors": "Hartmut Feld, Bruno Mirbach, Jigyasa Katrolia, Mohamed Selim, Oliver\n  Wasenm\\\"uller, Didier Stricker", "title": "DFKI Cabin Simulator: A Test Platform for Visual In-Cabin Monitoring\n  Functions", "comments": "corrected typos and bad reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a test platform for visual in-cabin scene analysis and occupant\nmonitoring functions. The test platform is based on a driving simulator\ndeveloped at the DFKI, consisting of a realistic in-cabin mock-up and a\nwide-angle projection system for a realistic driving experience. The platform\nhas been equipped with a wide-angle 2D/3D camera system monitoring the entire\ninterior of the vehicle mock-up of the simulator. It is also supplemented with\na ground truth reference sensor system that allows to track and record the\noccupant's body movements synchronously with the 2D and 3D video streams of the\ncamera. Thus, the resulting test platform will serve as a basis to validate\nnumerous in-cabin monitoring functions, which are important for the realization\nof novel human-vehicle interfaces, advanced driver assistant systems, and\nautomated driving. Among the considered functions are occupant presence\ndetection, size and 3D-pose estimation and driver intention recognition. In\naddition, our platform will be the basis for the creation of large-scale\nin-cabin benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 07:15:50 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:27:42 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Feld", "Hartmut", ""], ["Mirbach", "Bruno", ""], ["Katrolia", "Jigyasa", ""], ["Selim", "Mohamed", ""], ["Wasenm\u00fcller", "Oliver", ""], ["Stricker", "Didier", ""]]}, {"id": "2002.03754", "submitter": "Andrey Voynov", "authors": "Andrey Voynov, Artem Babenko", "title": "Unsupervised Discovery of Interpretable Directions in the GAN Latent\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latent spaces of GAN models often have semantically meaningful\ndirections. Moving in these directions corresponds to human-interpretable image\ntransformations, such as zooming or recoloring, enabling a more controllable\ngeneration process. However, the discovery of such directions is currently\nperformed in a supervised manner, requiring human labels, pretrained models, or\nsome form of self-supervision. These requirements severely restrict a range of\ndirections existing approaches can discover. In this paper, we introduce an\nunsupervised method to identify interpretable directions in the latent space of\na pretrained GAN model. By a simple model-agnostic procedure, we find\ndirections corresponding to sensible semantic manipulations without any form of\n(self-)supervision. Furthermore, we reveal several non-trivial findings, which\nwould be difficult to obtain by existing methods, e.g., a direction\ncorresponding to background removal. As an immediate practical benefit of our\nwork, we show how to exploit this finding to achieve competitive performance\nfor weakly-supervised saliency detection.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:57:14 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:08:49 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 12:12:14 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Voynov", "Andrey", ""], ["Babenko", "Artem", ""]]}, {"id": "2002.03755", "submitter": "Haitham Bou Ammar PhD", "authors": "Rasul Tutunov and Minne Li and Alexander I. Cowen-Rivers and Jun Wang\n  and Haitham Bou-Ammar", "title": "Compositional ADAM: An Adaptive Compositional Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present C-ADAM, the first adaptive solver for compositional\nproblems involving a non-linear functional nesting of expected values. We proof\nthat C-ADAM converges to a stationary point in $\\mathcal{O}(\\delta^{-2.25})$\nwith $\\delta$ being a precision parameter. Moreover, we demonstrate the\nimportance of our results by bridging, for the first time, model-agnostic\nmeta-learning (MAML) and compositional optimisation showing fastest known rates\nfor deep network adaptation to-date. Finally, we validate our findings in a set\nof experiments from portfolio optimisation and meta-learning. Our results\nmanifest significant sample complexity reductions compared to both standard and\ncompositional solvers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:00:45 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 15:10:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tutunov", "Rasul", ""], ["Li", "Minne", ""], ["Cowen-Rivers", "Alexander I.", ""], ["Wang", "Jun", ""], ["Bou-Ammar", "Haitham", ""]]}, {"id": "2002.03757", "submitter": "Shao-Bo Lin", "authors": "Shao-Bo Lin", "title": "Distributed Learning with Dependent Samples", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on learning rate analysis of distributed kernel ridge\nregression for strong mixing sequences. Using a recently developed integral\noperator approach and a classical covariance inequality for Banach-valued\nstrong mixing sequences, we succeed in deriving optimal learning rate for\ndistributed kernel ridge regression. As a byproduct, we also deduce a\nsufficient condition for the mixing property to guarantee the optimal learning\nrates for kernel ridge regression. Our results extend the applicable range of\ndistributed learning from i.i.d. samples to non-i.i.d. sequences.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:03:45 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lin", "Shao-Bo", ""]]}, {"id": "2002.03763", "submitter": "Shenghua He", "authors": "Shenghua He and Weimin Zhou and Hua Li and Mark A. Anastasio", "title": "Learning Numerical Observers using Unsupervised Domain Adaptation", "comments": "SPIE Medical Imaging 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical imaging systems are commonly assessed by use of objective image\nquality measures. Supervised deep learning methods have been investigated to\nimplement numerical observers for task-based image quality assessment. However,\nlabeling large amounts of experimental data to train deep neural networks is\ntedious, expensive, and prone to subjective errors. Computer-simulated image\ndata can potentially be employed to circumvent these issues; however, it is\noften difficult to computationally model complicated anatomical structures,\nnoise sources, and the response of real world imaging systems. Hence, simulated\nimage data will generally possess physical and statistical differences from the\nexperimental image data they seek to emulate. Within the context of machine\nlearning, these differences between the sets of two images is referred to as\ndomain shift. In this study, we propose and investigate the use of an\nadversarial domain adaptation method to mitigate the deleterious effects of\ndomain shift between simulated and experimental image data for deep\nlearning-based numerical observers (DL-NOs) that are trained on simulated\nimages but applied to experimental ones. In the proposed method, a DL-NO will\ninitially be trained on computer-simulated image data and subsequently adapted\nfor use with experimental image data, without the need for any labeled\nexperimental images. As a proof of concept, a binary signal detection task is\nconsidered. The success of this strategy as a function of the degree of domain\nshift present between the simulated and experimental image data is\ninvestigated.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:58:28 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 16:56:25 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["He", "Shenghua", ""], ["Zhou", "Weimin", ""], ["Li", "Hua", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2002.03774", "submitter": "Bugra Turan", "authors": "Bugra Turan and Sinem Coleri", "title": "Machine Learning Based Channel Modeling for Vehicular Visible Light\n  Communication", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Wireless Communication (OWC) propagation channel characterization\nplays a key role on the design and performance analysis of Vehicular Visible\nLight Communication (VVLC) systems. Current OWC channel models based on\ndeterministic and stochastic methods, fail to address mobility induced ambient\nlight, optical turbulence and road reflection effects on channel\ncharacterization. Therefore, alternative machine learning (ML) based schemes,\nconsidering ambient light, optical turbulence, road reflection effects in\naddition to intervehicular distance and geometry, are proposed to obtain\naccurate VVLC channel loss and channel frequency response (CFR). This work\ndemonstrates synthesis of ML based VVLC channel model frameworks through multi\nlayer perceptron feed-forward neural network (MLP), radial basis function\nneural network (RBF-NN) and Random Forest ensemble learning algorithms.\nPredictor and response variables, collected through practical road\nmeasurements, are employed to train and validate proposed models for various\nconditions. Additionally, the importance of different predictor variables on\nchannel loss and CFR is assessed, normalized importance of features for\nmeasured VVLC channel is introduced. We show that RBF-NN, Random Forest and MLP\nbased models yield more accurate channel loss estimations with 3.53 dB, 3.81\ndB, 3.95 dB root mean square error (RMSE), respectively, when compared to\nfitting curve based VVLC channel model with 7 dB RMSE. Moreover, RBF-NN and MLP\nmodels are demonstrated to predict VVLC CFR with respect to distance, ambient\nlight and receiver inclination angle predictor variables with 3.78 dB and 3.60\ndB RMSE respectively.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:38:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Turan", "Bugra", ""], ["Coleri", "Sinem", ""]]}, {"id": "2002.03781", "submitter": "Robin Yancey", "authors": "Robin Elizabeth Yancey", "title": "Multi-stream Faster RCNN for Mitosis Counting in Breast Cancer Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitotic count is a commonly used method to assess the level of progression of\nbreast cancer, which is now the fourth most prevalent cancer. Unfortunately,\ncounting mitosis is a tedious and subjective task with poor reproducibility,\nespecially for non-experts. Luckily, since the machine can read and compare\nmore data with greater efficiency this could be the next modern technique to\ncount mitosis. Furthermore, technological advancements in medicine have led to\nthe increase in image data available for use in training. In this work, we\npropose a network constructed using a similar approach to one that has been\nused for image fraud detection with the segmented image map as the second\nstream input to Faster RCNN. This region-based detection model combines a fully\nconvolutional Region Proposal Network to generate proposals and a\nclassification network to classify each of these proposals as containing\nmitosis or not. Features from both streams are fused in the bilinear pooling\nlayer to maintain the spatial concurrence of each. After training this model on\nthe ICPR 2014 MITOSIS contest dataset, we received an F-measure score of 0.507,\nhigher than both the winners score and scores from recent tests on the same\ndata. Our method is clinically applicable, taking only around five min per ten\nfull High Power Field slides when tested on a Quadro P6000 cloud GPU.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:20:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yancey", "Robin Elizabeth", ""]]}, {"id": "2002.03785", "submitter": "Guangzhi Sun", "authors": "Guangzhi Sun, Yu Zhang, Ron J. Weiss, Yuan Cao, Heiga Zen, Yonghui Wu", "title": "Fully-hierarchical fine-grained prosody modeling for interpretable\n  speech synthesis", "comments": "to appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hierarchical, fine-grained and interpretable latent\nvariable model for prosody based on the Tacotron 2 text-to-speech model. It\nachieves multi-resolution modeling of prosody by conditioning finer level\nrepresentations on coarser level ones. Additionally, it imposes hierarchical\nconditioning across all latent dimensions using a conditional variational\nauto-encoder (VAE) with an auto-regressive structure. Evaluation of\nreconstruction performance illustrates that the new structure does not degrade\nthe model while allowing better interpretability. Interpretations of prosody\nattributes are provided together with the comparison between word-level and\nphone-level prosody representations. Moreover, both qualitative and\nquantitative evaluations are used to demonstrate the improvement in the\ndisentanglement of the latent dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:52:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sun", "Guangzhi", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Cao", "Yuan", ""], ["Zen", "Heiga", ""], ["Wu", "Yonghui", ""]]}, {"id": "2002.03788", "submitter": "Guangzhi Sun", "authors": "Guangzhi Sun, Yu Zhang, Ron J. Weiss, Yuan Cao, Heiga Zen, Andrew\n  Rosenberg, Bhuvana Ramabhadran, Yonghui Wu", "title": "Generating diverse and natural text-to-speech samples using a quantized\n  fine-grained VAE and auto-regressive prosody prior", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural text-to-speech (TTS) models with fine-grained latent features\nenable precise control of the prosody of synthesized speech. Such models\ntypically incorporate a fine-grained variational autoencoder (VAE) structure,\nextracting latent features at each input token (e.g., phonemes). However,\ngenerating samples with the standard VAE prior often results in unnatural and\ndiscontinuous speech, with dramatic prosodic variation between tokens. This\npaper proposes a sequential prior in a discrete latent space which can generate\nmore naturally sounding samples. This is accomplished by discretizing the\nlatent features using vector quantization (VQ), and separately training an\nautoregressive (AR) prior model over the result. We evaluate the approach using\nlistening tests, objective metrics of automatic speech recognition (ASR)\nperformance, and measurements of prosody attributes. Experimental results show\nthat the proposed model significantly improves the naturalness in random sample\ngeneration. Furthermore, initial experiments demonstrate that randomly sampling\nfrom the proposed model can be used as data augmentation to improve the ASR\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:35:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sun", "Guangzhi", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Cao", "Yuan", ""], ["Zen", "Heiga", ""], ["Rosenberg", "Andrew", ""], ["Ramabhadran", "Bhuvana", ""], ["Wu", "Yonghui", ""]]}, {"id": "2002.03793", "submitter": "Yingdong Hu", "authors": "Yingdong Hu, Liang Zhang, Wei Shan, Xiaoxiao Qin, Jing Qi, Zhenzhou\n  Wu, Yang Yuan", "title": "Adversarial Data Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, many organizations face the dilemma of data sharing.\nRegular data sharing is often necessary for human-centered discussion and\ncommunication, especially in medical scenarios. However, unprotected data\nsharing may also lead to data leakage. Inspired by adversarial attack, we\npropose a method for data encryption, so that for human beings the encrypted\ndata look identical to the original version, but for machine learning methods\nthey are misleading. To show the effectiveness of our method, we collaborate\nwith the Beijing Tiantan Hospital, which has a world leading neurological\ncenter. We invite $3$ doctors to manually inspect our encryption method based\non real world medical images. The results show that the encrypted images can be\nused for diagnosis by the doctors, but not by machine learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:32:57 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 05:52:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Hu", "Yingdong", ""], ["Zhang", "Liang", ""], ["Shan", "Wei", ""], ["Qin", "Xiaoxiao", ""], ["Qi", "Jing", ""], ["Wu", "Zhenzhou", ""], ["Yuan", "Yang", ""]]}, {"id": "2002.03801", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Ville Hautam\\\"aki, Tomi Kinnunen, Junichi Yamagishi", "title": "An initial investigation on optimizing tandem speaker verification and\n  countermeasure systems using reinforcement learning", "comments": "Odyssey 2020 The Speaker and Language Recognition Workshop. Code\n  available at https://github.com/Miffyli/asv-cm-reinforce", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spoofing countermeasure (CM) systems in automatic speaker verification\n(ASV) are not typically used in isolation of each other. These systems can be\ncombined, for example, into a cascaded system where CM produces first a\ndecision whether the input is synthetic or bona fide speech. In case the CM\ndecides it is a bona fide sample, then the ASV system will consider it for\nspeaker verification. End users of the system are not interested in the\nperformance of the individual sub-modules, but instead are interested in the\nperformance of the combined system. Such combination can be evaluated with\ntandem detection cost function (t-DCF) measure, yet the individual components\nare trained separately from each other using their own performance metrics. In\nthis work we study training the ASV and CM components together for a better\nt-DCF measure by using reinforcement learning. We demonstrate that such\ntraining procedure indeed is able to improve the performance of the combined\nsystem, and does so with more reliable results than with the standard\nsupervised learning techniques we compare against.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:13:49 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 11:09:14 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Hautam\u00e4ki", "Ville", ""], ["Kinnunen", "Tomi", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "2002.03802", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer and Mitchell McLaren", "title": "A Speaker Verification Backend for Improved Calibration Performance\n  across Varying Conditions", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.11622", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent work, we presented a discriminative backend for speaker\nverification that achieved good out-of-the-box calibration performance on most\ntested conditions containing varying levels of mismatch to the training\nconditions. This backend mimics the standard PLDA-based backend process used in\nmost current speaker verification systems, including the calibration stage. All\nparameters of the backend are jointly trained to optimize the binary\ncross-entropy for the speaker verification task. Calibration robustness is\nachieved by making the parameters of the calibration stage a function of\nvectors representing the conditions of the signal, which are extracted using a\nmodel trained to predict condition labels. In this work, we propose a\nsimplified version of this backend where the vectors used to compute the\ncalibration parameters are estimated within the backend, without the need for a\ncondition prediction model. We show that this simplified method provides\nsimilar performance to the previously proposed method while being simpler to\nimplement, and having less requirements on the training data. Further, we\nprovide an analysis of different aspects of the method including the effect of\ninitialization, the nature of the vectors used to compute the calibration\nparameters, and the effect that the random seed and the number of training\nepochs has on performance. We also compare the proposed method with the\ntrial-based calibration (TBC) method that, to our knowledge, was the\nstate-of-the-art for achieving good calibration across varying conditions. We\nshow that the proposed method outperforms TBC while also being several orders\nof magnitude faster to run, comparable to the standard PLDA baseline.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 15:37:46 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ferrer", "Luciana", ""], ["McLaren", "Mitchell", ""]]}, {"id": "2002.03807", "submitter": "Johanna \\\"Arje", "authors": "Johanna \\\"Arje, Claus Melvad, Mads Rosenh{\\o}j Jeppesen, Sigurd\n  Agerskov Madsen, Jenni Raitoharju, Maria Strandg{\\aa}rd Rasmussen, Alexandros\n  Iosifidis, Ville Tirronen, Kristian Meissner, Moncef Gabbouj, Toke Thomas\n  H{\\o}ye", "title": "Automatic image-based identification and biomass estimation of\n  invertebrates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how biological communities respond to environmental changes is\na key challenge in ecology and ecosystem management. The apparent decline of\ninsect populations necessitates more biomonitoring but the time-consuming\nsorting and identification of taxa pose strong limitations on how many insect\nsamples can be processed. In turn, this affects the scale of efforts to map\ninvertebrate diversity altogether. Given recent advances in computer vision, we\npropose to replace the standard manual approach of human expert-based sorting\nand identification with an automatic image-based technology. We describe a\nrobot-enabled image-based identification machine, which can automate the\nprocess of invertebrate identification, biomass estimation and sample sorting.\nWe use the imaging device to generate a comprehensive image database of\nterrestrial arthropod species. We use this database to test the classification\naccuracy i.e. how well the species identity of a specimen can be predicted from\nimages taken by the machine. We also test sensitivity of the classification\naccuracy to the camera settings (aperture and exposure time) in order to move\nforward with the best possible image quality. We use state-of-the-art Resnet-50\nand InceptionV3 CNNs for the classification task. The results for the initial\ndataset are very promising ($\\overline{ACC}=0.980$). The system is general and\ncan easily be used for other groups of invertebrates as well. As such, our\nresults pave the way for generating more data on spatial and temporal variation\nin invertebrate abundance, diversity and biomass.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:38:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["\u00c4rje", "Johanna", ""], ["Melvad", "Claus", ""], ["Jeppesen", "Mads Rosenh\u00f8j", ""], ["Madsen", "Sigurd Agerskov", ""], ["Raitoharju", "Jenni", ""], ["Rasmussen", "Maria Strandg\u00e5rd", ""], ["Iosifidis", "Alexandros", ""], ["Tirronen", "Ville", ""], ["Meissner", "Kristian", ""], ["Gabbouj", "Moncef", ""], ["H\u00f8ye", "Toke Thomas", ""]]}, {"id": "2002.03808", "submitter": "June-Woo Kim", "authors": "June-Woo Kim, Ho-Young Jung, Minho Lee", "title": "Vocoder-free End-to-End Voice Conversion with Transformer Network", "comments": "Work in progress", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9207653", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mel-frequency filter bank (MFB) based approaches have the advantage of\nlearning speech compared to raw spectrum since MFB has less feature size.\nHowever, speech generator with MFB approaches require additional vocoder that\nneeds a huge amount of computation expense for training process. The additional\npre/post processing such as MFB and vocoder is not essential to convert real\nhuman speech to others. It is possible to only use the raw spectrum along with\nthe phase to generate different style of voices with clear pronunciation. In\nthis regard, we propose a fast and effective approach to convert realistic\nvoices using raw spectrum in a parallel manner. Our transformer-based model\narchitecture which does not have any CNN or RNN layers has shown the advantage\nof learning fast and solved the limitation of sequential computation of\nconventional RNN. In this paper, we introduce a vocoder-free end-to-end voice\nconversion method using transformer network. The presented conversion model can\nalso be used in speaker adaptation for speech recognition. Our approach can\nconvert the source voice to a target voice without using MFB and vocoder. We\ncan get an adapted MFB for speech recognition by multiplying the converted\nmagnitude with phase. We perform our voice conversion experiments on TIDIGITS\ndataset using the metrics such as naturalness, similarity, and clarity with\nmean opinion score, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 06:19:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kim", "June-Woo", ""], ["Jung", "Ho-Young", ""], ["Lee", "Minho", ""]]}, {"id": "2002.03820", "submitter": "Andreas Kofler", "authors": "Andreas Kofler, Marc Dewey, Tobias Schaeffter, Christoph Kolbitsch and\n  Markus Haltmeier", "title": "Unsupervised Adaptive Neural Network Regularization for Accelerated\n  Radial Cine MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an iterative reconstruction scheme (ALONE - Adaptive\nLearning Of NEtworks) for 2D radial cine MRI based on ground truth-free\nunsupervised learning of shallow convolutional neural networks. The network is\ntrained to approximate patches of the current estimate of the solution during\nthe reconstruction. By imposing a shallow network topology and constraining the\n$L_2$-norm of the learned filters, the network's representation power is\nlimited in order not to be able to recover noise. Therefore, the network can be\ninterpreted to perform a low dimensional approximation of the patches for\nstabilizing the inversion process. We compare the proposed reconstruction\nscheme to two ground truth-free reconstruction methods, namely a well known\nTotal Variation (TV) minimization and an unsupervised adaptive Dictionary\nLearning (DIC) method. The proposed method outperforms both methods with\nrespect to all reported quantitative measures. Further, in contrast to DIC,\nwhere the sparse approximation of the patches involves the solution of a\ncomplex optimization problem, ALONE only requires a forward pass of all patches\nthrough the shallow network and therefore significantly accelerates the\nreconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:47:20 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kofler", "Andreas", ""], ["Dewey", "Marc", ""], ["Schaeffter", "Tobias", ""], ["Kolbitsch", "Christoph", ""], ["Haltmeier", "Markus", ""]]}, {"id": "2002.03827", "submitter": "Yunhan Huang", "authors": "Yunhan Huang and Quanyan Zhu", "title": "Manipulating Reinforcement Learning: Poisoning Attacks on Cost Signals", "comments": "This chapter is written for the forthcoming book \"Game Theory and\n  Machine Learning for Cyber Security\" (Wiley-IEEE Press), edited by Charles\n  Kamhoua et. al. arXiv admin note: text overlap with arXiv:1906.10571", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter studies emerging cyber-attacks on reinforcement learning (RL)\nand introduces a quantitative approach to analyze the vulnerabilities of RL.\nFocusing on adversarial manipulation on the cost signals, we analyze the\nperformance degradation of TD($\\lambda$) and $Q$-learning algorithms under the\nmanipulation. For TD($\\lambda$), the approximation learned from the manipulated\ncosts has an approximation error bound proportional to the magnitude of the\nattack. The effect of the adversarial attacks on the bound does not depend on\nthe choice of $\\lambda$. In $Q$-learning, we show that $Q$-learning algorithms\nconverge under stealthy attacks and bounded falsifications on cost signals. We\ncharacterize the relation between the falsified cost and the $Q$-factors as\nwell as the policy learned by the learning agent which provides fundamental\nlimits for feasible offensive and defensive moves. We propose a robust region\nin terms of the cost within which the adversary can never achieve the targeted\npolicy. We provide conditions on the falsified cost which can mislead the agent\nto learn an adversary's favored policy. A case study of TD($\\lambda$) learning\nis provided to corroborate the results.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:42:02 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 22:55:26 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Huang", "Yunhan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2002.03830", "submitter": "David W. Romero", "authors": "David W. Romero, Erik J. Bekkers, Jakub M. Tomczak, Mark Hoogendoorn", "title": "Attentive Group Equivariant Convolutional Networks", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although group convolutional networks are able to learn powerful\nrepresentations based on symmetry patterns, they lack explicit means to learn\nmeaningful relationships among them (e.g., relative positions and poses). In\nthis paper, we present attentive group equivariant convolutions, a\ngeneralization of the group convolution, in which attention is applied during\nthe course of convolution to accentuate meaningful symmetry combinations and\nsuppress non-plausible, misleading ones. We indicate that prior work on visual\nattention can be described as special cases of our proposed framework and show\nempirically that our attentive group equivariant convolutional networks\nconsistently outperform conventional group convolutional networks on benchmark\nimage datasets. Simultaneously, we provide interpretability to the learned\nconcepts through the visualization of equivariant attention maps.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:06:24 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 12:34:17 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 07:41:35 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Romero", "David W.", ""], ["Bekkers", "Erik J.", ""], ["Tomczak", "Jakub M.", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "2002.03839", "submitter": "Evrard Garcelon", "authors": "Evrard Garcelon, Baptiste Roziere, Laurent Meunier, Jean Tarbouriech,\n  Olivier Teytaud, Alessandro Lazaric, Matteo Pirotta", "title": "Adversarial Attacks on Linear Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are applied in a wide range of domains, from\nadvertising to recommender systems, from clinical trials to education. In many\nof these domains, malicious agents may have incentives to attack the bandit\nalgorithm to induce it to perform a desired behavior. For instance, an\nunscrupulous ad publisher may try to increase their own revenue at the expense\nof the advertisers; a seller may want to increase the exposure of their\nproducts, or thwart a competitor's advertising campaign. In this paper, we\nstudy several attack scenarios and show that a malicious agent can force a\nlinear contextual bandit algorithm to pull any desired arm $T - o(T)$ times\nover a horizon of $T$ steps, while applying adversarial modifications to either\nrewards or contexts that only grow logarithmically as $O(\\log T)$. We also\ninvestigate the case when a malicious agent is interested in affecting the\nbehavior of the bandit algorithm in a single context (e.g., a specific user).\nWe first provide sufficient conditions for the feasibility of the attack and we\nthen propose an efficient algorithm to perform the attack. We validate our\ntheoretical results on experiments performed on both synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:04:09 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:54:10 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 08:18:10 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Garcelon", "Evrard", ""], ["Roziere", "Baptiste", ""], ["Meunier", "Laurent", ""], ["Tarbouriech", "Jean", ""], ["Teytaud", "Olivier", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2002.03843", "submitter": "Stefania Russo", "authors": "Stefania Russo, Andy Disch, Frank Blumensaat, Kris Villez", "title": "Anomaly Detection using Deep Autoencoders for in-situ Wastewater Systems\n  Monitoring Data", "comments": "10th IWA Symposium on Modelling and Integrated Assessment (Watermatex\n  2019)", "journal-ref": "10th IWA Symposium on Modelling and Integrated Assessment\n  (Watermatex 2019)", "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the growing amount of data from in-situ sensors in wastewater systems,\nit becomes necessary to automatically identify abnormal behaviours and ensure\nhigh data quality. This paper proposes an anomaly detection method based on a\ndeep autoencoder for in-situ wastewater systems monitoring data. The\nautoencoder architecture is based on 1D Convolutional Neural Network (CNN)\nlayers where the convolutions are performed over the inputs across the temporal\naxis of the data. Anomaly detection is then performed based on the\nreconstruction error of the decoding stage. The approach is validated on\nmultivariate time series from in-sewer process monitoring data. We discuss the\nresults and the challenge of labelling anomalies in complex time series. We\nsuggest that our proposed approach can support the domain experts in the\nidentification of anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:53:46 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:35:20 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 12:36:27 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Russo", "Stefania", ""], ["Disch", "Andy", ""], ["Blumensaat", "Frank", ""], ["Villez", "Kris", ""]]}, {"id": "2002.03844", "submitter": "Palash Goyal", "authors": "Palash Goyal, Saurabh Sahu, Shalini Ghosh, Chul Lee", "title": "Exploiting Temporal Coherence for Multi-modal Video Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal ML models can process data in multiple modalities (e.g., video,\nimages, audio, text) and are useful for video content analysis in a variety of\nproblems (e.g., object detection, scene understanding). In this paper, we focus\non the problem of video categorization by using a multimodal approach. We have\ndeveloped a novel temporal coherence-based regularization approach, which\napplies to different types of models (e.g., RNN, NetVLAD, Transformer). We\ndemonstrate through experiments how our proposed multimodal video\ncategorization models with temporal coherence out-perform strong\nstate-of-the-art baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 06:42:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 00:17:11 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Goyal", "Palash", ""], ["Sahu", "Saurabh", ""], ["Ghosh", "Shalini", ""], ["Lee", "Chul", ""]]}, {"id": "2002.03846", "submitter": "Felipe Giuste", "authors": "Felipe O. Giuste and Juan C. Vizcarra", "title": "CIFAR-10 Image Classification Using Feature Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification requires the generation of features capable of detecting\nimage patterns informative of group identity. The objective of this study was\nto classify images from the public CIFAR-10 image dataset by leveraging\ncombinations of disparate image feature sources from both manual and deep\nlearning approaches. Histogram of oriented gradients (HOG) and pixel\nintensities successfully inform classification (53% and 59% classification\naccuracy, respectively), yet there is much room for improvement. VGG16 with\nImageNet trained weights and a CIFAR-10 optimized model (CIFAR-VGG) further\nimprove upon image classification (60% and 93.43% accuracy, respectively). We\nfurther improved classification by utilizing transfer learning to re-establish\noptimal network weights for VGG16 (TL-VGG) and Inception ResNet v2\n(TL-Inception) resulting in significant performance increases (85% and 90.74%,\nrespectively), yet fail to surpass CIFAR-VGG. We hypothesized that if each\ngenerated feature set obtained some unique insight into the classification\nproblem, then combining these features would result in greater classification\naccuracy, surpassing that of CIFAR-VGG. Upon selection of the top 1000\nprincipal components from TL-VGG, TL-Inception, HOG, pixel intensities, and\nCIFAR-VGG, we achieved testing accuracy of 94.6%, lending support to our\nhypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:53:46 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 22:33:53 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Giuste", "Felipe O.", ""], ["Vizcarra", "Juan C.", ""]]}, {"id": "2002.03847", "submitter": "Tobias Brudermueller", "authors": "Tobias Brudermueller, Dennis L. Shung, Adrian J. Stanley, Johannes\n  Stegmaier, Smita Krishnaswamy", "title": "Making Logic Learnable With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are good at learning unspecified functions from\ntraining samples, they cannot be directly implemented in hardware and are often\nnot interpretable or formally verifiable. On the other hand, logic circuits are\nimplementable, verifiable, and interpretable but are not able to learn from\ntraining data in a generalizable way. We propose a novel logic learning\npipeline that combines the advantages of neural networks and logic circuits.\nOur pipeline first trains a neural network on a classification task, and then\ntranslates this, first to random forests, and then to AND-Inverter logic. We\nshow that our pipeline maintains greater accuracy than naive translations to\nlogic, and minimizes the logic such that it is more interpretable and has\ndecreased hardware cost. We show the utility of our pipeline on a network that\nis trained on biomedical data. This approach could be applied to patient care\nto provide risk stratification and guide clinical decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:11:40 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:49:30 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:07:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Brudermueller", "Tobias", ""], ["Shung", "Dennis L.", ""], ["Stanley", "Adrian J.", ""], ["Stegmaier", "Johannes", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2002.03848", "submitter": "Romain Tavenard", "authors": "Titouan Vayer and Laetitia Chapel and Nicolas Courty and R\\'emi\n  Flamary and Yann Soullard and Romain Tavenard", "title": "Time Series Alignment with Global Invariances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we address the problem of comparing time series while taking\ninto account both feature space transformation and temporal variability. The\nproposed framework combines a latent global transformation of the feature space\nwith the widely used Dynamic Time Warping (DTW). The latent global\ntransformation captures the feature invariance while the DTW (or its smooth\ncounterpart soft-DTW) deals with the temporal shifts. We cast the problem as a\njoint optimization over the global transformation and the temporal alignments.\nThe versatility of our framework allows for several variants depending on the\ninvariance class at stake. Among our contributions we define a differentiable\nloss for time series and present two algorithms for the computation of time\nseries barycenters under our new geometry. We illustrate the interest of our\napproach on both simulated and real world data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:11:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Vayer", "Titouan", ""], ["Chapel", "Laetitia", ""], ["Courty", "Nicolas", ""], ["Flamary", "R\u00e9mi", ""], ["Soullard", "Yann", ""], ["Tavenard", "Romain", ""]]}, {"id": "2002.03850", "submitter": "Rohit Zambre", "authors": "Rohit Zambre, Lars Bergstrom, Laleh Aghababaie Beni, Aparna\n  Chandramowliswharan", "title": "Parallel Performance-Energy Predictive Modeling of Browsers: Case Study\n  of Servo", "comments": "In Proceedings of the 23rd IEEE International Conference on High\n  Performance Computing, Data, and Analytics (HiPC), Hyderabad, India, December\n  2016", "journal-ref": null, "doi": "10.1109/HiPC.2016.013", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mozilla Research is developing Servo, a parallel web browser engine, to\nexploit the benefits of parallelism and concurrency in the web rendering\npipeline. Parallelization results in improved performance for pinterest.com but\nnot for google.com. This is because the workload of a browser is dependent on\nthe web page it is rendering. In many cases, the overhead of creating,\ndeleting, and coordinating parallel work outweighs any of its benefits. In this\npaper, we model the relationship between web page primitives and a web\nbrowser's parallel performance using supervised learning. We discover a feature\nspace that is representative of the parallelism available in a web page and\ncharacterize it using seven key features. Additionally, we consider energy\nusage trade-offs for different levels of performance improvements using\nautomated labeling algorithms. Such a model allows us to predict the degree of\nparallelism available in a web page and decide whether or not to render a web\npage in parallel. This modeling is critical for improving the browser's\nperformance and minimizing its energy usage. We evaluate our model by using\nServo's layout stage as a case study. Experiments on a quad-core Intel Ivy\nBridge (i7-3615QM) laptop show that we can improve performance and energy usage\nby up to 94.52% and 46.32% respectively on the 535 web pages considered in this\nstudy. Looking forward, we identify opportunities to apply this model to other\nstages of a browser's architecture as well as other performance- and\nenergy-critical devices.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:16:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zambre", "Rohit", ""], ["Bergstrom", "Lars", ""], ["Beni", "Laleh Aghababaie", ""], ["Chandramowliswharan", "Aparna", ""]]}, {"id": "2002.03851", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed Tewfik", "title": "Continuous Silent Speech Recognition using EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore continuous silent speech recognition using\nelectroencephalography (EEG) signals. We implemented a connectionist temporal\nclassification (CTC) automatic speech recognition (ASR) model to translate EEG\nsignals recorded in parallel while subjects were reading English sentences in\ntheir mind without producing any voice to text. Our results demonstrate the\nfeasibility of using EEG signals for performing continuous silent speech\nrecognition. We demonstrate our results for a limited English vocabulary\nconsisting of 30 unique sentences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:28:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 21:51:51 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 05:59:33 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 16:43:06 GMT"}, {"version": "v5", "created": "Sun, 8 Mar 2020 23:18:15 GMT"}, {"version": "v6", "created": "Sun, 15 Mar 2020 19:04:57 GMT"}, {"version": "v7", "created": "Mon, 4 May 2020 20:37:29 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed", ""]]}, {"id": "2002.03854", "submitter": "Prerana Mukherjee", "authors": "Gullapalli Keerti, A N Vaishnavi, Prerana Mukherjee, A Sree Vidya,\n  Gattineni Sai Sreenithya, Deeksha Nayab", "title": "Attentional networks for music generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic music generation has always remained as a challenging problem as it\nmay lack structure or rationality. In this work, we propose a deep learning\nbased music generation method in order to produce old style music particularly\nJAZZ with rehashed melodic structures utilizing a Bi-directional Long Short\nTerm Memory (Bi-LSTM) Neural Network with Attention. Owing to the success in\nmodelling long-term temporal dependencies in sequential data and its success in\ncase of videos, Bi-LSTMs with attention serve as the natural choice and early\nutilization in music generation. We validate in our experiments that Bi-LSTMs\nwith attention are able to preserve the richness and technical nuances of the\nmusic performed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:26:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Keerti", "Gullapalli", ""], ["Vaishnavi", "A N", ""], ["Mukherjee", "Prerana", ""], ["Vidya", "A Sree", ""], ["Sreenithya", "Gattineni Sai", ""], ["Nayab", "Deeksha", ""]]}, {"id": "2002.03860", "submitter": "Boris Muzellec", "authors": "Boris Muzellec, Julie Josse, Claire Boyer, Marco Cuturi", "title": "Missing Data Imputation using Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is a crucial issue when applying machine learning algorithms to\nreal-world datasets. Starting from the simple assumption that two batches\nextracted randomly from the same dataset should share the same distribution, we\nleverage optimal transport distances to quantify that criterion and turn it\ninto a loss function to impute missing data values. We propose practical\nmethods to minimize these losses using end-to-end learning, that can exploit or\nnot parametric assumptions on the underlying distributions of values. We\nevaluate our methods on datasets from the UCI repository, in MCAR, MAR and MNAR\nsettings. These experiments show that OT-based methods match or out-perform\nstate-of-the-art imputation methods, even for high percentages of missing\nvalues.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:23:42 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:06:16 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 09:16:41 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Muzellec", "Boris", ""], ["Josse", "Julie", ""], ["Boyer", "Claire", ""], ["Cuturi", "Marco", ""]]}, {"id": "2002.03862", "submitter": "Axel Chemla--Romeu-Santos", "authors": "Axel Chemla--Romeu-Santos, Stavros Ntalampiras, Philippe Esling,\n  Goffredo Haus, G\\'erard Assayag", "title": "Cross-modal variational inference for bijective signal-symbol\n  translation", "comments": "Proceedings of the 22nd International Conference on Digital Audio\n  Effects (DAFx-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extraction of symbolic information from signals is an active field of\nresearch enabling numerous applications especially in the Musical Information\nRetrieval domain. This complex task, that is also related to other topics such\nas pitch extraction or instrument recognition, is a demanding subject that gave\nbirth to numerous approaches, mostly based on advanced signal processing-based\nalgorithms. However, these techniques are often non-generic, allowing the\nextraction of definite physical properties of the signal (pitch, octave), but\nnot allowing arbitrary vocabularies or more general annotations. On top of\nthat, these techniques are one-sided, meaning that they can extract symbolic\ndata from an audio signal, but cannot perform the reverse process and make\nsymbol-to-signal generation. In this paper, we propose an bijective approach\nfor signal/symbol translation by turning this problem into a density estimation\ntask over signal and symbolic domains, considered both as related random\nvariables. We estimate this joint distribution with two different variational\nauto-encoders, one for each domain, whose inner representations are forced to\nmatch with an additive constraint, allowing both models to learn and generate\nseparately while allowing signal-to-symbol and symbol-to-signal inference. In\nthis article, we test our models on pitch, octave and dynamics symbols, which\ncomprise a fundamental step towards music transcription and label-constrained\naudio generation. In addition to its versatility, this system is rather light\nduring training and generation while allowing several interesting creative uses\nthat we outline at the end of the article.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:25:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chemla--Romeu-Santos", "Axel", ""], ["Ntalampiras", "Stavros", ""], ["Esling", "Philippe", ""], ["Haus", "Goffredo", ""], ["Assayag", "G\u00e9rard", ""]]}, {"id": "2002.03864", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar, C\\u{a}t\\u{a}lina Cangea, Pietro Li\\`o", "title": "Deep Graph Mapper: Seeing Graphs through the Neural Lens", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in graph representation learning have led to the\nemergence of condensed encodings that capture the main properties of a graph.\nHowever, even though these abstract representations are powerful for downstream\ntasks, they are not equally suitable for visualisation purposes. In this work,\nwe merge Mapper, an algorithm from the field of Topological Data Analysis\n(TDA), with the expressive power of Graph Neural Networks (GNNs) to produce\nhierarchical, topologically-grounded visualisations of graphs. These\nvisualisations do not only help discern the structure of complex graphs but\nalso provide a means of understanding the models applied to them for solving\nvarious tasks. We further demonstrate the suitability of Mapper as a\ntopological framework for graph pooling by mathematically proving an\nequivalence with Min-Cut and Diff Pool. Building upon this framework, we\nintroduce a novel pooling algorithm based on PageRank, which obtains\ncompetitive results with state of the art methods on graph classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:29:09 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 12:03:17 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Bodnar", "Cristian", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2002.03866", "submitter": "Rita Pucci", "authors": "Rita Pucci and Alessio Micheli and Stefano Chessa and Jane Hunter", "title": "Machine learning approaches for identifying prey handling activity in\n  otariid pinnipeds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems developed in wearable devices with sensors onboard are widely used to\ncollect data of humans and animals activities with the perspective of an\non-board automatic classification of data. An interesting application of these\nsystems is to support animals' behaviour monitoring gathered by sensors' data\nanalysis. This is a challenging area and in particular with fixed memories\ncapabilities because the devices should be able to operate autonomously for\nlong periods before being retrieved by human operators, and being able to\nclassify activities onboard can significantly improve their autonomy. In this\npaper, we focus on the identification of prey handling activity in seals (when\nthe animal start attaching and biting the prey), which is one of the main\nmovement that identifies a successful foraging activity. Data taken into\nconsideration are streams of 3D accelerometers and depth sensors values\ncollected by devices attached directly on seals. To analyse these data, we\npropose an automatic model based on Machine Learning (ML) algorithms. In\nparticular, we compare the performance (in terms of accuracy and F1score) of\nthree ML algorithms: Input Delay Neural Networks, Support Vector Machines, and\nEcho State Networks. We attend to the final aim of developing an automatic\nclassifier on-board. For this purpose, in this paper, the comparison is\nperformed concerning the performance obtained by each ML approach developed and\nits memory footprint. In the end, we highlight the advantage of using an ML\nalgorithm, in terms of feasibility in wild animals' monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:30:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pucci", "Rita", ""], ["Micheli", "Alessio", ""], ["Chessa", "Stefano", ""], ["Hunter", "Jane", ""]]}, {"id": "2002.03872", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Fares Meghdouri, Joachim Fabini, Tanja Zseby", "title": "SparseIDS: Learning Packet Sampling with Reinforcement Learning", "comments": null, "journal-ref": "2020 IEEE Conference on Communications and Network Security (CNS),\n  Avignon, France", "doi": "10.1109/CNS48642.2020.9162253", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been shown to be valuable for\nconstructing Intrusion Detection Systems (IDSs) for network data. They allow\ndetermining if a flow is malicious or not already before it is over, making it\npossible to take action immediately. However, considering the large number of\npackets that has to be inspected, for example in cloud/fog and edge computing,\nthe question of computational efficiency arises. We show that by using a novel\nReinforcement Learning (RL)-based approach called SparseIDS, we can reduce the\nnumber of consumed packets by more than three fourths while keeping\nclassification accuracy high. To minimize the computational expenses of the\nRL-based sampling we show that a shared neural network can be used for both the\nclassifier and the RL logic. Thus, no additional resources are consumed by the\nsampling in deployment. Comparing to various other sampling techniques,\nSparseIDS consistently achieves higher classification accuracy by learning to\nsample only relevant packets. A major novelty of our RL-based approach is that\nit can not only skip up to a predefined maximum number of samples like other\napproaches proposed in the domain of Natural Language Processing but can even\nskip arbitrarily many packets in one step. This enables saving even more\ncomputational resources for long sequences. Inspecting SparseIDS's behavior of\nchoosing packets shows that it adopts different sampling strategies for\ndifferent attack types and network flows. Finally we build an automatic\nsteering mechanism that can guide SparseIDS in deployment to achieve a desired\nlevel of sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:38:38 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 12:18:44 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:22:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bachl", "Maximilian", ""], ["Meghdouri", "Fares", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "2002.03875", "submitter": "Jayaraman J. Thiagarajan", "authors": "Bindya Venkatesh, Jayaraman J. Thiagarajan, Kowshik Thopalli and\n  Prasanna Sattigeri", "title": "Calibrate and Prune: Improving Reliability of Lottery Tickets Through\n  Prediction Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis that sub-network initializations (lottery) exist within the\ninitializations of over-parameterized networks, which when trained in isolation\nproduce highly generalizable models, has led to crucial insights into network\ninitialization and has enabled efficient inferencing. Supervised models with\nuncalibrated confidences tend to be overconfident even when making wrong\nprediction. In this paper, for the first time, we study how explicit confidence\ncalibration in the over-parameterized network impacts the quality of the\nresulting lottery tickets. More specifically, we incorporate a suite of\ncalibration strategies, ranging from mixup regularization, variance-weighted\nconfidence calibration to the newly proposed likelihood-based calibration and\nnormalized bin assignment strategies. Furthermore, we explore different\ncombinations of architectures and datasets, and make a number of key findings\nabout the role of confidence calibration. Our empirical studies reveal that\nincluding calibration mechanisms consistently lead to more effective lottery\ntickets, in terms of accuracy as well as empirical calibration metrics, even\nwhen retrained using data with challenging distribution shifts with respect to\nthe source dataset.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:42:36 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:56:46 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 05:17:25 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Venkatesh", "Bindya", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Thopalli", "Kowshik", ""], ["Sattigeri", "Prasanna", ""]]}, {"id": "2002.03893", "submitter": "Craigory Coppola", "authors": "Craigory Coppola, Heba Elgazzar", "title": "Novel Machine Learning Algorithms for Centrality and Cliques Detection\n  in Youtube Social Networks", "comments": null, "journal-ref": "IJAIA Volume 11, No. 1, January 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this research project is to analyze the dynamics of social\nnetworks using machine learning techniques to locate maximal cliques and to\nfind clusters for the purpose of identifying a target demographic. Unsupervised\nmachine learning techniques are designed and implemented in this project to\nanalyze a dataset from YouTube to discover communities in the social network\nand find central nodes. Different clustering algorithms are implemented and\napplied to the YouTube dataset. The well-known Bron-Kerbosch algorithm is used\neffectively in this research to find maximal cliques. The results obtained from\nthis research could be used for advertising purposes and for building smart\nrecommendation systems. All algorithms were implemented using Python\nprogramming language. The experimental results show that we were able to\nsuccessfully find central nodes through clique-centrality and degree\ncentrality. By utilizing clique detection algorithms, the research shown how\nmachine learning algorithms can detect close knit groups within a larger\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:05:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Coppola", "Craigory", ""], ["Elgazzar", "Heba", ""]]}, {"id": "2002.03896", "submitter": "Sam Earle", "authors": "Sam Earle", "title": "Using Fractal Neural Networks to Play SimCity 1 and Conway's Game of\n  Life at Variable Scales", "comments": "8 pages, 5 figures, presented at EXAG, an AIIDE workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce gym-city, a Reinforcement Learning environment that uses SimCity\n1's game engine to simulate an urban environment, wherein agents might seek to\noptimize one or a combination of any number of city-wide metrics, on gameboards\nof various sizes. We focus on population, and analyze our agents' ability to\ngeneralize to larger map-sizes than those seen during training. The environment\nis interactive, allowing a human player to build alongside agents during\ntraining and inference, potentially influencing the course of their learning,\nor manually probing and evaluating their performance. To test our agents'\nability to capture distance-agnostic relationships between elements of the\ngameboard, we design a minigame within the environment which is, by design,\nunsolvable at large enough scales given strictly local strategies. Given the\ngame engine's extensive use of Cellular Automata, we also train our agents to\n\"play\" Conway's Game of Life -- again optimizing for population -- and examine\ntheir behaviour at multiple scales. To make our models compatible with\nvariable-scale gameplay, we use Neural Networks with recursive weights and\nstructure -- fractals to be truncated at different depths, dependent upon the\nsize of the gameboard.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:10:31 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Earle", "Sam", ""]]}, {"id": "2002.03898", "submitter": "Pritam Sarkar", "authors": "Pritam Sarkar and Ali Etemad", "title": "Self-supervised ECG Representation Learning for Emotion Recognition", "comments": "Accepted in IEEE Transactions of Affective Computing", "journal-ref": null, "doi": "10.1109/TAFFC.2020.3014842", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We exploit a self-supervised deep multi-task learning framework for\nelectrocardiogram (ECG) -based emotion recognition. The proposed solution\nconsists of two stages of learning a) learning ECG representations and b)\nlearning to classify emotions. ECG representations are learned by a signal\ntransformation recognition network. The network learns high-level abstract\nrepresentations from unlabeled ECG data. Six different signal transformations\nare applied to the ECG signals, and transformation recognition is performed as\npretext tasks. Training the model on pretext tasks helps the network learn\nspatiotemporal representations that generalize well across different datasets\nand different emotion categories. We transfer the weights of the\nself-supervised network to an emotion recognition network, where the\nconvolutional layers are kept frozen and the dense layers are trained with\nlabelled ECG data. We show that the proposed solution considerably improves the\nperformance compared to a network trained using fully-supervised learning. New\nstate-of-the-art results are set in classification of arousal, valence,\naffective states, and stress for the four utilized datasets. Extensive\nexperiments are performed, providing interesting insights into the impact of\nusing a multi-task self-supervised structure instead of a single-task model, as\nwell as the optimum level of difficulty required for the pretext\nself-supervised tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:15:37 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 07:09:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sarkar", "Pritam", ""], ["Etemad", "Ali", ""]]}, {"id": "2002.03899", "submitter": "Adrien Saumard", "authors": "Camille Brunet-Saumard, Edouard Genetay, Adrien Saumard", "title": "K-bMOM: a robust Lloyd-type clustering algorithm based on bootstrap\n  Median-of-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new clustering algorithm that is robust to the presence of\noutliers in the dataset. We perform Lloyd-type iterations with robust estimates\nof the centroids. More precisely, we build on the idea of median-of-means\nstatistics to estimate the centroids, but allow for replacement while\nconstructing the blocks. We call this methodology the bootstrap median-of-means\n(bMOM) and prove that if enough blocks are generated through the bootstrap\nsampling, then it has a better breakdown point for mean estimation than the\nclassical median-of-means (MOM), where the blocks form a partition of the\ndataset. From a clustering perspective, bMOM enables to take many blocks of a\ndesired size, thus avoiding possible disappearance of clusters in some blocks,\na pitfall that can occur for the partition-based generation of blocks of the\nclassical median-of-means. Experiments on simulated datasets show that the\nproposed approach, called K-bMOM, performs better than existing robust K-means\nbased methods. Guidelines are provided for tuning the hyper-parameters K-bMOM\nin practice. It is also recommended to the practitionner to use such a robust\napproach to initialize their clustering algorithm. Finally, considering a\nsimplified and theoretical version of our estimator, we prove its robustness to\nadversarial contamination by deriving robust rates of convergence for the\nK-means distorsion. To our knowledge, it is the first result of this kind for\nthe K-means distorsion.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:08:08 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:56:21 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Brunet-Saumard", "Camille", ""], ["Genetay", "Edouard", ""], ["Saumard", "Adrien", ""]]}, {"id": "2002.03909", "submitter": "Will Shand", "authors": "Will Shand and Stephen Becker", "title": "Locality-sensitive hashing in function spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of performing similarity search over function spaces.\nTo perform search over such spaces in a reasonable amount of time, we use {\\it\nlocality-sensitive hashing} (LSH). We present two methods that allow LSH\nfunctions on $\\mathbb{R}^N$ to be extended to $L^p$ spaces: one using function\napproximation in an orthonormal basis, and another using (quasi-)Monte\nCarlo-style techniques. We use the presented hashing schemes to construct an\nLSH family for Wasserstein distance over one-dimensional, continuous\nprobability distributions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:16:26 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shand", "Will", ""], ["Becker", "Stephen", ""]]}, {"id": "2002.03911", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ankur Mali, Daniel Kifer, C. Lee Giles", "title": "Large-Scale Gradient-Free Deep Learning with Recursive Local\n  Representation Alignment", "comments": "Further revised submission -- main description of rec-LRA revamped\n  and architecture-agnostic pseudo-code moved to appendix with additional\n  results/derivation updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks on large-scale datasets requires significant\nhardware resources whose costs (even on cloud platforms) put them out of reach\nof smaller organizations, groups, and individuals. Backpropagation, the\nworkhorse for training these networks, is an inherently sequential process that\nis difficult to parallelize. Furthermore, it requires researchers to\ncontinually develop various tricks, such as specialized weight initializations\nand activation functions, in order to ensure a stable parameter optimization.\nOur goal is to seek an effective, neuro-biologically-plausible alternative to\nbackprop that can be used to train deep networks. In this paper, we propose a\ngradient-free learning procedure, recursive local representation alignment, for\ntraining large-scale neural architectures. Experiments with residual networks\non CIFAR-10 and the large benchmark, ImageNet, show that our algorithm\ngeneralizes as well as backprop while converging sooner due to weight updates\nthat are parallelizable and computationally less demanding. This is empirical\nevidence that a backprop-free algorithm can scale up to larger datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:20:02 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 04:46:28 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 06:16:08 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ororbia", "Alexander", ""], ["Mali", "Ankur", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "2002.03924", "submitter": "Raj Dasgupta", "authors": "Prithviraj Dasgupta, Joseph B. Collins, Michael McCarrick", "title": "Playing to Learn Better: Repeated Games for Adversarial Learning with\n  Multiple Classifiers", "comments": "Presented at Artificial Intelligence for Cyber Security (AICS) 2020\n  workshop (non-archival), New York, NY. February 8, 2020", "journal-ref": null, "doi": null, "report-no": "NRL/CP/5580--19-0044", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of prediction by a machine learning algorithm, called\nlearner, within an adversarial learning setting. The learner's task is to\ncorrectly predict the class of data passed to it as a query. However, along\nwith queries containing clean data, the learner could also receive malicious or\nadversarial queries from an adversary. The objective of the adversary is to\nevade the learner's prediction mechanism by sending adversarial queries that\nresult in erroneous class prediction by the learner, while the learner's\nobjective is to reduce the incorrect prediction of these adversarial queries\nwithout degrading the prediction quality of clean queries. We propose a game\ntheory-based technique called a Repeated Bayesian Sequential Game where the\nlearner interacts repeatedly with a model of the adversary using self play to\ndetermine the distribution of adversarial versus clean queries. It then\nstrategically selects a classifier from a set of pre-trained classifiers that\nbalances the likelihood of correct prediction for the query along with reducing\nthe costs to use the classifier. We have evaluated our proposed technique using\nclean and adversarial text data with deep neural network-based classifiers and\nshown that the learner can select an appropriate classifier that is\ncommensurate with the query type (clean or adversarial) while remaining aware\nof the cost to use the classifier.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:33:42 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dasgupta", "Prithviraj", ""], ["Collins", "Joseph B.", ""], ["McCarrick", "Michael", ""]]}, {"id": "2002.03932", "submitter": "Wei-Cheng Chang", "authors": "Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar", "title": "Pre-training Tasks for Embedding-based Large-scale Retrieval", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the large-scale query-document retrieval problem: given a query\n(e.g., a question), return the set of relevant documents (e.g., paragraphs\ncontaining the answer) from a large document corpus. This problem is often\nsolved in two steps. The retrieval phase first reduces the solution space,\nreturning a subset of candidate documents. The scoring phase then re-ranks the\ndocuments. Critically, the retrieval algorithm not only desires high recall but\nalso requires to be highly efficient, returning candidates in time sublinear to\nthe number of documents. Unlike the scoring phase witnessing significant\nadvances recently due to the BERT-style pre-training tasks on cross-attention\nmodels, the retrieval phase remains less well studied. Most previous works rely\non classic Information Retrieval (IR) methods such as BM-25 (token matching +\nTF-IDF weights). These models only accept sparse handcrafted features and can\nnot be optimized for different downstream tasks of interest. In this paper, we\nconduct a comprehensive study on the embedding-based retrieval models. We show\nthat the key ingredient of learning a strong embedding-based Transformer model\nis the set of pre-training tasks. With adequately designed paragraph-level\npre-training tasks, the Transformer models can remarkably improve over the\nwidely-used BM-25 as well as embedding models without Transformers. The\nparagraph-level pre-training tasks we studied are Inverse Cloze Task (ICT),\nBody First Selection (BFS), Wiki Link Prediction (WLP), and the combination of\nall three.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:44:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chang", "Wei-Cheng", ""], ["Yu", "Felix X.", ""], ["Chang", "Yin-Wen", ""], ["Yang", "Yiming", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2002.03936", "submitter": "Rafael M\\\"uller", "authors": "Rafael M\\\"uller, Simon Kornblith, Geoffrey Hinton", "title": "Subclass Distillation", "comments": "Under review, corrected citation spelling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a large \"teacher\" neural network has been trained on labeled data, the\nprobabilities that the teacher assigns to incorrect classes reveal a lot of\ninformation about the way in which the teacher generalizes. By training a small\n\"student\" model to match these probabilities, it is possible to transfer most\nof the generalization ability of the teacher to the student, often producing a\nmuch better small model than directly training the student on the training\ndata. The transfer works best when there are many possible classes because more\nis then revealed about the function learned by the teacher, but in cases where\nthere are only a few possible classes we show that we can improve the transfer\nby forcing the teacher to divide each class into many subclasses that it\ninvents during the supervised training. The student is then trained to match\nthe subclass probabilities. For datasets where there are known, natural\nsubclasses we demonstrate that the teacher learns similar subclasses and these\nimprove distillation. For clickthrough datasets where the subclasses are\nunknown we demonstrate that subclass distillation allows the student to learn\nfaster and better.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:45:30 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 18:32:14 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["M\u00fcller", "Rafael", ""], ["Kornblith", "Simon", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2002.03938", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Wenjing Liao, Hongyuan Zha, Tuo Zhao", "title": "Statistical Guarantees of Generative Adversarial Networks for\n  Distribution Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have achieved great success in\nunsupervised learning. Despite the remarkable empirical performance, there are\nlimited theoretical understandings on the statistical properties of GANs. This\npaper provides statistical guarantees of GANs for the estimation of data\ndistributions which have densities in a H\\\"{o}lder space. Our main result shows\nthat, if the generator and discriminator network architectures are properly\nchosen (universally for all distributions with H\\\"{o}lder densities), GANs are\nconsistent estimators of the data distributions under strong discrepancy\nmetrics, such as the Wasserstein distance. To our best knowledge, this is the\nfirst statistical theory of GANs for H\\\"{o}lder densities. In comparison with\nexisting works, our theory requires minimum assumptions on data distributions.\nOur generator and discriminator networks utilize general weight matrices and\nthe non-invertible ReLU activation function, while many existing works only\napply to invertible weight matrices and invertible activation functions. In our\nanalysis, we decompose the error into a statistical error and an approximation\nerror by a new oracle inequality, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:47:57 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:04:00 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chen", "Minshuo", ""], ["Liao", "Wenjing", ""], ["Zha", "Hongyuan", ""], ["Zhao", "Tuo", ""]]}, {"id": "2002.03963", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky", "title": "Adaptive Online Learning with Varying Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given any increasing sequence of norms $\\|\\cdot\\|_0,\\dots,\\|\\cdot\\|_{T-1}$,\nwe provide an online convex optimization algorithm that outputs points $w_t$ in\nsome domain $W$ in response to convex losses $\\ell_t:W\\to \\mathbb{R}$ that\nguarantees regret $R_T(u)=\\sum_{t=1}^T \\ell_t(w_t)-\\ell_t(u)\\le \\tilde\nO\\left(\\|u\\|_{T-1}\\sqrt{\\sum_{t=1}^T \\|g_t\\|_{t-1,\\star}^2}\\right)$ where $g_t$\nis a subgradient of $\\ell_t$ at $w_t$. Our method does not require tuning to\nthe value of $u$ and allows for arbitrary convex $W$. We apply this result to\nobtain new \"full-matrix\"-style regret bounds. Along the way, we provide a new\nexamination of the full-matrix AdaGrad algorithm, suggesting a better learning\nrate value that improves significantly upon prior analysis. We use our new\ntechniques to tune AdaGrad on-the-fly, realizing our improved bound in a\nconcrete algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:22:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Cutkosky", "Ashok", ""]]}, {"id": "2002.03967", "submitter": "Fran\\c{c}ois-Pierre Paty", "authors": "Fran\\c{c}ois-Pierre Paty, Marco Cuturi", "title": "Regularized Optimal Transport is Ground Cost Adversarial", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularizing the optimal transport (OT) problem has proven crucial for OT\ntheory to impact the field of machine learning. For instance, it is known that\nregularizing OT problems with entropy leads to faster computations and better\ndifferentiation using the Sinkhorn algorithm, as well as better sample\ncomplexity bounds than classic OT. In this work we depart from this practical\nperspective and propose a new interpretation of regularization as a robust\nmechanism, and show using Fenchel duality that any convex regularization of OT\ncan be interpreted as ground cost adversarial. This incidentally gives access\nto a robust dissimilarity measure on the ground space, which can in turn be\nused in other applications. We propose algorithms to compute this robust cost,\nand illustrate the interest of this approach empirically.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:28:35 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 14:23:25 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 07:14:41 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Paty", "Fran\u00e7ois-Pierre", ""], ["Cuturi", "Marco", ""]]}, {"id": "2002.03977", "submitter": "Ross Cutler", "authors": "Ross Cutler, Ramin Mehran, Sam Johnson, Cha Zhang, Adam Kirk, Oliver\n  Whyte, Adarsh Kowdle", "title": "Multimodal active speaker detection and virtual cinematography for video\n  conferencing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active speaker detection (ASD) and virtual cinematography (VC) can\nsignificantly improve the remote user experience of a video conference by\nautomatically panning, tilting and zooming of a video conferencing camera:\nusers subjectively rate an expert video cinematographer's video significantly\nhigher than unedited video. We describe a new automated ASD and VC that\nperforms within 0.3 MOS of an expert cinematographer based on subjective\nratings with a 1-5 scale. This system uses a 4K wide-FOV camera, a depth\ncamera, and a microphone array; it extracts features from each modality and\ntrains an ASD using an AdaBoost machine learning system that is very efficient\nand runs in real-time. A VC is similarly trained using machine learning to\noptimize the subjective quality of the overall experience. To avoid distracting\nthe room participants and reduce switching latency the system has no moving\nparts -- the VC works by cropping and zooming the 4K wide-FOV video stream. The\nsystem was tuned and evaluated using extensive crowdsourcing techniques and\nevaluated on a dataset with N=100 meetings, each 2-5 minutes in length.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:41:51 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 06:09:28 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Cutler", "Ross", ""], ["Mehran", "Ramin", ""], ["Johnson", "Sam", ""], ["Zhang", "Cha", ""], ["Kirk", "Adam", ""], ["Whyte", "Oliver", ""], ["Kowdle", "Adarsh", ""]]}, {"id": "2002.03979", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Xi Chen, Wei Biao Wu", "title": "Online Covariance Matrix Estimation in Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient descent (SGD) algorithm is widely used for parameter\nestimation, especially for huge data sets and online learning. While this\nrecursive algorithm is popular for computation and memory efficiency,\nquantifying variability and randomness of the solutions has been rarely\nstudied. This paper aims at conducting statistical inference of SGD-based\nestimates in an online setting. In particular, we propose a fully online\nestimator for the covariance matrix of averaged SGD iterates (ASGD) only using\nthe iterates from SGD. We formally establish our online estimator's consistency\nand show that the convergence rate is comparable to offline counterparts. Based\non the classic asymptotic normality results of ASGD, we construct\nasymptotically valid confidence intervals for model parameters. Upon receiving\nnew observations, we can quickly update the covariance matrix estimate and the\nconfidence intervals. This approach fits in an online setting and takes full\nadvantage of SGD: efficiency in computation and memory.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:46:10 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 02:16:56 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 15:16:16 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhu", "Wanrong", ""], ["Chen", "Xi", ""], ["Wu", "Wei Biao", ""]]}, {"id": "2002.03996", "submitter": "Chandrashekar Lakshminarayanan", "authors": "Chandrashekar Lakshminarayanan and Amit Vikram Singh", "title": "Deep Gated Networks: A framework to understand training and\n  generalisation in deep learning", "comments": "18 Pages, submitted to ICML, added convnets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the role of (stochastic) gradient descent (SGD) in the training\nand generalisation of deep neural networks (DNNs) with ReLU activation has been\nthe object study in the recent past. In this paper, we make use of deep gated\nnetworks (DGNs) as a framework to obtain insights about DNNs with ReLU\nactivation. In DGNs, a single neuronal unit has two components namely the\npre-activation input (equal to the inner product the weights of the layer and\nthe previous layer outputs), and a gating value which belongs to $[0,1]$ and\nthe output of the neuronal unit is equal to the multiplication of\npre-activation input and the gating value. The standard DNN with ReLU\nactivation, is a special case of the DGNs, wherein the gating value is $1/0$\nbased on whether or not the pre-activation input is positive or negative. We\ntheoretically analyse and experiment with several variants of DGNs, each\nvariant suited to understand a particular aspect of either training or\ngeneralisation in DNNs with ReLU activation. Our theory throws light on two\nquestions namely i) why increasing depth till a point helps in training and ii)\nwhy increasing depth beyond a point hurts training? We also present\nexperimental evidence to show that gate adaptation, i.e., the change of gating\nvalue through the course of training is key for generalisation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:12:20 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:25:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lakshminarayanan", "Chandrashekar", ""], ["Singh", "Amit Vikram", ""]]}, {"id": "2002.04010", "submitter": "Yu Bai", "authors": "Yu Bai, Ben Krause, Huan Wang, Caiming Xiong, Richard Socher", "title": "Taylorized Training: Towards Better Approximation of Neural Network\n  Training at Finite Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose \\emph{Taylorized training} as an initiative towards better\nunderstanding neural network training at finite width. Taylorized training\ninvolves training the $k$-th order Taylor expansion of the neural network at\ninitialization, and is a principled extension of linearized training---a\nrecently proposed theory for understanding the success of deep learning.\n  We experiment with Taylorized training on modern neural network\narchitectures, and show that Taylorized training (1) agrees with full neural\nnetwork training increasingly better as we increase $k$, and (2) can\nsignificantly close the performance gap between linearized and full training.\nCompared with linearized training, higher-order training works in more\nrealistic settings such as standard parameterization and large (initial)\nlearning rate. We complement our experiments with theoretical results showing\nthat the approximation error of $k$-th order Taylorized models decay\nexponentially over $k$ in wide neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:37:04 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 21:12:54 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bai", "Yu", ""], ["Krause", "Ben", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "2002.04013", "submitter": "Max Ryabinin", "authors": "Max Ryabinin, Anton Gusev", "title": "Towards Crowdsourced Training of Large Neural Networks using\n  Decentralized Mixture-of-Experts", "comments": "Advances in Neural Information Processing Systems, 2020. Code URL:\n  https://github.com/mryab/learning-at-home. 16 pages, 6 figures", "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)\n  3659-3672", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent breakthroughs in deep learning were achieved by training\nincreasingly larger models on massive datasets. However, training such models\ncan be prohibitively expensive. For instance, the cluster used to train GPT-3\ncosts over \\$250 million. As a result, most researchers cannot afford to train\nstate of the art models and contribute to their development. Hypothetically, a\nresearcher could crowdsource the training of large neural networks with\nthousands of regular PCs provided by volunteers. The raw computing power of a\nhundred thousand \\$2500 desktops dwarfs that of a \\$250M server pod, but one\ncannot utilize that power efficiently with conventional distributed training\nmethods. In this work, we propose Learning@home: a novel neural network\ntraining paradigm designed to handle large amounts of poorly connected\nparticipants. We analyze the performance, reliability, and architectural\nconstraints of this paradigm and compare it against existing distributed\ntraining techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:39:25 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 15:15:44 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 16:36:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ryabinin", "Max", ""], ["Gusev", "Anton", ""]]}, {"id": "2002.04014", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Masatoshi Uehara", "title": "Statistically Efficient Off-Policy Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods in reinforcement learning update policy parameters by\ntaking steps in the direction of an estimated gradient of policy value. In this\npaper, we consider the statistically efficient estimation of policy gradients\nfrom off-policy data, where the estimation is particularly non-trivial. We\nderive the asymptotic lower bound on the feasible mean-squared error in both\nMarkov and non-Markov decision processes and show that existing estimators fail\nto achieve it in general settings. We propose a meta-algorithm that achieves\nthe lower bound without any parametric assumptions and exhibits a unique 3-way\ndouble robustness property. We discuss how to estimate nuisances that the\nalgorithm relies on. Finally, we establish guarantees on the rate at which we\napproach a stationary point when we take steps in the direction of our new\nestimated policy gradient.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:41:25 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 14:40:50 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "2002.04017", "submitter": "Yu Bai", "authors": "Yu Bai, Chi Jin", "title": "Provable Self-Play Algorithms for Competitive Reinforcement Learning", "comments": "Appearing at ICML 2020. Fixed typos from v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-play, where the algorithm learns by playing against itself without\nrequiring any direct supervision, has become the new weapon in modern\nReinforcement Learning (RL) for achieving superhuman performance in practice.\nHowever, the majority of exisiting theory in reinforcement learning only\napplies to the setting where the agent plays against a fixed environment; it\nremains largely open whether self-play algorithms can be provably effective,\nespecially when it is necessary to manage the exploration/exploitation\ntradeoff. We study self-play in competitive reinforcement learning under the\nsetting of Markov games, a generalization of Markov decision processes to the\ntwo-player case. We introduce a self-play algorithm---Value Iteration with\nUpper/Lower Confidence Bound (VI-ULCB)---and show that it achieves regret\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ after playing $T$ steps of the game, where the\nregret is measured by the agent's performance against a \\emph{fully\nadversarial} opponent who can exploit the agent's strategy at \\emph{any} step.\nWe also introduce an explore-then-exploit style algorithm, which achieves a\nslightly worse regret of $\\tilde{\\mathcal{O}}(T^{2/3})$, but is guaranteed to\nrun in polynomial time even in the worst case. To the best of our knowledge,\nour work presents the first line of provably sample-efficient self-play\nalgorithms for competitive reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:44:50 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 22:29:39 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 17:07:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Bai", "Yu", ""], ["Jin", "Chi", ""]]}, {"id": "2002.04019", "submitter": "Sreyas Mohan", "authors": "Aakash Kaku, Sreyas Mohan, Avinash Parnandi, Heidi Schambra and Carlos\n  Fernandez-Granda", "title": "Be Like Water: Robustness to Extraneous Variables Via Adaptive Feature\n  Normalization", "comments": "Aakash and Sreyas contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extraneous variables are variables that are irrelevant for a certain task,\nbut heavily affect the distribution of the available data. In this work, we\nshow that the presence of such variables can degrade the performance of\ndeep-learning models. We study three datasets where there is a strong influence\nof known extraneous variables: classification of upper-body movements in stroke\npatients, annotation of surgical activities, and recognition of corrupted\nimages. Models trained with batch normalization learn features that are highly\ndependent on the extraneous variables. In batch normalization, the statistics\nused to normalize the features are learned from the training set and fixed at\ntest time, which produces a mismatch in the presence of varying extraneous\nvariables. We demonstrate that estimating the feature statistics adaptively\nduring inference, as in instance normalization, addresses this issue, producing\nnormalized features that are more robust to changes in the extraneous\nvariables. This results in a significant gain in performance for different\nnetwork architectures and choices of feature statistics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:47:08 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 21:35:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kaku", "Aakash", ""], ["Mohan", "Sreyas", ""], ["Parnandi", "Avinash", ""], ["Schambra", "Heidi", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "2002.04025", "submitter": "Zhengdao Chen", "authors": "Zhengdao Chen, Lei Chen, Soledad Villar, Joan Bruna", "title": "Can Graph Neural Networks Count Substructures?", "comments": "Improved the descriptions of the Local Relational Pooling (LRP) model\n  and its practical implementation; Added more experimental results on\n  synthetic and molecular datasets; Added the LRP-l-1 model in the experiments", "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect and count certain substructures in graphs is important\nfor solving many tasks on graph-structured data, especially in the contexts of\ncomputational chemistry and biology as well as social network analysis.\nInspired by this, we propose to study the expressive power of graph neural\nnetworks (GNNs) via their ability to count attributed graph substructures,\nextending recent works that examine their power in graph isomorphism testing\nand function approximation. We distinguish between two types of substructure\ncounting: induced-subgraph-count and subgraph-count, and establish both\npositive and negative answers for popular GNN architectures. Specifically, we\nprove that Message Passing Neural Networks (MPNNs), 2-Weisfeiler-Lehman (2-WL)\nand 2-Invariant Graph Networks (2-IGNs) cannot perform induced-subgraph-count\nof substructures consisting of 3 or more nodes, while they can perform\nsubgraph-count of star-shaped substructures. As an intermediary step, we prove\nthat 2-WL and 2-IGNs are equivalent in distinguishing non-isomorphic graphs,\npartly answering an open problem raised in Maron et al. (2019). We also prove\npositive results for k-WL and k-IGNs as well as negative results for k-WL with\na finite number of iterations. We then conduct experiments that support the\ntheoretical results for MPNNs and 2-IGNs. Moreover, motivated by substructure\ncounting and inspired by Murphy et al. (2019), we propose the Local Relational\nPooling model and demonstrate that it is not only effective for substructure\ncounting but also able to achieve competitive performance on molecular\nprediction tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:53:30 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 04:39:59 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 17:59:28 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 18:03:30 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chen", "Zhengdao", ""], ["Chen", "Lei", ""], ["Villar", "Soledad", ""], ["Bruna", "Joan", ""]]}, {"id": "2002.04026", "submitter": "Quanquan Gu", "authors": "Zixiang Chen and Yuan Cao and Quanquan Gu and Tong Zhang", "title": "A Generalized Neural Tangent Kernel Analysis for Two-layer Neural\n  Networks", "comments": "33 pages. This version changes the title and improves the\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent breakthrough in deep learning theory shows that the training of\nover-parameterized deep neural networks can be characterized by a kernel\nfunction called \\textit{neural tangent kernel} (NTK). However, it is known that\nthis type of results does not perfectly match the practice, as NTK-based\nanalysis requires the network weights to stay very close to their\ninitialization throughout training, and cannot handle regularizers or gradient\nnoises. In this paper, we provide a generalized neural tangent kernel analysis\nand show that noisy gradient descent with weight decay can still exhibit a\n\"kernel-like\" behavior. This implies that the training loss converges linearly\nup to a certain accuracy. We also establish a novel generalization error bound\nfor two-layer neural networks trained by noisy gradient descent with weight\ndecay.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:56:15 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:45:59 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Chen", "Zixiang", ""], ["Cao", "Yuan", ""], ["Gu", "Quanquan", ""], ["Zhang", "Tong", ""]]}, {"id": "2002.04033", "submitter": "Theofanis Karaletsos", "authors": "Theofanis Karaletsos, Thang D. Bui", "title": "Hierarchical Gaussian Process Priors for Bayesian Neural Network Weights", "comments": "12 pages main paper, 13 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic neural networks are typically modeled with independent weight\npriors, which do not capture weight correlations in the prior and do not\nprovide a parsimonious interface to express properties in function space. A\ndesirable class of priors would represent weights compactly, capture\ncorrelations between weights, facilitate calibrated reasoning about\nuncertainty, and allow inclusion of prior knowledge about the function space\nsuch as periodicity or dependence on contexts such as inputs. To this end, this\npaper introduces two innovations: (i) a Gaussian process-based hierarchical\nmodel for network weights based on unit embeddings that can flexibly encode\ncorrelated weight structures, and (ii) input-dependent versions of these weight\npriors that can provide convenient ways to regularize the function space\nthrough the use of kernels defined on contextual inputs. We show these models\nprovide desirable test-time uncertainty estimates on out-of-distribution data,\ndemonstrate cases of modeling inductive biases for neural networks with kernels\nwhich help both interpolation and extrapolation from training data, and\ndemonstrate competitive predictive performance on an active learning benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:19:52 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Karaletsos", "Theofanis", ""], ["Bui", "Thang D.", ""]]}, {"id": "2002.04060", "submitter": "Behnam Asadi", "authors": "Behnam Asadi, Hui Jiang", "title": "On Approximation Capabilities of ReLU Activation and Softmax Output\n  Layer in Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have extended the well-established universal approximator\ntheory to neural networks that use the unbounded ReLU activation function and a\nnonlinear softmax output layer. We have proved that a sufficiently large neural\nnetwork using the ReLU activation function can approximate any function in\n$L^1$ up to any arbitrary precision. Moreover, our theoretical results have\nshown that a large enough neural network using a nonlinear softmax output layer\ncan also approximate any indicator function in $L^1$, which is equivalent to\nmutually-exclusive class labels in any realistic multiple-class pattern\nclassification problems. To the best of our knowledge, this work is the first\ntheoretical justification for using the softmax output layers in neural\nnetworks for pattern classification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 19:48:47 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Asadi", "Behnam", ""], ["Jiang", "Hui", ""]]}, {"id": "2002.04069", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh", "title": "On the Communication Latency of Wireless Decentralized Learning", "comments": "Submitted to the 2020 IEEE International Symposium on Information\n  Theory (ISIT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless network comprising $n$ nodes located within a circular\narea of radius $R$, which are participating in a decentralized learning\nalgorithm to optimize a global objective function using their local datasets.\nTo enable gradient exchanges across the network, we assume each node\ncommunicates only with a set of neighboring nodes, which are within a distance\n$R n^{-\\beta}$ of itself, where $\\beta\\in(0,\\frac{1}{2})$. We use tools from\nnetwork information theory and random geometric graph theory to show that the\ncommunication delay for a single round of exchanging gradients on all the links\nthroughout the network scales as\n$\\mathcal{O}\\left(\\frac{n^{2-3\\beta}}{\\beta\\log n}\\right)$, increasing (at\ndifferent rates) with both the number of nodes and the gradient exchange\nthreshold distance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:10:07 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Naderializadeh", "Navid", ""]]}, {"id": "2002.04083", "submitter": "Ioana Bica", "authors": "Ioana Bica, Ahmed M. Alaa, James Jordon, Mihaela van der Schaar", "title": "Estimating Counterfactual Treatment Outcomes over Time Through\n  Adversarially Balanced Representations", "comments": null, "journal-ref": "In Proc. 8th International Conference on Learning Representations\n  (ICLR 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying when to give treatments to patients and how to select among\nmultiple treatments over time are important medical problems with a few\nexisting solutions. In this paper, we introduce the Counterfactual Recurrent\nNetwork (CRN), a novel sequence-to-sequence model that leverages the\nincreasingly available patient observational data to estimate treatment effects\nover time and answer such medical questions. To handle the bias from\ntime-varying confounders, covariates affecting the treatment assignment policy\nin the observational data, CRN uses domain adversarial training to build\nbalancing representations of the patient history. At each timestep, CRN\nconstructs a treatment invariant representation which removes the association\nbetween patient history and treatment assignments and thus can be reliably used\nfor making counterfactual predictions. On a simulated model of tumour growth,\nwith varying degree of time-dependent confounding, we show how our model\nachieves lower error in estimating counterfactuals and in choosing the correct\ntreatment and timing of treatment than current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:47:36 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bica", "Ioana", ""], ["Alaa", "Ahmed M.", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2002.04094", "submitter": "Subhro Das", "authors": "Subhro Das, Prasanth Lade, Soundar Srinivasan", "title": "Model adaptation and unsupervised learning with non-stationary batch\n  data under smooth concept drift", "comments": "11 pages, 4 figures, 3 tables, 2016 NIPS Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most predictive models assume that training and test data are generated from\na stationary process. However, this assumption does not hold true in practice.\nIn this paper, we consider the scenario of a gradual concept drift due to the\nunderlying non-stationarity of the data source. While previous work has\ninvestigated this scenario under a supervised-learning and adaption conditions,\nfew have addressed the common, real-world scenario when labels are only\navailable during training. We propose a novel, iterative algorithm for\nunsupervised adaptation of predictive models. We show that the performance of\nour batch adapted prediction algorithm is better than that of its corresponding\nunadapted version. The proposed algorithm provides similar (or better, in most\ncases) performance within significantly less run time compared to other state\nof the art methods. We validate our claims though extensive numerical\nevaluations on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:29:09 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Das", "Subhro", ""], ["Lade", "Prasanth", ""], ["Srinivasan", "Soundar", ""]]}, {"id": "2002.04108", "submitter": "Swabha Swayamdipta", "authors": "Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers,\n  Matthew E. Peters, Ashish Sabharwal, Yejin Choi", "title": "Adversarial Filters of Dataset Biases", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural models have demonstrated human-level performance on language and\nvision benchmarks, while their performance degrades considerably on adversarial\nor out-of-distribution samples. This raises the question of whether these\nmodels have learned to solve a dataset rather than the underlying task by\noverfitting to spurious dataset biases. We investigate one recently proposed\napproach, AFLite, which adversarially filters such dataset biases, as a means\nto mitigate the prevalent overestimation of machine performance. We provide a\ntheoretical understanding for AFLite, by situating it in the generalized\nframework for optimum bias reduction. We present extensive supporting evidence\nthat AFLite is broadly applicable for reduction of measurable dataset biases,\nand that models trained on the filtered datasets yield better generalization to\nout-of-distribution tasks. Finally, filtering results in a large drop in model\nperformance (e.g., from 92% to 62% for SNLI), while human performance still\nremains high. Our work thus shows that such filtered datasets can pose new\nresearch challenges for robust generalization by serving as upgraded\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:59:21 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:37:37 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 00:44:43 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bras", "Ronan Le", ""], ["Swayamdipta", "Swabha", ""], ["Bhagavatula", "Chandra", ""], ["Zellers", "Rowan", ""], ["Peters", "Matthew E.", ""], ["Sabharwal", "Ashish", ""], ["Choi", "Yejin", ""]]}, {"id": "2002.04116", "submitter": "Weiwen Jiang", "authors": "Lei Yang, Zheyu Yan, Meng Li, Hyoukjun Kwon, Liangzhen Lai, Tushar\n  Krishna, Vikas Chandra, Weiwen Jiang, Yiyu Shi", "title": "Co-Exploration of Neural Architectures and Heterogeneous ASIC\n  Accelerator Designs Targeting Multiple Tasks", "comments": "Accepted by DAC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has demonstrated its power on various AI\naccelerating platforms such as Field Programmable Gate Arrays (FPGAs) and\nGraphic Processing Units (GPUs). However, it remains an open problem, how to\nintegrate NAS with Application-Specific Integrated Circuits (ASICs), despite\nthem being the most powerful AI accelerating platforms. The major bottleneck\ncomes from the large design freedom associated with ASIC designs. Moreover,\nwith the consideration that multiple DNNs will run in parallel for different\nworkloads with diverse layer operations and sizes, integrating heterogeneous\nASIC sub-accelerators for distinct DNNs in one design can significantly boost\nperformance, and at the same time further complicate the design space. To\naddress these challenges, in this paper we build ASIC template set based on\nexisting successful designs, described by their unique dataflows, so that the\ndesign space is significantly reduced. Based on the templates, we further\npropose a framework, namely NASAIC, which can simultaneously identify multiple\nDNN architectures and the associated heterogeneous ASIC accelerator design,\nsuch that the design specifications (specs) can be satisfied, while the\naccuracy can be maximized. Experimental results show that compared with\nsuccessive NAS and ASIC design optimizations which lead to design spec\nviolations, NASAIC can guarantee the results to meet the design specs with\n17.77%, 2.49x, and 2.32x reductions on latency, energy, and area and with 0.76%\naccuracy loss. To the best of the authors' knowledge, this is the first work on\nneural architecture and ASIC accelerator design co-exploration.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:22:19 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Yang", "Lei", ""], ["Yan", "Zheyu", ""], ["Li", "Meng", ""], ["Kwon", "Hyoukjun", ""], ["Lai", "Liangzhen", ""], ["Krishna", "Tushar", ""], ["Chandra", "Vikas", ""], ["Jiang", "Weiwen", ""], ["Shi", "Yiyu", ""]]}, {"id": "2002.04121", "submitter": "Kevin Tian", "authors": "Yin Tat Lee, Ruoqi Shen, Kevin Tian", "title": "Logsmooth Gradient Concentration and Tighter Runtimes for Metropolized\n  Hamiltonian Monte Carlo", "comments": "31 pages. v2 propagates changes from COLT 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the gradient norm $\\|\\nabla f(x)\\|$ for $x \\sim \\exp(-f(x))$,\nwhere $f$ is strongly convex and smooth, concentrates tightly around its mean.\nThis removes a barrier in the prior state-of-the-art analysis for the\nwell-studied Metropolized Hamiltonian Monte Carlo (HMC) algorithm for sampling\nfrom a strongly logconcave distribution. We correspondingly demonstrate that\nMetropolized HMC mixes in $\\tilde{O}(\\kappa d)$ iterations, improving upon the\n$\\tilde{O}(\\kappa^{1.5}\\sqrt{d} + \\kappa d)$ runtime of (Dwivedi et. al. '18,\nChen et. al. '19) by a factor $(\\kappa/d)^{1/2}$ when the condition number\n$\\kappa$ is large. Our mixing time analysis introduces several techniques which\nto our knowledge have not appeared in the literature and may be of independent\ninterest, including restrictions to a nonconvex set with good conductance\nbehavior, and a new reduction technique for boosting a constant-accuracy total\nvariation guarantee under weak warmness assumptions. This is the first\nhigh-accuracy mixing time result for logconcave distributions using only\nfirst-order function information which achieves linear dependence on $\\kappa$;\nwe also give evidence that this dependence is likely to be necessary for\nstandard Metropolized first-order methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:44:50 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 05:24:03 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 02:12:45 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lee", "Yin Tat", ""], ["Shen", "Ruoqi", ""], ["Tian", "Kevin", ""]]}, {"id": "2002.04127", "submitter": "Maria Ines Silva", "authors": "Maria In\\^es Silva and Roberto Henriques", "title": "Finding manoeuvre motifs in vehicle telematics", "comments": "11 pages, 3 figures, submitted to Accident Analysis & Prevention", "journal-ref": null, "doi": "10.1016/j.aap.2020.105467", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driving behaviour has a great impact on road safety. A popular way of\nanalysing driving behaviour is to move the focus to the manoeuvres as they give\nuseful information about the driver who is performing them. In this paper, we\ninvestigate a new way of identifying manoeuvres from vehicle telematics data,\nthrough motif detection in time-series. We implement a modified version of the\nExtended Motif Discovery (EMD) algorithm, a classical variable-length motif\ndetection algorithm for time-series and we applied it to the UAH-DriveSet, a\npublicly available naturalistic driving dataset. After a systematic exploration\nof the extracted motifs, we were able to conclude that the EMD algorithm was\nnot only capable of extracting simple manoeuvres such as accelerations, brakes\nand curves, but also more complex manoeuvres, such as lane changes and\novertaking manoeuvres, which validates motif discovery as a worthwhile line for\nfuture research.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:07:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Silva", "Maria In\u00eas", ""], ["Henriques", "Roberto", ""]]}, {"id": "2002.04131", "submitter": "Haotian Gu", "authors": "Haotian Gu, Xin Guo, Xiaoli Wei, Renyuan Xu", "title": "Mean-Field Controls with Q-learning for Cooperative MARL: Convergence\n  and Complexity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL), despite its popularity and\nempirical success, suffers from the curse of dimensionality. This paper builds\nthe mathematical framework to approximate cooperative MARL by a mean-field\ncontrol (MFC) framework, and shows that the approximation error is of\n$O(\\frac{1}{\\sqrt{N}})$. By establishing appropriate form of the dynamic\nprogramming principle for both the value function and the Q function, it\nproposes a model-free kernel-based Q-learning algorithm (MFC-K-Q), which is\nshown to be of linear convergence rate, the first of its kind in the MARL\nliterature. It further establishes that the convergence rate and the sample\ncomplexity of MFC-K-Q are independent of the number of agents $N$. Empirical\nstudies for the network traffic congestion problem demonstrate that MFC-K-Q\noutperforms existing MARL algorithms when $N$ is large, for instance when\n$N>50$.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:30:39 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 22:47:46 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 21:22:10 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gu", "Haotian", ""], ["Guo", "Xin", ""], ["Wei", "Xiaoli", ""], ["Xu", "Renyuan", ""]]}, {"id": "2002.04137", "submitter": "Zifan Liu", "authors": "Zifan Liu and Jongho Park and Theodoros Rekatsinas and Christos Tzamos", "title": "On Robust Mean Estimation under Coordinate-level Corruption", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robust mean estimation and introduce a novel Hamming\ndistance-based measure of distribution shift for coordinate-level corruptions.\nWe show that this measure yields adversary models that capture more realistic\ncorruptions than those used in prior works, and present an\ninformation-theoretic analysis of robust mean estimation in these settings. We\nshow that for structured distributions, methods that leverage the structure\nyield information theoretically more accurate mean estimation. We also focus on\npractical algorithms for robust mean estimation and study when data\ncleaning-inspired approaches that first fix corruptions in the input data and\nthen perform robust mean estimation can match the information theoretic bounds\nof our analysis. We finally demonstrate experimentally that this two-step\napproach outperforms structure-agnostic robust estimation and provides accurate\nmean estimation even for high-magnitude corruption.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:48:50 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 18:47:37 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 18:01:16 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 06:51:52 GMT"}, {"version": "v5", "created": "Fri, 11 Jun 2021 03:26:42 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Zifan", ""], ["Park", "Jongho", ""], ["Rekatsinas", "Theodoros", ""], ["Tzamos", "Christos", ""]]}, {"id": "2002.04138", "submitter": "Joseph Janizek", "authors": "Joseph D. Janizek, Pascal Sturmfels, Su-In Lee", "title": "Explaining Explanations: Axiomatic Feature Interactions for Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown great promise in explaining neural network behavior. In\nparticular, feature attribution methods explain which features were most\nimportant to a model's prediction on a given input. However, for many tasks,\nsimply knowing which features were important to a model's prediction may not\nprovide enough insight to understand model behavior. The interactions between\nfeatures within the model may better help us understand not only the model, but\nalso why certain features are more important than others. In this work, we\npresent Integrated Hessians, an extension of Integrated Gradients that explains\npairwise feature interactions in neural networks. Integrated Hessians overcomes\nseveral theoretical limitations of previous methods to explain interactions,\nand unlike such previous methods is not limited to a specific architecture or\nclass of neural network. Additionally, we find that our method is faster than\nexisting methods when the number of features is large, and outperforms previous\nmethods on existing quantitative benchmarks. Code available at\nhttps://github.com/suinleelab/path_explain\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:49:00 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:00:08 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:54:05 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Janizek", "Joseph D.", ""], ["Sturmfels", "Pascal", ""], ["Lee", "Su-In", ""]]}, {"id": "2002.04151", "submitter": "Vojtech Kejzlar", "authors": "Vojtech Kejzlar, L\\'eo Neufcourt, Witold Nazarewicz, Paul-Gerhard\n  Reinhard", "title": "Statistical aspects of nuclear mass models", "comments": "Accepted for publication in J. Phys. G Focus Issue on \"Focus on\n  further enhancing the interaction between nuclear experiment and theory\n  through information and statistics (ISNET 2.0),\"", "journal-ref": null, "doi": "10.1088/1361-6471/ab907c", "report-no": null, "categories": "nucl-th stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the information content of nuclear masses from the perspective of\nglobal models of nuclear binding energies. To this end, we employ a number of\nstatistical methods and diagnostic tools, including Bayesian calibration,\nBayesian model averaging, chi-square correlation analysis, principal component\nanalysis, and empirical coverage probability. Using a Bayesian framework, we\ninvestigate the structure of the 4-parameter Liquid Drop Model by considering\ndiscrepant mass domains for calibration. We then use the chi-square correlation\nframework to analyze the 14-parameter Skyrme energy density functional\ncalibrated using homogeneous and heterogeneous datasets. We show that a quite\ndramatic parameter reduction can be achieved in both cases. The advantage of\nBayesian model averaging for improving uncertainty quantification is\ndemonstrated. The statistical approaches used are pedagogically described; in\nthis context this work can serve as a guide for future applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 00:47:22 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:45:36 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 00:39:02 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kejzlar", "Vojtech", ""], ["Neufcourt", "L\u00e9o", ""], ["Nazarewicz", "Witold", ""], ["Reinhard", "Paul-Gerhard", ""]]}, {"id": "2002.04155", "submitter": "Joel Dabrowski Dr", "authors": "Joel Janek Dabrowski, YiFan Zhang, Ashfaqur Rahman", "title": "ForecastNet: A Time-Variant Deep Feed-Forward Neural Network\n  Architecture for Multi-Step-Ahead Time-Series Forecasting", "comments": null, "journal-ref": "Neural Information Processing. ICONIP 2020", "doi": "10.1007/978-3-030-63836-8_48", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent and convolutional neural networks are the most common architectures\nused for time series forecasting in deep learning literature. These networks\nuse parameter sharing by repeating a set of fixed architectures with fixed\nparameters over time or space. The result is that the overall architecture is\ntime-invariant (shift-invariant in the spatial domain) or stationary. We argue\nthat time-invariance can reduce the capacity to perform multi-step-ahead\nforecasting, where modelling the dynamics at a range of scales and resolutions\nis required. We propose ForecastNet which uses a deep feed-forward architecture\nto provide a time-variant model. An additional novelty of ForecastNet is\ninterleaved outputs, which we show assist in mitigating vanishing gradients.\nForecastNet is demonstrated to outperform statistical and deep learning\nbenchmark models on several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:03:33 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 23:24:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Dabrowski", "Joel Janek", ""], ["Zhang", "YiFan", ""], ["Rahman", "Ashfaqur", ""]]}, {"id": "2002.04156", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, and A. Salman Avestimehr", "title": "Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed framework for training machine learning\nmodels over the data residing at mobile devices, while protecting the privacy\nof individual users. A major bottleneck in scaling federated learning to a\nlarge number of users is the overhead of secure model aggregation across many\nusers. In particular, the overhead of the state-of-the-art protocols for secure\nmodel aggregation grows quadratically with the number of users. In this paper,\nwe propose the first secure aggregation framework, named Turbo-Aggregate, that\nin a network with $N$ users achieves a secure aggregation overhead of\n$O(N\\log{N})$, as opposed to $O(N^2)$, while tolerating up to a user dropout\nrate of $50\\%$. Turbo-Aggregate employs a multi-group circular strategy for\nefficient model aggregation, and leverages additive secret sharing and novel\ncoding techniques for injecting aggregation redundancy in order to handle user\ndropouts while guaranteeing user privacy. We experimentally demonstrate that\nTurbo-Aggregate achieves a total running time that grows almost linear in the\nnumber of users, and provides up to $40\\times$ speedup over the\nstate-of-the-art protocols with up to $N=200$ users. Our experiments also\ndemonstrate the impact of model size and bandwidth on the performance of\nTurbo-Aggregate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:15:41 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 16:52:26 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 20:20:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2002.04162", "submitter": "Avinash Ravichandran", "authors": "Qing Liu, Orchid Majumder, Alessandro Achille, Avinash Ravichandran,\n  Rahul Bhotika, Stefano Soatto", "title": "Incremental Meta-Learning via Indirect Discriminant Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the modern meta-learning methods for few-shot classification\ntasks operate in two phases: a meta-training phase where the meta-learner\nlearns a generic representation by solving multiple few-shot tasks sampled from\na large dataset and a testing phase, where the meta-learner leverages its\nlearnt internal representation for a specific few-shot task involving classes\nwhich were not seen during the meta-training phase. To the best of our\nknowledge, all such meta-learning methods use a single base dataset for\nmeta-training to sample tasks from and do not adapt the algorithm after\nmeta-training. This strategy may not scale to real-world use-cases where the\nmeta-learner does not potentially have access to the full meta-training dataset\nfrom the very beginning and we need to update the meta-learner in an\nincremental fashion when additional training data becomes available. Through\nour experimental setup, we develop a notion of incremental learning during the\nmeta-training phase of meta-learning and propose a method which can be used\nwith multiple existing metric-based meta-learning algorithms. Experimental\nresults on benchmark dataset show that our approach performs favorably at test\ntime as compared to training a model with the full meta-training set and incurs\nnegligible amount of catastrophic forgetting\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:39:12 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 18:19:18 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Liu", "Qing", ""], ["Majumder", "Orchid", ""], ["Achille", "Alessandro", ""], ["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2002.04180", "submitter": "Chonggang Song", "authors": "Chonggang Song, Qian Lin, Guohui Ling, Zongyi Zhang, Hongzhao Chen,\n  Jun Liao, Chuan Chen", "title": "LoCEC: Local Community-based Edge Classification in Large Online Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relationships in online social networks often imply social connections in the\nreal world. An accurate understanding of relationship types benefits many\napplications, e.g. social advertising and recommendation. Some recent attempts\nhave been proposed to classify user relationships into predefined types with\nthe help of pre-labeled relationships or abundant interaction features on\nrelationships. Unfortunately, both relationship feature data and label data are\nvery sparse in real social platforms like WeChat, rendering existing methods\ninapplicable. In this paper, we present an in-depth analysis of WeChat\nrelationships to identify the major challenges for the relationship\nclassification task. To tackle the challenges, we propose a Local\nCommunity-based Edge Classification (LoCEC) framework that classifies user\nrelationships in a social network into real-world social connection types.\nLoCEC enforces a three-phase processing, namely local community detection,\ncommunity classification and relationship classification, to address the\nsparsity issue of relationship features and relationship labels. Moreover,\nLoCEC is designed to handle large-scale networks by allowing parallel and\ndistributed processing. We conduct extensive experiments on the real-world\nWeChat network with hundreds of billions of edges to validate the effectiveness\nand efficiency of LoCEC.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 02:58:56 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 05:53:26 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Song", "Chonggang", ""], ["Lin", "Qian", ""], ["Ling", "Guohui", ""], ["Zhang", "Zongyi", ""], ["Chen", "Hongzhao", ""], ["Liao", "Jun", ""], ["Chen", "Chuan", ""]]}, {"id": "2002.04185", "submitter": "Casey Chu", "authors": "Casey Chu, Kentaro Minami, Kenji Fukumizu", "title": "Smoothness and Stability in GANs", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks, or GANs, commonly display unstable behavior\nduring training. In this work, we develop a principled theoretical framework\nfor understanding the stability of various types of GANs. In particular, we\nderive conditions that guarantee eventual stationarity of the generator when it\nis trained with gradient descent, conditions that must be satisfied by the\ndivergence that is minimized by the GAN and the generator's architecture. We\nfind that existing GAN variants satisfy some, but not all, of these conditions.\nUsing tools from convex analysis, optimal transport, and reproducing kernels,\nwe construct a GAN that fulfills these conditions simultaneously. In the\nprocess, we explain and clarify the need for various existing GAN stabilization\ntechniques, including Lipschitz constraints, gradient penalties, and smooth\nactivation functions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:08:28 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Chu", "Casey", ""], ["Minami", "Kentaro", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2002.04186", "submitter": "Jianfei Gao", "authors": "Jianfei Gao, Mohamed A. Zahran, Amit Sheoran, Sonia Fahmy, Bruno\n  Ribeiro", "title": "Infinity Learning: Learning Markov Chains from Aggregate Steady-State\n  Observations", "comments": null, "journal-ref": "Published as a conference paper at the Thirty-Fourth AAAI\n  Conference on Artificial Intelligence (AAAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider the task of learning a parametric Continuous Time Markov Chain\n(CTMC) sequence model without examples of sequences, where the training data\nconsists entirely of aggregate steady-state statistics. Making the problem\nharder, we assume that the states we wish to predict are unobserved in the\ntraining data. Specifically, given a parametric model over the transition rates\nof a CTMC and some known transition rates, we wish to extrapolate its steady\nstate distribution to states that are unobserved. A technical roadblock to\nlearn a CTMC from its steady state has been that the chain rule to compute\ngradients will not work over the arbitrarily long sequences necessary to reach\nsteady state ---from where the aggregate statistics are sampled. To overcome\nthis optimization challenge, we propose $\\infty$-SGD, a principled stochastic\ngradient descent method that uses randomly-stopped estimators to avoid infinite\nsums required by the steady state computation, while learning even when only a\nsubset of the CTMC states can be observed. We apply $\\infty$-SGD to a\nreal-world testbed and synthetic experiments showcasing its accuracy, ability\nto extrapolate the steady state distribution to unobserved states under\nunobserved conditions (heavy loads, when training under light loads), and\nsucceeding in difficult scenarios where even a tailor-made extension of\nexisting methods fails.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:29:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Jianfei", ""], ["Zahran", "Mohamed A.", ""], ["Sheoran", "Amit", ""], ["Fahmy", "Sonia", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2002.04189", "submitter": "Rohit Jammula", "authors": "Rohit Jammula, Vishnu Rajan Tejus, Shreya Shankar", "title": "Optimal Transfer Learning Model for Binary Classification of Funduscopic\n  Images through Simple Heuristics", "comments": "5 pages. 4 tables. Accepted to present in Machine Learning in\n  Computational Biology (MLCB) 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have the capacity to fundamentally revolutionize medical\nimaging analysis, and they have particularly interesting applications in\ncomputer-aided diagnosis. We attempt to use deep learning neural networks to\ndiagnose funduscopic images, visual representations of the interior of the eye.\nRecently, a few robust deep learning approaches have performed binary\nclassification to infer the presence of a specific ocular disease, such as\nglaucoma or diabetic retinopathy. In an effort to broaden the applications of\ncomputer-aided ocular disease diagnosis, we propose a unifying model for\ndisease classification: low-cost inference of a fundus image to determine\nwhether it is healthy or diseased. To achieve this, we use transfer learning\ntechniques, which retain the more overarching capabilities of a pre-trained\nbase architecture but can adapt to another dataset. For comparisons, we then\ndevelop a custom heuristic equation and evaluation metric ranking system to\ndetermine the optimal base architecture and hyperparameters. The Xception base\narchitecture, Adam optimizer, and mean squared error loss function perform\nbest, achieving 90% accuracy, 94% sensitivity, and 86% specificity. For\nadditional ease of use, we contain the model in a web interface whose file\nchooser can access the local filesystem, allowing for use on any\ninternet-connected device: mobile, PC, or otherwise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:49:14 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:33:06 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 21:41:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jammula", "Rohit", ""], ["Tejus", "Vishnu Rajan", ""], ["Shankar", "Shreya", ""]]}, {"id": "2002.04193", "submitter": "Zeqian Li", "authors": "Zeqian Li, Michael C. Mozer, Jacob Whitehill", "title": "Compositional Embeddings for Multi-Label One-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a compositional embedding framework that infers not just a single\nclass per input image, but a set of classes, in the setting of one-shot\nlearning. Specifically, we propose and evaluate several novel models consisting\nof (1) an embedding function f trained jointly with a \"composition\" function g\nthat computes set union operations between the classes encoded in two embedding\nvectors; and (2) embedding f trained jointly with a \"query\" function h that\ncomputes whether the classes encoded in one embedding subsume the classes\nencoded in another embedding. In contrast to prior work, these models must both\nperceive the classes associated with the input examples and encode the\nrelationships between different class label sets, and they are trained using\nonly weak one-shot supervision consisting of the label-set relationships among\ntraining examples. Experiments on the OmniGlot, Open Images, and COCO datasets\nshow that the proposed compositional embedding models outperform existing\nembedding methods. Our compositional embedding models have applications to\nmulti-label object recognition for both one-shot and supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:54:30 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:10:02 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 17:54:56 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 20:01:24 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 14:31:59 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Li", "Zeqian", ""], ["Mozer", "Michael C.", ""], ["Whitehill", "Jacob", ""]]}, {"id": "2002.04195", "submitter": "Shahin Shahrampour", "authors": "Liang Ding, Rui Tuo, Shahin Shahrampour", "title": "Generalization Guarantees for Sparse Kernel Approximation with Entropic\n  Optimal Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their success, kernel methods suffer from a massive computational\ncost in practice. In this paper, in lieu of commonly used kernel expansion with\nrespect to $N$ inputs, we develop a novel optimal design maximizing the entropy\namong kernel features. This procedure results in a kernel expansion with\nrespect to entropic optimal features (EOF), improving the data representation\ndramatically due to features dissimilarity. Under mild technical assumptions,\nour generalization bound shows that with only $O(N^{\\frac{1}{4}})$ features\n(disregarding logarithmic factors), we can achieve the optimal statistical\naccuracy (i.e., $O(1/\\sqrt{N})$). The salient feature of our design is its\nsparsity that significantly reduces the time and space cost. Our numerical\nexperiments on benchmark datasets verify the superiority of EOF over the\nstate-of-the-art in kernel approximation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 04:12:31 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Ding", "Liang", ""], ["Tuo", "Rui", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2002.04197", "submitter": "Zac Cranko", "authors": "Zac Cranko, Zhan Shi, Xinhua Zhang, Richard Nock, Simon Kornblith", "title": "Generalised Lipschitz Regularisation Equals Distributional Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial examples has highlighted the need for a theory of\nregularisation that is general enough to apply to exotic function classes, such\nas universal approximators. In response, we give a very general equality result\nregarding the relationship between distributional robustness and\nregularisation, as defined with a transportation cost uncertainty set. The\ntheory allows us to (tightly) certify the robustness properties of a\nLipschitz-regularised model with very mild assumptions. As a theoretical\napplication we show a new result explicating the connection between adversarial\nlearning and distributional robustness. We then give new results for how to\nachieve Lipschitz regularisation of kernel classifiers, which are demonstrated\nexperimentally.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 04:19:43 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Cranko", "Zac", ""], ["Shi", "Zhan", ""], ["Zhang", "Xinhua", ""], ["Nock", "Richard", ""], ["Kornblith", "Simon", ""]]}, {"id": "2002.04205", "submitter": "Rahul Soni", "authors": "Rahul Soni, Naresh Shah, Jimmy D. Moore", "title": "Fine-grained Uncertainty Modeling in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing uncertainty modeling approaches try to detect an out-of-distribution\npoint from the in-distribution dataset. We extend this argument to detect\nfiner-grained uncertainty that distinguishes between (a). certain points, (b).\nuncertain points but within the data distribution, and (c). out-of-distribution\npoints. Our method corrects overconfident NN decisions, detects outlier points\nand learns to say ``I don't know'' when uncertain about a critical point\nbetween the top two predictions. In addition, we provide a mechanism to\nquantify class distributions overlap in the decision manifold and investigate\nits implications in model interpretability.\n  Our method is two-step: in the first step, the proposed method builds a class\ndistribution using Kernel Activation Vectors (kav) extracted from the Network.\nIn the second step, the algorithm determines the confidence of a test point by\na hierarchical decision rule based on the chi-squared distribution of squared\nMahalanobis distances.\n  Our method sits on top of a given Neural Network, requires a single scan of\ntraining data to estimate class distribution statistics, and is highly scalable\nto deep networks and wider pre-softmax layer. As a positive side effect, our\nmethod helps to prevent adversarial attacks without requiring any additional\ntraining. It is directly achieved when the Softmax layer is substituted by our\nrobust uncertainty layer at the evaluation phase.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 05:06:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Soni", "Rahul", ""], ["Shah", "Naresh", ""], ["Moore", "Jimmy D.", ""]]}, {"id": "2002.04232", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Ashwin Maran,\n  N. V. Vinodchandran", "title": "Learning and Sampling of Atomic Interventions from Observations", "comments": "26 pages, 4 figures, a version appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficiently estimating the effect of an intervention\non a single variable (atomic interventions) using observational samples in a\ncausal Bayesian network. Our goal is to give algorithms that are efficient in\nboth time and sample complexity in a non-parametric setting.\n  Tian and Pearl (AAAI `02) have exactly characterized the class of causal\ngraphs for which causal effects of atomic interventions can be identified from\nobservational data. We make their result quantitative. Suppose P is a causal\nmodel on a set $\\vec{V}$ of n observable variables with respect to a given\ncausal graph G with observable distribution $P$. Let $P_x$ denote the\ninterventional distribution over the observables with respect to an\nintervention of a designated variable X with x. Assuming that $G$ has bounded\nin-degree, bounded c-components ($k$), and that the observational distribution\nis identifiable and satisfies certain strong positivity condition, we give an\nalgorithm that takes $m=\\tilde{O}(n\\epsilon^{-2})$ samples from $P$ and $O(mn)$\ntime, and outputs with high probability a description of a distribution\n$\\hat{P}$ such that $d_{\\mathrm{TV}}(P_x, \\hat{P}) \\leq \\epsilon$, and:\n  1. [Evaluation] the description can return in $O(n)$ time the probability\n$\\hat{P}(\\vec{v})$ for any assignment $\\vec{v}$ to $\\vec{V}$\n  2. [Generation] the description can return an iid sample from $\\hat{P}$ in\n$O(n)$ time.\n  We also show lower bounds for the sample complexity showing that our sample\ncomplexity has an optimal dependence on the parameters $n$ and $\\epsilon$, as\nwell as if $k=1$ on the strong positivity parameter.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:15:32 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 06:11:17 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Kandasamy", "Saravanan", ""], ["Maran", "Ashwin", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2002.04235", "submitter": "Xiangfeng Wang", "authors": "Junjie Sheng, Xiangfeng Wang, Bo Jin, Junchi Yan, Wenhao Li, Tsung-Hui\n  Chang, Jun Wang, Hongyuan Zha", "title": "Learning Structured Communication for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the large-scale multi-agent communication mechanism under\na multi-agent reinforcement learning (MARL) setting. We summarize the general\ncategories of topology for communication structures in MARL literature, which\nare often manually specified. Then we propose a novel framework termed as\nLearning Structured Communication (LSC) by using a more flexible and efficient\ncommunication topology. Our framework allows for adaptive agent grouping to\nform different hierarchical formations over episodes, which is generated by an\nauxiliary task combined with a hierarchical routing protocol. Given each formed\ntopology, a hierarchical graph neural network is learned to enable effective\nmessage information generation and propagation among inter- and intra-group\ncommunications. In contrast to existing communication mechanisms, our method\nhas an explicit while learnable design for hierarchical communication.\nExperiments on challenging tasks show the proposed LSC enjoys high\ncommunication efficiency, scalability, and global cooperation capability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:19:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Sheng", "Junjie", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Yan", "Junchi", ""], ["Li", "Wenhao", ""], ["Chang", "Tsung-Hui", ""], ["Wang", "Jun", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.04236", "submitter": "Ane Bl\\'azquez-Garc\\'ia", "authors": "Ane Bl\\'azquez-Garc\\'ia, Angel Conde, Usue Mori, Jose A. Lozano", "title": "A review on outlier/anomaly detection in time series data", "comments": "32 pages, 21 figures, submitted to ACM Computing Surveys (CSUR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in technology have brought major breakthroughs in data\ncollection, enabling a large amount of data to be gathered over time and thus\ngenerating time series. Mining this data has become an important task for\nresearchers and practitioners in the past few years, including the detection of\noutliers or anomalies that may represent errors or events of interest. This\nreview aims to provide a structured and comprehensive state-of-the-art on\noutlier detection techniques in the context of time series. To this end, a\ntaxonomy is presented based on the main aspects that characterize an outlier\ndetection technique.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:25:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bl\u00e1zquez-Garc\u00eda", "Ane", ""], ["Conde", "Angel", ""], ["Mori", "Usue", ""], ["Lozano", "Jose A.", ""]]}, {"id": "2002.04237", "submitter": "Sidharth Gupta", "authors": "Sidharth Gupta, Parijat Dube, Ashish Verma", "title": "Improving the affordability of robustness training for DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projected Gradient Descent (PGD) based adversarial training has become one of\nthe most prominent methods for building robust deep neural network models.\nHowever, the computational complexity associated with this approach, due to the\nmaximization of the loss function when finding adversaries, is a longstanding\nproblem and may be prohibitive when using larger and more complex models. In\nthis paper we show that the initial phase of adversarial training is redundant\nand can be replaced with natural training which significantly improves the\ncomputational efficiency. We demonstrate that this efficiency gain can be\nachieved without any loss in accuracy on natural and adversarial test samples.\nWe support our argument with insights on the nature of the adversaries and\ntheir relative strength during the training process. We show that our proposed\nmethod can reduce the training time by a factor of up to 2.5 with comparable or\nbetter model test accuracy and generalization on various strengths of\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:29:45 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 04:17:09 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Gupta", "Sidharth", ""], ["Dube", "Parijat", ""], ["Verma", "Ashish", ""]]}, {"id": "2002.04238", "submitter": "Xiangfeng Wang", "authors": "Yun Hua, Xiangfeng Wang, Bo Jin, Wenhao Li, Junchi Yan, Xiaofeng He,\n  Hongyuan Zha", "title": "HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning\n  Problem", "comments": "13 pages", "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the success of existing meta reinforcement learning methods, they\nstill have difficulty in learning a meta policy effectively for RL problems\nwith sparse reward. In this respect, we develop a novel meta reinforcement\nlearning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems.\nIt is consisted with three modules including the cross-environment meta state\nembedding module which constructs a common meta state space to adapt to\ndifferent environments; the meta state based environment-specific meta reward\nshaping which effectively extends the original sparse reward trajectory by\ncross-environmental knowledge complementarity and as a consequence the meta\npolicy achieves better generalization and efficiency with the shaped meta\nreward. Experiments with sparse-reward environments show the superiority of\nHMRL on both transferability and policy learning efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:31:11 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 06:36:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hua", "Yun", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Li", "Wenhao", ""], ["Yan", "Junchi", ""], ["He", "Xiaofeng", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.04254", "submitter": "Joseph Lam-Weil", "authors": "Joseph Lam-Weil, B\\'eatrice Laurent, Jean-Michel Loubes", "title": "Minimax optimal goodness-of-fit testing for densities and multinomials\n  under a local differential privacy constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding anonymization mechanisms to protect personal data is at the heart of\nrecent machine learning research. Here, we consider the consequences of local\ndifferential privacy constraints on goodness-of-fit testing, i.e. the\nstatistical problem assessing whether sample points are generated from a fixed\ndensity $f_0$, or not. The observations are kept hidden and replaced by a\nstochastic transformation satisfying the local differential privacy constraint.\nIn this setting, we propose a testing procedure which is based on an estimation\nof the quadratic distance between the density $f$ of the unobserved samples and\n$f_0$. We establish an upper bound on the separation distance associated with\nthis test, and a matching lower bound on the minimax separation rates of\ntesting under non-interactive privacy in the case that $f_0$ is uniform, in\ndiscrete and continuous settings. To the best of our knowledge, we provide the\nfirst minimax optimal test and associated private transformation under a local\ndifferential privacy constraint over Besov balls in the continuous setting,\nquantifying the price to pay for data privacy. We also present a test that is\nadaptive to the smoothness parameter of the unknown density and remains minimax\noptimal up to a logarithmic factor. Finally, we note that our results can be\ntranslated to the discrete case, where the treatment of probability vectors is\nshown to be equivalent to that of piecewise constant densities in our setting.\nThat is why we work with a unified setting for both the continuous and the\ndiscrete cases.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:41:05 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 08:53:58 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 07:12:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Lam-Weil", "Joseph", ""], ["Laurent", "B\u00e9atrice", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "2002.04258", "submitter": "Manuel Gomez Rodriguez", "authors": "Vahid Balazadeh Meresht and Abir De and Adish Singla and Manuel\n  Gomez-Rodriguez", "title": "Learning to Switch Between Machines and Humans", "comments": "Added support for unknown transition probabilities and multiple teams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents have been mostly developed and evaluated under\nthe assumption that they will operate in a fully autonomous manner -- they will\ntake all actions. In this work, our goal is to develop algorithms that, by\nlearning to switch control between machine and human agents, allow existing\nreinforcement learning agents to operate under different automation levels. To\nthis end, we first formally define the problem of learning to switch control\namong agents in a team via a 2-layer Markov decision process. Then, we develop\nan online learning algorithm that uses upper confidence bounds on the agents'\npolicies and the environment's transition probabilities to find a sequence of\nswitching policies. We prove that the total regret of our algorithm with\nrespect to the optimal switching policy is sublinear in the number of learning\nsteps. Moreover, we also show that our algorithm can be used to find multiple\nsequences of switching policies across several independent teams of agents\noperating in similar environments, where it greatly benefits from maintaining\nshared confidence bounds for the environments' transition probabilities.\nSimulation experiments in obstacle avoidance in a semi-autonomous driving\nscenario illustrate our theoretical findings and demonstrate that, by\nexploiting the specific structure of the problem, our proposed algorithm is\nsuperior to problem-agnostic algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:50:52 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 08:43:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Meresht", "Vahid Balazadeh", ""], ["De", "Abir", ""], ["Singla", "Adish", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2002.04267", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska and Przemyslaw Biecek", "title": "Lifting Interpretability-Performance Trade-off via Automated Feature\n  Engineering", "comments": "12 pages, 5 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1902.11035", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex black-box predictive models may have high performance, but lack of\ninterpretability causes problems like lack of trust, lack of stability,\nsensitivity to concept drift. On the other hand, achieving satisfactory\naccuracy of interpretable models require more time-consuming work related to\nfeature engineering. Can we train interpretable and accurate models, without\ntimeless feature engineering? We propose a method that uses elastic black-boxes\nas surrogate models to create a simpler, less opaque, yet still accurate and\ninterpretable glass-box models. New models are created on newly engineered\nfeatures extracted with the help of a surrogate model. We supply the analysis\nby a large-scale benchmark on several tabular data sets from the OpenML\ndatabase. There are two results 1) extracting information from complex models\nmay improve the performance of linear models, 2) questioning a common myth that\ncomplex machine learning models outperform linear models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:16:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2002.04274", "submitter": "Nanyi Fei", "authors": "Nanyi Fei, Zhiwu Lu, Yizhao Gao, Jia Tian, Tao Xiang and Ji-Rong Wen", "title": "Meta-Learning across Meta-Tasks for Few-Shot Learning", "comments": "There are some mistakes in the experiments. We thus choose to\n  withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing meta-learning based few-shot learning (FSL) methods typically adopt\nan episodic training strategy whereby each episode contains a meta-task. Across\nepisodes, these tasks are sampled randomly and their relationships are ignored.\nIn this paper, we argue that the inter-meta-task relationships should be\nexploited and those tasks are sampled strategically to assist in meta-learning.\nSpecifically, we consider the relationships defined over two types of meta-task\npairs and propose different strategies to exploit them. (1) Two meta-tasks with\ndisjoint sets of classes: this pair is interesting because it is reminiscent of\nthe relationship between the source seen classes and target unseen classes,\nfeatured with domain gap caused by class differences. A novel learning\nobjective termed meta-domain adaptation (MDA) is proposed to make the\nmeta-learned model more robust to the domain gap. (2) Two meta-tasks with\nidentical sets of classes: this pair is useful because it can be employed to\nlearn models that are robust against poorly sampled few-shots. To that end, a\nnovel meta-knowledge distillation (MKD) objective is formulated. There are some\nmistakes in the experiments. We thus choose to withdraw this paper.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:25:13 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 15:26:20 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 07:30:28 GMT"}, {"version": "v4", "created": "Sat, 26 Sep 2020 05:02:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fei", "Nanyi", ""], ["Lu", "Zhiwu", ""], ["Gao", "Yizhao", ""], ["Tian", "Jia", ""], ["Xiang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2002.04275", "submitter": "Viktor Bengs", "authors": "Adil El Mesaoudi-Paul, Viktor Bengs, Eyke H\\\"ullermeier", "title": "Online Preselection with Context Information under the Plackett-Luce\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an extension of the contextual multi-armed bandit problem, in\nwhich, instead of selecting a single alternative (arm), a learner is supposed\nto make a preselection in the form of a subset of alternatives. More\nspecifically, in each iteration, the learner is presented a set of arms and a\ncontext, both described in terms of feature vectors. The task of the learner is\nto preselect $k$ of these arms, among which a final choice is made in a second\nstep. In our setup, we assume that each arm has a latent (context-dependent)\nutility, and that feedback on a preselection is produced according to a\nPlackett-Luce model. We propose the CPPL algorithm, which is inspired by the\nwell-known UCB algorithm, and evaluate this algorithm on synthetic and real\ndata. In particular, we consider an online algorithm selection scenario, which\nserved as a main motivation of our problem setting. Here, an instance (which\ndefines the context) from a certain problem class (such as SAT) can be solved\nby different algorithms (the arms), but only $k$ of these algorithms can\nactually be run.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:27:24 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mesaoudi-Paul", "Adil El", ""], ["Bengs", "Viktor", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2002.04276", "submitter": "Katarzyna Wo\\'znica", "authors": "Katarzyna Wo\\'znica and Przemys{\\l}aw Biecek", "title": "Towards explainable meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is a field that aims at discovering how different machine\nlearning algorithms perform on a wide range of predictive tasks. Such knowledge\nspeeds up the hyperparameter tuning or feature engineering. With the use of\nsurrogate models various aspects of the predictive task such as meta-features,\nlandmarker models e.t.c. are used to predict the expected performance. State of\nthe art approaches are focused on searching for the best meta-model but do not\nexplain how these different aspects contribute to its performance. However, to\nbuild a new generation of meta-models we need a deeper understanding of the\nimportance and effect of meta-features on the model tunability. In this paper,\nwe propose techniques developed for eXplainable Artificial Intelligence (XAI)\nto examine and extract knowledge from black-box surrogate models. To our\nknowledge, this is the first paper that shows how post-hoc explainability can\nbe used to improve the meta-learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:42:29 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 12:23:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wo\u017anica", "Katarzyna", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2002.04289", "submitter": "Alo\\\"is Pourchot", "authors": "Alo\\\"is Pourchot, Alexis Ducarouge, Olivier Sigaud", "title": "To Share or Not To Share: A Comprehensive Appraisal of Weight-Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight-sharing (WS) has recently emerged as a paradigm to accelerate the\nautomated search for efficient neural architectures, a process dubbed Neural\nArchitecture Search (NAS). Although very appealing, this framework is not\nwithout drawbacks and several works have started to question its capabilities\non small hand-crafted benchmarks. In this paper, we take advantage of the\n\\nasbench dataset to challenge the efficiency of WS on a representative search\nspace. By comparing a SOTA WS approach to a plain random search we show that,\ndespite decent correlations between evaluations using weight-sharing and\nstandalone ones, WS is only rarely significantly helpful to NAS. In particular\nwe highlight the impact of the search space itself on the benefits.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:29:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:11:20 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Pourchot", "Alo\u00efs", ""], ["Ducarouge", "Alexis", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2002.04301", "submitter": "Yangzi Guo", "authors": "Yangzi Guo, Yiyuan She, Adrian Barbu", "title": "Network Pruning via Annealing and Direct Sparsity Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) especially deep convolutional networks are\nvery popular these days and have been proved to successfully offer quite\nreliable solutions to many vision problems. However, the use of deep neural\nnetworks is widely impeded by their intensive computational and memory cost. In\nthis paper, we propose a novel efficient network pruning method that is\nsuitable for both non-structured and structured channel-level pruning. Our\nproposed method tightens a sparsity constraint by gradually removing network\nparameters or filter channels based on a criterion and a schedule. The\nattractive fact that the network size keeps dropping throughout the iterations\nmakes it suitable for the pruning of any untrained or pre-trained network.\nBecause our method uses a $L_0$ constraint instead of the $L_1$ penalty, it\ndoes not introduce any bias in the training parameters or filter channels.\nFurthermore, the $L_0$ constraint makes it easy to directly specify the desired\nsparsity level during the network pruning process. Finally, experimental\nvalidation on extensive synthetic and real vision datasets show that the\nproposed method obtains better or competitive performance compared to other\nstates of art network pruning methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:51:12 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 00:28:09 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 02:48:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Guo", "Yangzi", ""], ["She", "Yiyuan", ""], ["Barbu", "Adrian", ""]]}, {"id": "2002.04312", "submitter": "Saulo Martiello Mastelini", "authors": "Everton Jose Santana and Felipe Rodrigues dos Santos and Saulo\n  Martiello Mastelini and Fabio Luiz Melquiades and Sylvio Barbon Jr", "title": "Improved prediction of soil properties with Multi-target Stacked\n  Generalisation on EDXRF spectra", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms have been used for assessing soil quality\nparameters along with non-destructive methodologies. Among spectroscopic\nanalytical methodologies, energy dispersive X-ray fluorescence (EDXRF) is one\nof the more quick, environmentally friendly and less expensive when compared to\nconventional methods. However, some challenges in EDXRF spectral data analysis\nstill demand more efficient methods capable of providing accurate outcomes.\nUsing Multi-target Regression (MTR) methods, multiple parameters can be\npredicted, and also taking advantage of inter-correlated parameters the overall\npredictive performance can be improved. In this study, we proposed the\nMulti-target Stacked Generalisation (MTSG), a novel MTR method relying on\nlearning from different regressors arranged in stacking structure for a boosted\noutcome. We compared MTSG and 5 MTR methods for predicting 10 parameters of\nsoil fertility. Random Forest and Support Vector Machine (with linear and\nradial kernels) were used as learning algorithms embedded into each MTR method.\nResults showed the superiority of MTR methods over the Single-target Regression\n(the traditional ML method), reducing the predictive error for 5 parameters.\nParticularly, MTSG obtained the lowest error for phosphorus, total organic\ncarbon and cation exchange capacity. When observing the relative performance of\nSupport Vector Machine with a radial kernel, the prediction of base saturation\npercentage was improved in 19%. Finally, the proposed method was able to reduce\nthe average error from 0.67 (single-target) to 0.64 analysing all targets,\nrepresenting a global improvement of 4.48%.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:05:03 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Santana", "Everton Jose", ""], ["Santos", "Felipe Rodrigues dos", ""], ["Mastelini", "Saulo Martiello", ""], ["Melquiades", "Fabio Luiz", ""], ["Barbon", "Sylvio", "Jr"]]}, {"id": "2002.04317", "submitter": "Baptiste Caramiaux", "authors": "Baptiste Caramiaux, Jules Fran\\c{c}oise, Wanyu Liu, T\\'eo Sanchez and\n  Fr\\'ed\\'eric Bevilacqua", "title": "Machine Learning Approaches For Motor Learning: A Short Review", "comments": "Mini Review, Frontiers Comput. Sci. - Human-Media Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning approaches have seen considerable applications in human\nmovement modeling, but remain limited for motor learning. Motor learning\nrequires accounting for motor variability, and poses new challenges as the\nalgorithms need to be able to differentiate between new movements and variation\nof known ones. In this short review, we outline existing machine learning\nmodels for motor learning and their adaptation capabilities. We identify and\ndescribe three types of adaptation: Parameter adaptation in probabilistic\nmodels, Transfer and meta-learning in deep neural networks, and Planning\nadaptation by reinforcement learning. To conclude, we discuss challenges for\napplying these models in the domain of motor learning support systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:11:26 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 07:40:27 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 13:07:49 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 15:00:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Caramiaux", "Baptiste", ""], ["Fran\u00e7oise", "Jules", ""], ["Liu", "Wanyu", ""], ["Sanchez", "T\u00e9o", ""], ["Bevilacqua", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2002.04319", "submitter": "Yangzi Guo", "authors": "Gitesh Dawer, Yangzi Guo, Sida Liu, Adrian Barbu", "title": "Neural Rule Ensembles: Encoding Sparse Feature Interactions into Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks form the basis of very powerful learning methods.\nIt has been observed that a naive application of fully connected neural\nnetworks to data with many irrelevant variables often leads to overfitting. In\nan attempt to circumvent this issue, a prior knowledge pertaining to what\nfeatures are relevant and their possible feature interactions can be encoded\ninto these networks. In this work, we use decision trees to capture such\nrelevant features and their interactions and define a mapping to encode\nextracted relationships into a neural network. This addresses the\ninitialization related concern of fully connected neural networks. At the same\ntime through feature selection it enables learning of compact representations\ncompared to state of the art tree-based approaches. Empirical evaluations and\nsimulation studies show the superiority of such an approach over fully\nconnected neural networks and tree-based approaches\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:22:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Dawer", "Gitesh", ""], ["Guo", "Yangzi", ""], ["Liu", "Sida", ""], ["Barbu", "Adrian", ""]]}, {"id": "2002.04322", "submitter": "Yangzi Guo", "authors": "Yangzi Guo, Adrian Barbu", "title": "A study of local optima for learning feature interactions using neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields such as bioinformatics, high energy physics, power\ndistribution, etc., it is desirable to learn non-linear models where a small\nnumber of variables are selected and the interaction between them is explicitly\nmodeled to predict the response. In principle, neural networks (NNs) could\naccomplish this task since they can model non-linear feature interactions very\nwell. However, NNs require large amounts of training data to have a good\ngeneralization. In this paper we study the datastarved regime where a NN is\ntrained on a relatively small amount of training data. For that purpose we\nstudy feature selection for NNs, which is known to improve generalization for\nlinear models. As an extreme case of data with feature selection and feature\ninteractions we study the XOR-like data with irrelevant variables. We\nexperimentally observed that the cross-entropy loss function on XOR-like data\nhas many non-equivalent local optima, and the number of local optima grows\nexponentially with the number of irrelevant variables. To deal with the local\nminima and for feature selection we propose a node pruning and feature\nselection algorithm that improves the capability of NNs to find better local\nminima even when there are irrelevant variables. Finally, we show that the\nperformance of a NN on real datasets can be improved using pruning, obtaining\ncompact networks on a small number of features, with good prediction and\ninterpretability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:38:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Guo", "Yangzi", ""], ["Barbu", "Adrian", ""]]}, {"id": "2002.04328", "submitter": "Giuseppe Brandi", "authors": "Giuseppe Brandi and T. Di Matteo", "title": "Predicting Multidimensional Data via Tensor Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of multidimensional data is becoming a more and more relevant\ntopic in statistical and machine learning research. Given their complexity,\nsuch data objects are usually reshaped into matrices or vectors and then\nanalysed. However, this methodology presents several drawbacks. First of all,\nit destroys the intrinsic interconnections among datapoints in the\nmultidimensional space and, secondly, the number of parameters to be estimated\nin a model increases exponentially. We develop a model that overcomes such\ndrawbacks. In particular, in this paper, we propose a parsimonious tensor\nregression model that retains the intrinsic multidimensional structure of the\ndataset. Tucker structure is employed to achieve parsimony and a shrinkage\npenalization is introduced to deal with over-fitting and collinearity. To\nestimate the model parameters, an Alternating Least Squares algorithm is\ndeveloped. In order to validate the model performance and robustness, a\nsimulation exercise is produced. Moreover, we perform an empirical analysis\nthat highlight the forecasting power of the model with respect to benchmark\nmodels. This is achieved by implementing an autoregressive specification on the\nFoursquares spatio-temporal dataset together with a macroeconomic panel\ndataset. Overall, the proposed model is able to outperform benchmark models\npresent in the forecasting literature.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:57:07 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:37:28 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 18:13:53 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Brandi", "Giuseppe", ""], ["Di Matteo", "T.", ""]]}, {"id": "2002.04333", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis and Manuel Gomez-Rodriguez", "title": "Decisions, Counterfactual Explanations and Strategic Behavior", "comments": "Transportation of mass experiment in main. Clarification of model\n  assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.GT cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data-driven predictive models are increasingly used to inform decisions,\nit has been argued that decision makers should provide explanations that help\nindividuals understand what would have to change for these decisions to be\nbeneficial ones. However, there has been little discussion on the possibility\nthat individuals may use the above counterfactual explanations to invest effort\nstrategically and maximize their chances of receiving a beneficial decision. In\nthis paper, our goal is to find policies and counterfactual explanations that\nare optimal in terms of utility in such a strategic setting. We first show\nthat, given a pre-defined policy, the problem of finding the optimal set of\ncounterfactual explanations is NP-hard. Then, we show that the corresponding\nobjective is nondecreasing and satisfies submodularity and this allows a\nstandard greedy algorithm to enjoy approximation guarantees. In addition, we\nfurther show that the problem of jointly finding both the optimal policy and\nset of counterfactual explanations reduces to maximizing a non-monotone\nsubmodular function. As a result, we can use a recent randomized algorithm to\nsolve the problem, which also offers approximation guarantees. Finally, we\ndemonstrate that, by incorporating a matroid constraint into the problem\nformulation, we can increase the diversity of the optimal set of counterfactual\nexplanations and incentivize individuals across the whole spectrum of the\npopulation to self improve. Experiments on synthetic and real lending and\ncredit card data illustrate our theoretical findings and show that the\ncounterfactual explanations and decision policies found by our algorithms\nachieve higher utility than several competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:04:41 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 11:28:00 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 16:55:44 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2002.04337", "submitter": "Felix Opolka", "authors": "Felix L. Opolka, Pietro Li\\`o", "title": "Graph Convolutional Gaussian Processes For Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction aims to reveal missing edges in a graph. We address this task\nwith a Gaussian process that is transformed using simplified graph convolutions\nto better leverage the inductive bias of the domain. To scale the Gaussian\nprocess model to large graphs, we introduce a variational inducing point method\nthat places pseudo inputs on a graph-structured domain. We evaluate our model\non eight large graphs with up to thousands of nodes and report consistent\nimprovements over existing Gaussian process models as well as competitive\nperformance when compared to state-of-the-art graph neural network approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:12:21 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Opolka", "Felix L.", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2002.04348", "submitter": "Kateryna Chumachenko", "authors": "Kateryna Chumachenko, Jenni Raitoharju, Moncef Gabbouj, Alexandros\n  Iosifidis", "title": "Incremental Fast Subclass Discriminant Analysis", "comments": "\\c{opyright} 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an incremental solution to Fast Subclass Discriminant\nAnalysis (fastSDA). We present an exact and an approximate linear solution,\nalong with an approximate kernelized variant. Extensive experiments on eight\nimage datasets with different incremental batch sizes show the superiority of\nthe proposed approach in terms of training time and accuracy being equal or\nclose to fastSDA solution and outperforming other methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:38:56 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Chumachenko", "Kateryna", ""], ["Raitoharju", "Jenni", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2002.04359", "submitter": "Ginevra Carbone", "authors": "Ginevra Carbone, Matthew Wicker, Luca Laurenti, Andrea Patane, Luca\n  Bortolussi, Guido Sanguinetti", "title": "Robustness of Bayesian Neural Networks to Gradient-Based Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability to adversarial attacks is one of the principal hurdles to the\nadoption of deep learning in safety-critical applications. Despite significant\nefforts, both practical and theoretical, the problem remains open. In this\npaper, we analyse the geometry of adversarial attacks in the large-data,\noverparametrized limit for Bayesian Neural Networks (BNNs). We show that, in\nthe limit, vulnerability to gradient-based attacks arises as a result of\ndegeneracy in the data distribution, i.e., when the data lies on a\nlower-dimensional submanifold of the ambient space. As a direct consequence, we\ndemonstrate that in the limit BNN posteriors are robust to gradient-based\nadversarial attacks. Experimental results on the MNIST and Fashion MNIST\ndatasets with BNNs trained with Hamiltonian Monte Carlo and Variational\nInference support this line of argument, showing that BNNs can display both\nhigh accuracy and robustness to gradient based adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:03:57 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 16:29:29 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 10:57:33 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Carbone", "Ginevra", ""], ["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""], ["Bortolussi", "Luca", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "2002.04372", "submitter": "Cedric Gerbelot", "authors": "C\\'edric Gerbelot, Alia Abbara and Florent Krzakala", "title": "Asymptotic errors for convex penalized linear regression beyond Gaussian\n  matrices", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a coefficient vector $x_{0}$ in $R^{N}$\nfrom noisy linear observations $y=Fx_{0}+w$ in $R^{M}$ in the high dimensional\nlimit $M,N$ to infinity with $\\alpha=M/N$ fixed. We provide a rigorous\nderivation of an explicit formula -- first conjectured using heuristic methods\nfrom statistical physics -- for the asymptotic mean squared error obtained by\npenalized convex regression estimators such as the LASSO or the elastic net,\nfor a class of very generic random matrices corresponding to rotationally\ninvariant data matrices with arbitrary spectrum. The proof is based on a\nconvergence analysis of an oracle version of vector approximate message-passing\n(oracle-VAMP) and on the properties of its state evolution equations. Our\nmethod leverages on and highlights the link between vector approximate\nmessage-passing, Douglas-Rachford splitting and proximal descent algorithms,\nextending previous results obtained with i.i.d. matrices for a large class of\nproblems. We illustrate our results on some concrete examples and show that\neven though they are asymptotic, our predictions agree remarkably well with\nnumerics even for very moderate sizes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:43:32 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Gerbelot", "C\u00e9dric", ""], ["Abbara", "Alia", ""], ["Krzakala", "Florent", ""]]}, {"id": "2002.04374", "submitter": "Juan Camilo Vasquez Correa J. C. Vasquez-Correa", "authors": "J. C. V\\'asquez-Correa, T. Arias-Vergara, C. D. Rios-Urrego, M.\n  Schuster, J. Rusz, J. R. Orozco-Arroyave, E. N\\\"oth", "title": "Convolutional Neural Networks and a Transfer Learning Strategy to\n  Classify Parkinson's Disease from Speech in Three Different Languages", "comments": null, "journal-ref": "In Iberoamerican Congress on Pattern Recognition (pp. 697-706)\n  2019", "doi": "10.1007/978-3-030-33904-3_66", "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parkinson's disease patients develop different speech impairments that affect\ntheir communication capabilities. The automatic assessment of the speech of the\npatients allows the development of computer aided tools to support the\ndiagnosis and the evaluation of the disease severity. This paper introduces a\nmethodology to classify Parkinson's disease from speech in three different\nlanguages: Spanish, German, and Czech. The proposed approach considers\nconvolutional neural networks trained with time frequency representations and a\ntransfer learning strategy among the three languages. The transfer learning\nscheme aims to improve the accuracy of the models when the weights of the\nneural network are initialized with utterances from a different language than\nthe used for the test set. The results suggest that the proposed strategy\nimproves the accuracy of the models in up to 8\\% when the base model used to\ninitialize the weights of the classifier is robust enough. In addition, the\nresults obtained after the transfer learning are in most cases more balanced in\nterms of specificity-sensitivity than those trained without the transfer\nlearning strategy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:48:38 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["V\u00e1squez-Correa", "J. C.", ""], ["Arias-Vergara", "T.", ""], ["Rios-Urrego", "C. D.", ""], ["Schuster", "M.", ""], ["Rusz", "J.", ""], ["Orozco-Arroyave", "J. R.", ""], ["N\u00f6th", "E.", ""]]}, {"id": "2002.04375", "submitter": "Patrick Heas", "authors": "Patrick Heas, Cedric Herzet, Benoit Combes", "title": "Generalized Kernel-Based Dynamic Mode Decomposition", "comments": "45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2020). arXiv admin note: substantial text overlap with\n  arXiv:1710.10919", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced modeling in high-dimensional reproducing kernel Hilbert spaces offers\nthe opportunity to approximate efficiently non-linear dynamics. In this work,\nwe devise an algorithm based on low rank constraint optimization and\nkernel-based computation that generalizes a recent approach called\n\"kernel-based dynamic mode decomposition\". This new algorithm is characterized\nby a gain in approximation accuracy, as evidenced by numerical simulations, and\nin computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:50:00 GMT"}], "update_date": "2020-02-23", "authors_parsed": [["Heas", "Patrick", ""], ["Herzet", "Cedric", ""], ["Combes", "Benoit", ""]]}, {"id": "2002.04392", "submitter": "Sven Koehler", "authors": "Sven Koehler and Animesh Tandon and Tarique Hussain and Heiner Latus\n  and Thomas Pickardt and Samir Sarikouch and Philipp Beerbaum and Gerald Greil\n  and Sandy Engelhardt and Ivo Wolf", "title": "How well do U-Net-based segmentation trained on adult cardiac magnetic\n  resonance imaging data generalise to rare congenital heart diseases for\n  surgical planning?", "comments": "Accepted for SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Planning the optimal time of intervention for pulmonary valve replacement\nsurgery in patients with the congenital heart disease Tetralogy of Fallot (TOF)\nis mainly based on ventricular volume and function according to current\nguidelines. Both of these two biomarkers are most reliably assessed by\nsegmentation of 3D cardiac magnetic resonance (CMR) images. In several grand\nchallenges in the last years, U-Net architectures have shown impressive results\non the provided data. However, in clinical practice, data sets are more diverse\nconsidering individual pathologies and image properties derived from different\nscanner properties. Additionally, specific training data for complex rare\ndiseases like TOF is scarce.\n  For this work, 1) we assessed the accuracy gap when using a publicly\navailable labelled data set (the Automatic Cardiac Diagnosis Challenge (ACDC)\ndata set) for training and subsequent applying it to CMR data of TOF patients\nand vice versa and 2) whether we can achieve similar results when applying the\nmodel to a more heterogeneous data base.\n  Multiple deep learning models were trained with four-fold cross validation.\nAfterwards they were evaluated on the respective unseen CMR images from the\nother collection. Our results confirm that current deep learning models can\nachieve excellent results (left ventricle dice of\n$0.951\\pm{0.003}$/$0.941\\pm{0.007}$ train/validation) within a single data\ncollection. But once they are applied to other pathologies, it becomes apparent\nhow much they overfit to the training pathologies (dice score drops between\n$0.072\\pm{0.001}$ for the left and $0.165\\pm{0.001}$ for the right ventricle).\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:50:51 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Koehler", "Sven", ""], ["Tandon", "Animesh", ""], ["Hussain", "Tarique", ""], ["Latus", "Heiner", ""], ["Pickardt", "Thomas", ""], ["Sarikouch", "Samir", ""], ["Beerbaum", "Philipp", ""], ["Greil", "Gerald", ""], ["Engelhardt", "Sandy", ""], ["Wolf", "Ivo", ""]]}, {"id": "2002.04397", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren, Jiawei Zhang", "title": "Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:09:13 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 03:16:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "2002.04406", "submitter": "Saif Jabari", "authors": "Ouafa Benkraouda, Bilal Thonnam Thodi, Hwasoo Yeo, Monica Menendez,\n  and Saif Eddin Jabari", "title": "Traffic Data Imputation using Deep Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Access, 8, 2020, pp. 104740-104752", "doi": "10.1109/ACCESS.2020.2999662", "report-no": null, "categories": "physics.soc-ph cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical learning-based traffic speed estimation method that\nuses sparse vehicle trajectory information. Using a convolutional\nencoder-decoder based architecture, we show that a well trained neural network\ncan learn spatio-temporal traffic speed dynamics from time-space diagrams. We\ndemonstrate this for a homogeneous road section using simulated vehicle\ntrajectories and then validate it using real-world data from NGSIM. Our results\nshow that with probe vehicle penetration levels as low as 5\\%, the proposed\nestimation method can provide a sound reconstruction of macroscopic traffic\nspeeds and reproduce realistic shockwave patterns, implying applicability in a\nvariety of traffic conditions. We further discuss the model's reconstruction\nmechanisms and confirm its ability to differentiate various traffic behaviors\nsuch as congested and free-flow traffic states, transition dynamics, and\nshockwave propagation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 12:52:58 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Benkraouda", "Ouafa", ""], ["Thodi", "Bilal Thonnam", ""], ["Yeo", "Hwasoo", ""], ["Menendez", "Monica", ""], ["Jabari", "Saif Eddin", ""]]}, {"id": "2002.04439", "submitter": "Maurice Quach", "authors": "Maurice Quach, Giuseppe Valenzise and Frederic Dufaux", "title": "Folding-based compression of point cloud attributes", "comments": "Published in ICIP 2020. The source code can be found at\n  https://github.com/mauriceqch/pcc_attr_folding", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.GR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques to compress point cloud attributes leverage either\ngeometric or video-based compression tools. We explore a radically different\napproach inspired by recent advances in point cloud representation learning.\nPoint clouds can be interpreted as 2D manifolds in 3D space. Specifically, we\nfold a 2D grid onto a point cloud and we map attributes from the point cloud\nonto the folded 2D grid using a novel optimized mapping method. This mapping\nresults in an image, which opens a way to apply existing image processing\ntechniques on point cloud attributes. However, as this mapping process is lossy\nin nature, we propose several strategies to refine it so that attributes can be\nmapped to the 2D grid with minimal distortion. Moreover, this approach can be\nflexibly applied to point cloud patches in order to better adapt to local\ngeometric complexity. In this work, we consider point cloud attribute\ncompression; thus, we compress this image with a conventional 2D image codec.\nOur preliminary results show that the proposed folding-based coding scheme can\nalready reach performance similar to the latest MPEG Geometry-based PCC (G-PCC)\ncodec.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 14:55:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 09:04:51 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 07:17:57 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Dufaux", "Frederic", ""]]}, {"id": "2002.04457", "submitter": "Dong Xia", "authors": "Bing-Yi Jing and Ting Li and Zhongyuan Lyu and Dong Xia", "title": "Community Detection on Mixture Multi-layer Networks via Regularized\n  Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG math.IT math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of community detection in multi-layer networks, where\npairs of nodes can be related in multiple modalities. We introduce a general\nframework, i.e., mixture multi-layer stochastic block model (MMSBM), which\nincludes many earlier models as special cases. We propose a tensor-based\nalgorithm (TWIST) to reveal both global/local memberships of nodes, and\nmemberships of layers. We show that the TWIST procedure can accurately detect\nthe communities with small misclassification error as the number of nodes\nand/or the number of layers increases. Numerical studies confirm our\ntheoretical findings. To our best knowledge, this is the first systematic study\non the mixture multi-layer networks using tensor decomposition. The method is\napplied to two real datasets: worldwide trading networks and malaria parasite\ngenes networks, yielding new and interesting findings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 06:19:50 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Jing", "Bing-Yi", ""], ["Li", "Ting", ""], ["Lyu", "Zhongyuan", ""], ["Xia", "Dong", ""]]}, {"id": "2002.04458", "submitter": "Luna Zhang", "authors": "Luna M. Zhang", "title": "Pairwise Neural Networks (PairNets) with Low Memory for Fast On-Device\n  Applications", "comments": "arXiv admin note: text overlap with arXiv:2001.08886", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A traditional artificial neural network (ANN) is normally trained slowly by a\ngradient descent algorithm, such as the backpropagation algorithm, since a\nlarge number of hyperparameters of the ANN need to be fine-tuned with many\ntraining epochs. Since a large number of hyperparameters of a deep neural\nnetwork, such as a convolutional neural network, occupy much memory, a\nmemory-inefficient deep learning model is not ideal for real-time Internet of\nThings (IoT) applications on various devices, such as mobile phones. Thus, it\nis necessary to develop fast and memory-efficient Artificial Intelligence of\nThings (AIoT) systems for real-time on-device applications. We created a novel\nwide and shallow 4-layer ANN called \"Pairwise Neural Network\" (\"PairNet\") with\nhigh-speed non-gradient-descent hyperparameter optimization. The PairNet is\ntrained quickly with only one epoch since its hyperparameters are directly\noptimized one-time via simply solving a system of linear equations by using the\nmultivariate least squares fitting method. In addition, an n-input space is\npartitioned into many n-input data subspaces, and a local PairNet is built in a\nlocal n-input subspace. This divide-and-conquer approach can train the local\nPairNet using specific local features to improve model performance. Simulation\nresults indicate that the three PairNets with incremental learning have smaller\naverage prediction mean squared errors, and achieve much higher speeds than\ntraditional ANNs. An important future work is to develop better and faster\nnon-gradient-descent hyperparameter optimization algorithms to generate\neffective, fast, and memory-efficient PairNets with incremental learning on\noptimal subspaces for real-time AIoT on-device applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:12:59 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Luna M.", ""]]}, {"id": "2002.04461", "submitter": "Alexander Tong", "authors": "Alexander Tong, Jessie Huang, Guy Wolf, David van Dijk, Smita\n  Krishnaswamy", "title": "TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular\n  Dynamics", "comments": "Presented at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is increasingly common to encounter data from dynamic processes captured\nby static cross-sectional measurements over time, particularly in biomedical\nsettings. Recent attempts to model individual trajectories from this data use\noptimal transport to create pairwise matchings between time points. However,\nthese methods cannot model continuous dynamics and non-linear paths that\nentities can take in these systems. To address this issue, we establish a link\nbetween continuous normalizing flows and dynamic optimal transport, that allows\nus to model the expected paths of points over time. Continuous normalizing\nflows are generally under constrained, as they are allowed to take an arbitrary\npath from the source to the target distribution. We present TrajectoryNet,\nwhich controls the continuous paths taken between distributions to produce\ndynamic optimal transport. We show how this is particularly applicable for\nstudying cellular dynamics in data from single-cell RNA sequencing (scRNA-seq)\ntechnologies, and that TrajectoryNet improves upon recently proposed static\noptimal transport-based models that can be used for interpolating cellular\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 21:00:38 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 13:42:19 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tong", "Alexander", ""], ["Huang", "Jessie", ""], ["Wolf", "Guy", ""], ["van Dijk", "David", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2002.04464", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Sa\\v{s}o D\\v{z}eroski, Nada Lavra\\v{c} and Matej\n  Petkovi\\v{c}", "title": "Feature Importance Estimation with Self-Attention Networks", "comments": "Accepted for publication in ECAI 2020", "journal-ref": null, "doi": "10.3233/FAIA200256", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box neural network models are widely used in industry and science, yet\nare hard to understand and interpret. Recently, the attention mechanism was\nintroduced, offering insights into the inner workings of neural language\nmodels. This paper explores the use of attention-based neural networks\nmechanism for estimating feature importance, as means for explaining the models\nlearned from propositional (tabular) data. Feature importance estimates,\nassessed by the proposed Self-Attention Network (SAN) architecture, are\ncompared with the established ReliefF, Mutual Information and Random\nForest-based estimates, which are widely used in practice for model\ninterpretation. For the first time we conduct scale-free comparisons of feature\nimportance estimates across algorithms on ten real and synthetic data sets to\nstudy the similarities and differences of the resulting feature importance\nestimates, showing that SANs identify similar high-ranked features as the other\nmethods. We demonstrate that SANs identify feature interactions which in some\ncases yield better predictive performance than the baselines, suggesting that\nattention extends beyond interactions of just a few key features and detects\nlarger feature subsets relevant for the considered learning task.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:15:58 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Lavra\u010d", "Nada", ""], ["Petkovi\u010d", "Matej", ""]]}, {"id": "2002.04486", "submitter": "Lenaic Chizat", "authors": "Lenaic Chizat (LMO), Francis Bach (LIENS, SIERRA)", "title": "Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks\n  Trained with the Logistic Loss", "comments": null, "journal-ref": "Conference on Learning Theory, Jul 2020, Graz, Austria", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks trained to minimize the logistic (a.k.a. cross-entropy) loss\nwith gradient-based methods are observed to perform well in many supervised\nclassification tasks. Towards understanding this phenomenon, we analyze the\ntraining and generalization behavior of infinitely wide two-layer neural\nnetworks with homogeneous activations. We show that the limits of the gradient\nflow on exponentially tailed losses can be fully characterized as a max-margin\nclassifier in a certain non-Hilbertian space of functions. In presence of\nhidden low-dimensional structures, the resulting margin is independent of the\nambiant dimension, which leads to strong generalization bounds. In contrast,\ntraining only the output layer implicitly solves a kernel support vector\nmachine, which a priori does not enjoy such an adaptivity. Our analysis of\ntraining is non-quantitative in terms of running time but we prove\ncomputational guarantees in simplified settings by showing equivalences with\nonline mirror descent. Finally, numerical experiments suggest that our analysis\ndescribes well the practical behavior of two-layer neural networks with ReLU\nactivation and confirm the statistical benefits of this implicit bias.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:42:09 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:07:48 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:50:38 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 15:50:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chizat", "Lenaic", "", "LMO"], ["Bach", "Francis", "", "LIENS, SIERRA"]]}, {"id": "2002.04495", "submitter": "Alireza Doostan", "authors": "Subhayan De, Jolene Britton, Matthew Reynolds, Ryan Skinner, Kenneth\n  Jansen, and Alireza Doostan", "title": "On transfer learning of neural networks using bi-fidelity data for\n  uncertainty propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their high degree of expressiveness, neural networks have recently\nbeen used as surrogate models for mapping inputs of an engineering system to\noutputs of interest. Once trained, neural networks are computationally\ninexpensive to evaluate and remove the need for repeated evaluations of\ncomputationally expensive models in uncertainty quantification applications.\nHowever, given the highly parameterized construction of neural networks,\nespecially deep neural networks, accurate training often requires large amounts\nof simulation data that may not be available in the case of computationally\nexpensive systems. In this paper, to alleviate this issue for uncertainty\npropagation, we explore the application of transfer learning techniques using\ntraining data generated from both high- and low-fidelity models. We explore two\nstrategies for coupling these two datasets during the training procedure,\nnamely, the standard transfer learning and the bi-fidelity weighted learning.\nIn the former approach, a neural network model mapping the inputs to the\noutputs of interest is trained based on the low-fidelity data. The\nhigh-fidelity data is then used to adapt the parameters of the upper layer(s)\nof the low-fidelity network, or train a simpler neural network to map the\noutput of the low-fidelity network to that of the high-fidelity model. In the\nlatter approach, the entire low-fidelity network parameters are updated using\ndata generated via a Gaussian process model trained with a small high-fidelity\ndataset. The parameter updates are performed via a variant of stochastic\ngradient descent with learning rates given by the Gaussian process model. Using\nthree numerical examples, we illustrate the utility of these bi-fidelity\ntransfer learning methods where we focus on accuracy improvement achieved by\ntransfer learning over standard training approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:56:11 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["De", "Subhayan", ""], ["Britton", "Jolene", ""], ["Reynolds", "Matthew", ""], ["Skinner", "Ryan", ""], ["Jansen", "Kenneth", ""], ["Doostan", "Alireza", ""]]}, {"id": "2002.04518", "submitter": "Angela Zhou", "authors": "Nathan Kallus and Angela Zhou", "title": "Confounding-Robust Policy Evaluation in Infinite-Horizon Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation of sequential decision policies from observational data\nis necessary in applications of batch reinforcement learning such as education\nand healthcare. In such settings, however, unobserved variables confound\nobserved actions, rendering exact evaluation of new policies impossible, i.e.,\nunidentifiable. We develop a robust approach that estimates sharp bounds on the\n(unidentifiable) value of a given policy in an infinite-horizon problem given\ndata from another policy with unobserved confounding, subject to a sensitivity\nmodel. We consider stationary or baseline unobserved confounding and compute\nbounds by optimizing over the set of all stationary state-occupancy ratios that\nagree with a new partially identified estimating equation and the sensitivity\nmodel. We prove convergence to the sharp bounds as we collect more confounded\ndata. Although checking set membership is a linear program, the support\nfunction is given by a difficult nonconvex optimization problem. We develop\napproximations based on nonconvex projected gradient descent and demonstrate\nthe resulting bounds empirically.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:18:14 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:03:17 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "2002.04523", "submitter": "Nathan Lambert", "authors": "Nathan Lambert, Brandon Amos, Omry Yadan, Roberto Calandra", "title": "Objective Mismatch in Model-based Reinforcement Learning", "comments": "9 pages, 2 pages references, 5 pages appendices", "journal-ref": "Proceedings of the 2nd Conference on Learning for Dynamics and\n  Control, PMLR 120:761-770, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) has been shown to be a powerful\nframework for data-efficiently learning control of continuous tasks. Recent\nwork in MBRL has mostly focused on using more advanced function approximators\nand planning schemes, with little development of the general framework. In this\npaper, we identify a fundamental issue of the standard MBRL framework -- what\nwe call the objective mismatch issue. Objective mismatch arises when one\nobjective is optimized in the hope that a second, often uncorrelated, metric\nwill also be optimized. In the context of MBRL, we characterize the objective\nmismatch between training the forward dynamics model w.r.t.~the likelihood of\nthe one-step ahead prediction, and the overall goal of improving performance on\na downstream control task. For example, this issue can emerge with the\nrealization that dynamics models effective for a specific task do not\nnecessarily need to be globally accurate, and vice versa globally accurate\nmodels might not be sufficiently accurate locally to obtain good control\nperformance on a specific task. In our experiments, we study this objective\nmismatch issue and demonstrate that the likelihood of one-step ahead\npredictions is not always correlated with control performance. This observation\nhighlights a critical limitation in the MBRL framework which will require\nfurther research to be fully understood and addressed. We propose an initial\nmethod to mitigate the mismatch issue by re-weighting dynamics model training.\nBuilding on it, we conclude with a discussion about other potential directions\nof research for addressing this issue.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:26:07 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 22:21:48 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 03:02:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lambert", "Nathan", ""], ["Amos", "Brandon", ""], ["Yadan", "Omry", ""], ["Calandra", "Roberto", ""]]}, {"id": "2002.04555", "submitter": "Andrew Brereton", "authors": "Andrew E. Brereton, Stephen MacKinnon, Zhaleh Safikhani, Shawn Reeves,\n  Sana Alwash, Vijay Shahani, Andreas Windemuth", "title": "Predicting drug properties with parameter-free machine learning:\n  Pareto-Optimal Embedded Modeling (POEM)", "comments": "37 pages, 9 figures, supplemental included, submitted to \"Machine\n  Learning: Science and Technology\"", "journal-ref": null, "doi": "10.1088/2632-2153/ab891b", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of absorption, distribution, metabolism, excretion, and\ntoxicity (ADMET) of small molecules from their molecular structure is a central\nproblem in medicinal chemistry with great practical importance in drug\ndiscovery. Creating predictive models conventionally requires substantial\ntrial-and-error for the selection of molecular representations, machine\nlearning (ML) algorithms, and hyperparameter tuning. A generally applicable\nmethod that performs well on all datasets without tuning would be of great\nvalue but is currently lacking. Here, we describe Pareto-Optimal Embedded\nModeling (POEM), a similarity-based method for predicting molecular properties.\nPOEM is a non-parametric, supervised ML algorithm developed to generate\nreliable predictive models without need for optimization. POEMs predictive\nstrength is obtained by combining multiple different representations of\nmolecular structures in a context-specific manner, while maintaining low\ndimensionality. We benchmark POEM relative to industry-standard ML algorithms\nand published results across 17 classifications tasks. POEM performs well in\nall cases and reduces the risk of overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:20:28 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 19:13:45 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Brereton", "Andrew E.", ""], ["MacKinnon", "Stephen", ""], ["Safikhani", "Zhaleh", ""], ["Reeves", "Shawn", ""], ["Alwash", "Sana", ""], ["Shahani", "Vijay", ""], ["Windemuth", "Andreas", ""]]}, {"id": "2002.04592", "submitter": "Min Zhou", "authors": "Yang Feng, Min Zhou, Xin Tong", "title": "Imbalanced classification: a paradigm-based review", "comments": "34 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common issue for classification in scientific research and industry is the\nexistence of imbalanced classes. When sample sizes of different classes are\nimbalanced in training data, naively implementing a classification method often\nleads to unsatisfactory prediction results on test data. Multiple resampling\ntechniques have been proposed to address the class imbalance issues. Yet, there\nis no general guidance on when to use each technique. In this article, we\nprovide a paradigm-based review of the common resampling techniques for binary\nclassification under imbalanced class sizes. The paradigms we consider include\nthe classical paradigm that minimizes the overall classification error, the\ncost-sensitive learning paradigm that minimizes a cost-adjusted weighted type I\nand type II errors, and the Neyman-Pearson paradigm that minimizes the type II\nerror subject to a type I error constraint. Under each paradigm, we investigate\nthe combination of the resampling techniques and a few state-of-the-art\nclassification methods. For each pair of resampling techniques and\nclassification methods, we use simulation studies and a real data set on credit\ncard fraud to study the performance under different evaluation metrics. From\nthese extensive numerical experiments, we demonstrate under each classification\nparadigm, the complex dynamics among resampling techniques, base classification\nmethods, evaluation metrics, and imbalance ratios. We also summarize a few\ntakeaway messages regarding the choices of resampling techniques and base\nclassification methods, which could be helpful for practitioners.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:34:48 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 02:08:35 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Feng", "Yang", ""], ["Zhou", "Min", ""], ["Tong", "Xin", ""]]}, {"id": "2002.04599", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Jens Behrmann and Nicholas Carlini and Nicolas\n  Papernot and J\\\"orn-Henrik Jacobsen", "title": "Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial\n  Perturbations", "comments": "ICML 2020 (Supersedes the workshop paper \"Exploiting Excessive\n  Invariance caused by Norm-Bounded Adversarial Robustness\", arXiv:1903.10484)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs crafted to induce\nmisclassification. Commonly studied sensitivity-based adversarial examples\nintroduce semantically-small changes to an input that result in a different\nmodel prediction. This paper studies a complementary failure mode,\ninvariance-based adversarial examples, that introduce minimal semantic changes\nthat modify an input's true label yet preserve the model's prediction. We\ndemonstrate fundamental tradeoffs between these two types of adversarial\nexamples.\n  We show that defenses against sensitivity-based attacks actively harm a\nmodel's accuracy on invariance-based attacks, and that new approaches are\nneeded to resist both attack types. In particular, we break state-of-the-art\nadversarially-trained and certifiably-robust models by generating small\nperturbations that the models are (provably) robust to, yet that change an\ninput's class according to human labelers. Finally, we formally show that the\nexistence of excessively invariant classifiers arises from the presence of\noverly-robust predictive features in standard datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:50:23 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 16:53:43 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Behrmann", "Jens", ""], ["Carlini", "Nicholas", ""], ["Papernot", "Nicolas", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "2002.04632", "submitter": "Sergey Shirobokov", "authors": "Sergey Shirobokov, Vladislav Belavin, Michael Kagan, Andrey\n  Ustyuzhanin, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin", "title": "Black-Box Optimization with Local Generative Surrogates", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems 34 (NeurIPS),\n  2020", "doi": null, "report-no": null, "categories": "cs.LG hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for gradient-based optimization of black-box\nsimulators using differentiable local surrogate models. In fields such as\nphysics and engineering, many processes are modeled with non-differentiable\nsimulators with intractable likelihoods. Optimization of these forward models\nis particularly challenging, especially when the simulator is stochastic. To\naddress such cases, we introduce the use of deep generative models to\niteratively approximate the simulator in local neighborhoods of the parameter\nspace. We demonstrate that these local surrogates can be used to approximate\nthe gradient of the simulator, and thus enable gradient-based optimization of\nsimulator parameters. In cases where the dependence of the simulator on the\nparameter space is constrained to a low dimensional submanifold, we observe\nthat our method attains minima faster than baseline methods, including Bayesian\noptimization, numerical optimization, and approaches using score function\ngradient estimators.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:02:57 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 19:49:24 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shirobokov", "Sergey", ""], ["Belavin", "Vladislav", ""], ["Kagan", "Michael", ""], ["Ustyuzhanin", "Andrey", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""]]}, {"id": "2002.04640", "submitter": "Raoni Louren\\c{c}o", "authors": "Raoni Louren\\c{c}o and Juliana Freire and Dennis Shasha", "title": "Debugging Machine Learning Pipelines", "comments": "10 pages", "journal-ref": "Proceedings of the 3rd International Workshop on Data Management\n  for End-to-End Machine Learning, June 2019, Article No.: 3", "doi": "10.1145/3329486.3329489", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning tasks entail the use of complex computational pipelines to\nreach quantitative and qualitative conclusions. If some of the activities in a\npipeline produce erroneous or uninformative outputs, the pipeline may fail or\nproduce incorrect results. Inferring the root cause of failures and unexpected\nbehavior is challenging, usually requiring much human thought, and is both\ntime-consuming and error-prone. We propose a new approach that makes use of\niteration and provenance to automatically infer the root causes and derive\nsuccinct explanations of failures. Through a detailed experimental evaluation,\nwe assess the cost, precision, and recall of our approach compared to the state\nof the art. Our source code and experimental data will be available for\nreproducibility and enhancement.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:13:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Louren\u00e7o", "Raoni", ""], ["Freire", "Juliana", ""], ["Shasha", "Dennis", ""]]}, {"id": "2002.04658", "submitter": "Tong Qin", "authors": "Jun Hou, Tong Qin, Kailiang Wu, Dongbin Xiu", "title": "A Non-Intrusive Correction Algorithm for Classification Problems with\n  Corrupted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel correction algorithm is proposed for multi-class classification\nproblems with corrupted training data. The algorithm is non-intrusive, in the\nsense that it post-processes a trained classification model by adding a\ncorrection procedure to the model prediction. The correction procedure can be\ncoupled with any approximators, such as logistic regression, neural networks of\nvarious architectures, etc. When training dataset is sufficiently large, we\nprove that the corrected models deliver correct classification results as if\nthere is no corruption in the training data. For datasets of finite size, the\ncorrected models produce significantly better recovery results, compared to the\nmodels without the correction algorithm. All of the theoretical findings in the\npaper are verified by our numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:07:05 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hou", "Jun", ""], ["Qin", "Tong", ""], ["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "2002.04676", "submitter": "Dmitrii Beloborodov", "authors": "Dmitrii Beloborodov (1), A. E. Ulanov (1), Jakob N. Foerster (2),\n  Shimon Whiteson (2), A. I. Lvovsky (1 and 2) ((1) Russian Quantum Center, (2)\n  University of Oxford)", "title": "Reinforcement Learning Enhanced Quantum-inspired Algorithm for\n  Combinatorial Optimization", "comments": "Submitted to ICML 2020. 9 pages, 3 pdf figures. V2: fixed\n  acknowledgements", "journal-ref": "Machine Learning: Science and Technology, 2, 025009 (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum hardware and quantum-inspired algorithms are becoming increasingly\npopular for combinatorial optimization. However, these algorithms may require\ncareful hyperparameter tuning for each problem instance. We use a reinforcement\nlearning agent in conjunction with a quantum-inspired algorithm to solve the\nIsing energy minimization problem, which is equivalent to the Maximum Cut\nproblem. The agent controls the algorithm by tuning one of its parameters with\nthe goal of improving recently seen solutions. We propose a new Rescaled Ranked\nReward (R3) method that enables stable single-player version of self-play\ntraining that helps the agent to escape local optima. The training on any\nproblem instance can be accelerated by applying transfer learning from an agent\ntrained on randomly generated problems. Our approach allows sampling\nhigh-quality solutions to the Ising problem with high probability and\noutperforms both baseline heuristics and a black-box hyperparameter\noptimization approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:55:07 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:47:49 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Beloborodov", "Dmitrii", "", "1 and 2"], ["Ulanov", "A. E.", "", "1 and 2"], ["Foerster", "Jakob N.", "", "1 and 2"], ["Whiteson", "Shimon", "", "1 and 2"], ["Lvovsky", "A. I.", "", "1 and 2"]]}, {"id": "2002.04679", "submitter": "Marc Pfetsch", "authors": "Marc E. Pfetsch and Sebastian Pokutta", "title": "IPBoost -- Non-Convex Boosting via Integer Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently non-convex optimization approaches for solving machine learning\nproblems have gained significant attention. In this paper we explore non-convex\nboosting in classification by means of integer programming and demonstrate\nreal-world practicability of the approach while circumventing shortcomings of\nconvex boosting approaches. We report results that are comparable to or better\nthan the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:00:03 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pfetsch", "Marc E.", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2002.04687", "submitter": "Paul Norridge", "authors": "Paul Norridge", "title": "Think Global, Act Local: Relating DNN generalisation and node-level SNR", "comments": "15 pages, 5 figures; for associated colab files see\n  http://github.com/pnorridge/think-global-act-local/settings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The reasons behind good DNN generalisation remain an open question. In this\npaper we explore the problem by looking at the Signal-to-Noise Ratio of nodes\nin the network. Starting from information theory principles, it is possible to\nderive an expression for the SNR of a DNN node output. Using this expression we\nconstruct figures-of-merit that quantify how well the weights of a node\noptimise SNR (or, equivalently, information rate). Applying these\nfigures-of-merit, we give examples indicating that weight sets that promote\ngood SNR performance also exhibit good generalisation. In addition, we are able\nto identify the qualities of weight sets that exhibit good SNR behaviour and\nhence promote good generalisation. This leads to a discussion of how these\nresults relate to network training and regularisation. Finally, we identify\nsome ways that these observations can be used in training design.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:16:37 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Norridge", "Paul", ""]]}, {"id": "2002.04688", "submitter": "Jeremy Howard", "authors": "Jeremy Howard and Sylvain Gugger", "title": "fastai: A Layered API for Deep Learning", "comments": null, "journal-ref": "Information 2020, 11(2), 108", "doi": "10.3390/info11020108", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  fastai is a deep learning library which provides practitioners with\nhigh-level components that can quickly and easily provide state-of-the-art\nresults in standard deep learning domains, and provides researchers with\nlow-level components that can be mixed and matched to build new approaches. It\naims to do both things without substantial compromises in ease of use,\nflexibility, or performance. This is possible thanks to a carefully layered\narchitecture, which expresses common underlying patterns of many deep learning\nand data processing techniques in terms of decoupled abstractions. These\nabstractions can be expressed concisely and clearly by leveraging the dynamism\nof the underlying Python language and the flexibility of the PyTorch library.\nfastai includes: a new type dispatch system for Python along with a semantic\ntype hierarchy for tensors; a GPU-optimized computer vision library which can\nbe extended in pure Python; an optimizer which refactors out the common\nfunctionality of modern optimizers into two basic pieces, allowing optimization\nalgorithms to be implemented in 4-5 lines of code; a novel 2-way callback\nsystem that can access any part of the data, model, or optimizer and change it\nat any point during training; a new data block API; and much more. We have used\nthis library to successfully create a complete deep learning course, which we\nwere able to write more quickly than using previous approaches, and the code\nwas more clear. The library is already in wide use in research, industry, and\nteaching. NB: This paper covers fastai v2, which is currently in pre-release at\nhttp://dev.fast.ai/\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:16:48 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 18:17:51 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Howard", "Jeremy", ""], ["Gugger", "Sylvain", ""]]}, {"id": "2002.04692", "submitter": "Kartik Ahuja", "authors": "Kartik Ahuja, Karthikeyan Shanmugam, Kush R. Varshney, Amit Dhurandhar", "title": "Invariant Risk Minimization Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard risk minimization paradigm of machine learning is brittle when\noperating in environments whose test distributions are different from the\ntraining distribution due to spurious correlations. Training on data from many\nenvironments and finding invariant predictors reduces the effect of spurious\nfeatures by concentrating models on features that have a causal relationship\nwith the outcome. In this work, we pose such invariant risk minimization as\nfinding the Nash equilibrium of an ensemble game among several environments. By\ndoing so, we develop a simple training algorithm that uses best response\ndynamics and, in our experiments, yields similar or better empirical accuracy\nwith much lower variance than the challenging bi-level optimization problem of\nArjovsky et al. (2019). One key theoretical contribution is showing that the\nset of Nash equilibria for the proposed game are equivalent to the set of\ninvariant predictors for any finite number of environments, even with nonlinear\nclassifiers and transformations. As a result, our method also retains the\ngeneralization guarantees to a large set of environments shown in Arjovsky et\nal. (2019). The proposed algorithm adds to the collection of successful\ngame-theoretic machine learning algorithms such as generative adversarial\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:25:14 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 21:18:17 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Ahuja", "Kartik", ""], ["Shanmugam", "Karthikeyan", ""], ["Varshney", "Kush R.", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2002.04694", "submitter": "Pavol Bielik", "authors": "Pavol Bielik and Martin Vechev", "title": "Adversarial Robustness for Code", "comments": "Proceedings of the 37th International Conference on Machine Learning,\n  Online, PMLR 119, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and deep learning in particular has been recently used to\nsuccessfully address many tasks in the domain of code such as finding and\nfixing bugs, code completion, decompilation, type inference and many others.\nHowever, the issue of adversarial robustness of models for code has gone\nlargely unnoticed. In this work, we explore this issue by: (i) instantiating\nadversarial attacks for code (a domain with discrete and highly structured\ninputs), (ii) showing that, similar to other domains, neural models for code\nare vulnerable to adversarial attacks, and (iii) combining existing and novel\ntechniques to improve robustness while preserving high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:32:14 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 12:35:28 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bielik", "Pavol", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.04697", "submitter": "Filippo Pellegrino", "authors": "Filippo Pellegrino", "title": "Selecting time-series hyperparameters with the artificial jackknife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a generalisation of the delete-$d$ jackknife to solve\nhyperparameter selection problems for time series. This novel technique is\ncompatible with dependent data since it substitutes the jackknife removal step\nwith a fictitious deletion, wherein observed datapoints are replaced with\nartificial missing values. In order to emphasise this point, I called this\nmethodology artificial delete-$d$ jackknife. As an illustration, it is used to\nregulate vector autoregressions with an elastic-net penalty on the\ncoefficients. A software implementation, ElasticNetVAR.jl, is available on\nGitHub.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:38:51 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 19:37:17 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Pellegrino", "Filippo", ""]]}, {"id": "2002.04704", "submitter": "Robert Hu", "authors": "Robert Hu, Geoff K. Nicholls, Dino Sejdinovic", "title": "Large Scale Tensor Regression using Kernels and Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline an inherent weakness of tensor factorization models when latent\nfactors are expressed as a function of side information and propose a novel\nmethod to mitigate this weakness. We coin our method \\textit{Kernel Fried\nTensor}(KFT) and present it as a large scale forecasting tool for high\ndimensional data. Our results show superior performance against\n\\textit{LightGBM} and \\textit{Field Aware Factorization Machines}(FFM), two\nalgorithms with proven track records widely used in industrial forecasting. We\nalso develop a variational inference framework for KFT and associate our\nforecasts with calibrated uncertainty estimates on three large scale datasets.\nFurthermore, KFT is empirically shown to be robust against uninformative side\ninformation in terms of constants and Gaussian noise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:46:52 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hu", "Robert", ""], ["Nicholls", "Geoff K.", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2002.04706", "submitter": "Arman Oganisian", "authors": "Arman Oganisian, Nandita Mitra, Jason Roy", "title": "Bayesian Nonparametric Cost-Effectiveness Analyses: Causal Estimation\n  and Adaptive Subgroup Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cost-effectiveness analyses (CEAs) are at the center of health economic\ndecision making. While these analyses help policy analysts and economists\ndetermine coverage, inform policy, and guide resource allocation, they are\nstatistically challenging for several reasons. Cost and effectiveness are\ncorrelated and follow complex joint distributions which are difficult to\ncapture parametrically. Effectiveness (often measured as increased survival\ntime) and accumulated cost tends to be right-censored in many applications.\nMoreover, CEAs are often conducted using observational data with non-random\ntreatment assignment. Policy-relevant causal estimation therefore requires\nrobust confounding control. Finally, current CEA methods do not address\ncost-effectiveness heterogeneity in a principled way - often presenting\npopulation-averaged estimates even though significant effect heterogeneity may\nexist. Motivated by these challenges, we develop a nonparametric Bayesian model\nfor joint cost-survival distributions in the presence of censoring. Our\napproach utilizes a joint Enriched Dirichlet Process prior on the covariate\neffects of cost and survival time, while using a Gamma Process prior on the\nbaseline survival time hazard. Causal CEA estimands, with policy-relevant\ninterpretations, are identified and estimated via a Bayesian nonparametric\ng-computation procedure. Finally, we outline how the induced clustering of the\nEnriched Dirichlet Process can be used to adaptively detect presence of\nsubgroups with different cost-effectiveness profiles. We outline an MCMC\nprocedure for full posterior inference and evaluate frequentist properties via\nsimulations. We use our model to assess the cost-efficacy of chemotherapy\nversus radiation adjuvant therapy for treating endometrial cancer in the\nSEER-Medicare database.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:51:58 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 22:28:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Oganisian", "Arman", ""], ["Mitra", "Nandita", ""], ["Roy", "Jason", ""]]}, {"id": "2002.04709", "submitter": "Se Young Chun", "authors": "Kwanyoung Kim, Dongwon Park, Kwang In Kim, Se Young Chun", "title": "Task-Aware Variational Adversarial Active Learning", "comments": "14 pages, 13 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, labeling large amount of data is challenging due to high labeling cost\nlimiting the application domain of deep learning techniques. Active learning\n(AL) tackles this by querying the most informative samples to be annotated\namong unlabeled pool. Two promising directions for AL that have been recently\nexplored are task-agnostic approach to select data points that are far from the\ncurrent labeled pool and task-aware approach that relies on the perspective of\ntask model. Unfortunately, the former does not exploit structures from tasks\nand the latter does not seem to well-utilize overall data distribution. Here,\nwe propose task-aware variational adversarial AL (TA-VAAL) that modifies\ntask-agnostic VAAL, that considered data distribution of both label and\nunlabeled pools, by relaxing task learning loss prediction to ranking loss\nprediction and by using ranking conditional generative adversarial network to\nembed normalized ranking loss information on VAAL. Our proposed TA-VAAL\noutperforms state-of-the-arts on various benchmark datasets for classifications\nwith balanced / imbalanced labels as well as semantic segmentation and its\ntask-aware and task-agnostic AL properties were confirmed with our in-depth\nanalyses.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:00:48 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 05:36:08 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kim", "Kwanyoung", ""], ["Park", "Dongwon", ""], ["Kim", "Kwang In", ""], ["Chun", "Se Young", ""]]}, {"id": "2002.04710", "submitter": "Rotem Mulayoff", "authors": "Rotem Mulayoff, Tomer Michaeli", "title": "Unique Properties of Flat Minima in Deep Networks", "comments": "Presented at ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that (stochastic) gradient descent has an implicit bias\ntowards flat minima. In deep neural network training, this mechanism serves to\nscreen out minima. However, the precise effect that this has on the trained\nnetwork is not yet fully understood. In this paper, we characterize the flat\nminima in linear neural networks trained with a quadratic loss. First, we show\nthat linear ResNets with zero initialization necessarily converge to the\nflattest of all minima. We then prove that these minima correspond to nearly\nbalanced networks whereby the gain from the input to any intermediate\nrepresentation does not change drastically from one layer to the next. Finally,\nwe show that consecutive layers in flat minima solutions are coupled. That is,\none of the left singular vectors of each weight matrix, equals one of the right\nsingular vectors of the next matrix. This forms a distinct path from input to\noutput, that, as we show, is dedicated to the signal that experiences the\nlargest gain end-to-end. Experiments indicate that these properties are\ncharacteristic of both linear and nonlinear models trained in practice.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:01:19 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 22:13:17 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mulayoff", "Rotem", ""], ["Michaeli", "Tomer", ""]]}, {"id": "2002.04720", "submitter": "Kevin Yang", "authors": "Kevin Yang, Wengong Jin, Kyle Swanson, Regina Barzilay, Tommi Jaakkola", "title": "Improving Molecular Design by Stochastic Iterative Target Augmentation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models in molecular design tend to be richly parameterized,\ndata-hungry neural models, as they must create complex structured objects as\noutputs. Estimating such models from data may be challenging due to the lack of\nsufficient training data. In this paper, we propose a surprisingly effective\nself-training approach for iteratively creating additional molecular targets.\nWe first pre-train the generative model together with a simple property\npredictor. The property predictor is then used as a likelihood model for\nfiltering candidate structures from the generative model. Additional targets\nare iteratively produced and used in the course of stochastic EM iterations to\nmaximize the log-likelihood that the candidate structures are accepted. A\nsimple rejection (re-weighting) sampler suffices to draw posterior samples\nsince the generative model is already reasonable after pre-training. We\ndemonstrate significant gains over strong baselines for both unconditional and\nconditional molecular design. In particular, our approach outperforms the\nprevious state-of-the-art in conditional molecular design by over 10% in\nabsolute gain. Finally, we show that our approach is useful in other domains as\nwell, such as program synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:40:04 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 21:00:24 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Kevin", ""], ["Jin", "Wengong", ""], ["Swanson", "Kyle", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.04723", "submitter": "Li Zhang", "authors": "John Anderson, Qingqing Huang, Walid Krichene, Steffen Rendle, Li\n  Zhang", "title": "Superbloom: Bloom filter meets Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the idea of word pieces in natural language models to machine\nlearning tasks on opaque ids. This is achieved by applying hash functions to\nmap each id to multiple hash tokens in a much smaller space, similarly to a\nBloom filter. We show that by applying a multi-layer Transformer to these Bloom\nfilter digests, we are able to obtain models with high accuracy. They\noutperform models of a similar size without hashing and, to a large degree,\nmodels of a much larger size trained using sampled softmax with the same\ncomputational budget. Our key observation is that it is important to use a\nmulti-layer Transformer for Bloom filter digests to remove ambiguity in the\nhashed input. We believe this provides an alternative method to solving\nproblems with large vocabulary size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:52:40 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Anderson", "John", ""], ["Huang", "Qingqing", ""], ["Krichene", "Walid", ""], ["Rendle", "Steffen", ""], ["Zhang", "Li", ""]]}, {"id": "2002.04724", "submitter": "Zhengli Zhao", "authors": "Zhengli Zhao, Sameer Singh, Honglak Lee, Zizhao Zhang, Augustus Odena,\n  Han Zhang", "title": "Improved Consistency Regularization for GANs", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has increased the performance of Generative Adversarial Networks\n(GANs) by enforcing a consistency cost on the discriminator. We improve on this\ntechnique in several ways. We first show that consistency regularization can\nintroduce artifacts into the GAN samples and explain how to fix this issue. We\nthen propose several modifications to the consistency regularization procedure\ndesigned to improve its performance. We carry out extensive experiments\nquantifying the benefit of our improvements. For unconditional image synthesis\non CIFAR-10 and CelebA, our modifications yield the best known FID scores on\nvarious GAN architectures. For conditional image synthesis on CIFAR-10, we\nimprove the state-of-the-art FID score from 11.48 to 9.21. Finally, on\nImageNet-2012, we apply our technique to the original BigGAN model and improve\nthe FID from 6.66 to 5.38, which is the best score at that model size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:53:21 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 21:33:59 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhao", "Zhengli", ""], ["Singh", "Sameer", ""], ["Lee", "Honglak", ""], ["Zhang", "Zizhao", ""], ["Odena", "Augustus", ""], ["Zhang", "Han", ""]]}, {"id": "2002.04725", "submitter": "Lin Chen", "authors": "Lin Chen, Yifei Min, Mingrui Zhang, Amin Karbasi", "title": "More Data Can Expand the Generalization Gap Between Adversarially Robust\n  and Standard Models", "comments": "Accepted to ICML'20. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable success in practice, modern machine learning models have\nbeen found to be susceptible to adversarial attacks that make\nhuman-imperceptible perturbations to the data, but result in serious and\npotentially dangerous prediction errors. To address this issue, practitioners\noften use adversarial training to learn models that are robust against such\nattacks at the cost of higher generalization error on unperturbed test sets.\nThe conventional wisdom is that more training data should shrink the gap\nbetween the generalization error of adversarially-trained models and standard\nmodels. However, we study the training of robust classifiers for both Gaussian\nand Bernoulli models under $\\ell_\\infty$ attacks, and we prove that more data\nmay actually increase this gap. Furthermore, our theoretical results identify\nif and when additional data will finally begin to shrink the gap. Lastly, we\nexperimentally demonstrate that our results also hold for linear regression\nmodels, which may indicate that this phenomenon occurs more broadly.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:01:29 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:55:55 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 23:36:51 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Lin", ""], ["Min", "Yifei", ""], ["Zhang", "Mingrui", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.04726", "submitter": "Manish Purohit", "authors": "Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar and Manish Purohit", "title": "Online Learning with Imperfect Hints", "comments": "appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the classical online linear optimization problem in\nwhich at every step, the online player receives a \"hint\" vector before choosing\nthe action for that round. Rather surprisingly, it was shown that if the hint\nvector is guaranteed to have a positive correlation with the cost vector, then\nthe online player can achieve a regret of $O(\\log T)$, thus significantly\nimproving over the $O(\\sqrt{T})$ regret in the general setting. However, the\nresult and analysis require the correlation property at \\emph{all} time steps,\nthus raising the natural question: can we design online learning algorithms\nthat are resilient to bad hints?\n  In this paper we develop algorithms and nearly matching lower bounds for\nonline learning with imperfect directional hints. Our algorithms are oblivious\nto the quality of the hints, and the regret bounds interpolate between the\nalways-correlated hints case and the no-hints case. Our results also\ngeneralize, simplify, and improve upon previous results on optimistic regret\nbounds, which can be viewed as an additive version of hints.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:06:09 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 17:28:35 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Cutkosky", "Ashok", ""], ["Kumar", "Ravi", ""], ["Purohit", "Manish", ""]]}, {"id": "2002.04732", "submitter": "Kumar Vijay Mishra", "authors": "Kumar Vijay Mishra and M. Ashok Kumar", "title": "Generalized Bayesian Cram\\'{e}r-Rao Inequality via Information Geometry\n  of Relative $\\alpha$-Entropy", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relative $\\alpha$-entropy is the R\\'enyi analog of relative entropy and\narises prominently in information-theoretic problems. Recent information\ngeometric investigations on this quantity have enabled the generalization of\nthe Cram\\'{e}r-Rao inequality, which provides a lower bound for the variance of\nan estimator of an escort of the underlying parametric probability\ndistribution. However, this framework remains unexamined in the Bayesian\nframework. In this paper, we propose a general Riemannian metric based on\nrelative $\\alpha$-entropy to obtain a generalized Bayesian Cram\\'{e}r-Rao\ninequality. This establishes a lower bound for the variance of an unbiased\nestimator for the $\\alpha$-escort distribution starting from an unbiased\nestimator for the underlying distribution. We show that in the limiting case\nwhen the entropy order approaches unity, this framework reduces to the\nconventional Bayesian Cram\\'{e}r-Rao inequality. Further, in the absence of\npriors, the same framework yields the deterministic Cram\\'{e}r-Rao inequality.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:38:01 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Mishra", "Kumar Vijay", ""], ["Kumar", "M. Ashok", ""]]}, {"id": "2002.04742", "submitter": "Klas Leino", "authors": "Aymeric Fromherz, Klas Leino, Matt Fredrikson, Bryan Parno, Corina\n  P\\u{a}s\\u{a}reanu", "title": "Fast Geometric Projections for Local Robustness Certification", "comments": "Appearing in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local robustness ensures that a model classifies all inputs within an\n$\\ell_2$-ball consistently, which precludes various forms of adversarial\ninputs. In this paper, we present a fast procedure for checking local\nrobustness in feed-forward neural networks with piecewise-linear activation\nfunctions. Such networks partition the input space into a set of convex\npolyhedral regions in which the network's behavior is linear; hence, a\nsystematic search for decision boundaries within the regions around a given\ninput is sufficient for assessing robustness. Crucially, we show how the\nregions around a point can be analyzed using simple geometric projections, thus\nadmitting an efficient, highly-parallel GPU implementation that excels\nparticularly for the $\\ell_2$ norm, where previous work has been less\neffective. Empirically we find this approach to be far more precise than many\napproximate verification approaches, while at the same time performing multiple\norders of magnitude faster than complete verifiers, and scaling to much deeper\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:21:55 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 03:20:39 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 18:42:52 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Fromherz", "Aymeric", ""], ["Leino", "Klas", ""], ["Fredrikson", "Matt", ""], ["Parno", "Bryan", ""], ["P\u0103s\u0103reanu", "Corina", ""]]}, {"id": "2002.04745", "submitter": "Di He", "authors": "Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen\n  Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu", "title": "On Layer Normalization in the Transformer Architecture", "comments": null, "journal-ref": "Published on ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer is widely used in natural language processing tasks. To train\na Transformer however, one usually needs a carefully designed learning rate\nwarm-up stage, which is shown to be crucial to the final performance but will\nslow down the optimization and bring more hyper-parameter tunings. In this\npaper, we first study theoretically why the learning rate warm-up stage is\nessential and show that the location of layer normalization matters.\nSpecifically, we prove with mean field theory that at initialization, for the\noriginal-designed Post-LN Transformer, which places the layer normalization\nbetween the residual blocks, the expected gradients of the parameters near the\noutput layer are large. Therefore, using a large learning rate on those\ngradients makes the training unstable. The warm-up stage is practically helpful\nfor avoiding this problem. On the other hand, our theory also shows that if the\nlayer normalization is put inside the residual blocks (recently proposed as\nPre-LN Transformer), the gradients are well-behaved at initialization. This\nmotivates us to remove the warm-up stage for the training of Pre-LN\nTransformers. We show in our experiments that Pre-LN Transformers without the\nwarm-up stage can reach comparable results with baselines while requiring\nsignificantly less training time and hyper-parameter tuning on a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:33:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 07:55:12 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Ruibin", ""], ["Yang", "Yunchang", ""], ["He", "Di", ""], ["Zheng", "Kai", ""], ["Zheng", "Shuxin", ""], ["Xing", "Chen", ""], ["Zhang", "Huishuai", ""], ["Lan", "Yanyan", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2002.04747", "submitter": "Samory Kpotufe", "authors": "Steve Hanneke and Samory Kpotufe", "title": "On the Value of Target Data in Transfer Learning", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to understand the value of additional labeled or unlabeled target data\nin transfer learning, for any given amount of source data; this is motivated by\npractical questions around minimizing sampling costs, whereby, target data is\nusually harder or costlier to acquire than source data, but can yield better\naccuracy. To this aim, we establish the first minimax-rates in terms of both\nsource and target sample sizes, and show that performance limits are captured\nby new notions of discrepancy between source and target, which we refer to as\ntransfer exponents.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:37:18 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hanneke", "Steve", ""], ["Kpotufe", "Samory", ""]]}, {"id": "2002.04753", "submitter": "Ting-Jui Chang", "authors": "Ting-Jui Chang, Shahin Shahrampour", "title": "RFN: A Random-Feature Based Newton Method for Empirical Risk\n  Minimization in Reproducing Kernel Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning using kernel methods, we encounter a large-scale\nfinite-sum minimization over a reproducing kernel Hilbert space (RKHS). Often\ntimes large-scale finite-sum problems can be solved using efficient variants of\nNewton's method where the Hessian is approximated via sub-samples. In RKHS,\nhowever, the dependence of the penalty function to kernel makes standard\nsub-sampling approaches inapplicable, since the gram matrix is not readily\navailable in a low-rank form. In this paper, we observe that for this class of\nproblems, one can naturally use kernel approximation to speed up the Newton's\nmethod. Focusing on randomized features for kernel approximation, we provide a\nnovel second-order algorithm that enjoys local superlinear convergence and\nglobal convergence in the high probability sense. The key to our analysis is\nshowing that the approximated Hessian via random features preserves the\nspectrum of the original Hessian. We provide numerical experiments verifying\nthe efficiency of our approach, compared to variants of sub-sampling methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:14:44 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 03:04:44 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 22:03:46 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Chang", "Ting-Jui", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2002.04758", "submitter": "Tao Yu", "authors": "Tao Yu, Eugene Bagdasaryan, Vitaly Shmatikov", "title": "Salvaging Federated Learning by Local Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a heavily promoted approach for training ML models\non sensitive data, e.g., text typed by users on their smartphones. FL is\nexpressly designed for training on data that are unbalanced and non-iid across\nthe participants. To ensure privacy and integrity of the federated model,\nlatest FL approaches use differential privacy or robust aggregation to limit\nthe influence of \"outlier\" participants.\n  First, we show that on standard tasks such as next-word prediction, many\nparticipants gain no benefit from FL because the federated model is less\naccurate on their data than the models they can train locally on their own.\nSecond, we show that differential privacy and robust aggregation make this\nproblem worse by further destroying the accuracy of the federated model for\nmany participants.\n  Then, we evaluate three techniques for local adaptation of federated models:\nfine-tuning, multi-task learning, and knowledge distillation. We analyze where\neach technique is applicable and demonstrate that all participants benefit from\nlocal adaptation. Participants whose local models are poor obtain big accuracy\nimprovements over conventional FL. Participants whose local models are better\nthan the federated model and who have no incentive to participate in FL today\nimprove less, but sufficiently to make the adapted federated model better than\ntheir local models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:56:16 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yu", "Tao", ""], ["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2002.04759", "submitter": "Chi Zhang", "authors": "Chi Zhang, Yong Sheng Soh, Ling Feng, Tianyi Zhou, Qianxiao Li", "title": "Collaborative Inference for Efficient Remote Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current machine learning models have impressive performance over a wide\nrange of applications, their large size and complexity render them unsuitable\nfor tasks such as remote monitoring on edge devices with limited storage and\ncomputational power. A naive approach to resolve this on the model level is to\nuse simpler architectures, but this sacrifices prediction accuracy and is\nunsuitable for monitoring applications requiring accurate detection of the\nonset of adverse events. In this paper, we propose an alternative solution to\nthis problem by decomposing the predictive model as the sum of a simple\nfunction which serves as a local monitoring tool, and a complex correction term\nto be evaluated on the server. A sign requirement is imposed on the latter to\nensure that the local monitoring function is safe, in the sense that it can\neffectively serve as an early warning system. Our analysis quantifies the\ntrade-offs between model complexity and performance, and serves as a guidance\nfor architecture design. We validate our proposed framework on a series of\nmonitoring experiments, where we succeed at learning monitoring models with\nsignificantly reduced complexity that minimally violate the safety requirement.\nMore broadly, our framework is useful for learning classifiers in applications\nwhere false negatives are significantly more costly compared to false\npositives.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:57:17 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhang", "Chi", ""], ["Soh", "Yong Sheng", ""], ["Feng", "Ling", ""], ["Zhou", "Tianyi", ""], ["Li", "Qianxiao", ""]]}, {"id": "2002.04763", "submitter": "Bo Liu", "authors": "Bo Liu", "title": "Understanding Global Loss Landscape of One-hidden-layer ReLU Networks,\n  Part 1: Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For one-hidden-layer ReLU networks, we prove that all differentiable local\nminima are global inside differentiable regions. We give the locations and\nlosses of differentiable local minima, and show that these local minima can be\nisolated points or continuous hyperplanes, depending on an interplay between\ndata, activation pattern of hidden neurons and network size. Furthermore, we\ngive necessary and sufficient conditions for the existence of saddle points as\nwell as non-differentiable local minima, and their locations if they exist.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:04:55 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 01:57:24 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Liu", "Bo", ""]]}, {"id": "2002.04764", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai, Nitish Srivastava, Hanlin Goh, Ruslan\n  Salakhutdinov", "title": "Capsules with Inverted Dot-Product Attention Routing", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new routing algorithm for capsule networks, in which a child\ncapsule is routed to a parent based only on agreement between the parent's\nstate and the child's vote. The new mechanism 1) designs routing via inverted\ndot-product attention; 2) imposes Layer Normalization as normalization; and 3)\nreplaces sequential iterative routing with concurrent iterative routing. When\ncompared to previously proposed routing algorithms, our method improves\nperformance on benchmark datasets such as CIFAR-10 and CIFAR-100, and it\nperforms at-par with a powerful CNN (ResNet-18) with 4x fewer parameters. On a\ndifferent task of recognizing digits from overlayed digit images, the proposed\ncapsule model performs favorably against CNNs given the same number of layers\nand neurons per layer. We believe that our work raises the possibility of\napplying capsule networks to complex real-world tasks. Our code is publicly\navailable at: https://github.com/apple/ml-capsules-inverted-attention-routing\nAn alternative implementation is available at:\nhttps://github.com/yaohungt/Capsules-Inverted-Attention-Routing/blob/master/README.md\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:09:33 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 17:48:16 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Srivastava", "Nitish", ""], ["Goh", "Hanlin", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2002.04766", "submitter": "Liam Collins", "authors": "Liam Collins, Aryan Mokhtari, Sanjay Shakkottai", "title": "Task-Robust Model-Agnostic Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning methods have shown an impressive ability to train models that\nrapidly learn new tasks. However, these methods only aim to perform well in\nexpectation over tasks coming from some particular distribution that is\ntypically equivalent across meta-training and meta-testing, rather than\nconsidering worst-case task performance. In this work we introduce the notion\nof \"task-robustness\" by reformulating the popular Model-Agnostic Meta-Learning\n(MAML) objective [Finn et al. 2017] such that the goal is to minimize the\nmaximum loss over the observed meta-training tasks. The solution to this novel\nformulation is task-robust in the sense that it places equal importance on even\nthe most difficult and/or rare tasks. This also means that it performs well\nover all distributions of the observed tasks, making it robust to shifts in the\ntask distribution between meta-training and meta-testing. We present an\nalgorithm to solve the proposed min-max problem, and show that it converges to\nan $\\epsilon$-accurate point at the optimal rate of $\\mathcal{O}(1/\\epsilon^2)$\nin the convex setting and to an $(\\epsilon, \\delta)$-stationary point at the\nrate of $\\mathcal{O}(\\max\\{1/\\epsilon^5, 1/\\delta^5\\})$ in nonconvex settings.\nWe also provide an upper bound on the new task generalization error that\ncaptures the advantage of minimizing the worst-case task loss, and demonstrate\nthis advantage in sinusoid regression and image classification experiments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:20:51 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 03:06:25 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Collins", "Liam", ""], ["Mokhtari", "Aryan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2002.04770", "submitter": "Hugh Chen", "authors": "Hugh Chen, Scott Lundberg, Gabe Erion, Jerry H. Kim, Su-In Lee", "title": "Forecasting adverse surgical events using self-supervised transfer\n  learning for physiological signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hundreds of millions of surgical procedures take place annually across the\nworld, which generate a prevalent type of electronic health record (EHR) data\ncomprising time series physiological signals. Here, we present a transferable\nembedding method (i.e., a method to transform time series signals into input\nfeatures for predictive machine learning models) named PHASE (PHysiologicAl\nSignal Embeddings) that enables us to more accurately forecast adverse surgical\noutcomes based on physiological signals. We evaluate PHASE on minute-by-minute\nEHR data of more than 50,000 surgeries from two operating room (OR) datasets\nand patient stays in an intensive care unit (ICU) dataset. PHASE outperforms\nother state-of-the-art approaches, such as long-short term memory networks\ntrained on raw data and gradient boosted trees trained on handcrafted features,\nin predicting five distinct outcomes: hypoxemia, hypocapnia, hypotension,\nhypertension, and phenylephrine administration. In a transfer learning setting\nwhere we train embedding models in one dataset then embed signals and predict\nadverse events in unseen data, PHASE achieves significantly higher prediction\naccuracy at lower computational cost compared to conventional approaches.\nFinally, given the importance of understanding models in clinical applications\nwe demonstrate that PHASE is explainable and validate our predictive models\nusing local feature attribution methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:49:15 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 21:27:17 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Chen", "Hugh", ""], ["Lundberg", "Scott", ""], ["Erion", "Gabe", ""], ["Kim", "Jerry H.", ""], ["Lee", "Su-In", ""]]}, {"id": "2002.04783", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Nhat Ho, Xi Chen, Marco Cuturi, and Michael I. Jordan", "title": "Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast\n  Algorithm", "comments": "Accepted by NeurIPS 2020; fix some confusing parts in the proof and\n  improve the empirical evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fixed-support Wasserstein barycenter problem (FS-WBP), which\nconsists in computing the Wasserstein barycenter of $m$ discrete probability\nmeasures supported on a finite metric space of size $n$. We show first that the\nconstraint matrix arising from the standard linear programming (LP)\nrepresentation of the FS-WBP is \\textit{not totally unimodular} when $m \\geq 3$\nand $n \\geq 3$. This result resolves an open question pertaining to the\nrelationship between the FS-WBP and the minimum-cost flow (MCF) problem since\nit proves that the FS-WBP in the standard LP form is not an MCF problem when $m\n\\geq 3$ and $n \\geq 3$. We also develop a provably fast \\textit{deterministic}\nvariant of the celebrated iterative Bregman projection (IBP) algorithm, named\n\\textsc{FastIBP}, with a complexity bound of\n$\\tilde{O}(mn^{7/3}\\varepsilon^{-4/3})$, where $\\varepsilon \\in (0, 1)$ is the\ndesired tolerance. This complexity bound is better than the best known\ncomplexity bound of $\\tilde{O}(mn^2\\varepsilon^{-2})$ for the IBP algorithm in\nterms of $\\varepsilon$, and that of $\\tilde{O}(mn^{5/2}\\varepsilon^{-1})$ from\naccelerated alternating minimization algorithm or accelerated primal-dual\nadaptive gradient algorithm in terms of $n$. Finally, we conduct extensive\nexperiments with both synthetic data and real images and demonstrate the\nfavorable performance of the \\textsc{FastIBP} algorithm in practice.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:40:52 GMT"}, {"version": "v10", "created": "Mon, 26 Jul 2021 17:26:50 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:08:33 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 20:13:25 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 11:16:44 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 03:38:29 GMT"}, {"version": "v6", "created": "Sat, 17 Oct 2020 02:19:25 GMT"}, {"version": "v7", "created": "Wed, 25 Nov 2020 23:08:14 GMT"}, {"version": "v8", "created": "Sun, 20 Dec 2020 11:25:02 GMT"}, {"version": "v9", "created": "Sat, 17 Jul 2021 06:25:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Tianyi", ""], ["Ho", "Nhat", ""], ["Chen", "Xi", ""], ["Cuturi", "Marco", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.04784", "submitter": "Jie Chen", "authors": "Xiao Zang, Yi Xie, Jie Chen, Bo Yuan", "title": "Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph\n  Learning Models", "comments": "IJCAI 2021. Code is available at\n  https://github.com/chisam0217/Graph-Universal-Attack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, while generalize well, are known to be sensitive to\nsmall adversarial perturbations. This phenomenon poses severe security threat\nand calls for in-depth investigation of the robustness of deep learning models.\nWith the emergence of neural networks for graph structured data, similar\ninvestigations are urged to understand their robustness. It has been found that\nadversarially perturbing the graph structure and/or node features may result in\na significant degradation of the model performance. In this work, we show from\na different angle that such fragility similarly occurs if the graph contains a\nfew bad-actor nodes, which compromise a trained graph neural network through\nflipping the connections to any targeted victim. Worse, the bad actors found\nfor one graph model severely compromise other models as well. We call the bad\nactors ``anchor nodes'' and propose an algorithm, named GUA, to identify them.\nThorough empirical investigations suggest an interesting finding that the\nanchor nodes often belong to the same class; and they also corroborate the\nintuitive trade-off between the number of anchor nodes and the attack success\nrate. For the dataset Cora which contains 2708 nodes, as few as six anchor\nnodes will result in an attack success rate higher than 80\\% for GCN and other\nthree models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:52:11 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 03:41:22 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zang", "Xiao", ""], ["Xie", "Yi", ""], ["Chen", "Jie", ""], ["Yuan", "Bo", ""]]}, {"id": "2002.04788", "submitter": "Hao Wang", "authors": "Hao Wang, Hsiang Hsu, Mario Diaz, Flavio P. Calmon", "title": "To Split or Not to Split: The Impact of Disparate Treatment in\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:05:31 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:13:28 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 21:05:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Hao", ""], ["Hsu", "Hsiang", ""], ["Diaz", "Mario", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2002.04792", "submitter": "Yu Zhang", "authors": "Sicong Liang and Yu Zhang", "title": "A Simple General Approach to Balance Task Difficulty in Multi-Task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task learning, difficulty levels of different tasks are varying.\nThere are many works to handle this situation and we classify them into five\ncategories, including the direct sum approach, the weighted sum approach, the\nmaximum approach, the curriculum learning approach, and the multi-objective\noptimization approach. Those approaches have their own limitations, for\nexample, using manually designed rules to update task weights, non-smooth\nobjective function, and failing to incorporate other functions than training\nlosses. In this paper, to alleviate those limitations, we propose a Balanced\nMulti-Task Learning (BMTL) framework. Different from existing studies which\nrely on task weighting, the BMTL framework proposes to transform the training\nloss of each task to balance difficulty levels among tasks based on an\nintuitive idea that tasks with larger training losses will receive more\nattention during the optimization procedure. We analyze the transformation\nfunction and derive necessary conditions. The proposed BMTL framework is very\nsimple and it can be combined with most multi-task learning models. Empirical\nstudies show the state-of-the-art performance of the proposed BMTL framework.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:31:34 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Liang", "Sicong", ""], ["Zhang", "Yu", ""]]}, {"id": "2002.04799", "submitter": "Yu Zhang", "authors": "Yi Zhang, Yu Zhang, Wei Wang", "title": "Deep Multi-Task Learning via Generalized Tensor Trace Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trace norm is widely used in multi-task learning as it can discover\nlow-rank structures among tasks in terms of model parameters. Nowadays, with\nthe emerging of big datasets and the popularity of deep learning techniques,\ntensor trace norms have been used for deep multi-task models. However, existing\ntensor trace norms cannot discover all the low-rank structures and they require\nusers to manually determine the importance of their components. To solve those\ntwo issues together, in this paper, we propose a Generalized Tensor Trace Norm\n(GTTN). The GTTN is defined as a convex combination of matrix trace norms of\nall possible tensor flattenings and hence it can discover all the possible\nlow-rank structures. In the induced objective function, we will learn\ncombination coefficients in the GTTN to automatically determine the importance.\nExperiments on real-world datasets demonstrate the effectiveness of the\nproposed GTTN.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:06:35 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhang", "Yi", ""], ["Zhang", "Yu", ""], ["Wang", "Wei", ""]]}, {"id": "2002.04803", "submitter": "Sebastian Raschka", "authors": "Sebastian Raschka, Joshua Patterson, Corey Nolet", "title": "Machine Learning in Python: Main developments and technology trends in\n  data science, machine learning, and artificial intelligence", "comments": "Preprint of a manuscript accepted for publication in \"Machine\n  Learning with Python,\" a special issue of Information (ISSN 2078-2489)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smarter applications are making better use of the insights gleaned from data,\nhaving an impact on every industry and research discipline. At the core of this\nrevolution lies the tools and the methods that are driving it, from processing\nthe massive piles of data generated each day to learning from and taking useful\naction. Deep neural networks, along with advancements in classical ML and\nscalable general-purpose GPU computing, have become critical components of\nartificial intelligence, enabling many of these astounding breakthroughs and\nlowering the barrier to adoption. Python continues to be the most preferred\nlanguage for scientific computing, data science, and machine learning, boosting\nboth performance and productivity by enabling the use of low-level libraries\nand clean high-level APIs. This survey offers insight into the field of machine\nlearning with Python, taking a tour through important topics to identify some\nof the core hardware and software paradigms that have enabled it. We cover\nwidely-used libraries and concepts, collected together for holistic comparison,\nwith the goal of educating the reader and driving the field of Python machine\nlearning forward.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:20:59 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 16:58:28 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Raschka", "Sebastian", ""], ["Patterson", "Joshua", ""], ["Nolet", "Corey", ""]]}, {"id": "2002.04805", "submitter": "Christoph David Hofer PhD MSc", "authors": "Christoph D. Hofer, Florian Graf, Marc Niethammer, Roland Kwitt", "title": "Topologically Densified Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study regularization in the context of small sample-size learning with\nover-parameterized neural networks. Specifically, we shift focus from\narchitectural properties, such as norms on the network weights, to properties\nof the internal representations before a linear classifier. Specifically, we\nimpose a topological constraint on samples drawn from the probability measure\ninduced in that space. This provably leads to mass concentration effects around\nthe representations of training instances, i.e., a property beneficial for\ngeneralization. By leveraging previous work to impose topological constraints\nin a neural network setting, we provide empirical evidence (across various\nvision benchmarks) to support our claim for better generalization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:25:15 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 04:15:03 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hofer", "Christoph D.", ""], ["Graf", "Florian", ""], ["Niethammer", "Marc", ""], ["Kwitt", "Roland", ""]]}, {"id": "2002.04809", "submitter": "Jaeho Lee", "authors": "Sejun Park, Jaeho Lee, Sangwoo Mo, Jinwoo Shin", "title": "Lookahead: A Far-Sighted Alternative of Magnitude-based Pruning", "comments": "ICLR 2020, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnitude-based pruning is one of the simplest methods for pruning neural\nnetworks. Despite its simplicity, magnitude-based pruning and its variants\ndemonstrated remarkable performances for pruning modern architectures. Based on\nthe observation that magnitude-based pruning indeed minimizes the Frobenius\ndistortion of a linear operator corresponding to a single layer, we develop a\nsimple pruning method, coined lookahead pruning, by extending the single layer\noptimization to a multi-layer optimization. Our experimental results\ndemonstrate that the proposed method consistently outperforms magnitude-based\npruning on various networks, including VGG and ResNet, particularly in the\nhigh-sparsity regime. See https://github.com/alinlab/lookahead_pruning for\ncodes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:38:42 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Park", "Sejun", ""], ["Lee", "Jaeho", ""], ["Mo", "Sangwoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2002.04813", "submitter": "Yu Zhang Dr.", "authors": "Pengxin Guo, Chang Deng, Linjie Xu, Xiaonan Huang, Yu Zhang", "title": "Deep Multi-Task Augmented Feature Learning via Hierarchical Graph Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep multi-task learning attracts much attention in recent years as it\nachieves good performance in many applications. Feature learning is important\nto deep multi-task learning for sharing common information among tasks. In this\npaper, we propose a Hierarchical Graph Neural Network (HGNN) to learn augmented\nfeatures for deep multi-task learning. The HGNN consists of two-level graph\nneural networks. In the low level, an intra-task graph neural network is\nresponsible of learning a powerful representation for each data point in a task\nby aggregating its neighbors. Based on the learned representation, a task\nembedding can be generated for each task in a similar way to max pooling. In\nthe second level, an inter-task graph neural network updates task embeddings of\nall the tasks based on the attention mechanism to model task relations. Then\nthe task embedding of one task is used to augment the feature representation of\ndata points in this task. Moreover, for classification tasks, an inter-class\ngraph neural network is introduced to conduct similar operations on a finer\ngranularity, i.e., the class level, to generate class embeddings for each class\nin all the tasks use class embeddings to augment the feature representation.\nThe proposed feature augmentation strategy can be used in many deep multi-task\nlearning models. we analyze the HGNN in terms of training and generalization\nlosses. Experiments on real-world datastes show the significant performance\nimprovement when using this strategy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 06:02:20 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Guo", "Pengxin", ""], ["Deng", "Chang", ""], ["Xu", "Linjie", ""], ["Huang", "Xiaonan", ""], ["Zhang", "Yu", ""]]}, {"id": "2002.04829", "submitter": "Cong Geng", "authors": "Cong Geng, Jia Wang, Li Chen, Wenbo Bao, Chu Chu, Zhiyong Gao", "title": "Uniform Interpolation Constrained Geodesic Learning on Data Manifold", "comments": "submitted to NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method to learn a minimizing geodesic within a\ndata manifold. Along the learned geodesic, our method can generate high-quality\ninterpolations between two given data samples. Specifically, we use an\nautoencoder network to map data samples into latent space and perform\ninterpolation via an interpolation network. We add prior geometric information\nto regularize our autoencoder for the convexity of representations so that for\nany given interpolation approach, the generated interpolations remain within\nthe distribution of the data manifold. Before the learning of a geodesic, a\nproper Riemannianmetric should be defined. Therefore, we induce a Riemannian\nmetric by the canonical metric in the Euclidean space which the data manifold\nis isometrically immersed in. Based on this defined Riemannian metric, we\nintroduce a constant speed loss and a minimizing geodesic loss to regularize\nthe interpolation network to generate uniform interpolation along the learned\ngeodesic on the manifold. We provide a theoretical analysis of our model and\nuse image translation as an example to demonstrate the effectiveness of our\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 07:47:41 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:16:20 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 01:23:45 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 05:32:56 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Geng", "Cong", ""], ["Wang", "Jia", ""], ["Chen", "Li", ""], ["Bao", "Wenbo", ""], ["Chu", "Chu", ""], ["Gao", "Zhiyong", ""]]}, {"id": "2002.04839", "submitter": "Zhikang Wang Mr.", "authors": "Liu Ziyin, Zhikang T.Wang, Masahito Ueda", "title": "LaProp: Separating Momentum and Adaptivity in Adam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identity a by-far-unrecognized problem of Adam-style optimizers which\nresults from unnecessary coupling between momentum and adaptivity. The coupling\nleads to instability and divergence when the momentum and adaptivity parameters\nare mismatched. In this work, we propose a method, Laprop, which decouples\nmomentum and adaptivity in the Adam-style methods. We show that the decoupling\nleads to greater flexibility in the hyperparameters and allows for a\nstraightforward interpolation between the signed gradient methods and the\nadaptive gradient methods. We experimentally show that Laprop has consistently\nimproved speed and stability over Adam on a variety of tasks. We also bound the\nregret of Laprop on a convex problem and show that our bound differs from that\nof Adam by a key factor, which demonstrates its advantage.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:28:19 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 11:58:21 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 21:13:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ziyin", "Liu", ""], ["Wang", "Zhikang T.", ""], ["Ueda", "Masahito", ""]]}, {"id": "2002.04840", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang and Jie Shen and Pranjal Awasthi", "title": "Efficient active learning of sparse halfspaces with arbitrary bounded\n  noise", "comments": "43 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active learning of homogeneous $s$-sparse halfspaces in\n$\\mathbb{R}^d$ under label noise. Even in the presence of mild label noise this\nis a challenging problem and only recently have label complexity bounds of the\nform $\\tilde{\\mathcal{O}} (s \\cdot \\mathrm{polylog}(d, \\frac{1}{\\epsilon}) )$\nbeen established in \\cite{zhang2018efficient} for computationally efficient\nalgorithms under the broad class of isotropic log-concave distributions. In\ncontrast, under high levels of label noise, the label complexity bounds\nachieved by computationally efficient algorithms are much worse. When the label\nnoise satisfies the {\\em Massart} condition \\cite{massart2006risk}, i.e., each\nlabel is flipped with probability at most $\\eta$ for a parameter $\\eta \\in\n\\big[0, \\frac12\\big)$, state-of-the-art result \\cite{awasthi2016learning}\nprovides a computationally efficient active learning algorithm under isotropic\nlog-concave distributions with label complexity\n$\\tilde{\\mathcal{O}}(s^{\\mathrm{poly}({1/(1-2\\eta)})} \\mathrm{poly}(\\ln d,\n\\frac{1}{\\epsilon}) )$, which is label-efficient only when the noise rate\n$\\eta$ is a constant. In this work, we substantially improve on it by designing\na polynomial time algorithm for active learning of $s$-sparse halfspaces under\nbounded noise and isotropic log-concave distributions, with a label complexity\nof $\\tilde{\\mathcal{O}}\\Big(\\frac{s}{(1-2\\eta)^4} \\mathrm{polylog} (d, \\frac 1\n\\epsilon) \\Big)$. This is the first efficient algorithm with label complexity\npolynomial in $\\frac{1}{1-2\\eta}$ in this setting, which is label-efficient\neven for $\\eta$ arbitrarily close to $\\frac12$. Our guarantees also immediately\ntranslate to new state-of-the-art label complexity results for full-dimensional\nactive and passive halfspace learning under arbitrary bounded noise and\nisotropic log-concave distributions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:28:24 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 06:05:13 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Zhang", "Chicheng", ""], ["Shen", "Jie", ""], ["Awasthi", "Pranjal", ""]]}, {"id": "2002.04861", "submitter": "David Holzm\\\"uller", "authors": "David Holzm\\\"uller and Ingo Steinwart", "title": "Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent", "comments": "Changes in v2: Single-column layout, NTK discussion, new experiment,\n  updated introduction, improved explanations. 20 pages + 33 pages appendix.\n  Code available at https://github.com/dholzmueller/nn_inconsistency", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that two-layer (Leaky)ReLU networks initialized by e.g. the widely\nused method proposed by He et al. (2015) and trained using gradient descent on\na least-squares loss are not universally consistent. Specifically, we describe\na large class of one-dimensional data-generating distributions for which, with\nhigh probability, gradient descent only finds a bad local minimum of the\noptimization landscape. It turns out that in these cases, the found network\nessentially performs linear regression even if the target function is\nnon-linear. We further provide numerical evidence that this happens in\npractical situations, for some multi-dimensional distributions and that\nstochastic gradient descent exhibits similar behavior.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:22:45 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 17:33:31 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Holzm\u00fcller", "David", ""], ["Steinwart", "Ingo", ""]]}, {"id": "2002.04862", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "Convex Density Constraints for Computing Plausible Counterfactual\n  Explanations", "comments": "Accepted at ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing deployment of machine learning as well as legal regulations\nsuch as EU's GDPR cause a need for user-friendly explanations of decisions\nproposed by machine learning models. Counterfactual explanations are considered\nas one of the most popular techniques to explain a specific decision of a\nmodel. While the computation of \"arbitrary\" counterfactual explanations is well\nstudied, it is still an open research problem how to efficiently compute\nplausible and feasible counterfactual explanations. We build upon recent work\nand propose and study a formal definition of plausible counterfactual\nexplanations. In particular, we investigate how to use density estimators for\nenforcing plausibility and feasibility of counterfactual explanations. For the\npurpose of efficient computations, we propose convex density constraints that\nensure that the resulting counterfactual is located in a region of the data\nspace of high density.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:23:42 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 08:14:22 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "2002.04881", "submitter": "Nutan Chen Ph.D.", "authors": "Nutan Chen, Alexej Klushyn, Francesco Ferroni, Justin Bayer, Patrick\n  van der Smagt", "title": "Learning Flat Latent Manifolds with VAEs", "comments": "Thirty-seventh International Conference on Machine Learning (ICML)\n  2020", "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the similarity between data points often requires domain knowledge,\nwhich can in parts be compensated by relying on unsupervised methods such as\nlatent-variable models, where similarity/distance is estimated in a more\ncompact latent space. Prevalent is the use of the Euclidean metric, which has\nthe drawback of ignoring information about similarity of data stored in the\ndecoder, as captured by the framework of Riemannian geometry. We propose an\nextension to the framework of variational auto-encoders allows learning flat\nlatent manifolds, where the Euclidean metric is a proxy for the similarity\nbetween data points. This is achieved by defining the latent space as a\nRiemannian manifold and by regularising the metric tensor to be a scaled\nidentity matrix. Additionally, we replace the compact prior typically used in\nvariational auto-encoders with a recently presented, more expressive\nhierarchical one---and formulate the learning problem as a constrained\noptimisation problem. We evaluate our method on a range of data-sets, including\na video-tracking benchmark, where the performance of our unsupervised approach\nnears that of state-of-the-art supervised approaches, while retaining the\ncomputational efficiency of straight-line-based approaches.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:54:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 15:31:15 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 08:18:19 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Chen", "Nutan", ""], ["Klushyn", "Alexej", ""], ["Ferroni", "Francesco", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "2002.04911", "submitter": "Johannes Andreas Stork", "authors": "Johannes A. Stork and Todor Stoyanov", "title": "Ensemble of Sparse Gaussian Process Experts for Implicit Surface Mapping\n  with Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating maps is an essential task in robotics and provides the basis for\neffective planning and navigation. In this paper, we learn a compact and\ncontinuous implicit surface map of an environment from a stream of range data\nwith known poses. For this, we create and incrementally adjust an ensemble of\napproximate Gaussian process (GP) experts which are each responsible for a\ndifferent part of the map. Instead of inserting all arriving data into the GP\nmodels, we greedily trade-off between model complexity and prediction error.\nOur algorithm therefore uses less resources on areas with few geometric\nfeatures and more where the environment is rich in variety. We evaluate our\napproach on synthetic and real-world data sets and analyze sensitivity to\nparameters and measurement noise. The results show that we can learn compact\nand accurate implicit surface models under different conditions, with a\nperformance comparable to or better than that of exact GP regression with\nsubsampled data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:06:48 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Stork", "Johannes A.", ""], ["Stoyanov", "Todor", ""]]}, {"id": "2002.04913", "submitter": "Peter Wirnsberger", "authors": "Peter Wirnsberger, Andrew J. Ballard, George Papamakarios, Stuart\n  Abercrombie, S\\'ebastien Racani\\`ere, Alexander Pritzel, Danilo Jimenez\n  Rezende and Charles Blundell", "title": "Targeted free energy estimation via learned mappings", "comments": "Added figure 3, added data augmentation for octahedral symmetries,\n  updated experimental results and revised text (11 pages, 6 figures)", "journal-ref": null, "doi": "10.1063/5.0018903", "report-no": null, "categories": "physics.comp-ph physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Free energy perturbation (FEP) was proposed by Zwanzig more than six decades\nago as a method to estimate free energy differences, and has since inspired a\nhuge body of related methods that use it as an integral building block. Being\nan importance sampling based estimator, however, FEP suffers from a severe\nlimitation: the requirement of sufficient overlap between distributions. One\nstrategy to mitigate this problem, called Targeted Free Energy Perturbation,\nuses a high-dimensional mapping in configuration space to increase overlap of\nthe underlying distributions. Despite its potential, this method has attracted\nonly limited attention due to the formidable challenge of formulating a\ntractable mapping. Here, we cast Targeted FEP as a machine learning problem in\nwhich the mapping is parameterized as a neural network that is optimized so as\nto increase overlap. We develop a new model architecture that respects\npermutational and periodic symmetries often encountered in atomistic\nsimulations and test our method on a fully-periodic solvation system. We\ndemonstrate that our method leads to a substantial variance reduction in free\nenergy estimates when compared against baselines, without requiring any\nadditional data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:10:00 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 20:15:11 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Wirnsberger", "Peter", ""], ["Ballard", "Andrew J.", ""], ["Papamakarios", "George", ""], ["Abercrombie", "Stuart", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Pritzel", "Alexander", ""], ["Rezende", "Danilo Jimenez", ""], ["Blundell", "Charles", ""]]}, {"id": "2002.04926", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin", "title": "Beyond UCB: Optimal and Efficient Contextual Bandits with Regression\n  Oracles", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in contextual bandits is to develop flexible,\ngeneral-purpose algorithms with computational requirements no worse than\nclassical supervised learning tasks such as classification and regression.\nAlgorithms based on regression have shown promising empirical success, but\ntheoretical guarantees have remained elusive except in special cases. We\nprovide the first universal and optimal reduction from contextual bandits to\nonline regression. We show how to transform any oracle for online regression\nwith a given value function class into an algorithm for contextual bandits with\nthe induced policy class, with no overhead in runtime or memory requirements.\nWe characterize the minimax rates for contextual bandits with general,\npotentially nonparametric function classes, and show that our algorithm is\nminimax optimal whenever the oracle obtains the optimal rate for regression.\nCompared to previous results, our algorithm requires no distributional\nassumptions beyond realizability, and works even when contexts are chosen\nadversarially.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:33:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 10:44:25 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "2002.04930", "submitter": "Shuai Wang", "authors": "Shuai Wang and Tsung-Hui Chang", "title": "Federated Matrix Factorization: Algorithm Design and Application to Data\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent demands on data privacy have called for federated learning (FL) as a\nnew distributed learning paradigm in massive and heterogeneous networks.\nAlthough many FL algorithms have been proposed, few of them have considered the\nmatrix factorization (MF) model, which is known to have a vast number of signal\nprocessing and machine learning applications. Different from the existing FL\nalgorithms that are designed for smooth problems with single block of\nvariables, in federated MF (FedMF), one has to deal with challenging non-convex\nand non-smooth problems (due to constraints or regularization) with two blocks\nof variables. In this paper, we address the challenge by proposing two new\nFedMF algorithms, namely, FedMAvg and FedMGS, based on the model averaging and\ngradient sharing principles, respectively. Both FedMAvg and FedMGS adopt\nmultiple steps of local updates per communication round to speed up\nconvergence, and allow only a randomly sampled subset of clients to communicate\nwith the server for reducing the communication cost. Convergence analyses for\nthe two algorithms are respectively presented, which delineate the impacts of\ndata distribution, local update number, and partial client communication on the\nalgorithm performance. By focusing on a data clustering task, extensive\nexperiment results are presented to examine the practical performance of both\nalgorithms, as well as demonstrating their efficacy over the existing\ndistributed clustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:48:54 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 09:49:24 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Shuai", ""], ["Chang", "Tsung-Hui", ""]]}, {"id": "2002.04985", "submitter": "Ay\\c{c}a \\\"Oz\\c{c}elikkale", "authors": "Ayca Ozcelikkale", "title": "Sparse Recovery With Non-Linear Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random non-linear Fourier features have recently shown remarkable performance\nin a wide-range of regression and classification applications. Motivated by\nthis success, this article focuses on a sparse non-linear Fourier feature (NFF)\nmodel. We provide a characterization of the sufficient number of data points\nthat guarantee perfect recovery of the unknown parameters with\nhigh-probability. In particular, we show how the sufficient number of data\npoints depends on the kernel matrix associated with the probability\ndistribution function of the input data. We compare our results with the\nrecoverability bounds for the bounded orthonormal systems and provide examples\nthat illustrate sparse recovery under the NFF model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 13:41:25 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Ozcelikkale", "Ayca", ""]]}, {"id": "2002.04991", "submitter": "Maximilian Weininger", "authors": "Pranav Ashok, Mathias Jackermeier, Pushpak Jagtap, Jan\n  K\\v{r}et\\'insk\\'y, Maximilian Weininger, Majid Zamani", "title": "dtControl: Decision Tree Learning Algorithms for Controller\n  Representation", "comments": null, "journal-ref": null, "doi": "10.1145/3365365.3383468", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree learning is a popular classification technique most commonly\nused in machine learning applications. Recent work has shown that decision\ntrees can be used to represent provably-correct controllers concisely. Compared\nto representations using lookup tables or binary decision diagrams, decision\ntrees are smaller and more explainable. We present dtControl, an easily\nextensible tool for representing memoryless controllers as decision trees. We\ngive a comprehensive evaluation of various decision tree learning algorithms\napplied to 10 case studies arising out of correct-by-construction controller\nsynthesis. These algorithms include two new techniques, one for using arbitrary\nlinear binary classifiers in the decision tree learning, and one novel approach\nfor determinizing controllers during the decision tree construction. In\nparticular the latter turns out to be extremely efficient, yielding decision\ntrees with a single-digit number of decision nodes on 5 of the case studies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:13:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ashok", "Pranav", ""], ["Jackermeier", "Mathias", ""], ["Jagtap", "Pushpak", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weininger", "Maximilian", ""], ["Zamani", "Majid", ""]]}, {"id": "2002.04992", "submitter": "Yossi Adi", "authors": "Felix Kreuk, Yaniv Sheena, Joseph Keshet, and Yossi Adi", "title": "Phoneme Boundary Detection using Learnable Segmental Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phoneme boundary detection plays an essential first step for a variety of\nspeech processing applications such as speaker diarization, speech science,\nkeyword spotting, etc. In this work, we propose a neural architecture coupled\nwith a parameterized structured loss function to learn segmental\nrepresentations for the task of phoneme boundary detection. First, we evaluated\nour model when the spoken phonemes were not given as input. Results on the\nTIMIT and Buckeye corpora suggest that the proposed model is superior to the\nbaseline models and reaches state-of-the-art performance in terms of F1 and\nR-value. We further explore the use of phonetic transcription as additional\nsupervision and show this yields minor improvements in performance but\nsubstantially better convergence rates. We additionally evaluate the model on a\nHebrew corpus and demonstrate such phonetic supervision can be beneficial in a\nmulti-lingual setting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 14:03:08 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 07:26:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kreuk", "Felix", ""], ["Sheena", "Yaniv", ""], ["Keshet", "Joseph", ""], ["Adi", "Yossi", ""]]}, {"id": "2002.04996", "submitter": "Esa Ollila", "authors": "Esa Ollila, Daniel P. Palomar and Frederic Pascal", "title": "M-estimators of scatter with eigenvalue shrinkage", "comments": "To appear in Proc. IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP 2020), May 4 - 8, Barcelona, Spain, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular regularized (shrinkage) covariance estimator is the shrinkage\nsample covariance matrix (SCM) which shares the same set of eigenvectors as the\nSCM but shrinks its eigenvalues toward its grand mean. In this paper, a more\ngeneral approach is considered in which the SCM is replaced by an M-estimator\nof scatter matrix and a fully automatic data adaptive method to compute the\noptimal shrinkage parameter with minimum mean squared error is proposed. Our\napproach permits the use of any weight function such as Gaussian, Huber's, or\n$t$ weight functions, all of which are commonly used in M-estimation framework.\nOur simulation examples illustrate that shrinkage M-estimators based on the\nproposed optimal tuning combined with robust weight function do not loose in\nperformance to shrinkage SCM estimator when the data is Gaussian, but provide\nsignificantly improved performance when the data is sampled from a heavy-tailed\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 13:47:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Ollila", "Esa", ""], ["Palomar", "Daniel P.", ""], ["Pascal", "Frederic", ""]]}, {"id": "2002.04997", "submitter": "Zhanhong Tan", "authors": "Zhanhong Tan, Jiebo Song, Xiaolong Ma, Sia-Huat Tan, Hongyang Chen,\n  Yuanqing Miao, Yifu Wu, Shaokai Ye, Yanzhi Wang, Dehui Li, Kaisheng Ma", "title": "PCNN: Pattern-based Fine-Grained Regular Pruning towards Optimizing CNN\n  Accelerators", "comments": "6 pages, DAC 2020 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning is a powerful technique to realize model compression. We\npropose PCNN, a fine-grained regular 1D pruning method. A novel index format\ncalled Sparsity Pattern Mask (SPM) is presented to encode the sparsity in PCNN.\nLeveraging SPM with limited pruning patterns and non-zero sequences with equal\nlength, PCNN can be efficiently employed in hardware. Evaluated on VGG-16 and\nResNet-18, our PCNN achieves the compression rate up to 8.4X with only 0.2%\naccuracy loss. We also implement a pattern-aware architecture in 55nm process,\nachieving up to 9.0X speedup and 28.39 TOPS/W efficiency with only 3.1% on-chip\nmemory overhead of indices.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:49:21 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 02:05:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tan", "Zhanhong", ""], ["Song", "Jiebo", ""], ["Ma", "Xiaolong", ""], ["Tan", "Sia-Huat", ""], ["Chen", "Hongyang", ""], ["Miao", "Yuanqing", ""], ["Wu", "Yifu", ""], ["Ye", "Shaokai", ""], ["Wang", "Yanzhi", ""], ["Li", "Dehui", ""], ["Ma", "Kaisheng", ""]]}, {"id": "2002.04999", "submitter": "Anees Kazi", "authors": "Anees Kazi, Luca Cosmo, Nassir Navab and Michael Bronstein", "title": "Differentiable Graph Module (DGM) for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph deep learning has recently emerged as a powerful ML concept allowing to\ngeneralize successful deep neural architectures to non-Euclidean structured\ndata. Such methods have shown promising results on a broad spectrum of\napplications ranging from social science, biomedicine, and particle physics to\ncomputer vision, graphics, and chemistry. One of the limitations of the\nmajority of the current graph neural network architectures is that they are\noften restricted to the transductive setting and rely on the assumption that\nthe underlying graph is known and fixed. In many settings, such as those\narising in medical and healthcare applications, this assumption is not\nnecessarily true since the graph may be noisy, partially- or even completely\nunknown, and one is thus interested in inferring it from the data. This is\nespecially important in inductive settings when dealing with nodes not present\nin the graph at training time. Furthermore, sometimes such a graph itself may\nconvey insights that are even more important than the downstream task. In this\npaper, we introduce Differentiable Graph Module (DGM), a learnable function\npredicting the edge probability in the graph relevant for the task, that can be\ncombined with convolutional graph neural network layers and trained in an\nend-to-end fashion. We provide an extensive evaluation of applications from the\ndomains of healthcare (disease prediction), brain imaging (gender and age\nprediction), computer graphics (3D point cloud segmentation), and computer\nvision (zero-shot learning). We show that our model provides a significant\nimprovement over baselines both in transductive and inductive settings and\nachieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:59:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:22:42 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 12:04:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kazi", "Anees", ""], ["Cosmo", "Luca", ""], ["Navab", "Nassir", ""], ["Bronstein", "Michael", ""]]}, {"id": "2002.05033", "submitter": "Shuyang Zhao", "authors": "Shuyang Zhao, Toni Heittola, Tuomas Virtanen", "title": "Active Learning for Sound Event Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an active learning system for sound event detection\n(SED). It aims at maximizing the accuracy of a learned SED model with limited\nannotation effort. The proposed system analyzes an initially unlabeled audio\ndataset, from which it selects sound segments for manual annotation. The\ncandidate segments are generated based on a proposed change point detection\napproach, and the selection is based on the principle of mismatch-first\nfarthest-traversal. During the training of SED models, recordings are used as\ntraining inputs, preserving the long-term context for annotated segments. The\nproposed system clearly outperforms reference methods in the two datasets used\nfor evaluation (TUT Rare Sound 2017 and TAU Spatial Sound 2019). Training with\nrecordings as context outperforms training with only annotated segments.\nMismatch-first farthest-traversal outperforms reference sample selection\nmethods based on random sampling and uncertainty sampling. Remarkably, the\nrequired annotation effort can be greatly reduced on the dataset where target\nsound events are rare: by annotating only 2% of the training data, the achieved\nSED performance is similar to annotating all the training data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 14:46:55 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:49:55 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zhao", "Shuyang", ""], ["Heittola", "Toni", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "2002.05039", "submitter": "Raghavendra Reddy Pappagari", "authors": "Raghavendra Pappagari, Tianzi Wang, Jesus Villalba, Nanxin Chen, Najim\n  Dehak", "title": "x-vectors meet emotions: A study on dependencies between emotion and\n  speaker recognition", "comments": "45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we explore the dependencies between speaker recognition and\nemotion recognition. We first show that knowledge learned for speaker\nrecognition can be reused for emotion recognition through transfer learning.\nThen, we show the effect of emotion on speaker recognition. For emotion\nrecognition, we show that using a simple linear model is enough to obtain good\nperformance on the features extracted from pre-trained models such as the\nx-vector model. Then, we improve emotion recognition performance by fine-tuning\nfor emotion classification. We evaluated our experiments on three different\ntypes of datasets: IEMOCAP, MSP-Podcast, and Crema-D. By fine-tuning, we\nobtained 30.40%, 7.99%, and 8.61% absolute improvement on IEMOCAP, MSP-Podcast,\nand Crema-D respectively over baseline model with no pre-training. Finally, we\npresent results on the effect of emotion on speaker verification. We observed\nthat speaker verification performance is prone to changes in test speaker\nemotions. We found that trials with angry utterances performed worst in all\nthree datasets. We hope our analysis will initiate a new line of research in\nthe speaker recognition community.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:13:07 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pappagari", "Raghavendra", ""], ["Wang", "Tianzi", ""], ["Villalba", "Jesus", ""], ["Chen", "Nanxin", ""], ["Dehak", "Najim", ""]]}, {"id": "2002.05059", "submitter": "Jan Rosenzweig", "authors": "Jan Rosenzweig, Zoran Cvetkovic and Ivana Roenzweig", "title": "Goldilocks Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the new \"Goldilocks\" class of activation functions, which\nnon-linearly deform the input signal only locally when the input signal is in\nthe appropriate range. The small local deformation of the signal enables better\nunderstanding of how and why the signal is transformed through the layers.\nNumerical results on CIFAR-10 and CIFAR-100 data sets show that Goldilocks\nnetworks perform better than, or comparably to SELU and RELU, while introducing\ntractability of data deformation through the layers.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:26:30 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 11:20:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rosenzweig", "Jan", ""], ["Cvetkovic", "Zoran", ""], ["Roenzweig", "Ivana", ""]]}, {"id": "2002.05076", "submitter": "Michele Ceriotti", "authors": "Benjamin A. Helfrecht, Rose K. Cersonsky, Guillaume Fraux, and Michele\n  Ceriotti", "title": "Structure-Property Maps with Kernel Principal Covariates Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analyses based on linear methods constitute the simplest, most robust,\nand transparent approaches to the automatic processing of large amounts of data\nfor building supervised or unsupervised machine learning models. Principal\ncovariates regression (PCovR) is an underappreciated method that interpolates\nbetween principal component analysis and linear regression, and can be used to\nconveniently reveal structure-property relations in terms of\nsimple-to-interpret, low-dimensional maps. Here we provide a pedagogic overview\nof these data analysis schemes, including the use of the kernel trick to\nintroduce an element of non-linearity, while maintaining most of the\nconvenience and the simplicity of linear approaches. We then introduce a\nkernelized version of PCovR and a sparsified extension, and demonstrate the\nperformance of this approach in revealing and predicting structure-property\nrelations in chemistry and materials science, showing a variety of examples\nincluding elemental carbon, porous silicate frameworks, organic molecules,\namino acid conformers, and molecular materials.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:29:24 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 15:58:36 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Helfrecht", "Benjamin A.", ""], ["Cersonsky", "Rose K.", ""], ["Fraux", "Guillaume", ""], ["Ceriotti", "Michele", ""]]}, {"id": "2002.05079", "submitter": "Kirandeep Kour", "authors": "Kirandeep Kour, Sergey Dolgov, Martin Stoll and Peter Benner", "title": "Efficient Structure-preserving Support Tensor Train Machine", "comments": "21 pages, 6 figures, 2 table, 1 Algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of collected data are high-dimensional and it is crucial\nfor efficient learning algorithms to exploit the tensorial structure as much as\npossible. The ever present curse of dimensionality for high dimensional data\nand the loss of structure when vectorizing the data motivates the use of\ntailored low-rank tensor methods. In the presence of small amounts of training\ndata kernel methods offer an attractive choice as they provide the possibility\nfor a nonlinear decision boundary. We introduce the Tensor Train Multi-way\nMulti-level Kernel (TT-MMK) as a method that combines the simplicity of\nCanonical Polyadic (CP) with the robustness of the tensor train (TT)\ndecomposition. We embed this approach into a Dual Structure-preserving Support\nVector Machine and show that the TT-MMK method is more reliable\ncomputationally, less sensitive to tuning parameters, and gives higher\nprediction accuracy in the SVM classification when benchmarked against other\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:35:10 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 16:33:37 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kour", "Kirandeep", ""], ["Dolgov", "Sergey", ""], ["Stoll", "Martin", ""], ["Benner", "Peter", ""]]}, {"id": "2002.05095", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Compressive Learning of Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative networks implicitly approximate complex densities from their\nsampling with impressive accuracy. However, because of the enormous scale of\nmodern datasets, this training process is often computationally expensive. We\ncast generative network training into the recent framework of compressive\nlearning: we reduce the computational burden of large-scale datasets by first\nharshly compressing them in a single pass as a single sketch vector. We then\npropose a cost function, which approximates the Maximum Mean Discrepancy\nmetric, but requires only this sketch, which makes it time- and\nmemory-efficient to optimize.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:03:43 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 10:52:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "2002.05096", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Victor Picheny, Nicolas Durrande", "title": "Regret Bounds for Noise-Free Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a powerful method for non-convex black-box\noptimization in low data regimes. However, the question of establishing tight\nupper bounds for common algorithms in the noiseless setting remains a largely\nopen question. In this paper, we establish new and tightest bounds for two\nalgorithms, namely GP-UCB and Thompson sampling, under the assumption that the\nobjective function is smooth in terms of having a bounded norm in a Mat\\'ern\nRKHS. Importantly, unlike several related works, we do not consider perfect\nknowledge of the kernel of the Gaussian process emulator used within the\nBayesian optimization loop. This allows us to provide results for practical\nalgorithms that sequentially estimate the Gaussian process kernel parameters\nfrom the available data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:06:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Vakili", "Sattar", ""], ["Picheny", "Victor", ""], ["Durrande", "Nicolas", ""]]}, {"id": "2002.05105", "submitter": "Shisheng Cui", "authors": "Shisheng Cui and Chia-Jung Chang", "title": "Development of modeling and control strategies for an approximated\n  Gaussian process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process (GP) model, which has been extensively applied as priors\nof functions, has demonstrated excellent performance. The specification of a\nlarge number of parameters affects the computational efficiency and the\nfeasibility of implementation of a control strategy. We propose a linear model\nto approximate GPs; this model expands the GP model by a series of basis\nfunctions. Several examples and simulation studies are presented to demonstrate\nthe advantages of the proposed method. A control strategy is provided with the\nproposed linear model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:28:24 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Cui", "Shisheng", ""], ["Chang", "Chia-Jung", ""]]}, {"id": "2002.05115", "submitter": "Lukas Gemein", "authors": "Lukas Alexander Wilhelm Gemein, Robin Tibor Schirrmeister, Patryk\n  Chrab\\k{a}szcz, Daniel Wilson, Joschka Boedecker, Andreas Schulze-Bonhage,\n  Frank Hutter, Tonio Ball", "title": "Machine-Learning-Based Diagnostics of EEG Pathology", "comments": null, "journal-ref": "NeuroImage, Volume 220, 15 October 2020, 117021", "doi": "10.1016/j.neuroimage.2020.117021", "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) methods have the potential to automate clinical EEG\nanalysis. They can be categorized into feature-based (with handcrafted\nfeatures), and end-to-end approaches (with learned features). Previous studies\non EEG pathology decoding have typically analyzed a limited number of features,\ndecoders, or both. For a I) more elaborate feature-based EEG analysis, and II)\nin-depth comparisons of both approaches, here we first develop a comprehensive\nfeature-based framework, and then compare this framework to state-of-the-art\nend-to-end methods. To this aim, we apply the proposed feature-based framework\nand deep neural networks including an EEG-optimized temporal convolutional\nnetwork (TCN) to the task of pathological versus non-pathological EEG\nclassification. For a robust comparison, we chose the Temple University\nHospital (TUH) Abnormal EEG Corpus (v2.0.0), which contains approximately 3000\nEEG recordings. The results demonstrate that the proposed feature-based\ndecoding framework can achieve accuracies on the same level as state-of-the-art\ndeep neural networks. We find accuracies across both approaches in an\nastonishingly narrow range from 81--86\\%. Moreover, visualizations and analyses\nindicated that both approaches used similar aspects of the data, e.g., delta\nand theta band power at temporal electrode locations. We argue that the\naccuracies of current binary EEG pathology decoders could saturate near 90\\%\ndue to the imperfect inter-rater agreement of the clinical labels, and that\nsuch decoders are already clinically useful, such as in areas where clinical\nEEG experts are rare. We make the proposed feature-based framework available\nopen source and thus offer a new tool for EEG machine learning research.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:12:24 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gemein", "Lukas Alexander Wilhelm", ""], ["Schirrmeister", "Robin Tibor", ""], ["Chrab\u0105szcz", "Patryk", ""], ["Wilson", "Daniel", ""], ["Boedecker", "Joschka", ""], ["Schulze-Bonhage", "Andreas", ""], ["Hutter", "Frank", ""], ["Ball", "Tonio", ""]]}, {"id": "2002.05120", "submitter": "Jason Jo", "authors": "Giulia Zarpellon, Jason Jo, Andrea Lodi and Yoshua Bengio", "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies", "comments": "AAAI 2021 camera-ready version with supplementary materials, improved\n  readability of figures in main article. Code, data and trained models are\n  available at https://github.com/ds4dm/branch-search-trees", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  2021, 35(5), 3931-3939", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch and Bound (B&B) is the exact tree search method typically used to\nsolve Mixed-Integer Linear Programming problems (MILPs). Learning branching\npolicies for MILP has become an active research area, with most works proposing\nto imitate the strong branching rule and specialize it to distinct classes of\nproblems. We aim instead at learning a policy that generalizes across\nheterogeneous MILPs: our main hypothesis is that parameterizing the state of\nthe B&B search tree can aid this type of generalization. We propose a novel\nimitation learning framework, and introduce new input features and\narchitectures to represent branching. Experiments on MILP benchmark instances\nclearly show the advantages of incorporating an explicit parameterization of\nthe state of the search tree to modulate the branching decisions, in terms of\nboth higher accuracy and smaller B&B trees. The resulting policies\nsignificantly outperform the current state-of-the-art method for \"learning to\nbranch\" by effectively allowing generalization to generic unseen instances.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:43:23 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:32:08 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 18:30:16 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 20:11:03 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zarpellon", "Giulia", ""], ["Jo", "Jason", ""], ["Lodi", "Andrea", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.05123", "submitter": "Roi Pony", "authors": "Roi Pony, Itay Naeh, Shie Mannor", "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:58:12 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 10:17:19 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 14:39:25 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 22:11:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pony", "Roi", ""], ["Naeh", "Itay", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.05135", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Kristian Georgiev, Aryan Mokhtari, Asuman Ozdaglar", "title": "Provably Convergent Policy Gradient Methods for Model-Agnostic\n  Meta-Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Model-Agnostic Meta-Learning (MAML) methods for Reinforcement\nLearning (RL) problems where the goal is to find a policy using data from\nseveral tasks represented by Markov Decision Processes (MDPs) that can be\nupdated by one step of stochastic policy gradient for the realized MDP. In\nparticular, using stochastic gradients in MAML update step is crucial for RL\nproblems since computation of exact gradients requires access to a large number\nof possible trajectories. For this formulation, we propose a variant of the\nMAML method, named Stochastic Gradient Meta-Reinforcement Learning (SG-MRL),\nand study its convergence properties. We derive the iteration and sample\ncomplexity of SG-MRL to find an $\\epsilon$-first-order stationary point, which,\nto the best of our knowledge, provides the first convergence guarantee for\nmodel-agnostic meta-reinforcement learning algorithms. We further show how our\nresults extend to the case where more than one step of stochastic policy\ngradient method is used in the update during the test time.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:29:09 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 03:39:02 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Fallah", "Alireza", ""], ["Georgiev", "Kristian", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.05138", "submitter": "Shuang Liu", "authors": "Shuang Liu and Hao Su", "title": "Regret Bounds for Discounted MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has traditionally been understood from an\nepisodic perspective; the concept of non-episodic RL, where there is no restart\nand therefore no reliable recovery, remains elusive. A fundamental question in\nnon-episodic RL is how to measure the performance of a learner and derive\nalgorithms to maximize such performance. Conventional wisdom is to maximize the\ndifference between the average reward received by the learner and the maximal\nlong-term average reward. In this paper, we argue that if the total time budget\nis relatively limited compared to the complexity of the environment, such\ncomparison may fail to reflect the finite-time optimality of the learner. We\npropose a family of measures, called $\\gamma$-regret, which we believe to\nbetter capture the finite-time optimality. We give motivations and derive lower\nand upper bounds for such measures. Note: A follow-up work (arXiv:2010.00587)\nhas improved both our lower and upper bound, the gap is now closed at\n$\\tilde{\\Theta}\\left(\\frac{\\sqrt{SAT}}{(1 - \\gamma)^{\\frac{1}{2}}}\\right)$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:30:09 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 00:26:46 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 22:32:32 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Liu", "Shuang", ""], ["Su", "Hao", ""]]}, {"id": "2002.05139", "submitter": "Pravesh K Kothari", "authors": "Ainesh Bakshi and Pravesh K. Kothari", "title": "List-Decodable Subspace Recovery: Dimension Independent Error in\n  Polynomial Time", "comments": "To appear in SODA 2021. This version fixes an issue in a technical\n  claim bounding the variance of degree 2 polynomials and improves exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In list-decodable subspace recovery, the input is a collection of $n$ points\n$\\alpha n$ (for some $\\alpha \\ll 1/2$) of which are drawn i.i.d. from a\ndistribution $\\mathcal{D}$ with a isotropic rank $r$ covariance $\\Pi_*$ (the\n\\emph{inliers}) and the rest are arbitrary, potential adversarial outliers. The\ngoal is to recover a $O(1/\\alpha)$ size list of candidate covariances that\ncontains a $\\hat{\\Pi}$ close to $\\Pi_*$. Two recent independent works\n(Raghavendra-Yau, Bakshi-Kothari 2020) gave the first efficient algorithm for\nthis problem. These results, however, obtain an error that grows with the\ndimension (linearly in [RY] and logarithmically in BK) at the cost of\nquasi-polynomial running time) and rely on \\emph{certifiable\nanti-concentration} - a relatively strict condition satisfied essentially only\nby the Gaussian distribution.\n  In this work, we improve on these results on all three fronts:\n\\emph{dimension-independent} error via a faster fixed-polynomial running time\nunder less restrictive distributional assumptions. Specifically, we give a\n$poly(1/\\alpha) d^{O(1)}$ time algorithm that outputs a list containing a\n$\\hat{\\Pi}$ satisfying $\\|\\hat{\\Pi} -\\Pi_*\\|_F \\leq O(1/\\alpha)$. Our result\nonly needs $\\mathcal{D}$ to have \\emph{certifiably hypercontractive} degree 2\npolynomials. As a result, in addition to Gaussians, our algorithm applies to\nthe uniform distribution on the hypercube and $q$-ary cubes and arbitrary\nproduct distributions with subgaussian marginals. Prior work (Raghavendra and\nYau, 2020) had identified such distributions as potential hard examples as such\ndistributions do not exhibit strong enough anti-concentration. When\n$\\mathcal{D}$ satisfies certifiable anti-concentration, we obtain a stronger\nerror guarantee of $\\|\\hat{\\Pi}-\\Pi_*\\|_F \\leq \\eta$ for any arbitrary $\\eta >\n0$ in $d^{O(poly(1/\\alpha) + \\log (1/\\eta))}$ time.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:30:09 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 04:53:41 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 17:54:57 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Bakshi", "Ainesh", ""], ["Kothari", "Pravesh K.", ""]]}, {"id": "2002.05141", "submitter": "Anastasios Tsiamis", "authors": "Anastasios Tsiamis and George Pappas", "title": "Online Learning of the Kalman Filter with Logarithmic Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of predicting observations generated\nonline by an unknown, partially observed linear system, which is driven by\nstochastic noise. For such systems the optimal predictor in the mean square\nsense is the celebrated Kalman filter, which can be explicitly computed when\nthe system model is known. When the system model is unknown, we have to learn\nhow to predict observations online based on finite data, suffering possibly a\nnon-zero regret with respect to the Kalman filter's prediction. We show that it\nis possible to achieve a regret of the order of $\\mathrm{poly}\\log(N)$ with\nhigh probability, where $N$ is the number of observations collected. Our work\nis the first to provide logarithmic regret guarantees for the widely used\nKalman filter. This is achieved using an online least-squares algorithm, which\nexploits the approximately linear relation between future observations and past\nobservations. The regret analysis is based on the stability properties of the\nKalman filter, recent statistical tools for finite sample analysis of system\nidentification, and classical results for the analysis of least-squares\nalgorithms for time series. Our regret analysis can also be applied for state\nprediction of the hidden state, in the case of unknown noise statistics but\nknown state-space basis. A fundamental technical contribution is that our\nbounds hold even for the class of non-explosive systems, which includes the\nclass of marginally stable systems, which was an open problem for the case of\nonline prediction under stochastic noise.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:31:31 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Tsiamis", "Anastasios", ""], ["Pappas", "George", ""]]}, {"id": "2002.05145", "submitter": "Robin Vogel", "authors": "Robin Vogel, Mastane Achab, St\\'ephan Cl\\'emen\\c{c}on, Charles Tillier", "title": "Weighted Empirical Risk Minimization: Sample Selection Bias Correction\n  based on Importance Sampling", "comments": "20 pages, 7 tables and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical learning problems, when the distribution $P'$ of the\ntraining observations $Z'_1,\\; \\ldots,\\; Z'_n$ differs from the distribution\n$P$ involved in the risk one seeks to minimize (referred to as the test\ndistribution) but is still defined on the same measurable space as $P$ and\ndominates it. In the unrealistic case where the likelihood ratio\n$\\Phi(z)=dP/dP'(z)$ is known, one may straightforwardly extends the Empirical\nRisk Minimization (ERM) approach to this specific transfer learning setup using\nthe same idea as that behind Importance Sampling, by minimizing a weighted\nversion of the empirical risk functional computed from the 'biased' training\ndata $Z'_i$ with weights $\\Phi(Z'_i)$. Although the importance function\n$\\Phi(z)$ is generally unknown in practice, we show that, in various situations\nfrequently encountered in practice, it takes a simple form and can be directly\nestimated from the $Z'_i$'s and some auxiliary information on the statistical\npopulation $P$. By means of linearization techniques, we then prove that the\ngeneralization capacity of the approach aforementioned is preserved when\nplugging the resulting estimates of the $\\Phi(Z'_i)$'s into the weighted\nempirical risk. Beyond these theoretical guarantees, numerical results provide\nstrong empirical evidence of the relevance of the approach promoted in this\narticle.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:42:47 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:50:34 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Vogel", "Robin", ""], ["Achab", "Mastane", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""], ["Tillier", "Charles", ""]]}, {"id": "2002.05149", "submitter": "Daniel Elton", "authors": "Daniel C. Elton", "title": "Self-explaining AI as an alternative to interpretable AI", "comments": "10pgs, 2 column format", "journal-ref": null, "doi": "10.1007/978-3-030-52152-3_10", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to explain decisions made by AI systems is highly sought after,\nespecially in domains where human lives are at stake such as medicine or\nautonomous vehicles. While it is often possible to approximate the input-output\nrelations of deep neural networks with a few human-understandable rules, the\ndiscovery of the double descent phenomena suggests that such approximations do\nnot accurately capture the mechanism by which deep neural networks work. Double\ndescent indicates that deep neural networks typically operate by smoothly\ninterpolating between data points rather than by extracting a few high level\nrules. As a result, neural networks trained on complex real world data are\ninherently hard to interpret and prone to failure if asked to extrapolate. To\nshow how we might be able to trust AI despite these problems we introduce the\nconcept of self-explaining AI. Self-explaining AIs are capable of providing a\nhuman-understandable explanation of each decision along with confidence levels\nfor both the decision and explanation. For this approach to work, it is\nimportant that the explanation actually be related to the decision, ideally\ncapturing the mechanism used to arrive at the explanation. Finally, we argue it\nis important that deep learning based systems include a \"warning light\" based\non techniques from applicability domain analysis to warn the user if a model is\nasked to extrapolate outside its training distribution. For a video\npresentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& .\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:50:11 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:13:25 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 18:56:25 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 15:26:15 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 13:38:58 GMT"}, {"version": "v6", "created": "Thu, 2 Jul 2020 19:03:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Elton", "Daniel C.", ""]]}, {"id": "2002.05152", "submitter": "Mohsen Bayati", "authors": "Nima Hamidi, Mohsen Bayati", "title": "Toward Better Use of Data in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the well-known stochastic linear bandit problem where\na decision-maker sequentially chooses among a set of given actions, observes\ntheir noisy reward, and aims to maximize her cumulative expected reward over a\nhorizon of length $T$. In this paper, we first introduce a general analysis\nframework and a family of rate optimal algorithms for the problem. We show that\nthis family of algorithms includes well-known algorithms such as optimism in\nthe face of uncertainty linear bandit (OFUL) and Thompson sampling (TS) as\nspecial cases. The proposed analysis technique directly captures complexity of\nuncertainty in the action sets that we show is tied to regret analysis of any\npolicy. This insight allows us to design a new rate-optimal policy, called\nSieved-Greedy (SG), that reduces the over-exploration problem in existing\nalgorithms. SG utilizes data to discard the actions with relatively low\nuncertainty and then choosing one among the remaining actions greedily. In\naddition to proving that SG is theoretically rate-optimal, our empirical\nsimulations show that SG significantly outperforms existing benchmarks such as\ngreedy, OFUL, and TS. Moreover, our analysis technique yields a number of new\nresults such as obtaining poly-logarithmic (in $T$) regret bounds for OFUL and\nTS, under a generalized gap assumption and a margin condition, as in literature\non contextual bandits. We also improve regret bounds of these algorithms for\nthe sub-class of $k$-armed contextual bandit problems by a factor $\\sqrt{k}$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:54:41 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:40:55 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 17:49:47 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hamidi", "Nima", ""], ["Bayati", "Mohsen", ""]]}, {"id": "2002.05153", "submitter": "Andrew Bennett", "authors": "Andrew Bennett and Nathan Kallus", "title": "Efficient Policy Learning from Surrogate-Loss Classification Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on policy learning from observational data has highlighted the\nimportance of efficient policy evaluation and has proposed reductions to\nweighted (cost-sensitive) classification. But, efficient policy evaluation need\nnot yield efficient estimation of policy parameters. We consider the estimation\nproblem given by a weighted surrogate-loss classification reduction of policy\nlearning with any score function, either direct, inverse-propensity weighted,\nor doubly robust. We show that, under a correct specification assumption, the\nweighted classification formulation need not be efficient for policy\nparameters. We draw a contrast to actual (possibly weighted) binary\nclassification, where correct specification implies a parametric model, while\nfor policy learning it only implies a semiparametric model. In light of this,\nwe instead propose an estimation approach based on generalized method of\nmoments, which is efficient for the policy parameters. We propose a particular\nmethod based on recent developments on solving moment problems using neural\nnetworks and demonstrate the efficiency and regret benefits of this method\nempirically.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:54:41 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Bennett", "Andrew", ""], ["Kallus", "Nathan", ""]]}, {"id": "2002.05155", "submitter": "Shahin Boluki", "authors": "Shahin Boluki, Randy Ardywibowo, Siamak Zamani Dadaneh, Mingyuan Zhou,\n  Xiaoning Qian", "title": "Learnable Bernoulli Dropout for Bayesian Deep Learning", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose learnable Bernoulli dropout (LBD), a new\nmodel-agnostic dropout scheme that considers the dropout rates as parameters\njointly optimized with other model parameters. By probabilistic modeling of\nBernoulli dropout, our method enables more robust prediction and uncertainty\nquantification in deep models. Especially, when combined with variational\nauto-encoders (VAEs), LBD enables flexible semi-implicit posterior\nrepresentations, leading to new semi-implicit VAE~(SIVAE) models. We solve the\noptimization for training with respect to the dropout parameters using\nAugment-REINFORCE-Merge (ARM), an unbiased and low-variance gradient estimator.\nOur experiments on a range of tasks show the superior performance of our\napproach compared with other commonly used dropout schemes. Overall, LBD leads\nto improved accuracy and uncertainty estimates in image classification and\nsemantic segmentation. Moreover, using SIVAE, we can achieve state-of-the-art\nperformance on collaborative filtering for implicit feedback on several public\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:57:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Boluki", "Shahin", ""], ["Ardywibowo", "Randy", ""], ["Dadaneh", "Siamak Zamani", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "2002.05158", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Elizabeth Munch, Paul Rosen", "title": "Fast and Scalable Complex Network Descriptor Using PageRank and\n  Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PageRank of a graph is a scalar function defined on the node set of the\ngraph which encodes nodes centrality information of the graph. In this article,\nwe use the PageRank function along with persistent homology to obtain a\nscalable graph descriptor and utilize it to compare the similarities between\ngraphs. For a given graph $G(V,E)$, our descriptor can be computed in\n$O(|E|\\alpha(|V|))$, where $\\alpha$ is the inverse Ackermann function which\nmakes it scalable and computable on massive graphs. We show the effectiveness\nof our method by utilizing it on multiple shape mesh datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:08:48 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 03:33:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hajij", "Mustafa", ""], ["Munch", "Elizabeth", ""], ["Rosen", "Paul", ""]]}, {"id": "2002.05160", "submitter": "Mathilde Fekom", "authors": "Mathilde Fekom, Nicolas Vayatis, Argyris Kalogeratos", "title": "Optimal Multiple Stopping Rule for Warm-Starting Sequential Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Warm-starting Dynamic Thresholding algorithm,\ndeveloped using dynamic programming, for a variant of the standard online\nselection problem. The problem allows job positions to be either free or\nalready occupied at the beginning of the process. Throughout the selection\nprocess, the decision maker interviews one after the other the new candidates\nand reveals a quality score for each of them. Based on that information, she\ncan (re)assign each job at most once by taking immediate and irrevocable\ndecisions. We relax the hard requirement of the class of dynamic programming\nalgorithms to perfectly know the distribution from which the scores of\ncandidates are drawn, by presenting extensions for the partial and\nno-information cases, in which the decision maker can learn the underlying\nscore distribution sequentially while interviewing candidates.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 14:04:43 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fekom", "Mathilde", ""], ["Vayatis", "Nicolas", ""], ["Kalogeratos", "Argyris", ""]]}, {"id": "2002.05169", "submitter": "Sven Krippendorf", "authors": "Philip Betzler, Sven Krippendorf", "title": "Connecting Dualities and Machine Learning", "comments": "35 pages, 19 figures", "journal-ref": null, "doi": "10.1002/prop.202000022", "report-no": "LMU-ASC 05/20, MPP-2020-14", "categories": "physics.comp-ph cond-mat.dis-nn cs.LG hep-ph hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dualities are widely used in quantum field theories and string theory to\nobtain correlation functions at high accuracy. Here we present examples where\ndual data representations are useful in supervised classification, linking\nmachine learning and typical tasks in theoretical physics. We then discuss how\nsuch beneficial representations can be enforced in the latent dimension of\nneural networks. We find that additional contributions to the loss based on\nfeature separation, feature matching with respect to desired representations,\nand a good performance on a `simple' correlation function can lead to known and\nunknown dual representations. This is the first proof of concept that computers\ncan find dualities. We discuss how our examples, based on discrete Fourier\ntransformation and Ising models, connect to other dualities in theoretical\nphysics, for instance Seiberg duality.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:00:02 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Betzler", "Philip", ""], ["Krippendorf", "Sven", ""]]}, {"id": "2002.05183", "submitter": "Luiz F. O. Chamon", "authors": "Luiz F. O. Chamon and Santiago Paternain and Miguel Calvo-Fullana and\n  Alejandro Ribeiro", "title": "The empirical duality gap of constrained statistical learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the study of constrained statistical learning\nproblems, the unconstrained version of which are at the core of virtually all\nof modern information processing. Accounting for constraints, however, is\nparamount to incorporate prior knowledge and impose desired structural and\nstatistical properties on the solutions. Still, solving constrained statistical\nproblems remains challenging and guarantees scarce, leaving them to be tackled\nusing regularized formulations. Though practical and effective, selecting\nregularization parameters so as to satisfy requirements is challenging, if at\nall possible, due to the lack of a straightforward relation between parameters\nand constraints. In this work, we propose to directly tackle the constrained\nstatistical problem overcoming its infinite dimensionality, unknown\ndistributions, and constraints by leveraging finite dimensional\nparameterizations, sample averages, and duality theory. Aside from making the\nproblem tractable, these tools allow us to bound the empirical duality gap,\ni.e., the difference between our approximate tractable solutions and the actual\nsolutions of the original statistical problem. We demonstrate the effectiveness\nand usefulness of this constrained formulation in a fair learning application.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:12:29 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chamon", "Luiz F. O.", ""], ["Paternain", "Santiago", ""], ["Calvo-Fullana", "Miguel", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2002.05189", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Shubham Tulsiani, Saurabh Gupta, Abhinav Gupta", "title": "Intrinsic Motivation for Encouraging Synergistic Behavior", "comments": "ICLR 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of intrinsic motivation as an exploration bias for\nreinforcement learning in sparse-reward synergistic tasks, which are tasks\nwhere multiple agents must work together to achieve a goal they could not\nindividually. Our key idea is that a good guiding principle for intrinsic\nmotivation in synergistic tasks is to take actions which affect the world in\nways that would not be achieved if the agents were acting on their own. Thus,\nwe propose to incentivize agents to take (joint) actions whose effects cannot\nbe predicted via a composition of the predicted effect for each individual\nagent. We study two instantiations of this idea, one based on the true states\nencountered, and another based on a dynamics model trained concurrently with\nthe policy. While the former is simpler, the latter has the benefit of being\nanalytically differentiable with respect to the action taken. We validate our\napproach in robotic bimanual manipulation and multi-agent locomotion tasks with\nsparse rewards; we find that our approach yields more efficient learning than\nboth 1) training with only the sparse reward and 2) using the typical\nsurprise-based formulation of intrinsic motivation, which does not bias toward\nsynergistic behavior. Videos are available on the project webpage:\nhttps://sites.google.com/view/iclr2020-synergistic.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:34:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chitnis", "Rohan", ""], ["Tulsiani", "Shubham", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2002.05193", "submitter": "Momin M. Malik", "authors": "Momin M. Malik", "title": "A Hierarchy of Limitations in Machine Learning", "comments": "68 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  \"All models are wrong, but some are useful\", wrote George E. P. Box (1979).\nMachine learning has focused on the usefulness of probability models for\nprediction in social systems, but is only now coming to grips with the ways in\nwhich these models are wrong---and the consequences of those shortcomings. This\npaper attempts a comprehensive, structured overview of the specific conceptual,\nprocedural, and statistical limitations of models in machine learning when\napplied to society. Machine learning modelers themselves can use the described\nhierarchy to identify possible failure points and think through how to address\nthem, and consumers of machine learning models can know what to question when\nconfronted with the decision about if, where, and how to apply machine\nlearning. The limitations go from commitments inherent in quantification\nitself, through to showing how unmodeled dependencies can lead to\ncross-validation being overly optimistic as a way of assessing model\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:39:29 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:04:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Malik", "Momin M.", ""]]}, {"id": "2002.05194", "submitter": "Oberon Berlage", "authors": "Oberon Berlage, Klaus-Michael Lux, David Graus", "title": "Improving automated segmentation of radio shows with audio embeddings", "comments": "5 pages, 2 figures, submitted to ICASSP2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054315", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio features have been proven useful for increasing the performance of\nautomated topic segmentation systems. This study explores the novel task of\nusing audio embeddings for automated, topically coherent segmentation of radio\nshows. We created three different audio embedding generators using multi-class\nclassification tasks on three datasets from different domains. We evaluate\ntopic segmentation performance of the audio embeddings and compare it against a\ntext-only baseline. We find that a set-up including audio embeddings generated\nthrough a non-speech sound event classification task significantly outperforms\nour text-only baseline by 32.3% in F1-measure. In addition, we find that\ndifferent classification tasks yield audio embeddings that vary in segmentation\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:40:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Berlage", "Oberon", ""], ["Lux", "Klaus-Michael", ""], ["Graus", "David", ""]]}, {"id": "2002.05198", "submitter": "Fabricio Breve", "authors": "Fabricio Aparecido Breve, Liang Zhao, Marcos Gon\\c{c}alves Quiles", "title": "Particle Competition and Cooperation for Semi-Supervised Learning with\n  Label Noise", "comments": null, "journal-ref": "Neurocomputing (Amsterdam), v.160, p.63 - 72, 2015", "doi": "10.1016/j.neucom.2014.08.082", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning methods are usually employed in the classification\nof data sets where only a small subset of the data items is labeled. In these\nscenarios, label noise is a crucial issue, since the noise may easily spread to\na large portion or even the entire data set, leading to major degradation in\nclassification accuracy. Therefore, the development of new techniques to reduce\nthe nasty effects of label noise in semi-supervised learning is a vital issue.\nRecently, a graph-based semi-supervised learning approach based on Particle\ncompetition and cooperation was developed. In this model, particles walk in the\ngraphs constructed from the data sets. Competition takes place among particles\nrepresenting different class labels, while the cooperation occurs among\nparticles with the same label. This paper presents a new particle competition\nand cooperation algorithm, specifically designed to increase the robustness to\nthe presence of label noise, improving its label noise tolerance. Different\nfrom other methods, the proposed one does not require a separate technique to\ndeal with label noise. It performs classification of unlabeled nodes and\nreclassification of the nodes affected by label noise in a unique process.\nComputer simulations show the classification accuracy of the proposed method\nwhen applied to some artificial and real-world data sets, in which we introduce\nincreasing amounts of label noise. The classification accuracy is compared to\nthose achieved by previous particle competition and cooperation algorithms and\nother representative graph-based semi-supervised learning methods using the\nsame scenarios. Results show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:44:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Breve", "Fabricio Aparecido", ""], ["Zhao", "Liang", ""], ["Quiles", "Marcos Gon\u00e7alves", ""]]}, {"id": "2002.05202", "submitter": "Noam Shazeer", "authors": "Noam Shazeer", "title": "GLU Variants Improve Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gated Linear Units (arXiv:1612.08083) consist of the component-wise product\nof two linear projections, one of which is first passed through a sigmoid\nfunction. Variations on GLU are possible, using different nonlinear (or even\nlinear) functions in place of sigmoid. We test these variants in the\nfeed-forward sublayers of the Transformer (arXiv:1706.03762)\nsequence-to-sequence model, and find that some of them yield quality\nimprovements over the typically-used ReLU or GELU activations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:57:13 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Shazeer", "Noam", ""]]}, {"id": "2002.05212", "submitter": "Tianhui Zhou", "authors": "Tianhui Zhou, Yitong Li, Yuan Wu, David Carlson", "title": "Estimating Uncertainty Intervals from Collaborating Networks", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective decision making requires understanding the uncertainty inherent in\na prediction. To estimate uncertainty in regression, one could modify a deep\nneural network to predict coverage intervals, such as by predicting the mean\nand standard deviation. Unfortunately, in our empirical evaluations the\npredicted coverage from existing approaches is either overconfident or lacks\nsharpness (gives imprecise intervals). To address this challenge, we propose a\nnovel method to estimate uncertainty based on two distinct neural networks with\ntwo distinct loss functions in a similar vein to Generative Adversarial\nNetworks. Specifically, one network tries to learn the cumulative distribution\nfunction, and the second network tries to learn its inverse. Theoretical\nanalysis demonstrates that the idealized solution is a fixed point and that\nunder certain conditions the approach is asymptotically consistent to ground\ntruth. We benchmark the approach on one synthetic and five real-world datasets,\nincluding forecasting A1c values in diabetic patients from electronic health\nrecords, where uncertainty is critical. In synthetic data, the proposed\napproach essentially matches the theoretically optimal solution in all aspects.\nIn the real datasets, the proposed approach is empirically more faithful in its\ncoverage estimates and typically gives sharper intervals than competing\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:10:27 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 17:42:21 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhou", "Tianhui", ""], ["Li", "Yitong", ""], ["Wu", "Yuan", ""], ["Carlson", "David", ""]]}, {"id": "2002.05217", "submitter": "Sergei Volodin", "authors": "Sergei Volodin, Nevan Wichers, Jeremy Nixon", "title": "Resolving Spurious Correlations in Causal Models of Environments via\n  Interventions", "comments": "9 pages, 7 figures, 3 pages supplementary material", "journal-ref": "Causal Learning for Decision Making (CLDM) ICLR CLDM 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal models bring many benefits to decision-making systems (or agents) by\nmaking them interpretable, sample-efficient, and robust to changes in the input\ndistribution. However, spurious correlations can lead to wrong causal models\nand predictions. We consider the problem of inferring a causal model of a\nreinforcement learning environment and we propose a method to deal with\nspurious correlations. Specifically, our method designs a reward function that\nincentivizes an agent to do an intervention to find errors in the causal model.\nThe data obtained from doing the intervention is used to improve the causal\nmodel. We propose several intervention design methods and compare them. The\nexperimental results in a grid-world environment show that our approach leads\nto better causal models compared to baselines: learning the model on data from\na random policy or a policy trained on the environment's reward. The main\ncontribution consists of methods to design interventions to resolve spurious\ncorrelations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:20:47 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 19:40:05 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Volodin", "Sergei", ""], ["Wichers", "Nevan", ""], ["Nixon", "Jeremy", ""]]}, {"id": "2002.05226", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Conditional Path Analysis in Singly-Connected Path Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the classical path analysis by showing that, for a singly-connected\npath diagram, the partial covariance of two random variables factorizes over\nthe nodes and edges in the path between the variables. This result allows us to\nshow that Simpson's paradox cannot occur in singly-connected path diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:31:02 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 15:12:41 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 21:08:06 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 10:50:18 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "2002.05227", "submitter": "Dimitris Kalatzis", "authors": "Dimitris Kalatzis, David Eklund, Georgios Arvanitidis, S{\\o}ren\n  Hauberg", "title": "Variational Autoencoders with Riemannian Brownian Motion Priors", "comments": "Published in ICML 2020", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational Autoencoders (VAEs) represent the given data in a low-dimensional\nlatent space, which is generally assumed to be Euclidean. This assumption\nnaturally leads to the common choice of a standard Gaussian prior over\ncontinuous latent variables. Recent work has, however, shown that this prior\nhas a detrimental effect on model capacity, leading to subpar performance. We\npropose that the Euclidean assumption lies at the heart of this failure mode.\nTo counter this, we assume a Riemannian structure over the latent space, which\nconstitutes a more principled geometric view of the latent codes, and replace\nthe standard Gaussian prior with a Riemannian Brownian motion prior. We propose\nan efficient inference scheme that does not rely on the unknown normalizing\nfactor of this prior. Finally, we demonstrate that this prior significantly\nincreases model capacity using only one additional scalar parameter.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:35:21 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:08:37 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 16:01:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kalatzis", "Dimitris", ""], ["Eklund", "David", ""], ["Arvanitidis", "Georgios", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2002.05229", "submitter": "Ge Liu", "authors": "Ge Liu, Rui Wu, Heng-Tze Cheng, Jing Wang, Jayden Ooi, Lihong Li, Ang\n  Li, Wai Lok Sibon Li, Craig Boutilier, Ed Chi", "title": "Data Efficient Training for Reinforcement Learning with Adaptive\n  Behavior Policy Sharing", "comments": "on Deep Reinforcement Learning workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning (RL) is proven powerful for decision making in\nsimulated environments. However, training deep RL model is challenging in real\nworld applications such as production-scale health-care or recommender systems\nbecause of the expensiveness of interaction and limitation of budget at\ndeployment. One aspect of the data inefficiency comes from the expensive\nhyper-parameter tuning when optimizing deep neural networks. We propose\nAdaptive Behavior Policy Sharing (ABPS), a data-efficient training algorithm\nthat allows sharing of experience collected by behavior policy that is\nadaptively selected from a pool of agents trained with an ensemble of\nhyper-parameters. We further extend ABPS to evolve hyper-parameters during\ntraining by hybridizing ABPS with an adapted version of Population Based\nTraining (ABPS-PBT). We conduct experiments with multiple Atari games with up\nto 16 hyper-parameter/architecture setups. ABPS achieves superior overall\nperformance, reduced variance on top 25% agents, and equivalent performance on\nthe best agent compared to conventional hyper-parameter tuning with independent\ntraining, even though ABPS only requires the same number of environmental\ninteractions as training a single agent. We also show that ABPS-PBT further\nimproves the convergence speed and reduces the variance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:35:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Liu", "Ge", ""], ["Wu", "Rui", ""], ["Cheng", "Heng-Tze", ""], ["Wang", "Jing", ""], ["Ooi", "Jayden", ""], ["Li", "Lihong", ""], ["Li", "Ang", ""], ["Li", "Wai Lok Sibon", ""], ["Boutilier", "Craig", ""], ["Chi", "Ed", ""]]}, {"id": "2002.05233", "submitter": "Emanuele Pesce Mr.", "authors": "Emanuele Pesce, Giovanni Montana", "title": "Learning Multi-Agent Coordination through Graph-driven Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of learning collaborative behaviour through\ncommunication in multi-agent systems using deep reinforcement learning. A\nconnectivity-driven communication (CDC) algorithm is proposed to address three\nkey aspects: what agents to involve in the communication, what information\ncontent to share, and how often to share it. The multi-agent system is modelled\nas a weighted graph with nodes representing agents. The unknown edge weights\nreflect the degree of communication between pairs of agents, which depends on a\ndiffusion process on the graph - the heat kernel. An optimal communication\nstrategy, tightly coupled with overall graph topology, is learned end-to-end\nconcurrently with the agents' policy so as to maximise future expected returns.\nEmpirical results show that CDC is capable of superior performance over\nalternative algorithms for a range of cooperative navigation tasks, and that\nthe learned graph structures can be interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:58:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 20:00:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Pesce", "Emanuele", ""], ["Montana", "Giovanni", ""]]}, {"id": "2002.05257", "submitter": "Fatemeh Salehi Rizi", "authors": "Fatemeh Salehi Rizi, Joerg Schloetterer, Michael Granitzer", "title": "Shortest path distance approximation using deep learning techniques", "comments": null, "journal-ref": null, "doi": "10.1109/ASONAM.2018.8508763", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Computing shortest path distances between nodes lies at the heart of many\ngraph algorithms and applications. Traditional exact methods such as\nbreadth-first-search (BFS) do not scale up to contemporary, rapidly evolving\ntoday's massive networks. Therefore, it is required to find approximation\nmethods to enable scalable graph processing with a significant speedup. In this\npaper, we utilize vector embeddings learnt by deep learning techniques to\napproximate the shortest paths distances in large graphs. We show that a\nfeedforward neural network fed with embeddings can approximate distances with\nrelatively low distortion error. The suggested method is evaluated on the\nFacebook, BlogCatalog, Youtube and Flickr social networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:59:25 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Rizi", "Fatemeh Salehi", ""], ["Schloetterer", "Joerg", ""], ["Granitzer", "Michael", ""]]}, {"id": "2002.05273", "submitter": "Xiaoyu Li", "authors": "Xiaoyu Li, Zhenxun Zhuang, Francesco Orabona", "title": "A Second look at Exponential and Cosine Step Sizes: Simplicity,\n  Adaptivity, and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is a popular tool in training large-scale\nmachine learning models. Its performance, however, is highly variable,\ndepending crucially on the choice of the step sizes. Accordingly, a variety of\nstrategies for tuning the step sizes have been proposed, ranging from\ncoordinate-wise approaches (a.k.a. ``adaptive'' step sizes) to sophisticated\nheuristics to change the step size in each iteration. In this paper, we study\ntwo step size schedules whose power has been repeatedly confirmed in practice:\nthe exponential and the cosine step sizes. For the first time, we provide\ntheoretical support for them proving convergence rates for smooth non-convex\nfunctions, with and without the Polyak-\\L{}ojasiewicz (PL) condition. Moreover,\nwe show the surprising property that these two strategies are \\emph{adaptive}\nto the noise level in the stochastic gradients of PL functions. That is,\ncontrary to polynomial step sizes, they achieve almost optimal performance\nwithout needing to know the noise level nor tuning their hyperparameters based\non it. Finally, we conduct a fair and comprehensive empirical evaluation of\nreal-world datasets with deep learning architectures. Results show that, even\nif only requiring at most two hyperparameters to tune, these two strategies\nbest or match the performance of various finely-tuned state-of-the-art\nstrategies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:10:38 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 15:22:38 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 19:27:19 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 18:26:34 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Li", "Xiaoyu", ""], ["Zhuang", "Zhenxun", ""], ["Orabona", "Francesco", ""]]}, {"id": "2002.05283", "submitter": "Xiangning Chen", "authors": "Xiangning Chen, Cho-Jui Hsieh", "title": "Stabilizing Differentiable Architecture Search via Perturbation-based\n  Regularization", "comments": "ICML 2020, code is available at\n  https://github.com/xiangning-chen/SmoothDARTS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable architecture search (DARTS) is a prevailing NAS solution to\nidentify architectures. Based on the continuous relaxation of the architecture\nspace, DARTS learns a differentiable architecture weight and largely reduces\nthe search cost. However, its stability has been challenged for yielding\ndeteriorating architectures as the search proceeds. We find that the\nprecipitous validation loss landscape, which leads to a dramatic performance\ndrop when distilling the final architecture, is an essential factor that causes\ninstability. Based on this observation, we propose a perturbation-based\nregularization - SmoothDARTS (SDARTS), to smooth the loss landscape and improve\nthe generalizability of DARTS-based methods. In particular, our new\nformulations stabilize DARTS-based methods by either random smoothing or\nadversarial attack. The search trajectory on NAS-Bench-1Shot1 demonstrates the\neffectiveness of our approach and due to the improved stability, we achieve\nperformance gain across various search spaces on 4 datasets. Furthermore, we\nmathematically show that SDARTS implicitly regularizes the Hessian norm of the\nvalidation loss, which accounts for a smoother loss landscape and improved\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:46:58 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 21:56:42 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 19:17:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chen", "Xiangning", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.05287", "submitter": "Bingzhe Wei", "authors": "Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, Bo Yang", "title": "Geom-GCN: Geometric Graph Convolutional Networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message-passing neural networks (MPNNs) have been successfully applied to\nrepresentation learning on graphs in a variety of real-world applications.\nHowever, two fundamental weaknesses of MPNNs' aggregators limit their ability\nto represent graph-structured data: losing the structural information of nodes\nin neighborhoods and lacking the ability to capture long-range dependencies in\ndisassortative graphs. Few studies have noticed the weaknesses from different\nperspectives. From the observations on classical neural network and network\ngeometry, we propose a novel geometric aggregation scheme for graph neural\nnetworks to overcome the two weaknesses. The behind basic idea is the\naggregation on a graph can benefit from a continuous space underlying the\ngraph. The proposed aggregation scheme is permutation-invariant and consists of\nthree modules, node embedding, structural neighborhood, and bi-level\naggregation. We also present an implementation of the scheme in graph\nconvolutional networks, termed Geom-GCN (Geometric Graph Convolutional\nNetworks), to perform transductive learning on graphs. Experimental results\nshow the proposed Geom-GCN achieved state-of-the-art performance on a wide\nrange of open datasets of graphs. Code is available at\nhttps://github.com/graphdml-uiuc-jlu/geom-gcn.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:03:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 01:47:35 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pei", "Hongbin", ""], ["Wei", "Bingzhe", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Lei", "Yu", ""], ["Yang", "Bo", ""]]}, {"id": "2002.05289", "submitter": "Qin Ding Miss", "authors": "Qin Ding, Cho-Jui Hsieh, James Sharpnack", "title": "Multiscale Non-stationary Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic contextual bandit algorithms for linear models, such as LinUCB,\nassume that the reward distribution for an arm is modeled by a stationary\nlinear regression. When the linear regression model is non-stationary over\ntime, the regret of LinUCB can scale linearly with time. In this paper, we\npropose a novel multiscale changepoint detection method for the non-stationary\nlinear bandit problems, called Multiscale-LinUCB, which actively adapts to the\nchanging environment. We also provide theoretical analysis of regret bound for\nMultiscale-LinUCB algorithm. Experimental results show that our proposed\nMultiscale-LinUCB algorithm outperforms other state-of-the-art algorithms in\nnon-stationary contextual environments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:24:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ding", "Qin", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "2002.05291", "submitter": "Mohammad Saeed Abrishami", "authors": "Mohammad Saeed Abrishami, Massoud Pedram, Shahin Nazarian", "title": "CSM-NN: Current Source Model Based Logic Circuit Simulation -- A Neural\n  Network Approach", "comments": "37th IEEE International Conference on Computer Design (ICCD), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The miniaturization of transistors down to 5nm and beyond, plus the\nincreasing complexity of integrated circuits, significantly aggravate short\nchannel effects, and demand analysis and optimization of more design corners\nand modes. Simulators need to model output variables related to circuit timing,\npower, noise, etc., which exhibit nonlinear behavior. The existing simulation\nand sign-off tools, based on a combination of closed-form expressions and\nlookup tables are either inaccurate or slow, when dealing with circuits with\nmore than billions of transistors. In this work, we present CSM-NN, a scalable\nsimulation framework with optimized neural network structures and processing\nalgorithms. CSM-NN is aimed at optimizing the simulation time by accounting for\nthe latency of the required memory query and computation, given the underlying\nCPU and GPU parallel processing capabilities. Experimental results show that\nCSM-NN reduces the simulation time by up to $6\\times$ compared to a\nstate-of-the-art current source model based simulator running on a CPU. This\nspeedup improves by up to $15\\times$ when running on a GPU. CSM-NN also\nprovides high accuracy levels, with less than $2\\%$ error, compared to HSPICE.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:29:44 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Abrishami", "Mohammad Saeed", ""], ["Pedram", "Massoud", ""], ["Nazarian", "Shahin", ""]]}, {"id": "2002.05295", "submitter": "Viet Lai", "authors": "Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen", "title": "Exploiting the Matching Information in the Support Set for Few Shot\n  Event Classification", "comments": "Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2020", "journal-ref": null, "doi": "10.1007/978-3-030-47436-2_18", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The existing event classification (EC) work primarily focuseson the\ntraditional supervised learning setting in which models are unableto extract\nevent mentions of new/unseen event types. Few-shot learninghas not been\ninvestigated in this area although it enables EC models toextend their\noperation to unobserved event types. To fill in this gap, inthis work, we\ninvestigate event classification under the few-shot learningsetting. We propose\na novel training method for this problem that exten-sively exploit the support\nset during the training process of a few-shotlearning model. In particular, in\naddition to matching the query exam-ple with those in the support set for\ntraining, we seek to further matchthe examples within the support set\nthemselves. This method providesmore training signals for the models and can be\napplied to every metric-learning-based few-shot learning methods. Our extensive\nexperiments ontwo benchmark EC datasets show that the proposed method can\nimprovethe best reported few-shot learning models by up to 10% on accuracyfor\nevent classification\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:40:36 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 07:37:15 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lai", "Viet Dac", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "2002.05304", "submitter": "Guang Cheng", "authors": "Yue Xing, Qifan Song, Guang Cheng", "title": "Predictive Power of Nearest Neighbors Algorithm under Random\n  Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a data corruption scenario in the classical $k$ Nearest Neighbors\n($k$-NN) algorithm, that is, the testing data are randomly perturbed. Under\nsuch a scenario, the impact of corruption level on the asymptotic regret is\ncarefully characterized. In particular, our theoretical analysis reveals a\nphase transition phenomenon that, when the corruption level $\\omega$ is below a\ncritical order (i.e., small-$\\omega$ regime), the asymptotic regret remains the\nsame; when it is beyond that order (i.e., large-$\\omega$ regime), the\nasymptotic regret deteriorates polynomially. Surprisingly, we obtain a negative\nresult that the classical noise-injection approach will not help improve the\ntesting performance in the beginning stage of the large-$\\omega$ regime, even\nin the level of the multiplicative constant of asymptotic regret. As a\ntechnical by-product, we prove that under different model assumptions, the\npre-processed 1-NN proposed in \\cite{xue2017achieving} will at most achieve a\nsub-optimal rate when the data dimension $d>4$ even if $k$ is chosen optimally\nin the pre-processing step.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 01:35:35 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.05308", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Takuya Ishihara, Junya Honda, Yusuke Narita", "title": "Adaptive Experimental Design for Efficient Treatment Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of many scientific experiments including A/B testing is to estimate\nthe average treatment effect (ATE), which is defined as the difference between\nthe expected outcomes of two or more treatments. In this paper, we consider a\nsituation where an experimenter can assign a treatment to research subjects\nsequentially. In adaptive experimental design, the experimenter is allowed to\nchange the probability of assigning a treatment using past observations for\nestimating the ATE efficiently. However, with this approach, it is difficult to\napply a standard statistical method to construct an estimator because the\nobservations are not independent and identically distributed. We thus propose\nan algorithm for efficient experiments with estimators constructed from\ndependent samples. We also introduce a sequential testing framework using the\nproposed estimator. To justify our proposed approach, we provide finite and\ninfinite sample analyses. Finally, we experimentally show that the proposed\nalgorithm exhibits preferable performance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:04:17 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:15:49 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 15:24:34 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kato", "Masahiro", ""], ["Ishihara", "Takuya", ""], ["Honda", "Junya", ""], ["Narita", "Yusuke", ""]]}, {"id": "2002.05309", "submitter": "Yan Yan", "authors": "Yan Yan and Yi Xu and Qihang Lin and Wei Liu and Tianbao Yang", "title": "Optimal Epoch Stochastic Gradient Descent Ascent Methods for Min-Max\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epoch gradient descent method (a.k.a. Epoch-GD) proposed by Hazan and Kale\n(2011) was deemed a breakthrough for stochastic strongly convex minimization,\nwhich achieves the optimal convergence rate of $O(1/T)$ with $T$ iterative\nupdates for the {\\it objective gap}. However, its extension to solving\nstochastic min-max problems with strong convexity and strong concavity still\nremains open, and it is still unclear whether a fast rate of $O(1/T)$ for the\n{\\it duality gap} is achievable for stochastic min-max optimization under\nstrong convexity and strong concavity. Although some recent studies have\nproposed stochastic algorithms with fast convergence rates for min-max\nproblems, they require additional assumptions about the problem, e.g.,\nsmoothness, bi-linear structure, etc. In this paper, we bridge this gap by\nproviding a sharp analysis of epoch-wise stochastic gradient descent ascent\nmethod (referred to as Epoch-GDA) for solving strongly convex strongly concave\n(SCSC) min-max problems, without imposing any additional assumption about\nsmoothness or the function's structure. To the best of our knowledge, our\nresult is the first one that shows Epoch-GDA can achieve the optimal rate of\n$O(1/T)$ for the duality gap of general SCSC min-max problems. We emphasize\nthat such generalization of Epoch-GD for strongly convex minimization problems\nto Epoch-GDA for SCSC min-max problems is non-trivial and requires novel\ntechnical analysis. Moreover, we notice that the key lemma can also be used for\nproving the convergence of Epoch-GDA for weakly-convex strongly-concave min-max\nproblems, leading to a nearly optimal complexity without resorting to\nsmoothness or other structural conditions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:16:57 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 09:02:49 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Yan", "Yan", ""], ["Xu", "Yi", ""], ["Lin", "Qihang", ""], ["Liu", "Wei", ""], ["Yang", "Tianbao", ""]]}, {"id": "2002.05314", "submitter": "Yifan Ding", "authors": "Yifan Ding, Yong Xu, Shi-Xiong Zhang, Yahuan Cong and Liqiang Wang", "title": "Self-supervised learning for audio-visual speaker diarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization, which is to find the speech segments of specific\nspeakers, has been widely used in human-centered applications such as video\nconferences or human-computer interaction systems. In this paper, we propose a\nself-supervised audio-video synchronization learning method to address the\nproblem of speaker diarization without massive labeling effort. We improve the\nprevious approaches by introducing two new loss functions: the dynamic triplet\nloss and the multinomial loss. We test them on a real-world human-computer\ninteraction system and the results show our best model yields a remarkable gain\nof +8%F1-scoresas well as diarization error rate reduction. Finally, we\nintroduce a new large scale audio-video corpus designed to fill the vacancy of\naudio-video datasets in Chinese.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:36:32 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ding", "Yifan", ""], ["Xu", "Yong", ""], ["Zhang", "Shi-Xiong", ""], ["Cong", "Yahuan", ""], ["Wang", "Liqiang", ""]]}, {"id": "2002.05318", "submitter": "Guanya Shi", "authors": "Guanya Shi, Yiheng Lin, Soon-Jo Chung, Yisong Yue, Adam Wierman", "title": "Online Optimization with Memory and Competitive Control", "comments": "Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents competitive algorithms for a novel class of online\noptimization problems with memory. We consider a setting where the learner\nseeks to minimize the sum of a hitting cost and a switching cost that depends\non the previous $p$ decisions. This setting generalizes Smoothed Online Convex\nOptimization. The proposed approach, Optimistic Regularized Online Balanced\nDescent, achieves a constant, dimension-free competitive ratio. Further, we\nshow a connection between online optimization with memory and online control\nwith adversarial disturbances. This connection, in turn, leads to a new\nconstant-competitive policy for a rich class of online control problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:58:11 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 00:50:24 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 06:24:19 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Shi", "Guanya", ""], ["Lin", "Yiheng", ""], ["Chung", "Soon-Jo", ""], ["Yue", "Yisong", ""], ["Wierman", "Adam", ""]]}, {"id": "2002.05321", "submitter": "Shaojie Tang", "authors": "Shaojie Tang and Jing Yuan", "title": "Assortment Optimization with Repeated Exposures and Product-dependent\n  Patience Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the assortment optimization problem faced by many\nonline retailers such as Amazon. We develop a \\emph{cascade multinomial logit\nmodel}, based on the classic multinomial logit model, to capture the consumers'\npurchasing behavior across multiple stages. Different from existing studies,\nour model allows for repeated exposures of a product, i.e., the same product\ncan be displayed multiple times across different stages. In addition, each\nconsumer has a \\emph{patience budget} that is sampled from a known distribution\nand each product is associated with a \\emph{patience cost}, which captures the\ncognitive efforts spent on browsing that product. Given an assortment of\nproducts, a consumer sequentially browses them stage by stage. After browsing\nall products in one stage, if the utility of a product exceeds the utility of\nthe outside option, the consumer proceeds to purchase the product and leave the\nplatform. Otherwise, if the patience cost of all products browsed up to that\npoint is no larger than her patience budget, she continues to view the next\nstage. We propose an approximation solution to this problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 03:12:49 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 20:32:29 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Tang", "Shaojie", ""], ["Yuan", "Jing", ""]]}, {"id": "2002.05359", "submitter": "Samuel Horv\\'ath", "authors": "Samuel Horv\\'ath, Lihua Lei, Peter Richt\\'arik, Michael I. Jordan", "title": "Adaptivity of Stochastic Gradient Methods for Nonconvex Optimization", "comments": "11 pages, 4 Figures, 20 pages Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptivity is an important yet under-studied property in modern optimization\ntheory. The gap between the state-of-the-art theory and the current practice is\nstriking in that algorithms with desirable theoretical guarantees typically\ninvolve drastically different settings of hyperparameters, such as step-size\nschemes and batch sizes, in different regimes. Despite the appealing\ntheoretical results, such divisive strategies provide little, if any, insight\nto practitioners to select algorithms that work broadly without tweaking the\nhyperparameters. In this work, blending the \"geometrization\" technique\nintroduced by Lei & Jordan 2016 and the \\texttt{SARAH} algorithm of Nguyen et\nal., 2017, we propose the Geometrized \\texttt{SARAH} algorithm for non-convex\nfinite-sum and stochastic optimization. Our algorithm is proved to achieve\nadaptivity to both the magnitude of the target accuracy and the\nPolyak-\\L{}ojasiewicz (PL) constant if present. In addition, it achieves the\nbest-available convergence rate for non-PL objectives simultaneously while\noutperforming existing algorithms for PL objectives.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 05:42:27 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Horv\u00e1th", "Samuel", ""], ["Lei", "Lihua", ""], ["Richt\u00e1rik", "Peter", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.05366", "submitter": "Taejong Joo", "authors": "Taejong Joo, Donggu Kang, Byunghoon Kim", "title": "Regularizing activations in neural networks via distribution matching\n  with the Wasserstein metric", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization and normalization have become indispensable components in\ntraining deep neural networks, resulting in faster training and improved\ngeneralization performance. We propose the projected error function\nregularization loss (PER) that encourages activations to follow the standard\nnormal distribution. PER randomly projects activations onto one-dimensional\nspace and computes the regularization loss in the projected space. PER is\nsimilar to the Pseudo-Huber loss in the projected space, thus taking advantage\nof both $L^1$ and $L^2$ regularization losses. Besides, PER can capture the\ninteraction between hidden units by projection vector drawn from a unit sphere.\nBy doing so, PER minimizes the upper bound of the Wasserstein distance of order\none between an empirical distribution of activations and the standard normal\ndistribution. To the best of the authors' knowledge, this is the first work to\nregularize activations via distribution matching in the probability\ndistribution space. We evaluate the proposed method on the image classification\ntask and the word-level language modeling task.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 06:42:01 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 02:31:16 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Joo", "Taejong", ""], ["Kang", "Donggu", ""], ["Kim", "Byunghoon", ""]]}, {"id": "2002.05373", "submitter": "Usman Khan", "authors": "Ran Xin, Soummya Kar, Usman A. Khan", "title": "Gradient tracking and variance reduction for decentralized optimization\n  and machine learning", "comments": "accepted for publication, IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized methods to solve finite-sum minimization problems are important\nin many signal processing and machine learning tasks where the data is\ndistributed over a network of nodes and raw data sharing is not permitted due\nto privacy and/or resource constraints. In this article, we review\ndecentralized stochastic first-order methods and provide a unified algorithmic\nframework that combines variance-reduction with gradient tracking to achieve\nboth robust performance and fast convergence. We provide explicit theoretical\nguarantees of the corresponding methods when the objective functions are smooth\nand strongly-convex, and show their applicability to non-convex problems via\nnumerical experiments. Throughout the article, we provide intuitive\nillustrations of the main technical ideas by casting appropriate tradeoffs and\ncomparisons among the methods of interest and by highlighting applications to\ndecentralized training of machine learning models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:17:07 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2002.05379", "submitter": "Ian Fischer", "authors": "Ian Fischer", "title": "The Conditional Entropy Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the field of Machine Learning exhibits a prominent set of failure\nmodes, including vulnerability to adversarial examples, poor\nout-of-distribution (OoD) detection, miscalibration, and willingness to\nmemorize random labelings of datasets. We characterize these as failures of\nrobust generalization, which extends the traditional measure of generalization\nas accuracy or related metrics on a held-out set. We hypothesize that these\nfailures to robustly generalize are due to the learning systems retaining too\nmuch information about the training data. To test this hypothesis, we propose\nthe Minimum Necessary Information (MNI) criterion for evaluating the quality of\na model. In order to train models that perform well with respect to the MNI\ncriterion, we present a new objective function, the Conditional Entropy\nBottleneck (CEB), which is closely related to the Information Bottleneck (IB).\nWe experimentally test our hypothesis by comparing the performance of CEB\nmodels with deterministic models and Variational Information Bottleneck (VIB)\nmodels on a variety of different datasets and robustness challenges. We find\nstrong empirical evidence supporting our hypothesis that MNI models improve on\nthese problems of robust generalization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:46:38 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Fischer", "Ian", ""]]}, {"id": "2002.05380", "submitter": "Ian Fischer", "authors": "Ian Fischer and Alexander A. Alemi", "title": "CEB Improves Model Robustness", "comments": null, "journal-ref": null, "doi": "10.3390/e22101081", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that the Conditional Entropy Bottleneck (CEB) can improve\nmodel robustness. CEB is an easy strategy to implement and works in tandem with\ndata augmentation procedures. We report results of a large scale adversarial\nrobustness study on CIFAR-10, as well as the ImageNet-C Common Corruptions\nBenchmark, ImageNet-A, and PGD attacks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:49:22 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Fischer", "Ian", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "2002.05392", "submitter": "Nadav Merlis", "authors": "Nadav Merlis, Shie Mannor", "title": "Tight Lower Bounds for Combinatorial Multi-Armed Bandits", "comments": "Accepted to COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Combinatorial Multi-Armed Bandit problem is a sequential decision-making\nproblem in which an agent selects a set of arms on each round, observes\nfeedback for each of these arms and aims to maximize a known reward function of\nthe arms it chose. While previous work proved regret upper bounds in this\nsetting for general reward functions, only a few works provided matching lower\nbounds, all for specific reward functions. In this work, we prove regret lower\nbounds for combinatorial bandits that hold under mild assumptions for all\nsmooth reward functions. We derive both problem-dependent and\nproblem-independent bounds and show that the recently proposed Gini-weighted\nsmoothness parameter (Merlis and Mannor, 2019) also determines the lower bounds\nfor monotone reward functions. Notably, this implies that our lower bounds are\ntight up to log-factors.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 08:53:43 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:00:09 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 11:26:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.05397", "submitter": "Johan Simonsson", "authors": "Johan Simonsson, Khalid Tourkey Atta, Dave Zachariah, Wolfgang Birk", "title": "A latent variable approach to heat load prediction in thermal grids", "comments": "Paper submitted to 2020 European Control Conference, Saint\n  Petersburg, Russia", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new method for heat load prediction in district energy\nsystems is proposed. The method uses a nominal model for the prediction of the\noutdoor temperature dependent space heating load, and a data driven latent\nvariable model to predict the time dependent residual heat load. The residual\nheat load arises mainly from time dependent operation of space heating and\nventilation, and domestic hot water production. The resulting model is\nrecursively updated on the basis of a hyper-parameter free implementation that\nresults in a parsimonious model allowing for high computational performance.\nThe approach is applied to a single multi-dwelling building in Lulea, Sweden,\npredicting the heat load using a relatively small number of model parameters\nand easily obtained measurements. The results are compared with predictions\nusing an artificial neural network, showing that the proposed method achieves\nbetter prediction accuracy for the validation case. Additionally, the proposed\nmethods exhibits explainable behavior through the use of an interpretable\nphysical model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:21:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Simonsson", "Johan", ""], ["Atta", "Khalid Tourkey", ""], ["Zachariah", "Dave", ""], ["Birk", "Wolfgang", ""]]}, {"id": "2002.05411", "submitter": "Juan Camilo Vasquez Correa J. C. Vasquez-Correa", "authors": "C. D. Rios-Urrego, J. C. V\\'asquez-Correa, J. F. Vargas-Bonilla, E.\n  N\\\"oth, F. Lopera, J. R. Orozco-Arroyave", "title": "Analysis and Evaluation of Handwriting in Patients with Parkinson's\n  Disease Using kinematic, Geometrical, and Non-linear Features", "comments": null, "journal-ref": "Computer methods and programs in biomedicine, 173, 43-52 (2019)", "doi": "10.1016/j.cmpb.2019.03.005", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and objectives: Parkinson's disease is a neurological disorder\nthat affects the motor system producing lack of coordination, resting tremor,\nand rigidity. Impairments in handwriting are among the main symptoms of the\ndisease. Handwriting analysis can help in supporting the diagnosis and in\nmonitoring the progress of the disease. This paper aims to evaluate the\nimportance of different groups of features to model handwriting deficits that\nappear due to Parkinson's disease; and how those features are able to\ndiscriminate between Parkinson's disease patients and healthy subjects.\n  Methods: Features based on kinematic, geometrical and non-linear dynamics\nanalyses were evaluated to classify Parkinson's disease and healthy subjects.\nClassifiers based on K-nearest neighbors, support vector machines, and random\nforest were considered.\n  Results: Accuracies of up to $93.1\\%$ were obtained in the classification of\npatients and healthy control subjects. A relevance analysis of the features\nindicated that those related to speed, acceleration, and pressure are the most\ndiscriminant. The automatic classification of patients in different stages of\nthe disease shows $\\kappa$ indexes between $0.36$ and $0.44$. Accuracies of up\nto $83.3\\%$ were obtained in a different dataset used only for validation\npurposes.\n  Conclusions: The results confirmed the negative impact of aging in the\nclassification process when we considered different groups of healthy subjects.\nIn addition, the results reported with the separate validation set comprise a\nstep towards the development of automated tools to support the diagnosis\nprocess in clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:54:41 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Rios-Urrego", "C. D.", ""], ["V\u00e1squez-Correa", "J. C.", ""], ["Vargas-Bonilla", "J. F.", ""], ["N\u00f6th", "E.", ""], ["Lopera", "F.", ""], ["Orozco-Arroyave", "J. R.", ""]]}, {"id": "2002.05412", "submitter": "Juan Camilo V\\'asquez-Correa", "authors": "J. C. Vasquez-Correa, T. Bocklet, J. R. Orozco-Arroyave, E. N\\\"oth", "title": "Comparison of user models based on GMM-UBM and i-vectors for speech,\n  handwriting, and gait assessment of Parkinson's disease patients", "comments": "Proceedings of ICASSP (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parkinson's disease is a neurodegenerative disorder characterized by the\npresence of different motor impairments. Information from speech, handwriting,\nand gait signals have been considered to evaluate the neurological state of the\npatients. On the other hand, user models based on Gaussian mixture models -\nuniversal background models (GMM-UBM) and i-vectors are considered the\nstate-of-the-art in biometric applications like speaker verification because\nthey are able to model specific speaker traits. This study introduces the use\nof GMM-UBM and i-vectors to evaluate the neurological state of Parkinson's\npatients using information from speech, handwriting, and gait. The results show\nthe importance of different feature sets from each type of signal in the\nassessment of the neurological state of the patients.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:01:08 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Vasquez-Correa", "J. C.", ""], ["Bocklet", "T.", ""], ["Orozco-Arroyave", "J. R.", ""], ["N\u00f6th", "E.", ""]]}, {"id": "2002.05424", "submitter": "Carlo Ciliberto", "authors": "Carlo Ciliberto, Lorenzo Rosasco, Alessandro Rudi", "title": "A General Framework for Consistent Structured Prediction with Implicit\n  Loss Embeddings", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a novel theoretical and algorithmic framework for\nstructured prediction. While so far the term has referred to discrete output\nspaces, here we consider more general settings, such as manifolds or spaces of\nprobability measures. We define structured prediction as a problem where the\noutput space lacks a vectorial structure. We identify and study a large class\nof loss functions that implicitly defines a suitable geometry on the problem.\nThe latter is the key to develop an algorithmic framework amenable to a sharp\nstatistical analysis and yielding efficient computations. When dealing with\noutput spaces with infinite cardinality, a suitable implicit formulation of the\nestimator is shown to be crucial.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:30:04 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ciliberto", "Carlo", ""], ["Rosasco", "Lorenzo", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2002.05426", "submitter": "Ramona Leenings", "authors": "Ramona Leenings, Nils Ralf Winter, Lucas Plagwitz, Vincent Holstein,\n  Jan Ernsting, Jakob Steenweg, Julian Gebker, Kelvin Sarink, Daniel Emden,\n  Dominik Grotegerd, Nils Opel, Benjamin Risse, Xiaoyi Jiang, Udo Dannlowski,\n  Tim Hahn", "title": "PHOTONAI -- A Python API for Rapid Machine Learning Model Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PHOTONAI is a high-level Python API designed to simplify and accelerate\nmachine learning model development. It functions as a unifying framework\nallowing the user to easily access and combine algorithms from different\ntoolboxes into custom algorithm sequences. It is especially designed to support\nthe iterative model development process and automates the repetitive training,\nhyperparameter optimization and evaluation tasks. Importantly, the workflow\nensures unbiased performance estimates while still allowing the user to fully\ncustomize the machine learning analysis. PHOTONAI extends existing solutions\nwith a novel pipeline implementation supporting more complex data streams,\nfeature combinations, and algorithm selection. Metrics and results can be\nconveniently visualized using the PHOTONAI Explorer and predictive models are\nshareable in a standardized format for further external validation or\napplication. A growing add-on ecosystem allows researchers to offer data\nmodality specific algorithms to the community and enhance machine learning in\nthe areas of the life sciences. Its practical utility is demonstrated on an\nexemplary medical machine learning problem, achieving a state-of-the-art\nsolution in few lines of code. Source code is publicly available on Github,\nwhile examples and documentation can be found at www.photon-ai.com.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:33:05 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 13:05:32 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 09:29:35 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 14:34:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Leenings", "Ramona", ""], ["Winter", "Nils Ralf", ""], ["Plagwitz", "Lucas", ""], ["Holstein", "Vincent", ""], ["Ernsting", "Jan", ""], ["Steenweg", "Jakob", ""], ["Gebker", "Julian", ""], ["Sarink", "Kelvin", ""], ["Emden", "Daniel", ""], ["Grotegerd", "Dominik", ""], ["Opel", "Nils", ""], ["Risse", "Benjamin", ""], ["Jiang", "Xiaoyi", ""], ["Dannlowski", "Udo", ""], ["Hahn", "Tim", ""]]}, {"id": "2002.05463", "submitter": "Victor Akinwande", "authors": "Victor Akinwande, Celia Cintas, Skyler Speakman, Srihari Sridharan", "title": "Identifying Audio Adversarial Examples via Anomalous Pattern Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio processing models based on deep neural networks are susceptible to\nadversarial attacks even when the adversarial audio waveform is 99.9% similar\nto a benign sample. Given the wide application of DNN-based audio recognition\nsystems, detecting the presence of adversarial examples is of high practical\nrelevance. By applying anomalous pattern detection techniques in the activation\nspace of these models, we show that 2 of the recent and current\nstate-of-the-art adversarial attacks on audio processing systems systematically\nlead to higher-than-expected activation at some subset of nodes and we can\ndetect these with up to an AUC of 0.98 with no degradation in performance on\nbenign samples.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:08:34 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 06:25:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Akinwande", "Victor", ""], ["Cintas", "Celia", ""], ["Speakman", "Skyler", ""], ["Sridharan", "Srihari", ""]]}, {"id": "2002.05465", "submitter": "\\\"Omer Deniz Akyildiz", "authors": "\\\"Omer Deniz Akyildiz, Sotirios Sabanis", "title": "Nonasymptotic analysis of Stochastic Gradient Hamiltonian Monte Carlo\n  under local conditions for nonconvex optimization", "comments": "Some proofs are fixed and polished", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a nonasymptotic analysis of the convergence of the stochastic\ngradient Hamiltonian Monte Carlo (SGHMC) to a target measure in Wasserstein-2\ndistance without assuming log-concavity. Our analysis quantifies key\ntheoretical properties of the SGHMC as a sampler under local conditions which\nsignificantly improves the findings of previous results. In particular, we\nprove that the Wasserstein-2 distance between the target and the law of the\nSGHMC is uniformly controlled by the step-size of the algorithm, therefore\ndemonstrate that the SGHMC can provide high-precision results uniformly in the\nnumber of iterations. The analysis also allows us to obtain nonasymptotic\nbounds for nonconvex optimization problems under local conditions and implies\nthat the SGHMC, when viewed as a nonconvex optimizer, converges to a global\nminimum with the best known rates. We apply our results to obtain nonasymptotic\nbounds for scalable Bayesian inference and nonasymptotic generalization bounds.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:10:07 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 23:47:55 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 22:30:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Akyildiz", "\u00d6mer Deniz", ""], ["Sabanis", "Sotirios", ""]]}, {"id": "2002.05474", "submitter": "Christopher Jung", "authors": "Yahav Bechavod, Christopher Jung, Zhiwei Steven Wu", "title": "Metric-Free Individual Fairness in Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online learning problem subject to the constraint of individual\nfairness, which requires that similar individuals are treated similarly. Unlike\nprior work on individual fairness, we do not assume the similarity measure\namong individuals is known, nor do we assume that such measure takes a certain\nparametric form. Instead, we leverage the existence of an auditor who detects\nfairness violations without enunciating the quantitative measure. In each\nround, the auditor examines the learner's decisions and attempts to identify a\npair of individuals that are treated unfairly by the learner. We provide a\ngeneral reduction framework that reduces online classification in our model to\nstandard online classification, which allows us to leverage existing online\nlearning algorithms to achieve sub-linear regret and number of fairness\nviolations. Surprisingly, in the stochastic setting where the data are drawn\nindependently from a distribution, we are also able to establish PAC-style\nfairness and accuracy generalization guarantees (Yona and Rothblum [2018]),\ndespite only having access to a very restricted form of fairness feedback. Our\nfairness generalization bound qualitatively matches the uniform convergence\nbound of Yona and Rothblum [2018], while also providing a meaningful accuracy\ngeneralization guarantee. Our results resolve an open question by Gillen et al.\n[2018] by showing that online learning under an unknown individual fairness\nconstraint is possible even without assuming a strong parametric form of the\nunderlying similarity measure.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:25:27 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 16:34:03 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 14:39:52 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Bechavod", "Yahav", ""], ["Jung", "Christopher", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.05502", "submitter": "Ren Yangang", "authors": "Yangang Ren, Jingliang Duan, Shengbo Eben Li, Yang Guan and Qi Sun", "title": "Improving Generalization of Reinforcement Learning with Minimax\n  Distributional Soft Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has achieved remarkable performance in numerous\nsequential decision making and control tasks. However, a common problem is that\nlearned nearly optimal policy always overfits to the training environment and\nmay not be extended to situations never encountered during training. For\npractical applications, the randomness of environment usually leads to some\ndevastating events, which should be the focus of safety-critical systems such\nas autonomous driving. In this paper, we introduce the minimax formulation and\ndistributional framework to improve the generalization ability of RL algorithms\nand develop the Minimax Distributional Soft Actor-Critic (Minimax DSAC)\nalgorithm. Minimax formulation aims to seek optimal policy considering the most\nsevere variations from environment, in which the protagonist policy maximizes\naction-value function while the adversary policy tries to minimize it.\nDistributional framework aims to learn a state-action return distribution, from\nwhich we can model the risk of different returns explicitly, thereby\nformulating a risk-averse protagonist policy and a risk-seeking adversarial\npolicy. We implement our method on the decision-making tasks of autonomous\nvehicles at intersections and test the trained policy in distinct environments.\nResults demonstrate that our method can greatly improve the generalization\nability of the protagonist agent to different environmental variations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:09:22 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 07:59:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ren", "Yangang", ""], ["Duan", "Jingliang", ""], ["Li", "Shengbo Eben", ""], ["Guan", "Yang", ""], ["Sun", "Qi", ""]]}, {"id": "2002.05508", "submitter": "Alessio Pagani Dr", "authors": "Alessio Pagani, Zhuangkun Wei, Ricardo Silva, Weisi Guo", "title": "Neural Network Approximation of Graph Fourier Transforms for Sparse\n  Sampling of Networked Flow Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrastructure monitoring is critical for safe operations and sustainability.\nWater distribution networks (WDNs) are large-scale networked critical systems\nwith complex cascade dynamics which are difficult to predict. Ubiquitous\nmonitoring is expensive and a key challenge is to infer the contaminant\ndynamics from partial sparse monitoring data. Existing approaches use\nmulti-objective optimisation to find the minimum set of essential monitoring\npoints, but lack performance guarantees and a theoretical framework.\n  Here, we first develop Graph Fourier Transform (GFT) operators to compress\nnetworked contamination spreading dynamics to identify the essential principle\ndata collection points with inference performance guarantees. We then build\nautoencoder (AE) inspired neural networks (NN) to generalize the GFT sampling\nprocess and under-sample further from the initial sampling set, allowing a very\nsmall set of data points to largely reconstruct the contamination dynamics over\nreal and artificial WDNs. Various sources of the contamination are tested and\nwe obtain high accuracy reconstruction using around 5-10% of the sample set.\nThis general approach of compression and under-sampled recovery via neural\nnetworks can be applied to a wide range of networked infrastructures to enable\ndigital twins.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:18:37 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Pagani", "Alessio", ""], ["Wei", "Zhuangkun", ""], ["Silva", "Ricardo", ""], ["Guo", "Weisi", ""]]}, {"id": "2002.05511", "submitter": "Sanna Wager C", "authors": "Sanna Wager, George Tzanetakis, Cheng-i Wang, Minje Kim", "title": "Deep Autotuner: a Pitch Correcting Network for Singing Performances", "comments": "arXiv admin note: text overlap with arXiv:1902.00956", "journal-ref": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce a data-driven approach to automatic pitch correction of solo\nsinging performances. The proposed approach predicts note-wise pitch shifts\nfrom the relationship between the respective spectrograms of the singing and\naccompaniment. This approach differs from commercial systems, where vocal track\nnotes are usually shifted to be centered around pitches in a user-defined\nscore, or mapped to the closest pitch among the twelve equal-tempered scale\ndegrees. The proposed system treats pitch as a continuous value rather than\nrelying on a set of discretized notes found in musical scores, thus allowing\nfor improvisation and harmonization in the singing performance. We train our\nneural network model using a dataset of 4,702 amateur karaoke performances\nselected for good intonation. Our model is trained on both incorrect\nintonation, for which it learns a correction, and intentional pitch variation,\nwhich it learns to preserve. The proposed deep neural network with gated\nrecurrent units on top of convolutional layers shows promising performance on\nthe real-world score-free singing pitch correction task of autotuning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:33:56 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wager", "Sanna", ""], ["Tzanetakis", "George", ""], ["Wang", "Cheng-i", ""], ["Kim", "Minje", ""]]}, {"id": "2002.05512", "submitter": "Yuanbo Xiangli", "authors": "Yuanbo Xiangli, Yubin Deng, Bo Dai, Chen Change Loy, Dahua Lin", "title": "Real or Not Real, that is the Question", "comments": "ICLR2020 spotlight. 1) train GAN by maximizing kl-divergence. 2)\n  train non-progressive GAN (DCGAN) architecture at 1024*1024 resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generative adversarial networks (GAN) have been widely adopted in\nvarious topics, in this paper we generalize the standard GAN to a new\nperspective by treating realness as a random variable that can be estimated\nfrom multiple angles. In this generalized framework, referred to as\nRealnessGAN, the discriminator outputs a distribution as the measure of\nrealness. While RealnessGAN shares similar theoretical guarantees with the\nstandard GAN, it provides more insights on adversarial learning. Compared to\nmultiple baselines, RealnessGAN provides stronger guidance for the generator,\nachieving improvements on both synthetic and real-world datasets. Moreover, it\nenables the basic DCGAN architecture to generate realistic images at 1024*1024\nresolution when trained from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:41:55 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xiangli", "Yuanbo", ""], ["Deng", "Yubin", ""], ["Dai", "Bo", ""], ["Loy", "Chen Change", ""], ["Lin", "Dahua", ""]]}, {"id": "2002.05514", "submitter": "Alexander Wikner", "authors": "Alexander Wikner, Jaideep Pathak, Brian Hunt, Michelle Girvan, Troy\n  Arcomano, Istvan Szunyogh, Andrew Pomerance, and Edward Ott", "title": "Combining Machine Learning with Knowledge-Based Modeling for Scalable\n  Forecasting and Subgrid-Scale Closure of Large, Complex, Spatiotemporal\n  Systems", "comments": "45 pages, 15 figures", "journal-ref": null, "doi": "10.1063/5.0005541", "report-no": null, "categories": "cs.LG nlin.CD physics.ao-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the commonly encountered situation (e.g., in weather forecasting)\nwhere the goal is to predict the time evolution of a large, spatiotemporally\nchaotic dynamical system when we have access to both time series data of\nprevious system states and an imperfect model of the full system dynamics.\nSpecifically, we attempt to utilize machine learning as the essential tool for\nintegrating the use of past data into predictions. In order to facilitate\nscalability to the common scenario of interest where the spatiotemporally\nchaotic system is very large and complex, we propose combining two\napproaches:(i) a parallel machine learning prediction scheme; and (ii) a hybrid\ntechnique, for a composite prediction system composed of a knowledge-based\ncomponent and a machine-learning-based component. We demonstrate that not only\ncan this method combining (i) and (ii) be scaled to give excellent performance\nfor very large systems, but also that the length of time series data needed to\ntrain our multiple, parallel machine learning components is dramatically less\nthan that necessary without parallelization. Furthermore, considering cases\nwhere computational realization of the knowledge-based component does not\nresolve subgrid-scale processes, our scheme is able to use training data to\nincorporate the effect of the unresolved short-scale dynamics upon the resolved\nlonger-scale dynamics (\"subgrid-scale closure\").\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:21:50 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wikner", "Alexander", ""], ["Pathak", "Jaideep", ""], ["Hunt", "Brian", ""], ["Girvan", "Michelle", ""], ["Arcomano", "Troy", ""], ["Szunyogh", "Istvan", ""], ["Pomerance", "Andrew", ""], ["Ott", "Edward", ""]]}, {"id": "2002.05515", "submitter": "Malay Haldar", "authors": "Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tyler Sax, Lanbo\n  Zhang, Aamir Mansawala, Shulin Yang, Bradley Turnbull, Junshuo Liao", "title": "Improving Deep Learning For Airbnb Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to search ranking was one of the most\nimpactful product improvements at Airbnb. But what comes next after you launch\na deep learning model? In this paper we describe the journey beyond, discussing\nwhat we refer to as the ABCs of improving search: A for architecture, B for\nbias and C for cold start. For architecture, we describe a new ranking neural\nnetwork, focusing on the process that evolved our existing DNN beyond a fully\nconnected two layer network. On handling positional bias in ranking, we\ndescribe a novel approach that led to one of the most significant improvements\nin tackling inventory that the DNN historically found challenging. To solve\ncold start, we describe our perspective on the problem and changes we made to\nimprove the treatment of new listings on the platform. We hope ranking teams\ntransitioning to deep learning will find this a practical case study of how to\niterate on DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:47:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Haldar", "Malay", ""], ["Abdool", "Mustafa", ""], ["Ramanathan", "Prashant", ""], ["Sax", "Tyler", ""], ["Zhang", "Lanbo", ""], ["Mansawala", "Aamir", ""], ["Yang", "Shulin", ""], ["Turnbull", "Bradley", ""], ["Liao", "Junshuo", ""]]}, {"id": "2002.05516", "submitter": "Filip Hanzely", "authors": "Filip Hanzely and Peter Richt\\'arik", "title": "Federated Learning of a Mixture of Global and Local Models", "comments": "40 pages, 8 algorithms, 6 figures, 1 table (minor changes compared to\n  the previous versions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new optimization formulation for training federated learning\nmodels. The standard formulation has the form of an empirical risk minimization\nproblem constructed to find a single global model trained from the private data\nstored across all participating devices. In contrast, our formulation seeks an\nexplicit trade-off between this traditional global model and the local models,\nwhich can be learned by each device from its own private data without any\ncommunication. Further, we develop several efficient variants of SGD (with and\nwithout partial participation and with and without variance reduction) for\nsolving the new formulation and prove communication complexity guarantees.\nNotably, our methods are similar but not identical to federated averaging /\nlocal SGD, thus shedding some light on the role of local steps in federated\nlearning. In particular, we are the first to i) show that local steps can\nimprove communication for problems with heterogeneous data, and ii) point out\nthat personalization yields reduced communication complexity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 09:17:08 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:05:50 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 06:30:47 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.05517", "submitter": "Keith Dillon", "authors": "Keith Dillon", "title": "Feature-level Malware Obfuscation in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting malware with deep learning models, where\nthe malware may be combined with significant amounts of benign code. Examples\nof this include piggybacking and trojan horse attacks on a system, where\nmalicious behavior is hidden within a useful application. Such added\nflexibility in augmenting the malware enables significantly more code\nobfuscation. Hence we focus on the use of static features, particularly\nIntents, Permissions, and API calls, which we presume cannot be ultimately\nhidden from the Android system, but only augmented with yet more such features.\nWe first train a deep neural network classifier for malware classification\nusing features of benign and malware samples. Then we demonstrate a steep\nincrease in false negative rate (i.e., attacks succeed), simply by randomly\nadding features of a benign app to malware. Finally we test the use of data\naugmentation to harden the classifier against such attacks. We find that for\nAPI calls, it is possible to reject the vast majority of attacks, where using\nIntents or Permissions is less successful.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:47:23 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Dillon", "Keith", ""]]}, {"id": "2002.05518", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, David Abel, Michael L. Littman", "title": "Learning State Abstractions for Transfer in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can simple algorithms with a good representation solve challenging\nreinforcement learning problems? In this work, we answer this question in the\naffirmative, where we take \"simple learning algorithm\" to be tabular\nQ-Learning, the \"good representations\" to be a learned state abstraction, and\n\"challenging problems\" to be continuous control tasks. Our main contribution is\na learning algorithm that abstracts a continuous state-space into a discrete\none. We transfer this learned representation to unseen problems to enable\neffective learning. We provide theory showing that learned abstractions\nmaintain a bounded value loss, and we report experiments showing that the\nabstractions empower tabular Q-Learning to learn efficiently in unseen tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 20:42:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Asadi", "Kavosh", ""], ["Abel", "David", ""], ["Littman", "Michael L.", ""]]}, {"id": "2002.05519", "submitter": "Yixuan Qiu", "authors": "Yixuan Qiu and Xiao Wang", "title": "Stochastic Approximate Gradient Descent via the Langevin Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel and efficient algorithm called the stochastic\napproximate gradient descent (SAGD), as an alternative to the stochastic\ngradient descent for cases where unbiased stochastic gradients cannot be\ntrivially obtained. Traditional methods for such problems rely on\ngeneral-purpose sampling techniques such as Markov chain Monte Carlo, which\ntypically requires manual intervention for tuning parameters and does not work\nefficiently in practice. Instead, SAGD makes use of the Langevin algorithm to\nconstruct stochastic gradients that are biased in finite steps but accurate\nasymptotically, enabling us to theoretically establish the convergence\nguarantee for SAGD. Inspired by our theoretical analysis, we also provide\nuseful guidelines for its practical implementation. Finally, we show that SAGD\nperforms well experimentally in popular statistical and machine learning\nproblems such as the expectation-maximization algorithm and the variational\nautoencoders.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:29:21 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Qiu", "Yixuan", ""], ["Wang", "Xiao", ""]]}, {"id": "2002.05520", "submitter": "Mu Yuan", "authors": "Mu Yuan, Lan Zhang, Xiang-Yang Li, Hui Xiong", "title": "Comprehensive and Efficient Data Labeling via Adaptive Model Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling data (e.g., labeling the people, objects, actions and scene in\nimages) comprehensively and efficiently is a widely needed but challenging\ntask. Numerous models were proposed to label various data and many approaches\nwere designed to enhance the ability of deep learning models or accelerate\nthem. Unfortunately, a single machine-learning model is not powerful enough to\nextract various semantic information from data. Given certain applications,\nsuch as image retrieval platforms and photo album management apps, it is often\nrequired to execute a collection of models to obtain sufficient labels. With\nlimited computing resources and stringent delay, given a data stream and a\ncollection of applicable resource-hungry deep-learning models, we design a\nnovel approach to adaptively schedule a subset of these models to execute on\neach data item, aiming to maximize the value of the model output (e.g., the\nnumber of high-confidence labels). Achieving this lofty goal is nontrivial\nsince a model's output on any data item is content-dependent and unknown until\nwe execute it. To tackle this, we propose an Adaptive Model Scheduling\nframework, consisting of 1) a deep reinforcement learning-based approach to\npredict the value of unexecuted models by mining semantic relationship among\ndiverse models, and 2) two heuristic algorithms to adaptively schedule the\nmodel execution order under a deadline or deadline-memory constraints\nrespectively. The proposed framework doesn't require any prior knowledge of the\ndata, which works as a powerful complement to existing model optimization\ntechnologies. We conduct extensive evaluations on five diverse image datasets\nand 30 popular image labeling models to demonstrate the effectiveness of our\ndesign: our design could save around 53\\% execution time without loss of any\nvaluable labels.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:54:39 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Yuan", "Mu", ""], ["Zhang", "Lan", ""], ["Li", "Xiang-Yang", ""], ["Xiong", "Hui", ""]]}, {"id": "2002.05522", "submitter": "Jayden Ooi", "authors": "Sungryull Sohn and Yinlam Chow and Jayden Ooi and Ofir Nachum and\n  Honglak Lee and Ed Chi and Craig Boutilier", "title": "BRPO: Batch Residual Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In batch reinforcement learning (RL), one often constrains a learned policy\nto be close to the behavior (data-generating) policy, e.g., by constraining the\nlearned action distribution to differ from the behavior policy by some maximum\ndegree that is the same at each state. This can cause batch RL to be overly\nconservative, unable to exploit large policy changes at frequently-visited,\nhigh-confidence states without risking poor performance at sparsely-visited\nstates. To remedy this, we propose residual policies, where the allowable\ndeviation of the learned policy is state-action-dependent. We derive a new for\nRL method, BRPO, which learns both the policy and allowable deviation that\njointly maximize a lower bound on policy performance. We show that BRPO\nachieves the state-of-the-art performance in a number of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:59:33 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 00:45:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Sohn", "Sungryull", ""], ["Chow", "Yinlam", ""], ["Ooi", "Jayden", ""], ["Nachum", "Ofir", ""], ["Lee", "Honglak", ""], ["Chi", "Ed", ""], ["Boutilier", "Craig", ""]]}, {"id": "2002.05536", "submitter": "Yan Li", "authors": "Yang Li, Yan Li, Hua Tian", "title": "Deep Learning-based End-to-end Diagnosis System for Avascular Necrosis\n  of Femoral Head", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": "10.1109/JBHI.2020.3037079", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the first diagnostic imaging modality of avascular necrosis of the femoral\nhead (AVNFH), accurately staging AVNFH from a plain radiograph is critical yet\nchallenging for orthopedists. Thus, we propose a deep learning-based AVNFH\ndiagnosis system (AVN-net). The proposed AVN-net reads plain radiographs of the\npelvis, conducts diagnosis, and visualizes results automatically. Deep\nconvolutional neural networks are trained to provide an end-to-end diagnosis\nsolution, covering tasks of femoral head detection, exam-view identification,\nside classification, AVNFH diagnosis, and key clinical notes generation.\nAVN-net is able to obtain state-of-the-art testing AUC of 0.97 (95% CI:\n0.97-0.98) in AVNFH detection and significantly greater F1 scores than\nless-to-moderately experienced orthopedists in all diagnostic tests (p<0.01).\nFurthermore, two real-world pilot studies were conducted for diagnosis support\nand education assistance, respectively, to assess the utility of AVN-net. The\nexperimental results are promising. With the AVN-net diagnosis as a reference,\nthe diagnostic accuracy and consistency of all orthopedists considerably\nimproved while requiring only 1/4 of the time. Students self-studying the AVNFH\ndiagnosis using AVN-net can learn better and faster than the control group. To\nthe best of our knowledge, this study is the first research on the prospective\nuse of a deep learning-based diagnosis system for AVNFH by conducting two pilot\nstudies representing real-world application scenarios. We have demonstrated\nthat the proposed AVN-net achieves expert-level AVNFH diagnosis performance,\nprovides efficient support in clinical decision-making, and effectively passes\nclinical experience to students.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:55:50 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 14:06:56 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Li", "Yang", ""], ["Li", "Yan", ""], ["Tian", "Hua", ""]]}, {"id": "2002.05544", "submitter": "Anderson Tavares", "authors": "Pedro H. C. Avelar, Anderson R. Tavares, Thiago L. T. da Silveira,\n  Cl\\'audio R. Jung, Lu\\'is C. Lamb", "title": "Superpixel Image Classification with Graph Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for image classification using Graph Neural\nNetwork (GNN) models. We transform the input images into region adjacency\ngraphs (RAGs), in which regions are superpixels and edges connect neighboring\nsuperpixels. Our experiments suggest that Graph Attention Networks (GATs),\nwhich combine graph convolutions with self-attention mechanisms, outperforms\nother GNN models. Although raw image classifiers perform better than GATs due\nto information loss during the RAG generation, our methodology opens an\ninteresting avenue of research on deep learning beyond rectangular-gridded\nimages, such as 360-degree field of view panoramas. Traditional convolutional\nkernels of current state-of-the-art methods cannot handle panoramas, whereas\nthe adapted superpixel algorithms and the resulting region adjacency graphs can\nnaturally feed a GNN, without topology issues.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:52:32 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 17:04:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Tavares", "Anderson R.", ""], ["da Silveira", "Thiago L. T.", ""], ["Jung", "Cl\u00e1udio R.", ""], ["Lamb", "Lu\u00eds C.", ""]]}, {"id": "2002.05551", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss and Vincent Fortuin and Martin Josifoski and Andreas\n  Krause", "title": "PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning can successfully acquire useful inductive biases from data.\nYet, its generalization properties to unseen learning tasks are poorly\nunderstood. Particularly if the number of meta-training tasks is small, this\nraises concerns about overfitting. We provide a theoretical analysis using the\nPAC-Bayesian framework and derive novel generalization bounds for\nmeta-learning. Using these bounds, we develop a class of PAC-optimal\nmeta-learning algorithms with performance guarantees and a principled\nmeta-level regularization. Unlike previous PAC-Bayesian meta-learners, our\nmethod results in a standard stochastic optimization problem which can be\nsolved efficiently and scales well. When instantiating our PAC-optimal\nhyper-posterior (PACOH) with Gaussian processes and Bayesian Neural Networks as\nbase learners, the resulting methods yield state-of-the-art performance, both\nin terms of predictive accuracy and the quality of uncertainty estimates.\nThanks to their principled treatment of uncertainty, our meta-learners can also\nbe successfully employed for sequential decision problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:01:38 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 08:50:08 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 08:39:52 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 17:27:31 GMT"}, {"version": "v5", "created": "Fri, 18 Jun 2021 07:08:24 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Fortuin", "Vincent", ""], ["Josifoski", "Martin", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.05576", "submitter": "Andrej Risteski", "authors": "Ankur Moitra, Andrej Risteski", "title": "Fast Convergence for Langevin Diffusion with Manifold Structure", "comments": "52 pages, in submission to NeurIPS 2020. This version: various typos\n  fixed, minor reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of sampling from distributions of the\nform p(x) \\propto e^{-\\beta f(x)} for some function f whose values and\ngradients we can query. This mode of access to f is natural in the scenarios in\nwhich such problems arise, for instance sampling from posteriors in parametric\nBayesian models. Classical results show that a natural random walk, Langevin\ndiffusion, mixes rapidly when f is convex. Unfortunately, even in simple\nexamples, the applications listed above will entail working with functions f\nthat are nonconvex -- for which sampling from p may in general require an\nexponential number of queries.\n  In this paper, we focus on an aspect of nonconvexity relevant for modern\nmachine learning applications: existence of invariances (symmetries) in the\nfunction f, as a result of which the distribution p will have manifolds of\npoints with equal probability. First, we give a recipe for proving mixing time\nbounds for Langevin diffusion as a function of the geometry of these manifolds.\nSecond, we specialize our arguments to classic matrix factorization-like\nBayesian inference problems where we get noisy measurements A(XX^T), X \\in R^{d\n\\times k} of a low-rank matrix, i.e. f(X) = \\|A(XX^T) - b\\|^2_2, X \\in R^{d\n\\times k}, and \\beta the inverse of the variance of the noise. Such functions f\nare invariant under orthogonal transformations, and include problems like\nmatrix factorization, sensing, completion. Beyond sampling, Langevin dynamics\nis a popular toy model for studying stochastic gradient descent. Along these\nlines, we believe that our work is an important first step towards\nunderstanding how SGD behaves when there is a high degree of symmetry in the\nspace of parameters the produce the same output.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:49:04 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:48:52 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moitra", "Ankur", ""], ["Risteski", "Andrej", ""]]}, {"id": "2002.05578", "submitter": "Jung Yeon Park", "authors": "Jung Yeon Park, Kenneth Theo Carr, Stephan Zheng, Yisong Yue, and Rose\n  Yu", "title": "Multiresolution Tensor Learning for Efficient and Interpretable Spatial\n  Analysis", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and interpretable spatial analysis is crucial in many fields such\nas geology, sports, and climate science. Tensor latent factor models can\ndescribe higher-order correlations for spatial data. However, they are\ncomputationally expensive to train and are sensitive to initialization, leading\nto spatially incoherent, uninterpretable results. We develop a novel\nMultiresolution Tensor Learning (MRTL) algorithm for efficiently learning\ninterpretable spatial patterns. MRTL initializes the latent factors from an\napproximate full-rank tensor model for improved interpretability and\nprogressively learns from a coarse resolution to the fine resolution to reduce\ncomputation. We also prove the theoretical convergence and computational\ncomplexity of MRTL. When applied to two real-world datasets, MRTL demonstrates\n4~5x speedup compared to a fixed resolution approach while yielding accurate\nand interpretable latent factors.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:50:48 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 16:40:26 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 15:19:08 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 13:54:04 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 23:34:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Park", "Jung Yeon", ""], ["Carr", "Kenneth Theo", ""], ["Zheng", "Stephan", ""], ["Yue", "Yisong", ""], ["Yu", "Rose", ""]]}, {"id": "2002.05582", "submitter": "Shi Hu", "authors": "Shi Hu and Nicola Pezzotti and Max Welling", "title": "Learning to Predict Error for MRI Reconstruction", "comments": "Accepted to MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare applications, predictive uncertainty has been used to assess\npredictive accuracy. In this paper, we demonstrate that predictive uncertainty\nestimated by the current methods does not highly correlate with prediction\nerror by decomposing the latter into random and systematic errors, and showing\nthat the former is equivalent to the variance of the random error. In addition,\nwe observe that current methods unnecessarily compromise performance by\nmodifying the model and training loss to estimate the target and uncertainty\njointly. We show that estimating them separately without modifications improves\nperformance. Following this, we propose a novel method that estimates the\ntarget labels and magnitude of the prediction error in two steps. We\ndemonstrate this method on a large-scale MRI reconstruction task, and achieve\nsignificantly better results than the state-of-the-art uncertainty estimation\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:55:32 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 13:38:21 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 00:14:13 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Hu", "Shi", ""], ["Pezzotti", "Nicola", ""], ["Welling", "Max", ""]]}, {"id": "2002.05616", "submitter": "Will Grathwohl", "authors": "Will Grathwohl, Kuan-Chieh Wang, Jorn-Henrik Jacobsen, David Duvenaud,\n  Richard Zemel", "title": "Learning the Stein Discrepancy for Training and Evaluating Energy-Based\n  Models without Sampling", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for evaluating and training unnormalized density\nmodels. Our approach only requires access to the gradient of the unnormalized\nmodel's log-density. We estimate the Stein discrepancy between the data density\n$p(x)$ and the model density $q(x)$ defined by a vector function of the data.\nWe parameterize this function with a neural network and fit its parameters to\nmaximize the discrepancy. This yields a novel goodness-of-fit test which\noutperforms existing methods on high dimensional data. Furthermore, optimizing\n$q(x)$ to minimize this discrepancy produces a novel method for training\nunnormalized models which scales more gracefully than existing methods. The\nability to both learn and compare models is a unique feature of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:39:07 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:03:42 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 14:38:26 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:32:47 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Grathwohl", "Will", ""], ["Wang", "Kuan-Chieh", ""], ["Jacobsen", "Jorn-Henrik", ""], ["Duvenaud", "David", ""], ["Zemel", "Richard", ""]]}, {"id": "2002.05628", "submitter": "Anthony Stein", "authors": "Anthony Stein, Roland Maier, Lukas Rosenbauer, J\\\"org H\\\"ahner", "title": "XCS Classifier System with Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XCS constitutes the most deeply investigated classifier system today. It\nbears strong potentials and comes with inherent capabilities for mastering a\nvariety of different learning tasks. Besides outstanding successes in various\nclassification and regression tasks, XCS also proved very effective in certain\nmulti-step environments from the domain of reinforcement learning. Especially\nin the latter domain, recent advances have been mainly driven by algorithms\nwhich model their policies based on deep neural networks -- among which the\nDeep-Q-Network (DQN) is a prominent representative. Experience Replay (ER)\nconstitutes one of the crucial factors for the DQN's successes, since it\nfacilitates stabilized training of the neural network-based Q-function\napproximators. Surprisingly, XCS barely takes advantage of similar mechanisms\nthat leverage stored raw experiences encountered so far. To bridge this gap,\nthis paper investigates the benefits of extending XCS with ER. On the one hand,\nwe demonstrate that for single-step tasks ER bears massive potential for\nimprovements in terms of sample efficiency. On the shady side, however, we\nreveal that the use of ER might further aggravate well-studied issues not yet\nsolved for XCS when applied to sequential decision problems demanding for\nlong-action-chains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:55:08 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Stein", "Anthony", ""], ["Maier", "Roland", ""], ["Rosenbauer", "Lukas", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.05630", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "On the Sensory Commutativity of Action Sequences for Embodied Agents", "comments": "Accepted to RSS'20 Workshop on Self-Supervised Robot Learning & to\n  the Workshop on Learning in Artificial Open Worlds at ICML20 & Extended\n  abstract at AAMAS21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception of artificial agents is one the grand challenges of AI research.\nDeep Learning and data-driven approaches are successful on constrained problems\nwhere perception can be learned using supervision, but do not scale to\nopen-worlds. In such case, for autonomous embodied agents with first-person\nsensors, perception can be learned end-to-end to solve particular tasks.\nHowever, literature shows that perception is not a purely passive compression\nmechanism, and that actions play an important role in the formulation of\nabstract representations. We propose to study perception for these embodied\nagents, under the mathematical formalism of group theory in order to make the\nlink between perception and action. In particular, we consider the commutative\nproperties of continuous action sequences with respect to sensory information\nperceived by such an embodied agent. We introduce the Sensory Commutativity\nProbability (SCP) criterion which measures how much an agent's degree of\nfreedom affects the environment in embodied scenarios. We show how to compute\nthis criterion in different environments, including realistic robotic setups.\nWe empirically illustrate how SCP and the commutative properties of action\nsequences can be used to learn about objects in the environment and improve\nsample-efficiency in Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:58:23 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 14:32:44 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 10:15:08 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "2002.05632", "submitter": "Vasilis Kontonis", "authors": "Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, and Nikos\n  Zarifis", "title": "Learning Halfspaces with Massart Noise Under Structured Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning halfspaces with Massart noise in the\ndistribution-specific PAC model. We give the first computationally efficient\nalgorithm for this problem with respect to a broad family of distributions,\nincluding log-concave distributions. This resolves an open question posed in a\nnumber of prior works. Our approach is extremely simple: We identify a smooth\n{\\em non-convex} surrogate loss with the property that any approximate\nstationary point of this loss defines a halfspace that is close to the target\nhalfspace. Given this structural result, we can use SGD to solve the underlying\nlearning problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:02:37 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kontonis", "Vasilis", ""], ["Tzamos", "Christos", ""], ["Zarifis", "Nikos", ""]]}, {"id": "2002.05635", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Ilya Tyagin, Michael Shtutman, Ilya Safro", "title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis\n  generation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical research is risky and expensive. Drug discovery, as an example,\nrequires that researchers efficiently winnow thousands of potential targets to\na small candidate set for more thorough evaluation. However, research groups\nspend significant time and money to perform the experiments necessary to\ndetermine this candidate set long before seeing intermediate results.\nHypothesis generation systems address this challenge by mining the wealth of\npublicly available scientific information to predict plausible research\ndirections. We present AGATHA, a deep-learning hypothesis generation system\nthat can introduce data-driven insights earlier in the discovery process.\nThrough a learned ranking criteria, this system quickly prioritizes plausible\nterm-pairs among entity sets, allowing us to recommend new research directions.\nWe massively validate our system with a temporal holdout wherein we predict\nconnections first introduced after 2015 using data published beforehand. We\nadditionally explore biomedical sub-domains, and demonstrate AGATHA's\npredictive capacity across the twenty most popular relationship types. This\nsystem achieves best-in-class performance on an established benchmark, and\ndemonstrates high recommendation scores across subdomains. Reproducibility: All\ncode, experimental data, and pre-trained models are available online:\nsybrandt.com/2020/agatha\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:06:47 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sybrandt", "Justin", ""], ["Tyagin", "Ilya", ""], ["Shtutman", "Michael", ""], ["Safro", "Ilya", ""]]}, {"id": "2002.05637", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Ilya Safro", "title": "CBAG: Conditional Biomedical Abstract Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical research papers use significantly different language and jargon\nwhen compared to typical English text, which reduces the utility of pre-trained\nNLP models in this domain. Meanwhile Medline, a database of biomedical\nabstracts, introduces nearly a million new documents per-year. Applications\nthat could benefit from understanding this wealth of publicly available\ninformation, such as scientific writing assistants, chat-bots, or descriptive\nhypothesis generation systems, require new domain-centered approaches. A\nconditional language model, one that learns the probability of words given some\na priori criteria, is a fundamental building block in many such applications.\nWe propose a transformer-based conditional language model with a shallow\nencoder \"condition\" stack, and a deep \"language model\" stack of multi-headed\nattention blocks. The condition stack encodes metadata used to alter the output\nprobability distribution of the language model stack. We sample this\ndistribution in order to generate biomedical abstracts given only a proposed\ntitle, an intended publication year, and a set of keywords. Using typical\nnatural language generation metrics, we demonstrate that this proposed approach\nis more capable of producing non-trivial relevant entities within the abstract\nbody than the 1.5B parameter GPT-2 language model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:11:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sybrandt", "Justin", ""], ["Safro", "Ilya", ""]]}, {"id": "2002.05645", "submitter": "Maral Mesmakhosroshahi", "authors": "Bharadwaj Pudipeddi, Maral Mesmakhosroshahi, Jinwen Xi, and Sujeeth\n  Bharadwaj", "title": "Training Large Neural Networks with Constant Memory using a New\n  Execution Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely popular transformer-based NLP models such as BERT and Turing-NLG have\nenormous capacity trending to billions of parameters. Current execution methods\ndemand brute-force resources such as HBM devices and high speed\ninterconnectivity for data parallelism. In this paper, we introduce a new\nrelay-style execution technique called L2L (layer-to-layer) where at any given\nmoment, the device memory is primarily populated only with the executing\nlayer(s)'s footprint. The model resides in the DRAM memory attached to either a\nCPU or an FPGA as an entity we call eager param-server (EPS). To overcome the\nbandwidth issues of shuttling parameters to and from EPS, the model is executed\na layer at a time across many micro-batches instead of the conventional method\nof minibatches over whole model. L2L is implemented using 16GB V100 devices for\nBERT-Large running it with a device batch size of up to 256. Our results show\n45% reduction in memory and 40% increase in the throughput compared to the\nstate-of-the-art baseline. L2L is also able to fit models up to 50 Billion\nparameters on a machine with a single 16GB V100 and 512GB CPU memory and\nwithout requiring any model partitioning. L2L scales to arbitrary depth\nallowing researchers to develop on affordable devices which is a big step\ntoward democratizing AI. By running the optimizer in the host EPS, we show a\nnew form of mixed precision for faster throughput and convergence. In addition,\nthe EPS enables dynamic neural architecture approaches by varying layers across\niterations. Finally, we also propose and demonstrate a constant memory\nvariation of L2L and we propose future enhancements. This work has been\nperformed on GPUs first, but also targeted towards all high TFLOPS/Watt\naccelerators.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:29:47 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:21:52 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 22:51:58 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 23:54:24 GMT"}, {"version": "v5", "created": "Fri, 5 Jun 2020 03:00:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Pudipeddi", "Bharadwaj", ""], ["Mesmakhosroshahi", "Maral", ""], ["Xi", "Jinwen", ""], ["Bharadwaj", "Sujeeth", ""]]}, {"id": "2002.05646", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Magnus Nystr\\\"om, John Lambert, Andrew\n  Marshall, Mario Goertzel, Andi Comissoneru, Matt Swann, Sharon Xia", "title": "Adversarial Machine Learning -- Industry Perspectives", "comments": "Minor Typos corrected 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on interviews with 28 organizations, we found that industry\npractitioners are not equipped with tactical and strategic tools to protect,\ndetect and respond to attacks on their Machine Learning (ML) systems. We\nleverage the insights from the interviews and we enumerate the gaps in\nperspective in securing machine learning systems when viewed in the context of\ntraditional software security development. We write this paper from the\nperspective of two personas: developers/ML engineers and security incident\nresponders who are tasked with securing ML systems as they are designed,\ndeveloped and deployed ML systems. The goal of this paper is to engage\nresearchers to revise and amend the Security Development Lifecycle for\nindustrial-grade software in the adversarial ML era.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:28:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 17:33:37 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 16:02:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Nystr\u00f6m", "Magnus", ""], ["Lambert", "John", ""], ["Marshall", "Andrew", ""], ["Goertzel", "Mario", ""], ["Comissoneru", "Andi", ""], ["Swann", "Matt", ""], ["Xia", "Sharon", ""]]}, {"id": "2002.05648", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Jonathon Penney, Bruce Schneier, Ram Shankar Siva Kumar", "title": "Politics of Adversarial Machine Learning", "comments": "Authors ordered alphabetically; 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to their security properties, adversarial machine-learning\nattacks and defenses have political dimensions. They enable or foreclose\ncertain options for both the subjects of the machine learning systems and for\nthose who deploy them, creating risks for civil liberties and human rights. In\nthis paper, we draw on insights from science and technology studies,\nanthropology, and human rights literature, to inform how defenses against\nadversarial attacks can be used to suppress dissent and limit attempts to\ninvestigate machine learning systems. To make this concrete, we use real-world\nexamples of how attacks such as perturbation, model inversion, or membership\ninference can be used for socially desirable ends. Although the predictions of\nthis analysis may seem dire, there is hope. Efforts to address human rights\nconcerns in the commercial spyware industry provide guidance for similar\nmeasures to ensure ML systems serve democratic, not authoritarian ends\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:15:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:34:56 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 04:59:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Albert", "Kendra", ""], ["Penney", "Jonathon", ""], ["Schneier", "Bruce", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2002.05655", "submitter": "Subhro Das", "authors": "Subhro Das, Sebastian Steffen, Wyatt Clarke, Prabhat Reddy, Erik\n  Brynjolfsson, Martin Fleming", "title": "Learning Occupational Task-Shares Dynamics for the Future of Work", "comments": "9 pages, 5 figures, 6 tables, Proceedings of the AAAI/ACM Conference\n  on AI, Ethics, and Society (AIES), 2020", "journal-ref": null, "doi": "10.1145/3375627.3375826", "report-no": null, "categories": "cs.CY cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent wave of AI and automation has been argued to differ from previous\nGeneral Purpose Technologies (GPTs), in that it may lead to rapid change in\noccupations' underlying task requirements and persistent technological\nunemployment. In this paper, we apply a novel methodology of dynamic task\nshares to a large dataset of online job postings to explore how exactly\noccupational task demands have changed over the past decade of AI innovation,\nespecially across high, mid and low wage occupations. Notably, big data and AI\nhave risen significantly among high wage occupations since 2012 and 2016,\nrespectively. We built an ARIMA model to predict future occupational task\ndemands and showcase several relevant examples in Healthcare, Administration,\nand IT. Such task demands predictions across occupations will play a pivotal\nrole in retraining the workforce of the future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 21:20:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Das", "Subhro", ""], ["Steffen", "Sebastian", ""], ["Clarke", "Wyatt", ""], ["Reddy", "Prabhat", ""], ["Brynjolfsson", "Erik", ""], ["Fleming", "Martin", ""]]}, {"id": "2002.05660", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Adam Kalai, Katrina Ligett, and Zhiwei Steven Wu", "title": "Learn to Expect the Unexpected: Probably Approximately Correct Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization is the problem of machine learning when the training\ndata and the test data come from different data domains. We present a simple\ntheoretical model of learning to generalize across domains in which there is a\nmeta-distribution over data distributions, and those data distributions may\neven have different supports. In our model, the training data given to a\nlearning algorithm consists of multiple datasets each from a single domain\ndrawn in turn from the meta-distribution. We study this model in three\ndifferent problem settings---a multi-domain Massart noise setting, a decision\ntree multi-dataset setting, and a feature selection setting, and find that\ncomputationally efficient, polynomial-sample domain generalization is possible\nin each. Experiments demonstrate that our feature selection algorithm indeed\nignores spurious correlations and improves generalization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:37:53 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Garg", "Vikas K.", ""], ["Kalai", "Adam", ""], ["Ligett", "Katrina", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.05674", "submitter": "Micha{\\l} Ku\\'zba", "authors": "Micha{\\l} Ku\\'zba, Przemys{\\l}aw Biecek", "title": "What Would You Ask the Machine Learning Model? Identification of User\n  Needs for Model Explanations Based on Human-Model Conversations", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we see a rising number of methods in the field of eXplainable\nArtificial Intelligence. To our surprise, their development is driven by model\ndevelopers rather than a study of needs for human end users. The analysis of\nneeds, if done, takes the form of an A/B test rather than a study of open\nquestions. To answer the question \"What would a human operator like to ask the\nML model?\" we propose a conversational system explaining decisions of the\npredictive model. In this experiment, we developed a chatbot called dr_ant to\ntalk about machine learning model trained to predict survival odds on Titanic.\nPeople can talk with dr_ant about different aspects of the model to understand\nthe rationale behind its predictions. Having collected a corpus of 1000+\ndialogues, we analyse the most common types of questions that users would like\nto ask. To our knowledge, it is the first study which uses a conversational\nsystem to collect the needs of human operators from the interactive and\niterative dialogue explorations of a predictive model.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:59:49 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:14:08 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 13:49:43 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ku\u017aba", "Micha\u0142", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2002.05678", "submitter": "Abram Magner", "authors": "Abram Magner and Mayank Baranwal and Alfred O. Hero III", "title": "The Power of Graph Convolutional Networks to Distinguish Random Graph\n  Models: Short Version", "comments": "Conference version of arXiv:1910.12954", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are a widely used method for graph\nrepresentation learning. We investigate the power of GCNs, as a function of\ntheir number of layers, to distinguish between different random graph models on\nthe basis of the embeddings of their sample graphs. In particular, the graph\nmodels that we consider arise from graphons, which are the most general\npossible parameterizations of infinite exchangeable graph models and which are\nthe central objects of study in the theory of dense graph limits. We exhibit an\ninfinite class of graphons that are well-separated in terms of cut distance and\nare indistinguishable by a GCN with nonlinear activation functions coming from\na certain broad class if its depth is at least logarithmic in the size of the\nsample graph. These results theoretically match empirical observations of\nseveral prior works. Finally, we show a converse result that for pairs of\ngraphons satisfying a degree profile separation property, a very simple GCN\narchitecture suffices for distinguishability. To prove our results, we exploit\na connection to random walks on graphs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:58:42 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Magner", "Abram", ""], ["Baranwal", "Mayank", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "2002.05683", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Asuman Ozdaglar, Sarath Pattathil", "title": "An Optimal Multistage Stochastic Gradient Method for Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the minimax optimization problem in the smooth and\nstrongly convex-strongly concave setting when we have access to noisy estimates\nof gradients. In particular, we first analyze the stochastic Gradient Descent\nAscent (GDA) method with constant stepsize, and show that it converges to a\nneighborhood of the solution of the minimax problem. We further provide tight\nbounds on the convergence rate and the size of this neighborhood. Next, we\npropose a multistage variant of stochastic GDA (M-GDA) that runs in multiple\nstages with a particular learning rate decay schedule and converges to the\nexact solution of the minimax problem. We show M-GDA achieves the lower bounds\nin terms of noise dependence without any assumptions on the knowledge of noise\ncharacteristics. We also show that M-GDA obtains a linear decay rate with\nrespect to the error's dependence on the initial error, although the dependence\non condition number is suboptimal. In order to improve this dependence, we\napply the multistage machinery to the stochastic Optimistic Gradient Descent\nAscent (OGDA) algorithm and propose the M-OGDA algorithm which also achieves\nthe optimal linear decay rate with respect to the initial error. To the best of\nour knowledge, this method is the first to simultaneously achieve the best\ndependence on noise characteristic as well as the initial error and condition\nnumber.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:01:18 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Fallah", "Alireza", ""], ["Ozdaglar", "Asuman", ""], ["Pattathil", "Sarath", ""]]}, {"id": "2002.05685", "submitter": "Umut \\c{S}im\\c{s}ekli", "authors": "Umut \\c{S}im\\c{s}ekli, Lingjiong Zhu, Yee Whye Teh, Mert\n  G\\\"urb\\\"uzbalaban", "title": "Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum\n  under Heavy-Tailed Gradient Noise", "comments": "20 pages, Published at International Conference on Machine Learning\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent with momentum (SGDm) is one of the most popular\noptimization algorithms in deep learning. While there is a rich theory of SGDm\nfor convex problems, the theory is considerably less developed in the context\nof deep learning where the problem is non-convex and the gradient noise might\nexhibit a heavy-tailed behavior, as empirically observed in recent studies. In\nthis study, we consider a \\emph{continuous-time} variant of SGDm, known as the\nunderdamped Langevin dynamics (ULD), and investigate its asymptotic properties\nunder heavy-tailed perturbations. Supported by recent studies from statistical\nphysics, we argue both theoretically and empirically that the heavy-tails of\nsuch perturbations can result in a bias even when the step-size is small, in\nthe sense that \\emph{the optima of stationary distribution} of the dynamics\nmight not match \\emph{the optima of the cost function to be optimized}. As a\nremedy, we develop a novel framework, which we coin as \\emph{fractional} ULD\n(FULD), and prove that FULD targets the so-called Gibbs distribution, whose\noptima exactly match the optima of the original cost. We observe that the Euler\ndiscretization of FULD has noteworthy algorithmic similarities with\n\\emph{natural gradient} methods and \\emph{gradient clipping}, bringing a new\nperspective on understanding their role in deep learning. We support our theory\nwith experiments conducted on a synthetic model and neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:04:27 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:17:37 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["\u015eim\u015fekli", "Umut", ""], ["Zhu", "Lingjiong", ""], ["Teh", "Yee Whye", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""]]}, {"id": "2002.05687", "submitter": "Emma Pierce-Hoffman", "authors": "Isaac Robinson, Emma Pierce-Hoffman", "title": "Tree-SNE: Hierarchical Clustering and Visualization Using t-SNE", "comments": "19 pages, 19 figures (from 36 image files)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-SNE and hierarchical clustering are popular methods of exploratory data\nanalysis, particularly in biology. Building on recent advances in speeding up\nt-SNE and obtaining finer-grained structure, we combine the two to create\ntree-SNE, a hierarchical clustering and visualization algorithm based on\nstacked one-dimensional t-SNE embeddings. We also introduce alpha-clustering,\nwhich recommends the optimal cluster assignment, without foreknowledge of the\nnumber of clusters, based off of the cluster stability across multiple scales.\nWe demonstrate the effectiveness of tree-SNE and alpha-clustering on images of\nhandwritten digits, mass cytometry (CyTOF) data from blood cells, and\nsingle-cell RNA-sequencing (scRNA-seq) data from retinal cells. Furthermore, to\ndemonstrate the validity of the visualization, we use alpha-clustering to\nobtain unsupervised clustering results competitive with the state of the art on\nseveral image data sets. Software is available at\nhttps://github.com/isaacrob/treesne.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:11:00 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Robinson", "Isaac", ""], ["Pierce-Hoffman", "Emma", ""]]}, {"id": "2002.05702", "submitter": "Pietro Nardelli", "authors": "Pietro Nardelli, James C. Ross, Ra\\'ul San Jos\\'e Est\\'epar", "title": "Generative-based Airway and Vessel Morphology Quantification on Chest CT\n  Images", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.media.2020.101691", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately and precisely characterizing the morphology of small pulmonary\nstructures from Computed Tomography (CT) images, such as airways and vessels,\nis becoming of great importance for diagnosis of pulmonary diseases. The\nsmaller conducting airways are the major site of increased airflow resistance\nin chronic obstructive pulmonary disease (COPD), while accurately sizing\nvessels can help identify arterial and venous changes in lung regions that may\ndetermine future disorders. However, traditional methods are often limited due\nto image resolution and artifacts.\n  We propose a Convolutional Neural Regressor (CNR) that provides\ncross-sectional measurement of airway lumen, airway wall thickness, and vessel\nradius. CNR is trained with data created by a generative model of synthetic\nstructures which is used in combination with Simulated and Unsupervised\nGenerative Adversarial Network (SimGAN) to create simulated and refined airways\nand vessels with known ground-truth.\n  For validation, we first use synthetically generated airways and vessels\nproduced by the proposed generative model to compute the relative error and\ndirectly evaluate the accuracy of CNR in comparison with traditional methods.\nThen, in-vivo validation is performed by analyzing the association between the\npercentage of the predicted forced expiratory volume in one second (FEV1\\%) and\nthe value of the Pi10 parameter, two well-known measures of lung function and\nairway disease, for airways. For vessels, we assess the correlation between our\nestimate of the small-vessel blood volume and the lungs' diffusing capacity for\ncarbon monoxide (DLCO).\n  The results demonstrate that Convolutional Neural Networks (CNNs) provide a\npromising direction for accurately measuring vessels and airways on chest CT\nimages with physiological correlates.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:45:31 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 16:32:10 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Nardelli", "Pietro", ""], ["Ross", "James C.", ""], ["Est\u00e9par", "Ra\u00fal San Jos\u00e9", ""]]}, {"id": "2002.05706", "submitter": "Junqi Wang", "authors": "Junqi Wang, Pei Wang, Patrick Shafto", "title": "Sequential Cooperative Bayesian Inference", "comments": "25 pages, 22 figures, accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation is often implicitly assumed when learning from other agents.\nCooperation implies that the agent selecting the data, and the agent learning\nfrom the data, have the same goal, that the learner infer the intended\nhypothesis. Recent models in human and machine learning have demonstrated the\npossibility of cooperation. We seek foundational theoretical results for\ncooperative inference by Bayesian agents through sequential data. We develop\nnovel approaches analyzing consistency, rate of convergence and stability of\nSequential Cooperative Bayesian Inference (SCBI). Our analysis of the\neffectiveness, sample efficiency and robustness show that cooperation is not\nonly possible in specific instances but theoretically well-founded in general.\nWe discuss implications for human-human and human-machine cooperation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:48:06 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:21:52 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 13:25:21 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wang", "Junqi", ""], ["Wang", "Pei", ""], ["Shafto", "Patrick", ""]]}, {"id": "2002.05707", "submitter": "Ke Chen", "authors": "William Woof and Ke Chen", "title": "A Framework for End-to-End Learning on Semantic Tree-Structured Data", "comments": "This is a preliminary version of our work. The project is still\n  ongoing. The source code for a JSON-based implementation of our framework\n  along with experiments can be downloaded at\n  https://github.com/EndingCredits/json2vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learning models are typically studied for inputs in the form of a fixed\ndimensional feature vector, real world data is rarely found in this form. In\norder to meet the basic requirement of traditional learning models, structural\ndata generally have to be converted into fix-length vectors in a handcrafted\nmanner, which is tedious and may even incur information loss. A common form of\nstructured data is what we term \"semantic tree-structures\", corresponding to\ndata where rich semantic information is encoded in a compositional manner, such\nas those expressed in JavaScript Object Notation (JSON) and eXtensible Markup\nLanguage (XML). For tree-structured data, several learning models have been\nstudied to allow for working directly on raw tree-structure data, However such\nlearning models are limited to either a specific tree-topology or a specific\ntree-structured data format, e.g., synthetic parse trees. In this paper, we\npropose a novel framework for end-to-end learning on generic semantic\ntree-structured data of arbitrary topology and heterogeneous data types, such\nas data expressed in JSON, XML and so on. Motivated by the works in recursive\nand recurrent neural networks, we develop exemplar neural implementations of\nour framework for the JSON format. We evaluate our approach on several UCI\nbenchmark datasets, including ablation and data-efficiency studies, and on a\ntoy reinforcement learning task. Experimental results suggest that our\nframework yields comparable performance to use of standard models with\ndedicated feature-vectors in general, and even exceeds baseline performance in\ncases where compositional nature of the data is particularly important.\n  The source code for a JSON-based implementation of our framework along with\nexperiments can be downloaded at https://github.com/EndingCredits/json2vec.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:49:29 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Woof", "William", ""], ["Chen", "Ke", ""]]}, {"id": "2002.05708", "submitter": "Fabricio Breve", "authors": "Fabricio Aparecido Breve", "title": "Simple Interactive Image Segmentation using Label Propagation through\n  kNN graphs", "comments": null, "journal-ref": "BREVE, Fabricio A. Simple Interactive Image Segmentation using\n  Label Propagation through kNN graphs In: National Meeting on Artificial and\n  Computational Intelligence (ENIAC'2017), 2017, Uberl\\^andia, Minas Gerais,\n  2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interactive image segmentation techniques are based on semi-supervised\nlearning. The user may label some pixels from each object and the SSL algorithm\nwill propagate the labels from the labeled to the unlabeled pixels, finding\nobject boundaries. This paper proposes a new SSL graph-based interactive image\nsegmentation approach, using undirected and unweighted kNN graphs, from which\nthe unlabeled nodes receive contributions from other nodes (either labeled or\nunlabeled). It is simpler than many other techniques, but it still achieves\nsignificant classification accuracy in the image segmentation task. Computer\nsimulations are performed using some real-world images, extracted from the\nMicrosoft GrabCut dataset. The segmentation results show the effectiveness of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:50:21 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Breve", "Fabricio Aparecido", ""]]}, {"id": "2002.05709", "submitter": "Ting Chen", "authors": "Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton", "title": "A Simple Framework for Contrastive Learning of Visual Representations", "comments": "ICML'2020. Code and pretrained models at\n  https://github.com/google-research/simclr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents SimCLR: a simple framework for contrastive learning of\nvisual representations. We simplify recently proposed contrastive\nself-supervised learning algorithms without requiring specialized architectures\nor a memory bank. In order to understand what enables the contrastive\nprediction tasks to learn useful representations, we systematically study the\nmajor components of our framework. We show that (1) composition of data\naugmentations plays a critical role in defining effective predictive tasks, (2)\nintroducing a learnable nonlinear transformation between the representation and\nthe contrastive loss substantially improves the quality of the learned\nrepresentations, and (3) contrastive learning benefits from larger batch sizes\nand more training steps compared to supervised learning. By combining these\nfindings, we are able to considerably outperform previous methods for\nself-supervised and semi-supervised learning on ImageNet. A linear classifier\ntrained on self-supervised representations learned by SimCLR achieves 76.5%\ntop-1 accuracy, which is a 7% relative improvement over previous\nstate-of-the-art, matching the performance of a supervised ResNet-50. When\nfine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy,\noutperforming AlexNet with 100X fewer labels.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:50:45 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 15:32:51 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 00:09:08 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Chen", "Ting", ""], ["Kornblith", "Simon", ""], ["Norouzi", "Mohammad", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2002.05712", "submitter": "Zhuliang Yao", "authors": "Zhuliang Yao, Yue Cao, Shuxin Zheng, Gao Huang, Stephen Lin", "title": "Cross-Iteration Batch Normalization", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known issue of Batch Normalization is its significantly reduced\neffectiveness in the case of small mini-batch sizes. When a mini-batch contains\nfew examples, the statistics upon which the normalization is defined cannot be\nreliably estimated from it during a training iteration. To address this\nproblem, we present Cross-Iteration Batch Normalization (CBN), in which\nexamples from multiple recent iterations are jointly utilized to enhance\nestimation quality. A challenge of computing statistics over multiple\niterations is that the network activations from different iterations are not\ncomparable to each other due to changes in network weights. We thus compensate\nfor the network weight changes via a proposed technique based on Taylor\npolynomials, so that the statistics can be accurately estimated and batch\nnormalization can be effectively applied. On object detection and image\nclassification with small mini-batch sizes, CBN is found to outperform the\noriginal batch normalization and a direct calculation of statistics over\nprevious iterations without the proposed compensation technique. Code is\navailable at https://github.com/Howal/Cross-iterationBatchNorm .\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:52:57 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:10:04 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 06:57:36 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Yao", "Zhuliang", ""], ["Cao", "Yue", ""], ["Zheng", "Shuxin", ""], ["Huang", "Gao", ""], ["Lin", "Stephen", ""]]}, {"id": "2002.05715", "submitter": "Hossein Mobahi", "authors": "Hossein Mobahi, Mehrdad Farajtabar, Peter L. Bartlett", "title": "Self-Distillation Amplifies Regularization in Hilbert Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation introduced in the deep learning context is a method to\ntransfer knowledge from one architecture to another. In particular, when the\narchitectures are identical, this is called self-distillation. The idea is to\nfeed in predictions of the trained model as new target values for retraining\n(and iterate this loop possibly a few times). It has been empirically observed\nthat the self-distilled model often achieves higher accuracy on held out data.\nWhy this happens, however, has been a mystery: the self-distillation dynamics\ndoes not receive any new information about the task and solely evolves by\nlooping over training. To the best of our knowledge, there is no rigorous\nunderstanding of this phenomenon. This work provides the first theoretical\nanalysis of self-distillation. We focus on fitting a nonlinear function to\ntraining data, where the model space is Hilbert space and fitting is subject to\n$\\ell_2$ regularization in this function space. We show that self-distillation\niterations modify regularization by progressively limiting the number of basis\nfunctions that can be used to represent the solution. This implies (as we also\nverify empirically) that while a few rounds of self-distillation may reduce\nover-fitting, further rounds may lead to under-fitting and thus worse\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:56:06 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:46:19 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 17:29:22 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mobahi", "Hossein", ""], ["Farajtabar", "Mehrdad", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "2002.05747", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo", "title": "Multiple Metric Learning for Structured Data", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.MG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of merging graph and feature-space information while\nlearning a metric from structured data. Existing algorithms tackle the problem\nin an asymmetric way, by either extracting vectorized summaries of the graph\nstructure or adding hard constraints to feature-space algorithms. Following a\ndifferent path, we define a metric regression scheme where we train\nmetric-constrained linear combinations of dissimilarity matrices. The idea is\nthat the input matrices can be pre-computed dissimilarity measures obtained\nfrom any kind of available data (e.g. node attributes or edge structure). As\nthe model inputs are distance measures, we do not need to assume the existence\nof any underlying feature space. Main challenge is that metric constraints\n(especially positive-definiteness and sub-additivity), are not automatically\nrespected if, for example, the coefficients of the linear combination are\nallowed to be negative. Both positive and sub-additive constraints are linear\ninequalities, but the computational complexity of imposing them scales as\nO(D3), where D is the size of the input matrices (i.e. the size of the data\nset). This becomes quickly prohibitive, even when D is relatively small. We\npropose a new graph-based technique for optimizing under such constraints and\nshow that, in some cases, our approach may reduce the original computational\ncomplexity of the optimization process by one order of magnitude. Contrarily to\nexisting methods, our scheme applies to any (possibly non-convex)\nmetric-constrained objective function.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 19:11:32 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Colombo", "Nicolo", ""]]}, {"id": "2002.05761", "submitter": "Venkitesh Ayyar", "authors": "Venkitesh Ayyar, Wahid Bhimji, Lisa Gerhardt, Sally Robertson and\n  Zahra Ronaghi", "title": "The use of Convolutional Neural Networks for signal-background\n  classification in Particle Physics experiments", "comments": "Contribution to Proceedings of CHEP 2019, Nov 4-8, Adelaide,\n  Australia", "journal-ref": "EPJ Web of Conferences 245, 06003 (2020)", "doi": "10.1051/epjconf/202024506003", "report-no": null, "categories": "hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Convolutional Neural Networks (CNNs) in image classification\nhas prompted efforts to study their use for classifying image data obtained in\nParticle Physics experiments. Here, we discuss our efforts to apply CNNs to 2D\nand 3D image data from particle physics experiments to classify signal from\nbackground.\n  In this work we present an extensive convolutional neural architecture\nsearch, achieving high accuracy for signal/background discrimination for a HEP\nclassification use-case based on simulated data from the Ice Cube neutrino\nobservatory and an ATLAS-like detector. We demonstrate among other things that\nwe can achieve the same accuracy as complex ResNet architectures with CNNs with\nless parameters, and present comparisons of computational requirements,\ntraining and inference times.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 19:54:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ayyar", "Venkitesh", ""], ["Bhimji", "Wahid", ""], ["Gerhardt", "Lisa", ""], ["Robertson", "Sally", ""], ["Ronaghi", "Zahra", ""]]}, {"id": "2002.05770", "submitter": "Yang Liu", "authors": "Yang Liu, Tiexing Wang, Yuexin Jiang, Biao Chen", "title": "Harvesting Ambient RF for Presence Detection Through Deep Learning", "comments": "Source code and datasets are available at Github:\n  https://github.com/bigtreeyanger/presence_detection_cnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of ambient radio frequency (RF) signals for human\npresence detection through deep learning. Using WiFi signal as an example, we\ndemonstrate that the channel state information (CSI) obtained at the receiver\ncontains rich information about the propagation environment. Through judicious\npre-processing of the estimated CSI followed by deep learning, reliable\npresence detection can be achieved. Several challenges in passive RF sensing\nare addressed. With presence detection, how to collect training data with human\npresence can have a significant impact on the performance. This is in contrast\nto activity detection when a specific motion pattern is of interest. A second\nchallenge is that RF signals are complex-valued. Handling complex-valued input\nin deep learning requires careful data representation and network architecture\ndesign. Finally, human presence affects CSI variation along multiple\ndimensions; such variation, however, is often masked by system impediments such\nas timing or frequency offset. Addressing these challenges, the proposed\nlearning system uses pre-processing to preserve human motion induced channel\nvariation while insulating against other impairments. A convolutional neural\nnetwork (CNN) properly trained with both magnitude and phase information is\nthen designed to achieve reliable presence detection. Extensive experiments are\nconducted. Using off-the-shelf WiFi devices, the proposed deep learning based\nRF sensing achieves near perfect presence detection during multiple extended\nperiods of test and exhibits superior performance compared with leading edge\npassive infrared sensors. Comparison with existing RF based human presence\ndetection also demonstrates its robustness in performance, especially when\ndeployed in a completely new environment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:35:55 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:56:47 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 01:03:59 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Liu", "Yang", ""], ["Wang", "Tiexing", ""], ["Jiang", "Yuexin", ""], ["Chen", "Biao", ""]]}, {"id": "2002.05777", "submitter": "David R\\\"ugamer", "authors": "David R\\\"ugamer, Chris Kolb, Nadja Klein", "title": "Semi-Structured Deep Distributional Regression: Combining Structured\n  Additive Models and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining additive models and neural networks allows to broaden the scope of\nstatistical regression and extends deep learning-based approaches by\ninterpretable structured additive predictors at the same time. Existing\napproaches uniting the two modeling approaches are, however, limited to very\nspecific combinations and, more importantly, involve an identifiability issue.\nAs a consequence, interpretability and stable estimation is typically lost. We\npropose a general framework to combine structured regression models and deep\nneural networks into a unifying network architecture. To overcome the inherent\nidentifiability issues between different model parts, we construct an\northogonalization cell that projects the deep neural network into the\northogonal complement of the statistical model predictor. This enables proper\nestimation of structured model parts and thereby interpretability. We\ndemonstrate the framework's efficacy in numerical experiments and illustrate\nits special merits in benchmarks and real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 21:01:26 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 16:06:39 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 13:32:23 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 14:44:21 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["R\u00fcgamer", "David", ""], ["Kolb", "Chris", ""], ["Klein", "Nadja", ""]]}, {"id": "2002.05780", "submitter": "Yunan Ye", "authors": "Yunan Ye, Hengzhi Pei, Boxin Wang, Pin-Yu Chen, Yada Zhu, Jun Xiao, Bo\n  Li", "title": "Reinforcement-Learning based Portfolio Management with Augmented Asset\n  Movement Prediction States", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio management (PM) is a fundamental financial planning task that aims\nto achieve investment goals such as maximal profits or minimal risks. Its\ndecision process involves continuous derivation of valuable information from\nvarious data sources and sequential decision optimization, which is a\nprospective research direction for reinforcement learning (RL). In this paper,\nwe propose SARL, a novel State-Augmented RL framework for PM. Our framework\naims to address two unique challenges in financial PM: (1) data heterogeneity\n-- the collected information for each asset is usually diverse, noisy and\nimbalanced (e.g., news articles); and (2) environment uncertainty -- the\nfinancial market is versatile and non-stationary. To incorporate heterogeneous\ndata and enhance robustness against environment uncertainty, our SARL augments\nthe asset information with their price movement prediction as additional\nstates, where the prediction can be solely based on financial data (e.g., asset\nprices) or derived from alternative sources such as news. Experiments on two\nreal-world datasets, (i) Bitcoin market and (ii) HighTech stock market with\n7-year Reuters news articles, validate the effectiveness of SARL over existing\nPM approaches, both in terms of accumulated profits and risk-adjusted profits.\nMoreover, extensive simulations are conducted to demonstrate the importance of\nour proposed state augmentation, providing new insights and boosting\nperformance significantly over standard RL-based PM method and other baselines.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 08:10:03 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ye", "Yunan", ""], ["Pei", "Hengzhi", ""], ["Wang", "Boxin", ""], ["Chen", "Pin-Yu", ""], ["Zhu", "Yada", ""], ["Xiao", "Jun", ""], ["Li", "Bo", ""]]}, {"id": "2002.05784", "submitter": "Lior Sidi", "authors": "Lior Sidi", "title": "Improving S&P stock prediction with time series stock similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stock market prediction with forecasting algorithms is a popular topic these\ndays where most of the forecasting algorithms train only on data collected on a\nparticular stock. In this paper, we enriched the stock data with related stocks\njust as a professional trader would have done to improve the stock prediction\nmodels. We tested five different similarities functions and found\nco-integration similarity to have the best improvement on the prediction model.\nWe evaluate the models on seven S&P stocks from various industries over five\nyears period. The prediction model we trained on similar stocks had\nsignificantly better results with 0.55 mean accuracy, and 19.782 profit compare\nto the state of the art model with an accuracy of 0.52 and profit of 6.6.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:13:45 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Sidi", "Lior", ""]]}, {"id": "2002.05786", "submitter": "Murat Ozbayoglu", "authors": "Ahmet Murat Ozbayoglu, Mehmet Ugur Gudelek, Omer Berat Sezer", "title": "Deep Learning for Financial Applications : A Survey", "comments": "13 Figures, 15 Tables, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational intelligence in finance has been a very popular topic for both\nacademia and financial industry in the last few decades. Numerous studies have\nbeen published resulting in various models. Meanwhile, within the Machine\nLearning (ML) field, Deep Learning (DL) started getting a lot of attention\nrecently, mostly due to its outperformance over the classical models. Lots of\ndifferent implementations of DL exist today, and the broad interest is\ncontinuing. Finance is one particular area where DL models started getting\ntraction, however, the playfield is wide open, a lot of research opportunities\nstill exist. In this paper, we tried to provide a state-of-the-art snapshot of\nthe developed DL models for financial applications, as of today. We not only\ncategorized the works according to their intended subfield in finance but also\nanalyzed them based on their DL models. In addition, we also aimed at\nidentifying possible future implementations and highlighted the pathway for the\nongoing research within the field.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 14:34:56 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ozbayoglu", "Ahmet Murat", ""], ["Gudelek", "Mehmet Ugur", ""], ["Sezer", "Omer Berat", ""]]}, {"id": "2002.05789", "submitter": "Felipe Tobar", "authors": "Taco de Wolff, Alejandro Cuevas, Felipe Tobar", "title": "Gaussian process imputation of multiple financial series", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Financial Signal Processing, multiple time series such as financial\nindicators, stock prices and exchange rates are strongly coupled due to their\ndependence on the latent state of the market and therefore they are required to\nbe jointly analysed. We focus on learning the relationships among financial\ntime series by modelling them through a multi-output Gaussian process (MOGP)\nwith expressive covariance functions. Learning these market dependencies among\nfinancial series is crucial for the imputation and prediction of financial\nobservations. The proposed model is validated experimentally on two real-world\nfinancial datasets for which their correlations across channels are analysed.\nWe compare our model against other MOGPs and the independent Gaussian process\non real financial data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:18:18 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["de Wolff", "Taco", ""], ["Cuevas", "Alejandro", ""], ["Tobar", "Felipe", ""]]}, {"id": "2002.05809", "submitter": "Konstantinos P. Panousis", "authors": "Konstantinos P. Panousis, Sotirios Chatzis, Sergios Theodoridis", "title": "Variational Conditional-Dependence Hidden Markov Models for Human Action\n  Recognition", "comments": "Under review ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov Models (HMMs) are a powerful generative approach for modeling\nsequential data and time-series in general. However, the commonly employed\nassumption of the dependence of the current time frame to a single or multiple\nimmediately preceding frames is unrealistic; more complicated dynamics\npotentially exist in real world scenarios. Human Action Recognition constitutes\nsuch a scenario, and has attracted increased attention with the advent of\nlow-cost 3D sensors. The naturally arising variations and complex temporal\ndependencies have established this task as a challenging problem in the\ncommunity. This paper revisits conventional sequential modeling approaches,\naiming to address the problem of capturing time-varying temporal dependency\npatterns. To this end, we propose a different formulation of HMMs, whereby the\ndependence on past frames is dynamically inferred from the data. Specifically,\nwe introduce a hierarchical extension by postulating an additional latent\nvariable layer; therein, the (time-varying) temporal dependence patterns are\ntreated as latent variables over which inference is performed. We leverage\nsolid arguments from the Variational Bayes framework and derive a tractable\ninference algorithm based on the forward-backward algorithm. As we\nexperimentally show using benchmark datasets, our approach yields competitive\nrecognition accuracy and can effectively handle data with missing values.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 23:18:52 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Panousis", "Konstantinos P.", ""], ["Chatzis", "Sotirios", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "2002.05810", "submitter": "Xinshi Chen", "authors": "Xinshi Chen, Yu Li, Ramzan Umarov, Xin Gao, Le Song", "title": "RNA Secondary Structure Prediction By Learning Unrolled Algorithms", "comments": "International Conference on Learning Representations 2020", "journal-ref": "International Conference on Learning Representations 2020,\n  https://openreview.net/forum?id=S1eALyrYDH", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an end-to-end deep learning model, called E2Efold,\nfor RNA secondary structure prediction which can effectively take into account\nthe inherent constraints in the problem. The key idea of E2Efold is to directly\npredict the RNA base-pairing matrix, and use an unrolled algorithm for\nconstrained programming as the template for deep architectures to enforce\nconstraints. With comprehensive experiments on benchmark datasets, we\ndemonstrate the superior performance of E2Efold: it predicts significantly\nbetter structures compared to previous SOTA (especially for pseudoknotted\nstructures), while being as efficient as the fastest algorithms in terms of\ninference time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 23:21:25 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Xinshi", ""], ["Li", "Yu", ""], ["Umarov", "Ramzan", ""], ["Gao", "Xin", ""], ["Song", "Le", ""]]}, {"id": "2002.05815", "submitter": "Jonathan Wells", "authors": "Kai Ming Ting, Jonathan R. Wells and Ye Zhu", "title": "Clustering based on Point-Set Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarity between two objects is the core operation in existing\ncluster analyses in grouping similar objects into clusters. Cluster analyses\nhave been applied to a number of applications, including image segmentation,\nsocial network analysis, and computational biology. This paper introduces a new\nsimilarity measure called point-set kernel which computes the similarity\nbetween an object and a sample of objects generated from an unknown\ndistribution. The proposed clustering procedure utilizes this new measure to\ncharacterize both the typical point of every cluster and the cluster grown from\nthe typical point. We show that the new clustering procedure is both effective\nand efficient such that it can deal with large scale datasets. In contrast,\nexisting clustering algorithms are either efficient or effective; and even\nefficient ones have difficulty dealing with large scale datasets without\nspecial hardware. We show that the proposed algorithm is more effective and\nruns orders of magnitude faster than the state-of-the-art density-peak\nclustering and scalable kernel k-means clustering when applying to datasets of\nmillions of data points, on commonly used computing machines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:00:03 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ting", "Kai Ming", ""], ["Wells", "Jonathan R.", ""], ["Zhu", "Ye", ""]]}, {"id": "2002.05818", "submitter": "Natalie Doss", "authors": "Natalie Doss and Yihong Wu and Pengkun Yang and Harrison H. Zhou", "title": "Optimal estimation of high-dimensional location Gaussian mixtures", "comments": "Adds Theorems 4.7 and 4.8 on computationally efficient density\n  estimation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the optimal rate of estimation in a finite Gaussian\nlocation mixture model in high dimensions without separation conditions. We\nassume that the number of components $k$ is bounded and that the centers lie in\na ball of bounded radius, while allowing the dimension $d$ to be as large as\nthe sample size $n$. Extending the one-dimensional result of Heinrich and Kahn\n\\cite{HK2015}, we show that the minimax rate of estimating the mixing\ndistribution in Wasserstein distance is $\\Theta((d/n)^{1/4} + n^{-1/(4k-2)})$,\nachieved by an estimator computable in time $O(nd^2+n^{5/4})$. Furthermore, we\nshow that the mixture density can be estimated at the optimal parametric rate\n$\\Theta(\\sqrt{d/n})$ in Hellinger distance and provide a computationally\nefficient algorithm to achieve this rate in the special case of $k=2$.\n  Both the theoretical and methodological development rely on a careful\napplication of the method of moments. Central to our results is the observation\nthat the information geometry of finite Gaussian mixtures is characterized by\nthe moment tensors of the mixing distribution, whose low-rank structure can be\nexploited to obtain a sharp local entropy bound.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:11:54 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 00:49:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Doss", "Natalie", ""], ["Wu", "Yihong", ""], ["Yang", "Pengkun", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "2002.05820", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, David Balduzzi, Wojciech Marian Czarnecki, Marta\n  Garnelo and Yoram Bachrach", "title": "A Limited-Capacity Minimax Theorem for Non-Convex Games or: How I\n  Learned to Stop Worrying about Mixed-Nash and Love Neural Nets", "comments": "Appears in: Proceedings of the 24th International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2021). 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, a special case of multi-objective optimization, is an\nincreasingly prevalent machine learning technique: some of its most notable\napplications include GAN-based generative modeling and self-play techniques in\nreinforcement learning which have been applied to complex games such as Go or\nPoker. In practice, a \\emph{single} pair of networks is typically trained in\norder to find an approximate equilibrium of a highly nonconcave-nonconvex\nadversarial problem. However, while a classic result in game theory states such\nan equilibrium exists in concave-convex games, there is no analogous guarantee\nif the payoff is nonconcave-nonconvex. Our main contribution is to provide an\napproximate minimax theorem for a large class of games where the players pick\nneural networks including WGAN, StarCraft II, and Blotto Game. Our findings\nrely on the fact that despite being nonconcave-nonconvex with respect to the\nneural networks parameters, these games are concave-convex with respect to the\nactual models (e.g., functions or distributions) represented by these neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:17:24 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 15:25:32 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 21:37:08 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gidel", "Gauthier", ""], ["Balduzzi", "David", ""], ["Czarnecki", "Wojciech Marian", ""], ["Garnelo", "Marta", ""], ["Bachrach", "Yoram", ""]]}, {"id": "2002.05822", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Jincheng Mei, Amir-massoud Farahmand", "title": "Frequency-based Search-control in Dyna", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning has been empirically demonstrated as a\nsuccessful strategy to improve sample efficiency. In particular, Dyna is an\nelegant model-based architecture integrating learning and planning that\nprovides huge flexibility of using a model. One of the most important\ncomponents in Dyna is called search-control, which refers to the process of\ngenerating state or state-action pairs from which we query the model to acquire\nsimulated experiences. Search-control is critical in improving learning\nefficiency. In this work, we propose a simple and novel search-control strategy\nby searching high frequency regions of the value function. Our main intuition\nis built on Shannon sampling theorem from signal processing, which indicates\nthat a high frequency signal requires more samples to reconstruct. We\nempirically show that a high frequency function is more difficult to\napproximate. This suggests a search-control strategy: we should use states from\nhigh frequency regions of the value function to query the model to acquire more\nsamples. We develop a simple strategy to locally measure the frequency of a\nfunction by gradient and hessian norms, and provide theoretical justification\nfor this approach. We then apply our strategy to search-control in Dyna, and\nconduct experiments to show its property and effectiveness on benchmark\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:27:58 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pan", "Yangchen", ""], ["Mei", "Jincheng", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2002.05825", "submitter": "Silviu Pitis", "authors": "Silviu Pitis, Harris Chan, Kiarash Jamali, Jimmy Ba", "title": "An Inductive Bias for Distances: Neural Nets that Respect the Triangle\n  Inequality", "comments": "11 pages (+18 appendix). Published as a conference paper at ICLR\n  2020. https://openreview.net/forum?id=HJeiDpVFPr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distances are pervasive in machine learning. They serve as similarity\nmeasures, loss functions, and learning targets; it is said that a good distance\nmeasure solves a task. When defining distances, the triangle inequality has\nproven to be a useful constraint, both theoretically--to prove convergence and\noptimality guarantees--and empirically--as an inductive bias. Deep metric\nlearning architectures that respect the triangle inequality rely, almost\nexclusively, on Euclidean distance in the latent space. Though effective, this\nfails to model two broad classes of subadditive distances, common in graphs and\nreinforcement learning: asymmetric metrics, and metrics that cannot be embedded\ninto Euclidean space. To address these problems, we introduce novel\narchitectures that are guaranteed to satisfy the triangle inequality. We prove\nour architectures universally approximate norm-induced metrics on\n$\\mathbb{R}^n$, and present a similar result for modified Input Convex Neural\nNetworks. We show that our architectures outperform existing metric approaches\nwhen modeling graph distances and have a better inductive bias than non-metric\napproaches when training data is limited in the multi-goal reinforcement\nlearning setting.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:47:31 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:23:59 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 20:06:56 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Pitis", "Silviu", ""], ["Chan", "Harris", ""], ["Jamali", "Kiarash", ""], ["Ba", "Jimmy", ""]]}, {"id": "2002.05826", "submitter": "Yuichi Yoshida", "authors": "Tasuku Soma and Yuichi Yoshida", "title": "Statistical Learning with Conditional Value at Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a risk-averse statistical learning framework wherein the\nperformance of a learning algorithm is evaluated by the conditional\nvalue-at-risk (CVaR) of losses rather than the expected loss. We devise\nalgorithms based on stochastic gradient descent for this framework. While\nexisting studies of CVaR optimization require direct access to the underlying\ndistribution, our algorithms make a weaker assumption that only i.i.d.\\ samples\nare given. For convex and Lipschitz loss functions, we show that our algorithm\nhas $O(1/\\sqrt{n})$-convergence to the optimal CVaR, where $n$ is the number of\nsamples. For nonconvex and smooth loss functions, we show a generalization\nbound on CVaR. By conducting numerical experiments on various machine learning\ntasks, we demonstrate that our algorithms effectively minimize CVaR compared\nwith other baseline algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:58:34 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Soma", "Tasuku", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "2002.05842", "submitter": "C.B. Scott", "authors": "C.B. Scott and Eric Mjolsness", "title": "Graph Prolongation Convolutional Networks: Explicitly Multiscale Machine\n  Learning on Graphs with Applications to Modeling of Cytoskeleton", "comments": "Revised version submitted to IOP: Machine Learning, Science, and\n  Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a novel type of ensemble Graph Convolutional Network (GCN) model.\nUsing optimized linear projection operators to map between spatial scales of\ngraph, this ensemble model learns to aggregate information from each scale for\nits final prediction. We calculate these linear projection operators as the\ninfima of an objective function relating the structure matrices used for each\nGCN. Equipped with these projections, our model (a Graph\nProlongation-Convolutional Network) outperforms other GCN ensemble models at\npredicting the potential energy of monomer subunits in a coarse-grained\nmechanochemical simulation of microtubule bending. We demonstrate these\nperformance gains by measuring an estimate of the FLOPs spent to train each\nmodel, as well as wall-clock time. Because our model learns at multiple scales,\nit is possible to train at each scale according to a predetermined schedule of\ncoarse vs. fine training. We examine several such schedules adapted from the\nAlgebraic Multigrid (AMG) literature, and quantify the computational benefit of\neach. We also compare this model to another model which features an optimized\ncoarsening of the input graph. Finally, we derive backpropagation rules for the\ninput of our network model with respect to its output, and discuss how our\nmethod may be extended to very large graphs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 01:56:17 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 23:41:33 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Scott", "C. B.", ""], ["Mjolsness", "Eric", ""]]}, {"id": "2002.05856", "submitter": "Christopher Metzler", "authors": "Christopher A. Metzler and Gordon Wetzstein", "title": "Deep S$^3$PR: Simultaneous Source Separation and Phase Retrieval Using\n  Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and solves the simultaneous source separation and phase\nretrieval (S$^3$PR) problem. S$^3$PR is an important but largely unsolved\nproblem in a number application domains, including microscopy, wireless\ncommunication, and imaging through scattering media, where one has multiple\nindependent coherent sources whose phase is difficult to measure. In general,\nS$^3$PR is highly under-determined, non-convex, and difficult to solve. In this\nwork, we demonstrate that by restricting the solutions to lie in the range of a\ndeep generative model, we can constrain the search space sufficiently to solve\nS$^3$PR.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 03:20:26 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 01:55:29 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Metzler", "Christopher A.", ""], ["Wetzstein", "Gordon", ""]]}, {"id": "2002.05873", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Kohei Yatabe, Marc Delcroix, Yoshiki Masuyama, Daiki\n  Takeuchi", "title": "Speech Enhancement using Self-Adaptation and Multi-Head Self-Attention", "comments": "5 pages, to appear in IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a self-adaptation method for speech enhancement using\nauxiliary speaker-aware features; we extract a speaker representation used for\nadaptation directly from the test utterance. Conventional studies of deep\nneural network (DNN)--based speech enhancement mainly focus on building a\nspeaker independent model. Meanwhile, in speech applications including speech\nrecognition and synthesis, it is known that model adaptation to the target\nspeaker improves the accuracy. Our research question is whether a DNN for\nspeech enhancement can be adopted to unknown speakers without any auxiliary\nguidance signal in test-phase. To achieve this, we adopt multi-task learning of\nspeech enhancement and speaker identification, and use the output of the final\nhidden layer of speaker identification branch as an auxiliary feature. In\naddition, we use multi-head self-attention for capturing long-term dependencies\nin the speech and noise. Experimental results on a public dataset show that our\nstrategy achieves the state-of-the-art performance and also outperform\nconventional methods in terms of subjective quality.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 05:05:36 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Koizumi", "Yuma", ""], ["Yatabe", "Kohei", ""], ["Delcroix", "Marc", ""], ["Masuyama", "Yoshiki", ""], ["Takeuchi", "Daiki", ""]]}, {"id": "2002.05879", "submitter": "Masaki Kawanaka", "authors": "Masaki Kawanaka, Yuma Koizumi, Ryoichi Miyazaki and Kohei Yatabe", "title": "Stable Training of DNN for Speech Enhancement based on\n  Perceptually-Motivated Black-Box Cost Function", "comments": "accepted to the 45th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving subjective sound quality of enhanced signals is one of the most\nimportant missions in speech enhancement. For evaluating the subjective\nquality, several methods related to perceptually-motivated objective sound\nquality assessment (OSQA) have been proposed such as PESQ (perceptual\nevaluation of speech quality). However, direct use of such measures for\ntraining deep neural network (DNN) is not allowed in most cases because popular\nOSQAs are non-differentiable with respect to DNN parameters. Therefore, the\nprevious study has proposed to approximate the score of OSQAs by an auxiliary\nDNN so that its gradient can be used for training the primary DNN. One problem\nwith this approach is instability of the training caused by the approximation\nerror of the score. To overcome this problem, we propose to use stabilization\ntechniques borrowed from reinforcement learning. The experiments, aimed to\nincrease the score of PESQ as an example, show that the proposed method (i) can\nstably train a DNN to increase PESQ, (ii) achieved the state-of-the-art PESQ\nscore on a public dataset, and (iii) resulted in better sound quality than\nconventional methods based on subjective evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 05:44:17 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kawanaka", "Masaki", ""], ["Koizumi", "Yuma", ""], ["Miyazaki", "Ryoichi", ""], ["Yatabe", "Kohei", ""]]}, {"id": "2002.05897", "submitter": "Wouter Verbeke", "authors": "Floris Devriendt, Tias Guns and Wouter Verbeke", "title": "Learning to rank for uplift modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling has effectively been used in fields such as marketing and\ncustomer retention, to target those customers that are most likely to respond\ndue to the campaign or treatment. Uplift models produce uplift scores which are\nthen used to essentially create a ranking. We instead investigate to learn to\nrank directly by looking into the potential of learning-to-rank techniques in\nthe context of uplift modeling. We propose a unified formalisation of different\nglobal uplift modeling measures in use today and explore how these can be\nintegrated into the learning-to-rank framework. Additionally, we introduce a\nnew metric for learning-to-rank that focusses on optimizing the area under the\nuplift curve called the promoted cumulative gain (PCG). We employ the\nlearning-to-rank technique LambdaMART to optimize the ranking according to PCG\nand show improved results over standard learning-to-rank metrics and equal to\nimproved results when compared with state-of-the-art uplift modeling. Finally,\nwe show how learning-to-rank models can learn to optimize a certain targeting\ndepth, however, these results do not generalize on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 07:37:16 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Devriendt", "Floris", ""], ["Guns", "Tias", ""], ["Verbeke", "Wouter", ""]]}, {"id": "2002.05909", "submitter": "William Gilpin", "authors": "William Gilpin", "title": "Deep reconstruction of strange attractors from time series", "comments": "9 pages, 6 figures, plus appendices", "journal-ref": "NeurIPS (Neural Information Processing Systems) 2020", "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.data-an q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental measurements of physical systems often have a limited number of\nindependent channels, causing essential dynamical variables to remain\nunobserved. However, many popular methods for unsupervised inference of latent\ndynamics from experimental data implicitly assume that the measurements have\nhigher intrinsic dimensionality than the underlying system---making coordinate\nidentification a dimensionality reduction problem. Here, we study the opposite\nlimit, in which hidden governing coordinates must be inferred from only a\nlow-dimensional time series of measurements. Inspired by classical analysis\ntechniques for partial observations of chaotic attractors, we introduce a\ngeneral embedding technique for univariate and multivariate time series,\nconsisting of an autoencoder trained with a novel latent-space loss function.\nWe show that our technique reconstructs the strange attractors of synthetic and\nreal-world systems better than existing techniques, and that it creates\nconsistent, predictive representations of even stochastic systems. We conclude\nby using our technique to discover dynamical attractors in diverse systems such\nas patient electrocardiograms, household electricity usage, neural spiking, and\neruptions of the Old Faithful geyser---demonstrating diverse applications of\nour technique for exploratory data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:14:52 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 12:18:43 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 12:02:15 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gilpin", "William", ""]]}, {"id": "2002.05954", "submitter": "Sammy Christen", "authors": "Sammy Christen, Lukas Jendele, Emre Aksan, Otmar Hilliges", "title": "Learning Functionally Decomposed Hierarchies for Continuous Control\n  Tasks with Path Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HiDe, a novel hierarchical reinforcement learning architecture\nthat successfully solves long horizon control tasks and generalizes to unseen\ntest scenarios. Functional decomposition between planning and low-level control\nis achieved by explicitly separating the state-action spaces across the\nhierarchy, which allows the integration of task-relevant knowledge per layer.\nWe propose an RL-based planner to efficiently leverage the information in the\nplanning layer of the hierarchy, while the control layer learns a\ngoal-conditioned control policy. The hierarchy is trained jointly but allows\nfor the composition of different policies such as transferring layers across\nmultiple agents. We experimentally show that our method generalizes across\nunseen test environments and can scale to tasks well beyond 3x horizon length\ncompared to both learning and non-learning based approaches. We evaluate on\ncomplex continuous control tasks with sparse rewards, including navigation and\nrobot manipulation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 10:19:52 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 12:01:32 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 11:38:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Christen", "Sammy", ""], ["Jendele", "Lukas", ""], ["Aksan", "Emre", ""], ["Hilliges", "Otmar", ""]]}, {"id": "2002.05969", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Weihua Hu, Jure Leskovec", "title": "Query2box: Reasoning over Knowledge Graphs in Vector Space using Box\n  Embeddings", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex logical queries on large-scale incomplete knowledge graphs\n(KGs) is a fundamental yet challenging task. Recently, a promising approach to\nthis problem has been to embed KG entities as well as the query into a vector\nspace such that entities that answer the query are embedded close to the query.\nHowever, prior work models queries as single points in the vector space, which\nis problematic because a complex query represents a potentially large set of\nits answer entities, but it is unclear how such a set can be represented as a\nsingle point. Furthermore, prior work can only handle queries that use\nconjunctions ($\\wedge$) and existential quantifiers ($\\exists$). Handling\nqueries with logical disjunctions ($\\vee$) remains an open problem. Here we\npropose query2box, an embedding-based framework for reasoning over arbitrary\nqueries with $\\wedge$, $\\vee$, and $\\exists$ operators in massive and\nincomplete KGs. Our main insight is that queries can be embedded as boxes\n(i.e., hyper-rectangles), where a set of points inside the box corresponds to a\nset of answer entities of the query. We show that conjunctions can be naturally\nrepresented as intersections of boxes and also prove a negative result that\nhandling disjunctions would require embedding with dimension proportional to\nthe number of KG entities. However, we show that by transforming queries into a\nDisjunctive Normal Form, query2box is capable of handling arbitrary logical\nqueries with $\\wedge$, $\\vee$, $\\exists$ in a scalable manner. We demonstrate\nthe effectiveness of query2box on three large KGs and show that query2box\nachieves up to 25% relative improvement over the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:20:10 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 03:59:06 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ren", "Hongyu", ""], ["Hu", "Weihua", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.05988", "submitter": "Ana Sofia Gomes", "authors": "Bernardo Branco, Pedro Abreu, Ana Sofia Gomes, Mariana S. C. Almeida,\n  Jo\\~ao Tiago Ascens\\~ao, Pedro Bizarro", "title": "Interleaved Sequence RNNs for Fraud Detection", "comments": "9 pages, 4 figures, to appear in SIGKDD'20 Industry Track", "journal-ref": null, "doi": "10.1145/3394486.3403361", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment card fraud causes multibillion dollar losses for banks and merchants\nworldwide, often fueling complex criminal activities. To address this, many\nreal-time fraud detection systems use tree-based models, demanding complex\nfeature engineering systems to efficiently enrich transactions with historical\ndata while complying with millisecond-level latencies.\n  In this work, we do not require those expensive features by using recurrent\nneural networks and treating payments as an interleaved sequence, where the\nhistory of each card is an unbounded, irregular sub-sequence. We present a\ncomplete RNN framework to detect fraud in real-time, proposing an efficient ML\npipeline from preprocessing to deployment.\n  We show that these feature-free, multi-sequence RNNs outperform\nstate-of-the-art models saving millions of dollars in fraud detection and using\nfewer computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:04:11 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:59:41 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Branco", "Bernardo", ""], ["Abreu", "Pedro", ""], ["Gomes", "Ana Sofia", ""], ["Almeida", "Mariana S. C.", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2002.05990", "submitter": "Dongxian Wu", "authors": "Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma", "title": "Skip Connections Matter: On the Transferability of Adversarial Examples\n  Generated with ResNets", "comments": "ICLR 2020 conference paper (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip connections are an essential component of current state-of-the-art deep\nneural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt.\nDespite their huge success in building deeper and more powerful DNNs, we\nidentify a surprising security weakness of skip connections in this paper. Use\nof skip connections allows easier generation of highly transferable adversarial\nexamples. Specifically, in ResNet-like (with skip connections) neural networks,\ngradients can backpropagate through either skip connections or residual\nmodules. We find that using more gradients from the skip connections rather\nthan the residual modules according to a decay factor, allows one to craft\nadversarial examples with high transferability. Our method is termed Skip\nGradient Method(SGM). We conduct comprehensive transfer attacks against\nstate-of-the-art DNNs including ResNets, DenseNets, Inceptions,\nInception-ResNet, Squeeze-and-Excitation Network (SENet) and robustly trained\nDNNs. We show that employing SGM on the gradient flow can greatly improve the\ntransferability of crafted attacks in almost all cases. Furthermore, SGM can be\neasily combined with existing black-box attack techniques, and obtain high\nimprovements over state-of-the-art transferability methods. Our findings not\nonly motivate new research into the architectural vulnerability of DNNs, but\nalso open up further challenges for the design of secure DNN architectures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:09:21 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wu", "Dongxian", ""], ["Wang", "Yisen", ""], ["Xia", "Shu-Tao", ""], ["Bailey", "James", ""], ["Ma", "Xingjun", ""]]}, {"id": "2002.05999", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Zhijie Deng, Tianyu Pang, Hang Su, Jun Zhu", "title": "Adversarial Distributional Training for Robust Deep Learning", "comments": "NeurIPS 2020. The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is among the most effective techniques to improve\nmodel robustness by augmenting training data with adversarial examples.\nHowever, most existing AT methods adopt a specific attack to craft adversarial\nexamples, leading to the unreliable robustness against other unseen attacks.\nBesides, a single attack algorithm could be insufficient to explore the space\nof perturbations. In this paper, we introduce adversarial distributional\ntraining (ADT), a novel framework for learning robust models. ADT is formulated\nas a minimax optimization problem, where the inner maximization aims to learn\nan adversarial distribution to characterize the potential adversarial examples\naround a natural one under an entropic regularizer, and the outer minimization\naims to train robust models by minimizing the expected loss over the worst-case\nadversarial distributions. Through a theoretical analysis, we develop a general\nalgorithm for solving ADT, and present three approaches for parameterizing the\nadversarial distributions, ranging from the typical Gaussian distributions to\nthe flexible implicit ones. Empirical results on several benchmarks validate\nthe effectiveness of ADT compared with the state-of-the-art AT methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:36:59 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 05:47:50 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dong", "Yinpeng", ""], ["Deng", "Zhijie", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2002.06015", "submitter": "Kazuki Osawa", "authors": "Kazuki Osawa, Yohei Tsuji, Yuichiro Ueno, Akira Naruse, Chuan-Sheng\n  Foo, and Rio Yokota", "title": "Scalable and Practical Natural Gradient for Large-Scale Deep Learning", "comments": "arXiv admin note: text overlap with arXiv:1811.12019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed training of deep neural networks results in models\nwith worse generalization performance as a result of the increase in the\neffective mini-batch size. Previous approaches attempt to address this problem\nby varying the learning rate and batch size over epochs and layers, or ad hoc\nmodifications of batch normalization. We propose Scalable and Practical Natural\nGradient Descent (SP-NGD), a principled approach for training models that\nallows them to attain similar generalization performance to models trained with\nfirst-order optimization methods, but with accelerated convergence.\nFurthermore, SP-NGD scales to large mini-batch sizes with a negligible\ncomputational overhead as compared to first-order methods. We evaluated SP-NGD\non a benchmark task where highly optimized first-order methods are available as\nreferences: training a ResNet-50 model for image classification on ImageNet. We\ndemonstrate convergence to a top-1 validation accuracy of 75.4% in 5.5 minutes\nusing a mini-batch size of 32,768 with 1,024 GPUs, as well as an accuracy of\n74.9% with an extremely large mini-batch size of 131,072 in 873 steps of\nSP-NGD.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:55:37 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Osawa", "Kazuki", ""], ["Tsuji", "Yohei", ""], ["Ueno", "Yuichiro", ""], ["Naruse", "Akira", ""], ["Foo", "Chuan-Sheng", ""], ["Yokota", "Rio", ""]]}, {"id": "2002.06033", "submitter": "Sergey Novoselov", "authors": "Aleksei Gusev, Vladimir Volokhov, Tseren Andzhukaev, Sergey Novoselov,\n  Galina Lavrentyeva, Marina Volkova, Alice Gazizullina, Andrey Shulipa, Artem\n  Gorlanov, Anastasia Avdeeva, Artem Ivanov, Alexander Kozlov, Timur Pekhovsky,\n  Yuri Matveev", "title": "Deep Speaker Embeddings for Far-Field Speaker Recognition on Short\n  Utterances", "comments": "Submitted to Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition systems based on deep speaker embeddings have achieved\nsignificant performance in controlled conditions according to the results\nobtained for early NIST SRE (Speaker Recognition Evaluation) datasets. From the\npractical point of view, taking into account the increased interest in virtual\nassistants (such as Amazon Alexa, Google Home, AppleSiri, etc.), speaker\nverification on short utterances in uncontrolled noisy environment conditions\nis one of the most challenging and highly demanded tasks. This paper presents\napproaches aimed to achieve two goals: a) improve the quality of far-field\nspeaker verification systems in the presence of environmental noise,\nreverberation and b) reduce the system qualitydegradation for short utterances.\nFor these purposes, we considered deep neural network architectures based on\nTDNN (TimeDelay Neural Network) and ResNet (Residual Neural Network) blocks. We\nexperimented with state-of-the-art embedding extractors and their training\nprocedures. Obtained results confirm that ResNet architectures outperform the\nstandard x-vector approach in terms of speaker verification quality for both\nlong-duration and short-duration utterances. We also investigate the impact of\nspeech activity detector, different scoring models, adaptation and score\nnormalization techniques. The experimental results are presented for publicly\navailable data and verification protocols for the VoxCeleb1, VoxCeleb2, and\nVOiCES datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 13:34:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Gusev", "Aleksei", ""], ["Volokhov", "Vladimir", ""], ["Andzhukaev", "Tseren", ""], ["Novoselov", "Sergey", ""], ["Lavrentyeva", "Galina", ""], ["Volkova", "Marina", ""], ["Gazizullina", "Alice", ""], ["Shulipa", "Andrey", ""], ["Gorlanov", "Artem", ""], ["Avdeeva", "Anastasia", ""], ["Ivanov", "Artem", ""], ["Kozlov", "Alexander", ""], ["Pekhovsky", "Timur", ""], ["Matveev", "Yuri", ""]]}, {"id": "2002.06038", "submitter": "Adri\\`a Puigdom\\`enech Badia", "authors": "Adri\\`a Puigdom\\`enech Badia, Pablo Sprechmann, Alex Vitvitskyi,\n  Daniel Guo, Bilal Piot, Steven Kapturowski, Olivier Tieleman, Mart\\'in\n  Arjovsky, Alexander Pritzel, Andew Bolt, Charles Blundell", "title": "Never Give Up: Learning Directed Exploration Strategies", "comments": "Published as a conference paper in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reinforcement learning agent to solve hard exploration games by\nlearning a range of directed exploratory policies. We construct an episodic\nmemory-based intrinsic reward using k-nearest neighbors over the agent's recent\nexperience to train the directed exploratory policies, thereby encouraging the\nagent to repeatedly revisit all states in its environment. A self-supervised\ninverse dynamics model is used to train the embeddings of the nearest neighbour\nlookup, biasing the novelty signal towards what the agent can control. We\nemploy the framework of Universal Value Function Approximators (UVFA) to\nsimultaneously learn many directed exploration policies with the same neural\nnetwork, with different trade-offs between exploration and exploitation. By\nusing the same neural network for different degrees of\nexploration/exploitation, transfer is demonstrated from predominantly\nexploratory policies yielding effective exploitative policies. The proposed\nmethod can be incorporated to run with modern distributed RL agents that\ncollect large amounts of experience from many actors running in parallel on\nseparate environment instances. Our method doubles the performance of the base\nagent in all hard exploration in the Atari-57 suite while maintaining a very\nhigh score across the remaining games, obtaining a median human normalised\nscore of 1344.0%. Notably, the proposed method is the first algorithm to\nachieve non-zero rewards (with a mean score of 8,400) in the game of Pitfall!\nwithout using demonstrations or hand-crafted features.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 13:57:22 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Sprechmann", "Pablo", ""], ["Vitvitskyi", "Alex", ""], ["Guo", "Daniel", ""], ["Piot", "Bilal", ""], ["Kapturowski", "Steven", ""], ["Tieleman", "Olivier", ""], ["Arjovsky", "Mart\u00edn", ""], ["Pritzel", "Alexander", ""], ["Bolt", "Andew", ""], ["Blundell", "Charles", ""]]}, {"id": "2002.06043", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof, Max Welling", "title": "Estimating Gradients for Discrete Random Variables by Sampling without\n  Replacement", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an unbiased estimator for expectations over discrete random\nvariables based on sampling without replacement, which reduces variance as it\navoids duplicate samples. We show that our estimator can be derived as the\nRao-Blackwellization of three different estimators. Combining our estimator\nwith REINFORCE, we obtain a policy gradient estimator and we reduce its\nvariance using a built-in control variate which is obtained without additional\nmodel evaluations. The resulting estimator is closely related to other gradient\nestimators. Experiments with a toy problem, a categorical Variational\nAuto-Encoder and a structured prediction problem show that our estimator is the\nonly estimator that is consistently among the best estimators in both high and\nlow entropy settings.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:15:18 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Welling", "Max", ""]]}, {"id": "2002.06053", "submitter": "Hakime \\\"Ozt\\\"urk", "authors": "Hakime \\\"Ozt\\\"urk, Arzucan \\\"Ozg\\\"ur, Philippe Schwaller, Teodoro\n  Laino, Elif Ozkirimli", "title": "Exploring Chemical Space using Natural Language Processing Methodologies\n  for Drug Discovery", "comments": null, "journal-ref": null, "doi": "10.1016/j.drudis.2020.01.020", "report-no": null, "categories": "q-bio.BM cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based representations of chemicals and proteins can be thought of as\nunstructured languages codified by humans to describe domain-specific\nknowledge. Advances in natural language processing (NLP) methodologies in the\nprocessing of spoken languages accelerated the application of NLP to elucidate\nhidden knowledge in textual representations of these biochemical entities and\nthen use it to construct models to predict molecular properties or to design\nnovel molecules. This review outlines the impact made by these advances on drug\ndiscovery and aims to further the dialogue between medicinal chemists and\ncomputer scientists.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:02:05 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["\u00d6zt\u00fcrk", "Hakime", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["Schwaller", "Philippe", ""], ["Laino", "Teodoro", ""], ["Ozkirimli", "Elif", ""]]}, {"id": "2002.06063", "submitter": "Parameswaran Kamalaruban Dr.", "authors": "Parameswaran Kamalaruban, Yu-Ting Huang, Ya-Ping Hsieh, Paul Rolland,\n  Cheng Shi, Volkan Cevher", "title": "Robust Reinforcement Learning via Adversarial training with Langevin\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a sampling perspective to tackle the challenging task of\ntraining robust Reinforcement Learning (RL) agents. Leveraging the powerful\nStochastic Gradient Langevin Dynamics, we present a novel, scalable two-player\nRL algorithm, which is a sampling variant of the two-player policy gradient\nmethod. Our algorithm consistently outperforms existing baselines, in terms of\ngeneralization across different training and testing conditions, on several\nMuJoCo environments. Our experiments also show that, even for objective\nfunctions that entirely ignore potential environmental shifts, our sampling\napproach remains highly robust in comparison to standard RL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:59:14 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 19:09:36 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Kamalaruban", "Parameswaran", ""], ["Huang", "Yu-Ting", ""], ["Hsieh", "Ya-Ping", ""], ["Rolland", "Paul", ""], ["Shi", "Cheng", ""], ["Cevher", "Volkan", ""]]}, {"id": "2002.06075", "submitter": "David Aparicio", "authors": "David Apar\\'icio, Ricardo Barata, Jo\\~ao Bravo, Jo\\~ao Tiago\n  Ascens\\~ao, Pedro Bizarro", "title": "ARMS: Automated rules management system for fraud detection", "comments": "11 pages, 12 figures, submitted to KDD '20 Applied Data Science Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection is essential in financial services, with the potential of\ngreatly reducing criminal activities and saving considerable resources for\nbusinesses and customers. We address online fraud detection, which consists of\nclassifying incoming transactions as either legitimate or fraudulent in\nreal-time. Modern fraud detection systems consist of a machine learning model\nand rules defined by human experts. Often, the rules performance degrades over\ntime due to concept drift, especially of adversarial nature. Furthermore, they\ncan be costly to maintain, either because they are computationally expensive or\nbecause they send transactions for manual review. We propose ARMS, an automated\nrules management system that evaluates the contribution of individual rules and\noptimizes the set of active rules using heuristic search and a user-defined\nloss-function. It complies with critical domain-specific requirements, such as\nhandling different actions (e.g., accept, alert, and decline), priorities,\nblacklists, and large datasets (i.e., hundreds of rules and millions of\ntransactions). We use ARMS to optimize the rule-based systems of two real-world\nclients. Results show that it can maintain the original systems' performance\n(e.g., recall, or false-positive rate) using only a fraction of the original\nrules (~ 50% in one case, and ~ 20% in the other).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:29:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Apar\u00edcio", "David", ""], ["Barata", "Ricardo", ""], ["Bravo", "Jo\u00e3o", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2002.06103", "submitter": "Kashif Rasul", "authors": "Kashif Rasul, Abdul-Saboor Sheikh, Ingmar Schuster, Urs Bergmann,\n  Roland Vollgraf", "title": "Multivariate Probabilistic Time Series Forecasting via Conditioned\n  Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is often fundamental to scientific and engineering\nproblems and enables decision making. With ever increasing data set sizes, a\ntrivial solution to scale up predictions is to assume independence between\ninteracting time series. However, modeling statistical dependencies can improve\naccuracy and enable analysis of interaction effects. Deep learning methods are\nwell suited for this problem, but multivariate models often assume a simple\nparametric distribution and do not scale to high dimensions. In this work we\nmodel the multivariate temporal dynamics of time series via an autoregressive\ndeep learning model, where the data distribution is represented by a\nconditioned normalizing flow. This combination retains the power of\nautoregressive models, such as good performance in extrapolation into the\nfuture, with the flexibility of flows as a general purpose high-dimensional\ndistribution model, while remaining computationally tractable. We show that it\nimproves over the state-of-the-art for standard metrics on many real-world data\nsets with several thousand interacting time-series.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:16:51 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 13:53:39 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 19:15:12 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Rasul", "Kashif", ""], ["Sheikh", "Abdul-Saboor", ""], ["Schuster", "Ingmar", ""], ["Bergmann", "Urs", ""], ["Vollgraf", "Roland", ""]]}, {"id": "2002.06115", "submitter": "William Cohen", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "title": "Scalable Neural Methods for Reasoning With a Symbolic Knowledge Base", "comments": "Also published in ICLR2020\n  https://openreview.net/forum?id=BJlguT4YPr&noteId=BJlguT4YPr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel way of representing a symbolic knowledge base (KB) called\na sparse-matrix reified KB. This representation enables neural modules that are\nfully differentiable, faithful to the original semantics of the KB, expressive\nenough to model multi-hop inferences, and scalable enough to use with\nrealistically large KBs. The sparse-matrix reified KB can be distributed across\nmultiple GPUs, can scale to tens of millions of entities and facts, and is\norders of magnitude faster than naive sparse-matrix implementations. The\nreified KB enables very simple end-to-end architectures to obtain competitive\nperformance on several benchmarks representing two families of tasks: KB\ncompletion, and learning semantic parsers from denotations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:32:19 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Cohen", "William W.", ""], ["Sun", "Haitian", ""], ["Hofer", "R. Alex", ""], ["Siegler", "Matthew", ""]]}, {"id": "2002.06141", "submitter": "Craig Pelissier", "authors": "Craig Pelissier, Jonathan Frame, Grey Nearing", "title": "Combining Parametric Land Surface Models with Machine Learning", "comments": "4 pages, 3 figures, 1 table, submitted to IGARSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid machine learning and process-based-modeling (PBM) approach is\nproposed and evaluated at a handful of AmeriFlux sites to simulate the\ntop-layer soil moisture state. The Hybrid-PBM (HPBM) employed here uses the\nNoah land-surface model integrated with Gaussian Processes. It is designed to\ncorrect the model only in climatological situations similar to the training\ndata else it reverts to the PBM. In this way, our approach avoids bad\npredictions in scenarios where similar training data is not available and\nincorporates our physical understanding of the system. Here we assume an\nautoregressive model and obtain out-of-sample results with upwards of a 3-fold\nreduction in the RMSE using a one-year leave-one-out cross-validation at each\nof the selected sites. A path is outlined for using hybrid modeling to build\nglobal land-surface models with the potential to significantly outperform the\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:50:33 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 18:20:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pelissier", "Craig", ""], ["Frame", "Jonathan", ""], ["Nearing", "Grey", ""]]}, {"id": "2002.06157", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Stefanie Jegelka, and Tommi Jaakkola", "title": "Generalization and Representational Limits of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two fundamental questions about graph neural networks (GNNs).\nFirst, we prove that several important graph properties cannot be computed by\nGNNs that rely entirely on local information. Such GNNs include the standard\nmessage passing models, and more powerful spatial variants that exploit local\ngraph structure (e.g., via relative orientation of messages, or local port\nordering) to distinguish neighbors of each node. Our treatment includes a novel\ngraph-theoretic formalism. Second, we provide the first data dependent\ngeneralization bounds for message passing GNNs. This analysis explicitly\naccounts for the local permutation invariance of GNNs. Our bounds are much\ntighter than existing VC-dimension based guarantees for GNNs, and are\ncomparable to Rademacher bounds for recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:10:14 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Garg", "Vikas K.", ""], ["Jegelka", "Stefanie", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.06160", "submitter": "Nicholas Hoernle", "authors": "Nicholas Hoernle and Gregory Kehne and Ariel D. Procaccia and Kobi Gal", "title": "The Phantom Steering Effect in Q&A Websites", "comments": "To appear in IEEE ICDM2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Badges are commonly used in online platforms as incentives for promoting\ncontributions. It is widely accepted that badges \"steer\" people's behavior\ntoward increasing their rate of contributions before obtaining the badge. This\npaper provides a new probabilistic model of user behavior in the presence of\nbadges. By applying the model to data from thousands of users on the Q&A site\nStack Overflow, we find that steering is not as widely applicable as was\npreviously understood. Rather, the majority of users remain apathetic toward\nbadges, while still providing a substantial number of contributions to the\nsite. An interesting statistical phenomenon, termed \"Phantom Steering,\"\naccounts for the interaction data of these users and this may have contributed\nto some previous conclusions about steering. Our results suggest that a small\npopulation, approximately 20%, of users respond to the badge incentives.\nMoreover, we conduct a qualitative survey of the users on Stack Overflow which\nprovides further evidence that the insights from the model reflect the true\nbehavior of the community. We argue that while badges might contribute toward a\nsuite of effective rewards in an online system, research into other aspects of\nreward systems such as Stack Overflow reputation points should become a focus\nof the community.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:20:37 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 14:00:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Hoernle", "Nicholas", ""], ["Kehne", "Gregory", ""], ["Procaccia", "Ariel D.", ""], ["Gal", "Kobi", ""]]}, {"id": "2002.06189", "submitter": "Lingkai Kong", "authors": "Lingkai Kong and Molei Tao", "title": "Stochasticity of Deterministic Gradient Descent: Large Learning Rate for\n  Multiscale Objective Function", "comments": "NeurIPS 2020. v1->v2: Weakened conditions needed for the theory.\n  Added connections to neural network. Corrected typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article suggests that deterministic Gradient Descent, which does not use\nany stochastic gradient approximation, can still exhibit stochastic behaviors.\nIn particular, it shows that if the objective function exhibit multiscale\nbehaviors, then in a large learning rate regime which only resolves the\nmacroscopic but not the microscopic details of the objective, the deterministic\nGD dynamics can become chaotic and convergent not to a local minimizer but to a\nstatistical distribution. A sufficient condition is also established for\napproximating this long-time statistical limit by a rescaled Gibbs\ndistribution. Both theoretical and numerical demonstrations are provided, and\nthe theoretical part relies on the construction of a stochastic map that uses\nbounded noise (as opposed to discretized diffusions).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:59:20 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:37:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kong", "Lingkai", ""], ["Tao", "Molei", ""]]}, {"id": "2002.06195", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Ehsan Imani, Martha White, Amir-massoud Farahmand", "title": "An implicit function learning approach for parametric modal regression", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For multi-valued functions---such as when the conditional distribution on\ntargets given the inputs is multi-modal---standard regression approaches are\nnot always desirable because they provide the conditional mean. Modal\nregression algorithms address this issue by instead finding the conditional\nmode(s). Most, however, are nonparametric approaches and so can be difficult to\nscale. Further, parametric approximators, like neural networks, facilitate\nlearning complex relationships between inputs and targets. In this work, we\npropose a parametric modal regression algorithm. We use the implicit function\ntheorem to develop an objective, for learning a joint function over inputs and\ntargets. We empirically demonstrate on several synthetic problems that our\nmethod (i) can learn multi-valued functions and produce the conditional modes,\n(ii) scales well to high-dimensional inputs, and (iii) can even be more\neffective for certain uni-modal problems, particularly for high-frequency\nfunctions. We demonstrate that our method is competitive in a real-world modal\nregression problem and two regular regression datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:37:41 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:46:18 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Pan", "Yangchen", ""], ["Imani", "Ehsan", ""], ["White", "Martha", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2002.06200", "submitter": "Daniel Steinberg", "authors": "Daniel Steinberg, Alistair Reid, Simon O'Callaghan, Finnian Lattimore,\n  Lachlan McCalman, Tiberio Caetano", "title": "Fast Fair Regression via Efficient Approximations of Mutual Information", "comments": "arXiv admin note: text overlap with arXiv:2001.06089", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in algorithmic fairness to date has focused on discrete outcomes,\nsuch as deciding whether to grant someone a loan or not. In these\nclassification settings, group fairness criteria such as independence,\nseparation and sufficiency can be measured directly by comparing rates of\noutcomes between subpopulations. Many important problems however require the\nprediction of a real-valued outcome, such as a risk score or insurance premium.\nIn such regression settings, measuring group fairness criteria is\ncomputationally challenging, as it requires estimating information-theoretic\ndivergences between conditional probability density functions. This paper\nintroduces fast approximations of the independence, separation and sufficiency\ngroup fairness criteria for regression models from their (conditional) mutual\ninformation definitions, and uses such approximations as regularisers to\nenforce fairness within a regularised risk minimisation framework. Experiments\nin real-world datasets indicate that in spite of its superior computational\nefficiency our algorithm still displays state-of-the-art accuracy/fairness\ntradeoffs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:50:51 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Steinberg", "Daniel", ""], ["Reid", "Alistair", ""], ["O'Callaghan", "Simon", ""], ["Lattimore", "Finnian", ""], ["McCalman", "Lachlan", ""], ["Caetano", "Tiberio", ""]]}, {"id": "2002.06205", "submitter": "Avi Caciularu", "authors": "Oren Barkan, Avi Caciularu, Ori Katz and Noam Koenigstein", "title": "Attentive Item2Vec: Neural Attentive User Representations", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization methods for recommender systems tend to represent users as a\nsingle latent vector. However, user behavior and interests may change in the\ncontext of the recommendations that are presented to the user. For example, in\nthe case of movie recommendations, it is usually true that earlier user data is\nless informative than more recent data. However, it is possible that a certain\nearly movie may become suddenly more relevant in the presence of a popular\nsequel movie. This is just a single example of a variety of possible\ndynamically altering user interests in the presence of a potential new\nrecommendation. In this work, we present Attentive Item2vec (AI2V) - a novel\nattentive version of Item2vec (I2V). AI2V employs a context-target attention\nmechanism in order to learn and capture different characteristics of user\nhistorical behavior (context) with respect to a potential recommended item\n(target). The attentive context-target mechanism enables a final neural\nattentive user representation. We demonstrate the effectiveness of AI2V on\nseveral datasets, where it is shown to outperform other baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:22:47 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 13:41:55 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 18:25:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Barkan", "Oren", ""], ["Caciularu", "Avi", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2002.06212", "submitter": "Minas Karamanis", "authors": "Minas Karamanis and Florian Beutler", "title": "Ensemble Slice Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO astro-ph.IM cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slice Sampling has emerged as a powerful Markov Chain Monte Carlo algorithm\nthat adapts to the characteristics of the target distribution with minimal\nhand-tuning. However, Slice Sampling's performance is highly sensitive to the\nuser-specified initial length scale hyperparameter. Moreover, Slice Sampling\ngenerally struggles with poorly scaled or strongly correlated distributions.\nThis paper introduces Ensemble Slice Sampling, a new class of algorithms that\nbypasses such difficulties by adaptively tuning the length scale. Furthermore,\nEnsemble Slice Sampling's performance is immune to linear correlations by\nexploiting an ensemble of parallel walkers. These algorithms are trivial to\nconstruct, require no hand-tuning, and can easily be implemented in parallel\ncomputing environments. Empirical tests show that Ensemble Slice Sampling can\nimprove efficiency by more than an order of magnitude compared to conventional\nMCMC methods on highly correlated target distributions such as the\nAutoregressive Process of Order 1 and the Correlated Funnel distribution.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:00:12 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Karamanis", "Minas", ""], ["Beutler", "Florian", ""]]}, {"id": "2002.06215", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh, Jaroslaw Sydir, Meryem Simsek, Hosein Nikopour", "title": "Resource Management in Wireless Networks via Multi-Agent Deep\n  Reinforcement Learning", "comments": "Final version to appear in IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": "10.1109/TWC.2021.3051163", "report-no": null, "categories": "cs.LG cs.IT cs.MA eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mechanism for distributed resource management and interference\nmitigation in wireless networks using multi-agent deep reinforcement learning\n(RL). We equip each transmitter in the network with a deep RL agent that\nreceives delayed observations from its associated users, while also exchanging\nobservations with its neighboring agents, and decides on which user to serve\nand what transmit power to use at each scheduling interval. Our proposed\nframework enables agents to make decisions simultaneously and in a distributed\nmanner, unaware of the concurrent decisions of other agents. Moreover, our\ndesign of the agents' observation and action spaces is scalable, in the sense\nthat an agent trained on a scenario with a specific number of transmitters and\nusers can be applied to scenarios with different numbers of transmitters and/or\nusers. Simulation results demonstrate the superiority of our proposed approach\ncompared to decentralized baselines in terms of the tradeoff between average\nand $5^{th}$ percentile user rates, while achieving performance close to, and\neven in certain cases outperforming, that of a centralized\ninformation-theoretic baseline. We also show that our trained agents are robust\nand maintain their performance gains when experiencing mismatches between train\nand test deployments.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:01:07 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 06:04:45 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Sydir", "Jaroslaw", ""], ["Simsek", "Meryem", ""], ["Nikopour", "Hosein", ""]]}, {"id": "2002.06219", "submitter": "Rafael Derradi De Souza", "authors": "Paulo Finardi, Israel Campiotti, Gustavo Plensack, Rafael Derradi de\n  Souza, Rodrigo Nogueira, Gustavo Pinheiro, Roberto Lotufo", "title": "Electricity Theft Detection with self-attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel self-attention mechanism model to address\nelectricity theft detection on an imbalanced realistic dataset that presents a\ndaily electricity consumption provided by State Grid Corporation of China. Our\nkey contribution is the introduction of a multi-head self-attention mechanism\nconcatenated with dilated convolutions and unified by a convolution of kernel\nsize $1$. Moreover, we introduce a binary input channel (Binary Mask) to\nidentify the position of the missing values, allowing the network to learn how\nto deal with these values. Our model achieves an AUC of $0.926$ which is an\nimprovement in more than $17\\%$ with respect to previous baseline work. The\ncode is available on GitHub at\nhttps://github.com/neuralmind-ai/electricity-theft-detection-with-self-attention.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:11:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Finardi", "Paulo", ""], ["Campiotti", "Israel", ""], ["Plensack", "Gustavo", ""], ["de Souza", "Rafael Derradi", ""], ["Nogueira", "Rodrigo", ""], ["Pinheiro", "Gustavo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "2002.06224", "submitter": "Zhengli Zhao", "authors": "Samarth Sinha, Zhengli Zhao, Anirudh Goyal, Colin Raffel, Augustus\n  Odena", "title": "Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad\n  Samples", "comments": "NeurIPS 2020. Samarth Sinha and Zhengli Zhao contributed equally as\n  joint first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple (one line of code) modification to the Generative\nAdversarial Network (GAN) training algorithm that materially improves results\nwith no increase in computational cost: When updating the generator parameters,\nwe simply zero out the gradient contributions from the elements of the batch\nthat the critic scores as `least realistic'. Through experiments on many\ndifferent GAN variants, we show that this `top-k update' procedure is a\ngenerally applicable improvement. In order to understand the nature of the\nimprovement, we conduct extensive analysis on a simple mixture-of-Gaussians\ndataset and discover several interesting phenomena. Among these is that, when\ngradient updates are computed using the worst-scoring batch elements, samples\ncan actually be pushed further away from their nearest mode. We also apply our\nmethod to recent GAN variants and improve state-of-the-art FID for conditional\ngeneration from 9.21 to 8.57 on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:27:50 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 00:02:08 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 17:43:22 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 21:42:09 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sinha", "Samarth", ""], ["Zhao", "Zhengli", ""], ["Goyal", "Anirudh", ""], ["Raffel", "Colin", ""], ["Odena", "Augustus", ""]]}, {"id": "2002.06226", "submitter": "Amir Mosavi Prof", "authors": "Saeed Samadianfard, Sajjad Hashemi, Katayoun Kargar, Mojtaba Izadyar,\n  Ali Mostafaeipour, Amir Mosavi, Narjes Nabipour, Shahaboddin Shamshirband", "title": "Wind speed prediction using a hybrid model of the multi-layer perceptron\n  and whale optimization algorithm", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wind power as a renewable source of energy, has numerous economic,\nenvironmental and social benefits. In order to enhance and control renewable\nwind power, it is vital to utilize models that predict wind speed with high\naccuracy. Due to neglecting of requirement and significance of data\npreprocessing and disregarding the inadequacy of using a single predicting\nmodel, many traditional models have poor performance in wind speed prediction.\nIn the current study, for predicting wind speed at target stations in the north\nof Iran, the combination of a multi-layer perceptron model (MLP) with the Whale\nOptimization Algorithm (WOA) used to build new method (MLP-WOA) with a limited\nset of data (2004-2014). Then, the MLP-WOA model was utilized at each of the\nten target stations, with the nine stations for training and tenth station for\ntesting (namely: Astara, Bandar-E-Anzali, Rasht, Manjil, Jirandeh, Talesh,\nKiyashahr, Lahijan, Masuleh, and Deylaman) to increase the accuracy of the\nsubsequent hybrid model. The capability of the hybrid model in wind speed\nforecasting at each target station was compared with the MLP model without the\nWOA optimizer. To determine definite results, numerous statistical performances\nwere utilized. For all ten target stations, the MLP-WOA model had precise\noutcomes than the standalone MLP model. The hybrid model had acceptable\nperformances with lower amounts of the RMSE, SI and RE parameters and higher\nvalues of NSE, WI, and KGE parameters. It was concluded that the WOA\noptimization algorithm can improve the prediction accuracy of MLP model and may\nbe recommended for accurate wind speed prediction.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:29:33 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Samadianfard", "Saeed", ""], ["Hashemi", "Sajjad", ""], ["Kargar", "Katayoun", ""], ["Izadyar", "Mojtaba", ""], ["Mostafaeipour", "Ali", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Shamshirband", "Shahaboddin", ""]]}, {"id": "2002.06238", "submitter": "Warren Powell", "authors": "Warren B Powell", "title": "On State Variables, Bandit Problems and POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State variables are easily the most subtle dimension of sequential decision\nproblems. This is especially true in the context of active learning problems\n(bandit problems\") where decisions affect what we observe and learn. We\ndescribe our canonical framework that models {\\it any} sequential decision\nproblem, and present our definition of state variables that allows us to claim:\nAny properly modeled sequential decision problem is Markovian. We then present\na novel two-agent perspective of partially observable Markov decision problems\n(POMDPs) that allows us to then claim: Any model of a real decision problem is\n(possibly) non-Markovian. We illustrate these perspectives using the context of\nobserving and treating flu in a population, and provide examples of all four\nclasses of policies in this setting. We close with an indication of how to\nextend this thinking to multiagent problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:09:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Powell", "Warren B", ""]]}, {"id": "2002.06243", "submitter": "Kei Nakagawa", "authors": "Yusuke Uchiyama, Kei Nakagawa", "title": "TPLVM: Portfolio Construction by Student's $t$-process Latent Variable\n  Model", "comments": null, "journal-ref": null, "doi": "10.3390/math8030449", "report-no": null, "categories": "q-fin.PM cs.LG math.ST q-fin.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal asset allocation is a key topic in modern finance theory. To realize\nthe optimal asset allocation on investor's risk aversion, various portfolio\nconstruction methods have been proposed. Recently, the applications of machine\nlearning are rapidly growing in the area of finance. In this article, we\npropose the Student's $t$-process latent variable model (TPLVM) to describe\nnon-Gaussian fluctuations of financial timeseries by lower dimensional latent\nvariables. Subsequently, we apply the TPLVM to minimum-variance portfolio as an\nalternative of existing nonlinear factor models. To test the performance of the\nproposed portfolio, we construct minimum-variance portfolios of global stock\nmarket indices based on the TPLVM or Gaussian process latent variable model. By\ncomparing these portfolios, we confirm the proposed portfolio outperforms that\nof the existing Gaussian process latent variable model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 02:02:02 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Uchiyama", "Yusuke", ""], ["Nakagawa", "Kei", ""]]}, {"id": "2002.06247", "submitter": "Julien Grand-Cl\\'ement", "authors": "Julien Grand-Clement, Carri W. Chan, Vineet Goyal, Gabriel Escobar", "title": "Robust Policies For Proactive ICU Transfers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients whose transfer to the Intensive Care Unit (ICU) is unplanned are\nprone to higher mortality rates than those who were admitted directly to the\nICU. Recent advances in machine learning to predict patient deterioration have\nintroduced the possibility of \\emph{proactive transfer} from the ward to the\nICU. In this work, we study the problem of finding \\emph{robust} patient\ntransfer policies which account for uncertainty in statistical estimates due to\ndata limitations when optimizing to improve overall patient care. We propose a\nMarkov Decision Process model to capture the evolution of patient health, where\nthe states represent a measure of patient severity. Under fairly general\nassumptions, we show that an optimal transfer policy has a threshold structure,\ni.e., that it transfers all patients above a certain severity level to the ICU\n(subject to available capacity). As model parameters are typically determined\nbased on statistical estimations from real-world data, they are inherently\nsubject to misspecification and estimation errors. We account for this\nparameter uncertainty by deriving a robust policy that optimizes the worst-case\nreward across all plausible values of the model parameters. We show that the\nrobust policy also has a threshold structure under fairly general assumptions.\nMoreover, it is more aggressive in transferring patients than the optimal\nnominal policy, which does not take into account parameter uncertainty. We\npresent computational experiments using a dataset of hospitalizations at 21\nKNPC hospitals, and present empirical evidence of the sensitivity of various\nhospital metrics (mortality, length-of-stay, average ICU occupancy) to small\nchanges in the parameters. Our work provides useful insights into the impact of\nparameter uncertainty on deriving simple policies for proactive ICU transfer\nthat have strong empirical performance and theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:07:15 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 21:00:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Grand-Clement", "Julien", ""], ["Chan", "Carri W.", ""], ["Goyal", "Vineet", ""], ["Escobar", "Gabriel", ""]]}, {"id": "2002.06262", "submitter": "Kaixuan Huang", "authors": "Kaixuan Huang, Yuqing Wang, Molei Tao, Tuo Zhao", "title": "Why Do Deep Residual Networks Generalize Better than Deep Feedforward\n  Networks? -- A Neural Tangent Kernel Perspective", "comments": "Accepted in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual networks (ResNets) have demonstrated better generalization\nperformance than deep feedforward networks (FFNets). However, the theory behind\nsuch a phenomenon is still largely unknown. This paper studies this fundamental\nproblem in deep learning from a so-called \"neural tangent kernel\" perspective.\nSpecifically, we first show that under proper conditions, as the width goes to\ninfinity, training deep ResNets can be viewed as learning reproducing kernel\nfunctions with some kernel function. We then compare the kernel of deep ResNets\nwith that of deep FFNets and discover that the class of functions induced by\nthe kernel of FFNets is asymptotically not learnable, as the depth goes to\ninfinity. In contrast, the class of functions induced by the kernel of ResNets\ndoes not exhibit such degeneracy. Our discovery partially justifies the\nadvantages of deep ResNets over deep FFNets in generalization abilities.\nNumerical results are provided to support our claim.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:53:58 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 08:47:38 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Huang", "Kaixuan", ""], ["Wang", "Yuqing", ""], ["Tao", "Molei", ""], ["Zhao", "Tuo", ""]]}, {"id": "2002.06277", "submitter": "Joan Bruna", "authors": "Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff,\n  Joan Bruna", "title": "A mean-field analysis of two-player zero-sum games", "comments": null, "journal-ref": "Published at NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding Nash equilibria in two-player zero-sum continuous games is a central\nproblem in machine learning, e.g. for training both GANs and robust models. The\nexistence of pure Nash equilibria requires strong conditions which are not\ntypically met in practice. Mixed Nash equilibria exist in greater generality\nand may be found using mirror descent. Yet this approach does not scale to high\ndimensions. To address this limitation, we parametrize mixed strategies as\nmixtures of particles, whose positions and weights are updated using gradient\ndescent-ascent. We study this dynamics as an interacting gradient flow over\nmeasure spaces endowed with the Wasserstein-Fisher-Rao metric. We establish\nglobal convergence to an approximate equilibrium for the related Langevin\ngradient-ascent dynamic. We prove a law of large numbers that relates particle\ndynamics to mean-field dynamics. Our method identifies mixed equilibria in high\ndimensions and is demonstrably effective for training mixtures of GANs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:46:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:17:14 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 14:26:56 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 14:02:00 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Domingo-Enrich", "Carles", ""], ["Jelassi", "Samy", ""], ["Mensch", "Arthur", ""], ["Rotskoff", "Grant", ""], ["Bruna", "Joan", ""]]}, {"id": "2002.06278", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Bernhard Sch\\\"olkopf, Isabel Valera", "title": "Algorithmic Recourse: from Counterfactual Explanations to Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to inform consequential\ndecision-making (e.g., pre-trial bail and loan approval), it becomes important\nto explain how the system arrived at its decision, and also suggest actions to\nachieve a favorable decision. Counterfactual explanations -- \"how the world\nwould have (had) to be different for a desirable outcome to occur\" -- aim to\nsatisfy these criteria. Existing works have primarily focused on designing\nalgorithms to obtain counterfactual explanations for a wide range of settings.\nHowever, one of the main objectives of \"explanations as a means to help a\ndata-subject act rather than merely understand\" has been overlooked. In\nlayman's terms, counterfactual explanations inform an individual where they\nneed to get to, but not how to get there. In this work, we rely on causal\nreasoning to caution against the use of counterfactual explanations as a\nrecommendable set of actions for recourse. Instead, we propose a shift of\nparadigm from recourse via nearest counterfactual explanations to recourse\nthrough minimal interventions, moving the focus from explanations to\nrecommendations. Finally, we provide the reader with an extensive discussion on\nhow to realistically achieve recourse beyond structural interventions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:49:42 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:48:42 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:19:02 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 15:15:33 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Valera", "Isabel", ""]]}, {"id": "2002.06285", "submitter": "Bryan Bischof Dr.", "authors": "Bryan Bischof", "title": "Higher order co-occurrence tensors for hypergraphs via face-splitting", "comments": "8 pages, 1 figure, examples in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular trick for computing a pairwise co-occurrence matrix is the product\nof an incidence matrix and its transpose. We present an analog for higher order\ntuple co-occurrences using the face-splitting product, or alternately known as\nthe transpose Khatri-Rao product. These higher order co-occurrences encode the\ncommonality of tokens in the company of other tokens, and thus generalize the\nmutual information commonly studied. We demonstrate this tensor's use via a\npopular NLP model, and hypergraph models of similarity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:16:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bischof", "Bryan", ""]]}, {"id": "2002.06286", "submitter": "Huaqing Xiong", "authors": "Huaqing Xiong, Tengyu Xu, Yingbin Liang, Wei Zhang", "title": "Non-asymptotic Convergence of Adam-type Reinforcement Learning\n  Algorithms under Markovian Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wide applications of Adam in reinforcement learning (RL), the\ntheoretical convergence of Adam-type RL algorithms has not been established.\nThis paper provides the first such convergence analysis for two fundamental RL\nalgorithms of policy gradient (PG) and temporal difference (TD) learning that\nincorporate AMSGrad updates (a standard alternative of Adam in theoretical\nanalysis), referred to as PG-AMSGrad and TD-AMSGrad, respectively. Moreover,\nour analysis focuses on Markovian sampling for both algorithms. We show that\nunder general nonlinear function approximation, PG-AMSGrad with a constant\nstepsize converges to a neighborhood of a stationary point at the rate of\n$\\mathcal{O}(1/T)$ (where $T$ denotes the number of iterations), and with a\ndiminishing stepsize converges exactly to a stationary point at the rate of\n$\\mathcal{O}(\\log^2 T/\\sqrt{T})$. Furthermore, under linear function\napproximation, TD-AMSGrad with a constant stepsize converges to a neighborhood\nof the global optimum at the rate of $\\mathcal{O}(1/T)$, and with a diminishing\nstepsize converges exactly to the global optimum at the rate of\n$\\mathcal{O}(\\log T/\\sqrt{T})$. Our study develops new techniques for analyzing\nthe Adam-type RL algorithms under Markovian sampling.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:26:49 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:28:43 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xiong", "Huaqing", ""], ["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""], ["Zhang", "Wei", ""]]}, {"id": "2002.06288", "submitter": "Sriram Gopalakrishnan", "authors": "Sriram Gopalakrishnan, Utkarsh Soni", "title": "Let Me At Least Learn What You Really Like: Dealing With Noisy Humans\n  When Learning Preferences", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the preferences of a human improves the quality of the interaction\nwith the human. The number of queries available to learn preferences maybe\nlimited especially when interacting with a human, and so active learning is a\nmust. One approach to active learning is to use uncertainty sampling to decide\nthe informativeness of a query. In this paper, we propose a modification to\nuncertainty sampling which uses the expected output value to help speed up\nlearning of preferences. We compare our approach with the uncertainty sampling\nbaseline, as well as conduct an ablation study to test the validity of each\ncomponent of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:36:23 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gopalakrishnan", "Sriram", ""], ["Soni", "Utkarsh", ""]]}, {"id": "2002.06298", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "Extreme Classification via Adversarial Softmax Approximation", "comments": "Accepted for presentation at the Eighth International Conference on\n  Learning Representations (ICLR 2020),\n  https://openreview.net/forum?id=rJxe3xSYDS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a classifier over a large number of classes, known as 'extreme\nclassification', has become a topic of major interest with applications in\ntechnology, science, and e-commerce. Traditional softmax regression induces a\ngradient cost proportional to the number of classes $C$, which often is\nprohibitively expensive. A popular scalable softmax approximation relies on\nuniform negative sampling, which suffers from slow convergence due a poor\nsignal-to-noise ratio. In this paper, we propose a simple training method for\ndrastically enhancing the gradient signal by drawing negative samples from an\nadversarial model that mimics the data distribution. Our contributions are\nthree-fold: (i) an adversarial sampling mechanism that produces negative\nsamples at a cost only logarithmic in $C$, thus still resulting in cheap\ngradient updates; (ii) a mathematical proof that this adversarial sampling\nminimizes the gradient variance while any bias due to non-uniform sampling can\nbe removed; (iii) experimental results on large scale data sets that show a\nreduction of the training time by an order of magnitude relative to several\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 01:42:52 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "2002.06299", "submitter": "Falcon Dai", "authors": "Falcon Z. Dai, Matthew R. Walter", "title": "Loop Estimator for Discounted Values in Markov Reward Processes", "comments": "accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the working heart of policy iteration algorithms commonly used and studied\nin the discounted setting of reinforcement learning, the policy evaluation step\nestimates the value of states with samples from a Markov reward process induced\nby following a Markov policy in a Markov decision process. We propose a simple\nand efficient estimator called loop estimator that exploits the regenerative\nstructure of Markov reward processes without explicitly estimating a full\nmodel. Our method enjoys a space complexity of $O(1)$ when estimating the value\nof a single positive recurrent state $s$ unlike TD with $O(S)$ or model-based\nmethods with $O\\left(S^2\\right)$. Moreover, the regenerative structure enables\nus to show, without relying on the generative model approach, that the\nestimator has an instance-dependent convergence rate of\n$\\widetilde{O}\\left(\\sqrt{\\tau_s/T}\\right)$ over steps $T$ on a single sample\npath, where $\\tau_s$ is the maximal expected hitting time to state $s$. In\npreliminary numerical experiments, the loop estimator outperforms model-free\nmethods, such as TD(k), and is competitive with the model-based estimator.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 01:42:53 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 17:03:36 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 05:05:36 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Dai", "Falcon Z.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "2002.06306", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Abulhair Saparov and Tom Mitchell", "title": "Jelly Bean World: A Testbed for Never-Ending Learning", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": "International Conference on Learning Representations 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown growing success in recent years. However, current\nmachine learning systems are highly specialized, trained for particular\nproblems or domains, and typically on a single narrow dataset. Human learning,\non the other hand, is highly general and adaptable. Never-ending learning is a\nmachine learning paradigm that aims to bridge this gap, with the goal of\nencouraging researchers to design machine learning systems that can learn to\nperform a wider variety of inter-related tasks in more complex environments. To\ndate, there is no environment or testbed to facilitate the development and\nevaluation of never-ending learning systems. To this end, we propose the Jelly\nBean World testbed. The Jelly Bean World allows experimentation over\ntwo-dimensional grid worlds which are filled with items and in which agents can\nnavigate. This testbed provides environments that are sufficiently complex and\nwhere more generally intelligent algorithms ought to perform better than\ncurrent state-of-the-art reinforcement learning approaches. It does so by\nproducing non-stationary environments and facilitating experimentation with\nmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hope\nthat this new freely-available software will prompt new research and interest\nin the development and evaluation of never-ending learning systems and more\nbroadly, general intelligence systems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 02:43:16 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Saparov", "Abulhair", ""], ["Mitchell", "Tom", ""]]}, {"id": "2002.06336", "submitter": "Avishek Bose", "authors": "Avishek Joey Bose, Ariella Smofsky, Renjie Liao, Prakash Panangaden,\n  and William L. Hamilton", "title": "Latent Variable Modelling with Hyperbolic Normalizing Flows", "comments": "Preprint, work under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of approximate posterior distributions plays a central role in\nstochastic variational inference (SVI). One effective solution is the use of\nnormalizing flows \\cut{defined on Euclidean spaces} to construct flexible\nposterior distributions. However, one key limitation of existing normalizing\nflows is that they are restricted to the Euclidean space and are ill-equipped\nto model data with an underlying hierarchical structure. To address this\nfundamental limitation, we present the first extension of normalizing flows to\nhyperbolic spaces. We first elevate normalizing flows to hyperbolic spaces\nusing coupling transforms defined on the tangent bundle, termed Tangent\nCoupling ($\\mathcal{TC}$). We further introduce Wrapped Hyperboloid Coupling\n($\\mathcal{W}\\mathbb{H}C$), a fully invertible and learnable transformation\nthat explicitly utilizes the geometric structure of hyperbolic spaces, allowing\nfor expressive posteriors while being efficient to sample from. We demonstrate\nthe efficacy of our novel normalizing flow over hyperbolic VAEs and Euclidean\nnormalizing flows. Our approach achieves improved performance on density\nestimation, as well as reconstruction of real-world graph data, which exhibit a\nhierarchical structure. Finally, we show that our approach can be used to power\na generative model over hierarchical data using hyperbolic latent variables.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 07:44:00 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 03:56:12 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 15:51:14 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 05:04:01 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Smofsky", "Ariella", ""], ["Liao", "Renjie", ""], ["Panangaden", "Prakash", ""], ["Hamilton", "William L.", ""]]}, {"id": "2002.06337", "submitter": "Taejoon Byun", "authors": "Taejoon Byun, Abhishek Vijayakumar, Sanjai Rayadurgam, Darren Cofer", "title": "Manifold-based Test Generation for Image Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks used for image classification tasks in critical applications\nmust be tested with sufficient realistic data to assure their correctness. To\neffectively test an image classification neural network, one must obtain\nrealistic test data adequate enough to inspire confidence that differences\nbetween the implicit requirements and the learned model would be exposed. This\nraises two challenges: first, an adequate subset of the data points must be\ncarefully chosen to inspire confidence, and second, the implicit requirements\nmust be meaningfully extrapolated to data points beyond those in the explicit\ntraining set. This paper proposes a novel framework to address these\nchallenges. Our approach is based on the premise that patterns in a large input\ndata space can be effectively captured in a smaller manifold space, from which\nsimilar yet novel test cases---both the input and the label---can be sampled\nand generated. A variant of Conditional Variational Autoencoder (CVAE) is used\nfor capturing this manifold with a generative function, and a search technique\nis applied on this manifold space to efficiently find fault-revealing inputs.\nExperiments show that this approach enables generation of thousands of\nrealistic yet fault-revealing test cases efficiently even for well-trained\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 07:53:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Byun", "Taejoon", ""], ["Vijayakumar", "Abhishek", ""], ["Rayadurgam", "Sanjai", ""], ["Cofer", "Darren", ""]]}, {"id": "2002.06349", "submitter": "Apostolos Modas", "authors": "Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen\n  Moosavi-Dezfooli, Pascal Frossard", "title": "Hold me tight! Influence of discriminative features on deep network\n  boundaries", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS) 2020 (30 pages, 38 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important insights towards the explainability of neural networks reside in\nthe characteristics of their decision boundaries. In this work, we borrow tools\nfrom the field of adversarial robustness, and propose a new perspective that\nrelates dataset features to the distance of samples to the decision boundary.\nThis enables us to carefully tweak the position of the training samples and\nmeasure the induced changes on the boundaries of CNNs trained on large-scale\nvision datasets. We use this framework to reveal some intriguing properties of\nCNNs. Specifically, we rigorously confirm that neural networks exhibit a high\ninvariance to non-discriminative features, and show that the decision\nboundaries of a DNN can only exist as long as the classifier is trained with\nsome features that hold them together. Finally, we show that the construction\nof the decision boundary is extremely sensitive to small perturbations of the\ntraining samples, and that changes in certain directions can lead to sudden\ninvariances in the orthogonal ones. This is precisely the mechanism that\nadversarial training uses to achieve robustness.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 09:29:36 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:42:50 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 12:08:17 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 07:16:47 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ortiz-Jimenez", "Guillermo", ""], ["Modas", "Apostolos", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "2002.06358", "submitter": "Tiangang Cui", "authors": "Johnathan Bardsley, Tiangang Cui", "title": "Optimization-Based MCMC Methods for Nonlinear Hierarchical Statistical\n  Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many hierarchical inverse problems, not only do we want to estimate high-\nor infinite-dimensional model parameters in the parameter-to-observable maps,\nbut we also have to estimate hyperparameters that represent critical\nassumptions in the statistical and mathematical modeling processes. As a joint\neffect of high-dimensionality, nonlinear dependence, and non-concave structures\nin the joint posterior posterior distribution over model parameters and\nhyperparameters, solving inverse problems in the hierarchical Bayesian setting\nposes a significant computational challenge. In this work, we aim to develop\nscalable optimization-based Markov chain Monte Carlo (MCMC) methods for solving\nhierarchical Bayesian inverse problems with nonlinear parameter-to-observable\nmaps and a broader class of hyperparameters. Our algorithmic development is\nbased on the recently developed scalable randomize-then-optimize (RTO) method\n[4] for exploring the high- or infinite-dimensional model parameter space. By\nusing RTO either as a proposal distribution in a Metropolis-within-Gibbs update\nor as a biasing distribution in the pseudo-marginal MCMC [2], we are able to\ndesign efficient sampling tools for hierarchical Bayesian inversion. In\nparticular, the integration of RTO and the pseudo-marginal MCMC has sampling\nperformance robust to model parameter dimensions. We also extend our methods to\nnonlinear inverse problems with Poisson-distributed measurements. Numerical\nexamples in PDE-constrained inverse problems and positron emission tomography\n(PET) are used to demonstrate the performance of our methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 10:19:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bardsley", "Johnathan", ""], ["Cui", "Tiangang", ""]]}, {"id": "2002.06372", "submitter": "Kirill Akhmetzyanov", "authors": "Kirill Akhmetzyanov, Alexander Yuzhakov", "title": "Multi-Task Multicriteria Hyperparameter Optimization", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for searching optimal hyperparameters among several\ntasks and several criteria. Multi-Task Multi Criteria method (MTMC) provides\nseveral Pareto-optimal solutions, among which one solution is selected with\ngiven criteria significance coefficients. The article begins with a\nmathematical formulation of the problem of choosing optimal hyperparameters.\nThen, the steps of the MTMC method that solves this problem are described. The\nproposed method is evaluated on the image classification problem using a\nconvolutional neural network. The article presents optimal hyperparameters for\nvarious criteria significance coefficients.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 12:47:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Akhmetzyanov", "Kirill", ""], ["Yuzhakov", "Alexander", ""]]}, {"id": "2002.06382", "submitter": "Cefas Rodrigues Freire", "authors": "Cefas Rodrigues Freire, Julio Cesar da Costa Moura, Daniele Montenegro\n  da Silva Barros and Ricardo Alexsandro de Medeiros Valentim", "title": "Automatic lesion segmentation and Pathological Myopia classification in\n  fundus images", "comments": "ISBI 2019 PALM Challenge Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present algorithms to diagnosis Pathological Myopia (PM) and\ndetection of retinal structures and lesions such asOptic Disc (OD), Fovea,\nAtrophy and Detachment. All these tasks were performed in fundus imaging from\nPM patients and they are requirements to participate in the Pathologic Myopia\nChallenge (PALM). The challenge was organized as a half day Challenge, a\nSatellite Event of The IEEE International Symposium on Biomedical Imaging in\nVenice Italy.Our method applies different Deep Learning techniques for each\ntask. Transfer learning is applied in all tasks using Xception as the baseline\nmodel. Also, some key ideas of YOLO architecture are used in the Optic Disc\nsegmentation algorithm pipeline. We have evaluated our model's performance\naccording the challenge rules in terms of AUC-ROC, F1-Score, Mean Dice Score\nand Mean Euclidean Distance. For initial activities our method has shown\nsatisfactory results.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 13:38:30 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Freire", "Cefas Rodrigues", ""], ["Moura", "Julio Cesar da Costa", ""], ["Barros", "Daniele Montenegro da Silva", ""], ["Valentim", "Ricardo Alexsandro de Medeiros", ""]]}, {"id": "2002.06383", "submitter": "Andrew McDole", "authors": "Andrew McDole and Mahmoud Abdelsalam and Maanak Gupta and Sudip Mittal", "title": "Analyzing CNN Based Behavioural Malware Detection Techniques on Cloud\n  IaaS", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59635-4_5", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Infrastructure as a Service (IaaS) is vulnerable to malware due to its\nexposure to external adversaries, making it a lucrative attack vector for\nmalicious actors. A datacenter infected with malware can cause data loss and/or\nmajor disruptions to service for its users. This paper analyzes and compares\nvarious Convolutional Neural Networks (CNNs) for online detection of malware in\ncloud IaaS. The detection is performed based on behavioural data using process\nlevel performance metrics including cpu usage, memory usage, disk usage etc. We\nhave used the state of the art DenseNets and ResNets in effectively detecting\nmalware in online cloud system. CNN are designed to extract features from data\ngathered from a live malware running on a real cloud environment. Experiments\nare performed on OpenStack (a cloud IaaS software) testbed designed to\nreplicate a typical 3-tier web architecture. Comparative analysis is performed\nfor different metrics for different CNN models used in this research.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 14:04:33 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["McDole", "Andrew", ""], ["Abdelsalam", "Mahmoud", ""], ["Gupta", "Maanak", ""], ["Mittal", "Sudip", ""]]}, {"id": "2002.06395", "submitter": "Giuseppe Di Molfetta Prof.", "authors": "Balthazar Casal\\'e, Giuseppe Di Molfetta, Hachem Kadri, Liva Ralaivola", "title": "Quantum Bandits", "comments": "All your comments are very welcome!", "journal-ref": "Quantum Machine Intelligence 2, 1-7 (2020)", "doi": "10.1007/s42484-020-00024-8", "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quantum version of the bandit problem known as {\\em best arm\nidentification} (BAI). We first propose a quantum modeling of the BAI problem,\nwhich assumes that both the learning agent and the environment are quantum; we\nthen propose an algorithm based on quantum amplitude amplification to solve\nBAI. We formally analyze the behavior of the algorithm on all instances of the\nproblem and we show, in particular, that it is able to get the optimal solution\nquadratically faster than what is known to hold in the classical case.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:17:11 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 14:13:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Casal\u00e9", "Balthazar", ""], ["Di Molfetta", "Giuseppe", ""], ["Kadri", "Hachem", ""], ["Ralaivola", "Liva", ""]]}, {"id": "2002.06405", "submitter": "Alexis Marchal", "authors": "Oksana Bashchenko and Alexis Marchal", "title": "Deep Learning for Asset Bubbles Detection", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a methodology for detecting asset bubbles using a neural network.\nWe rely on the theory of local martingales in continuous-time and use a deep\nnetwork to estimate the diffusion coefficient of the price process more\naccurately than the current estimator, obtaining an improved detection of\nbubbles. We show the outperformance of our algorithm over the existing\nstatistical method in a laboratory created with simulated data. We then apply\nthe network classification to real data and build a zero net exposure trading\nstrategy that exploits the risky arbitrage emanating from the presence of\nbubbles in the US equity market from 2006 to 2008. The profitability of the\nstrategy provides an estimation of the economical magnitude of bubbles as well\nas support for the theoretical assumptions relied on.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 16:16:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bashchenko", "Oksana", ""], ["Marchal", "Alexis", ""]]}, {"id": "2002.06410", "submitter": "Song Liu Dr.", "authors": "Song Liu, Yulong Zhang, Mingxuan Yi, Mladen Kolar", "title": "Posterior Ratio Estimation of Latent Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density Ratio Estimation has attracted attention from the machine learning\ncommunity due to its ability to compare the underlying distributions of two\ndatasets. However, in some applications, we want to compare distributions of\nrandom variables that are \\emph{inferred} from observations. In this paper, we\nstudy the problem of estimating the ratio between two posterior probability\ndensity functions of a latent variable. Particularly, we assume the posterior\nratio function can be well-approximated by a parametric model, which is then\nestimated using observed information and prior samples. We prove the\nconsistency of our estimator and the asymptotic normality of the estimated\nparameters as the number of prior samples tending to infinity. Finally, we\nvalidate our theories using numerical experiments and demonstrate the\nusefulness of the proposed method through some real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 16:46:42 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 17:49:50 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Liu", "Song", ""], ["Zhang", "Yulong", ""], ["Yi", "Mingxuan", ""], ["Kolar", "Mladen", ""]]}, {"id": "2002.06436", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "MRRC: Multiple Role Representation Crossover Interpretation for Image\n  Captioning With R-CNN Feature Distribution Composition (FDC)", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While image captioning through machines requires structured learning and\nbasis for interpretation, improvement requires multiple context understanding\nand processing in a meaningful way. This research will provide a novel concept\nfor context combination and will impact many applications to deal visual\nfeatures as an equivalence of descriptions of objects, activities and events.\nThere are three components of our architecture: Feature Distribution\nComposition (FDC) Layer Attention, Multiple Role Representation Crossover\n(MRRC) Attention Layer and the Language Decoder. FDC Layer Attention helps in\ngenerating the weighted attention from RCNN features, MRRC Attention Layer acts\nas intermediate representation processing and helps in generating the next word\nattention, while Language Decoder helps in estimation of the likelihood for the\nnext probable word in the sentence. We demonstrated effectiveness of FDC, MRRC,\nregional object feature attention and reinforcement learning for effective\nlearning to generate better captions from images. The performance of our model\nenhanced previous performances by 35.3\\% and created a new standard and theory\nfor representation generation based on logic, better interpretability and\ncontexts.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 19:45:22 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2002.06440", "submitter": "Hongyi Wang", "authors": "Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos,\n  Yasaman Khazaeni", "title": "Federated Learning with Matched Averaging", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning allows edge devices to collaboratively learn a shared\nmodel while keeping the training data on device, decoupling the ability to do\nmodel training from the need to store the data in the cloud. We propose\nFederated matched averaging (FedMA) algorithm designed for federated learning\nof modern neural network architectures e.g. convolutional neural networks\n(CNNs) and LSTMs. FedMA constructs the shared global model in a layer-wise\nmanner by matching and averaging hidden elements (i.e. channels for convolution\nlayers; hidden states for LSTM; neurons for fully connected layers) with\nsimilar feature extraction signatures. Our experiments indicate that FedMA not\nonly outperforms popular state-of-the-art federated learning algorithms on deep\nCNN and LSTM architectures trained on real world datasets, but also reduces the\noverall communication burden.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 20:09:24 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Hongyi", ""], ["Yurochkin", "Mikhail", ""], ["Sun", "Yuekai", ""], ["Papailiopoulos", "Dimitris", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2002.06442", "submitter": "Chuan Xiao", "authors": "Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang,\n  and Makoto Onizuka", "title": "Monotonic Cardinality Estimation of Similarity Selection: A Deep\n  Learning Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3318464.3380570", "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the outstanding capability of capturing underlying data distributions,\ndeep learning techniques have been recently utilized for a series of\ntraditional database problems. In this paper, we investigate the possibilities\nof utilizing deep learning for cardinality estimation of similarity selection.\nAnswering this problem accurately and efficiently is essential to many data\nmanagement applications, especially for query optimization. Moreover, in some\napplications the estimated cardinality is supposed to be consistent and\ninterpretable. Hence a monotonic estimation w.r.t. the query threshold is\npreferred. We propose a novel and generic method that can be applied to any\ndata type and distance function. Our method consists of a feature extraction\nmodel and a regression model. The feature extraction model transforms original\ndata and threshold to a Hamming space, in which a deep learning-based\nregression model is utilized to exploit the incremental property of cardinality\nw.r.t. the threshold for both accuracy and monotonicity. We develop a training\nstrategy tailored to our model as well as techniques for fast estimation. We\nalso discuss how to handle updates. We demonstrate the accuracy and the\nefficiency of our method through experiments, and show how it improves the\nperformance of a query optimizer.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 20:22:51 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 15:54:07 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 19:04:19 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Wang", "Yaoshu", ""], ["Xiao", "Chuan", ""], ["Qin", "Jianbin", ""], ["Cao", "Xin", ""], ["Sun", "Yifang", ""], ["Wang", "Wei", ""], ["Onizuka", "Makoto", ""]]}, {"id": "2002.06460", "submitter": "Alfredo Kalaitzis", "authors": "Michel Deudon, Alfredo Kalaitzis, Israel Goytom, Md Rifat Arefin,\n  Zhichao Lin, Kris Sankaran, Vincent Michalski, Samira E. Kahou, Julien\n  Cornebise, Yoshua Bengio", "title": "HighRes-net: Recursive Fusion for Multi-Frame Super-Resolution of\n  Satellite Imagery", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative deep learning has sparked a new wave of Super-Resolution (SR)\nalgorithms that enhance single images with impressive aesthetic results, albeit\nwith imaginary details. Multi-frame Super-Resolution (MFSR) offers a more\ngrounded approach to the ill-posed problem, by conditioning on multiple\nlow-resolution views. This is important for satellite monitoring of human\nimpact on the planet -- from deforestation, to human rights violations -- that\ndepend on reliable imagery. To this end, we present HighRes-net, the first deep\nlearning approach to MFSR that learns its sub-tasks in an end-to-end fashion:\n(i) co-registration, (ii) fusion, (iii) up-sampling, and (iv)\nregistration-at-the-loss. Co-registration of low-resolution views is learned\nimplicitly through a reference-frame channel, with no explicit registration\nmechanism. We learn a global fusion operator that is applied recursively on an\narbitrary number of low-resolution pairs. We introduce a registered loss, by\nlearning to align the SR output to a ground-truth through ShiftNet. We show\nthat by learning deep representations of multiple views, we can super-resolve\nlow-resolution signals and enhance Earth Observation data at scale. Our\napproach recently topped the European Space Agency's MFSR competition on\nreal-world satellite imagery.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:17:47 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Deudon", "Michel", ""], ["Kalaitzis", "Alfredo", ""], ["Goytom", "Israel", ""], ["Arefin", "Md Rifat", ""], ["Lin", "Zhichao", ""], ["Sankaran", "Kris", ""], ["Michalski", "Vincent", ""], ["Kahou", "Samira E.", ""], ["Cornebise", "Julien", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.06469", "submitter": "Murad Tukan", "authors": "Murad Tukan, Cenk Baykal, Dan Feldman, Daniela Rus", "title": "On Coresets for Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient coreset construction algorithm for large-scale\nSupport Vector Machine (SVM) training in Big Data and streaming applications. A\ncoreset is a small, representative subset of the original data points such that\na models trained on the coreset are provably competitive with those trained on\nthe original data set. Since the size of the coreset is generally much smaller\nthan the original set, our preprocess-then-train scheme has potential to lead\nto significant speedups when training SVM models. We prove lower and upper\nbounds on the size of the coreset required to obtain small data summaries for\nthe SVM problem. As a corollary, we show that our algorithm can be used to\nextend the applicability of any off-the-shelf SVM solver to streaming,\ndistributed, and dynamic data settings. We evaluate the performance of our\nalgorithm on real-world and synthetic data sets. Our experimental results\nreaffirm the favorable theoretical properties of our algorithm and demonstrate\nits practical effectiveness in accelerating SVM training.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:25:12 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tukan", "Murad", ""], ["Baykal", "Cenk", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "2002.06470", "submitter": "Arsenii Ashukha", "authors": "Arsenii Ashukha, Alexander Lyzhov, Dmitry Molchanov, Dmitry Vetrov", "title": "Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep\n  Learning", "comments": null, "journal-ref": "Eighth International Conference on Learning Representations (ICLR\n  2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation and ensembling methods go hand-in-hand. Uncertainty\nestimation is one of the main benchmarks for assessment of ensembling\nperformance. At the same time, deep learning ensembles have provided\nstate-of-the-art results in uncertainty estimation. In this work, we focus on\nin-domain uncertainty for image classification. We explore the standards for\nits quantification and point out pitfalls of existing metrics. Avoiding these\npitfalls, we perform a broad study of different ensembling techniques. To\nprovide more insight in this study, we introduce the deep ensemble equivalent\nscore (DEE) and show that many sophisticated ensembling techniques are\nequivalent to an ensemble of only few independently trained networks in terms\nof test performance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:28:19 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:47:14 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 16:44:09 GMT"}, {"version": "v4", "created": "Sun, 18 Jul 2021 16:17:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ashukha", "Arsenii", ""], ["Lyzhov", "Alexander", ""], ["Molchanov", "Dmitry", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2002.06473", "submitter": "Yannick Schroecker", "authors": "Yannick Schroecker, Charles Isbell", "title": "Universal Value Density Estimation for Imitation Learning and\n  Goal-Conditioned Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers two distinct settings: imitation learning and\ngoal-conditioned reinforcement learning. In either case, effective solutions\nrequire the agent to reliably reach a specified state (a goal), or set of\nstates (a demonstration). Drawing a connection between probabilistic long-term\ndynamics and the desired value function, this work introduces an approach which\nutilizes recent advances in density estimation to effectively learn to reach a\ngiven state. As our first contribution, we use this approach for\ngoal-conditioned reinforcement learning and show that it is both efficient and\ndoes not suffer from hindsight bias in stochastic domains. As our second\ncontribution, we extend the approach to imitation learning and show that it\nachieves state-of-the art demonstration sample-efficiency on standard benchmark\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:46:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Schroecker", "Yannick", ""], ["Isbell", "Charles", ""]]}, {"id": "2002.06476", "submitter": "Ari Azarafrooz", "authors": "Ari Azarafrooz", "title": "Follow the Neurally-Perturbed Leader for Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game-theoretic models of learning are a powerful set of models that optimize\nmulti-objective architectures. Among these models are zero-sum architectures\nthat have inspired adversarial learning frameworks. An important shortcoming of\nthese zeros-sum architectures is that gradient-based training leads to weak\nconvergence and cyclic dynamics.\n  We propose a novel follow the leader training algorithm for zeros-sum\narchitectures that guarantees convergence to mixed Nash equilibrium without\ncyclic behaviors. It is a special type of follow the perturbed leader algorithm\nwhere perturbations are the result of a neural mediating agent.\n  We validate our theoretical results by applying this training algorithm to\ngames with convex and non-convex loss as well as generative adversarial\narchitectures. Moreover, we customize the implementation of this algorithm for\nadversarial imitation learning applications. At every step of the training, the\nmediator agent perturbs the observations with generated codes. As a result of\nthese mediating codes, the proposed algorithm is also efficient for learning in\nenvironments with various factors of variations. We validate our assertion by\nusing a procedurally generated game environment as well as synthetic data.\nGithub implementation is available.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:09:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 04:54:53 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Azarafrooz", "Ari", ""]]}, {"id": "2002.06482", "submitter": "Jun Shu", "authors": "Jun Shu, Qian Zhao, Keyu Chen, Zongben Xu, Deyu Meng", "title": "Learning Adaptive Loss for Robust Learning with Noisy Labels", "comments": "10pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust loss minimization is an important strategy for handling robust\nlearning issue on noisy labels. Current robust loss functions, however,\ninevitably involve hyperparameter(s) to be tuned, manually or heuristically\nthrough cross validation, which makes them fairly hard to be generally applied\nin practice. Besides, the non-convexity brought by the loss as well as the\ncomplicated network architecture makes it easily trapped into an unexpected\nsolution with poor generalization capability. To address above issues, we\npropose a meta-learning method capable of adaptively learning hyperparameter in\nrobust loss functions. Specifically, through mutual amelioration between robust\nloss hyperparameter and network parameters in our method, both of them can be\nsimultaneously finely learned and coordinated to attain solutions with good\ngeneralization capability. Four kinds of SOTA robust loss functions are\nattempted to be integrated into our algorithm, and comprehensive experiments\nsubstantiate the general availability and effectiveness of the proposed method\nin both its accuracy and generalization performance, as compared with\nconventional hyperparameter tuning strategy, even with carefully tuned\nhyperparameters.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:53:37 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Shu", "Jun", ""], ["Zhao", "Qian", ""], ["Chen", "Keyu", ""], ["Xu", "Zongben", ""], ["Meng", "Deyu", ""]]}, {"id": "2002.06501", "submitter": "Hikaru Ogura", "authors": "Hikaru Ogura and Akiko Takeda", "title": "Convex Fairness Constrained Model Using Causal Effect Estimators", "comments": "10 pages, 5 figures, Accepted for the 2nd Workshop on Fairness,\n  Accountability, Transparency, Ethics and Society on the Web (FATES on the Web\n  2020), held in conjunction with the WWW'20", "journal-ref": null, "doi": "10.1145/3366424.3383556", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen much research on fairness in machine learning. Here,\nmean difference (MD) or demographic parity is one of the most popular measures\nof fairness. However, MD quantifies not only discrimination but also\nexplanatory bias which is the difference of outcomes justified by explanatory\nfeatures. In this paper, we devise novel models, called FairCEEs, which remove\ndiscrimination while keeping explanatory bias. The models are based on\nestimators of causal effect utilizing propensity score analysis. We prove that\nFairCEEs with the squared loss theoretically outperform a naive MD constraint\nmodel. We provide an efficient algorithm for solving FairCEEs in regression and\nbinary classification tasks. In our experiment on synthetic and real-world data\nin these two tasks, FairCEEs outperformed an existing model that considers\nexplanatory bias in specific cases.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 03:40:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ogura", "Hikaru", ""], ["Takeda", "Akiko", ""]]}, {"id": "2002.06504", "submitter": "Yujia Xie", "authors": "Yujia Xie, Hanjun Dai, Minshuo Chen, Bo Dai, Tuo Zhao, Hongyuan Zha,\n  Wei Wei, Tomas Pfister", "title": "Differentiable Top-k Operator with Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top-k operation, i.e., finding the k largest or smallest elements from a\ncollection of scores, is an important model component, which is widely used in\ninformation retrieval, machine learning, and data mining. However, if the top-k\noperation is implemented in an algorithmic way, e.g., using bubble algorithm,\nthe resulting model cannot be trained in an end-to-end way using prevalent\ngradient descent algorithms. This is because these implementations typically\ninvolve swapping indices, whose gradient cannot be computed. Moreover, the\ncorresponding mapping from the input scores to the indicator vector of whether\nthis element belongs to the top-k set is essentially discontinuous. To address\nthe issue, we propose a smoothed approximation, namely the SOFT (Scalable\nOptimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT\ntop-k operator approximates the output of the top-k operation as the solution\nof an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT\noperator can then be efficiently approximated based on the optimality\nconditions of EOT problem. We apply the proposed operator to the k-nearest\nneighbors and beam search algorithms, and demonstrate improved performance.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:57:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 18:56:09 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xie", "Yujia", ""], ["Dai", "Hanjun", ""], ["Chen", "Minshuo", ""], ["Dai", "Bo", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""], ["Wei", "Wei", ""], ["Pfister", "Tomas", ""]]}, {"id": "2002.06505", "submitter": "Kai Fong Ernest Chong", "authors": "Kai Fong Ernest Chong", "title": "A closer look at the approximation capabilities of neural networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The universal approximation theorem, in one of its most general versions,\nsays that if we consider only continuous activation functions $\\sigma$, then a\nstandard feedforward neural network with one hidden layer is able to\napproximate any continuous multivariate function $f$ to any given approximation\nthreshold $\\varepsilon$, if and only if $\\sigma$ is non-polynomial. In this\npaper, we give a direct algebraic proof of the theorem. Furthermore we shall\nexplicitly quantify the number of hidden units required for approximation.\nSpecifically, if $X\\subseteq \\mathbb{R}^n$ is compact, then a neural network\nwith $n$ input units, $m$ output units, and a single hidden layer with\n$\\binom{n+d}{d}$ hidden units (independent of $m$ and $\\varepsilon$), can\nuniformly approximate any polynomial function $f:X \\to \\mathbb{R}^m$ whose\ntotal degree is at most $d$ for each of its $m$ coordinate functions. In the\ngeneral case that $f$ is any continuous function, we show there exists some\n$N\\in \\mathcal{O}(\\varepsilon^{-n})$ (independent of $m$), such that $N$ hidden\nunits would suffice to approximate $f$. We also show that this uniform\napproximation property (UAP) still holds even under seemingly strong conditions\nimposed on the weights. We highlight several consequences: (i) For any $\\delta\n> 0$, the UAP still holds if we restrict all non-bias weights $w$ in the last\nlayer to satisfy $|w| < \\delta$. (ii) There exists some $\\lambda>0$ (depending\nonly on $f$ and $\\sigma$), such that the UAP still holds if we restrict all\nnon-bias weights $w$ in the first layer to satisfy $|w|>\\lambda$. (iii) If the\nnon-bias weights in the first layer are \\emph{fixed} and randomly chosen from a\nsuitable range, then the UAP holds with probability $1$.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:58:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chong", "Kai Fong Ernest", ""]]}, {"id": "2002.06506", "submitter": "Yiming Zhang", "authors": "Yiming Zhang, Quan Vuong, Keith W. Ross", "title": "First Order Constrained Optimization in Policy Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, an agent attempts to learn high-performing\nbehaviors through interacting with the environment, such behaviors are often\nquantified in the form of a reward function. However some aspects of\nbehavior-such as ones which are deemed unsafe and to be avoided-are best\ncaptured through constraints. We propose a novel approach called First Order\nConstrained Optimization in Policy Space (FOCOPS) which maximizes an agent's\noverall reward while ensuring the agent satisfies a set of cost constraints.\nUsing data generated from the current policy, FOCOPS first finds the optimal\nupdate policy by solving a constrained optimization problem in the\nnonparameterized policy space. FOCOPS then projects the update policy back into\nthe parametric policy space. Our approach has an approximate upper bound for\nworst-case constraint violation throughout training and is first-order in\nnature therefore simple to implement. We provide empirical evidence that our\nsimple approach achieves better performance on a set of constrained robotics\nlocomotive tasks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 05:07:17 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 15:35:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Yiming", ""], ["Vuong", "Quan", ""], ["Ross", "Keith W.", ""]]}, {"id": "2002.06508", "submitter": "Tongliang Liu", "authors": "Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Nannan\n  Wang, Haifeng Liu, Gang Niu", "title": "Multi-Class Classification from Noisy-Similarity-Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A similarity label indicates whether two instances belong to the same class\nwhile a class label shows the class of the instance. Without class labels, a\nmulti-class classifier could be learned from similarity-labeled pairwise data\nby meta classification learning. However, since the similarity label is less\ninformative than the class label, it is more likely to be noisy. Deep neural\nnetworks can easily remember noisy data, leading to overfitting in\nclassification. In this paper, we propose a method for learning from only\nnoisy-similarity-labeled data. Specifically, to model the noise, we employ a\nnoise transition matrix to bridge the class-posterior probability between clean\nand noisy data. We further estimate the transition matrix from only noisy data\nand build a novel learning system to learn a classifier which can assign\nnoise-free class labels for instances. Moreover, we theoretically justify how\nour proposed method generalizes for learning classifiers. Experimental results\ndemonstrate the superiority of the proposed method over the state-of-the-art\nmethod on benchmark-simulated and real-world noisy-label datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 05:10:21 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wu", "Songhua", ""], ["Xia", "Xiaobo", ""], ["Liu", "Tongliang", ""], ["Han", "Bo", ""], ["Gong", "Mingming", ""], ["Wang", "Nannan", ""], ["Liu", "Haifeng", ""], ["Niu", "Gang", ""]]}, {"id": "2002.06517", "submitter": "Kyungsu Kim", "authors": "Hyungjun Kim, Kyungsu Kim, Jinseok Kim, Jae-Joon Kim", "title": "BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by\n  Coupling Binary Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) have been garnering interest thanks to their\ncompute cost reduction and memory savings. However, BNNs suffer from\nperformance degradation mainly due to the gradient mismatch caused by\nbinarizing activations. Previous works tried to address the gradient mismatch\nproblem by reducing the discrepancy between activation functions used at\nforward pass and its differentiable approximation used at backward pass, which\nis an indirect measure. In this work, we use the gradient of smoothed loss\nfunction to better estimate the gradient mismatch in quantized neural network.\nAnalysis using the gradient mismatch estimator indicates that using higher\nprecision for activation is more effective than modifying the differentiable\napproximation of activation function. Based on the observation, we propose a\nnew training scheme for binary activation networks called BinaryDuo in which\ntwo binary activations are coupled into a ternary activation during training.\nExperimental results show that BinaryDuo outperforms state-of-the-art BNNs on\nvarious benchmarks with the same amount of parameters and computing cost.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 06:18:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kim", "Hyungjun", ""], ["Kim", "Kyungsu", ""], ["Kim", "Jinseok", ""], ["Kim", "Jae-Joon", ""]]}, {"id": "2002.06524", "submitter": "Chanwoo Lee", "authors": "Chanwoo Lee, Miaoyan Wang", "title": "Tensor denoising and completion based on ordinal observations", "comments": "35 pages, 6 figures", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning(ICML), 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order tensors arise frequently in applications such as neuroimaging,\nrecommendation system, social network analysis, and psychological studies. We\nconsider the problem of low-rank tensor estimation from possibly incomplete,\nordinal-valued observations. Two related problems are studied, one on tensor\ndenoising and the other on tensor completion. We propose a multi-linear\ncumulative link model, develop a rank-constrained M-estimator, and obtain\ntheoretical accuracy guarantees. Our mean squared error bound enjoys a faster\nconvergence rate than previous results, and we show that the proposed estimator\nis minimax optimal under the class of low-rank models. Furthermore, the\nprocedure developed serves as an efficient completion method which guarantees\nconsistent recovery of an order-$K$ $(d,\\ldots,d)$-dimensional low-rank tensor\nusing only $\\tilde{\\mathcal{O}}(Kd)$ noisy, quantized observations. We\ndemonstrate the outperformance of our approach over previous methods on the\ntasks of clustering and collaborative filtering.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 07:09:56 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 19:01:19 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 00:04:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lee", "Chanwoo", ""], ["Wang", "Miaoyan", ""]]}, {"id": "2002.06532", "submitter": "Disi Ji", "authors": "Disi Ji, Robert L. Logan IV, Padhraic Smyth, Mark Steyvers", "title": "Active Bayesian Assessment for Black-Box Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning have led to increased deployment of\nblack-box classifiers across a wide variety of applications. In many such\nsituations there is a critical need to both reliably assess the performance of\nthese pre-trained models and to perform this assessment in a label-efficient\nmanner (given that labels may be scarce and costly to collect). In this paper,\nwe introduce an active Bayesian approach for assessment of classifier\nperformance to satisfy the desiderata of both reliability and label-efficiency.\nWe begin by developing inference strategies to quantify uncertainty for common\nassessment metrics such as accuracy, misclassification cost, and calibration\nerror. We then propose a general framework for active Bayesian assessment using\ninferred uncertainty to guide efficient selection of instances for labeling,\nenabling better performance assessment with fewer labels. We demonstrate\nsignificant gains from our proposed active Bayesian approach via a series of\nsystematic empirical experiments assessing the performance of modern neural\nclassifiers (e.g., ResNet and BERT) on several standard image and text\nclassification datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 08:08:42 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 06:36:58 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 16:21:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ji", "Disi", ""], ["Logan", "Robert L.", "IV"], ["Smyth", "Padhraic", ""], ["Steyvers", "Mark", ""]]}, {"id": "2002.06540", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Distributed Averaging Methods for Randomized Second Order Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed optimization problems where forming the Hessian is\ncomputationally challenging and communication is a significant bottleneck. We\ndevelop unbiased parameter averaging methods for randomized second order\noptimization that employ sampling and sketching of the Hessian. Existing works\ndo not take the bias of the estimators into consideration, which limits their\napplication to massively parallel computation. We provide closed-form formulas\nfor regularization parameters and step sizes that provably minimize the bias\nfor sketched Newton directions. We also extend the framework of second order\naveraging methods to introduce an unbiased distributed optimization framework\nfor heterogeneous computing systems with varying worker resources.\nAdditionally, we demonstrate the implications of our theoretical findings via\nlarge scale experiments performed on a serverless computing platform.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:01:18 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.06541", "submitter": "Liu Ziyin", "authors": "Liu Ziyin, Blair Chen, Ru Wang, Paul Pu Liang, Ruslan Salakhutdinov,\n  Louis-Philippe Morency, Masahito Ueda", "title": "Learning Not to Learn in the Presence of Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the presence of label noise is a challenging yet important task:\nit is crucial to design models that are robust in the presence of mislabeled\ndatasets. In this paper, we discover that a new class of loss functions called\nthe gambler's loss provides strong robustness to label noise across various\nlevels of corruption. We show that training with this loss function encourages\nthe model to \"abstain\" from learning on the data points with noisy labels,\nresulting in a simple and effective method to improve robustness and\ngeneralization. In addition, we propose two practical extensions of the method:\n1) an analytical early stopping criterion to approximately stop training before\nthe memorization of noisy labels, as well as 2) a heuristic for setting\nhyperparameters which do not require knowledge of the noise corruption rate. We\ndemonstrate the effectiveness of our method by achieving strong results across\nthree image and text classification tasks as compared to existing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:12:27 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ziyin", "Liu", ""], ["Chen", "Blair", ""], ["Wang", "Ru", ""], ["Liang", "Paul Pu", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Ueda", "Masahito", ""]]}, {"id": "2002.06557", "submitter": "Gad Zalcberg", "authors": "Gad Zalcberg and Ami Wiesel", "title": "Fair Principal Component Analysis and Filter Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Fair Principal Component Analysis (FPCA) and search for a low\ndimensional subspace that spans multiple target vectors in a fair manner. FPCA\nis defined as a non-concave maximization of the worst projected target norm\nwithin a given set. The problem arises in filter design in signal processing,\nand when incorporating fairness into dimensionality reduction schemes. The\nstate of the art approach to FPCA is via semidefinite relaxation and involves a\npolynomial yet computationally expensive optimization. To allow scalability, we\npropose to address FPCA using naive sub-gradient descent. We analyze the\nlandscape of the underlying optimization in the case of orthogonal targets. We\nprove that the landscape is benign and that all local minima are globally\noptimal. Interestingly, the SDR approach leads to sub-optimal solutions in this\nsimple case. Finally, we discuss the equivalence between orthogonal FPCA and\nthe design of normalized tight frames.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 11:42:52 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:10:20 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Zalcberg", "Gad", ""], ["Wiesel", "Ami", ""]]}, {"id": "2002.06561", "submitter": "Li Shen", "authors": "Enneng Yang, Xin Xin, Li Shen and Guibing Guo", "title": "Generalized Embedding Machines for Recommender Systems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization machine (FM) is an effective model for feature-based\nrecommendation which utilizes inner product to capture second-order feature\ninteractions. However, one of the major drawbacks of FM is that it couldn't\ncapture complex high-order interaction signals. A common solution is to change\nthe interaction function, such as stacking deep neural networks on the top of\nFM. In this work, we propose an alternative approach to model high-order\ninteraction signals in the embedding level, namely Generalized Embedding\nMachine (GEM). The embedding used in GEM encodes not only the information from\nthe feature itself but also the information from other correlated features.\nUnder such situation, the embedding becomes high-order. Then we can incorporate\nGEM with FM and even its advanced variants to perform feature interactions.\nMore specifically, in this paper we utilize graph convolution networks (GCN) to\ngenerate high-order embeddings. We integrate GEM with several FM-based models\nand conduct extensive experiments on two real-world datasets. The results\ndemonstrate significant improvement of GEM over corresponding baselines.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 12:03:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Enneng", ""], ["Xin", "Xin", ""], ["Shen", "Li", ""], ["Guo", "Guibing", ""]]}, {"id": "2002.06610", "submitter": "Jae Myung Kim", "authors": "Jae Myung Kim, Hyungjin Kim, Chanwoo Park, and Jungwoo Lee", "title": "REST: Performance Improvement of a Black Box Model via RL-based Spatial\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks (DNN) have become a highly active area\nof research, and shown remarkable achievements on a variety of computer vision\ntasks. DNNs, however, are known to often make overconfident yet incorrect\npredictions on out-of-distribution samples, which can be a major obstacle to\nreal-world deployments because the training dataset is always limited compared\nto diverse real-world samples. Thus, it is fundamental to provide guarantees of\nrobustness to the distribution shift between training and test time when we\nconstruct DNN models in practice. Moreover, in many cases, the deep learning\nmodels are deployed as black boxes and the performance has been already\noptimized for a training dataset, thus changing the black box itself can lead\nto performance degradation. We here study the robustness to the geometric\ntransformations in a specific condition where the black-box image classifier is\ngiven. We propose an additional learner, \\emph{REinforcement Spatial Transform\nlearner (REST)}, that transforms the warped input data into samples regarded as\nin-distribution by the black-box models. Our work aims to improve the\nrobustness by adding a REST module in front of any black boxes and training\nonly the REST module without retraining the original black box model in an\nend-to-end manner, i.e. we try to convert the real-world data into training\ndistribution which the performance of the black-box model is best suited for.\nWe use a confidence score that is obtained from the black-box model to\ndetermine whether the transformed input is drawn from in-distribution. We\nempirically show that our method has an advantage in generalization to\ngeometric transformations and sample efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:15:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kim", "Jae Myung", ""], ["Kim", "Hyungjin", ""], ["Park", "Chanwoo", ""], ["Lee", "Jungwoo", ""]]}, {"id": "2002.06611", "submitter": "Dhasarathy Parthasarathy", "authors": "Dhasarathy Parthasarathy, Karl B\\\"ackstr\\\"om, Jens Henriksson and\n  S\\'olr\\'un Einarsd\\'ottir", "title": "Controlled time series generation for automotive software-in-the-loop\n  testing using GANs", "comments": "Preprint of paper accepted at The Second IEEE International\n  Conference on Artificial Intelligence Testing, April 13-16, 2020, Oxford, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing automotive mechatronic systems partly uses the software-in-the-loop\napproach, where systematically covering inputs of the system-under-test remains\na major challenge. In current practice, there are two major techniques of input\nstimulation. One approach is to craft input sequences which eases control and\nfeedback of the test process but falls short of exposing the system to\nrealistic scenarios. The other is to replay sequences recorded from field\noperations which accounts for reality but requires collecting a well-labeled\ndataset of sufficient capacity for widespread use, which is expensive. This\nwork applies the well-known unsupervised learning framework of Generative\nAdversarial Networks (GAN) to learn an unlabeled dataset of recorded in-vehicle\nsignals and uses it for generation of synthetic input stimuli. Additionally, a\nmetric-based linear interpolation algorithm is demonstrated, which guarantees\nthat generated stimuli follow a customizable similarity relationship with\nspecified references. This combination of techniques enables controlled\ngeneration of a rich range of meaningful and realistic input patterns,\nimproving virtual test coverage and reducing the need for expensive field\ntests.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:19:29 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:52:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Parthasarathy", "Dhasarathy", ""], ["B\u00e4ckstr\u00f6m", "Karl", ""], ["Henriksson", "Jens", ""], ["Einarsd\u00f3ttir", "S\u00f3lr\u00fan", ""]]}, {"id": "2002.06622", "submitter": "Zhouxing Shi", "authors": "Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh", "title": "Robustness Verification for Transformers", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness verification that aims to formally certify the prediction behavior\nof neural networks has become an important tool for understanding model\nbehavior and obtaining safety guarantees. However, previous methods can usually\nonly handle neural networks with relatively simple architectures. In this\npaper, we consider the robustness verification problem for Transformers.\nTransformers have complex self-attention layers that pose many challenges for\nverification, including cross-nonlinearity and cross-position dependency, which\nhave not been discussed in previous works. We resolve these challenges and\ndevelop the first robustness verification algorithm for Transformers. The\ncertified robustness bounds computed by our method are significantly tighter\nthan those by naive Interval Bound Propagation. These bounds also shed light on\ninterpreting Transformers as they consistently reflect the importance of\ndifferent words in sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 17:16:31 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 12:36:47 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Shi", "Zhouxing", ""], ["Zhang", "Huan", ""], ["Chang", "Kai-Wei", ""], ["Huang", "Minlie", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.06659", "submitter": "Yanchao Sun", "authors": "Yanchao Sun, Xiangyu Yin, Furong Huang", "title": "TempLe: Learning Template of Transitions for Sample Efficient Multi-task\n  RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge among various environments is important to efficiently\nlearn multiple tasks online. Most existing methods directly use the previously\nlearned models or previously learned optimal policies to learn new tasks.\nHowever, these methods may be inefficient when the underlying models or optimal\npolicies are substantially different across tasks. In this paper, we propose\nTemplate Learning (TempLe), the first PAC-MDP method for multi-task\nreinforcement learning that could be applied to tasks with varying state/action\nspace. TempLe generates transition dynamics templates, abstractions of the\ntransition dynamics across tasks, to gain sample efficiency by extracting\nsimilarities between tasks even when their underlying models or optimal\npolicies have limited commonalities. We present two algorithms for an \"online\"\nand a \"finite-model\" setting respectively. We prove that our proposed TempLe\nalgorithms achieve much lower sample complexity than single-task learners or\nstate-of-the-art multi-task methods. We show via systematically designed\nexperiments that our TempLe method universally outperforms the state-of-the-art\nmulti-task methods (PAC-MDP or not) in various settings and regimes.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 19:46:49 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 17:14:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Sun", "Yanchao", ""], ["Yin", "Xiangyu", ""], ["Huang", "Furong", ""]]}, {"id": "2002.06665", "submitter": "Fatemeh Salehi Rizi", "authors": "Fatemeh Salehi Rizi, Michael Granitzer", "title": "Predicting event attendance exploring social influence", "comments": null, "journal-ref": null, "doi": "10.1145/3297280.3297622", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The problem of predicting people's participation in real-world events has\nreceived considerable attention as it offers valuable insights for human\nbehavior analysis and event-related advertisement. Today social networks (e.g.\nTwitter) widely reflect large popular events where people discuss their\ninterest with friends. Event participants usually stimulate friends to join the\nevent which propagates a social influence in the network. In this paper, we\npropose to model the social influence of friends on event attendance. We\nconsider non-geotagged posts besides structures of social groups to infer\nusers' attendance. To leverage the information on network topology we apply\nsome of recent graph embedding techniques such as node2vec, HARP and Poincar`e.\nWe describe the approach followed to design the feature space and feed it to a\nneural network. The performance evaluation is conducted using two large music\nfestivals datasets, namely the VFestival and Creamfields. The experimental\nresults show that our classifier outperforms the state-of-the-art baseline with\n89% accuracy observed for the VFestival dataset.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:03:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rizi", "Fatemeh Salehi", ""], ["Granitzer", "Michael", ""]]}, {"id": "2002.06668", "submitter": "Yi Zhang", "authors": "Yi Zhang, Orestis Plevrakis, Simon S. Du, Xingguo Li, Zhao Song,\n  Sanjeev Arora", "title": "Over-parameterized Adversarial Training: An Analysis Overcoming the\n  Curse of Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a popular method to give neural nets robustness\nagainst adversarial perturbations. In practice adversarial training leads to\nlow robust training loss. However, a rigorous explanation for why this happens\nunder natural conditions is still missing. Recently a convergence theory for\nstandard (non-adversarial) supervised training was developed by various groups\nfor {\\em very overparametrized} nets. It is unclear how to extend these results\nto adversarial training because of the min-max objective. Recently, a first\nstep towards this direction was made by Gao et al. using tools from online\nlearning, but they require the width of the net to be \\emph{exponential} in\ninput dimension $d$, and with an unnatural activation function. Our work proves\nconvergence to low robust training loss for \\emph{polynomial} width instead of\nexponential, under natural assumptions and with the ReLU activation. Key\nelement of our proof is showing that ReLU networks near initialization can\napproximate the step function, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:13:43 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 03:10:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Yi", ""], ["Plevrakis", "Orestis", ""], ["Du", "Simon S.", ""], ["Li", "Xingguo", ""], ["Song", "Zhao", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2002.06673", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Juan C. Perdomo, Tijana Zrnic, Celestine Mendler-D\\\"unner, Moritz\n  Hardt", "title": "Performative Prediction", "comments": "published at ICML'20; fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When predictions support decisions they may influence the outcome they aim to\npredict. We call such predictions performative; the prediction influences the\ntarget. Performativity is a well-studied phenomenon in policy-making that has\nso far been neglected in supervised learning. When ignored, performativity\nsurfaces as undesirable distribution shift, routinely addressed with\nretraining.\n  We develop a risk minimization framework for performative prediction bringing\ntogether concepts from statistics, game theory, and causality. A conceptual\nnovelty is an equilibrium notion we call performative stability. Performative\nstability implies that the predictions are calibrated not against past\noutcomes, but against the future outcomes that manifest from acting on the\nprediction. Our main results are necessary and sufficient conditions for the\nconvergence of retraining to a performatively stable point of nearly minimal\nloss.\n  In full generality, performative prediction strictly subsumes the setting\nknown as strategic classification. We thus also give the first sufficient\nconditions for retraining to overcome strategic feedback effects.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:29:42 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 02:36:30 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 16:19:45 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 22:07:40 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Perdomo", "Juan C.", ""], ["Zrnic", "Tijana", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Hardt", "Moritz", ""]]}, {"id": "2002.06685", "submitter": "Fatemeh Salehi Rizi", "authors": "Fatemeh Salehi Rizi, Michael Granitzer, Konstantin Ziegler", "title": "Global and Local Feature Learning for Ego-Network Analysis", "comments": null, "journal-ref": null, "doi": "10.1109/DEXA.2017.36", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In an ego-network, an individual (ego) organizes its friends (alters) in\ndifferent groups (social circles). This social network can be efficiently\nanalyzed after learning representations of the ego and its alters in a\nlow-dimensional, real vector space. These representations are then easily\nexploited via statistical models for tasks such as social circle detection and\nprediction. Recent advances in language modeling via deep learning have\ninspired new methods for learning network representations. These methods can\ncapture the global structure of networks. In this paper, we evolve these\ntechniques to also encode the local structure of neighborhoods. Therefore, our\nlocal representations capture network features that are hidden in the global\nrepresentation of large networks. We show that the task of social circle\nprediction benefits from a combination of global and local features generated\nby our technique.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:35:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rizi", "Fatemeh Salehi", ""], ["Granitzer", "Michael", ""], ["Ziegler", "Konstantin", ""]]}, {"id": "2002.06694", "submitter": "Yuqian Zhang", "authors": "Wei Qian, Yuqian Zhang, Yudong Chen", "title": "Structures of Spurious Local Minima in $k$-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-means clustering is a fundamental problem in unsupervised learning. The\nproblem concerns finding a partition of the data points into $k$ clusters such\nthat the within-cluster variation is minimized. Despite its importance and wide\napplicability, a theoretical understanding of the $k$-means problem has not\nbeen completely satisfactory. Existing algorithms with theoretical performance\nguarantees often rely on sophisticated (sometimes artificial) algorithmic\ntechniques and restricted assumptions on the data. The main challenge lies in\nthe non-convex nature of the problem; in particular, there exist additional\nlocal solutions other than the global optimum. Moreover, the simplest and most\npopular algorithm for $k$-means, namely Lloyd's algorithm, generally converges\nto such spurious local solutions both in theory and in practice.\n  In this paper, we approach the $k$-means problem from a new perspective, by\ninvestigating the structures of these spurious local solutions under a\nprobabilistic generative model with $k$ ground truth clusters. As soon as\n$k=3$, spurious local minima provably exist, even for well-separated and\nbalanced clusters. One such local minimum puts two centers at one true cluster,\nand the third center in the middle of the other two true clusters. For general\n$k$, one local minimum puts multiple centers at a true cluster, and one center\nin the middle of multiple true clusters. Perhaps surprisingly, we prove that\nthis is essentially the only type of spurious local minima under a separation\ncondition. Our results pertain to the $k$-means formulation for mixtures of\nGaussians or bounded distributions. Our theoretical results corroborate\nexisting empirical observations and provide justification for several improved\nalgorithms for $k$-means clustering.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 22:15:03 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 21:19:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Qian", "Wei", ""], ["Zhang", "Yuqian", ""], ["Chen", "Yudong", ""]]}, {"id": "2002.06703", "submitter": "Guy Davidson", "authors": "Guy Davidson, Brenden M. Lake", "title": "Investigating Simple Object Representations in Model-Free Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the benefits of augmenting state-of-the-art model-free deep\nreinforcement algorithms with simple object representations. Following the\nFrostbite challenge posited by Lake et al. (2017), we identify object\nrepresentations as a critical cognitive capacity lacking from current\nreinforcement learning agents. We discover that providing the Rainbow model\n(Hessel et al.,2018) with simple, feature-engineered object representations\nsubstantially boosts its performance on the Frostbite game from Atari 2600. We\nthen analyze the relative contributions of the representations of different\ntypes of objects, identify environment states where these representations are\nmost impactful, and examine how these representations aid in generalizing to\nnovel situations.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:10:41 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 22:00:30 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Davidson", "Guy", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2002.06707", "submitter": "Jonas K\\\"ohler", "authors": "Hao Wu, Jonas K\\\"ohler and Frank No\\'e", "title": "Stochastic Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sampling of probability distributions specified up to a normalization\nconstant is an important problem in both machine learning and statistical\nmechanics. While classical stochastic sampling methods such as Markov Chain\nMonte Carlo (MCMC) or Langevin Dynamics (LD) can suffer from slow mixing times\nthere is a growing interest in using normalizing flows in order to learn the\ntransformation of a simple prior distribution to the given target distribution.\nHere we propose a generalized and combined approach to sample target densities:\nStochastic Normalizing Flows (SNF) -- an arbitrary sequence of deterministic\ninvertible functions and stochastic sampling blocks. We show that stochasticity\novercomes expressivity limitations of normalizing flows resulting from the\ninvertibility constraint, whereas trainable transformations between sampling\nsteps improve efficiency of pure MCMC/LD along the flow. By invoking ideas from\nnon-equilibrium statistical mechanics we derive an efficient training procedure\nby which both the sampler's and the flow's parameters can be optimized\nend-to-end, and by which we can compute exact importance weights without having\nto marginalize out the randomness of the stochastic blocks. We illustrate the\nrepresentational power, sampling efficiency and asymptotic correctness of SNFs\non several benchmarks including applications to sampling molecular systems in\nequilibrium.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:29:32 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:36:31 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 11:28:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wu", "Hao", ""], ["K\u00f6hler", "Jonas", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2002.06715", "submitter": "Yeming Wen", "authors": "Yeming Wen, Dustin Tran, Jimmy Ba", "title": "BatchEnsemble: An Alternative Approach to Efficient Ensemble and\n  Lifelong Learning", "comments": null, "journal-ref": "Eighth International Conference on Learning Representations (ICLR\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles, where multiple neural networks are trained individually and their\npredictions are averaged, have been shown to be widely successful for improving\nboth the accuracy and predictive uncertainty of single neural networks.\nHowever, an ensemble's cost for both training and testing increases linearly\nwith the number of networks, which quickly becomes untenable.\n  In this paper, we propose BatchEnsemble, an ensemble method whose\ncomputational and memory costs are significantly lower than typical ensembles.\nBatchEnsemble achieves this by defining each weight matrix to be the Hadamard\nproduct of a shared weight among all ensemble members and a rank-one matrix per\nmember. Unlike ensembles, BatchEnsemble is not only parallelizable across\ndevices, where one device trains one member, but also parallelizable within a\ndevice, where multiple ensemble members are updated simultaneously for a given\nmini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and\nout-of-distribution tasks, BatchEnsemble yields competitive accuracy and\nuncertainties as typical ensembles; the speedup at test time is 3X and memory\nreduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to\nlifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable\nperformance to progressive neural networks while having a much lower\ncomputational and memory costs. We further show that BatchEnsemble can easily\nscale up to lifelong learning on Split-ImageNet which involves 100 sequential\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:00:59 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 03:38:44 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wen", "Yeming", ""], ["Tran", "Dustin", ""], ["Ba", "Jimmy", ""]]}, {"id": "2002.06716", "submitter": "Michael Mahoney", "authors": "Charles H. Martin, Tongsu (Serena) Peng, and Michael W. Mahoney", "title": "Predicting trends in the quality of state-of-the-art neural networks\n  without access to training or testing data", "comments": "35 pages, 8 tables, 17 figures. To appear in Nature Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, one works with neural network models trained by someone\nelse. For such pretrained models, one may not have access to training data or\ntest data. Moreover, one may not know details about the model, e.g., the\nspecifics of the training data, the loss function, the hyperparameter values,\netc. Given one or many pretrained models, it is a challenge to say anything\nabout the expected performance or quality of the models. Here, we address this\nchallenge by providing a detailed meta-analysis of hundreds of\npublicly-available pretrained models. We examine norm based capacity control\nmetrics as well as power law based metrics from the recently-developed Theory\nof Heavy-Tailed Self Regularization. We find that norm based metrics correlate\nwell with reported test accuracies for well-trained models, but that they often\ncannot distinguish well-trained versus poorly-trained models. We also find that\npower law based metrics can do much better -- quantitatively better at\ndiscriminating among series of well-trained models with a given architecture;\nand qualitatively better at discriminating well-trained versus poorly-trained\nmodels. These methods can be used to identify when a pretrained neural network\nhas problems that cannot be detected simply by examining training/test\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:01:12 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 17:21:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Martin", "Charles H.", "", "Serena"], ["Tongsu", "", "", "Serena"], ["Peng", "", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.06723", "submitter": "Zhenyu Shou", "authors": "Zhenyu Shou, Xuan Di", "title": "Reward Design for Driver Repositioning Using Multi-Agent Reinforcement\n  Learning", "comments": "28 pages, 20 figures, published in Transportation Research Part C 119\n  (2020) 102738", "journal-ref": null, "doi": "10.1016/j.trc.2020.102738", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large portion of passenger requests is reportedly unserviced, partially due\nto vacant for-hire drivers' cruising behavior during the passenger seeking\nprocess. This paper aims to model the multi-driver repositioning task through a\nmean field multi-agent reinforcement learning (MARL) approach that captures\ncompetition among multiple agents. Because the direct application of MARL to\nthe multi-driver system under a given reward mechanism will likely yield a\nsuboptimal equilibrium due to the selfishness of drivers, this study proposes a\nreward design scheme with which a more desired equilibrium can be reached. To\neffectively solve the bilevel optimization problem with upper level as the\nreward design and the lower level as a multi-agent system, a Bayesian\noptimization (BO) algorithm is adopted to speed up the learning process. We\nthen apply the bilevel optimization model to two case studies, namely,\ne-hailing driver repositioning under service charge and multiclass taxi driver\nrepositioning under NYC congestion pricing. In the first case study, the model\nis validated by the agreement between the derived optimal control from BO and\nthat from an analytical solution. With a simple piecewise linear service\ncharge, the objective of the e-hailing platform can be increased by 8.4%. In\nthe second case study, an optimal toll charge of $5.1 is solved using BO, which\nimproves the objective of city planners by 7.9%, compared to that without any\ntoll charge. Under this optimal toll charge, the number of taxis in the NYC\ncentral business district is decreased, indicating a better traffic condition,\nwithout substantially increasing the crowdedness of the subway system.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:10:58 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 17:51:40 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 16:48:23 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Shou", "Zhenyu", ""], ["Di", "Xuan", ""]]}, {"id": "2002.06734", "submitter": "Abdelrahman Zayed", "authors": "Abdelrahman Zayed, Guy Cloutier and Hassan Rivaz", "title": "Automatic Frame Selection using CNN in Ultrasound Elastography", "comments": "2020 42nd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound elastography is used to estimate the mechanical properties of the\ntissue by monitoring its response to an internal or external force. Different\nlevels of deformation are obtained from different tissue types depending on\ntheir mechanical properties, where stiffer tissues deform less. Given two radio\nfrequency (RF) frames collected before and after some deformation, we estimate\ndisplacement and strain images by comparing the RF frames. The quality of the\nstrain image is dependent on the type of motion that occurs during deformation.\nIn-plane axial motion results in high-quality strain images, whereas\nout-of-plane motion results in low-quality strain images. In this paper, we\nintroduce a new method using a convolutional neural network (CNN) to determine\nthe suitability of a pair of RF frames for elastography in only 5.4 ms. Our\nmethod could also be used to automatically choose the best pair of RF frames,\nyielding a high-quality strain image. The CNN was trained on 3,818 pairs of RF\nframes, while testing was done on 986 new unseen pairs, achieving an accuracy\nof more than 91%. The RF frames were collected from both phantom and in vivo\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 01:26:22 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 03:45:37 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Zayed", "Abdelrahman", ""], ["Cloutier", "Guy", ""], ["Rivaz", "Hassan", ""]]}, {"id": "2002.06739", "submitter": "Zhen Wang", "authors": "Lan Bai, Yuan-Hai Shao, Wei-Jie Chen, Zhen Wang, Nai-Yang Deng", "title": "Multiple Flat Projections for Cross-manifold Clustering", "comments": "12 pages, 58 figures", "journal-ref": "IEEE Transactions on Cybernetics, 2021", "doi": "10.1109/TCYB.2021.3050487", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-manifold clustering is a hard topic and many traditional clustering\nmethods fail because of the cross-manifold structures. In this paper, we\npropose a Multiple Flat Projections Clustering (MFPC) to deal with\ncross-manifold clustering problems. In our MFPC, the given samples are\nprojected into multiple subspaces to discover the global structures of the\nimplicit manifolds. Thus, the cross-manifold clusters are distinguished from\nthe various projections. Further, our MFPC is extended to nonlinear manifold\nclustering via kernel tricks to deal with more complex cross-manifold\nclustering. A series of non-convex matrix optimization problems in MFPC are\nsolved by a proposed recursive algorithm. The synthetic tests show that our\nMFPC works on the cross-manifold structures well. Moreover, experimental\nresults on the benchmark datasets show the excellent performance of our MFPC\ncompared with some state-of-the-art clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:16:00 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Bai", "Lan", ""], ["Shao", "Yuan-Hai", ""], ["Chen", "Wei-Jie", ""], ["Wang", "Zhen", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "2002.06742", "submitter": "Ali Vakilian", "authors": "Sepideh Mahabadi and Ali Vakilian", "title": "Individual Fairness for $k$-Clustering", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a local search based algorithm for $k$-median and $k$-means (and more\ngenerally for any $k$-clustering with $\\ell_p$ norm cost function) from the\nperspective of individual fairness. More precisely, for a point $x$ in a point\nset $P$ of size $n$, let $r(x)$ be the minimum radius such that the ball of\nradius $r(x)$ centered at $x$ has at least $n/k$ points from $P$. Intuitively,\nif a set of $k$ random points are chosen from $P$ as centers, every point $x\\in\nP$ expects to have a center within radius $r(x)$. An individually fair\nclustering provides such a guarantee for every point $x\\in P$. This notion of\nfairness was introduced in [Jung et al., 2019] where they showed how to get an\napproximately feasible $k$-clustering with respect to this fairness condition.\n  In this work, we show how to get a bicriteria approximation for fair\n$k$-clustering: The $k$-median ($k$-means) cost of our solution is within a\nconstant factor of the cost of an optimal fair $k$-clustering, and our solution\napproximately satisfies the fairness condition (also within a constant factor).\nFurther, we complement our theoretical bounds with empirical evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:31:13 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 18:31:09 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mahabadi", "Sepideh", ""], ["Vakilian", "Ali", ""]]}, {"id": "2002.06746", "submitter": "Yoichi Chikahara", "authors": "Yoichi Chikahara, Shinsaku Sakaue, Akinori Fujino, Hisashi Kashima", "title": "Learning Individually Fair Classifier with Path-Specific Causal-Effect\n  Constraint", "comments": "23 pages, 9 figures, 3 tables; Accepted by AISTATS2021 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used to make decisions for individuals in various fields,\nwhich require us to achieve good prediction accuracy while ensuring fairness\nwith respect to sensitive features (e.g., race and gender). This problem,\nhowever, remains difficult in complex real-world scenarios. To quantify\nunfairness under such situations, existing methods utilize {\\it path-specific\ncausal effects}. However, none of them can ensure fairness for each individual\nwithout making impractical functional assumptions on the data. In this paper,\nwe propose a far more practical framework for learning an individually fair\nclassifier. To avoid restrictive functional assumptions, we define the {\\it\nprobability of individual unfairness} (PIU) and solve an optimization problem\nwhere PIU's upper bound, which can be estimated from data, is controlled to be\nclose to zero. We elucidate why our method can guarantee fairness for each\nindividual. Experimental results show that our method can learn an individually\nfair classifier at a slight cost of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:46:17 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:29:23 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 19:36:28 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 04:50:41 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Chikahara", "Yoichi", ""], ["Sakaue", "Shinsaku", ""], ["Fujino", "Akinori", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.06753", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Steven Reich, Liam Fowl, Renkun Ni, Valeriia\n  Cherepanova, Tom Goldstein", "title": "Unraveling Meta-Learning: Understanding Feature Representations for\n  Few-Shot Tasks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms produce feature extractors which achieve\nstate-of-the-art performance on few-shot classification. While the literature\nis rich with meta-learning methods, little is known about why the resulting\nfeature extractors perform so well. We develop a better understanding of the\nunderlying mechanics of meta-learning and the difference between models trained\nusing meta-learning and models which are trained classically. In doing so, we\nintroduce and verify several hypotheses for why meta-learned models perform\nbetter. Furthermore, we develop a regularizer which boosts the performance of\nstandard training routines for few-shot classification. In many cases, our\nroutine outperforms meta-learning while simultaneously running an order of\nmagnitude faster.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 03:18:45 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 22:50:45 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 13:59:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Goldblum", "Micah", ""], ["Reich", "Steven", ""], ["Fowl", "Liam", ""], ["Ni", "Renkun", ""], ["Cherepanova", "Valeriia", ""], ["Goldstein", "Tom", ""]]}, {"id": "2002.06755", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Jure Leskovec", "title": "Unifying Graph Convolutional Neural Networks and Label Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN) are\nboth message passing algorithms on graphs. Both solve the task of node\nclassification but LPA propagates node label information across the edges of\nthe graph, while GCN propagates and transforms node feature information.\nHowever, while conceptually similar, theoretical relation between LPA and GCN\nhas not yet been investigated. Here we study the relationship between LPA and\nGCN in terms of two aspects: (1) feature/label smoothing where we analyze how\nthe feature/label of one node is spread over its neighbors; And, (2)\nfeature/label influence of how much the initial feature/label of one node\ninfluences the final feature/label of another node. Based on our theoretical\nanalysis, we propose an end-to-end model that unifies GCN and LPA for node\nclassification. In our unified model, edge weights are learnable, and the LPA\nserves as regularization to assist the GCN in learning proper edge weights that\nlead to improved classification performance. Our model can also be seen as\nlearning attention weights based on node labels, which is more task-oriented\nthan existing feature-based attention models. In a number of experiments on\nreal-world graphs, our model shows superiority over state-of-the-art GCN-based\nmethods in terms of node classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 03:23:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Hongwei", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.06757", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Hongyu Ren, Jure Leskovec", "title": "Relational Message Passing for Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph completion aims to predict missing relations between entities\nin a knowledge graph. In this work, we propose a relational message passing\nmethod for knowledge graph completion. Different from existing embedding-based\nmethods, relational message passing only considers edge features (i.e.,\nrelation types) without entity IDs in the knowledge graph, and passes\nrelational messages among edges iteratively to aggregate neighborhood\ninformation. Specifically, two kinds of neighborhood topology are modeled for a\ngiven entity pair under the relational message passing framework: (1)\nRelational context, which captures the relation types of edges adjacent to the\ngiven entity pair; (2) Relational paths, which characterize the relative\nposition between the given two entities in the knowledge graph. The two message\npassing modules are combined together for relation prediction. Experimental\nresults on knowledge graph benchmarks as well as our newly proposed dataset\nshow that, our method PathCon outperforms state-of-the-art knowledge graph\ncompletion methods by a large margin. PathCon is also shown applicable to\ninductive settings where entities are not seen in training stage, and it is\nable to provide interpretable explanations for the predicted results. The code\nand all datasets are available at https://github.com/hwwang55/PathCon.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 03:33:41 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 21:33:59 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wang", "Hongwei", ""], ["Ren", "Hongyu", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.06768", "submitter": "Ioannis Panageas", "authors": "Qi Lei and Sai Ganesh Nagarajan and Ioannis Panageas and Xiao Wang", "title": "Last iterate convergence in no-regret learning: constrained min-max\n  optimization for convex-concave landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent series of papers it has been established that variants of\nGradient Descent/Ascent and Mirror Descent exhibit last iterate convergence in\nconvex-concave zero-sum games. Specifically, \\cite{DISZ17, LiangS18} show last\niterate convergence of the so called \"Optimistic Gradient Descent/Ascent\" for\nthe case of \\textit{unconstrained} min-max optimization. Moreover, in\n\\cite{Metal} the authors show that Mirror Descent with an extra gradient step\ndisplays last iterate convergence for convex-concave problems (both constrained\nand unconstrained), though their algorithm does not follow the online learning\nframework; it uses extra information rather than \\textit{only} the history to\ncompute the next iteration. In this work, we show that \"Optimistic\nMultiplicative-Weights Update (OMWU)\" which follows the no-regret online\nlearning framework, exhibits last iterate convergence locally for\nconvex-concave games, generalizing the results of \\cite{DP19} where last\niterate convergence of OMWU was shown only for the \\textit{bilinear case}. We\ncomplement our results with experiments that indicate fast convergence of the\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:40:38 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 05:04:45 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Lei", "Qi", ""], ["Nagarajan", "Sai Ganesh", ""], ["Panageas", "Ioannis", ""], ["Wang", "Xiao", ""]]}, {"id": "2002.06772", "submitter": "Branislav Kveton", "authors": "Craig Boutilier, Chih-Wei Hsu, Branislav Kveton, Martin Mladenov,\n  Csaba Szepesvari, and Manzil Zaheer", "title": "Differentiable Bandit Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration policies in Bayesian bandits maximize the average reward over\nproblem instances drawn from some distribution $\\mathcal{P}$. In this work, we\nlearn such policies for an unknown distribution $\\mathcal{P}$ using samples\nfrom $\\mathcal{P}$. Our approach is a form of meta-learning and exploits\nproperties of $\\mathcal{P}$ without making strong assumptions about its form.\nTo do this, we parameterize our policies in a differentiable way and optimize\nthem by policy gradients, an approach that is general and easy to implement. We\nderive effective gradient estimators and introduce novel variance reduction\ntechniques. We also analyze and experiment with various bandit policy classes,\nincluding neural networks and a novel softmax policy. The latter has regret\nguarantees and is a natural starting point for our optimization. Our\nexperiments show the versatility of our approach. We also observe that neural\nnetwork policies can learn implicit biases expressed only through the sampled\ninstances.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 05:07:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 07:35:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Boutilier", "Craig", ""], ["Hsu", "Chih-Wei", ""], ["Kveton", "Branislav", ""], ["Mladenov", "Martin", ""], ["Szepesvari", "Csaba", ""], ["Zaheer", "Manzil", ""]]}, {"id": "2002.06774", "submitter": "Janghyeon Lee", "authors": "Janghyeon Lee, Donggyu Joo, Hyeong Gwon Hong, Junmo Kim", "title": "Residual Continual Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel continual learning method called Residual Continual\nLearning (ResCL). Our method can prevent the catastrophic forgetting phenomenon\nin sequential learning of multiple tasks, without any source task information\nexcept the original network. ResCL reparameterizes network parameters by\nlinearly combining each layer of the original network and a fine-tuned network;\ntherefore, the size of the network does not increase at all. To apply the\nproposed method to general convolutional neural networks, the effects of batch\nnormalization layers are also considered. By utilizing residual-learning-like\nreparameterization and a special weight decay loss, the trade-off between\nsource and target performance is effectively controlled. The proposed method\nexhibits state-of-the-art performance in various continual learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 05:24:45 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lee", "Janghyeon", ""], ["Joo", "Donggyu", ""], ["Hong", "Hyeong Gwon", ""], ["Kim", "Junmo", ""]]}, {"id": "2002.06789", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Qi Lei, Pin-Yu Chen, Inderjit Dhillon, Cho-Jui Hsieh", "title": "CAT: Customized Adversarial Training for Improved Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has become one of the most effective methods for\nimproving robustness of neural networks. However, it often suffers from poor\ngeneralization on both clean and perturbed data. In this paper, we propose a\nnew algorithm, named Customized Adversarial Training (CAT), which adaptively\ncustomizes the perturbation level and the corresponding label for each training\nsample in adversarial training. We show that the proposed algorithm achieves\nbetter clean and robust accuracy than previous adversarial training methods\nthrough extensive experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:13:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cheng", "Minhao", ""], ["Lei", "Qi", ""], ["Chen", "Pin-Yu", ""], ["Dhillon", "Inderjit", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.06799", "submitter": "Steven Kommrusch", "authors": "Steve Kommrusch, Th\\'eo Barollet, Louis-No\\\"el Pouchet", "title": "Equivalence of Dataflow Graphs via Rewrite Rules Using a\n  Graph-to-Sequence Neural Model", "comments": "20 pages including references and appendices, 10 figures, updated to\n  include acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we target the problem of provably computing the equivalence\nbetween two programs represented as dataflow graphs. To this end, we formalize\nthe problem of equivalence between two programs as finding a set of\nsemantics-preserving rewrite rules from one into the other, such that after the\nrewrite the two programs are structurally identical, and therefore trivially\nequivalent. We then develop the first graph-to-sequence neural network system\nfor program equivalence, trained to produce such rewrite sequences from a\ncarefully crafted automatic example generation algorithm. We extensively\nevaluate our system on a rich multi-type linear algebra expression language,\nusing arbitrary combinations of 100+ graph-rewriting axioms of equivalence. Our\nsystem outputs via inference a correct rewrite sequence for 96% of the 10,000\nprogram pairs isolated for testing, using 30-term programs. And in all cases,\nthe validity of the sequence produced and therefore the provable assertion of\nprogram equivalence is computable, in negligible time.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:43:00 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 21:40:34 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kommrusch", "Steve", ""], ["Barollet", "Th\u00e9o", ""], ["Pouchet", "Louis-No\u00ebl", ""]]}, {"id": "2002.06815", "submitter": "Minsung Hyun", "authors": "Minsung Hyun, Jisoo Jeong and Nojun Kwak", "title": "Class-Imbalanced Semi-Supervised Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-Supervised Learning (SSL) has achieved great success in overcoming the\ndifficulties of labeling and making full use of unlabeled data. However, SSL\nhas a limited assumption that the numbers of samples in different classes are\nbalanced, and many SSL algorithms show lower performance for the datasets with\nthe imbalanced class distribution. In this paper, we introduce a task of\nclass-imbalanced semi-supervised learning (CISSL), which refers to\nsemi-supervised learning with class-imbalanced data. In doing so, we consider\nclass imbalance in both labeled and unlabeled sets. First, we analyze existing\nSSL methods in imbalanced environments and examine how the class imbalance\naffects SSL methods. Then we propose Suppressed Consistency Loss (SCL), a\nregularization method robust to class imbalance. Our method shows better\nperformance than the conventional methods in the CISSL environment. In\nparticular, the more severe the class imbalance and the smaller the size of the\nlabeled data, the better our method performs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:48:47 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hyun", "Minsung", ""], ["Jeong", "Jisoo", ""], ["Kwak", "Nojun", ""]]}, {"id": "2002.06836", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Flavio Mazzolini, Lorenzo Bisi, Luca Sabbioni,\n  Marcello Restelli", "title": "Control Frequency Adaptation via Action Persistence in Batch\n  Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of the control frequency of a system has a relevant impact on the\nability of reinforcement learning algorithms to learn a highly performing\npolicy. In this paper, we introduce the notion of action persistence that\nconsists in the repetition of an action for a fixed number of decision steps,\nhaving the effect of modifying the control frequency. We start analyzing how\naction persistence affects the performance of the optimal policy, and then we\npresent a novel algorithm, Persistent Fitted Q-Iteration (PFQI), that extends\nFQI, with the goal of learning the optimal value function at a given\npersistence. After having provided a theoretical study of PFQI and a heuristic\napproach to identify the optimal persistence, we present an experimental\ncampaign on benchmark domains to show the advantages of action persistence and\nproving the effectiveness of our persistence selection method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 08:38:51 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 19:18:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Mazzolini", "Flavio", ""], ["Bisi", "Lorenzo", ""], ["Sabbioni", "Luca", ""], ["Restelli", "Marcello", ""]]}, {"id": "2002.06856", "submitter": "Shakila Mahjabin Tonni", "authors": "Shakila Mahjabin Tonni, Dinusha Vatsalan, Farhad Farokhi, Dali Kaafar,\n  Zhigang Lu and Gioacchino Tangari", "title": "Data and Model Dependencies of Membership Inference Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models have been shown to be vulnerable to Membership\nInference Attacks (MIA), which infer the membership of a given data point in\nthe target dataset by observing the prediction output of the ML model. While\nthe key factors for the success of MIA have not yet been fully understood,\nexisting defense mechanisms such as using L2 regularization\n\\cite{10shokri2017membership} and dropout layers \\cite{salem2018ml} take only\nthe model's overfitting property into consideration. In this paper, we provide\nan empirical analysis of the impact of both the data and ML model properties on\nthe vulnerability of ML techniques to MIA. Our results reveal the relationship\nbetween MIA accuracy and properties of the dataset and training model in use.\nIn particular, we show that the size of shadow dataset, the class and feature\nbalance and the entropy of the target dataset, the configurations and fairness\nof the training model are the most influential factors. Based on those\nexperimental findings, we conclude that along with model overfitting, multiple\nproperties jointly contribute to MIA success instead of any single property.\nBuilding on our experimental findings, we propose using those data and model\nproperties as regularizers to protect ML models against MIA. Our results show\nthat the proposed defense mechanisms can reduce the MIA accuracy by up to 25\\%\nwithout sacrificing the ML model prediction utility.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:35:00 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 05:15:38 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 13:45:13 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 00:56:33 GMT"}, {"version": "v5", "created": "Sat, 25 Jul 2020 06:25:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tonni", "Shakila Mahjabin", ""], ["Vatsalan", "Dinusha", ""], ["Farokhi", "Farhad", ""], ["Kaafar", "Dali", ""], ["Lu", "Zhigang", ""], ["Tangari", "Gioacchino", ""]]}, {"id": "2002.06864", "submitter": "Teodora Baluta", "authors": "Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel and Prateek Saxena", "title": "Scalable Quantitative Verification For Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the functional success of deep neural networks (DNNs), their\ntrustworthiness remains a crucial open challenge. To address this challenge,\nboth testing and verification techniques have been proposed. But these existing\ntechniques provide either scalability to large networks or formal guarantees,\nnot both. In this paper, we propose a scalable quantitative verification\nframework for deep neural networks, i.e., a test-driven approach that comes\nwith formal guarantees that a desired probabilistic property is satisfied. Our\ntechnique performs enough tests until soundness of a formal probabilistic\nproperty can be proven. It can be used to certify properties of both\ndeterministic and randomized DNNs. We implement our approach in a tool called\nPROVERO and apply it in the context of certifying adversarial robustness of\nDNNs. In this context, we first show a new attack-agnostic measure of\nrobustness which offers an alternative to purely attack-based methodology of\nevaluating robustness being reported today. Second, PROVERO provides\ncertificates of robustness for large DNNs, where existing state-of-the-art\nverification tools fail to produce conclusive results. Our work paves the way\nforward for verifying properties of distributions captured by real-world deep\nneural networks, with provable guarantees, even where testers only have\nblack-box access to the neural network.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:53:50 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 10:25:06 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Baluta", "Teodora", ""], ["Chua", "Zheng Leong", ""], ["Meel", "Kuldeep S.", ""], ["Saxena", "Prateek", ""]]}, {"id": "2002.06873", "submitter": "Swapnil Mishra", "authors": "Swapnil Mishra, Seth Flaxman, Harrison Zhu, Samir Bhatt", "title": "$\\pi$VAE: Encoding stochastic process priors with variational\n  autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic processes provide a mathematically elegant way model complex data.\nIn theory, they provide flexible priors over function classes that can encode a\nwide range of interesting assumptions. In practice, however, efficient\ninference by optimisation or marginalisation is difficult, a problem further\nexacerbated with big data and high dimensional input spaces. We propose a novel\nvariational autoencoder (VAE) called the prior encoding variational autoencoder\n($\\pi$VAE). The $\\pi$VAE is finitely exchangeable and Kolmogorov consistent,\nand thus is a continuous stochastic process. We use $\\pi$VAE to learn low\ndimensional embeddings of function classes. We show that our framework can\naccurately learn expressive function classes such as Gaussian processes, but\nalso properties of functions to enable statistical inference (such as the\nintegral of a log Gaussian process). For popular tasks, such as spatial\ninterpolation, $\\pi$VAE achieves state-of-the-art performance both in terms of\naccuracy and computational efficiency. Perhaps most usefully, we demonstrate\nthat the low dimensional independently distributed latent space representation\nlearnt provides an elegant and scalable means of performing Bayesian inference\nfor stochastic processes within probabilistic programming languages such as\nStan.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 10:23:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 06:49:28 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 12:22:15 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mishra", "Swapnil", ""], ["Flaxman", "Seth", ""], ["Zhu", "Harrison", ""], ["Bhatt", "Samir", ""]]}, {"id": "2002.06898", "submitter": "Kumarjit Saha", "authors": "Subhroshekhar Ghosh and Kumarjit Saha", "title": "Transmission and navigation on disordered lattice networks, directed\n  spanning forests and Brownian web", "comments": "We improved the exposition of our approach to cover lattice\n  perturbations that are uniform in the unit Euclidean cube. In this version we\n  added many figures to explain our argument better", "journal-ref": null, "doi": "10.1007/s10955-020-02604-1", "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic networks based on random point sets as nodes have attracted\nconsiderable interest in many applications, particularly in communication\nnetworks, including wireless sensor networks, peer-to-peer networks and so on.\nThe study of such networks generally requires the nodes to be independently and\nuniformly distributed as a Poisson point process. In this work, we venture\nbeyond this standard paradigm and investigate the stochastic geometry of\nnetworks obtained from \\textit{directed spanning forests} (DSF) based on\nrandomly perturbed lattices, which have desirable statistical properties as a\nmodels of spatially dependent point fields. In the regime of low disorder, we\nshow in 2D and 3D that the DSF almost surely consists of a single tree. In 2D,\nwe further establish that the DSF, as a collection of paths, converges under\ndiffusive scaling to the Brownian web.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 11:45:49 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 05:20:49 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ghosh", "Subhroshekhar", ""], ["Saha", "Kumarjit", ""]]}, {"id": "2002.06910", "submitter": "Angelos Chatzimparmpas", "authors": "Angelos Chatzimparmpas, Rafael M. Martins, Andreas Kerren", "title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections", "comments": "This manuscript is published in the IEEE Transactions on\n  Visualization and Computer Graphics Journal (IEEE TVCG)", "journal-ref": "IEEE TVCG 2020, 26(8), 2696-2714", "doi": "10.1109/TVCG.2020.2986996", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-Distributed Stochastic Neighbor Embedding (t-SNE) for the visualization of\nmultidimensional data has proven to be a popular approach, with successful\napplications in a wide range of domains. Despite their usefulness, t-SNE\nprojections can be hard to interpret or even misleading, which hurts the\ntrustworthiness of the results. Understanding the details of t-SNE itself and\nthe reasons behind specific patterns in its output may be a daunting task,\nespecially for non-experts in dimensionality reduction. In this work, we\npresent t-viSNE, an interactive tool for the visual exploration of t-SNE\nprojections that enables analysts to inspect different aspects of their\naccuracy and meaning, such as the effects of hyper-parameters, distance and\nneighborhood preservation, densities and costs of specific neighborhoods, and\nthe correlations between dimensions and visual patterns. We propose a coherent,\naccessible, and well-integrated collection of different views for the\nvisualization of t-SNE projections. The applicability and usability of t-viSNE\nare demonstrated through hypothetical usage scenarios with real data sets.\nFinally, we present the results of a user study where the tool's effectiveness\nwas evaluated. By bringing to light information that would normally be lost\nafter running t-SNE, we hope to support analysts in using t-SNE and making its\nresults better understandable.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:22:34 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 09:37:40 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 05:12:47 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 20:40:37 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Chatzimparmpas", "Angelos", ""], ["Martins", "Rafael M.", ""], ["Kerren", "Andreas", ""]]}, {"id": "2002.06914", "submitter": "Max Berrendorf", "authors": "Max Berrendorf and Evgeniy Faerman and Laurent Vermue and Volker Tresp", "title": "On the Ambiguity of Rank-Based Evaluation of Entity Alignment or Link\n  Prediction Methods", "comments": "fixed a typo on page 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we take a closer look at the evaluation of two families of\nmethods for enriching information from knowledge graphs: Link Prediction and\nEntity Alignment. In the current experimental setting, multiple different\nscores are employed to assess different aspects of model performance. We\nanalyze the informativeness of these evaluation measures and identify several\nshortcomings. In particular, we demonstrate that all existing scores can hardly\nbe used to compare results across different datasets. Moreover, we demonstrate\nthat varying size of the test size automatically has impact on the performance\nof the same model based on commonly used metrics for the Entity Alignment task.\nWe show that this leads to various problems in the interpretation of results,\nwhich may support misleading conclusions. Therefore, we propose adjustments to\nthe evaluation and demonstrate empirically how this supports a fair,\ncomparable, and interpretable assessment of model performance. Our code is\navailable at https://github.com/mberr/rank-based-evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:26:14 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:42:48 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 16:12:47 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Vermue", "Laurent", ""], ["Tresp", "Volker", ""]]}, {"id": "2002.06945", "submitter": "Mahdi Boloursaz Mashhadi", "authors": "Mahdi Boloursaz Mashhadi, and Deniz G\\\"und\\\"uz", "title": "Deep Learning for Massive MIMO Channel State Acquisition and Feedback", "comments": "Accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (MIMO) systems are a main enabler of\nthe excessive throughput requirements in 5G and future generation wireless\nnetworks as they can serve many users simultaneously with high spectral and\nenergy efficiency. To achieve this, massive MIMO systems require accurate and\ntimely channel state information (CSI), which is acquired by a training process\nthat involves pilot transmission, CSI estimation and feedback. This training\nprocess incurs a training overhead, which scales with the number of antennas,\nusers and subcarriers. Reducing this training overhead in massive MIMO systems\nhas been a major topic of research since the emergence of the concept.\nRecently, deep learning (DL)-based approaches for massive MIMO training have\nbeen proposed and showed significant improvements compared to traditional\ntechniques. This paper provides an overview of how neural networks (NNs) can be\nused in the training process of massive MIMO systems to improve the performance\nby reducing the CSI acquisition overhead and to reduce complexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:16:34 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 11:17:59 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 18:30:54 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mashhadi", "Mahdi Boloursaz", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "2002.06946", "submitter": "Saad Mohamad", "authors": "Saad Mohamad and Giovanni Montana", "title": "Adaptive Experience Selection for Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient reinforcement learning (RL) algorithms have achieved\nimpressive performance in challenging learning tasks such as continuous\ncontrol, but suffer from high sample complexity. Experience replay is a\ncommonly used approach to improve sample efficiency, but gradient estimators\nusing past trajectories typically have high variance. Existing sampling\nstrategies for experience replay like uniform sampling or prioritised\nexperience replay do not explicitly try to control the variance of the gradient\nestimates. In this paper, we propose an online learning algorithm, adaptive\nexperience selection (AES), to adaptively learn an experience sampling\ndistribution that explicitly minimises this variance. Using a regret\nminimisation approach, AES iteratively updates the experience sampling\ndistribution to match the performance of a competitor distribution assumed to\nhave optimal variance. Sample non-stationarity is addressed by proposing a\ndynamic (i.e. time changing) competitor distribution for which a closed-form\nsolution is proposed. We demonstrate that AES is a low-regret algorithm with\nreasonable sample complexity. Empirically, AES has been implemented for deep\ndeterministic policy gradient and soft actor critic algorithms, and tested on 8\ncontinuous control tasks from the OpenAI Gym library. Ours results show that\nAES leads to significantly improved performance compared to currently available\nexperience sampling strategies for policy gradient.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:16:37 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Mohamad", "Saad", ""], ["Montana", "Giovanni", ""]]}, {"id": "2002.06967", "submitter": "Francesco Craighero", "authors": "Francesco Craighero, Fabrizio Angaroni, Alex Graudenzi, Fabio Stella,\n  Marco Antoniotti", "title": "Investigating the Compositional Structure Of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-64583-0_30", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current understanding of deep neural networks can only partially explain\nhow input structure, network parameters and optimization algorithms jointly\ncontribute to achieve the strong generalization power that is typically\nobserved in many real-world applications. In order to improve the comprehension\nand interpretability of deep neural networks, we here introduce a novel\ntheoretical framework based on the compositional structure of piecewise linear\nactivation functions. By defining a direct acyclic graph representing the\ncomposition of activation patterns through the network layers, it is possible\nto characterize the instances of the input data with respect to both the\npredicted label and the specific (linear) transformation used to perform\npredictions. Preliminary tests on the MNIST dataset show that our method can\ngroup input instances with regard to their similarity in the internal\nrepresentation of the neural network, providing an intuitive measure of input\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:16:17 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Craighero", "Francesco", ""], ["Angaroni", "Fabrizio", ""], ["Graudenzi", "Alex", ""], ["Stella", "Fabio", ""], ["Antoniotti", "Marco", ""]]}, {"id": "2002.06979", "submitter": "Zixin Wen", "authors": "Zixin Wen", "title": "Convergence of End-to-End Training in Deep Unsupervised Contrastive\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised contrastive learning has gained increasing attention in the\nlatest research and has proven to be a powerful method for learning\nrepresentations from unlabeled data. However, little theoretical analysis was\nknown for this framework. In this paper, we study the optimization of deep\nunsupervised contrastive learning. We prove that, by applying end-to-end\ntraining that simultaneously updates two deep over-parameterized neural\nnetworks, one can find an approximate stationary solution for the non-convex\ncontrastive loss. This result is inherently different from the existing\nover-parameterized analysis in the supervised setting because, in contrast to\nlearning a specific target function, unsupervised contrastive learning tries to\nencode the unlabeled data distribution into the neural networks, which\ngenerally has no optimal solution. Our analysis provides theoretical insights\ninto the practical success of these unsupervised pretraining methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:35:21 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 00:32:53 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 17:23:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wen", "Zixin", ""]]}, {"id": "2002.06987", "submitter": "Wei Deng", "authors": "Wei Deng and Junwei Pan and Tian Zhou and Deguang Kong and Aaron\n  Flores and Guang Lin", "title": "DeepLight: Deep Lightweight Feature Interactions for Accelerating CTR\n  Predictions in Ad Serving", "comments": "Accepted by WSDM 2021; Source code:\n  https://github.com/WayneDW/DeepLight_Deep-Lightweight-Feature-Interactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a crucial task in online display\nadvertising. The embedding-based neural networks have been proposed to learn\nboth explicit feature interactions through a shallow component and deep feature\ninteractions using a deep neural network (DNN) component. These sophisticated\nmodels, however, slow down the prediction inference by at least hundreds of\ntimes. To address the issue of significantly increased serving delay and high\nmemory usage for ad serving in production, this paper presents\n\\emph{DeepLight}: a framework to accelerate the CTR predictions in three\naspects: 1) accelerate the model inference via explicitly searching informative\nfeature interactions in the shallow component; 2) prune redundant layers and\nparameters at intra-layer and inter-layer level in the DNN component; 3)\npromote the sparsity of the embedding layer to preserve the most discriminant\nsignals. By combining the above efforts, the proposed approach accelerates the\nmodel inference by 46X on Criteo dataset and 27X on Avazu dataset without any\nloss on the prediction accuracy. This paves the way for successfully deploying\ncomplicated embedding-based neural networks in production for ad serving.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:51:31 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 01:46:08 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 22:13:51 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Deng", "Wei", ""], ["Pan", "Junwei", ""], ["Zhou", "Tian", ""], ["Kong", "Deguang", ""], ["Flores", "Aaron", ""], ["Lin", "Guang", ""]]}, {"id": "2002.06991", "submitter": "William Clements", "authors": "Robin Quessard, Thomas D. Barrett, William R. Clements", "title": "Learning Group Structure and Disentangled Representations of Dynamical\n  Environments", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations is a key step towards effectively\ndiscovering and modelling the underlying structure of environments. In the\nnatural sciences, physics has found great success by describing the universe in\nterms of symmetry preserving transformations. Inspired by this formalism, we\npropose a framework, built upon the theory of group representation, for\nlearning representations of a dynamical environment structured around the\ntransformations that generate its evolution. Experimentally, we learn the\nstructure of explicitly symmetric environments without supervision from\nobservational data generated by sequential interactions. We further introduce\nan intuitive disentanglement regularisation to ensure the interpretability of\nthe learnt representations. We show that our method enables accurate\nlong-horizon predictions, and demonstrate a correlation between the quality of\npredictions and disentanglement in the latent space.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:59:31 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 16:23:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Quessard", "Robin", ""], ["Barrett", "Thomas D.", ""], ["Clements", "William R.", ""]]}, {"id": "2002.07003", "submitter": "Deyi Liu", "authors": "Deyi Liu, Volkan Cevher, Quoc Tran-Dinh", "title": "A Newton Frank-Wolfe Method for Constrained Self-Concordant Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how to scalably solve a class of constrained self-concordant\nminimization problems using linear minimization oracles (LMO) over the\nconstraint set. We prove that the number of LMO calls of our method is nearly\nthe same as that of the Frank-Wolfe method in the L-smooth case. Specifically,\nour Newton Frank-Wolfe method uses $\\mathcal{O}(\\epsilon^{-\\nu})$ LMO's, where\n$\\epsilon$ is the desired accuracy and $\\nu:= 1 + o(1)$. In addition, we\ndemonstrate how our algorithm can exploit the improved variants of the\nLMO-based schemes, including away-steps, to attain linear convergence rates. We\nalso provide numerical evidence with portfolio design with the competitive\nratio, D-optimal experimental design, and logistic regression with the elastic\nnet where Newton Frank-Wolfe outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:28:31 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Liu", "Deyi", ""], ["Cevher", "Volkan", ""], ["Tran-Dinh", "Quoc", ""]]}, {"id": "2002.07007", "submitter": "Connor Coley", "authors": "Wenhao Gao, Connor W. Coley", "title": "The Synthesizability of Molecules Proposed by Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of functional molecules is an expensive and time-consuming\nprocess, exemplified by the rising costs of small molecule therapeutic\ndiscovery. One class of techniques of growing interest for early-stage drug\ndiscovery is de novo molecular generation and optimization, catalyzed by the\ndevelopment of new deep learning approaches. These techniques can suggest novel\nmolecular structures intended to maximize a multi-objective function, e.g.,\nsuitability as a therapeutic against a particular target, without relying on\nbrute-force exploration of a chemical space. However, the utility of these\napproaches is stymied by ignorance of synthesizability. To highlight the\nseverity of this issue, we use a data-driven computer-aided synthesis planning\nprogram to quantify how often molecules proposed by state-of-the-art generative\nmodels cannot be readily synthesized. Our analysis demonstrates that there are\nseveral tasks for which these models generate unrealistic molecular structures\ndespite performing well on popular quantitative benchmarks. Synthetic\ncomplexity heuristics can successfully bias generation toward\nsynthetically-tractable chemical space, although doing so necessarily detracts\nfrom the primary objective. This analysis suggests that to improve the utility\nof these models in real discovery workflows, new algorithm development is\nwarranted.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:41:28 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Wenhao", ""], ["Coley", "Connor W.", ""]]}, {"id": "2002.07017", "submitter": "Marco Federici", "authors": "Marco Federici, Anjan Dutta, Patrick Forr\\'e, Nate Kushman, Zeynep\n  Akata", "title": "Learning Robust Representations via Multi-View Information Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information bottleneck principle provides an information-theoretic method\nfor representation learning, by training an encoder to retain all information\nwhich is relevant for predicting the label while minimizing the amount of\nother, excess information in the representation. The original formulation,\nhowever, requires labeled data to identify the superfluous information. In this\nwork, we extend this ability to the multi-view unsupervised setting, where two\nviews of the same underlying entity are provided but the label is unknown. This\nenables us to identify superfluous information as that not shared by both\nviews. A theoretical analysis leads to the definition of a new multi-view model\nthat produces state-of-the-art results on the Sketchy dataset and label-limited\nversions of the MIR-Flickr dataset. We also extend our theory to the\nsingle-view setting by taking advantage of standard data augmentation\ntechniques, empirically showing better generalization capabilities when\ncompared to common unsupervised approaches for representation learning.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:01:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 09:47:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Federici", "Marco", ""], ["Dutta", "Anjan", ""], ["Forr\u00e9", "Patrick", ""], ["Kushman", "Nate", ""], ["Akata", "Zeynep", ""]]}, {"id": "2002.07019", "submitter": "Mingzhe Wang", "authors": "Mingzhe Wang, Jia Deng", "title": "Learning to Prove Theorems by Learning to Generate Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of automated theorem proving, a key AI task. Deep\nlearning has shown promise for training theorem provers, but there are limited\nhuman-written theorems and proofs available for supervised learning. To address\nthis limitation, we propose to learn a neural generator that automatically\nsynthesizes theorems and proofs for the purpose of training a theorem prover.\nExperiments on real-world tasks demonstrate that synthetic data from our\napproach improves the theorem prover and advances the state of the art of\nautomated theorem proving in Metamath. Code is available at\nhttps://github.com/princeton-vl/MetaGen.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:06:02 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 04:33:04 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Mingzhe", ""], ["Deng", "Jia", ""]]}, {"id": "2002.07024", "submitter": "Yahav Bechavod", "authors": "Yahav Bechavod, Katrina Ligett, Zhiwei Steven Wu, Juba Ziani", "title": "Gaming Helps! Learning from Strategic Interactions in Natural Dynamics", "comments": "The Conference version of this paper is to appear in the Proceedings\n  of AISTATS 2021. 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online regression setting in which individuals adapt to the\nregression model: arriving individuals are aware of the current model, and\ninvest strategically in modifying their own features so as to improve the\npredicted score that the current model assigns to them. Such feature\nmanipulation has been observed in various scenarios -- from credit assessment\nto school admissions -- posing a challenge for the learner. Surprisingly, we\nfind that such strategic manipulations may in fact help the learner recover the\nmeaningful variables -- that is, the features that, when changed, affect the\ntrue label (as opposed to non-meaningful features that have no effect). We show\nthat even simple behavior on the learner's part allows her to simultaneously i)\naccurately recover the meaningful features, and ii) incentivize agents to\ninvest in these meaningful features, providing incentives for improvement.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:09:37 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 19:04:00 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 15:45:05 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Bechavod", "Yahav", ""], ["Ligett", "Katrina", ""], ["Wu", "Zhiwei Steven", ""], ["Ziani", "Juba", ""]]}, {"id": "2002.07028", "submitter": "Srinadh Bhojanapalli", "authors": "Srinadh Bhojanapalli, Chulhee Yun, Ankit Singh Rawat, Sashank J.\n  Reddi, Sanjiv Kumar", "title": "Low-Rank Bottleneck in Multi-head Attention Models", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention based Transformer architecture has enabled significant advances in\nthe field of natural language processing. In addition to new pre-training\ntechniques, recent improvements crucially rely on working with a relatively\nlarger embedding dimension for tokens. Unfortunately, this leads to models that\nare prohibitively large to be employed in the downstream tasks. In this paper\nwe identify one of the important factors contributing to the large embedding\nsize requirement. In particular, our analysis highlights that the scaling\nbetween the number of heads and the size of each head in the current\narchitecture gives rise to a low-rank bottleneck in attention heads, causing\nthis limitation. We further validate this in our experiments. As a solution we\npropose to set the head size of an attention unit to input sequence length, and\nindependent of the number of heads, resulting in multi-head attention layers\nwith provably more expressive power. We empirically show that this allows us to\ntrain models with a relatively smaller embedding dimension and with better\nperformance scaling.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:16:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bhojanapalli", "Srinadh", ""], ["Yun", "Chulhee", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2002.07031", "submitter": "Qilin Li", "authors": "Qilin Li, Wanquan Liu, Ling Li", "title": "Regularizing Semi-supervised Graph Convolutional Networks with a\n  Manifold Smoothness Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph convolutional networks focus on the neighborhood aggregation\nscheme. When applied to semi-supervised learning, they often suffer from the\noverfitting problem as the networks are trained with the cross-entropy loss on\na small potion of labeled data. In this paper, we propose an unsupervised\nmanifold smoothness loss defined with respect to the graph structure, which can\nbe added to the loss function as a regularization. We draw connections between\nthe proposed loss with an iterative diffusion process, and show that minimizing\nthe loss is equivalent to aggregate neighbor predictions with infinite layers.\nWe conduct experiments on multi-layer perceptron and existing graph networks,\nand demonstrate that adding the proposed loss can improve the performance\nconsistently.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:51:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Li", "Qilin", ""], ["Liu", "Wanquan", ""], ["Li", "Ling", ""]]}, {"id": "2002.07064", "submitter": "Michele Gentili", "authors": "Michele Gentili, Leonardo Martini, Manuela Petti, Lorenzo Farina and\n  Luca Becchetti", "title": "Biological Random Walks: integrating heterogeneous data in disease gene\n  prioritization", "comments": null, "journal-ref": "2019 IEEE Conference on Computational Intelligence in\n  Bioinformatics and Computational Biology (CIBCB), 2019, 1-8", "doi": "10.1109/CIBCB.2019.8791472", "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a unified framework to leverage biological information in\nnetwork propagation-based gene prioritization algorithms. Preliminary results\non breast cancer data show significant improvements over state-of-the-art\nbaselines, such as the prioritization of genes that are not identified as\npotential candidates by interactome-based algorithms, but that appear to be\ninvolved in/or potentially related to breast cancer, according to a functional\nanalysis based on recent literature.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:46:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gentili", "Michele", ""], ["Martini", "Leonardo", ""], ["Petti", "Manuela", ""], ["Farina", "Lorenzo", ""], ["Becchetti", "Luca", ""]]}, {"id": "2002.07065", "submitter": "Xing Yong Kek", "authors": "Xing Yong Kek, Cheng Siong Chin, Ye Li", "title": "Acoustic Scene Classification Using Bilinear Pooling on Time-liked and\n  Frequency-liked Convolution Neural Network", "comments": "inclusion in conference proceedings 2019 IEEE Symposium Series on\n  Computational Intelligence (IEEE SSCI 2019), Xiamen", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current methodology in tackling Acoustic Scene Classification (ASC) task\ncan be described in two steps, preprocessing of the audio waveform into log-mel\nspectrogram and then using it as the input representation for Convolutional\nNeural Network (CNN). This paradigm shift occurs after DCASE 2016 where this\nframework model achieves the state-of-the-art result in ASC tasks on the\n(ESC-50) dataset and achieved an accuracy of 64.5%, which constitute to 20.5%\nimprovement over the baseline model, and DCASE 2016 dataset with an accuracy of\n90.0% (development) and 86.2% (evaluation), which constitute a 6.4% and 9%\nimprovements with respect to the baseline system. In this paper, we explored\nthe use of harmonic and percussive source separation (HPSS) to split the audio\ninto harmonic audio and percussive audio, which has received popularity in the\nfield of music information retrieval (MIR). Although works have been done in\nusing HPSS as input representation for CNN model in ASC task, this paper\nfurther investigate the possibility on leveraging the separated harmonic\ncomponent and percussive component by curating 2 CNNs which tries to understand\nharmonic audio and percussive audio in their natural form, one specialized in\nextracting deep features in time biased domain and another specialized in\nextracting deep features in frequency biased domain, respectively. The deep\nfeatures extracted from these 2 CNNs will then be combined using bilinear\npooling. Hence, presenting a two-stream time and frequency CNN architecture\napproach in classifying acoustic scene. The model is being evaluated on DCASE\n2019 sub task 1a dataset and scored an average of 65% on development dataset,\nKaggle Leadership Private and Public board.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:06:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kek", "Xing Yong", ""], ["Chin", "Cheng Siong", ""], ["Li", "Ye", ""]]}, {"id": "2002.07066", "submitter": "Yudong Chen", "authors": "Qiaomin Xie, Yudong Chen, Zhaoran Wang, Zhuoran Yang", "title": "Learning Zero-Sum Simultaneous-Move Markov Games Using Function\n  Approximation and Correlated Equilibrium", "comments": "Accepted for presentation at COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop provably efficient reinforcement learning algorithms for\ntwo-player zero-sum finite-horizon Markov games with simultaneous moves. To\nincorporate function approximation, we consider a family of Markov games where\nthe reward function and transition kernel possess a linear structure. Both the\noffline and online settings of the problems are considered. In the offline\nsetting, we control both players and aim to find the Nash Equilibrium by\nminimizing the duality gap. In the online setting, we control a single player\nplaying against an arbitrary opponent and aim to minimize the regret. For both\nsettings, we propose an optimistic variant of the least-squares minimax value\niteration algorithm. We show that our algorithm is computationally efficient\nand provably achieves an $\\tilde O(\\sqrt{d^3 H^3 T} )$ upper bound on the\nduality gap and regret, where $d$ is the linear dimension, $H$ the horizon and\n$T$ the total number of timesteps. Our results do not require additional\nassumptions on the sampling model.\n  Our setting requires overcoming several new challenges that are absent in\nMarkov decision processes or turn-based Markov games. In particular, to achieve\noptimism with simultaneous moves, we construct both upper and lower confidence\nbounds of the value function, and then compute the optimistic policy by solving\na general-sum matrix game with these bounds as the payoff matrices. As finding\nthe Nash Equilibrium of a general-sum game is computationally hard, our\nalgorithm instead solves for a Coarse Correlated Equilibrium (CCE), which can\nbe obtained efficiently. To our best knowledge, such a CCE-based scheme for\noptimism has not appeared in the literature and might be of interest in its own\nright.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:04:16 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 21:38:20 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 21:09:42 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Xie", "Qiaomin", ""], ["Chen", "Yudong", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""]]}, {"id": "2002.07069", "submitter": "Daniel Griffin", "authors": "Daniel K. Griffin", "title": "The Big Three: A Methodology to Increase Data Science ROI by Answering\n  the Questions Companies Care About", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Companies may be achieving only a third of the value they could be getting\nfrom data science in industry applications. In this paper, we propose a\nmethodology for categorizing and answering 'The Big Three' questions (what is\ngoing on, what is causing it, and what actions can I take that will optimize\nwhat I care about) using data science. The applications of data science seem to\nbe nearly endless in today's modern landscape, with each company jockeying for\nposition in the new data and insights economy. Yet, data scientists seem to be\nsolely focused on using classification, regression, and clustering methods to\nanswer the question 'what is going on'. Answering questions about why things\nare happening or how to take optimal actions to improve metrics are relegated\nto niche fields of research and generally neglected in industry data science\nanalysis. We survey technical methods to answer these other important\nquestions, describe areas in which some of these methods are being applied, and\nprovide a practical example of how to apply our methodology and selected\nmethods to a real business use case.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:25:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Griffin", "Daniel K.", ""]]}, {"id": "2002.07076", "submitter": "Florian Adriaens", "authors": "Florian Adriaens, Alexandru Mara, Jefrey Lijffijt, Tijl De Bie", "title": "Block-Approximated Exponential Random Graphs", "comments": "Accepted for DSAA 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge in the field of exponential random graphs (ERGs) is\nthe fitting of non-trivial ERGs on large graphs. By utilizing fast matrix\nblock-approximation techniques, we propose an approximative framework to such\nnon-trivial ERGs that result in dyadic independence (i.e., edge independent)\ndistributions, while being able to meaningfully model both local information of\nthe graph (e.g., degrees) as well as global information (e.g., clustering\ncoefficient, assortativity, etc.) if desired. This allows one to efficiently\ngenerate random networks with similar properties as an observed network, and\nthe models can be used for several downstream tasks such as link prediction.\nOur methods are scalable to sparse graphs consisting of millions of nodes.\nEmpirical evaluation demonstrates competitiveness in terms of both speed and\naccuracy with state-of-the-art methods -- which are typically based on\nembedding the graph into some low-dimensional space -- for link prediction,\nshowcasing the potential of a more direct and interpretable probabalistic model\nfor this task.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:42:16 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 13:42:09 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Adriaens", "Florian", ""], ["Mara", "Alexandru", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.07087", "submitter": "Daniel Flam-Shepherd", "authors": "Daniel Flam-Shepherd, Tony Wu and Alan Aspuru-Guzik", "title": "Graph Deconvolutional Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generation is an extremely important task, as graphs are found\nthroughout different areas of science and engineering. In this work, we focus\non the modern equivalent of the Erdos-Renyi random graph model: the graph\nvariational autoencoder (GVAE). This model assumes edges and nodes are\nindependent in order to generate entire graphs at a time using a multi-layer\nperceptron decoder. As a result of these assumptions, GVAE has difficulty\nmatching the training distribution and relies on an expensive graph matching\nprocedure. We improve this class of models by building a message passing neural\nnetwork into GVAE's encoder and decoder. We demonstrate our model on the\nspecific task of generating small organic molecules\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:37:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Flam-Shepherd", "Daniel", ""], ["Wu", "Tony", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2002.07089", "submitter": "Samaneh Abbasi Sureshjani", "authors": "Samaneh Abbasi-Sureshjani, Sina Amirrajab, Cristian Lorenz, Juergen\n  Weese, Josien Pluim, Marcel Breeuwer", "title": "4D Semantic Cardiac Magnetic Resonance Image Synthesis on XCAT\n  Anatomical Model", "comments": "Accepted to MIDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid controllable image generation method to synthesize\nanatomically meaningful 3D+t labeled Cardiac Magnetic Resonance (CMR) images.\nOur hybrid method takes the mechanistic 4D eXtended CArdiac Torso (XCAT) heart\nmodel as the anatomical ground truth and synthesizes CMR images via a\ndata-driven Generative Adversarial Network (GAN). We employ the\nstate-of-the-art SPatially Adaptive De-normalization (SPADE) technique for\nconditional image synthesis to preserve the semantic spatial information of\nground truth anatomy. Using the parameterized motion model of the XCAT heart,\nwe generate labels for 25 time frames of the heart for one cardiac cycle at 18\nlocations for the short axis view. Subsequently, realistic images are generated\nfrom these labels, with modality-specific features that are learned from real\nCMR image data. We demonstrate that style transfer from another cardiac image\ncan be accomplished by using a style encoder network. Due to the flexibility of\nXCAT in creating new heart models, this approach can result in a realistic\nvirtual population to address different challenges the medical image analysis\nresearch community is facing such as expensive data collection. Our proposed\nmethod has a great potential to synthesize 4D controllable CMR images with\nannotations and adaptable styles to be used in various supervised multi-site,\nmulti-vendor applications in medical image analysis.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:25:07 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 16:55:32 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 14:01:13 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Abbasi-Sureshjani", "Samaneh", ""], ["Amirrajab", "Sina", ""], ["Lorenz", "Cristian", ""], ["Weese", "Juergen", ""], ["Pluim", "Josien", ""], ["Breeuwer", "Marcel", ""]]}, {"id": "2002.07101", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Laurent Dinh, Aaron Courville", "title": "Augmented Normalizing Flows: Bridging the Gap Between Generative Flows\n  and Latent Variable Models", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new family of generative flows on an augmented\ndata space, with an aim to improve expressivity without drastically increasing\nthe computational cost of sampling and evaluation of a lower bound on the\nlikelihood. Theoretically, we prove the proposed flow can approximate a\nHamiltonian ODE as a universal transport map. Empirically, we demonstrate\nstate-of-the-art performance on standard benchmarks of flow-based generative\nmodeling.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:45:48 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Dinh", "Laurent", ""], ["Courville", "Aaron", ""]]}, {"id": "2002.07106", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Naveen Arivazhagan, Orhan Firat", "title": "Controlling Computation versus Quality for Neural Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural networks utilize the same amount of compute for every example\nindependent of the inherent complexity of the input. Further, methods that\nadapt the amount of computation to the example focus on finding a fixed\ninference-time computational graph per example, ignoring any external\ncomputational budgets or varying inference time limitations. In this work, we\nutilize conditional computation to make neural sequence models (Transformer)\nmore efficient and computation-aware during inference. We first modify the\nTransformer architecture, making each set of operations conditionally\nexecutable depending on the output of a learned control network. We then train\nthis model in a multi-task setting, where each task corresponds to a particular\ncomputation budget. This allows us to train a single model that can be\ncontrolled to operate on different points of the computation-quality trade-off\ncurve, depending on the available computation budget at inference time. We\nevaluate our approach on two tasks: (i) WMT English-French Translation and (ii)\nUnsupervised representation learning (BERT). Our experiments demonstrate that\nthe proposed Conditional Computation Transformer (CCT) is competitive with\nvanilla Transformers when allowed to utilize its full computational budget,\nwhile improving significantly over computationally equivalent baselines when\noperating on smaller computational budgets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:54:27 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 15:01:45 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bapna", "Ankur", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "2002.07113", "submitter": "Alaa Abdel-Hakim Ph. D.", "authors": "Alaa E. Abdel-Hakim and Wael Deabes", "title": "Handling Missing Annotations in Supervised Learning Data", "comments": "14 pages, 13 figures, 2 tables", "journal-ref": "Abdel Hakim, Alaa E., and Wael Deabes. \"Can People Really Do\n  Nothing? Handling Annotation Gaps in ADL Sensor Data.\" Algorithms 12, no. 10\n  (2019): 217", "doi": "10.3390/a12100217", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data annotation is an essential stage in supervised learning. However, the\nannotation process is exhaustive and time consuming, specially for large\ndatasets. Activities of Daily Living (ADL) recognition is an example of systems\nthat exploit very large raw sensor data readings. In such systems, sensor\nreadings are collected from activity-monitoring sensors in a 24/7 manner. The\nsize of the generated dataset is so huge that it is almost impossible for a\nhuman annotator to give a certain label to every single instance in the\ndataset. This results in annotation gaps in the input data to the adopting\nsupervised learning system. The performance of the recognition system is\nnegatively affected by these gaps. In this work, we propose and investigate\nthree different paradigms to handle these gaps. In the first paradigm, the gaps\nare taken out by dropping all unlabeled readings. A single \"Unknown\" or\n\"Do-Nothing\" label is given to the unlabeled readings within the operation of\nthe second paradigm. The last paradigm handles these gaps by giving every one\nof them a unique label identifying the encapsulating deterministic labels.\nAlso, we propose a semantic preprocessing method of annotation gaps by\nconstructing a hybrid combination of some of these paradigms for further\nperformance improvement. The performance of the proposed three paradigms and\ntheir hybrid combination is evaluated using an ADL benchmark dataset containing\nmore than $2.5\\times 10^6$ sensor readings that had been collected over more\nthan nine months. The evaluation results emphasize the performance contrast\nunder the operation of each paradigm and support a specific gap handling\napproach for better performance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:23:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Abdel-Hakim", "Alaa E.", ""], ["Deabes", "Wael", ""]]}, {"id": "2002.07125", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Gaurav Mahajan, Ruosong Wang", "title": "Agnostic Q-learning with Function Approximation in Deterministic\n  Systems: Tight Bounds on Approximation Error and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper studies the problem of agnostic $Q$-learning with function\napproximation in deterministic systems where the optimal $Q$-function is\napproximable by a function in the class $\\mathcal{F}$ with approximation error\n$\\delta \\ge 0$. We propose a novel recursion-based algorithm and show that if\n$\\delta = O\\left(\\rho/\\sqrt{\\dim_E}\\right)$, then one can find the optimal\npolicy using $O\\left(\\dim_E\\right)$ trajectories, where $\\rho$ is the gap\nbetween the optimal $Q$-value of the best actions and that of the second-best\nactions and $\\dim_E$ is the Eluder dimension of $\\mathcal{F}$. Our result has\ntwo implications:\n  1) In conjunction with the lower bound in [Du et al., ICLR 2020], our upper\nbound suggests that the condition $\\delta =\n\\widetilde{\\Theta}\\left(\\rho/\\sqrt{\\mathrm{dim}_E}\\right)$ is necessary and\nsufficient for algorithms with polynomial sample complexity.\n  2) In conjunction with the lower bound in [Wen and Van Roy, NIPS 2013], our\nupper bound suggests that the sample complexity\n$\\widetilde{\\Theta}\\left(\\mathrm{dim}_E\\right)$ is tight even in the agnostic\nsetting.\n  Therefore, we settle the open problem on agnostic $Q$-learning proposed in\n[Wen and Van Roy, NIPS 2013]. We further extend our algorithm to the stochastic\nreward setting and obtain similar results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:41:49 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Mahajan", "Gaurav", ""], ["Wang", "Ruosong", ""]]}, {"id": "2002.07128", "submitter": "Arijit Sehanobish", "authors": "Neal G. Ravindra, Arijit Sehanobish, Jenna L. Pappalardo, David A.\n  Hafler, David van Dijk", "title": "Disease State Prediction From Single-Cell Data Using Graph Attention\n  Networks", "comments": "Incorporated suggestions from anonymous reviewers, Accepted at ACM\n  CHIL 2020, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-cell RNA sequencing (scRNA-seq) has revolutionized biological\ndiscovery, providing an unbiased picture of cellular heterogeneity in tissues.\nWhile scRNA-seq has been used extensively to provide insight into both healthy\nsystems and diseases, it has not been used for disease prediction or\ndiagnostics. Graph Attention Networks (GAT) have proven to be versatile for a\nwide range of tasks by learning from both original features and graph\nstructures. Here we present a graph attention model for predicting disease\nstate from single-cell data on a large dataset of Multiple Sclerosis (MS)\npatients. MS is a disease of the central nervous system that can be difficult\nto diagnose. We train our model on single-cell data obtained from blood and\ncerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy\nadults (HA), resulting in 66,667 individual cells. We achieve 92 % accuracy in\npredicting MS, outperforming other state-of-the-art methods such as a graph\nconvolutional network and a random forest classifier. Further, we use the\nlearned graph attention model to get insight into the features (cell types and\ngenes) that are important for this prediction. The graph attention model also\nallow us to infer a new feature space for the cells that emphasizes the\ndifferences between the two conditions. Finally we use the attention weights to\nlearn a new low-dimensional embedding that can be visualized. To the best of\nour knowledge, this is the first effort to use graph attention, and deep\nlearning in general, to predict disease state from single-cell data. We\nenvision applying this method to single-cell data for other diseases.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:08:30 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 21:29:15 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Ravindra", "Neal G.", ""], ["Sehanobish", "Arijit", ""], ["Pappalardo", "Jenna L.", ""], ["Hafler", "David A.", ""], ["van Dijk", "David", ""]]}, {"id": "2002.07141", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis", "title": "Subset Sampling For Progressive Neural Network Learning", "comments": "accepted in ICIP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progressive Neural Network Learning is a class of algorithms that\nincrementally construct the network's topology and optimize its parameters\nbased on the training data. While this approach exempts the users from the\nmanual task of designing and validating multiple network topologies, it often\nrequires an enormous number of computations. In this paper, we propose to speed\nup this process by exploiting subsets of training data at each incremental\ntraining step. Three different sampling strategies for selecting the training\nsamples according to different criteria are proposed and evaluated. We also\npropose to perform online hyperparameter selection during the network\nprogression, which further reduces the overall training time. Experimental\nresults in object, scene and face recognition problems demonstrate that the\nproposed approach speeds up the optimization procedure considerably while\noperating on par with the baseline approach exploiting the entire training set\nthroughout the training process.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:57:33 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:47:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2002.07161", "submitter": "Marco Virgolin", "authors": "M. Virgolin, Z. Wang, B.V. Balgobind, I.W.E.M. van Dijk, J. Wiersma,\n  P.S. Kroon, G.O. Janssens, M. van Herk, D.C. Hodgson, L. Zadravec Zaletel,\n  C.R.N. Rasch, A. Bel, P.A.N. Bosman, T. Alderliesten", "title": "Surrogate-free machine learning-based organ dose reconstruction for\n  pediatric abdominal radiotherapy", "comments": "M. Virgolin and Z. Wang share first authorship", "journal-ref": "Physics in Medicine & Biology. 2020 Dec 8;65(24):245021", "doi": "10.1088/1361-6560/ab9fcc", "report-no": null, "categories": "physics.med-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To study radiotherapy-related adverse effects, detailed dose information (3D\ndistribution) is needed for accurate dose-effect modeling. For childhood cancer\nsurvivors who underwent radiotherapy in the pre-CT era, only 2D radiographs\nwere acquired, thus 3D dose distributions must be reconstructed from limited\ninformation. State-of-the-art methods achieve this by using 3D surrogate\nanatomies. These can lack personalization and lead to coarse reconstructions.\nWe present and validate a surrogate-free dose reconstruction method based on\nMachine Learning (ML). Abdominal planning CTs ($n$=142) of recently-treated\nchildhood cancer patients were gathered, their organs at risk were segmented,\nand 300 artificial Wilms' tumor plans were sampled automatically. Each\nartificial plan was automatically emulated on the 142 CTs, resulting in 42,600\n3D dose distributions from which dose-volume metrics were derived. Anatomical\nfeatures were extracted from digitally reconstructed radiographs simulated from\nthe CTs to resemble historical radiographs. Further, patient and radiotherapy\nplan features typically available from historical treatment records were\ncollected. An evolutionary ML algorithm was then used to link features to\ndose-volume metrics. Besides 5-fold cross-validation, a further evaluation was\ndone on an independent dataset of five CTs each associated with two clinical\nplans. Cross-validation resulted in Mean Absolute Errors (MAEs) $\\leq$0.6 Gy\nfor organs completely inside or outside the field. For organs positioned at the\nedge of the field, MAEs $\\leq$1.7 Gy for D$_{mean}$, $\\leq$2.9 Gy for\nD$_{2cc}$, and $\\leq$13% for V$_{5Gy}$ and V$_{10Gy}$, were obtained, without\nsystematic bias. Similar results were found for the independent dataset. Our\nnovel, ML-based organ dose reconstruction method is not only accurate but also\nefficient, as the setup of a surrogate is no longer needed.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:19:01 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 17:30:15 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Virgolin", "M.", ""], ["Wang", "Z.", ""], ["Balgobind", "B. V.", ""], ["van Dijk", "I. W. E. M.", ""], ["Wiersma", "J.", ""], ["Kroon", "P. S.", ""], ["Janssens", "G. O.", ""], ["van Herk", "M.", ""], ["Hodgson", "D. C.", ""], ["Zaletel", "L. Zadravec", ""], ["Rasch", "C. R. N.", ""], ["Bel", "A.", ""], ["Bosman", "P. A. N.", ""], ["Alderliesten", "T.", ""]]}, {"id": "2002.07171", "submitter": "Shirli Di-Castro Shashua", "authors": "Shirli Di-Castro Shashua, Shie Mannor", "title": "Kalman meets Bellman: Improving Policy Evaluation through Value Tracking", "comments": "arXiv admin note: substantial text overlap with arXiv:1901.07860", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation is a key process in Reinforcement Learning (RL). It\nassesses a given policy by estimating the corresponding value function. When\nusing parameterized value functions, common approaches minimize the sum of\nsquared Bellman temporal-difference errors and receive a point-estimate for the\nparameters. Kalman-based and Gaussian-processes based frameworks were suggested\nto evaluate the policy by treating the value as a random variable. These\nframeworks can learn uncertainties over the value parameters and exploit them\nfor policy exploration. When adopting these frameworks to solve deep RL tasks,\nseveral limitations are revealed: excessive computations in each optimization\nstep, difficulty with handling batches of samples which slows training and the\neffect of memory in stochastic environments which prevents off-policy learning.\nIn this work, we discuss these limitations and propose to overcome them by an\nalternative general framework, based on the extended Kalman filter. We devise\nan optimization method, called Kalman Optimization for Value Approximation\n(KOVA) that can be incorporated as a policy evaluation component in policy\noptimization algorithms. KOVA minimizes a regularized objective function that\nconcerns both parameter and noisy return uncertainties. We analyze the\nproperties of KOVA and present its performance on deep RL control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:30:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shashua", "Shirli Di-Castro", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.07173", "submitter": "Koosha Zarei", "authors": "Koosha Zarei, Reza Farahbakhsh, Noel Crespi", "title": "How Impersonators Exploit Instagram to Generate Fake Engagement?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Impersonators on Online Social Networks such as Instagram are playing an\nimportant role in the propagation of the content. These entities are the type\nof nefarious fake accounts that intend to disguise a legitimate account by\nmaking similar profiles. In addition to having impersonated profiles, we\nobserved a considerable engagement from these entities to the published posts\nof verified accounts. Toward that end, we concentrate on the engagement of\nimpersonators in terms of active and passive engagements which is studied in\nthree major communities including ``Politician'', ``News agency'', and ``Sports\nstar'' on Instagram. Inside each community, four verified accounts have been\nselected. Based on the implemented approach in our previous studies, we have\ncollected 4.8K comments, and 2.6K likes across 566 posts created from 3.8K\nimpersonators during 7 months. Our study shed light into this interesting\nphenomena and provides a surprising observation that can help us to understand\nbetter how impersonators engaging themselves inside Instagram in terms of\nwriting Comments and leaving Likes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:53:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zarei", "Koosha", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "2002.07206", "submitter": "Jiyang Bai", "authors": "Jiyang Bai, Yuxiang Ren, Jiawei Zhang", "title": "Ripple Walk Training: A Subgraph-based training framework for Large and\n  Deep Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved outstanding performance in\nlearning graph-structured data and various tasks. However, many current GNNs\nsuffer from three common problems when facing large-size graphs or using a\ndeeper structure: neighbors explosion, node dependence, and oversmoothing. Such\nproblems attribute to the data structures of the graph itself or the designing\nof the multi-layers GNNs framework, and can lead to low training efficiency and\nhigh space complexity. To deal with these problems, in this paper, we propose a\ngeneral subgraph-based training framework, namely Ripple Walk Training (RWT),\nfor deep and large graph neural networks. RWT samples subgraphs from the full\ngraph to constitute a mini-batch, and the full GNN is updated based on the\nmini-batch gradient. We analyze the high-quality subgraphs to train GNNs in a\ntheoretical way. A novel sampling method Ripple Walk Sampler works for sampling\nthese high-quality subgraphs to constitute the mini-batch, which considers both\nthe randomness and connectivity of the graph-structured data. Extensive\nexperiments on different sizes of graphs demonstrate the effectiveness and\nefficiency of RWT in training various GNNs (GCN & GAT).\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:07:41 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 17:22:50 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 16:22:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bai", "Jiyang", ""], ["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "2002.07214", "submitter": "Ziwei Guan", "authors": "Ziwei Guan, Kaiyi Ji, Donald J Bucci Jr, Timothy Y Hu, Joseph Palombo,\n  Michael Liston, Yingbin Liang", "title": "Robust Stochastic Bandit Algorithms under Probabilistic Unbounded\n  Adversarial Attack", "comments": "Published at AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit formalism has been extensively studied under various\nattack models, in which an adversary can modify the reward revealed to the\nplayer. Previous studies focused on scenarios where the attack value either is\nbounded at each round or has a vanishing probability of occurrence. These\nmodels do not capture powerful adversaries that can catastrophically perturb\nthe revealed reward. This paper investigates the attack model where an\nadversary attacks with a certain probability at each round, and its attack\nvalue can be arbitrary and unbounded if it attacks. Furthermore, the attack\nvalue does not necessarily follow a statistical distribution. We propose a\nnovel sample median-based and exploration-aided UCB algorithm (called\nmed-E-UCB) and a median-based $\\epsilon$-greedy algorithm (called\nmed-$\\epsilon$-greedy). Both of these algorithms are provably robust to the\naforementioned attack model. More specifically we show that both algorithms\nachieve $\\mathcal{O}(\\log T)$ pseudo-regret (i.e., the optimal regret without\nattacks). We also provide a high probability guarantee of $\\mathcal{O}(\\log T)$\nregret with respect to random rewards and random occurrence of attacks. These\nbounds are achieved under arbitrary and unbounded reward perturbation as long\nas the attack probability does not exceed a certain constant threshold. We\nprovide multiple synthetic simulations of the proposed algorithms to verify\nthese claims and showcase the inability of existing techniques to achieve\nsublinear regret. We also provide experimental results of the algorithm\noperating in a cognitive radio setting using multiple software-defined radios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:21:08 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Guan", "Ziwei", ""], ["Ji", "Kaiyi", ""], ["Bucci", "Donald J", "Jr"], ["Hu", "Timothy Y", ""], ["Palombo", "Joseph", ""], ["Liston", "Michael", ""], ["Liang", "Yingbin", ""]]}, {"id": "2002.07217", "submitter": "Romain Lopez", "authors": "Romain Lopez, Pierre Boyeau, Nir Yosef, Michael I. Jordan and Jeffrey\n  Regier", "title": "Decision-Making with Auto-Encoding Variational Bayes", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To make decisions based on a model fit with auto-encoding variational Bayes\n(AEVB), practitioners often let the variational distribution serve as a\nsurrogate for the posterior distribution. This approach yields biased estimates\nof the expected risk, and therefore leads to poor decisions for two reasons.\nFirst, the model fit with AEVB may not equal the underlying data distribution.\nSecond, the variational distribution may not equal the posterior distribution\nunder the fitted model. We explore how fitting the variational distribution\nbased on several objective functions other than the ELBO, while continuing to\nfit the generative model based on the ELBO, affects the quality of downstream\ndecisions. For the probabilistic principal component analysis model, we\ninvestigate how importance sampling error, as well as the bias of the model\nparameter estimates, varies across several approximate posteriors when used as\nproposal distributions. Our theoretical results suggest that a posterior\napproximation distinct from the variational distribution should be used for\nmaking decisions. Motivated by these theoretical results, we propose learning\nseveral approximate proposals for the best model and combining them using\nmultiple importance sampling for decision-making. In addition to toy examples,\nwe present a full-fledged case study of single-cell RNA sequencing. In this\nchallenging instance of multiple hypothesis testing, our proposed approach\nsurpasses the current state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:23:36 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:34:20 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 18:01:59 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lopez", "Romain", ""], ["Boyeau", "Pierre", ""], ["Yosef", "Nir", ""], ["Jordan", "Michael I.", ""], ["Regier", "Jeffrey", ""]]}, {"id": "2002.07224", "submitter": "Garrett Bingham", "authors": "Garrett Bingham, William Macke, and Risto Miikkulainen", "title": "Evolutionary Optimization of Deep Learning Activation Functions", "comments": "8 pages; 9 figures/tables; GECCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of activation function can have a large effect on the performance\nof a neural network. While there have been some attempts to hand-engineer novel\nactivation functions, the Rectified Linear Unit (ReLU) remains the most\ncommonly-used in practice. This paper shows that evolutionary algorithms can\ndiscover novel activation functions that outperform ReLU. A tree-based search\nspace of candidate activation functions is defined and explored with mutation,\ncrossover, and exhaustive search. Experiments on training wide residual\nnetworks on the CIFAR-10 and CIFAR-100 image datasets show that this approach\nis effective. Replacing ReLU with evolved activation functions results in\nstatistically significant increases in network accuracy. Optimal performance is\nachieved when evolution is allowed to customize activation functions to a\nparticular task; however, these novel activation functions are shown to\ngeneralize, achieving high performance across tasks. Evolutionary optimization\nof activation functions is therefore a promising new dimension of metalearning\nin neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:54:26 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 15:53:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bingham", "Garrett", ""], ["Macke", "William", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.07233", "submitter": "Jason Lee", "authors": "Jason Lee, Dustin Tran, Orhan Firat, Kyunghyun Cho", "title": "On the Discrepancy between Density Estimation and Sequence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequence-to-sequence generation tasks, including machine translation and\ntext-to-speech, can be posed as estimating the density of the output y given\nthe input x: p(y|x). Given this interpretation, it is natural to evaluate\nsequence-to-sequence models using conditional log-likelihood on a test set.\nHowever, the goal of sequence-to-sequence generation (or structured prediction)\nis to find the best output y^ given an input x, and each task has its own\ndownstream metric R that scores a model output by comparing against a set of\nreferences y*: R(y^, y* | x). While we hope that a model that excels in density\nestimation also performs well on the downstream metric, the exact correlation\nhas not been studied for sequence generation tasks. In this paper, by comparing\nseveral density estimators on five machine translation tasks, we find that the\ncorrelation between rankings of models based on log-likelihood and BLEU varies\nsignificantly depending on the range of the model families being compared.\nFirst, log-likelihood is highly correlated with BLEU when we consider models\nwithin the same family (e.g. autoregressive models, or latent variable models\nwith the same parameterization of the prior). However, we observe no\ncorrelation between rankings of models across different families: (1) among\nnon-autoregressive latent variable models, a flexible prior distribution is\nbetter at density estimation but gives worse generation quality than a simple\nprior, and (2) autoregressive models offer the best translation performance\noverall, while latent variable models with a normalizing flow prior give the\nhighest held-out log-likelihood across all datasets. Therefore, we recommend\nusing a simple prior for the latent variable non-autoregressive model when fast\ngeneration speed is desired.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:13:35 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lee", "Jason", ""], ["Tran", "Dustin", ""], ["Firat", "Orhan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2002.07236", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Keertana Settaluri, Pieter Abbeel, Vladimir\n  Stojanovic", "title": "GACEM: Generalized Autoregressive Cross Entropy Method for Multi-Modal\n  Black Box Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new method of black-box optimization and constraint\nsatisfaction. Existing algorithms that have attempted to solve this problem are\nunable to consider multiple modes, and are not able to adapt to changes in\nenvironment dynamics. To address these issues, we developed a modified\nCross-Entropy Method (CEM) that uses a masked auto-regressive neural network\nfor modeling uniform distributions over the solution space. We train the model\nusing maximum entropy policy gradient methods from Reinforcement Learning. Our\nalgorithm is able to express complicated solution spaces, thus allowing it to\ntrack a variety of different solution regions. We empirically compare our\nalgorithm with variations of CEM, including one with a Gaussian prior with\nfixed variance, and demonstrate better performance in terms of: number of\ndiverse solutions, better mode discovery in multi-modal problems, and better\nsample efficiency in certain cases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:21:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Settaluri", "Keertana", ""], ["Abbeel", "Pieter", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "2002.07246", "submitter": "Huijie Feng", "authors": "Huijie Feng, Chunpeng Wu, Guoyang Chen, Weifeng Zhang, Yang Ning", "title": "Regularized Training and Tight Certification for Randomized Smoothed\n  Classifier with Provable Robustness", "comments": "AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently smoothing deep neural network based classifiers via isotropic\nGaussian perturbation is shown to be an effective and scalable way to provide\nstate-of-the-art probabilistic robustness guarantee against $\\ell_2$ norm\nbounded adversarial perturbations. However, how to train a good base classifier\nthat is accurate and robust when smoothed has not been fully investigated. In\nthis work, we derive a new regularized risk, in which the regularizer can\nadaptively encourage the accuracy and robustness of the smoothed counterpart\nwhen training the base classifier. It is computationally efficient and can be\nimplemented in parallel with other empirical defense methods. We discuss how to\nimplement it under both standard (non-adversarial) and adversarial training\nscheme. At the same time, we also design a new certification algorithm, which\ncan leverage the regularization effect to provide tighter robustness lower\nbound that holds with high probability. Our extensive experimentation\ndemonstrates the effectiveness of the proposed training and certification\napproaches on CIFAR-10 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:54:34 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Feng", "Huijie", ""], ["Wu", "Chunpeng", ""], ["Chen", "Guoyang", ""], ["Zhang", "Weifeng", ""], ["Ning", "Yang", ""]]}, {"id": "2002.07252", "submitter": "Fatemeh Salehi Rizi", "authors": "Joerg Schloetterer, Martin Wehking, Fatemeh Salehi Rizi, Michael\n  Granitzer", "title": "Investigating Extensions to Random Walk Based Graph Embedding", "comments": null, "journal-ref": null, "doi": "10.1109/ICCC.2019.00026", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph embedding has recently gained momentum in the research community, in\nparticular after the introduction of random walk and neural network based\napproaches. However, most of the embedding approaches focus on representing the\nlocal neighborhood of nodes and fail to capture the global graph structure,\ni.e. to retain the relations to distant nodes. To counter that problem, we\npropose a novel extension to random walk based graph embedding, which removes a\npercentage of least frequent nodes from the walks at different levels. By this\nremoval, we simulate farther distant nodes to reside in the close neighborhood\nof a node and hence explicitly represent their connection. Besides the common\nevaluation tasks for graph embeddings, such as node classification and link\nprediction, we evaluate and compare our approach against related methods on\nshortest path approximation. The results indicate, that extensions to random\nwalk based methods (including our own) improve the predictive performance only\nslightly - if at all.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:14:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Schloetterer", "Joerg", ""], ["Wehking", "Martin", ""], ["Rizi", "Fatemeh Salehi", ""], ["Granitzer", "Michael", ""]]}, {"id": "2002.07258", "submitter": "Richard Combes", "authors": "Thibaut Cuvelier and Richard Combes and Eric Gourdin", "title": "Statistically Efficient, Polynomial Time Algorithms for Combinatorial\n  Semi Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider combinatorial semi-bandits over a set of arms ${\\cal X} \\subset\n\\{0,1\\}^d$ where rewards are uncorrelated across items. For this problem, the\nalgorithm ESCB yields the smallest known regret bound $R(T) = {\\cal O}\\Big( {d\n(\\ln m)^2 (\\ln T) \\over \\Delta_{\\min} }\\Big)$, but it has computational\ncomplexity ${\\cal O}(|{\\cal X}|)$ which is typically exponential in $d$, and\ncannot be used in large dimensions. We propose the first algorithm which is\nboth computationally and statistically efficient for this problem with regret\n$R(T) = {\\cal O} \\Big({d (\\ln m)^2 (\\ln T)\\over \\Delta_{\\min} }\\Big)$ and\ncomputational complexity ${\\cal O}(T {\\bf poly}(d))$. Our approach involves\ncarefully designing an approximate version of ESCB with the same regret\nguarantees, showing that this approximate algorithm can be implemented in time\n${\\cal O}(T {\\bf poly}(d))$ by repeatedly maximizing a linear function over\n${\\cal X}$ subject to a linear budget constraint, and showing how to solve this\nmaximization problems efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:32:04 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 17:12:58 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Cuvelier", "Thibaut", ""], ["Combes", "Richard", ""], ["Gourdin", "Eric", ""]]}, {"id": "2002.07259", "submitter": "Mostafa ElAraby", "authors": "Mostafa ElAraby, Guy Wolf, Margarida Carvalho", "title": "Identifying Critical Neurons in ANN Architectures using Mixed Integer\n  Programming", "comments": "16 pages, 3 figures, 5 tables, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a mixed integer program (MIP) for assigning importance scores to\neach neuron in deep neural network architectures which is guided by the impact\nof their simultaneous pruning on the main learning task of the network. By\ncarefully devising the objective function of the MIP, we drive the solver to\nminimize the number of critical neurons (i.e., with high importance score) that\nneed to be kept for maintaining the overall accuracy of the trained neural\nnetwork. Further, the proposed formulation generalizes the recently considered\nlottery ticket optimization by identifying multiple \"lucky\" sub-networks\nresulting in optimized architecture that not only performs well on a single\ndataset, but also generalizes across multiple ones upon retraining of network\nweights. Finally, we present a scalable implementation of our method by\ndecoupling the importance scores across layers using auxiliary networks. We\ndemonstrate the ability of our formulation to prune neural networks with\nmarginal loss in accuracy and generalizability on popular datasets and\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:32:47 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 07:03:36 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 16:09:43 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 16:39:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["ElAraby", "Mostafa", ""], ["Wolf", "Guy", ""], ["Carvalho", "Margarida", ""]]}, {"id": "2002.07264", "submitter": "Philipp Marquetand", "authors": "Julia Westermayr, Michael Gastegger, Philipp Marquetand", "title": "Combining SchNet and SHARC: The SchNarc machine learning approach for\n  excited-state dynamics", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jpclett.0c00527", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has become a part of our everyday life and is\nrevolutionizing quantum chemistry as well. In this work, we show how deep\nlearning can be used to advance the research field of photochemistry by\nlearning all important properties for photodynamics simulations. The properties\nare multiple energies, forces, nonadiabatic couplings and spin-orbit couplings.\nThe nonadiabatic couplings are learned in a phase-free manner as derivatives of\na virtually constructed property by the deep learning model, which guarantees\nrotational covariance. Additionally, an approximation for nonadiabatic\ncouplings is introduced, based on the potentials, their gradients and Hessians.\nAs deep-learning method, we employ SchNet extended for multiple electronic\nstates. In combination with the molecular dynamics program SHARC, our approach\ntermed SchNarc is tested on a model system and two realistic polyatomic\nmolecules and paves the way towards efficient photodynamics simulations of\ncomplex systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:38:35 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Westermayr", "Julia", ""], ["Gastegger", "Michael", ""], ["Marquetand", "Philipp", ""]]}, {"id": "2002.07281", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Minghe Zhang, Ruyi Ding, Yao Xie", "title": "Deep Fourier Kernel for Self-Attentive Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel attention-based model for discrete event data to capture\ncomplex non-linear temporal dependence structures. We borrow the idea from the\nattention mechanism and incorporate it into the point processes' conditional\nintensity function. We further introduce a novel score function using Fourier\nkernel embedding, whose spectrum is represented using neural networks, which\ndrastically differs from the traditional dot-product kernel and can capture a\nmore complex similarity structure. We establish our approach's theoretical\nproperties and demonstrate our approach's competitive performance compared to\nthe state-of-the-art for synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:25:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:42:45 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 00:48:54 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 04:39:07 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 05:33:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhu", "Shixiang", ""], ["Zhang", "Minghe", ""], ["Ding", "Ruyi", ""], ["Xie", "Yao", ""]]}, {"id": "2002.07282", "submitter": "Vikranth Dwaracherla", "authors": "Vikranth Dwaracherla, Benjamin Van Roy", "title": "Langevin DQN", "comments": "5 figures, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that tackle deep exploration -- an important challenge in\nreinforcement learning -- have relied on epistemic uncertainty representation\nthrough ensembles or other hypermodels, exploration bonuses, or visitation\ncount distributions. An open question is whether deep exploration can be\nachieved by an incremental reinforcement learning algorithm that tracks a\nsingle point estimate, without additional complexity required to account for\nepistemic uncertainty. We answer this question in the affirmative. In\nparticular, we develop Langevin DQN, a variation of DQN that differs only in\nperturbing parameter updates with Gaussian noise and demonstrate through a\ncomputational study that the presented algorithm achieves deep exploration. We\nalso offer some intuition to how Langevin DQN achieves deep exploration. In\naddition, we present a modification of the Langevin DQN algorithm to improve\nthe computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:29:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 06:09:20 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Dwaracherla", "Vikranth", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2002.07284", "submitter": "Hossein Taheri", "authors": "Hossein Taheri, Ramtin Pedarsani, and Christos Thrampoulidis", "title": "Sharp Asymptotics and Optimal Performance for Inference in Binary Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT eess.SP math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study convex empirical risk minimization for high-dimensional inference in\nbinary models. Our first result sharply predicts the statistical performance of\nsuch estimators in the linear asymptotic regime under isotropic Gaussian\nfeatures. Importantly, the predictions hold for a wide class of convex loss\nfunctions, which we exploit in order to prove a bound on the best achievable\nperformance among them. Notably, we show that the proposed bound is tight for\npopular binary models (such as Signed, Logistic or Probit), by constructing\nappropriate loss functions that achieve it. More interestingly, for binary\nlinear classification under the Logistic and Probit models, we prove that the\nperformance of least-squares is no worse than 0.997 and 0.98 times the optimal\none. Numerical simulations corroborate our theoretical findings and suggest\nthey are accurate even for relatively small problem dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:32:14 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 06:14:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Taheri", "Hossein", ""], ["Pedarsani", "Ramtin", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2002.07285", "submitter": "Vasilis Syrgkanis", "authors": "Greg Lewis, Vasilis Syrgkanis", "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects via\n  g-Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of treatment effects in settings when multiple\ntreatments are assigned over time and treatments can have a causal effect on\nfuture outcomes or the state of the treated unit. We propose an extension of\nthe double/debiased machine learning framework to estimate the dynamic effects\nof treatments, which can be viewed as a Neyman orthogonal (locally robust)\ncross-fitted version of $g$-estimation in the dynamic treatment regime. Our\nmethod applies to a general class of non-linear dynamic treatment models known\nas Structural Nested Mean Models and allows the use of machine learning methods\nto control for potentially high dimensional state variables, subject to a mean\nsquare error guarantee, while still allowing parametric estimation and\nconstruction of confidence intervals for the structural parameters of interest.\nThese structural parameters can be used for off-policy evaluation of any target\ndynamic policy at parametric rates, subject to semi-parametric restrictions on\nthe data generating process. Our work is based on a recursive peeling process,\ntypical in $g$-estimation, and formulates a strongly convex objective at each\nstage, which allows us to extend the $g$-estimation framework in multiple\ndirections: i) to provide finite sample guarantees, ii) to estimate non-linear\neffect heterogeneity with respect to fixed unit characteristics, within\narbitrary function spaces, enabling a dynamic analogue of the RLearner\nalgorithm for heterogeneous effects, iii) to allow for high-dimensional sparse\nparameterizations of the target structural functions, enabling automated model\nselection via a recursive lasso algorithm. We also provide guarantees for data\nstemming from a single treated unit over a long horizon and under stationarity\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:32:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 11:56:31 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 20:29:01 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 19:46:52 GMT"}, {"version": "v5", "created": "Thu, 17 Jun 2021 01:57:43 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lewis", "Greg", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "2002.07290", "submitter": "Quoc Tran-Dinh", "authors": "Quoc Tran-Dinh and Nhan H. Pham and Lam M. Nguyen", "title": "Stochastic Gauss-Newton Algorithms for Nonconvex Compositional\n  Optimization", "comments": "32 pages and 8 figures", "journal-ref": "ICML 2020", "doi": null, "report-no": "UNC-STOR-Feb 2019-02", "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two new stochastic Gauss-Newton algorithms for solving a class of\nnon-convex stochastic compositional optimization problems frequently arising in\npractice. We consider both the expectation and finite-sum settings under\nstandard assumptions, and use both classical stochastic and SARAH estimators\nfor approximating function values and Jacobians. In the expectation case, we\nestablish $\\mathcal{O}(\\varepsilon^{-2})$ iteration-complexity to achieve a\nstationary point in expectation and estimate the total number of stochastic\noracle calls for both function value and its Jacobian, where $\\varepsilon$ is a\ndesired accuracy. In the finite sum case, we also estimate\n$\\mathcal{O}(\\varepsilon^{-2})$ iteration-complexity and the total oracle calls\nwith high probability. To our best knowledge, this is the first time such\nglobal stochastic oracle complexity is established for stochastic Gauss-Newton\nmethods. Finally, we illustrate our theoretical results via two numerical\nexamples on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:56:45 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 20:41:20 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Tran-Dinh", "Quoc", ""], ["Pham", "Nhan H.", ""], ["Nguyen", "Lam M.", ""]]}, {"id": "2002.07297", "submitter": "Jennifer Brennan", "authors": "Jennifer Brennan, Ramya Korlakai Vinayak and Kevin Jamieson", "title": "Estimating the number and effect sizes of non-null hypotheses", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the distribution of effect sizes (the mean\nof the test statistic under the alternate hypothesis) in a multiple testing\nsetting. Knowing this distribution allows us to calculate the power (type II\nerror) of any experimental design. We show that it is possible to estimate this\ndistribution using an inexpensive pilot experiment, which takes significantly\nfewer samples than would be required by an experiment that identified the\ndiscoveries. Our estimator can be used to guarantee the number of discoveries\nthat will be made using a given experimental design in a future experiment. We\nprove that this simple and computationally efficient estimator enjoys a number\nof favorable theoretical properties, and demonstrate its effectiveness on data\nfrom a gene knockout experiment on influenza inhibition in Drosophila.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 23:20:21 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 18:26:17 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Brennan", "Jennifer", ""], ["Vinayak", "Ramya Korlakai", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2002.07317", "submitter": "Hisaichi Shibata", "authors": "Hisaichi Shibata, Shouhei Hanaoka, Yukihiro Nomura, Naoto Hayashi and\n  Osamu Abe", "title": "On the Matrix-Free Generation of Adversarial Perturbations for Black-Box\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, adversarial perturbations superimposed on inputs are realistic\nthreats for a deep neural network (DNN). In this paper, we propose a practical\ngeneration method of such adversarial perturbation to be applied to black-box\nattacks that demand access to an input-output relationship only. Thus, the\nattackers generate such perturbation without invoking inner functions and/or\naccessing the inner states of a DNN. Unlike the earlier studies, the algorithm\nto generate the perturbation presented in this study requires much fewer query\ntrials. Moreover, to show the effectiveness of the adversarial perturbation\nextracted, we experiment with a DNN for semantic segmentation. The result shows\nthat the network is easily deceived with the perturbation generated than using\nuniformly distributed random noise with the same magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:50:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shibata", "Hisaichi", ""], ["Hanaoka", "Shouhei", ""], ["Nomura", "Yukihiro", ""], ["Hayashi", "Naoto", ""], ["Abe", "Osamu", ""]]}, {"id": "2002.07323", "submitter": "Yang Liu", "authors": "Yang Liu, Mingxin Chen, Wenxi Zhang, Junbo Zhang, Yu Zheng", "title": "Federated Extra-Trees with Privacy Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly observed that the data are scattered everywhere and difficult\nto be centralized. The data privacy and security also become a sensitive topic.\nThe laws and regulations such as the European Union's General Data Protection\nRegulation (GDPR) are designed to protect the public's data privacy. However,\nmachine learning requires a large amount of data for better performance, and\nthe current circumstances put deploying real-life AI applications in an\nextremely difficult situation. To tackle these challenges, in this paper we\npropose a novel privacy-preserving federated machine learning model, named\nFederated Extra-Trees, which applies local differential privacy in the\nfederated trees model. A secure multi-institutional machine learning system was\ndeveloped to provide superior performance by processing the modeling jointly on\ndifferent clients without exchanging any raw data. We have validated the\naccuracy of our work by conducting extensive experiments on public datasets and\nthe efficiency and robustness were also verified by simulating the real-world\nscenarios. Overall, we presented an extensible, scalable and practical solution\nto handle the data island problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 01:15:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Mingxin", ""], ["Zhang", "Wenxi", ""], ["Zhang", "Junbo", ""], ["Zheng", "Yu", ""]]}, {"id": "2002.07345", "submitter": "Wenbo Ma", "authors": "Wenbo Ma, Miguel A. Lejeune", "title": "A Distributionally Robust Area Under Curve Maximization Model", "comments": null, "journal-ref": "Operations Research Letters, Volume 48, Issue 4, July 2020, Pages\n  460-466", "doi": "10.1016/j.orl.2020.05.012", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Area under ROC curve (AUC) is a widely used performance measure for\nclassification models. We propose two new distributionally robust AUC\nmaximization models (DR-AUC) that rely on the Kantorovich metric and\napproximate the AUC with the hinge loss function. We consider the two cases\nwith respectively fixed and variable support for the worst-case distribution.\nWe use duality theory to reformulate the DR-AUC models and derive tractable\nconvex optimization problems. The numerical experiments show that the proposed\nDR-AUC models -- benchmarked with the standard deterministic AUC and the\nsupport vector machine models - perform better in general and in particular\nimprove the worst-case out-of-sample performance over the majority of the\nconsidered datasets, thereby showing their robustness. The results are\nparticularly encouraging since our numerical experiments are conducted with\ntraining sets of small size which have been known to be conducive to low\nout-of-sample performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:50:45 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 17:19:24 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ma", "Wenbo", ""], ["Lejeune", "Miguel A.", ""]]}, {"id": "2002.07348", "submitter": "Ningshan Zhang", "authors": "Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri,\n  Ningshan Zhang", "title": "Adaptive Region-Based Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new active learning algorithm that adaptively partitions the\ninput space into a finite number of regions, and subsequently seeks a distinct\npredictor for each region, both phases actively requesting labels. We prove\ntheoretical guarantees for both the generalization error and the label\ncomplexity of our algorithm, and analyze the number of regions defined by the\nalgorithm under some mild assumptions. We also report the results of an\nextensive suite of experiments on several real-world datasets demonstrating\nsubstantial empirical benefits over existing single-region and non-adaptive\nregion-based active learning baselines.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 03:16:36 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cortes", "Corinna", ""], ["DeSalvo", "Giulia", ""], ["Gentile", "Claudio", ""], ["Mohri", "Mehryar", ""], ["Zhang", "Ningshan", ""]]}, {"id": "2002.07349", "submitter": "Haoyi Fan", "authors": "Haoyi Fan, Fengbin Zhang, Ruidong Wang, Liang Xi, Zuoyong Li", "title": "Correlation-aware Deep Generative Model for Unsupervised Anomaly\n  Detection", "comments": "(Updating code and data) Accepted by PAKDD2020. Copyright (c) 2020\n  Springer. The source code and dataset are available at\n  https://haoyfan.github.io/. Only personal use of these materials is permitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised anomaly detection aims to identify anomalous samples from highly\ncomplex and unstructured data, which is pervasive in both fundamental research\nand industrial applications. However, most existing methods neglect the complex\ncorrelation among data samples, which is important for capturing normal\npatterns from which the abnormal ones deviate. In this paper, we propose a\nmethod of Correlation aware unsupervised Anomaly detection via Deep Gaussian\nMixture Model (CADGMM), which captures the complex correlation among data\npoints for high-quality low-dimensional representation learning. Specifically,\nthe relations among data samples are correlated firstly in forms of a graph\nstructure, in which, the node denotes the sample and the edge denotes the\ncorrelation between two samples from the feature space. Then, a dual-encoder\nthat consists of a graph encoder and a feature encoder, is employed to encode\nboth the feature and correlation information of samples into the\nlow-dimensional latent space jointly, followed by a decoder for data\nreconstruction. Finally, a separate estimation network as a Gaussian Mixture\nModel is utilized to estimate the density of the learned latent vector, and the\nanomalies can be detected by measuring the energy of the samples. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 03:32:06 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 11:30:58 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 04:04:58 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Fan", "Haoyi", ""], ["Zhang", "Fengbin", ""], ["Wang", "Ruidong", ""], ["Xi", "Liang", ""], ["Li", "Zuoyong", ""]]}, {"id": "2002.07367", "submitter": "Khai Nguyen", "authors": "Khai Nguyen and Nhat Ho and Tung Pham and Hung Bui", "title": "Distributional Sliced-Wasserstein and Applications to Generative\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein\ndistance (Max-SW), have been used widely in the recent years due to their fast\ncomputation and scalability even when the probability measures lie in a very\nhigh dimensional space. However, SW requires many unnecessary projection\nsamples to approximate its value while Max-SW only uses the most important\nprojection, which ignores the information of other useful directions. In order\nto account for these weaknesses, we propose a novel distance, named\nDistributional Sliced-Wasserstein distance (DSW), that finds an optimal\ndistribution over projections that can balance between exploring distinctive\nprojecting directions and the informativeness of projections themselves. We\nshow that the DSW is a generalization of Max-SW, and it can be computed\nefficiently by searching for the optimal push-forward measure over a set of\nprobability measures over the unit sphere satisfying certain regularizing\nconstraints that favor distinct directions. Finally, we conduct extensive\nexperiments with large-scale datasets to demonstrate the favorable performances\nof the proposed distances over the previous sliced-based distances in\ngenerative modeling applications.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 04:35:16 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 07:21:55 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Khai", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""]]}, {"id": "2002.07375", "submitter": "Sankalp Garg", "authors": "Sankalp Garg, Aniket Bajpai, Mausam", "title": "Symbolic Network: Generalized Neural Policies for Relational MDPs", "comments": "In Proceeding of ICML 2020. Code can be found at\n  https://github.com/dair-iitd/symnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Relational Markov Decision Process (RMDP) is a first-order representation\nto express all instances of a single probabilistic planning domain with\npossibly unbounded number of objects. Early work in RMDPs outputs generalized\n(instance-independent) first-order policies or value functions as a means to\nsolve all instances of a domain at once. Unfortunately, this line of work met\nwith limited success due to inherent limitations of the representation space\nused in such policies or value functions. Can neural models provide the missing\nlink by easily representing more complex generalized policies, thus making them\neffective on all instances of a given domain?\n  We present SymNet, the first neural approach for solving RMDPs that are\nexpressed in the probabilistic planning language of RDDL. SymNet trains a set\nof shared parameters for an RDDL domain using training instances from that\ndomain. For each instance, SymNet first converts it to an instance graph and\nthen uses relational neural models to compute node embeddings. It then scores\neach ground action as a function over the first-order action symbols and node\nembeddings related to the action. Given a new test instance from the same\ndomain, SymNet architecture with pre-trained parameters scores each ground\naction and chooses the best action. This can be accomplished in a single\nforward pass without any retraining on the test instance, thus implicitly\nrepresenting a neural generalized policy for the whole domain. Our experiments\non nine RDDL domains from IPPC demonstrate that SymNet policies are\nsignificantly better than random and sometimes even more effective than\ntraining a state-of-the-art deep reactive policy from scratch.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:03:17 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 17:05:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Garg", "Sankalp", ""], ["Bajpai", "Aniket", ""], ["Mausam", "", ""]]}, {"id": "2002.07376", "submitter": "Chaoqi Wang", "authors": "Chaoqi Wang, Guodong Zhang, Roger Grosse", "title": "Picking Winning Tickets Before Training by Preserving Gradient Flow", "comments": "Fix several typos", "journal-ref": "In Proceedings of the 8th International Conference on Learning\n  Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterization has been shown to benefit both the optimization and\ngeneralization of neural networks, but large networks are resource hungry at\nboth training and test time. Network pruning can reduce test-time resource\nrequirements, but is typically applied to trained networks and therefore cannot\navoid the expensive training process. We aim to prune networks at\ninitialization, thereby saving resources at training time as well.\nSpecifically, we argue that efficient training requires preserving the gradient\nflow through the network. This leads to a simple but effective pruning\ncriterion we term Gradient Signal Preservation (GraSP). We empirically\ninvestigate the effectiveness of the proposed method with extensive experiments\non CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNet, using VGGNet and ResNet\narchitectures. Our method can prune 80% of the weights of a VGG-16 network on\nImageNet at initialization, with only a 1.6% drop in top-1 accuracy. Moreover,\nour method achieves significantly better performance than the baseline at\nextreme sparsity levels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:14:47 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 00:02:33 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wang", "Chaoqi", ""], ["Zhang", "Guodong", ""], ["Grosse", "Roger", ""]]}, {"id": "2002.07384", "submitter": "Abhimanu Kumar", "authors": "Abhimanu Kumar, Aniket Anand Deshmukh, Urun Dogan, Denis Charles, Eren\n  Manavoglu", "title": "Data Transformation Insights in Self-supervision with Clustering Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervision is key to extending use of deep learning for label scarce\ndomains. For most of self-supervised approaches data transformations play an\nimportant role. However, up until now the impact of transformations have not\nbeen studied. Furthermore, different transformations may have different impact\non the system. We provide novel insights into the use of data transformation in\nself-supervised tasks, specially pertaining to clustering. We show\ntheoretically and empirically that certain set of transformations are helpful\nin convergence of self-supervised clustering. We also show the cases when the\ntransformations are not helpful or in some cases even harmful. We show faster\nconvergence rate with valid transformations for convex as well as certain\nfamily of non-convex objectives along with the proof of convergence to the\noriginal set of optima. We have synthetic as well as real world data\nexperiments. Empirically our results conform with the theoretical insights\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:49:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kumar", "Abhimanu", ""], ["Deshmukh", "Aniket Anand", ""], ["Dogan", "Urun", ""], ["Charles", "Denis", ""], ["Manavoglu", "Eren", ""]]}, {"id": "2002.07386", "submitter": "Ashkan Yousefpour", "authors": "Ashkan Yousefpour, Brian Q. Nguyen, Siddartha Devic, Guanhua Wang,\n  Aboudy Kreidieh, Hans Lobel, Alexandre M. Bayen, Jason P. Jue", "title": "ResiliNet: Failure-Resilient Inference in Distributed Neural Networks", "comments": "Accepted in FL-ICML 2020 (International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2020). Added FAQ to the end of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning aims to train distributed deep models without sharing the\nraw data with the centralized server. Similarly, in distributed inference of\nneural networks, by partitioning the network and distributing it across several\nphysical nodes, activations and gradients are exchanged between physical nodes,\nrather than raw data. Nevertheless, when a neural network is partitioned and\ndistributed among physical nodes, failure of physical nodes causes the failure\nof the neural units that are placed on those nodes, which results in a\nsignificant performance drop. Current approaches focus on resiliency of\ntraining in distributed neural networks. However, resiliency of inference in\ndistributed neural networks is less explored. We introduce ResiliNet, a scheme\nfor making inference in distributed neural networks resilient to physical node\nfailures. ResiliNet combines two concepts to provide resiliency: skip\nhyperconnection, a concept for skipping nodes in distributed neural networks\nsimilar to skip connection in resnets, and a novel technique called failout,\nwhich is introduced in this paper. Failout simulates physical node failure\nconditions during training using dropout, and is specifically designed to\nimprove the resiliency of distributed neural networks. The results of the\nexperiments and ablation studies using three datasets confirm the ability of\nResiliNet to provide inference resiliency for distributed neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:58:24 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:13:47 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 04:46:05 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 08:08:17 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yousefpour", "Ashkan", ""], ["Nguyen", "Brian Q.", ""], ["Devic", "Siddartha", ""], ["Wang", "Guanhua", ""], ["Kreidieh", "Aboudy", ""], ["Lobel", "Hans", ""], ["Bayen", "Alexandre M.", ""], ["Jue", "Jason P.", ""]]}, {"id": "2002.07399", "submitter": "Yikai Yan", "authors": "Yikai Yan, Chaoyue Niu, Yucheng Ding, Zhenzhe Zheng, Fan Wu, Guihai\n  Chen, Shaojie Tang, Zhihua Wu", "title": "Distributed Non-Convex Optimization with Sublinear Speedup under\n  Intermittent Client Availability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a new distributed machine learning framework, where a\nbunch of heterogeneous clients collaboratively train a model without sharing\ntraining data. In this work, we consider a practical and ubiquitous issue when\ndeploying federated learning in mobile environments: intermittent client\navailability, where the set of eligible clients may change during the training\nprocess. Such intermittent client availability would seriously deteriorate the\nperformance of the classical Federated Averaging algorithm (FedAvg for short).\nThus, we propose a simple distributed non-convex optimization algorithm, called\nFederated Latest Averaging (FedLaAvg for short), which leverages the latest\ngradients of all clients, even when the clients are not available, to jointly\nupdate the global model in each iteration. Our theoretical analysis shows that\nFedLaAvg attains the convergence rate of $O(E^{1/2}/(N^{1/4} T^{1/2}))$,\nachieving a sublinear speedup with respect to the total number of clients. We\nimplement FedLaAvg along with several baselines and evaluate them over the\nbenchmarking MNIST and Sentiment140 datasets. The evaluation results\ndemonstrate that FedLaAvg achieves more stable training than FedAvg in both\nconvex and non-convex settings and indeed reaches a sublinear speedup.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:32:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:13:20 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 02:47:23 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Yan", "Yikai", ""], ["Niu", "Chaoyue", ""], ["Ding", "Yucheng", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Tang", "Shaojie", ""], ["Wu", "Zhihua", ""]]}, {"id": "2002.07400", "submitter": "Eran Malach", "authors": "Amit Daniely, Eran Malach", "title": "Learning Parities with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years we see a rapidly growing line of research which shows\nlearnability of various models via common neural network algorithms. Yet,\nbesides a very few outliers, these results show learnability of models that can\nbe learned using linear methods. Namely, such results show that learning\nneural-networks with gradient-descent is competitive with learning a linear\nclassifier on top of a data-independent representation of the examples. This\nleaves much to be desired, as neural networks are far more successful than\nlinear methods. Furthermore, on the more conceptual level, linear models don't\nseem to capture the \"deepness\" of deep networks. In this paper we make a step\ntowards showing leanability of models that are inherently non-linear. We show\nthat under certain distributions, sparse parities are learnable via gradient\ndecent on depth-two network. On the other hand, under the same distributions,\nthese parities cannot be learned efficiently by linear methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:44:17 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 11:38:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Daniely", "Amit", ""], ["Malach", "Eran", ""]]}, {"id": "2002.07405", "submitter": "Yao Qin", "authors": "Yao Qin, Nicholas Frosst, Colin Raffel, Garrison Cottrell and Geoffrey\n  Hinton", "title": "Deflecting Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an ongoing cycle where stronger defenses against adversarial\nattacks are subsequently broken by a more advanced defense-aware attack. We\npresent a new approach towards ending this cycle where we \"deflect''\nadversarial attacks by causing the attacker to produce an input that\nsemantically resembles the attack's target class. To this end, we first propose\na stronger defense based on Capsule Networks that combines three detection\nmechanisms to achieve state-of-the-art detection performance on both standard\nand defense-aware attacks. We then show that undetected attacks against our\ndefense often perceptually resemble the adversarial target class by performing\na human study where participants are asked to label images produced by the\nattack. These attack images can no longer be called \"adversarial'' because our\nnetwork classifies them the same way as humans do.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:59:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Qin", "Yao", ""], ["Frosst", "Nicholas", ""], ["Raffel", "Colin", ""], ["Cottrell", "Garrison", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2002.07434", "submitter": "Sheng Shi", "authors": "Sheng Shi, Xinfeng Zhang, Wei Fan", "title": "A Modified Perturbed Sampling Method for Local Interpretable\n  Model-agnostic Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is a gateway between Artificial Intelligence and society as\nthe current popular deep learning models are generally weak in explaining the\nreasoning process and prediction results. Local Interpretable Model-agnostic\nExplanation (LIME) is a recent technique that explains the predictions of any\nclassifier faithfully by learning an interpretable model locally around the\nprediction. However, the sampling operation in the standard implementation of\nLIME is defective. Perturbed samples are generated from a uniform distribution,\nignoring the complicated correlation between features. This paper proposes a\nnovel Modified Perturbed Sampling operation for LIME (MPS-LIME), which is\nformalized as the clique set construction problem. In image classification,\nMPS-LIME converts the superpixel image into an undirected graph. Various\nexperiments show that the MPS-LIME explanation of the black-box model achieves\nmuch better performance in terms of understandability, fidelity, and\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:03:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shi", "Sheng", ""], ["Zhang", "Xinfeng", ""], ["Fan", "Wei", ""]]}, {"id": "2002.07454", "submitter": "Yucheng Ding", "authors": "Yucheng Ding, Chaoyue Niu, Yikai Yan, Zhenzhe Zheng, Fan Wu, Guihai\n  Chen, Shaojie Tang, Rongfei Jia", "title": "Distributed Optimization over Block-Cyclic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider practical data characteristics underlying federated learning,\nwhere unbalanced and non-i.i.d. data from clients have a block-cyclic\nstructure: each cycle contains several blocks, and each client's training data\nfollow block-specific and non-i.i.d. distributions. Such a data structure would\nintroduce client and block biases during the collaborative training: the single\nglobal model would be biased towards the client or block specific data. To\novercome the biases, we propose two new distributed optimization algorithms\ncalled multi-model parallel SGD (MM-PSGD) and multi-chain parallel SGD\n(MC-PSGD) with a convergence rate of $O(1/\\sqrt{NT})$, achieving a linear\nspeedup with respect to the total number of clients. In particular, MM-PSGD\nadopts the block-mixed training strategy, while MC-PSGD further adds the\nblock-separate training strategy. Both algorithms create a specific predictor\nfor each block by averaging and comparing the historical global models\ngenerated in this block from different cycles. We extensively evaluate our\nalgorithms over the CIFAR-10 dataset. Evaluation results demonstrate that our\nalgorithms significantly outperform the conventional federated averaging\nalgorithm in terms of test accuracy, and also preserve robustness for the\nvariance of critical parameters.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:47:15 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ding", "Yucheng", ""], ["Niu", "Chaoyue", ""], ["Yan", "Yikai", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Tang", "Shaojie", ""], ["Jia", "Rongfei", ""]]}, {"id": "2002.07467", "submitter": "Per Sid\\'en", "authors": "Per Sid\\'en and Fredrik Lindsten", "title": "Deep Gaussian Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Markov random fields (GMRFs) are probabilistic graphical models\nwidely used in spatial statistics and related fields to model dependencies over\nspatial structures. We establish a formal connection between GMRFs and\nconvolutional neural networks (CNNs). Common GMRFs are special cases of a\ngenerative model where the inverse mapping from data to latent variables is\ngiven by a 1-layer linear CNN. This connection allows us to generalize GMRFs to\nmulti-layer CNN architectures, effectively increasing the order of the\ncorresponding GMRF in a way which has favorable computational scaling. We\ndescribe how well-established tools, such as autodiff and variational\ninference, can be used for simple and efficient inference and learning of the\ndeep GMRF. We demonstrate the flexibility of the proposed model and show that\nit outperforms the state-of-the-art on a dataset of satellite temperatures, in\nterms of prediction and predictive uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:06:39 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 15:19:04 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sid\u00e9n", "Per", ""], ["Lindsten", "Fredrik", ""]]}, {"id": "2002.07469", "submitter": "Paul Baggenstoss", "authors": "Paul M Baggenstoss", "title": "A Neural Network Based on First Principles", "comments": null, "journal-ref": "ICASSP 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a Neural network is derived from first principles, assuming\nonly that each layer begins with a linear dimension-reducing transformation.\nThe approach appeals to the principle of Maximum Entropy (MaxEnt) to find the\nposterior distribution of the input data of each layer, conditioned on the\nlayer output variables. This posterior has a well-defined mean, the conditional\nmean estimator, that is calculated using a type of neural network with\ntheoretically-derived activation functions similar to sigmoid, softplus, and\nrelu. This implicitly provides a theoretical justification for their use. A\ntheorem that finds the conditional distribution and conditional mean estimator\nunder the MaxEnt prior is proposed, unifying results for special cases.\nCombining layers results in an auto-encoder with conventional feed-forward\nanalysis network and a type of linear Bayesian belief network in the\nreconstruction path.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:16:59 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Baggenstoss", "Paul M", ""]]}, {"id": "2002.07477", "submitter": "Vincent Margot", "authors": "Carmine de Franco, Christophe Geissler, Vincent Margot, Bruno Monnier", "title": "ESG investments: Filtering versus machine learning approaches", "comments": null, "journal-ref": "The Seventh Public Investors Conference, Oct 2018, Rome, Italy", "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed a machine learning algorithm that identifies patterns between ESG\nprofiles and financial performances for companies in a large investment\nuniverse. The algorithm consists of regularly updated sets of rules that map\nregions into the high-dimensional space of ESG features to excess return\npredictions. The final aggregated predictions are transformed into scores which\nallow us to design simple strategies that screen the investment universe for\nstocks with positive scores. By linking the ESG features with financial\nperformances in a non-linear way, our strategy based upon our machine learning\nalgorithm turns out to be an efficient stock picking tool, which outperforms\nclassic strategies that screen stocks according to their ESG ratings, as the\npopular best-in-class approach. Our paper brings new ideas in the growing field\nof financial literature that investigates the links between ESG behavior and\nthe economy. We show indeed that there is clearly some form of alpha in the ESG\nprofile of a company, but that this alpha can be accessed only with powerful,\nnon-linear techniques such as machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:29:36 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 07:20:07 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["de Franco", "Carmine", ""], ["Geissler", "Christophe", ""], ["Margot", "Vincent", ""], ["Monnier", "Bruno", ""]]}, {"id": "2002.07493", "submitter": "Michael Steininger", "authors": "Michael Steininger, Konstantin Kobs, Albin Zehe, Florian\n  Lautenschlager, Martin Becker, Andreas Hotho", "title": "MapLUR: Exploring a new Paradigm for Estimating Air Pollution using Deep\n  Learning on Map Images", "comments": "Accepted for publication in ACM TSAS - Special Issue on Deep Learning", "journal-ref": null, "doi": "10.1145/3380973", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land-use regression (LUR) models are important for the assessment of air\npollution concentrations in areas without measurement stations. While many such\nmodels exist, they often use manually constructed features based on restricted,\nlocally available data. Thus, they are typically hard to reproduce and\nchallenging to adapt to areas beyond those they have been developed for. In\nthis paper, we advocate a paradigm shift for LUR models: We propose the\nData-driven, Open, Global (DOG) paradigm that entails models based on purely\ndata-driven approaches using only openly and globally available data. Progress\nwithin this paradigm will alleviate the need for experts to adapt models to the\nlocal characteristics of the available data sources and thus facilitate the\ngeneralizability of air pollution models to new areas on a global scale. In\norder to illustrate the feasibility of the DOG paradigm for LUR, we introduce a\ndeep learning model called MapLUR. It is based on a convolutional neural\nnetwork architecture and is trained exclusively on globally and openly\navailable map data without requiring manual feature engineering. We compare our\nmodel to state-of-the-art baselines like linear regression, random forests and\nmulti-layer perceptrons using a large data set of modeled $\\text{NO}_2$\nconcentrations in Central London. Our results show that MapLUR significantly\noutperforms these approaches even though they are provided with manually\ntailored features. Furthermore, we illustrate that the automatic feature\nextraction inherent to models based on the DOG paradigm can learn features that\nare readily interpretable and closely resemble those commonly used in\ntraditional LUR approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:21:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Steininger", "Michael", ""], ["Kobs", "Konstantin", ""], ["Zehe", "Albin", ""], ["Lautenschlager", "Florian", ""], ["Becker", "Martin", ""], ["Hotho", "Andreas", ""]]}, {"id": "2002.07501", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Shuyu Cheng, Yueru Li, Jun Zhu, Bo Zhang", "title": "A Wasserstein Minimum Velocity Approach to Learning Unnormalized Models", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score matching provides an effective approach to learning flexible\nunnormalized models, but its scalability is limited by the need to evaluate a\nsecond-order derivative. In this paper, we present a scalable approximation to\na general family of learning objectives including score matching, by observing\na new connection between these objectives and Wasserstein gradient flows. We\npresent applications with promise in learning neural density estimators on\nmanifolds, and training implicit variational and Wasserstein auto-encoders with\na manifold-valued prior.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:40:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wang", "Ziyu", ""], ["Cheng", "Shuyu", ""], ["Li", "Yueru", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "2002.07518", "submitter": "Han Yang", "authors": "Han Yang, Xiao Yan, Xinyan Dai, Yongqiang Chen, James Cheng", "title": "Self-Enhanced GNN: Improving Graph Neural Networks Using Model Outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have received much attention recently because of\ntheir excellent performance on graph-based tasks. However, existing research on\nGNNs focuses on designing more effective models without considering much about\nthe quality of the input data. In this paper, we propose self-enhanced GNN\n(SEG), which improves the quality of the input data using the outputs of\nexisting GNN models for better performance on semi-supervised node\nclassification. As graph data consist of both topology and node labels, we\nimprove input data quality from both perspectives. For topology, we observe\nthat higher classification accuracy can be achieved when the ratio of\ninter-class edges (connecting nodes from different classes) is low and propose\ntopology update to remove inter-class edges and add intra-class edges. For node\nlabels, we propose training node augmentation, which enlarges the training set\nusing the labels predicted by existing GNN models. SEG is a general framework\nthat can be easily combined with existing GNN models. Experimental results\nvalidate that SEG consistently improves the performance of well-known GNN\nmodels such as GCN, GAT and SGC across different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:27:16 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 06:58:20 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 15:54:55 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yang", "Han", ""], ["Yan", "Xiao", ""], ["Dai", "Xinyan", ""], ["Chen", "Yongqiang", ""], ["Cheng", "James", ""]]}, {"id": "2002.07520", "submitter": "Milad Alizadeh", "authors": "Milad Alizadeh, Arash Behboodi, Mart van Baalen, Christos Louizos,\n  Tijmen Blankevoort, Max Welling", "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the effect of quantizing weights and activations of neural\nnetworks on their loss and derive a simple regularization scheme that improves\nrobustness against post-training quantization. By training quantization-ready\nnetworks, our approach enables storing a single set of weights that can be\nquantized on-demand to different bit-widths as energy and memory requirements\nof the application change. Unlike quantization-aware training using the\nstraight-through estimator that only targets a specific bit-width and requires\naccess to training data and pipeline, our regularization-based method paves the\nway for \"on the fly'' post-training quantization to various bit-widths. We show\nthat by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the\nfirst-order term in the loss expansion can be regularized using the\n$\\ell_1$-norm of gradients. We experimentally validate the effectiveness of our\nregularization scheme on different architectures on CIFAR-10 and ImageNet\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:31:34 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Alizadeh", "Milad", ""], ["Behboodi", "Arash", ""], ["van Baalen", "Mart", ""], ["Louizos", "Christos", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "2002.07528", "submitter": "Piotr Kicki", "authors": "Piotr Kicki, Mete Ozay and Piotr Skrzypczy\\'nski", "title": "A Computationally Efficient Neural Network Invariant to the Action of\n  Symmetry Subgroups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to design a computationally efficient $G$-invariant\nneural network that approximates functions invariant to the action of a given\npermutation subgroup $G \\leq S_n$ of the symmetric group on input data. The key\nelement of the proposed network architecture is a new $G$-invariant\ntransformation module, which produces a $G$-invariant latent representation of\nthe input data. This latent representation is then processed with a multi-layer\nperceptron in the network. We prove the universality of the proposed\narchitecture, discuss its properties and highlight its computational and memory\nefficiency. Theoretical considerations are supported by numerical experiments\ninvolving different network configurations, which demonstrate the effectiveness\nand strong generalization properties of the proposed method in comparison to\nother $G$-invariant neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:50:56 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kicki", "Piotr", ""], ["Ozay", "Mete", ""], ["Skrzypczy\u0144ski", "Piotr", ""]]}, {"id": "2002.07530", "submitter": "Louis Faury", "authors": "Louis Faury, Marc Abeille, Cl\\'ement Calauz\\`enes, Olivier Fercoq", "title": "Improved Optimistic Algorithms for Logistic Bandits", "comments": "Accepted at ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized linear bandit framework has attracted a lot of attention in\nrecent years by extending the well-understood linear setting and allowing to\nmodel richer reward structures. It notably covers the logistic model, widely\nused when rewards are binary. For logistic bandits, the frequentist regret\nguarantees of existing algorithms are $\\tilde{\\mathcal{O}}(\\kappa \\sqrt{T})$,\nwhere $\\kappa$ is a problem-dependent constant. Unfortunately, $\\kappa$ can be\narbitrarily large as it scales exponentially with the size of the decision set.\nThis may lead to significantly loose regret bounds and poor empirical\nperformance. In this work, we study the logistic bandit with a focus on the\nprohibitive dependencies introduced by $\\kappa$. We propose a new optimistic\nalgorithm based on a finer examination of the non-linearities of the reward\nfunction. We show that it enjoys a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret with\nno dependency in $\\kappa$, but for a second order term. Our analysis is based\non a new tail-inequality for self-normalized martingales, of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:52:32 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 07:36:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Faury", "Louis", ""], ["Abeille", "Marc", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""], ["Fercoq", "Olivier", ""]]}, {"id": "2002.07596", "submitter": "Thomas Budzinski", "authors": "S\\'ebastien Bubeck and Thomas Budzinski", "title": "Coordination without communication: optimal regret in two players\n  multi-armed bandits", "comments": "28 pages, 5 figures. V2: minor revision", "journal-ref": "COLT 2020", "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two agents playing simultaneously the same stochastic three-armed\nbandit problem. The two agents are cooperating but they cannot communicate. We\npropose a strategy with no collisions at all between the players (with very\nhigh probability), and with near-optimal regret $O(\\sqrt{T \\log(T)})$. We also\nargue that the extra logarithmic term $\\sqrt{\\log(T)}$ should be necessary by\nproving a lower bound for a full information variant of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:35:42 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 19:11:02 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Budzinski", "Thomas", ""]]}, {"id": "2002.07601", "submitter": "Yi Wei", "authors": "Yi Wei, Ming-Min Zhao, Min-Jian Zhao, and Ming Lei", "title": "ADMM-based Decoder for Binary Linear Codes Aided by Deep Learning", "comments": "5 pages, 4 figures, accepted for publication in IEEE communications\n  letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent advances in deep learning (DL), this work presents a\ndeep neural network aided decoding algorithm for binary linear codes. Based on\nthe concept of deep unfolding, we design a decoding network by unfolding the\nalternating direction method of multipliers (ADMM)-penalized decoder. In\naddition, we propose two improved versions of the proposed network. The first\none transforms the penalty parameter into a set of iteration-dependent ones,\nand the second one adopts a specially designed penalty function, which is based\non a piecewise linear function with adjustable slopes. Numerical results show\nthat the resulting DL-aided decoders outperform the original ADMM-penalized\ndecoder for various low density parity check (LDPC) codes with similar\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 03:32:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wei", "Yi", ""], ["Zhao", "Ming-Min", ""], ["Zhao", "Min-Jian", ""], ["Lei", "Ming", ""]]}, {"id": "2002.07605", "submitter": "Jinyang Jiao", "authors": "Jinyang Jiao, Ming Zhao, Jing Lin, Kaixuan Liang", "title": "A comprehensive review on convolutional neural network in machine fault\n  diagnosis", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.07.088", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of manufacturing industry, machine fault diagnosis\nhas become increasingly significant to ensure safe equipment operation and\nproduction. Consequently, multifarious approaches have been explored and\ndeveloped in the past years, of which intelligent algorithms develop\nparticularly rapidly. Convolutional neural network, as a typical representative\nof intelligent diagnostic models, has been extensively studied and applied in\nrecent five years, and a large amount of literature has been published in\nacademic journals and conference proceedings. However, there has not been a\nsystematic review to cover these studies and make a prospect for the further\nresearch. To fill in this gap, this work attempts to review and summarize the\ndevelopment of the Convolutional Network based Fault Diagnosis (CNFD)\napproaches comprehensively. Generally, a typical CNFD framework is composed of\nthe following steps, namely, data collection, model construction, and feature\nlearning and decision making, thus this paper is organized by following this\nstream. Firstly, data collection process is described, in which several popular\ndatasets are introduced. Then, the fundamental theory from the basic\nconvolutional neural network to its variants is elaborated. After that, the\napplications of CNFD are reviewed in terms of three mainstream directions, i.e.\nclassification, prediction and transfer diagnosis. Finally, conclusions and\nprospects are presented to point out the characteristics of current\ndevelopment, facing challenges and future trends. Last but not least, it is\nexpected that this work would provide convenience and inspire further\nexploration for researchers in this field.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:35:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jiao", "Jinyang", ""], ["Zhao", "Ming", ""], ["Lin", "Jing", ""], ["Liang", "Kaixuan", ""]]}, {"id": "2002.07613", "submitter": "Yiqiu Shen", "authors": "Yiqiu Shen, Nan Wu, Jason Phang, Jungkyu Park, Kangning Liu,\n  Sudarshini Tyagi, Laura Heacock, S. Gene Kim, Linda Moy, Kyunghyun Cho,\n  Krzysztof J. Geras", "title": "An interpretable classifier for high-resolution breast cancer screening\n  images utilizing weakly supervised localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images differ from natural images in significantly higher resolutions\nand smaller regions of interest. Because of these differences, neural network\narchitectures that work well for natural images might not be applicable to\nmedical image analysis. In this work, we extend the globally-aware multiple\ninstance classifier, a framework we proposed to address these unique properties\nof medical images. This model first uses a low-capacity, yet memory-efficient,\nnetwork on the whole image to identify the most informative regions. It then\napplies another higher-capacity network to collect details from chosen regions.\nFinally, it employs a fusion module that aggregates global and local\ninformation to make a final prediction. While existing methods often require\nlesion segmentation during training, our model is trained with only image-level\nlabels and can generate pixel-level saliency maps indicating possible malignant\nfindings. We apply the model to screening mammography interpretation:\npredicting the presence or absence of benign and malignant lesions. On the NYU\nBreast Cancer Screening Dataset, consisting of more than one million images,\nour model achieves an AUC of 0.93 in classifying breasts with malignant\nfindings, outperforming ResNet-34 and Faster R-CNN. Compared to ResNet-34, our\nmodel is 4.1x faster for inference while using 78.4% less GPU memory.\nFurthermore, we demonstrate, in a reader study, that our model surpasses\nradiologist-level AUC by a margin of 0.11. The proposed model is available\nonline: https://github.com/nyukat/GMIC.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:28:42 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Phang", "Jason", ""], ["Park", "Jungkyu", ""], ["Liu", "Kangning", ""], ["Tyagi", "Sudarshini", ""], ["Heacock", "Laura", ""], ["Kim", "S. Gene", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2002.07618", "submitter": "Adriano Fazzone", "authors": "Aris Anagnostopoulos and Carlos Castillo and Adriano Fazzone and\n  Stefano Leonardi and Evimaria Terzi", "title": "Algorithms for Hiring and Outsourcing in the Online Labor Market", "comments": "Published at 24th ACM SIGKDD International Conference on Knowledge\n  Discovery & Data Mining 2018", "journal-ref": null, "doi": "10.1145/3219819.3220056", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although freelancing work has grown substantially in recent years, in part\nfacilitated by a number of online labor marketplaces, (e.g., Guru, Freelancer,\nAmazon Mechanical Turk), traditional forms of \"in-sourcing\" work continue being\nthe dominant form of employment. This means that, at least for the time being,\nfreelancing and salaried employment will continue to co-exist. In this paper,\nwe provide algorithms for outsourcing and hiring workers in a general setting,\nwhere workers form a team and contribute different skills to perform a task. We\ncall this model team formation with outsourcing. In our model, tasks arrive in\nan online fashion: neither the number nor the composition of the tasks is known\na-priori. At any point in time, there is a team of hired workers who receive a\nfixed salary independently of the work they perform. This team is dynamic: new\nmembers can be hired and existing members can be fired, at some cost.\nAdditionally, some parts of the arriving tasks can be outsourced and thus\ncompleted by non-team members, at a premium. Our contribution is an efficient\nonline cost-minimizing algorithm for hiring and firing team members and\noutsourcing tasks. We present theoretical bounds obtained using a primal-dual\nscheme proving that our algorithms have a logarithmic competitive approximation\nratio. We complement these results with experiments using semi-synthetic\ndatasets based on actual task requirements and worker skills from three large\nonline labor marketplaces.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 18:56:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Anagnostopoulos", "Aris", ""], ["Castillo", "Carlos", ""], ["Fazzone", "Adriano", ""], ["Leonardi", "Stefano", ""], ["Terzi", "Evimaria", ""]]}, {"id": "2002.07624", "submitter": "Rong Ma", "authors": "T. Tony Cai, Hongzhe Li and Rong Ma", "title": "Optimal Structured Principal Subspace Estimation: Metric Entropy and\n  Minimax Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by a wide range of applications, many principal subspace estimation\nproblems have been studied individually under different structural constraints.\nThis paper presents a unified framework for the statistical analysis of a\ngeneral structured principal subspace estimation problem which includes as\nspecial cases non-negative PCA/SVD, sparse PCA/SVD, subspace constrained\nPCA/SVD, and spectral clustering. General minimax lower and upper bounds are\nestablished to characterize the interplay between the information-geometric\ncomplexity of the structural set for the principal subspaces, the\nsignal-to-noise ratio (SNR), and the dimensionality. The results yield\ninteresting phase transition phenomena concerning the rates of convergence as a\nfunction of the SNRs and the fundamental limit for consistent estimation.\nApplying the general results to the specific settings yields the minimax rates\nof convergence for those problems, including the previous unknown optimal rates\nfor non-negative PCA/SVD, sparse SVD and subspace constrained PCA/SVD.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:02:11 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 16:16:54 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 13:09:52 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""], ["Ma", "Rong", ""]]}, {"id": "2002.07629", "submitter": "Patrick Von Platen", "authors": "Patrick von Platen, Fei Tao, Gokhan Tur", "title": "Multi-Task Siamese Neural Network for Improving Replay Attack Detection", "comments": "Submit to INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification systems are vulnerable to audio replay attacks\nwhich bypass security by replaying recordings of authorized speakers. Replay\nattack detection (RA) detection systems built upon Residual Neural Networks\n(ResNet)s have yielded astonishing results on the public benchmark ASVspoof\n2019 Physical Access challenge. With most teams using fine-tuned feature\nextraction pipelines and model architectures, the generalizability of such\nsystems remains questionable though. In this work, we analyse the effect of\ndiscriminative feature learning in a multi-task learning (MTL) setting can have\non the generalizability and discriminability of RA detection systems. We use a\npopular ResNet architecture optimized by the cross-entropy criterion as our\nbaseline and compare it to the same architecture optimized by MTL using Siamese\nNeural Networks (SNN). It can be shown that SNN outperform the baseline by\nrelative 26.8 % Equal Error Rate (EER). We further enhance the model's\narchitecture and demonstrate that SNN with additional reconstruction loss yield\nanother significant improvement of relative 13.8 % EER.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:21:16 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["von Platen", "Patrick", ""], ["Tao", "Fei", ""], ["Tur", "Gokhan", ""]]}, {"id": "2002.07631", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh, Mark Eisen, Alejandro Ribeiro", "title": "Wireless Power Control via Counterfactual Optimization of Graph Neural\n  Networks", "comments": "Submitted to the 21st IEEE International Workshop on Signal\n  Processing Advances in Wireless Communications (SPAWC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of downlink power control in wireless networks,\nconsisting of multiple transmitter-receiver pairs communicating with each other\nover a single shared wireless medium. To mitigate the interference among\nconcurrent transmissions, we leverage the network topology to create a graph\nneural network architecture, and we then use an unsupervised primal-dual\ncounterfactual optimization approach to learn optimal power allocation\ndecisions. We show how the counterfactual optimization technique allows us to\nguarantee a minimum rate constraint, which adapts to the network size, hence\nachieving the right balance between average and $5^{th}$ percentile user rates\nthroughout a range of network configurations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:54:39 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Eisen", "Mark", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2002.07638", "submitter": "Hanwei Wu", "authors": "Hanwei Wu, Ather Gattami, Markus Flierl", "title": "Conditional Mutual information-based Contrastive Loss for Financial Time\n  Series Forecasting", "comments": "Published in ICAIF 2020 : ACM International Conference on AI in\n  Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation learning framework for financial time series\nforecasting. One challenge of using deep learning models for finance\nforecasting is the shortage of available training data when using small\ndatasets. Direct trend classification using deep neural networks trained on\nsmall datasets is susceptible to the overfitting problem. In this paper, we\npropose to first learn compact representations from time series data, then use\nthe learned representations to train a simpler model for predicting time series\nmovements. We consider a class-conditioned latent variable model. We train an\nencoder network to maximize the mutual information between the latent variables\nand the trend information conditioned on the encoded observed variables. We\nshow that conditional mutual information maximization can be approximated by a\ncontrastive loss. Then, the problem is transformed into a classification task\nof determining whether two encoded representations are sampled from the same\nclass or not. This is equivalent to performing pairwise comparisons of the\ntraining datapoints, and thus, improves the generalization ability of the\nencoder network. We use deep autoregressive models as our encoder to capture\nlong-term dependencies of the sequence data. Empirical experiments indicate\nthat our proposed method has the potential to advance state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:24:33 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:39:39 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 10:37:10 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Wu", "Hanwei", ""], ["Gattami", "Ather", ""], ["Flierl", "Markus", ""]]}, {"id": "2002.07650", "submitter": "Andrey Malinin Dr.", "authors": "Andrey Malinin, Mark Gales", "title": "Uncertainty Estimation in Autoregressive Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation is important for ensuring safety and robustness of AI\nsystems. While most research in the area has focused on un-structured\nprediction tasks, limited work has investigated general uncertainty estimation\napproaches for structured prediction. Thus, this work aims to investigate\nuncertainty estimation for autoregressive structured prediction tasks within a\nsingle unified and interpretable probabilistic ensemble-based framework. We\nconsider: uncertainty estimation for sequence data at the token-level and\ncomplete sequence-level; interpretations for, and applications of, various\nmeasures of uncertainty; and discuss both the theoretical and practical\nchallenges associated with obtaining them. This work also provides baselines\nfor token-level and sequence-level error detection, and sequence-level\nout-of-domain input detection on the WMT'14 English-French and WMT'17\nEnglish-German translation and LibriSpeech speech recognition datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:40:13 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 12:03:10 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 10:31:28 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 09:01:22 GMT"}, {"version": "v5", "created": "Thu, 11 Feb 2021 09:42:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "2002.07656", "submitter": "Stephen Green", "authors": "Stephen R. Green, Christine Simpson, Jonathan Gair", "title": "Gravitational-wave parameter estimation with autoregressive neural\n  network flows", "comments": "14 pages, 7 figures", "journal-ref": "Phys. Rev. D 102, 104057 (2020)", "doi": "10.1103/PhysRevD.102.104057", "report-no": "LIGO-P2000053", "categories": "astro-ph.IM cs.LG gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of autoregressive normalizing flows for rapid\nlikelihood-free inference of binary black hole system parameters from\ngravitational-wave data with deep neural networks. A normalizing flow is an\ninvertible mapping on a sample space that can be used to induce a\ntransformation from a simple probability distribution to a more complex one: if\nthe simple distribution can be rapidly sampled and its density evaluated, then\nso can the complex distribution. Our first application to gravitational waves\nuses an autoregressive flow, conditioned on detector strain data, to map a\nmultivariate standard normal distribution into the posterior distribution over\nsystem parameters. We train the model on artificial strain data consisting of\nIMRPhenomPv2 waveforms drawn from a five-parameter $(m_1, m_2, \\phi_0, t_c,\nd_L)$ prior and stationary Gaussian noise realizations with a fixed power\nspectral density. This gives performance comparable to current best\ndeep-learning approaches to gravitational-wave parameter estimation. We then\nbuild a more powerful latent variable model by incorporating autoregressive\nflows within the variational autoencoder framework. This model has performance\ncomparable to Markov chain Monte Carlo and, in particular, successfully models\nthe multimodal $\\phi_0$ posterior. Finally, we train the autoregressive latent\nvariable model on an expanded parameter space, including also aligned spins\n$(\\chi_{1z}, \\chi_{2z})$ and binary inclination $\\theta_{JN}$, and show that\nall parameters and degeneracies are well-recovered. In all cases, sampling is\nextremely fast, requiring less than two seconds to draw $10^4$ posterior\nsamples.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:44:04 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Green", "Stephen R.", ""], ["Simpson", "Christine", ""], ["Gair", "Jonathan", ""]]}, {"id": "2002.07676", "submitter": "Claire Lazar Reich", "authors": "Claire Lazar Reich and Suhas Vijaykumar", "title": "A Possibility in Algorithmic Fairness: Can Calibration and Equal Error\n  Rates Be Reconciled?", "comments": "2nd Symposium on Foundations of Responsible Computing (FORC 2021)\n  https://drops.dagstuhl.de/opus/volltexte/2021/13872/", "journal-ref": null, "doi": "10.4230/LIPIcs.FORC.2021.4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision makers increasingly rely on algorithmic risk scores to determine\naccess to binary treatments including bail, loans, and medical interventions.\nIn these settings, we reconcile two fairness criteria that were previously\nshown to be in conflict: calibration and error rate equality. In particular, we\nderive necessary and sufficient conditions for the existence of calibrated\nscores that yield classifications achieving equal error rates at any given\ngroup-blind threshold. We then present an algorithm that searches for the most\naccurate score subject to both calibration and minimal error rate disparity.\nApplied to the COMPAS criminal risk assessment tool, we show that our method\ncan eliminate error disparities while maintaining calibration. In a separate\napplication to credit lending, we compare our procedure to the omission of\nsensitive features and show that it raises both profit and the probability that\ncreditworthy individuals receive loans.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:03:09 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 15:09:40 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 20:41:16 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Reich", "Claire Lazar", ""], ["Vijaykumar", "Suhas", ""]]}, {"id": "2002.07681", "submitter": "Axel Mosig", "authors": "Arne P. Raulf and Joshua Butke and Lukas Menzen and Claus K\\\"upper and\n  Frederik Gro{\\ss}erueschkamp and Klaus Gerwert and Axel Mosig", "title": "Deep Neural Networks for the Correction of Mie Scattering in\n  Fourier-Transformed Infrared Spectra of Biological Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrared spectra obtained from cell or tissue specimen have commonly been\nobserved to involve a significant degree of (resonant) Mie scattering, which\noften overshadows biochemically relevant spectral information by a non-linear,\nnon-additive spectral component in Fourier transformed infrared (FTIR)\nspectroscopic measurements. Correspondingly, many successful machine learning\napproaches for FTIR spectra have relied on preprocessing procedures that\ncomputationally remove the scattering components from an infrared spectrum. We\npropose an approach to approximate this complex preprocessing function using\ndeep neural networks. As we demonstrate, the resulting model is not just\nseveral orders of magnitudes faster, which is important for real-time clinical\napplications, but also generalizes strongly across different tissue types.\nFurthermore, our proposed method overcomes the trade-off between computation\ntime and the corrected spectrum being biased towards an artificial reference\nspectrum.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:07:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Raulf", "Arne P.", ""], ["Butke", "Joshua", ""], ["Menzen", "Lukas", ""], ["K\u00fcpper", "Claus", ""], ["Gro\u00dferueschkamp", "Frederik", ""], ["Gerwert", "Klaus", ""], ["Mosig", "Axel", ""]]}, {"id": "2002.07682", "submitter": "Sagar Kale", "authors": "Ashish Chiplunkar, Sagar Kale, Sivaramakrishnan Natarajan Ramamoorthy", "title": "How to Solve Fair $k$-Center in Massive Data Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fueled by massive data, important decision making is being automated with the\nhelp of algorithms, therefore, fairness in algorithms has become an especially\nimportant research topic. In this work, we design new streaming and distributed\nalgorithms for the fair $k$-center problem that models fair data summarization.\nThe streaming and distributed models of computation have an attractive feature\nof being able to handle massive data sets that do not fit into main memory. Our\nmain contributions are: (a) the first distributed algorithm; which has provably\nconstant approximation ratio and is extremely parallelizable, and (b) a\ntwo-pass streaming algorithm with a provable approximation guarantee matching\nthe best known algorithm (which is not a streaming algorithm). Our algorithms\nhave the advantages of being easy to implement in practice, being fast with\nlinear running times, having very small working memory and communication, and\noutperforming existing algorithms on several real and synthetic data sets. To\ncomplement our distributed algorithm, we also give a hardness result for\nnatural distributed algorithms, which holds for even the special case of\n$k$-center.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:11:40 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 16:55:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chiplunkar", "Ashish", ""], ["Kale", "Sagar", ""], ["Ramamoorthy", "Sivaramakrishnan Natarajan", ""]]}, {"id": "2002.07684", "submitter": "Matteo Tiezzi", "authors": "Matteo Tiezzi, Giuseppe Marra, Stefano Melacci, Marco Maggini, and\n  Marco Gori", "title": "A Lagrangian Approach to Information Propagation in Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world applications, data are characterized by a complex\nstructure, that can be naturally encoded as a graph. In the last years, the\npopularity of deep learning techniques has renewed the interest in neural\nmodels able to process complex patterns. In particular, inspired by the Graph\nNeural Network (GNN) model, different architectures have been proposed to\nextend the original GNN scheme. GNNs exploit a set of state variables, each\nassigned to a graph node, and a diffusion mechanism of the states among\nneighbor nodes, to implement an iterative procedure to compute the fixed point\nof the (learnable) state transition function. In this paper, we propose a novel\napproach to the state computation and the learning algorithm for GNNs, based on\na constraint optimisation task solved in the Lagrangian framework. The state\nconvergence procedure is implicitly expressed by the constraint satisfaction\nmechanism and does not require a separate iterative phase for each epoch of the\nlearning procedure. In fact, the computational structure is based on the search\nfor saddle points of the Lagrangian in the adjoint space composed of weights,\nneural outputs (node states), and Lagrange multipliers. The proposed approach\nis compared experimentally with other popular models for processing graphs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:13:24 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:48:50 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 11:37:42 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tiezzi", "Matteo", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "2002.07686", "submitter": "Moran Shkolnik", "authors": "Moran Shkolnik, Brian Chmiel, Ron Banner, Gil Shomron, Yury Nahshan,\n  Alex Bronstein, Uri Weiser", "title": "Robust Quantization: One Model to Rule Them All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network quantization methods often involve simulating the quantization\nprocess during training, making the trained model highly dependent on the\ntarget bit-width and precise way quantization is performed. Robust quantization\noffers an alternative approach with improved tolerance to different classes of\ndata-types and quantization policies. It opens up new exciting applications\nwhere the quantization process is not static and can vary to meet different\ncircumstances and implementations. To address this issue, we propose a method\nthat provides intrinsic robustness to the model against a broad range of\nquantization processes. Our method is motivated by theoretical arguments and\nenables us to store a single generic model capable of operating at various\nbit-widths and quantization policies. We validate our method's effectiveness on\ndifferent ImageNet models.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:14:36 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:18:40 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 08:46:01 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Shkolnik", "Moran", ""], ["Chmiel", "Brian", ""], ["Banner", "Ron", ""], ["Shomron", "Gil", ""], ["Nahshan", "Yury", ""], ["Bronstein", "Alex", ""], ["Weiser", "Uri", ""]]}, {"id": "2002.07696", "submitter": "Oren Barkan", "authors": "Oren Barkan, Ori Katz, Noam Koenigstein", "title": "Neural Attentive Multiview Machines", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in multiview representation learning is finding the\noptimal combination of views with respect to the specific task at hand. To this\nend, we introduce NAM: a Neural Attentive Multiview machine that learns\nmultiview item representations and similarity by employing a novel attention\nmechanism. NAM harnesses multiple information sources and automatically\nquantifies their relevancy with respect to a supervised task. Finally, a very\npractical advantage of NAM is its robustness to the case of dataset with\nmissing views. We demonstrate the effectiveness of NAM for the task of movies\nand app recommendations. Our evaluations indicate that NAM outperforms single\nview models as well as alternative multiview methods on item recommendations\ntasks, including cold-start scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:21:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Barkan", "Oren", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2002.07703", "submitter": "Ziyang Wang", "authors": "Ziyang Wang", "title": "Deep Learning in Medical Ultrasound Image Segmentation: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning technologies, especially deep learning, into\nmedical image segmentation is being widely studied because of its\nstate-of-the-art performance and results. It can be a key step to provide a\nreliable basis for clinical diagnosis, such as 3D reconstruction of human\ntissues, image-guided interventions, image analyzing and visualization. In this\nreview article, deep-learning-based methods for ultrasound image segmentation\nare categorized into six main groups according to their architectures and\ntraining at first. Secondly, for each group, several current representative\nalgorithms are selected, introduced, analyzed and summarized in detail. In\naddition, common evaluation methods for image segmentation and ultrasound image\nsegmentation datasets are summarized. Further, the performance of the current\nmethods and their evaluations are reviewed. In the end, the challenges and\npotential research directions for medical ultrasound image segmentation are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:33:22 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:29:26 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 00:05:17 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wang", "Ziyang", ""]]}, {"id": "2002.07717", "submitter": "Gregor Simm", "authors": "Gregor N. C. Simm, Robert Pinsler, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Reinforcement Learning for Molecular Design Guided by Quantum Mechanics", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating molecular design using deep reinforcement learning (RL) holds the\npromise of accelerating the discovery of new chemical compounds. Existing\napproaches work with molecular graphs and thus ignore the location of atoms in\nspace, which restricts them to 1) generating single organic molecules and 2)\nheuristic reward functions. To address this, we present a novel RL formulation\nfor molecular design in Cartesian coordinates, thereby extending the class of\nmolecules that can be built. Our reward function is directly based on\nfundamental physical properties such as the energy, which we approximate via\nfast quantum-chemical methods. To enable progress towards de-novo molecular\ndesign, we introduce MolGym, an RL environment comprising several challenging\nmolecular design tasks along with baselines. In our experiments, we show that\nour agent can efficiently learn to solve these tasks from scratch by working in\na translation and rotation invariant state-action space.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:43:58 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 14:16:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Simm", "Gregor N. C.", ""], ["Pinsler", "Robert", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2002.07720", "submitter": "Matteo Tiezzi", "authors": "Giuseppe Marra, Matteo Tiezzi, Stefano Melacci, Alessandro Betti,\n  Marco Maggini, Marco Gori", "title": "Local Propagation in Constraint-based Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a constraint-based representation of neural network\narchitectures. We cast the learning problem in the Lagrangian framework and we\ninvestigate a simple optimization procedure that is well suited to fulfil the\nso-called architectural constraints, learning from the available supervisions.\nThe computational structure of the proposed Local Propagation (LP) algorithm is\nbased on the search for saddle points in the adjoint space composed of weights,\nneural outputs, and Lagrange multipliers. All the updates of the model\nvariables are locally performed, so that LP is fully parallelizable over the\nneural units, circumventing the classic problem of gradient vanishing in deep\nnetworks. The implementation of popular neural models is described in the\ncontext of LP, together with those conditions that trace a natural connection\nwith Backpropagation. We also investigate the setting in which we tolerate\nbounded violations of the architectural constraints, and we provide\nexperimental evidence that LP is a feasible approach to train shallow and deep\nnetworks, opening the road to further investigations on more complex\narchitectures, easily describable by constraints.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:47:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 10:20:48 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Marra", "Giuseppe", ""], ["Tiezzi", "Matteo", ""], ["Melacci", "Stefano", ""], ["Betti", "Alessandro", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "2002.07729", "submitter": "Akshay Krishnamurthy", "authors": "Yi Su, Pavithra Srinath, Akshay Krishnamurthy", "title": "Adaptive Estimator Selection for Off-Policy Evaluation", "comments": "Fixed some typos. Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a generic data-driven method for estimator selection in off-policy\npolicy evaluation settings. We establish a strong performance guarantee for the\nmethod, showing that it is competitive with the oracle estimator, up to a\nconstant factor. Via in-depth case studies in contextual bandits and\nreinforcement learning, we demonstrate the generality and applicability of the\nmethod. We also perform comprehensive experiments, demonstrating the empirical\nefficacy of our approach and comparing with related approaches. In both case\nstudies, our method compares favorably with existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:57:42 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 14:54:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Su", "Yi", ""], ["Srinath", "Pavithra", ""], ["Krishnamurthy", "Akshay", ""]]}, {"id": "2002.07738", "submitter": "Samuel Yeom", "authors": "Samuel Yeom, Matt Fredrikson", "title": "Individual Fairness Revisited: Transferring Techniques from Adversarial\n  Robustness", "comments": "Published at IJCAI 2020 (at https://www.ijcai.org/Proceedings/2020/61\n  ); the conference version has a minor error in the proof of Theorem 3, which\n  is fixed here", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We turn the definition of individual fairness on its head---rather than\nascertaining the fairness of a model given a predetermined metric, we find a\nmetric for a given model that satisfies individual fairness. This can\nfacilitate the discussion on the fairness of a model, addressing the issue that\nit may be difficult to specify a priori a suitable metric. Our contributions\nare twofold: First, we introduce the definition of a minimal metric and\ncharacterize the behavior of models in terms of minimal metrics. Second, for\nmore complicated models, we apply the mechanism of randomized smoothing from\nadversarial robustness to make them individually fair under a given weighted\n$L^p$ metric. Our experiments show that adapting the minimal metrics of linear\nmodels to more complicated neural networks can lead to meaningful and\ninterpretable fairness guarantees at little cost to utility.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:14:02 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 22:44:28 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 00:53:43 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 14:03:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yeom", "Samuel", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2002.07756", "submitter": "Morteza Haghir Chehreghani", "authors": "Morteza Haghir Chehreghani", "title": "Hierarchical Correlation Clustering and Tree Preserving Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchical correlation clustering method that extends the\nwell-known correlation clustering to produce hierarchical clusters. We then\ninvestigate embedding the respective hierarchy to be used for (tree preserving)\nembedding and feature extraction. We study the connection of such an embedding\nto single linkage embedding and minimax distances, and in particular study\nminimax distances for correlation clustering. Finally, we demonstrate the\nperformance of our methods on several UCI and 20 newsgroup datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:44:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2002.07766", "submitter": "Matthew Willetts", "authors": "Alexander Camuto, Matthew Willetts, Brooks Paige, Chris Holmes,\n  Stephen Roberts", "title": "Learning Bijective Feature Maps for Linear ICA", "comments": "8 pages", "journal-ref": "AISTATS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating high-dimensional data like images into independent latent factors,\ni.e independent component analysis (ICA), remains an open research problem. As\nwe show, existing probabilistic deep generative models (DGMs), which are\ntailor-made for image data, underperform on non-linear ICA tasks. To address\nthis, we propose a DGM which combines bijective feature maps with a linear ICA\nmodel to learn interpretable latent structures for high-dimensional data. Given\nthe complexities of jointly training such a hybrid model, we introduce novel\ntheory that constrains linear ICA to lie close to the manifold of orthogonal\nrectangular matrices, the Stiefel manifold. By doing so we create models that\nconverge quickly, are easy to train, and achieve better unsupervised latent\nfactor discovery than flow-based models, linear ICA, and Variational\nAutoencoders on images.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:58:07 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:03:28 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 17:10:45 GMT"}, {"version": "v4", "created": "Mon, 2 Nov 2020 17:57:27 GMT"}, {"version": "v5", "created": "Fri, 29 Jan 2021 18:08:28 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Camuto", "Alexander", ""], ["Willetts", "Matthew", ""], ["Paige", "Brooks", ""], ["Holmes", "Chris", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.07772", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh, Natalia Ponomareva, Petros Mol, Zhenyu Tan, Rahul\n  Mazumder", "title": "The Tree Ensemble Layer: Differentiability meets Conditional Computation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and tree ensembles are state-of-the-art learners, each with\nits unique statistical and computational advantages. We aim to combine these\nadvantages by introducing a new layer for neural networks, composed of an\nensemble of differentiable decision trees (a.k.a. soft trees). While\ndifferentiable trees demonstrate promising results in the literature, they are\ntypically slow in training and inference as they do not support conditional\ncomputation. We mitigate this issue by introducing a new sparse activation\nfunction for sample routing, and implement true conditional computation by\ndeveloping specialized forward and backward propagation algorithms that exploit\nsparsity. Our efficient algorithms pave the way for jointly training over deep\nand wide tree ensembles using first-order methods (e.g., SGD). Experiments on\n23 classification datasets indicate over 10x speed-ups compared to the\ndifferentiable trees used in the literature and over 20x reduction in the\nnumber of parameters compared to gradient boosted trees, while maintaining\ncompetitive performance. Moreover, experiments on CIFAR, MNIST, and Fashion\nMNIST indicate that replacing dense layers in CNNs with our tree layer reduces\nthe test loss by 7-53% and the number of parameters by 8x. We provide an\nopen-source TensorFlow implementation with a Keras API.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:05:31 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 00:40:16 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Ponomareva", "Natalia", ""], ["Mol", "Petros", ""], ["Tan", "Zhenyu", ""], ["Mazumder", "Rahul", ""]]}, {"id": "2002.07791", "submitter": "Oriol Ramos Terrades", "authors": "O. Ramos Terrades, A. Berenguel, D. Gil", "title": "A flexible outlier detector based on a topology given by graph\n  communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier, or anomaly, detection is essential for optimal performance of\nmachine learning methods and statistical predictive models. It is not just a\ntechnical step in a data cleaning process but a key topic in many fields such\nas fraudulent document detection, in medical applications and assisted\ndiagnosis systems or detecting security threats. In contrast to\npopulation-based methods, neighborhood based local approaches are simple\nflexible methods that have the potential to perform well in small sample size\nunbalanced problems. However, a main concern of local approaches is the impact\nthat the computation of each sample neighborhood has on the method performance.\nMost approaches use a distance in the feature space to define a single\nneighborhood that requires careful selection of several parameters. This work\npresents a local approach based on a local measure of the heterogeneity of\nsample labels in the feature space considered as a topological manifold.\nTopology is computed using the communities of a weighted graph codifying mutual\nnearest neighbors in the feature space. This way, we provide with a set of\nmultiple neighborhoods able to describe the structure of complex spaces without\nparameter fine tuning. The extensive experiments on real-world data sets show\nthat our approach overall outperforms, both, local and global strategies in\nmulti and single view settings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:40:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Terrades", "O. Ramos", ""], ["Berenguel", "A.", ""], ["Gil", "D.", ""]]}, {"id": "2002.07803", "submitter": "Tiago Peixoto", "authors": "Tiago P. Peixoto", "title": "Latent Poisson models for networks with heterogeneous density", "comments": "19 pages, 16 figures", "journal-ref": "Phys. Rev. E 102, 012309 (2020)", "doi": "10.1103/PhysRevE.102.012309", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Empirical networks are often globally sparse, with a small average number of\nconnections per node, when compared to the total size of the network. However,\nthis sparsity tends not to be homogeneous, and networks can also be locally\ndense, for example with a few nodes connecting to a large fraction of the rest\nof the network, or with small groups of nodes with a large probability of\nconnections between them. Here we show how latent Poisson models which generate\nhidden multigraphs can be effective at capturing this density heterogeneity,\nwhile being more tractable mathematically than some of the alternatives that\nmodel simple graphs directly. We show how these latent multigraphs can be\nreconstructed from data on simple graphs, and how this allows us to disentangle\ndisassortative degree-degree correlations from the constraints of imposed\ndegree sequences, and to improve the identification of community structure in\nempirically relevant scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:58:13 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 10:57:25 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 14:42:23 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 14:43:43 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Peixoto", "Tiago P.", ""]]}, {"id": "2002.07806", "submitter": "Nir Shlezinger", "authors": "Nariman Farsad, Nir Shlezinger, Andrea J. Goldsmith and Yonina C.\n  Eldar", "title": "Data-Driven Symbol Detection via Model-Based Machine Learning", "comments": "arXiv admin note: text overlap with arXiv:1905.10750", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of symbol detectors in digital communication systems has\ntraditionally relied on statistical channel models that describe the relation\nbetween the transmitted symbols and the observed signal at the receiver. Here\nwe review a data-driven framework to symbol detection design which combines\nmachine learning (ML) and model-based algorithms. In this hybrid approach,\nwell-known channel-model-based algorithms such as the Viterbi method, BCJR\ndetection, and multiple-input multiple-output (MIMO) soft interference\ncancellation (SIC) are augmented with ML-based algorithms to remove their\nchannel-model-dependence, allowing the receiver to learn to implement these\nalgorithms solely from data. The resulting data-driven receivers are most\nsuitable for systems where the underlying channel models are poorly understood,\nhighly complex, or do not well-capture the underlying physics. Our approach is\nunique in that it only replaces the channel-model-based computations with\ndedicated neural networks that can be trained from a small amount of data,\nwhile keeping the general algorithm intact. Our results demonstrate that these\ntechniques can yield near-optimal performance of model-based algorithms without\nknowing the exact channel input-output statistical relationship and in the\npresence of channel state information uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:58:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Farsad", "Nariman", ""], ["Shlezinger", "Nir", ""], ["Goldsmith", "Andrea J.", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2002.07815", "submitter": "Gr\\'egoire Aufort", "authors": "G. Aufort, L. Ciesla, P. Pudlo and V. Buat", "title": "Constraining the recent star formation history of galaxies : an\n  Approximate Bayesian Computation approach", "comments": null, "journal-ref": "A&A 635, A136 (2020)", "doi": "10.1051/0004-6361/201936788", "report-no": null, "categories": "astro-ph.GA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [Abridged] Although galaxies are found to follow a tight relation between\ntheir star formation rate and stellar mass, they are expected to exhibit\ncomplex star formation histories (SFH), with short-term fluctuations. The goal\nof this pilot study is to present a method that will identify galaxies that are\nundergoing a strong variation of star formation activity in the last tens to\nhundreds Myr. In other words, the proposed method will determine whether a\nvariation in the last few hundreds of Myr of the SFH is needed to properly\nmodel the SED rather than a smooth normal SFH. To do so, we analyze a sample of\nCOSMOS galaxies using high signal-to-noise ratio broad band photometry. We\napply Approximate Bayesian Computation, a state-of-the-art statistical method\nto perform model choice, associated to machine learning algorithms to provide\nthe probability that a flexible SFH is preferred based on the observed flux\ndensity ratios of galaxies. We present the method and test it on a sample of\nsimulated SEDs. The input information fed to the algorithm is a set of\nbroadband UV to NIR (rest-frame) flux ratios for each galaxy. The method has an\nerror rate of 21% in recovering the right SFH and is sensitive to SFR\nvariations larger than 1 dex. A more traditional SED fitting method using\nCIGALE is tested to achieve the same goal, based on fits comparisons through\nBayesian Information Criterion but the best error rate obtained is higher, 28%.\nWe apply our new method to the COSMOS galaxies sample. The stellar mass\ndistribution of galaxies with a strong to decisive evidence against the smooth\ndelayed-$\\tau$ SFH peaks at lower M* compared to galaxies where the smooth\ndelayed-$\\tau$ SFH is preferred. We discuss the fact that this result does not\ncome from any bias due to our training. Finally, we argue that flexible SFHs\nare needed to be able to cover that largest SFR-M* parameter space possible.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:00:01 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Aufort", "G.", ""], ["Ciesla", "L.", ""], ["Pudlo", "P.", ""], ["Buat", "V.", ""]]}, {"id": "2002.07836", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji, Junjie Yang, Yingbin Liang", "title": "Theoretical Convergence of Multi-Step Model-Agnostic Meta-Learning", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular meta-learning approach, the model-agnostic meta-learning (MAML)\nalgorithm has been widely used due to its simplicity and effectiveness.\nHowever, the convergence of the general multi-step MAML still remains\nunexplored. In this paper, we develop a new theoretical framework to provide\nsuch convergence guarantee for two types of objective functions that are of\ninterest in practice: (a) resampling case (e.g., reinforcement learning), where\nloss functions take the form in expectation and new data are sampled as the\nalgorithm runs; and (b) finite-sum case (e.g., supervised learning), where loss\nfunctions take the finite-sum form with given samples. For both cases, we\ncharacterize the convergence rate and the computational complexity to attain an\n$\\epsilon$-accurate solution for multi-step MAML in the general nonconvex\nsetting. In particular, our results suggest that an inner-stage stepsize needs\nto be chosen inversely proportional to the number $N$ of inner-stage steps in\norder for $N$-step MAML to have guaranteed convergence. From the technical\nperspective, we develop novel techniques to deal with the nested structure of\nthe meta gradient for multi-step MAML, which can be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:17:54 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:11:20 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 04:03:09 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ji", "Kaiyi", ""], ["Yang", "Junjie", ""], ["Liang", "Yingbin", ""]]}, {"id": "2002.07839", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Kumar Kshitij Patel, Sebastian U. Stich, Zhen Dai,\n  Brian Bullins, H. Brendan McMahan, Ohad Shamir, Nathan Srebro", "title": "Is Local SGD Better than Minibatch SGD?", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study local SGD (also known as parallel SGD and federated averaging), a\nnatural and frequently used stochastic distributed optimization method. Its\ntheoretical foundations are currently lacking and we highlight how all existing\nerror guarantees in the convex setting are dominated by a simple baseline,\nminibatch SGD. (1) For quadratic objectives we prove that local SGD strictly\ndominates minibatch SGD and that accelerated local SGD is minimax optimal for\nquadratics; (2) For general convex objectives we provide the first guarantee\nthat at least sometimes improves over minibatch SGD; (3) We show that indeed\nlocal SGD does not dominate minibatch SGD by presenting a lower bound on the\nperformance of local SGD that is worse than the minibatch SGD guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:22:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:47:48 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Woodworth", "Blake", ""], ["Patel", "Kumar Kshitij", ""], ["Stich", "Sebastian U.", ""], ["Dai", "Zhen", ""], ["Bullins", "Brian", ""], ["McMahan", "H. Brendan", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.07863", "submitter": "Georg Kohl", "authors": "Georg Kohl, Kiwon Um, Nils Thuerey", "title": "Learning Similarity Metrics for Numerical Simulations", "comments": "Main paper: 9 pages, Appendix: 19 pages. Accepted at ICML 2020.\n  Source code available at https://github.com/tum-pbs/LSIM and further\n  information at https://ge.in.tum.de/publications/2020-lsim-kohl/", "journal-ref": "Proceedings of Machine Learning Research 119 (2020) 5349-5360", "doi": null, "report-no": null, "categories": "cs.LG physics.data-an physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network-based approach that computes a stable and\ngeneralizing metric (LSiM) to compare data from a variety of numerical\nsimulation sources. We focus on scalar time-dependent 2D data that commonly\narises from motion and transport-based partial differential equations (PDEs).\nOur method employs a Siamese network architecture that is motivated by the\nmathematical properties of a metric. We leverage a controllable data generation\nsetup with PDE solvers to create increasingly different outputs from a\nreference simulation in a controlled environment. A central component of our\nlearned metric is a specialized loss function that introduces knowledge about\nthe correlation between single data samples into the training process. To\ndemonstrate that the proposed approach outperforms existing metrics for vector\nspaces and other learned, image-based metrics, we evaluate the different\nmethods on a large range of test data. Additionally, we analyze generalization\nbenefits of an adjustable training data difficulty and demonstrate the\nrobustness of LSiM via an evaluation on three real-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:11:15 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:14:55 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Kohl", "Georg", ""], ["Um", "Kiwon", ""], ["Thuerey", "Nils", ""]]}, {"id": "2002.07867", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen and Marco Mondelli", "title": "Global Convergence of Deep Networks with One Wide Layer Followed by\n  Pyramidal Topology", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that gradient descent can find a global minimum for\nover-parameterized neural networks where the widths of all the hidden layers\nscale polynomially with $N$ ($N$ being the number of training samples). In this\npaper, we prove that, for deep networks, a single layer of width $N$ following\nthe input layer suffices to ensure a similar guarantee. In particular, all the\nremaining layers are allowed to have constant widths, and form a pyramidal\ntopology. We show an application of our result to the widely used LeCun's\ninitialization and obtain an over-parameterization requirement for the single\nwide layer of order $N^2.$\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:21:27 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 15:23:02 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 19:45:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mondelli", "Marco", ""]]}, {"id": "2002.07873", "submitter": "Emily T Winn", "authors": "Emily T. Winn, Marilyn Vazquez, Prachi Loliencar, Kaisa Taipale, Xu\n  Wang and Giseon Heo", "title": "A survey of statistical learning techniques as applied to inexpensive\n  pediatric Obstructive Sleep Apnea data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pediatric obstructive sleep apnea affects an estimated 1-5% of\nelementary-school aged children and can lead to other detrimental health\nproblems. Swift diagnosis and treatment are critical to a child's growth and\ndevelopment, but the variability of symptoms and the complexity of the\navailable data make this a challenge. We take a first step in streamlining the\nprocess by focusing on inexpensive data from questionnaires and craniofacial\nmeasurements. We apply correlation networks, the Mapper algorithm from\ntopological data analysis, and singular value decomposition in a process of\nexploratory data analysis. We then apply a variety of supervised and\nunsupervised learning techniques from statistics, machine learning, and\ntopology, ranging from support vector machines to Bayesian classifiers and\nmanifold learning. Finally, we analyze the results of each of these methods and\ndiscuss the implications for a multi-data-sourced algorithm moving forward.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:15:32 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 14:35:46 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Winn", "Emily T.", ""], ["Vazquez", "Marilyn", ""], ["Loliencar", "Prachi", ""], ["Taipale", "Kaisa", ""], ["Wang", "Xu", ""], ["Heo", "Giseon", ""]]}, {"id": "2002.07874", "submitter": "Matthew Leming", "authors": "Matthew Leming, Juan Manuel G\\'orriz, John Suckling", "title": "Ensemble Deep Learning on Large, Mixed-Site fMRI Datasets in Autism and\n  Other Tasks", "comments": null, "journal-ref": null, "doi": "10.1142/S0129065720500124", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for MRI classification face two recurring problems: they\nare typically limited by low sample size, and are abstracted by their own\ncomplexity (the \"black box problem\"). In this paper, we train a convolutional\nneural network (CNN) with the largest multi-source, functional MRI (fMRI)\nconnectomic dataset ever compiled, consisting of 43,858 datapoints. We apply\nthis model to a cross-sectional comparison of autism (ASD) vs typically\ndeveloping (TD) controls that has proved difficult to characterise with\ninferential statistics. To contextualise these findings, we additionally\nperform classifications of gender and task vs rest. Employing class-balancing\nto build a training set, we trained 3$\\times$300 modified CNNs in an ensemble\nmodel to classify fMRI connectivity matrices with overall AUROCs of 0.6774,\n0.7680, and 0.9222 for ASD vs TD, gender, and task vs rest, respectively.\nAdditionally, we aim to address the black box problem in this context using two\nvisualization methods. First, class activation maps show which functional\nconnections of the brain our models focus on when performing classification.\nSecond, by analyzing maximal activations of the hidden layers, we were also\nable to explore how the model organizes a large and mixed-centre dataset,\nfinding that it dedicates specific areas of its hidden layers to processing\ndifferent covariates of data (depending on the independent variable analyzed),\nand other areas to mix data from different sources. Our study finds that deep\nlearning models that distinguish ASD from TD controls focus broadly on temporal\nand cerebellar connections, with a particularly high focus on the right caudate\nnucleus and paracentral sulcus.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:28:16 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:31:37 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Leming", "Matthew", ""], ["G\u00f3rriz", "Juan Manuel", ""], ["Suckling", "John", ""]]}, {"id": "2002.07877", "submitter": "Subhadip Maji", "authors": "Subhadip Maji and Smarajit Bose", "title": "CBIR using features derived by Deep Learning", "comments": "18 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Content Based Image Retrieval (CBIR) System, the task is to retrieve\nsimilar images from a large database given a query image. The usual procedure\nis to extract some useful features from the query image, and retrieve images\nwhich have similar set of features. For this purpose, a suitable similarity\nmeasure is chosen, and images with high similarity scores are retrieved.\nNaturally the choice of these features play a very important role in the\nsuccess of this system, and high level features are required to reduce the\nsemantic gap.\n  In this paper, we propose to use features derived from pre-trained network\nmodels from a deep-learning convolution network trained for a large image\nclassification problem. This approach appears to produce vastly superior\nresults for a variety of databases, and it outperforms many contemporary CBIR\nsystems. We analyse the retrieval time of the method, and also propose a\npre-clustering of the database based on the above-mentioned features which\nyields comparable results in a much shorter time in most of the cases.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 21:26:32 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Maji", "Subhadip", ""], ["Bose", "Smarajit", ""]]}, {"id": "2002.07884", "submitter": "Armen Allahverdyan", "authors": "A.E. Allahverdyan", "title": "Observational nonidentifiability, generalized likelihood and free energy", "comments": "25 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameter estimation problem in mixture models with\nobservational nonidentifiability: the full model (also containing hidden\nvariables) is identifiable, but the marginal (observed) model is not. Hence\nglobal maxima of the marginal likelihood are (infinitely) degenerate and\npredictions of the marginal likelihood are not unique. We show how to\ngeneralize the marginal likelihood by introducing an effective temperature, and\nmaking it similar to the free energy. This generalization resolves the\nobservational nonidentifiability, since its maximization leads to unique\nresults that are better than a random selection of one degenerate maximum of\nthe marginal likelihood or the averaging over many such maxima. The generalized\nlikelihood inherits many features from the usual likelihood, e.g. it holds the\nconditionality principle, and its local maximum can be searched for via\nsuitably modified expectation-maximization method. The maximization of the\ngeneralized likelihood relates to entropy optimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:22:14 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Allahverdyan", "A. E.", ""]]}, {"id": "2002.07891", "submitter": "Pu Zhao", "authors": "Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin", "title": "Towards Query-Efficient Black-Box Adversary with Zeroth-Order Natural\n  Gradient Descent", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great achievements of the modern deep neural networks (DNNs), the\nvulnerability/robustness of state-of-the-art DNNs raises security concerns in\nmany application domains requiring high reliability. Various adversarial\nattacks are proposed to sabotage the learning performance of DNN models. Among\nthose, the black-box adversarial attack methods have received special\nattentions owing to their practicality and simplicity. Black-box attacks\nusually prefer less queries in order to maintain stealthy and low costs.\nHowever, most of the current black-box attack methods adopt the first-order\ngradient descent method, which may come with certain deficiencies such as\nrelatively slow convergence and high sensitivity to hyper-parameter settings.\nIn this paper, we propose a zeroth-order natural gradient descent (ZO-NGD)\nmethod to design the adversarial attacks, which incorporates the zeroth-order\ngradient estimation technique catering to the black-box attack scenario and the\nsecond-order natural gradient descent to achieve higher query efficiency. The\nempirical evaluations on image classification datasets demonstrate that ZO-NGD\ncan obtain significantly lower model query complexities compared with\nstate-of-the-art attack methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:48:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhao", "Pu", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Siyue", ""], ["Lin", "Xue", ""]]}, {"id": "2002.07898", "submitter": "Wen Tang", "authors": "Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, and Hamid Krim", "title": "Deep Transform and Metric Learning Network: Wedding Deep Dictionary\n  Learning and Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On account of its many successes in inference tasks and denoising\napplications, Dictionary Learning (DL) and its related sparse optimization\nproblems have garnered a lot of research interest. While most solutions have\nfocused on single layer dictionaries, the improved recently proposed Deep DL\n(DDL) methods have also fallen short on a number of issues. We propose herein,\na novel DDL approach where each DL layer can be formulated as a combination of\none linear layer and a Recurrent Neural Network (RNN). The RNN is shown to\nflexibly account for the layer-associated and learned metric. Our proposed work\nunveils new insights into Neural Networks and DDL and provides a new, efficient\nand competitive approach to jointly learn a deep transform and a metric for\ninference applications. Extensive experiments are carried out to demonstrate\nthat the proposed method can not only outperform existing DDL but also\nstate-of-the-art generic CNNs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:04:11 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 01:57:18 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Tang", "Wen", ""], ["Chouzenoux", "Emilie", ""], ["Pesquet", "Jean-Christophe", ""], ["Krim", "Hamid", ""]]}, {"id": "2002.07905", "submitter": "Daniel Vial", "authors": "Daniel Vial, Vijay Subramanian", "title": "Empirical Policy Evaluation with Supergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise and analyze algorithms for the empirical policy evaluation problem\nin reinforcement learning. Our algorithms explore backward from high-cost\nstates to find high-value ones, in contrast to forward approaches that work\nforward from all states. While several papers have demonstrated the utility of\nbackward exploration empirically, we conduct rigorous analyses which show that\nour algorithms can reduce average-case sample complexity from $O(S \\log S)$ to\nas low as $O(\\log S)$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:17:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Vial", "Daniel", ""], ["Subramanian", "Vijay", ""]]}, {"id": "2002.07906", "submitter": "Wei Zhang", "authors": "Wei Zhang, Thomas Kobber Panum, Somesh Jha, Prasad Chalasani, and\n  David Page", "title": "CAUSE: Learning Granger Causality from Event Sequences using Attribution\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Granger causality between event types from\nasynchronous, interdependent, multi-type event sequences. Existing work suffers\nfrom either limited model flexibility or poor model explainability and thus\nfails to uncover Granger causality across a wide variety of event sequences\nwith diverse event interdependency. To address these weaknesses, we propose\nCAUSE (Causality from AttribUtions on Sequence of Events), a novel framework\nfor the studied task. The key idea of CAUSE is to first implicitly capture the\nunderlying event interdependency by fitting a neural point process, and then\nextract from the process a Granger causality statistic using an axiomatic\nattribution method. Across multiple datasets riddled with diverse event\ninterdependency, we demonstrate that CAUSE achieves superior performance on\ncorrectly inferring the inter-type Granger causality over a range of\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:21:11 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Wei", ""], ["Panum", "Thomas Kobber", ""], ["Jha", "Somesh", ""], ["Chalasani", "Prasad", ""], ["Page", "David", ""]]}, {"id": "2002.07911", "submitter": "Sharath Chandra Raparthy", "authors": "Sharath Chandra Raparthy, Bhairav Mehta, Florian Golemo, Liam Paull", "title": "Generating Automatic Curricula via Self-Supervised Active Domain\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-directed Reinforcement Learning (RL) traditionally considers an agent\ninteracting with an environment, prescribing a real-valued reward to an agent\nproportional to the completion of some goal. Goal-directed RL has seen large\ngains in sample efficiency, due to the ease of reusing or generating new\nexperience by proposing goals. One approach,self-play, allows an agent to\n\"play\" against itself by alternatively setting and accomplishing goals,\ncreating a learned curriculum through which an agent can learn to accomplish\nprogressively more difficult goals. However, self-play has been limited to goal\ncurriculum learning or learning progressively harder goals within a single\nenvironment. Recent work on robotic agents has shown that varying the\nenvironment during training, for example with domain randomization, leads to\nmore robust transfer. As a result, we extend the self-play framework to jointly\nlearn a goal and environment curriculum, leading to an approach that learns the\nmost fruitful domain randomization strategy with self-play. Our method,\nSelf-Supervised Active Domain Randomization(SS-ADR), generates a coupled\ngoal-task curriculum, where agents learn through progressively more difficult\ntasks and environment variations. By encouraging the agent to try tasks that\nare just outside of its current capabilities, SS-ADR builds a domain\nrandomization curriculum that enables state-of-the-art results on\nvarioussim2real transfer tasks. Our results show that a curriculum of\nco-evolving the environment difficulty together with the difficulty of goals\nset in each environment provides practical benefits in the goal-directed tasks\ntested.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:45:29 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 18:24:29 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Raparthy", "Sharath Chandra", ""], ["Mehta", "Bhairav", ""], ["Golemo", "Florian", ""], ["Paull", "Liam", ""]]}, {"id": "2002.07916", "submitter": "Siddhartha Jain", "authors": "Siddhartha Jain, Ge Liu, David Gifford", "title": "Information Condensing Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Information Condensing Active Learning (ICAL), a batch mode\nmodel agnostic Active Learning (AL) method targeted at Deep Bayesian Active\nLearning that focuses on acquiring labels for points which have as much\ninformation as possible about the still unacquired points. ICAL uses the\nHilbert Schmidt Independence Criterion (HSIC) to measure the strength of the\ndependency between a candidate batch of points and the unlabeled set. We\ndevelop key optimizations that allow us to scale our method to large unlabeled\nsets. We show significant improvements in terms of model accuracy and negative\nlog likelihood (NLL) on several image datasets compared to state of the art\nbatch mode AL methods for deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:55:08 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:52:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Jain", "Siddhartha", ""], ["Liu", "Ge", ""], ["Gifford", "David", ""]]}, {"id": "2002.07933", "submitter": "Hrayr Harutyunyan", "authors": "Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan", "title": "Improving Generalization by Controlling Label-Noise Information in\n  Neural Network Weights", "comments": "ICML, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of noisy or incorrect labels, neural networks have the\nundesirable tendency to memorize information about the noise. Standard\nregularization techniques such as dropout, weight decay or data augmentation\nsometimes help, but do not prevent this behavior. If one considers neural\nnetwork weights as random variables that depend on the data and stochasticity\nof training, the amount of memorized information can be quantified with the\nShannon mutual information between weights and the vector of all training\nlabels given inputs, $I(w ; \\mathbf{y} \\mid \\mathbf{x})$. We show that for any\ntraining algorithm, low values of this term correspond to reduction in\nmemorization of label-noise and better generalization bounds. To obtain these\nlow values, we propose training algorithms that employ an auxiliary network\nthat predicts gradients in the final layers of a classifier without accessing\nlabels. We illustrate the effectiveness of our approach on versions of MNIST,\nCIFAR-10, and CIFAR-100 corrupted with various noise models, and on a\nlarge-scale dataset Clothing1M that has noisy labels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:08:30 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 09:41:41 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Harutyunyan", "Hrayr", ""], ["Reing", "Kyle", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "2002.07942", "submitter": "John Thickstun", "authors": "Vivek Jayaram, John Thickstun", "title": "Source Separation with Deep Generative Priors", "comments": "20 pages; ICML camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite substantial progress in signal source separation, results for richly\nstructured data continue to contain perceptible artifacts. In contrast, recent\ndeep generative models can produce authentic samples in a variety of domains\nthat are indistinguishable from samples of the data distribution. This paper\nintroduces a Bayesian approach to source separation that uses generative models\nas priors over the components of a mixture of sources, and noise-annealed\nLangevin dynamics to sample from the posterior distribution of sources given a\nmixture. This decouples the source separation problem from generative modeling,\nenabling us to directly use cutting-edge generative models as priors. The\nmethod achieves state-of-the-art performance for MNIST digit separation. We\nintroduce new methodology for evaluating separation quality on richer datasets,\nproviding quantitative evaluation of separation results on CIFAR-10. We also\nprovide qualitative results on LSUN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:48:19 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:19:09 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jayaram", "Vivek", ""], ["Thickstun", "John", ""]]}, {"id": "2002.07948", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar", "title": "Personalized Federated Learning: A Meta-Learning Approach", "comments": "To appear in 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Federated Learning, we aim to train models across multiple computing units\n(users), while users can only communicate with a common central server, without\nexchanging their data samples. This mechanism exploits the computational power\nof all users and allows users to obtain a richer model as their models are\ntrained over a larger set of data points. However, this scheme only develops a\ncommon output for all the users, and, therefore, it does not adapt the model to\neach user. This is an important missing feature, especially given the\nheterogeneity of the underlying data distribution for various users. In this\npaper, we study a personalized variant of the federated learning in which our\ngoal is to find an initial shared model that current or new users can easily\nadapt to their local dataset by performing one or a few steps of gradient\ndescent with respect to their own data. This approach keeps all the benefits of\nthe federated learning architecture, and, by structure, leads to a more\npersonalized model for each user. We show this problem can be studied within\nthe Model-Agnostic Meta-Learning (MAML) framework. Inspired by this connection,\nwe study a personalized variant of the well-known Federated Averaging algorithm\nand evaluate its performance in terms of gradient norm for non-convex loss\nfunctions. Further, we characterize how this performance is affected by the\ncloseness of underlying distributions of user data, measured in terms of\ndistribution distances such as Total Variation and 1-Wasserstein metric.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:08:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 04:16:11 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 02:52:01 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 03:04:01 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Fallah", "Alireza", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.07956", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Tristan Deleu, Sharath Chandra Raparthy, Chris J. Pal,\n  Liam Paull", "title": "Curriculum in Gradient-Based Meta-Reinforcement Learning", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learners such as Model-Agnostic Meta-Learning (MAML) have\nshown strong few-shot performance in supervised and reinforcement learning\nsettings. However, specifically in the case of meta-reinforcement learning\n(meta-RL), we can show that gradient-based meta-learners are sensitive to task\ndistributions. With the wrong curriculum, agents suffer the effects of\nmeta-overfitting, shallow adaptation, and adaptation instability. In this work,\nwe begin by highlighting intriguing failure cases of gradient-based meta-RL and\nshow that task distributions can wildly affect algorithmic outputs, stability,\nand performance. To address this problem, we leverage insights from recent\nliterature on domain randomization and propose meta Active Domain Randomization\n(meta-ADR), which learns a curriculum of tasks for gradient-based meta-RL in a\nsimilar as ADR does for sim2real transfer. We show that this approach induces\nmore stable policies on a variety of simulated locomotion and navigation tasks.\nWe assess in- and out-of-distribution generalization and find that the learned\ntask distributions, even in an unstructured task space, greatly improve the\nadaptation performance of MAML. Finally, we motivate the need for better\nbenchmarking in meta-RL that prioritizes \\textit{generalization} over\nsingle-task adaption performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:40:45 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mehta", "Bhairav", ""], ["Deleu", "Tristan", ""], ["Raparthy", "Sharath Chandra", ""], ["Pal", "Chris J.", ""], ["Paull", "Liam", ""]]}, {"id": "2002.07962", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan", "title": "Inductive Representation Learning on Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive representation learning on temporal graphs is an important step\ntoward salable machine learning on real-world dynamic networks. The evolving\nnature of temporal dynamic graphs requires handling new nodes as well as\ncapturing temporal patterns. The node embeddings, which are now functions of\ntime, should represent both the static node features and the evolving\ntopological structures. Moreover, node and topological features can be temporal\nas well, whose patterns the node embeddings should also capture. We propose the\ntemporal graph attention (TGAT) layer to efficiently aggregate\ntemporal-topological neighborhood features as well as to learn the time-feature\ninteractions. For TGAT, we use the self-attention mechanism as building block\nand develop a novel functional time encoding technique based on the classical\nBochner's theorem from harmonic analysis. By stacking TGAT layers, the network\nrecognizes the node embeddings as functions of time and is able to inductively\ninfer embeddings for both new and observed nodes as the graph evolves. The\nproposed approach handles both node classification and link prediction task,\nand can be naturally extended to include the temporal edge features. We\nevaluate our method with transductive and inductive tasks under temporal\nsettings with two benchmark and one industrial dataset. Our TGAT model compares\nfavorably to state-of-the-art baselines as well as the previous temporal graph\nembedding approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:05:37 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "2002.07965", "submitter": "Taejong Joo", "authors": "Taejong Joo, Uijung Chung, Min-Gwan Seo", "title": "Being Bayesian about Categorical Probability", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks utilize the softmax as a building block in classification\ntasks, which contains an overconfidence problem and lacks an uncertainty\nrepresentation ability. As a Bayesian alternative to the softmax, we consider a\nrandom variable of a categorical probability over class labels. In this\nframework, the prior distribution explicitly models the presumed noise inherent\nin the observed label, which provides consistent gains in generalization\nperformance in multiple challenging tasks. The proposed method inherits\nadvantages of Bayesian approaches that achieve better uncertainty estimation\nand model calibration. Our method can be implemented as a plug-and-play loss\nfunction with negligible computational overhead compared to the softmax with\nthe cross-entropy loss function.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:35:32 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 13:00:28 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Joo", "Taejong", ""], ["Chung", "Uijung", ""], ["Seo", "Min-Gwan", ""]]}, {"id": "2002.07971", "submitter": "Sarkhan Badirli", "authors": "Sarkhan Badirli, Xuanqing Liu, Zhengming Xing, Avradeep Bhowmik, Khoa\n  Doan, and Sathiya S. Keerthi", "title": "Gradient Boosting Neural Networks: GrowNet", "comments": "Supplementary material starts after references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel gradient boosting framework is proposed where shallow neural networks\nare employed as ``weak learners''. General loss functions are considered under\nthis unified framework with specific examples presented for classification,\nregression, and learning to rank. A fully corrective step is incorporated to\nremedy the pitfall of greedy function approximation of classic gradient\nboosting decision tree. The proposed model rendered outperforming results\nagainst state-of-the-art boosting methods in all three tasks on multiple\ndatasets. An ablation study is performed to shed light on the effect of each\nmodel components and model hyperparameters.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:02:52 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 22:07:54 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Badirli", "Sarkhan", ""], ["Liu", "Xuanqing", ""], ["Xing", "Zhengming", ""], ["Bhowmik", "Avradeep", ""], ["Doan", "Khoa", ""], ["Keerthi", "Sathiya S.", ""]]}, {"id": "2002.07994", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Best-item Learning in Random Utility Models with Subset Choices", "comments": "Accepted to 23rd International Conference on Artificial Intelligence\n  and Statistics (AISTATS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of PAC learning the most valuable item from a pool of\n$n$ items using sequential, adaptively chosen plays of subsets of $k$ items,\nwhen, upon playing a subset, the learner receives relative feedback sampled\naccording to a general Random Utility Model (RUM) with independent noise\nperturbations to the latent item utilities. We identify a new property of such\na RUM, termed the minimum advantage, that helps in characterizing the\ncomplexity of separating pairs of items based on their relative win/loss\nempirical counts, and can be bounded as a function of the noise distribution\nalone. We give a learning algorithm for general RUMs, based on pairwise\nrelative counts of items and hierarchical elimination, along with a new PAC\nsample complexity guarantee of $O(\\frac{n}{c^2\\epsilon^2} \\log\n\\frac{k}{\\delta})$ rounds to identify an $\\epsilon$-optimal item with\nconfidence $1-\\delta$, when the worst case pairwise advantage in the RUM has\nsensitivity at least $c$ to the parameter gaps of items. Fundamental lower\nbounds on PAC sample complexity show that this is near-optimal in terms of its\ndependence on $n,k$ and $c$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:57:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2002.08000", "submitter": "Guanlin Liu", "authors": "Guanlin Liu and Lifeng lai", "title": "Action-Manipulation Attacks Against Stochastic Bandits: Attacks and\n  Defense", "comments": "13 pages, 7 figures, submitted to IEEE Transaction on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.3021525", "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the broad range of applications of stochastic multi-armed bandit\nmodel, understanding the effects of adversarial attacks and designing bandit\nalgorithms robust to attacks are essential for the safe applications of this\nmodel. In this paper, we introduce a new class of attack named\naction-manipulation attack. In this attack, an adversary can change the action\nsignal selected by the user. We show that without knowledge of mean rewards of\narms, our proposed attack can manipulate Upper Confidence Bound (UCB)\nalgorithm, a widely used bandit algorithm, into pulling a target arm very\nfrequently by spending only logarithmic cost. To defend against this class of\nattacks, we introduce a novel algorithm that is robust to action-manipulation\nattacks when an upper bound for the total attack cost is given. We prove that\nour algorithm has a pseudo-regret upper bounded by $\\mathcal{O}(\\max\\{\\log\nT,A\\})$, where $T$ is the total number of rounds and $A$ is the upper bound of\nthe total attack cost.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 04:09:15 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 22:14:33 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Guanlin", ""], ["lai", "Lifeng", ""]]}, {"id": "2002.08012", "submitter": "Tsubasa Takahashi", "authors": "Tsubasa Takahashi", "title": "Indirect Adversarial Attacks via Poisoning Neighbors for Graph\n  Convolutional Networks", "comments": "Accepted in IEEE BigData 2019", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006004", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks, which learn aggregations over neighbor\nnodes, have achieved great performance in node classification tasks. However,\nrecent studies reported that such graph convolutional node classifier can be\ndeceived by adversarial perturbations on graphs. Abusing graph convolutions, a\nnode's classification result can be influenced by poisoning its neighbors.\nGiven an attributed graph and a node classifier, how can we evaluate robustness\nagainst such indirect adversarial attacks? Can we generate strong adversarial\nperturbations which are effective on not only one-hop neighbors, but more far\nfrom the target? In this paper, we demonstrate that the node classifier can be\ndeceived with high-confidence by poisoning just a single node even two-hops or\nmore far from the target. Towards achieving the attack, we propose a new\napproach which searches smaller perturbations on just a single node far from\nthe target. In our experiments, our proposed method shows 99% attack success\nrate within two-hops from the target in two datasets. We also demonstrate that\nm-layer graph convolutional neural networks have chance to be deceived by our\nindirect attack within m-hop neighbors. The proposed attack can be used as a\nbenchmark in future defense attempts to develop graph convolutional neural\nnetworks with having adversary robustness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 05:44:09 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Takahashi", "Tsubasa", ""]]}, {"id": "2002.08014", "submitter": "Xiang Li", "authors": "Xiang Li, Shusen Wang, Kun Chen, Zhihua Zhang", "title": "Communication-Efficient Distributed SVD via Local Power Iterations", "comments": "9 pages, 7 figures, accepted by 2021 ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed computing of the truncated singular value decomposition\nproblem. We develop an algorithm that we call \\texttt{LocalPower} for improving\ncommunication efficiency. Specifically, we uniformly partition the dataset\namong $m$ nodes and alternate between multiple (precisely $p$) local power\niterations and one global aggregation. In the aggregation, we propose to weight\neach local eigenvector matrix with orthogonal Procrustes transformation (OPT).\nAs a practical surrogate of OPT, sign-fixing, which uses a diagonal matrix with\n$\\pm 1$ entries as weights, has better computation complexity and stability in\nexperiments. We theoretically show that under certain assumptions\n\\texttt{LocalPower} lowers the required number of communications by a factor of\n$p$ to reach a constant accuracy. We also show that the strategy of\nperiodically decaying $p$ helps obtain high-precision solutions. We conduct\nexperiments to demonstrate the effectiveness of \\texttt{LocalPower}.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 05:58:23 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 12:01:29 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 15:17:52 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 08:37:24 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Xiang", ""], ["Wang", "Shusen", ""], ["Chen", "Kun", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2002.08025", "submitter": "Minghong Fang", "authors": "Minghong Fang, Neil Zhenqiang Gong, Jia Liu", "title": "Influence Function based Data Poisoning Attacks to Top-N Recommender\n  Systems", "comments": "Accepted by WWW 2020; This is technical report version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender system is an essential component of web services to engage users.\nPopular recommender systems model user preferences and item properties using a\nlarge amount of crowdsourced user-item interaction data, e.g., rating scores;\nthen top-$N$ items that match the best with a user's preference are recommended\nto the user. In this work, we show that an attacker can launch a data poisoning\nattack to a recommender system to make recommendations as the attacker desires\nvia injecting fake users with carefully crafted user-item interaction data.\nSpecifically, an attacker can trick a recommender system to recommend a target\nitem to as many normal users as possible. We focus on matrix factorization\nbased recommender systems because they have been widely deployed in industry.\nGiven the number of fake users the attacker can inject, we formulate the\ncrafting of rating scores for the fake users as an optimization problem.\nHowever, this optimization problem is challenging to solve as it is a\nnon-convex integer programming problem. To address the challenge, we develop\nseveral techniques to approximately solve the optimization problem. For\ninstance, we leverage influence function to select a subset of normal users who\nare influential to the recommendations and solve our formulated optimization\nproblem based on these influential users. Our results show that our attacks are\neffective and outperform existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:41:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 20:45:44 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 21:24:05 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Fang", "Minghong", ""], ["Gong", "Neil Zhenqiang", ""], ["Liu", "Jia", ""]]}, {"id": "2002.08032", "submitter": "Jianhao Ding", "authors": "Jianhao Ding, Lansheng Han", "title": "A Fixed point view: A Model-Based Clustering Framework", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the inflation of the data, clustering analysis, as a branch of\nunsupervised learning, lacks unified understanding and application of its\nmathematical law. Based on the view of fixed point, this paper restates the\nmodel-based clustering and proposes a unified clustering framework. In order to\nfind fixed points as cluster centers, the framework iteratively constructs the\ncontraction map, which strongly reveals the convergence mechanism and\ninterconnections among algorithms. By specifying a contraction map, Gaussian\nmixture model (GMM) can be mapped to the framework as an application. We hope\nthe fixed point framework will help the design of future clustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:06:47 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Ding", "Jianhao", ""], ["Han", "Lansheng", ""]]}, {"id": "2002.08037", "submitter": "Tianpei Yang", "authors": "Tianpei Yang, Jianye Hao, Zhaopeng Meng, Zongzhang Zhang, Yujing Hu,\n  Yingfeng Cheng, Changjie Fan, Weixun Wang, Wulong Liu, Zhaodong Wang, and\n  Jiajie Peng", "title": "Efficient Deep Reinforcement Learning via Adaptive Policy Transfer", "comments": "Accepted by IJCAI'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) has shown great potential to accelerate Reinforcement\nLearning (RL) by leveraging prior knowledge from past learned policies of\nrelevant tasks. Existing transfer approaches either explicitly computes the\nsimilarity between tasks or select appropriate source policies to provide\nguided explorations for the target task. However, how to directly optimize the\ntarget policy by alternatively utilizing knowledge from appropriate source\npolicies without explicitly measuring the similarity is currently missing. In\nthis paper, we propose a novel Policy Transfer Framework (PTF) to accelerate RL\nby taking advantage of this idea. Our framework learns when and which source\npolicy is the best to reuse for the target policy and when to terminate it by\nmodeling multi-policy transfer as the option learning problem. PTF can be\neasily combined with existing deep RL approaches. Experimental results show it\nsignificantly accelerates the learning process and surpasses state-of-the-art\npolicy transfer methods in terms of learning efficiency and final performance\nin both discrete and continuous action spaces.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:30:57 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 08:41:30 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 10:21:28 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Yang", "Tianpei", ""], ["Hao", "Jianye", ""], ["Meng", "Zhaopeng", ""], ["Zhang", "Zongzhang", ""], ["Hu", "Yujing", ""], ["Cheng", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Wang", "Weixun", ""], ["Liu", "Wulong", ""], ["Wang", "Zhaodong", ""], ["Peng", "Jiajie", ""]]}, {"id": "2002.08041", "submitter": "Hai Tran", "authors": "Hai H. Tran, Sumyeong Ahn, Taeyoung Lee, Yung Yi", "title": "Enlarging Discriminative Power by Adding an Extra Class in Unsupervised\n  Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of unsupervised domain adaptation that\naims at obtaining a prediction model for the target domain using labeled data\nfrom the source domain and unlabeled data from the target domain. There exists\nan array of recent research based on the idea of extracting features that are\nnot only invariant for both domains but also provide high discriminative power\nfor the target domain. In this paper, we propose an idea of empowering the\ndiscriminativeness: Adding a new, artificial class and training the model on\nthe data together with the GAN-generated samples of the new class. The trained\nmodel based on the new class samples is capable of extracting the features that\nare more discriminative by repositioning data of current classes in the target\ndomain and therefore drawing the decision boundaries more effectively. Our idea\nis highly generic so that it is compatible with many existing methods such as\nDANN, VADA, and DIRT-T. We conduct various experiments for the standard data\ncommonly used for the evaluation of unsupervised domain adaptations and\ndemonstrate that our algorithm achieves the SOTA performance for many\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:58:24 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Tran", "Hai H.", ""], ["Ahn", "Sumyeong", ""], ["Lee", "Taeyoung", ""], ["Yi", "Yung", ""]]}, {"id": "2002.08053", "submitter": "Jiaqi Lv", "authors": "Jiaqi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, Masashi Sugiyama", "title": "Progressive Identification of True Labels for Partial-Label Learning", "comments": "In Proceedings of the 37th International Conference on Machine\n  Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial-label learning (PLL) is a typical weakly supervised learning problem,\nwhere each training instance is equipped with a set of candidate labels among\nwhich only one is the true label. Most existing methods elaborately designed\nlearning objectives as constrained optimizations that must be solved in\nspecific manners, making their computational complexity a bottleneck for\nscaling up to big data. The goal of this paper is to propose a novel framework\nof PLL with flexibility on the model and optimization algorithm. More\nspecifically, we propose a novel estimator of the classification risk,\ntheoretically analyze the classifier-consistency, and establish an estimation\nerror bound. Then we propose a progressive identification algorithm for\napproximately minimizing the proposed risk estimator, where the update of the\nmodel and identification of true labels are conducted in a seamless manner. The\nresulting algorithm is model-independent and loss-independent, and compatible\nwith stochastic optimization. Thorough experiments demonstrate it sets the new\nstate of the art.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 08:35:15 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 14:20:19 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 13:57:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Lv", "Jiaqi", ""], ["Xu", "Miao", ""], ["Feng", "Lei", ""], ["Niu", "Gang", ""], ["Geng", "Xin", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.08056", "submitter": "Lukas Balles", "authors": "Lukas Balles and Fabian Pedregosa and Nicolas Le Roux", "title": "The Geometry of Sign Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign-based optimization methods have become popular in machine learning due\nto their favorable communication cost in distributed optimization and their\nsurprisingly good performance in neural network training. Furthermore, they are\nclosely connected to so-called adaptive gradient methods like Adam. Recent\nworks on signSGD have used a non-standard \"separable smoothness\" assumption,\nwhereas some older works study sign gradient descent as steepest descent with\nrespect to the $\\ell_\\infty$-norm. In this work, we unify these existing\nresults by showing a close connection between separable smoothness and\n$\\ell_\\infty$-smoothness and argue that the latter is the weaker and more\nnatural assumption. We then proceed to study the smoothness constant with\nrespect to the $\\ell_\\infty$-norm and thereby isolate geometric properties of\nthe objective function which affect the performance of sign-based methods. In\nshort, we find sign-based methods to be preferable over gradient descent if (i)\nthe Hessian is to some degree concentrated on its diagonal, and (ii) its\nmaximal eigenvalue is much larger than the average eigenvalue. Both properties\nare common in deep networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 08:45:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Balles", "Lukas", ""], ["Pedregosa", "Fabian", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "2002.08071", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita,\n  Hajime Asama", "title": "Dissecting Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous deep learning architectures have recently re-emerged as Neural\nOrdinary Differential Equations (Neural ODEs). This infinite-depth approach\ntheoretically bridges the gap between deep learning and dynamical systems,\noffering a novel perspective. However, deciphering the inner working of these\nmodels is still an open challenge, as most applications apply them as generic\nblack-box modules. In this work we \"open the box\", further developing the\ncontinuous-depth formulation with the aim of clarifying the influence of\nseveral design choices on the underlying dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:14:46 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 04:22:32 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 06:46:43 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 14:40:32 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "2002.08095", "submitter": "Asaf Cassel", "authors": "Asaf Cassel (1), Alon Cohen (2), Tomer Koren (1) ((1) School of\n  Computer Science, Tel Aviv University, (2) Google Research, Tel Aviv)", "title": "Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently", "comments": "Accepted for presentation at International Conference on Machine\n  Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning in Linear Quadratic Control systems whose\ntransition parameters are initially unknown. Recent results in this setting\nhave demonstrated efficient learning algorithms with regret growing with the\nsquare root of the number of decision steps. We present new efficient\nalgorithms that achieve, perhaps surprisingly, regret that scales only\n(poly)logarithmically with the number of steps in two scenarios: when only the\nstate transition matrix $A$ is unknown, and when only the state-action\ntransition matrix $B$ is unknown and the optimal policy satisfies a certain\nnon-degeneracy condition. On the other hand, we give a lower bound that shows\nthat when the latter condition is violated, square root regret is unavoidable.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 10:09:26 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:37:42 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Cassel", "Asaf", ""], ["Cohen", "Alon", ""], ["Koren", "Tomer", ""]]}, {"id": "2002.08104", "submitter": "Aleksandra Nowak", "authors": "Romuald A. Janik and Aleksandra Nowak", "title": "Analyzing Neural Networks Based on Random Graphs", "comments": "Added new results and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a massive evaluation of neural networks with architectures\ncorresponding to random graphs of various types. We investigate various\nstructural and numerical properties of the graphs in relation to neural network\ntest accuracy. We find that none of the classical numerical graph invariants by\nitself allows to single out the best networks. Consequently, we introduce a new\nnumerical graph characteristic that selects a set of quasi-1-dimensional\ngraphs, which are a majority among the best performing networks. We also find\nthat networks with primarily short-range connections perform better than\nnetworks which allow for many long-range connections. Moreover, many resolution\nreducing pathways are beneficial. We provide a dataset of 1020 graphs and the\ntest accuracies of their corresponding neural networks at\nhttps://github.com/rmldj/random-graph-nn-paper\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:04:49 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 17:13:59 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 11:29:36 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Janik", "Romuald A.", ""], ["Nowak", "Aleksandra", ""]]}, {"id": "2002.08111", "submitter": "Sam Ringer", "authors": "Will Williams, Sam Ringer, Tom Ash, John Hughes, David MacLeod, Jamie\n  Dougherty", "title": "Hierarchical Quantized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite progress in training neural networks for lossy image compression,\ncurrent approaches fail to maintain both perceptual quality and abstract\nfeatures at very low bitrates. Encouraged by recent success in learning\ndiscrete representations with Vector Quantized Variational Autoencoders\n(VQ-VAEs), we motivate the use of a hierarchy of VQ-VAEs to attain high factors\nof compression. We show that the combination of stochastic quantization and\nhierarchical latent structure aids likelihood-based image compression. This\nleads us to introduce a novel objective for training hierarchical VQ-VAEs. Our\nresulting scheme produces a Markovian series of latent variables that\nreconstruct images of high-perceptual quality which retain semantically\nmeaningful features. We provide qualitative and quantitative evaluations on the\nCelebA and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:26:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 15:39:36 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 11:10:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Williams", "Will", ""], ["Ringer", "Sam", ""], ["Ash", "Tom", ""], ["Hughes", "John", ""], ["MacLeod", "David", ""], ["Dougherty", "Jamie", ""]]}, {"id": "2002.08118", "submitter": "Tony Duan", "authors": "Greg Yang, Tony Duan, J. Edward Hu, Hadi Salman, Ilya Razenshteyn,\n  Jerry Li", "title": "Randomized Smoothing of All Shapes and Sizes", "comments": "9 pages main text, 49 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing is the current state-of-the-art defense with provable\nrobustness against $\\ell_2$ adversarial attacks. Many works have devised new\nrandomized smoothing schemes for other metrics, such as $\\ell_1$ or\n$\\ell_\\infty$; however, substantial effort was needed to derive such new\nguarantees. This begs the question: can we find a general theory for randomized\nsmoothing?\n  We propose a novel framework for devising and analyzing randomized smoothing\nschemes, and validate its effectiveness in practice. Our theoretical\ncontributions are: (1) we show that for an appropriate notion of \"optimal\", the\noptimal smoothing distributions for any \"nice\" norms have level sets given by\nthe norm's *Wulff Crystal*; (2) we propose two novel and complementary methods\nfor deriving provably robust radii for any smoothing distribution; and, (3) we\nshow fundamental limits to current randomized smoothing techniques via the\ntheory of *Banach space cotypes*. By combining (1) and (2), we significantly\nimprove the state-of-the-art certified accuracy in $\\ell_1$ on standard\ndatasets. Meanwhile, we show using (3) that with only label statistics under\nrandom input perturbations, randomized smoothing cannot achieve nontrivial\ncertified accuracy against perturbations of $\\ell_p$-norm $\\Omega(\\min(1,\nd^{\\frac{1}{p} - \\frac{1}{2}}))$, when the input dimension $d$ is large. We\nprovide code in github.com/tonyduan/rs4a.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:41:09 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:33:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 06:59:55 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 05:27:53 GMT"}, {"version": "v5", "created": "Thu, 23 Jul 2020 21:20:51 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Yang", "Greg", ""], ["Duan", "Tony", ""], ["Hu", "J. Edward", ""], ["Salman", "Hadi", ""], ["Razenshteyn", "Ilya", ""], ["Li", "Jerry", ""]]}, {"id": "2002.08125", "submitter": "Andreas Krug", "authors": "Andreas Krug, Sebastian Stober", "title": "Gradient-Adjusted Neuron Activation Profiles for Comprehensive\n  Introspection of Convolutional Speech Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning based Automatic Speech Recognition (ASR) models are very\nsuccessful, but hard to interpret. To gain better understanding of how\nArtificial Neural Networks (ANNs) accomplish their tasks, introspection methods\nhave been proposed. Adapting such techniques from computer vision to speech\nrecognition is not straight-forward, because speech data is more complex and\nless interpretable than image data. In this work, we introduce\nGradient-adjusted Neuron Activation Profiles (GradNAPs) as means to interpret\nfeatures and representations in Deep Neural Networks. GradNAPs are\ncharacteristic responses of ANNs to particular groups of inputs, which\nincorporate the relevance of neurons for prediction. We show how to utilize\nGradNAPs to gain insight about how data is processed in ANNs. This includes\ndifferent ways of visualizing features and clustering of GradNAPs to compare\nembeddings of different groups of inputs in any layer of a given network. We\ndemonstrate our proposed techniques using a fully-convolutional ASR model.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:59:36 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Krug", "Andreas", ""], ["Stober", "Sebastian", ""]]}, {"id": "2002.08129", "submitter": "Steven Kleinegesse", "authors": "Steven Kleinegesse and Michael U. Gutmann", "title": "Bayesian Experimental Design for Implicit Models by Mutual Information\n  Neural Estimation", "comments": "Accepted at the thirty-seventh International Conference on Machine\n  Learning (ICML) 2020. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit stochastic models, where the data-generation distribution is\nintractable but sampling is possible, are ubiquitous in the natural sciences.\nThe models typically have free parameters that need to be inferred from data\ncollected in scientific experiments. A fundamental question is how to design\nthe experiments so that the collected data are most useful. The field of\nBayesian experimental design advocates that, ideally, we should choose designs\nthat maximise the mutual information (MI) between the data and the parameters.\nFor implicit models, however, this approach is severely hampered by the high\ncomputational cost of computing posteriors and maximising MI, in particular\nwhen we have more than a handful of design variables to optimise. In this\npaper, we propose a new approach to Bayesian experimental design for implicit\nmodels that leverages recent advances in neural MI estimation to deal with\nthese issues. We show that training a neural network to maximise a lower bound\non MI allows us to jointly determine the optimal design and the posterior.\nSimulation studies illustrate that this gracefully extends Bayesian\nexperimental design for implicit models to higher design dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:09:42 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 17:28:45 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 15:04:46 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kleinegesse", "Steven", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "2002.08158", "submitter": "Yibo Yang", "authors": "Yibo Yang, Robert Bamler and Stephan Mandt", "title": "Variational Bayesian Quantization", "comments": "9 pages + detailed supplement with additional full resolution\n  reconstructed images; ICML 2020 final camera-ready version, title changed to\n  \"Variational Bayesian Quantization\" following reviewer feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for quantizing continuous latent representations\nin trained models. Our approach applies to deep probabilistic models, such as\nvariational autoencoders (VAEs), and enables both data and model compression.\nUnlike current end-to-end neural compression methods that cater the model to a\nfixed quantization scheme, our algorithm separates model design and training\nfrom quantization. Consequently, our algorithm enables \"plug-and-play\"\ncompression with variable rate-distortion trade-off, using a single trained\nmodel. Our algorithm can be seen as a novel extension of arithmetic coding to\nthe continuous domain, and uses adaptive quantization accuracy based on\nestimates of posterior uncertainty. Our experimental results demonstrate the\nimportance of taking into account posterior uncertainties, and show that image\ncompression with the proposed algorithm outperforms JPEG over a wide range of\nbit rates using only a single standard VAE. Further experiments on Bayesian\nneural word embeddings demonstrate the versatility of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:15:37 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 22:25:12 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Yang", "Yibo", ""], ["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "2002.08159", "submitter": "Robin Vogel", "authors": "Robin Vogel, Aur\\'elien Bellet, and Stephan Cl\\'emen\\c{c}on", "title": "Learning Fair Scoring Functions: Bipartite Ranking under ROC-based\n  Fairness Constraints", "comments": "35 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of AI involve scoring individuals using a learned function\nof their attributes. These predictive risk scores are then used to take\ndecisions based on whether the score exceeds a certain threshold, which may\nvary depending on the context. The level of delegation granted to such systems\nin critical applications like credit lending and medical diagnosis will heavily\ndepend on how questions of fairness can be answered. In this paper, we study\nfairness for the problem of learning scoring functions from binary labeled\ndata, a classic learning task known as bipartite ranking. We argue that the\nfunctional nature of the ROC curve, the gold standard measure of ranking\naccuracy in this context, leads to several ways of formulating fairness\nconstraints. We introduce general families of fairness definitions based on the\nAUC and on ROC curves, and show that our ROC-based constraints can be\ninstantiated such that classifiers obtained by thresholding the scoring\nfunction satisfy classification fairness for a desired range of thresholds. We\nestablish generalization bounds for scoring functions learned under such\nconstraints, design practical learning algorithms and show the relevance our\napproach with numerical experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:17:39 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 13:25:54 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 14:50:12 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 18:54:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Vogel", "Robin", ""], ["Bellet", "Aur\u00e9lien", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "2002.08165", "submitter": "Arslan Chaudhry", "authors": "Arslan Chaudhry, Albert Gordo, Puneet K. Dokania, Philip Torr, David\n  Lopez-Paz", "title": "Using Hindsight to Anchor Past Knowledge in Continual Learning", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In continual learning, the learner faces a stream of data whose distribution\nchanges over time. Modern neural networks are known to suffer under this\nsetting, as they quickly forget previously acquired knowledge. To address such\ncatastrophic forgetting, many continual learning methods implement different\ntypes of experience replay, re-learning on past data stored in a small buffer\nknown as episodic memory. In this work, we complement experience replay with a\nnew objective that we call anchoring, where the learner uses bilevel\noptimization to update its knowledge on the current task, while keeping intact\nthe predictions on some anchor points of past tasks. These anchor points are\nlearned using gradient-based optimization to maximize forgetting, which is\napproximated by fine-tuning the currently trained model on the episodic memory\nof past tasks. Experiments on several supervised learning benchmarks for\ncontinual learning demonstrate that our approach improves the standard\nexperience replay in terms of both accuracy and forgetting metrics and for\nvarious sizes of episodic memories.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:21:19 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 08:05:50 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Chaudhry", "Arslan", ""], ["Gordo", "Albert", ""], ["Dokania", "Puneet K.", ""], ["Torr", "Philip", ""], ["Lopez-Paz", "David", ""]]}, {"id": "2002.08196", "submitter": "Tengchan Zeng", "authors": "Tengchan Zeng, Omid Semiari, Mohammad Mozaffari, Mingzhe Chen, Walid\n  Saad, and Mehdi Bennis", "title": "Federated Learning in the Sky: Joint Power Allocation and Scheduling\n  with UAV Swarms", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.RO eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicle (UAV) swarms must exploit machine learning (ML) in\norder to execute various tasks ranging from coordinated trajectory planning to\ncooperative target recognition. However, due to the lack of continuous\nconnections between the UAV swarm and ground base stations (BSs), using\ncentralized ML will be challenging, particularly when dealing with a large\nvolume of data. In this paper, a novel framework is proposed to implement\ndistributed federated learning (FL) algorithms within a UAV swarm that consists\nof a leading UAV and several following UAVs. Each following UAV trains a local\nFL model based on its collected data and then sends this trained local model to\nthe leading UAV who will aggregate the received models, generate a global FL\nmodel, and transmit it to followers over the intra-swarm network. To identify\nhow wireless factors, like fading, transmission delay, and UAV antenna angle\ndeviations resulting from wind and mechanical vibrations, impact the\nperformance of FL, a rigorous convergence analysis for FL is performed. Then, a\njoint power allocation and scheduling design is proposed to optimize the\nconvergence rate of FL while taking into account the energy consumption during\nconvergence and the delay requirement imposed by the swarm's control system.\nSimulation results validate the effectiveness of the FL convergence analysis\nand show that the joint design strategy can reduce the number of communication\nrounds needed for convergence by as much as 35% compared with the baseline\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:04:01 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 16:19:18 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zeng", "Tengchan", ""], ["Semiari", "Omid", ""], ["Mozaffari", "Mohammad", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2002.08243", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Lior Shani, Aviv Rosenberg and Shie Mannor", "title": "Optimistic Policy Optimization with Bandit Feedback", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization methods are one of the most widely used classes of\nReinforcement Learning (RL) algorithms. Yet, so far, such methods have been\nmostly analyzed from an optimization perspective, without addressing the\nproblem of exploration, or by making strong assumptions on the interaction with\nthe environment. In this paper we consider model-based RL in the tabular\nfinite-horizon MDP setting with unknown transitions and bandit feedback. For\nthis setting, we propose an optimistic trust region policy optimization (TRPO)\nalgorithm for which we establish $\\tilde O(\\sqrt{S^2 A H^4 K})$ regret for\nstochastic rewards. Furthermore, we prove $\\tilde O( \\sqrt{ S^2 A H^4 } K^{2/3}\n) $ regret for adversarial rewards. Interestingly, this result matches previous\nbounds derived for the bandit feedback case, yet with known transitions. To the\nbest of our knowledge, the two results are the first sub-linear regret bounds\nobtained for policy optimization algorithms with unknown transitions and bandit\nfeedback.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:41:18 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 17:13:53 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Efroni", "Yonathan", ""], ["Shani", "Lior", ""], ["Rosenberg", "Aviv", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.08246", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, Marten\n  van Dijk", "title": "A Unified Convergence Analysis for Shuffling-Type Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a unified convergence analysis for a class of\nshuffling-type gradient methods for solving a well-known finite-sum\nminimization problem commonly used in machine learning. This algorithm covers\nvarious variants such as randomized reshuffling, single shuffling, and\ncyclic/incremental gradient schemes. We consider two different settings:\nstrongly convex and non-convex problems. Our main contribution consists of new\nnon-asymptotic and asymptotic convergence rates for a general class of\nshuffling-type gradient methods to solve both non-convex and strongly convex\nproblems. While our rate in the non-convex problem is new (i.e. not known yet\nunder standard assumptions), the rate on the strongly convex case matches (up\nto a constant) the best-known results. However, unlike existing works in this\ndirection, we only use standard assumptions such as smoothness and strong\nconvexity. Finally, we empirically illustrate the effect of learning rates via\na non-convex logistic regression and neural network examples.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:45:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""], ["Phan", "Dzung T.", ""], ["Nguyen", "Phuong Ha", ""], ["van Dijk", "Marten", ""]]}, {"id": "2002.08247", "submitter": "Amit Dhurandhar", "authors": "Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam and\n  Amit Dhurandhar", "title": "Learning Global Transparent Models Consistent with Local Contrastive\n  Explanations", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a rich and growing literature on producing local\ncontrastive/counterfactual explanations for black-box models (e.g. neural\nnetworks).\n  In these methods, for an input, an explanation is in the form of a contrast\npoint differing in very few features from the original input and lying in a\ndifferent class. Other works try to build globally interpretable models like\ndecision trees and rule lists based on the data using actual labels or based on\nthe black-box models predictions. Although these interpretable global models\ncan be useful, they may not be consistent with local explanations from a\nspecific black-box of choice. In this work, we explore the question: Can we\nproduce a transparent global model that is simultaneously accurate and\nconsistent with the local (contrastive) explanations of the black-box model? We\nintroduce a natural local consistency metric that quantifies if the local\nexplanations and predictions of the black-box model are also consistent with\nthe proxy global transparent model. Based on a key insight we propose a novel\nmethod where we create custom boolean features from sparse local contrastive\nexplanations of the black-box model and then train a globally transparent model\non just these, and showcase empirically that such models have higher local\nconsistency compared with other known strategies, while still being close in\nperformance to models that are trained with access to the original data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:45:42 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 23:37:44 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 13:01:15 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 00:34:34 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Pedapati", "Tejaswini", ""], ["Balakrishnan", "Avinash", ""], ["Shanmugam", "Karthikeyan", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2002.08253", "submitter": "Henry Gouk", "authors": "Henry Gouk, Timothy M. Hospedales, Massimiliano Pontil", "title": "Distance-Based Regularisation of Deep Networks for Fine-Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate approaches to regularisation during fine-tuning of deep neural\nnetworks. First we provide a neural network generalisation bound based on\nRademacher complexity that uses the distance the weights have moved from their\ninitial values. This bound has no direct dependence on the number of weights\nand compares favourably to other bounds when applied to convolutional networks.\nOur bound is highly relevant for fine-tuning, because providing a network with\na good initialisation based on transfer learning means that learning can modify\nthe weights less, and hence achieve tighter generalisation. Inspired by this,\nwe develop a simple yet effective fine-tuning algorithm that constrains the\nhypothesis class to a small sphere centred on the initial pre-trained weights,\nthus obtaining provably better generalisation performance than conventional\ntransfer learning. Empirical evaluation shows that our algorithm works well,\ncorroborating our theoretical results. It outperforms both state of the art\nfine-tuning competitors, and penalty-based alternatives that we show do not\ndirectly constrain the radius of the search space.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:00:47 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 21:48:17 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 16:05:16 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Gouk", "Henry", ""], ["Hospedales", "Timothy M.", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "2002.08258", "submitter": "Yonathan Aflalo Dr", "authors": "Yonathan Aflalo and Asaf Noy and Ming Lin and Itamar Friedman and Lihi\n  Zelnik", "title": "Knapsack Pruning with Inner Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning reduces the computational cost of an\nover-parameterized network to improve its efficiency. Popular methods vary from\n$\\ell_1$-norm sparsification to Neural Architecture Search (NAS). In this work,\nwe propose a novel pruning method that optimizes the final accuracy of the\npruned network and distills knowledge from the over-parameterized parent\nnetwork's inner layers. To enable this approach, we formulate the network\npruning as a Knapsack Problem which optimizes the trade-off between the\nimportance of neurons and their associated computational cost. Then we prune\nthe network channels while maintaining the high-level structure of the network.\nThe pruned network is fine-tuned under the supervision of the parent network\nusing its inner network knowledge, a technique we refer to as the Inner\nKnowledge Distillation. Our method leads to state-of-the-art pruning results on\nImageNet, CIFAR-10 and CIFAR-100 using ResNet backbones. To prune complex\nnetwork structures such as convolutions with skip-links and depth-wise\nconvolutions, we propose a block grouping approach to cope with these\nstructures. Through this we produce compact architectures with the same FLOPs\nas EfficientNet-B0 and MobileNetV3 but with higher accuracy, by $1\\%$ and\n$0.3\\%$ respectively on ImageNet, and faster runtime on GPU.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:04:48 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 05:36:06 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 10:09:33 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Aflalo", "Yonathan", ""], ["Noy", "Asaf", ""], ["Lin", "Ming", ""], ["Friedman", "Itamar", ""], ["Zelnik", "Lihi", ""]]}, {"id": "2002.08260", "submitter": "Werner Zellinger", "authors": "Werner Zellinger, Bernhard A Moser and Susanne Saminger-Platz", "title": "On generalization in moment-based domain adaptation", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence 89, 333--369\n  (2021)", "doi": "10.1007/s10472-020-09719-x", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation algorithms are designed to minimize the misclassification\nrisk of a discriminative model for a target domain with little training data by\nadapting a model from a source domain with a large amount of training data.\nStandard approaches measure the adaptation discrepancy based on distance\nmeasures between the empirical probability distributions in the source and\ntarget domain. In this setting, we address the problem of deriving\ngeneralization bounds under practice-oriented general conditions on the\nunderlying probability distributions. As a result, we obtain generalization\nbounds for domain adaptation based on finitely many moments and smoothness\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:05:27 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 12:50:45 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 10:31:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zellinger", "Werner", ""], ["Moser", "Bernhard A", ""], ["Saminger-Platz", "Susanne", ""]]}, {"id": "2002.08264", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Tomasz Danel, S{\\l}awomir Mucha, Krzysztof Rataj,\n  Jacek Tabor, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Molecule Attention Transformer", "comments": null, "journal-ref": "Graph Representation Learning workshop and Machine Learning and\n  the Physical Sciences workshop at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a single neural network architecture that performs competitively\nacross a range of molecule property prediction tasks remains largely an open\nchallenge, and its solution may unlock a widespread use of deep learning in the\ndrug discovery industry. To move towards this goal, we propose Molecule\nAttention Transformer (MAT). Our key innovation is to augment the attention\nmechanism in Transformer using inter-atomic distances and the molecular graph\nstructure. Experiments show that MAT performs competitively on a diverse set of\nmolecular prediction tasks. Most importantly, with a simple self-supervised\npretraining, MAT requires tuning of only a few hyperparameter values to achieve\nstate-of-the-art performance on downstream tasks. Finally, we show that\nattention weights learned by MAT are interpretable from the chemical point of\nview.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:14:48 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["Danel", "Tomasz", ""], ["Mucha", "S\u0142awomir", ""], ["Rataj", "Krzysztof", ""], ["Tabor", "Jacek", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "2002.08274", "submitter": "Junteng Jia", "authors": "Junteng Jia and Austin R. Benson", "title": "Residual Correlation in Graph Neural Network Regression", "comments": null, "journal-ref": "KDD 2020", "doi": "10.1145/3394486.3403101", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph neural network transforms features in each vertex's neighborhood into\na vector representation of the vertex. Afterward, each vertex's representation\nis used independently for predicting its label. This standard pipeline\nimplicitly assumes that vertex labels are conditionally independent given their\nneighborhood features. However, this is a strong assumption, and we show that\nit is far from true on many real-world graph datasets. Focusing on regression\ntasks, we find that this conditional independence assumption severely limits\npredictive power. This should not be that surprising, given that traditional\ngraph-based semi-supervised learning methods such as label propagation work in\nthe opposite fashion by explicitly modeling the correlation in predicted\noutcomes.\n  Here, we address this problem with an interpretable and efficient framework\nthat can improve any graph neural network architecture simply by exploiting\ncorrelation structure in the regression residuals. In particular, we model the\njoint distribution of residuals on vertices with a parameterized multivariate\nGaussian, and estimate the parameters by maximizing the marginal likelihood of\nthe observed labels. Our framework achieves substantially higher accuracy than\ncompeting baselines, and the learned parameters can be interpreted as the\nstrength of correlation among connected vertices. Furthermore, we develop\nlinear time algorithms for low-variance, unbiased model parameter estimates,\nallowing us to scale to large networks. We also provide a basic version of our\nmethod that makes stronger assumptions on correlation structure but is painless\nto implement, often leading to great practical performance with minimal\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:32:54 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 22:18:57 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jia", "Junteng", ""], ["Benson", "Austin R.", ""]]}, {"id": "2002.08276", "submitter": "Mokhtar Z. Alaya", "authors": "Laetitia Chapel, Mokhtar Z. Alaya, Gilles Gasso", "title": "Partial Optimal Transport with Applications on Positive-Unlabeled\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical optimal transport problem seeks a transportation map that preserves\nthe total mass betwenn two probability distributions, requiring their mass to\nbe the same. This may be too restrictive in certain applications such as color\nor shape matching, since the distributions may have arbitrary masses and/or\nthat only a fraction of the total mass has to be transported. Several\nalgorithms have been devised for computing partial Wasserstein metrics that\nrely on an entropic regularization, but when it comes with exact solutions,\nalmost no partial formulation of neither Wasserstein nor Gromov-Wasserstein are\navailable yet. This precludes from working with distributions that do not lie\nin the same metric space or when invariance to rotation or translation is\nneeded. In this paper, we address the partial Wasserstein and\nGromov-Wasserstein problems and propose exact algorithms to solve them. We\nshowcase the new formulation in a positive-unlabeled (PU) learning application.\nTo the best of our knowledge, this is the first application of optimal\ntransport in this context and we first highlight that partial Wasserstein-based\nmetrics prove effective in usual PU learning settings. We then demonstrate that\npartial Gromov-Wasserstein metrics is efficient in scenario where point clouds\ncome from different domains or have different features.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:36:35 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:48:54 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Chapel", "Laetitia", ""], ["Alaya", "Mokhtar Z.", ""], ["Gasso", "Gilles", ""]]}, {"id": "2002.08289", "submitter": "Chitresh Bhushan", "authors": "Chitresh Bhushan, Zhaoyuan Yang, Nurali Virani, Naresh Iyer", "title": "Variational Encoder-based Reliable Classification", "comments": "Published in ICIP 2020. Typos fixed in revision", "journal-ref": "IEEE International Conference on Image Processing (2020) 1941-1945", "doi": "10.1109/ICIP40778.2020.9190836", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models provide statistically impressive results which might\nbe individually unreliable. To provide reliability, we propose an Epistemic\nClassifier (EC) that can provide justification of its belief using support from\nthe training dataset as well as quality of reconstruction. Our approach is\nbased on modified variational auto-encoders that can identify a semantically\nmeaningful low-dimensional space where perceptually similar instances are close\nin $\\ell_2$-distance too. Our results demonstrate improved reliability of\npredictions and robust identification of samples with adversarial attacks as\ncompared to baseline of softmax-based thresholding.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:05:32 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 13:51:37 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bhushan", "Chitresh", ""], ["Yang", "Zhaoyuan", ""], ["Virani", "Nurali", ""], ["Iyer", "Naresh", ""]]}, {"id": "2002.08295", "submitter": "Abdul Dakkak", "authors": "Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu", "title": "MLModelScope: A Distributed Platform for Model Evaluation and\n  Benchmarking at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) innovations are being introduced\nat such a rapid pace that researchers are hard-pressed to analyze and study\nthem. The complicated procedures for evaluating innovations, along with the\nlack of standard and efficient ways of specifying and provisioning ML/DL\nevaluation, is a major \"pain point\" for the community. This paper proposes\nMLModelScope, an open-source, framework/hardware agnostic, extensible and\ncustomizable design that enables repeatable, fair, and scalable model\nevaluation and benchmarking. We implement the distributed design with support\nfor all major frameworks and hardware, and equip it with web, command-line, and\nlibrary interfaces. To demonstrate MLModelScope's capabilities we perform\nparallel evaluation and show how subtle changes to model evaluation pipeline\naffects the accuracy and HW/SW stack choices affect performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:13:01 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Dakkak", "Abdul", ""], ["Li", "Cheng", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "2002.08301", "submitter": "Wen-Kai Yu", "authors": "Shuo-Fei Wang, Wen-Kai Yu, and Ya-Xin Li", "title": "Multi-wavelet residual dense convolutional neural network for image\n  denoising", "comments": "9 pages, 9 figures", "journal-ref": "IEEE Access (2020)", "doi": "10.1109/ACCESS.2020.3040542", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks with large receptive field (RF) have shown advanced fitting ability\nin recent years. In this work, we utilize the short-term residual learning\nmethod to improve the performance and robustness of networks for image\ndenoising tasks. Here, we choose a multi-wavelet convolutional neural network\n(MWCNN), one of the state-of-art networks with large RF, as the backbone, and\ninsert residual dense blocks (RDBs) in its each layer. We call this scheme\nmulti-wavelet residual dense convolutional neural network (MWRDCNN). Compared\nwith other RDB-based networks, it can extract more features of the object from\nadjacent layers, preserve the large RF, and boost the computing efficiency.\nMeanwhile, this approach also provides a possibility of absorbing advantages of\nmultiple architectures in a single network without conflicts. The performance\nof the proposed method has been demonstrated in extensive experiments with a\ncomparison with existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:21:37 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wang", "Shuo-Fei", ""], ["Yu", "Wen-Kai", ""], ["Li", "Ya-Xin", ""]]}, {"id": "2002.08314", "submitter": "Mokhtar Z. Alaya", "authors": "Mokhtar Z. Alaya, Maxime B\\'erar, Gilles Gasso, Alain Rakotomamonjy", "title": "Theoretical Guarantees for Bridging Metric Measure Embedding and Optimal\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for comparing distributions whose supports do not\nnecessarily lie on the same metric space. Unlike Gromov-Wasserstein (GW)\ndistance which compares pairwise distances of elements from each distribution,\nwe consider a method allowing to embed the metric measure spaces in a common\nEuclidean space and compute an optimal transport (OT) on the embedded\ndistributions. This leads to what we call a sub-embedding robust Wasserstein\n(SERW) distance. Under some conditions, SERW is a distance that considers an OT\ndistance of the (low-distorted) embedded distributions using a common metric.\nIn addition to this novel proposal that generalizes several recent OT works,\nour contributions stand on several theoretical analyses: (i) we characterize\nthe embedding spaces to define SERW distance for distribution alignment; (ii)\nwe prove that SERW mimics almost the same properties of GW distance, and we\ngive a cost relation between GW and SERW. The paper also provides some\nnumerical illustrations of how SERW behaves on matching problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:52:01 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 11:10:38 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 09:57:49 GMT"}, {"version": "v4", "created": "Fri, 25 Dec 2020 15:49:10 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 17:43:40 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Alaya", "Mokhtar Z.", ""], ["B\u00e9rar", "Maxime", ""], ["Gasso", "Gilles", ""], ["Rakotomamonjy", "Alain", ""]]}, {"id": "2002.08327", "submitter": "Shawn Shan", "authors": "Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben\n  Y. Zhao", "title": "Fawkes: Protecting Privacy against Unauthorized Deep Learning Models", "comments": null, "journal-ref": "USENIX Security Symposium 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's proliferation of powerful facial recognition systems poses a real\nthreat to personal privacy. As Clearview.ai demonstrated, anyone can canvas the\nInternet for data and train highly accurate facial recognition models of\nindividuals without their knowledge. We need tools to protect ourselves from\npotential misuses of unauthorized facial recognition systems. Unfortunately, no\npractical or effective solutions exist.\n  In this paper, we propose Fawkes, a system that helps individuals inoculate\ntheir images against unauthorized facial recognition models. Fawkes achieves\nthis by helping users add imperceptible pixel-level changes (we call them\n\"cloaks\") to their own photos before releasing them. When used to train facial\nrecognition models, these \"cloaked\" images produce functional models that\nconsistently cause normal images of the user to be misidentified. We\nexperimentally demonstrate that Fawkes provides 95+% protection against user\nrecognition regardless of how trackers train their models. Even when clean,\nuncloaked images are \"leaked\" to the tracker and used for training, Fawkes can\nstill maintain an 80+% protection success rate. We achieve 100% success in\nexperiments against today's state-of-the-art facial recognition services.\nFinally, we show that Fawkes is robust against a variety of countermeasures\nthat try to detect or disrupt image cloaks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:00:22 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 03:54:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Shan", "Shawn", ""], ["Wenger", "Emily", ""], ["Zhang", "Jiayun", ""], ["Li", "Huiying", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "2002.08329", "submitter": "Arthur Guez", "authors": "Arthur Guez, Fabio Viola, Th\\'eophane Weber, Lars Buesing, Steven\n  Kapturowski, Doina Precup, David Silver, Nicolas Heess", "title": "Value-driven Hindsight Modelling", "comments": "9 pages + reference + appendix. NeurIPS 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value estimation is a critical component of the reinforcement learning (RL)\nparadigm. The question of how to effectively learn value predictors from data\nis one of the major problems studied by the RL community, and different\napproaches exploit structure in the problem domain in different ways. Model\nlearning can make use of the rich transition structure present in sequences of\nobservations, but this approach is usually not sensitive to the reward\nfunction. In contrast, model-free methods directly leverage the quantity of\ninterest from the future, but receive a potentially weak scalar signal (an\nestimate of the return). We develop an approach for representation learning in\nRL that sits in between these two extremes: we propose to learn what to model\nin a way that can directly help value prediction. To this end, we determine\nwhich features of the future trajectory provide useful information to predict\nthe associated return. This provides tractable prediction targets that are\ndirectly relevant for a task, and can thus accelerate learning the value\nfunction. The idea can be understood as reasoning, in hindsight, about which\naspects of the future observations could help past value prediction. We show\nhow this can help dramatically even in simple policy evaluation settings. We\nthen test our approach at scale in challenging domains, including on 57 Atari\n2600 games.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:10:20 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:18:12 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Guez", "Arthur", ""], ["Viola", "Fabio", ""], ["Weber", "Th\u00e9ophane", ""], ["Buesing", "Lars", ""], ["Kapturowski", "Steven", ""], ["Precup", "Doina", ""], ["Silver", "David", ""], ["Heess", "Nicolas", ""]]}, {"id": "2002.08335", "submitter": "Gene Yoo", "authors": "Gene Ryan Yoo and Houman Owhadi", "title": "Deep regularization and direct training of the inner layers of Neural\n  Networks with Kernel Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new regularization method for Artificial Neural Networks\n(ANNs) based on Kernel Flows (KFs). KFs were introduced as a method for kernel\nselection in regression/kriging based on the minimization of the loss of\naccuracy incurred by halving the number of interpolation points in random\nbatches of the dataset. Writing $f_\\theta(x) = \\big(f^{(n)}_{\\theta_n}\\circ\nf^{(n-1)}_{\\theta_{n-1}} \\circ \\dots \\circ f^{(1)}_{\\theta_1}\\big)(x)$ for the\nfunctional representation of compositional structure of the ANN, the inner\nlayers outputs $h^{(i)}(x) = \\big(f^{(i)}_{\\theta_i}\\circ\nf^{(i-1)}_{\\theta_{i-1}} \\circ \\dots \\circ f^{(1)}_{\\theta_1}\\big)(x)$ define a\nhierarchy of feature maps and kernels $k^{(i)}(x,x')=\\exp(- \\gamma_i\n\\|h^{(i)}(x)-h^{(i)}(x')\\|_2^2)$. When combined with a batch of the dataset\nthese kernels produce KF losses $e_2^{(i)}$ (the $L^2$ regression error\nincurred by using a random half of the batch to predict the other half)\ndepending on parameters of inner layers $\\theta_1,\\ldots,\\theta_i$ (and\n$\\gamma_i$). The proposed method simply consists in aggregating a subset of\nthese KF losses with a classical output loss. We test the proposed method on\nCNNs and WRNs without alteration of structure nor output classifier and report\nreduced test errors, decreased generalization gaps, and increased robustness to\ndistribution shift without significant increase in computational complexity. We\nsuspect that these results might be explained by the fact that while\nconventional training only employs a linear functional (a generalized moment)\nof the empirical distribution defined by the dataset and can be prone to\ntrapping in the Neural Tangent Kernel regime (under over-parameterizations),\nthe proposed loss function (defined as a nonlinear functional of the empirical\ndistribution) effectively trains the underlying kernel defined by the CNN\nbeyond regressing the data with that kernel.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:20:36 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 03:47:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Yoo", "Gene Ryan", ""], ["Owhadi", "Houman", ""]]}, {"id": "2002.08338", "submitter": "Haw-Minn Lu", "authors": "Haw-minn Lu (1), Giancarlo Perrone (1), Jos\\'e Unpingco (1) ((1) Gary\n  and Mary West Health Institute)", "title": "Multiple Imputation with Denoising Autoencoder using Metamorphic Truth\n  and Imputation Feedback", "comments": "Machine Learning and Data Mining in Pattern Recognition, 16th\n  International Conference on Machine Learning and Data Mining, MLDM 2020,\n  Amsterdam, The Netherlands, July 20-21, 2020, Proceedings, pp. 197-208", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although data may be abundant, complete data is less so, due to missing\ncolumns or rows. This missingness undermines the performance of downstream data\nproducts that either omit incomplete cases or create derived completed data for\nsubsequent processing. Appropriately managing missing data is required in order\nto fully exploit and correctly use data. We propose a Multiple Imputation model\nusing Denoising Autoencoders to learn the internal representation of data.\nFurthermore, we use the novel mechanisms of Metamorphic Truth and Imputation\nFeedback to maintain statistical integrity of attributes and eliminate bias in\nthe learning process. Our approach explores the effects of imputation on\nvarious missingness mechanisms and patterns of missing data, outperforming\nother methods in many standard test cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:26:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 02:20:17 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Lu", "Haw-minn", ""], ["Perrone", "Giancarlo", ""], ["Unpingco", "Jos\u00e9", ""]]}, {"id": "2002.08339", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov and Michel A. Kinsy", "title": "NeuroFabric: Identifying Ideal Topologies for Training A Priori Sparse\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report-v05", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long training times of deep neural networks are a bottleneck in machine\nlearning research. The major impediment to fast training is the quadratic\ngrowth of both memory and compute requirements of dense and convolutional\nlayers with respect to their information bandwidth. Recently, training `a\npriori' sparse networks has been proposed as a method for allowing layers to\nretain high information bandwidth, while keeping memory and compute low.\nHowever, the choice of which sparse topology should be used in these networks\nis unclear. In this work, we provide a theoretical foundation for the choice of\nintra-layer topology. First, we derive a new sparse neural network\ninitialization scheme that allows us to explore the space of very deep sparse\nnetworks. Next, we evaluate several topologies and show that seemingly similar\ntopologies can often have a large difference in attainable accuracy. To explain\nthese differences, we develop a data-free heuristic that can evaluate a\ntopology independently from the dataset the network will be trained on. We then\nderive a set of requirements that make a good topology, and arrive at a single\ntopology that satisfies all of them.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:29:18 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Isakov", "Mihailo", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "2002.08345", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and Frank Nielsen", "title": "Schoenberg-Rao distances: Entropy-based and geometry-aware statistical\n  Hilbert distances", "comments": "Most results were already known. The distances described therein do\n  not generalize MMD: it is an MMD with a distance-induced kernel (see\n  [Sejdinovic et al. (2013)]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distances between probability distributions that take into account the\ngeometry of their sample space,like the Wasserstein or the Maximum Mean\nDiscrepancy (MMD) distances have received a lot of attention in machine\nlearning as they can, for instance, be used to compare probability\ndistributions with disjoint supports. In this paper, we study a class of\nstatistical Hilbert distances that we term the Schoenberg-Rao distances, a\ngeneralization of the MMD that allows one to consider a broader class of\nkernels, namely the conditionally negative semi-definite kernels. In\nparticular, we introduce a principled way to construct such kernels and derive\nnovel closed-form distances between mixtures of Gaussian distributions. These\ndistances, derived from the concave Rao's quadratic entropy, enjoy nice\ntheoretical properties and possess interpretable hyperparameters which can be\ntuned for specific applications. Our method constitutes a practical alternative\nto Wasserstein distances and we illustrate its efficiency on a broad range of\nmachine learning tasks such as density estimation, generative modeling and\nmixture simplification.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:48:33 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:19:50 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Nielsen", "Frank", ""]]}, {"id": "2002.08347", "submitter": "Florian Tram\\`er", "authors": "Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry", "title": "On Adaptive Attacks to Adversarial Example Defenses", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive attacks have (rightfully) become the de facto standard for\nevaluating defenses to adversarial examples. We find, however, that typical\nadaptive evaluations are incomplete. We demonstrate that thirteen defenses\nrecently published at ICLR, ICML and NeurIPS---and chosen for illustrative and\npedagogical purposes---can be circumvented despite attempting to perform\nevaluations using adaptive attacks. While prior evaluation papers focused\nmainly on the end result---showing that a defense was ineffective---this paper\nfocuses on laying out the methodology and the approach necessary to perform an\nadaptive attack. We hope that these analyses will serve as guidance on how to\nproperly perform adaptive attacks against defenses to adversarial examples, and\nthus will allow the community to make further progress in building more robust\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:50:29 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:07:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Tramer", "Florian", ""], ["Carlini", "Nicholas", ""], ["Brendel", "Wieland", ""], ["Madry", "Aleksander", ""]]}, {"id": "2002.08356", "submitter": "Takanori Fujiwara", "authors": "Rongchen Guo, Takanori Fujiwara, Yiran Li, Kelly M. Lima, Soman Sen,\n  Nam K. Tran, and Kwan-Liu Ma", "title": "Comparative Visual Analytics for Assessing Medical Records with Sequence\n  Embedding", "comments": "This is the author's version of the article that has been accepted in\n  PacificVis 2020 Visualization Meets AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for data-driven diagnosis has been actively studied in\nmedicine to provide better healthcare. Supporting analysis of a patient cohort\nsimilar to a patient under treatment is a key task for clinicians to make\ndecisions with high confidence. However, such analysis is not straightforward\ndue to the characteristics of medical records: high dimensionality,\nirregularity in time, and sparsity. To address this challenge, we introduce a\nmethod for similarity calculation of medical records. Our method employs event\nand sequence embeddings. While we use an autoencoder for the event embedding,\nwe apply its variant with the self-attention mechanism for the sequence\nembedding. Moreover, in order to better handle the irregularity of data, we\nenhance the self-attention mechanism with consideration of different time\nintervals. We have developed a visual analytics system to support comparative\nstudies of patient records. To make a comparison of sequences with different\nlengths easier, our system incorporates a sequence alignment method. Through\nits interactive interface, the user can quickly identify patients of interest\nand conveniently review both the temporal and multivariate aspects of the\npatient records. We demonstrate the effectiveness of our design and system with\ncase studies using a real-world dataset from the neonatal intensive care unit\nof UC Davis.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:29:30 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 20:02:15 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Guo", "Rongchen", ""], ["Fujiwara", "Takanori", ""], ["Li", "Yiran", ""], ["Lima", "Kelly M.", ""], ["Sen", "Soman", ""], ["Tran", "Nam K.", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2002.08396", "submitter": "Noah Siegel", "authors": "Noah Y. Siegel, Jost Tobias Springenberg, Felix Berkenkamp, Abbas\n  Abdolmaleki, Michael Neunert, Thomas Lampe, Roland Hafner, Nicolas Heess,\n  Martin Riedmiller", "title": "Keep Doing What Worked: Behavioral Modelling Priors for Offline\n  Reinforcement Learning", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning algorithms promise to be applicable in\nsettings where only a fixed data-set (batch) of environment interactions is\navailable and no new experience can be acquired. This property makes these\nalgorithms appealing for real world problems such as robot control. In\npractice, however, standard off-policy algorithms fail in the batch setting for\ncontinuous control. In this paper, we propose a simple solution to this\nproblem. It admits the use of data generated by arbitrary behavior policies and\nuses a learned prior -- the advantage-weighted behavior model (ABM) -- to bias\nthe RL policy towards actions that have previously been executed and are likely\nto be successful on the new task. Our method can be seen as an extension of\nrecent work on batch-RL that enables stable learning from conflicting\ndata-sources. We find improvements on competitive baselines in a variety of RL\ntasks -- including standard continuous control benchmarks and multi-task\nlearning for simulated and real-world robots.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:21:08 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 13:29:13 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 10:12:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Siegel", "Noah Y.", ""], ["Springenberg", "Jost Tobias", ""], ["Berkenkamp", "Felix", ""], ["Abdolmaleki", "Abbas", ""], ["Neunert", "Michael", ""], ["Lampe", "Thomas", ""], ["Hafner", "Roland", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2002.08404", "submitter": "Arthur Jacot", "authors": "Arthur Jacot, Berfin \\c{S}im\\c{s}ek, Francesco Spadaro, Cl\\'ement\n  Hongler, Franck Gabriel", "title": "Implicit Regularization of Random Feature Models", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2020, pp. 7397-7406", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Feature (RF) models are used as efficient parametric approximations of\nkernel methods. We investigate, by means of random matrix theory, the\nconnection between Gaussian RF models and Kernel Ridge Regression (KRR). For a\nGaussian RF model with $P$ features, $N$ data points, and a ridge $\\lambda$, we\nshow that the average (i.e. expected) RF predictor is close to a KRR predictor\nwith an effective ridge $\\tilde{\\lambda}$. We show that $\\tilde{\\lambda} >\n\\lambda$ and $\\tilde{\\lambda} \\searrow \\lambda$ monotonically as $P$ grows,\nthus revealing the implicit regularization effect of finite RF sampling. We\nthen compare the risk (i.e. test error) of the $\\tilde{\\lambda}$-KRR predictor\nwith the average risk of the $\\lambda$-RF predictor and obtain a precise and\nexplicit bound on their difference. Finally, we empirically find an extremely\ngood agreement between the test errors of the average $\\lambda$-RF predictor\nand $\\tilde{\\lambda}$-KRR predictor.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:36:23 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 10:29:43 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jacot", "Arthur", ""], ["\u015eim\u015fek", "Berfin", ""], ["Spadaro", "Francesco", ""], ["Hongler", "Cl\u00e9ment", ""], ["Gabriel", "Franck", ""]]}, {"id": "2002.08405", "submitter": "Nihal Sharma", "authors": "Nihal Sharma, Soumya Basu, Karthikeyan Shanmugam and Sanjay Shakkottai", "title": "On Under-exploration in Bandits with Mean Bounds from Confounded Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the multi-armed bandit problem where side information\nin the form of bounds on the mean of each arm is provided. We develop the novel\nnon-optimistic Global Under-Explore (GLUE) algorithm which uses the provided\nmean bounds (across all the arms) to infer pseudo-variances for each arm, which\nin turn decide the rate of exploration for the arms. We analyze the regret of\nGLUE and prove regret upper bounds that are never worse than that of the\nstandard UCB algorithm. Furthermore, we show that GLUE improves upon regret\nguarantees that exists in literature for structured bandit problems (both\ntheoretically and empirically). Finally, we study the practical setting of\nlearning adaptive interventions using prior data that has been confounded by\nunrecorded variables that affect rewards. We show that mean bounds can be\ninferred naturally from such logs and can thus be used to improve the learning\nprocess. We validate our findings through semi-synthetic experiments on data\nderived from real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:36:43 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 17:52:22 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 17:08:31 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 14:55:17 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Sharma", "Nihal", ""], ["Basu", "Soumya", ""], ["Shanmugam", "Karthikeyan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2002.08410", "submitter": "Qiong Zhang", "authors": "Qiong Zhang, Jiahua Chen", "title": "A Unified Framework for Gaussian Mixture Reduction with Composite\n  Transportation Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture reduction (GMR) is the problem of approximating a finite\nGaussian mixture by one with fewer components. It is widely used in density\nestimation, nonparametric belief propagation, and Bayesian recursive filtering.\nAlthough optimization and clustering-based algorithms have been proposed for\nGMR, they are either computationally expensive or lacking in theoretical\nsupports. In this work, we propose to perform GMR by minimizing the entropic\nregularized composite transportation distance between two mixtures. We show our\napproach provides a unified framework for GMR that is both interpretable and\ncomputationally efficient. Our work also bridges the gap between optimization\nand clustering-based approaches for GMR. A Majorization-Minimization algorithm\nis developed for our optimization problem and its theoretical convergence is\nalso established in this paper. Empirical experiments are also conducted to\nshow the effectiveness of GMR. The effect of the choice of transportation cost\non the performance of GMR is also investigated.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:52:17 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Zhang", "Qiong", ""], ["Chen", "Jiahua", ""]]}, {"id": "2002.08412", "submitter": "Raed Al Kontar", "authors": "Seokhyun Chung, Raed Al Kontar, Zhenke Wu", "title": "Weakly-supervised Multi-output Regression via Correlated Gaussian\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output regression seeks to infer multiple latent functions using data\nfrom multiple groups/sources while accounting for potential between-group\nsimilarities. In this paper, we consider multi-output regression under a\nweakly-supervised setting where a subset of data points from multiple groups\nare unlabeled. We use dependent Gaussian processes for multiple outputs\nconstructed by convolutions with shared latent processes. We introduce\nhyperpriors for the multinomial probabilities of the unobserved labels and\noptimize the hyperparameters which we show improves estimation. We derive two\nvariational bounds: (i) a modified variational bound for fast and stable\nconvergence in model inference, (ii) a scalable variational bound that is\namenable to stochastic optimization. We use experiments on synthetic and\nreal-world data to show that the proposed model outperforms state-of-the-art\nmodels with more accurate estimation of multiple latent functions and\nunobserved labels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:54:25 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Chung", "Seokhyun", ""], ["Kontar", "Raed Al", ""], ["Wu", "Zhenke", ""]]}, {"id": "2002.08422", "submitter": "Jaehyeok Shin", "authors": "Jaehyeok Shin, Aaditya Ramdas, Alessandro Rinaldo", "title": "On conditional versus marginal bias in multi-armed bandits", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bias of the sample means of the arms in multi-armed bandits is an\nimportant issue in adaptive data analysis that has recently received\nconsiderable attention in the literature. Existing results relate in precise\nways the sign and magnitude of the bias to various sources of data adaptivity,\nbut do not apply to the conditional inference setting in which the sample means\nare computed only if some specific conditions are satisfied. In this paper, we\ncharacterize the sign of the conditional bias of monotone functions of the\nrewards, including the sample mean. Our results hold for arbitrary conditioning\nevents and leverage natural monotonicity properties of the data collection\npolicy. We further demonstrate, through several examples from sequential\ntesting and best arm identification, that the sign of the conditional and\nmarginal bias of the sample mean of an arm can be different, depending on the\nconditioning event. Our analysis offers new and interesting perspectives on the\nsubtleties of assessing the bias in data adaptive settings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:16:10 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 04:02:37 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 21:10:15 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Shin", "Jaehyeok", ""], ["Ramdas", "Aaditya", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "2002.08423", "submitter": "Vaikkunth Mugunthan", "authors": "Vaikkunth Mugunthan, Anton Peraire-Bueno and Lalana Kagal", "title": "PrivacyFL: A simulator for privacy-preserving and secure federated\n  learning", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3412771", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a technique that enables distributed clients to\ncollaboratively learn a shared machine learning model while keeping their\ntraining data localized. This reduces data privacy risks, however, privacy\nconcerns still exist since it is possible to leak information about the\ntraining dataset from the trained model's weights or parameters. Setting up a\nfederated learning environment, especially with security and privacy\nguarantees, is a time-consuming process with numerous configurations and\nparameters that can be manipulated. In order to help clients ensure that\ncollaboration is feasible and to check that it improves their model accuracy, a\nreal-world simulator for privacy-preserving and secure federated learning is\nrequired. In this paper, we introduce PrivacyFL, which is an extensible, easily\nconfigurable and scalable simulator for federated learning environments. Its\nkey features include latency simulation, robustness to client departure,\nsupport for both centralized and decentralized learning, and configurable\nprivacy and security mechanisms based on differential privacy and secure\nmultiparty computation. In this paper, we motivate our research, describe the\narchitecture of the simulator and associated protocols, and discuss its\nevaluation in numerous scenarios that highlight its wide range of functionality\nand its advantages. Our paper addresses a significant real-world problem:\nchecking the feasibility of participating in a federated learning environment\nunder a variety of circumstances. It also has a strong practical impact because\norganizations such as hospitals, banks, and research institutes, which have\nlarge amounts of sensitive data and would like to collaborate, would greatly\nbenefit from having a system that enables them to do so in a privacy-preserving\nand secure manner.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:16:13 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:30:36 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Mugunthan", "Vaikkunth", ""], ["Peraire-Bueno", "Anton", ""], ["Kagal", "Lalana", ""]]}, {"id": "2002.08436", "submitter": "Guang Cheng", "authors": "Chi-Hua Wang, Yang Yu, Botao Hao, Guang Cheng", "title": "Residual Bootstrap Exploration for Bandit Algorithms", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel perturbation-based exploration method in\nbandit algorithms with bounded or unbounded rewards, called residual bootstrap\nexploration (\\texttt{ReBoot}). The \\texttt{ReBoot} enforces exploration by\ninjecting data-driven randomness through a residual-based perturbation\nmechanism. This novel mechanism captures the underlying distributional\nproperties of fitting errors, and more importantly boosts exploration to escape\nfrom suboptimal solutions (for small sample sizes) by inflating variance level\nin an \\textit{unconventional} way. In theory, with appropriate variance\ninflation level, \\texttt{ReBoot} provably secures instance-dependent\nlogarithmic regret in Gaussian multi-armed bandits. We evaluate the\n\\texttt{ReBoot} in different synthetic multi-armed bandits problems and observe\nthat the \\texttt{ReBoot} performs better for unbounded rewards and more\nrobustly than \\texttt{Giro} \\cite{kveton2018garbage} and \\texttt{PHE}\n\\cite{kveton2019perturbed}, with comparable computational efficiency to the\nThompson sampling method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:43:27 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Chi-Hua", ""], ["Yu", "Yang", ""], ["Hao", "Botao", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.08443", "submitter": "Guang Cheng", "authors": "Yang Yu, Shih-Kang Chao, Guang Cheng", "title": "Simultaneous Inference for Massive Data: Distributed Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a bootstrap method applied to massive data\nprocessed distributedly in a large number of machines. This new method is\ncomputationally efficient in that we bootstrap on the master machine without\nover-resampling, typically required by existing methods\n\\cite{kleiner2014scalable,sengupta2016subsampled}, while provably achieving\noptimal statistical efficiency with minimal communication. Our method does not\nrequire repeatedly re-fitting the model but only applies multiplier bootstrap\nin the master machine on the gradients received from the worker machines.\nSimulations validate our theory.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:53:32 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Yu", "Yang", ""], ["Chao", "Shih-Kang", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.08456", "submitter": "Julien Perolat", "authors": "Julien Perolat, Remi Munos, Jean-Baptiste Lespiau, Shayegan\n  Omidshafiei, Mark Rowland, Pedro Ortega, Neil Burch, Thomas Anthony, David\n  Balduzzi, Bart De Vylder, Georgios Piliouras, Marc Lanctot, Karl Tuyls", "title": "From Poincar\\'e Recurrence to Convergence in Imperfect Information\n  Games: Finding Equilibrium via Regularization", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the Follow the Regularized Leader dynamics in\nsequential imperfect information games (IIG). We generalize existing results of\nPoincar\\'e recurrence from normal-form games to zero-sum two-player imperfect\ninformation games and other sequential game settings. We then investigate how\nadapting the reward (by adding a regularization term) of the game can give\nstrong convergence guarantees in monotone games. We continue by showing how\nthis reward adaptation technique can be leveraged to build algorithms that\nconverge exactly to the Nash equilibrium. Finally, we show how these insights\ncan be directly used to build state-of-the-art model-free algorithms for\nzero-sum two-player Imperfect Information Games (IIG).\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 21:36:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Perolat", "Julien", ""], ["Munos", "Remi", ""], ["Lespiau", "Jean-Baptiste", ""], ["Omidshafiei", "Shayegan", ""], ["Rowland", "Mark", ""], ["Ortega", "Pedro", ""], ["Burch", "Neil", ""], ["Anthony", "Thomas", ""], ["Balduzzi", "David", ""], ["De Vylder", "Bart", ""], ["Piliouras", "Georgios", ""], ["Lanctot", "Marc", ""], ["Tuyls", "Karl", ""]]}, {"id": "2002.08465", "submitter": "Georgios Giasemidis Dr", "authors": "Georgios Giasemidis", "title": "Descriptive and Predictive Analysis of Euroleague Basketball Games and\n  the Wisdom of Basketball Crowds", "comments": "24 pages, several figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we focus on the prediction of basketball games in the\nEuroleague competition using machine learning modelling. The prediction is a\nbinary classification problem, predicting whether a match finishes 1 (home win)\nor 2 (away win). Data is collected from the Euroleague's official website for\nthe seasons 2016-2017, 2017-2018 and 2018-2019, i.e. in the new format era.\nFeatures are extracted from matches' data and off-the-shelf supervised machine\nlearning techniques are applied. We calibrate and validate our models. We find\nthat simple machine learning models give accuracy not greater than 67% on the\ntest set, worse than some sophisticated benchmark models. Additionally, the\nimportance of this study lies in the \"wisdom of the basketball crowd\" and we\ndemonstrate how the predicting power of a collective group of basketball\nenthusiasts can outperform machine learning models discussed in this study. We\nargue why the accuracy level of this group of \"experts\" should be set as the\nbenchmark for future studies in the prediction of (European) basketball games\nusing machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:04:29 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Giasemidis", "Georgios", ""]]}, {"id": "2002.08483", "submitter": "Joshua Robinson", "authors": "Joshua Robinson, Stefanie Jegelka, Suvrit Sra", "title": "Strength from Weakness: Fast Learning Using Weak Supervision", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study generalization properties of weakly supervised learning. That is,\nlearning where only a few \"strong\" labels (the actual target of our prediction)\nare present but many more \"weak\" labels are available. In particular, we show\nthat having access to weak labels can significantly accelerate the learning\nrate for the strong task to the fast rate of $\\mathcal{O}(\\nicefrac1n)$, where\n$n$ denotes the number of strongly labeled data points. This acceleration can\nhappen even if by itself the strongly labeled data admits only the slower\n$\\mathcal{O}(\\nicefrac{1}{\\sqrt{n}})$ rate. The actual acceleration depends\ncontinuously on the number of weak labels available, and on the relation\nbetween the two tasks. Our theoretical results are reflected empirically across\na range of tasks and illustrate how weak labels speed up learning on the strong\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:39:37 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Robinson", "Joshua", ""], ["Jegelka", "Stefanie", ""], ["Sra", "Suvrit", ""]]}, {"id": "2002.08484", "submitter": "Frederick Liu", "authors": "Garima Pruthi, Frederick Liu, Mukund Sundararajan, Satyen Kale", "title": "Estimating Training Data Influence by Tracing Gradient Descent", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method called TracIn that computes the influence of a training\nexample on a prediction made by the model. The idea is to trace how the loss on\nthe test point changes during the training process whenever the training\nexample of interest was utilized. We provide a scalable implementation of\nTracIn via: (a) a first-order gradient approximation to the exact computation,\n(b) saved checkpoints of standard training procedures, and (c) cherry-picking\nlayers of a deep neural network. In contrast with previously proposed methods,\nTracIn is simple to implement; all it needs is the ability to work with\ngradients, checkpoints, and loss functions. The method is general. It applies\nto any machine learning model trained using stochastic gradient descent or a\nvariant of it, agnostic of architecture, domain and task. We expect the method\nto be widely useful within processes that study and improve training data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:40:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 22:52:31 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 18:47:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Pruthi", "Garima", ""], ["Liu", "Frederick", ""], ["Sundararajan", "Mukund", ""], ["Kale", "Satyen", ""]]}, {"id": "2002.08491", "submitter": "Vasileios Charisopoulos", "authors": "Vasileios Charisopoulos, Austin R. Benson, Anil Damle", "title": "Entrywise convergence of iterative methods for eigenproblems", "comments": "21 pages, 8 figures. To appear in the 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Several problems in machine learning, statistics, and other fields rely on\ncomputing eigenvectors. For large scale problems, the computation of these\neigenvectors is typically performed via iterative schemes such as subspace\niteration or Krylov methods. While there is classical and comprehensive\nanalysis for subspace convergence guarantees with respect to the spectral norm,\nin many modern applications other notions of subspace distance are more\nappropriate. Recent theoretical work has focused on perturbations of subspaces\nmeasured in the $\\ell_{2 \\to \\infty}$ norm, but does not consider the actual\ncomputation of eigenvectors. Here we address the convergence of subspace\niteration when distances are measured in the $\\ell_{2 \\to \\infty}$ norm and\nprovide deterministic bounds. We complement our analysis with a practical\nstopping criterion and demonstrate its applicability via numerical experiments.\nOur results show that one can get comparable performance on downstream tasks\nwhile requiring fewer iterations, thereby saving substantial computational\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:59:56 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 02:06:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Benson", "Austin R.", ""], ["Damle", "Anil", ""]]}, {"id": "2002.08506", "submitter": "Yunpu Ma", "authors": "Yunpu Ma and Volker Tresp", "title": "Causal Inference under Networked Interference and Intervention Policy\n  Enhancement", "comments": "Published on AISTATS 2021", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics, PMLR 130:3700-3708, 2021", "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating individual treatment effects from data of randomized experiments\nis a critical task in causal inference. The Stable Unit Treatment Value\nAssumption (SUTVA) is usually made in causal inference. However, interference\ncan introduce bias when the assigned treatment on one unit affects the\npotential outcomes of the neighboring units. This interference phenomenon is\nknown as spillover effect in economics or peer effect in social science.\nUsually, in randomized experiments or observational studies with interconnected\nunits, one can only observe treatment responses under interference. Hence, how\nto estimate the superimposed causal effect and recover the individual treatment\neffect in the presence of interference becomes a challenging task in causal\ninference. In this work, we study causal effect estimation under general\nnetwork interference using GNNs, which are powerful tools for capturing the\ndependency in the graph. After deriving causal effect estimators, we further\nstudy intervention policy improvement on the graph under capacity constraint.\nWe give policy regret bounds under network interference and treatment capacity\nconstraint. Furthermore, a heuristic graph structure-dependent error bound for\nGNN-based causal estimators is provided.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 00:35:50 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:58:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "2002.08517", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Tim Pearce, Chris van der Heide, Fred Roosta, Marcus\n  Gallagher", "title": "Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite\n  Networks", "comments": "AAAI camera ready version. 18 pages, 9 figures, 2 tables. Corrected\n  name particle capitalisation and formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing and computing with Gaussian processes arising from infinitely wide\nneural networks has recently seen a resurgence in popularity. Despite this,\nmany explicit covariance functions of networks with activation functions used\nin modern networks remain unknown. Furthermore, while the kernels of deep\nnetworks can be computed iteratively, theoretical understanding of deep kernels\nis lacking, particularly with respect to fixed-point dynamics. Firstly, we\nderive the covariance functions of multi-layer perceptrons (MLPs) with\nexponential linear units (ELU) and Gaussian error linear units (GELU) and\nevaluate the performance of the limiting Gaussian processes on some benchmarks.\nSecondly, and more generally, we analyse the fixed-point dynamics of iterated\nkernels corresponding to a broad range of activation functions. We find that\nunlike some previously studied neural network kernels, these new kernels\nexhibit non-trivial fixed-point dynamics which are mirrored in finite-width\nneural networks. The fixed point behaviour present in some networks explains a\nmechanism for implicit regularisation in overparameterised deep models. Our\nresults relate to both the static iid parameter conjugate kernel and the\ndynamic neural tangent kernel constructions. Software at\ngithub.com/RussellTsuchida/ELU_GELU_kernels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:25:39 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 22:47:00 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 00:43:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Tsuchida", "Russell", ""], ["Pearce", "Tim", ""], ["van der Heide", "Chris", ""], ["Roosta", "Fred", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2002.08526", "submitter": "David Eriksson", "authors": "David Eriksson and Matthias Poloczek", "title": "Scalable Constrained Bayesian Optimization", "comments": "To appear in Proceedings of AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global optimization of a high-dimensional black-box function under\nblack-box constraints is a pervasive task in machine learning, control, and\nengineering. These problems are challenging since the feasible set is typically\nnon-convex and hard to find, in addition to the curses of dimensionality and\nthe heterogeneity of the underlying functions. In particular, these\ncharacteristics dramatically impact the performance of Bayesian optimization\nmethods, that otherwise have become the de facto standard for sample-efficient\noptimization in unconstrained settings, leaving practitioners with evolutionary\nstrategies or heuristics. We propose the scalable constrained Bayesian\noptimization (SCBO) algorithm that overcomes the above challenges and pushes\nthe applicability of Bayesian optimization far beyond the state-of-the-art. A\ncomprehensive experimental evaluation demonstrates that SCBO achieves excellent\nresults on a variety of benchmarks. To this end, we propose two new control\nproblems that we expect to be of independent value for the scientific\ncommunity.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:48:46 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 20:58:24 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 16:05:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Eriksson", "David", ""], ["Poloczek", "Matthias", ""]]}, {"id": "2002.08528", "submitter": "Ilqar Ramazanli", "authors": "Ilqar Ramazanli, Han Nguyen, Hai Pham, Sashank J. Reddi, Barnabas\n  Poczos", "title": "Adaptive Sampling Distributed Stochastic Variance Reduced Gradient for\n  Heterogeneous Distributed Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed optimization algorithms for minimizing the average of\n\\emph{heterogeneous} functions distributed across several machines with a focus\non communication efficiency. In such settings, naively using the classical\nstochastic gradient descent (SGD) or its variants (e.g., SVRG) with a uniform\nsampling of machines typically yields poor performance. It often leads to the\ndependence of convergence rate on maximum Lipschitz constant of gradients\nacross the devices. In this paper, we propose a novel \\emph{adaptive} sampling\nof machines specially catered to these settings. Our method relies on an\nadaptive estimate of local Lipschitz constants base on the information of past\ngradients. We show that the new way improves the dependence of convergence rate\nfrom maximum Lipschitz constant to \\emph{average} Lipschitz constant across\nmachines, thereby, significantly accelerating the convergence. Our experiments\ndemonstrate that our method indeed speeds up the convergence of the standard\nSVRG algorithm in heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:55:52 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 20:01:23 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 05:00:16 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ramazanli", "Ilqar", ""], ["Nguyen", "Han", ""], ["Pham", "Hai", ""], ["Reddi", "Sashank J.", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2002.08536", "submitter": "Kohei Yata", "authors": "Yusuke Narita, Shota Yasui, Kohei Yata", "title": "Off-policy Bandit and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for predicting the performance of reinforcement learning\nand bandit algorithms, given historical data that may have been generated by a\ndifferent algorithm. Our estimator has the property that its prediction\nconverges in probability to the true performance of a counterfactual algorithm\nat the fast $\\sqrt{N}$ rate, as the sample size $N$ increases. We also show a\ncorrect way to estimate the variance of our prediction, thus allowing the\nanalyst to quantify the uncertainty in the prediction. These properties hold\neven when the analyst does not know which among a large number of potentially\nimportant state variables are really important. These theoretical guarantees\nmake our estimator safe to use. We finally apply it to improve advertisement\ndesign by a major advertisement company. We find that our method produces\nsmaller mean squared errors than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:30:02 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:44:37 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Narita", "Yusuke", ""], ["Yasui", "Shota", ""], ["Yata", "Kohei", ""]]}, {"id": "2002.08537", "submitter": "Tao Sun", "authors": "Tao Sun, Han Shen, Tianyi Chen, Dongsheng Li", "title": "Adaptive Temporal Difference Learning with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the celebrated temporal difference (TD) learning\nalgorithm for the policy evaluation in reinforcement learning. Typically, the\nperformance of the plain-vanilla TD algorithm is sensitive to the choice of\nstepsizes. Oftentimes, TD suffers from slow convergence. Motivated by the tight\nconnection between the TD learning algorithm and the stochastic gradient\nmethods, we develop the first adaptive variant of the TD learning algorithm\nwith linear function approximation that we term AdaTD. In contrast to the\noriginal TD, AdaTD is robust or less sensitive to the choice of stepsizes.\nAnalytically, we establish that to reach an $\\epsilon$ accuracy, the number of\niterations needed is\n$\\tilde{O}(\\epsilon^2\\ln^4\\frac{1}{\\epsilon}/\\ln^4\\frac{1}{\\rho})$, where\n$\\rho$ represents the speed of the underlying Markov chain converges to the\nstationary distribution. This implies that the iteration complexity of AdaTD is\nno worse than that of TD in the worst case. Going beyond TD, we further develop\nan adaptive variant of TD($\\lambda$), which is referred to as AdaTD($\\lambda$).\nWe evaluate the empirical performance of AdaTD and AdaTD($\\lambda$) on several\nstandard reinforcement learning tasks in OpenAI Gym on both linear and\nnonlinear function approximation, which demonstrate the effectiveness of our\nnew approaches over existing ones.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:32:40 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Sun", "Tao", ""], ["Shen", "Han", ""], ["Chen", "Tianyi", ""], ["Li", "Dongsheng", ""]]}, {"id": "2002.08538", "submitter": "Yahya Sattar", "authors": "Yahya Sattar and Samet Oymak", "title": "Non-asymptotic and Accurate Learning of Nonlinear Dynamical Systems", "comments": null, "journal-ref": "arXiv preprint:2002.08538, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning stabilizable systems governed by\nnonlinear state equation $h_{t+1}=\\phi(h_t,u_t;\\theta)+w_t$. Here $\\theta$ is\nthe unknown system dynamics, $h_t $ is the state, $u_t$ is the input and $w_t$\nis the additive noise vector. We study gradient based algorithms to learn the\nsystem dynamics $\\theta$ from samples obtained from a single finite trajectory.\nIf the system is run by a stabilizing input policy, we show that\ntemporally-dependent samples can be approximated by i.i.d. samples via a\ntruncation argument by using mixing-time arguments. We then develop new\nguarantees for the uniform convergence of the gradients of empirical loss.\nUnlike existing work, our bounds are noise sensitive which allows for learning\nground-truth dynamics with high accuracy and small sample complexity. Together,\nour results facilitate efficient learning of the general nonlinear system under\nstabilizing policy. We specialize our guarantees to entry-wise nonlinear\nactivations and verify our theory in various numerical experiments\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:36:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sattar", "Yahya", ""], ["Oymak", "Samet", ""]]}, {"id": "2002.08541", "submitter": "Zhiyue Zhang", "authors": "Zhiyue Zhang, Kenneth Lange, Jason Xu", "title": "Simple and Scalable Sparse k-means Clustering via Feature Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering, a fundamental activity in unsupervised learning, is notoriously\ndifficult when the feature space is high-dimensional. Fortunately, in many\nrealistic scenarios, only a handful of features are relevant in distinguishing\nclusters. This has motivated the development of sparse clustering techniques\nthat typically rely on k-means within outer algorithms of high computational\ncomplexity. Current techniques also require careful tuning of shrinkage\nparameters, further limiting their scalability. In this paper, we propose a\nnovel framework for sparse k-means clustering that is intuitive, simple to\nimplement, and competitive with state-of-the-art algorithms. We show that our\nalgorithm enjoys consistency and convergence guarantees. Our core method\nreadily generalizes to several task-specific algorithms such as clustering on\nsubsets of attributes and in partially observed data settings. We showcase\nthese contributions thoroughly via simulated experiments and real data\nbenchmarks, including a case study on protein expression in trisomic mice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:41:02 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:28:41 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhang", "Zhiyue", ""], ["Lange", "Kenneth", ""], ["Xu", "Jason", ""]]}, {"id": "2002.08563", "submitter": "Elliott Gordon-Rodriguez", "authors": "Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, John P. Cunningham", "title": "The continuous categorical: a novel simplex-valued exponential family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplex-valued data appear throughout statistics and machine learning, for\nexample in the context of transfer learning and compression of deep networks.\nExisting models for this class of data rely on the Dirichlet distribution or\nother related loss functions; here we show these standard choices suffer\nsystematically from a number of limitations, including bias and numerical\nissues that frustrate the use of flexible network models upstream of these\ndistributions. We resolve these limitations by introducing a novel exponential\nfamily of distributions for modeling simplex-valued data - the continuous\ncategorical, which arises as a nontrivial multivariate generalization of the\nrecently discovered continuous Bernoulli. Unlike the Dirichlet and other\ntypical choices, the continuous categorical results in a well-behaved\nprobabilistic loss function that produces unbiased estimators, while preserving\nthe mathematical simplicity of the Dirichlet. As well as exploring its\ntheoretical properties, we introduce sampling methods for this distribution\nthat are amenable to the reparameterization trick, and evaluate their\nperformance. Lastly, we demonstrate that the continuous categorical outperforms\nstandard choices empirically, across a simulation study, an applied example on\nmulti-party elections, and a neural network compression task.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:28:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:13:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Gordon-Rodriguez", "Elliott", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Cunningham", "John P.", ""]]}, {"id": "2002.08567", "submitter": "Md. Shirajum Munir", "authors": "Md. Shirajum Munir, Nguyen H. Tran, Walid Saad, Choong Seon Hong", "title": "Multi-Agent Meta-Reinforcement Learning for Self-Powered and Sustainable\n  Edge Computing Systems", "comments": "Accepted article by IEEE Transactions on Network and Service\n  Management, DOI: 10.1109/TNSM.2021.3057960. Copyright 2021 IEEE", "journal-ref": null, "doi": "10.1109/TNSM.2021.3057960", "report-no": null, "categories": "cs.LG cs.MA eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The stringent requirements of mobile edge computing (MEC) applications and\nfunctions fathom the high capacity and dense deployment of MEC hosts to the\nupcoming wireless networks. However, operating such high capacity MEC hosts can\nsignificantly increase energy consumption. Thus, a base station (BS) unit can\nact as a self-powered BS. In this paper, an effective energy dispatch mechanism\nfor self-powered wireless networks with edge computing capabilities is studied.\nFirst, a two-stage linear stochastic programming problem is formulated with the\ngoal of minimizing the total energy consumption cost of the system while\nfulfilling the energy demand. Second, a semi-distributed data-driven solution\nis proposed by developing a novel multi-agent meta-reinforcement learning\n(MAMRL) framework to solve the formulated problem. In particular, each BS plays\nthe role of a local agent that explores a Markovian behavior for both energy\nconsumption and generation while each BS transfers time-varying features to a\nmeta-agent. Sequentially, the meta-agent optimizes (i.e., exploits) the energy\ndispatch decision by accepting only the observations from each local agent with\nits own state information. Meanwhile, each BS agent estimates its own energy\ndispatch policy by applying the learned parameters from meta-agent. Finally,\nthe proposed MAMRL framework is benchmarked by analyzing deterministic,\nasymmetric, and stochastic environments in terms of non-renewable energy\nusages, energy cost, and accuracy. Experimental results show that the proposed\nMAMRL model can reduce up to 11% non-renewable energy usage and by 22.4% the\nenergy cost (with 95.8% prediction accuracy), compared to other baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:58:07 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 07:10:35 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 02:47:56 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Munir", "Md. Shirajum", ""], ["Tran", "Nguyen H.", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2002.08570", "submitter": "Yilin Kang", "authors": "Yilin Kang, Yong Liu, Ben Niu, Xinyi Tong, Likun Zhang and Weiping\n  Wang", "title": "Input Perturbation: A New Paradigm between Central and Local\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, there are two models on differential privacy: the central\nmodel and the local model. The central model focuses on the machine learning\nmodel and the local model focuses on the training data. In this paper, we study\nthe \\textit{input perturbation} method in differentially private empirical risk\nminimization (DP-ERM), preserving privacy of the central model. By adding noise\nto the original training data and training with the `perturbed data', we\nachieve ($\\epsilon$,$\\delta$)-differential privacy on the final model, along\nwith some kind of privacy on the original data. We observe that there is an\ninteresting connection between the local model and the central model: the\nperturbation on the original data causes the perturbation on the gradient, and\nfinally the model parameters. This observation means that our method builds a\nbridge between local and central model, protecting the data, the gradient and\nthe model simultaneously, which is more superior than previous central methods.\nDetailed theoretical analysis and experiments show that our method achieves\nalmost the same (or even better) performance as some of the best previous\ncentral methods with more protections on privacy, which is an attractive\nresult. Moreover, we extend our method to a more general case: the loss\nfunction satisfies the Polyak-Lojasiewicz condition, which is more general than\nstrong convexity, the constraint on the loss function in most previous work.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:20:02 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kang", "Yilin", ""], ["Liu", "Yong", ""], ["Niu", "Ben", ""], ["Tong", "Xinyi", ""], ["Zhang", "Likun", ""], ["Wang", "Weiping", ""]]}, {"id": "2002.08578", "submitter": "Yilin Kang", "authors": "Yilin Kang, Yong Liu, Lizhong Ding, Xinwang Liu, Xinyi Tong and\n  Weiping Wang", "title": "Differentially Private ERM Based on Data Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, after observing that different training data instances affect\nthe machine learning model to different extents, we attempt to improve the\nperformance of differentially private empirical risk minimization (DP-ERM) from\na new perspective. Specifically, we measure the contributions of various\ntraining data instances on the final machine learning model, and select some of\nthem to add random noise. Considering that the key of our method is to measure\neach data instance separately, we propose a new `Data perturbation' based (DB)\nparadigm for DP-ERM: adding random noise to the original training data and\nachieving ($\\epsilon,\\delta$)-differential privacy on the final machine\nlearning model, along with the preservation on the original data. By\nintroducing the Influence Function (IF), we quantitatively measure the impact\nof the training data on the final model. Theoretical and experimental results\nshow that our proposed DBDP-ERM paradigm enhances the model performance\nsignificantly.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 06:05:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kang", "Yilin", ""], ["Liu", "Yong", ""], ["Ding", "Lizhong", ""], ["Liu", "Xinwang", ""], ["Tong", "Xinyi", ""], ["Wang", "Weiping", ""]]}, {"id": "2002.08583", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Regret Minimization in Stochastic Contextual Dueling Bandits", "comments": "Wrong result with incremental contribution, major revision required", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of stochastic $K$-armed dueling bandit in the\ncontextual setting, where at each round the learner is presented with a context\nset of $K$ items, each represented by a $d$-dimensional feature vector, and the\ngoal of the learner is to identify the best arm of each context sets. However,\nunlike the classical contextual bandit setup, our framework only allows the\nlearner to receive item feedback in terms of their (noisy) pariwise\npreferences--famously studied as dueling bandits which is practical interests\nin various online decision making scenarios, e.g. recommender systems,\ninformation retrieval, tournament ranking, where it is easier to elicit the\nrelative strength of the items instead of their absolute scores. However, to\nthe best of our knowledge this work is the first to consider the problem of\nregret minimization of contextual dueling bandits for potentially infinite\ndecision spaces and gives provably optimal algorithms along with a matching\nlower bound analysis. We present two algorithms for the setup with respective\nregret guarantees $\\tilde O(d\\sqrt{T})$ and $\\tilde O(\\sqrt{dT \\log K})$.\nSubsequently we also show that $\\Omega(\\sqrt {dT})$ is actually the fundamental\nperformance limit for this problem, implying the optimality of our second\nalgorithm. However the analysis of our first algorithm is comparatively\nsimpler, and it is often shown to outperform the former empirically. Finally,\nwe corroborate all the theoretical results with suitable experiments.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 06:36:19 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 00:21:15 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2002.08595", "submitter": "Yingtao Tian", "authors": "Yingtao Tian, Chikahiko Suzuki, Tarin Clanuwat, Mikel Bober-Irizar,\n  Alex Lamb, Asanobu Kitamoto", "title": "KaoKore: A Pre-modern Japanese Art Facial Expression Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From classifying handwritten digits to generating strings of text, the\ndatasets which have received long-time focus from the machine learning\ncommunity vary greatly in their subject matter. This has motivated a renewed\ninterest in building datasets which are socially and culturally relevant, so\nthat algorithmic research may have a more direct and immediate impact on\nsociety. One such area is in history and the humanities, where better and\nrelevant machine learning models can accelerate research across various fields.\nTo this end, newly released benchmarks and models have been proposed for\ntranscribing historical Japanese cursive writing, yet for the field as a whole\nusing machine learning for historical Japanese artworks still remains largely\nuncharted. To bridge this gap, in this work we propose a new dataset KaoKore\nwhich consists of faces extracted from pre-modern Japanese artwork. We\ndemonstrate its value as both a dataset for image classification as well as a\ncreative and artistic dataset, which we explore using generative models.\nDataset available at https://github.com/rois-codh/kaokore\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:22:13 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Tian", "Yingtao", ""], ["Suzuki", "Chikahiko", ""], ["Clanuwat", "Tarin", ""], ["Bober-Irizar", "Mikel", ""], ["Lamb", "Alex", ""], ["Kitamoto", "Asanobu", ""]]}, {"id": "2002.08596", "submitter": "Primoz Kocbek", "authors": "Gregor Stiglic, Primoz Kocbek, Nino Fijacko, Marinka Zitnik, Katrien\n  Verbert, Leona Cilar", "title": "Interpretability of machine learning based prediction models in\n  healthcare", "comments": "12 pages, 2 figures, published in Wiley Interdisciplinary Reviews:\n  Data Mining and Knowledge Discovery", "journal-ref": "WIREs Data Mining Knowl Discov (2020)", "doi": "10.1002/widm.1379", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a need of ensuring machine learning models that are interpretable.\nHigher interpretability of the model means easier comprehension and explanation\nof future predictions for end-users. Further, interpretable machine learning\nmodels allow healthcare experts to make reasonable and data-driven decisions to\nprovide personalized decisions that can ultimately lead to higher quality of\nservice in healthcare. Generally, we can classify interpretability approaches\nin two groups where the first focuses on personalized interpretation (local\ninterpretability) while the second summarizes prediction models on a population\nlevel (global interpretability). Alternatively, we can group interpretability\nmethods into model-specific techniques, which are designed to interpret\npredictions generated by a specific model, such as a neural network, and\nmodel-agnostic approaches, which provide easy-to-understand explanations of\npredictions made by any machine learning model. Here, we give an overview of\ninterpretability approaches and provide examples of practical interpretability\nof machine learning in different areas of healthcare, including prediction of\nhealth-related outcomes, optimizing treatments or improving the efficiency of\nscreening for specific conditions. Further, we outline future directions for\ninterpretable machine learning and highlight the importance of developing\nalgorithmic solutions that can enable machine-learning driven decision making\nin high-stakes healthcare problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:23:22 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 06:36:06 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Stiglic", "Gregor", ""], ["Kocbek", "Primoz", ""], ["Fijacko", "Nino", ""], ["Zitnik", "Marinka", ""], ["Verbert", "Katrien", ""], ["Cilar", "Leona", ""]]}, {"id": "2002.08599", "submitter": "Haggai Maron", "authors": "Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya", "title": "On Learning Sets of Symmetric Elements", "comments": "37th International Conference on Machine Learning, Vienna,2020,\n  Outstanding paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from unordered sets is a fundamental learning setup, recently\nattracting increasing attention. Research in this area has focused on the case\nwhere elements of the set are represented by feature vectors, and far less\nemphasis has been given to the common case where set elements themselves adhere\nto their own symmetries. That case is relevant to numerous applications, from\ndeblurring image bursts to multi-view 3D shape recognition and reconstruction.\nIn this paper, we present a principled approach to learning sets of general\nsymmetric elements. We first characterize the space of linear layers that are\nequivariant both to element reordering and to the inherent symmetries of\nelements, like translation in the case of images. We further show that networks\nthat are composed of these layers, called Deep Sets for Symmetric Elements\n(DSS) layers, are universal approximators of both invariant and equivariant\nfunctions, and that these networks are strictly more expressive than Siamese\nnetworks. DSS layers are also straightforward to implement. Finally, we show\nthat they improve over existing set-learning architectures in a series of\nexperiments with images, graphs, and point-clouds.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:29:20 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 06:15:15 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 09:28:48 GMT"}, {"version": "v4", "created": "Sun, 29 Nov 2020 07:34:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Maron", "Haggai", ""], ["Litany", "Or", ""], ["Chechik", "Gal", ""], ["Fetaya", "Ethan", ""]]}, {"id": "2002.08605", "submitter": "Harikrishna Narasimhan", "authors": "Qijia Jiang, Olaoluwa Adigun, Harikrishna Narasimhan, Mahdi Milani\n  Fard, Maya Gupta", "title": "Optimizing Black-box Metrics with Adaptive Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of training models with black-box and hard-to-optimize\nmetrics by expressing the metric as a monotonic function of a small number of\neasy-to-optimize surrogates. We pose the training problem as an optimization\nover a relaxed surrogate space, which we solve by estimating local gradients\nfor the metric and performing inexact convex projections. We analyze gradient\nestimates based on finite differences and local linear interpolations, and show\nconvergence of our approach under smoothness assumptions with respect to the\nsurrogates. Experimental results on classification and ranking problems verify\nthe proposal performs on par with methods that know the mathematical\nformulation, and adds notable value when the form of the metric is unknown.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:52:08 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Jiang", "Qijia", ""], ["Adigun", "Olaoluwa", ""], ["Narasimhan", "Harikrishna", ""], ["Fard", "Mahdi Milani", ""], ["Gupta", "Maya", ""]]}, {"id": "2002.08616", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel and Joachim Schreurs and Johan A.K. Suykens", "title": "Diversity sampling is an implicit regularization for kernel methods", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": "20-21", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have achieved very good performance on large scale regression\nand classification problems, by using the Nystr\\\"om method and preconditioning\ntechniques. The Nystr\\\"om approximation -- based on a subset of landmarks --\ngives a low rank approximation of the kernel matrix, and is known to provide a\nform of implicit regularization. We further elaborate on the impact of sampling\ndiverse landmarks for constructing the Nystr\\\"om approximation in supervised as\nwell as unsupervised kernel methods. By using Determinantal Point Processes for\nsampling, we obtain additional theoretical results concerning the interplay\nbetween diversity and regularization. Empirically, we demonstrate the\nadvantages of training kernel methods based on subsets made of diverse points.\nIn particular, if the dataset has a dense bulk and a sparser tail, we show that\nNystr\\\"om kernel regression with diverse landmarks increases the accuracy of\nthe regression in sparser regions of the dataset, with respect to a uniform\nlandmark sampling. A greedy heuristic is also proposed to select diverse\nsamples of significant size within large datasets when exact DPP sampling is\nnot practically feasible.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:24:42 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2002.08619", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Jun Zhu, Hang Su", "title": "Boosting Adversarial Training with Hypersphere Embedding", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is one of the most effective defenses against\nadversarial attacks for deep learning models. In this work, we advocate\nincorporating the hypersphere embedding (HE) mechanism into the AT procedure by\nregularizing the features onto compact manifolds, which constitutes a\nlightweight yet effective module to blend in the strength of representation\nlearning. Our extensive analyses reveal that AT and HE are well coupled to\nbenefit the robustness of the adversarially trained models from several\naspects. We validate the effectiveness and adaptability of HE by embedding it\ninto the popular AT frameworks including PGD-AT, ALP, and TRADES, as well as\nthe FreeAT and FastAT strategies. In the experiments, we evaluate our methods\nunder a wide range of adversarial attacks on the CIFAR-10 and ImageNet\ndatasets, which verifies that integrating HE can consistently enhance the model\nrobustness for each AT framework with little extra computation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:42:29 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 13:27:17 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 16:18:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Pang", "Tianyu", ""], ["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""], ["Su", "Hang", ""]]}, {"id": "2002.08621", "submitter": "Shangyuan Tong", "authors": "Shangyuan Tong, Timur Garipov, Tommi Jaakkola", "title": "The Benefits of Pairwise Discriminators for Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training methods typically align distributions by solving\ntwo-player games. However, in most current formulations, even if the generator\naligns perfectly with data, a sub-optimal discriminator can still drive the two\napart. Absent additional regularization, the instability can manifest itself as\na never-ending game. In this paper, we introduce a family of objectives by\nleveraging pairwise discriminators, and show that only the generator needs to\nconverge. The alignment, if achieved, would be preserved with any\ndiscriminator. We provide sufficient conditions for local convergence;\ncharacterize the capacity balance that should guide the discriminator and\ngenerator choices; and construct examples of minimally sufficient\ndiscriminators. Empirically, we illustrate the theory and the effectiveness of\nour approach on synthetic examples. Moreover, we show that practical methods\nderived from our approach can better generate higher-resolution images.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:43:59 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Tong", "Shangyuan", ""], ["Garipov", "Timur", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.08641", "submitter": "Tanya Motwani", "authors": "Tanya Motwani and Manojkumar Parmar", "title": "A Novel Framework for Selection of GANs for an Application", "comments": "11 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) is a current focal point of research.\nThe body of knowledge is fragmented, leading to a trial-error method while\nselecting an appropriate GAN for a given scenario. We provide a comprehensive\nsummary of the evolution of GANs starting from its inception addressing issues\nlike mode collapse, vanishing gradient, unstable training and non-convergence.\nWe also provide a comparison of various GANs from the application point of\nview, its behaviour and implementation details. We propose a novel framework to\nidentify candidate GANs for a specific use case based on architecture, loss,\nregularization and divergence. We also discuss application of the framework\nusing an example, and we demonstrate a significant reduction in search space.\nThis efficient way to determine potential GANs lowers unit economics of AI\ndevelopment for organizations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:51:48 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 09:48:42 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Motwani", "Tanya", ""], ["Parmar", "Manojkumar", ""]]}, {"id": "2002.08643", "submitter": "Hongyuan Zhang", "authors": "Hongyuan Zhang and Rui Zhang and Xuelong Li", "title": "Embedding Graph Auto-Encoder for Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering, aiming to partition nodes of a graph into various groups\nvia an unsupervised approach, is an attractive topic in recent years. To\nimprove the representative ability, several graph auto-encoder (GAE) models,\nwhich are based on semi-supervised graph convolution networks (GCN), have been\ndeveloped and they achieve good results compared with traditional clustering\nmethods. However, all existing methods either fail to utilize the orthogonal\nproperty of the representations generated by GAE, or separate the clustering\nand the learning of neural networks. We first prove that the relaxed k-means\nwill obtain an optimal partition in the inner-products used space. Driven by\ntheoretical analysis about relaxed k-means, we design a specific GAE-based\nmodel for graph clustering to be consistent with the theory, namely Embedding\nGraph Auto-Encoder (EGAE). Meanwhile, the learned representations are well\nexplainable such that the representations can be also used for other tasks. To\nfurther induce the neural network to produce deep features that are appropriate\nfor the specific clustering model, the relaxed k-means and GAE are learned\nsimultaneously. Therefore, the relaxed k-means can be equivalently regarded as\na decoder that attempts to learn representations that can be linearly\nconstructed by some centroid vectors. Accordingly, EGAE consists of one encoder\nand dual decoders. Extensive experiments are conducted to prove the superiority\nof EGAE and the corresponding theoretical analyses.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:53:28 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 08:07:29 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhang", "Hongyuan", ""], ["Zhang", "Rui", ""], ["Li", "Xuelong", ""]]}, {"id": "2002.08645", "submitter": "Alberto Tonda", "authors": "Pietro Barbiero, Giovanni Squillero, Alberto Tonda", "title": "Uncovering Coresets for Classification With Multi-Objective Evolutionary\n  Algorithms", "comments": "9 pages, 3 figures, conference. Submitted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A coreset is a subset of the training set, using which a machine learning\nalgorithm obtains performances similar to what it would deliver if trained over\nthe whole original data. Coreset discovery is an active and open line of\nresearch as it allows improving training speed for the algorithms and may help\nhuman understanding the results. Building on previous works, a novel approach\nis presented: candidate corsets are iteratively optimized, adding and removing\nsamples. As there is an obvious trade-off between limiting training size and\nquality of the results, a multi-objective evolutionary algorithm is used to\nminimize simultaneously the number of points in the set and the classification\nerror. Experimental results on non-trivial benchmarks show that the proposed\napproach is able to deliver results that allow a classifier to obtain lower\nerror and better ability of generalizing on unseen data than state-of-the-art\ncoreset discovery techniques.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:59:56 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Barbiero", "Pietro", ""], ["Squillero", "Giovanni", ""], ["Tonda", "Alberto", ""]]}, {"id": "2002.08648", "submitter": "Hongyuan Zhang", "authors": "Xuelong Li and Hongyuan Zhang and Rui Zhang", "title": "Adaptive Graph Auto-Encoder for General Data Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based clustering plays an important role in the clustering area. Recent\nstudies about graph convolution neural networks have achieved impressive\nsuccess on graph type data. However, in general clustering tasks, the graph\nstructure of data does not exist such that the strategy to construct a graph is\ncrucial for performance. Therefore, how to extend graph convolution networks\ninto general clustering tasks is an attractive problem. In this paper, we\npropose a graph auto-encoder for general data clustering, which constructs the\ngraph adaptively according to the generative perspective of graphs. The\nadaptive process is designed to induce the model to exploit the high-level\ninformation behind data and utilize the non-Euclidean structure sufficiently.\nWe further design a novel mechanism with rigorous analysis to avoid the\ncollapse caused by the adaptive construction. Via combining the generative\nmodel for network embedding and graph-based clustering, a graph auto-encoder\nwith a novel decoder is developed such that it performs well in weighted graph\nused scenarios. Extensive experiments prove the superiority of our model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:11:28 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 10:32:50 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 06:25:09 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 04:56:50 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Li", "Xuelong", ""], ["Zhang", "Hongyuan", ""], ["Zhang", "Rui", ""]]}, {"id": "2002.08663", "submitter": "Jonathan Scarlett", "authors": "Anamay Chaturvedi and Jonathan Scarlett", "title": "Learning Gaussian Graphical Models via Multiplicative Weights", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical model selection in Markov random fields is a fundamental problem in\nstatistics and machine learning. Two particularly prominent models, the Ising\nmodel and Gaussian model, have largely developed in parallel using different\n(though often related) techniques, and several practical algorithms with\nrigorous sample complexity bounds have been established for each. In this\npaper, we adapt a recently proposed algorithm of Klivans and Meka (FOCS, 2017),\nbased on the method of multiplicative weight updates, from the Ising model to\nthe Gaussian model, via non-trivial modifications to both the algorithm and its\nanalysis. The algorithm enjoys a sample complexity bound that is qualitatively\nsimilar to others in the literature, has a low runtime $O(mp^2)$ in the case of\n$m$ samples and $p$ nodes, and can trivially be implemented in an online\nmanner.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:50:58 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 03:07:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2002.08665", "submitter": "Calin Cruceru", "authors": "Calin Cruceru, Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Computationally Tractable Riemannian Manifolds for Graph Embeddings", "comments": "Submitted to the Thirty-fourth Conference on Neural Information\n  Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing graphs as sets of node embeddings in certain curved Riemannian\nmanifolds has recently gained momentum in machine learning due to their\ndesirable geometric inductive biases, e.g., hierarchical structures benefit\nfrom hyperbolic geometry. However, going beyond embedding spaces of constant\nsectional curvature, while potentially more representationally powerful, proves\nto be challenging as one can easily lose the appeal of computationally\ntractable tools such as geodesic distances or Riemannian gradients. Here, we\nexplore computationally efficient matrix manifolds, showcasing how to learn and\noptimize graph embeddings in these Riemannian spaces. Empirically, we\ndemonstrate consistent improvements over Euclidean geometry while often\noutperforming hyperbolic and elliptical embeddings based on various metrics\nthat capture different graph properties. Our results serve as new evidence for\nthe benefits of non-Euclidean embeddings in machine learning pipelines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:55:47 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 14:04:49 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Cruceru", "Calin", ""], ["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "2002.08675", "submitter": "You-Wei Luo", "authors": "You-Wei Luo, Chuan-Xian Ren, Pengfei Ge, Ke-Kun Huang, Yu-Feng Yu", "title": "Unsupervised Domain Adaptation via Discriminative Manifold Embedding and\n  Alignment", "comments": "Accepted to AAAI 2020. Code available:\n  \\<https://github.com/LavieLuo/DRMEA>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is effective in leveraging the rich\ninformation from the source domain to the unsupervised target domain. Though\ndeep learning and adversarial strategy make an important breakthrough in the\nadaptability of features, there are two issues to be further explored. First,\nthe hard-assigned pseudo labels on the target domain are risky to the intrinsic\ndata structure. Second, the batch-wise training manner in deep learning limits\nthe description of the global structure. In this paper, a Riemannian manifold\nlearning framework is proposed to achieve transferability and discriminability\nconsistently. As to the first problem, this method establishes a probabilistic\ndiscriminant criterion on the target domain via soft labels. Further, this\ncriterion is extended to a global approximation scheme for the second issue;\nsuch approximation is also memory-saving. The manifold metric alignment is\nexploited to be compatible with the embedding space. A theoretical error bound\nis derived to facilitate the alignment. Extensive experiments have been\nconducted to investigate the proposal and results of the comparison study\nmanifest the superiority of consistent manifold learning framework.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:06:41 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:36:53 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Luo", "You-Wei", ""], ["Ren", "Chuan-Xian", ""], ["Ge", "Pengfei", ""], ["Huang", "Ke-Kun", ""], ["Yu", "Yu-Feng", ""]]}, {"id": "2002.08676", "submitter": "Quentin Berthet", "authors": "Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi,\n  Jean-Philippe Vert, Francis Bach", "title": "Learning with Differentiable Perturbed Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning pipelines often rely on optimization procedures to make\ndiscrete decisions (e.g., sorting, picking closest neighbors, or shortest\npaths). Although these discrete decisions are easily computed, they break the\nback-propagation of computational graphs. In order to expand the scope of\nlearning problems that can be solved in an end-to-end fashion, we propose a\nsystematic method to transform optimizers into operations that are\ndifferentiable and never locally constant. Our approach relies on\nstochastically perturbed optimizers, and can be used readily together with\nexisting solvers. Their derivatives can be evaluated efficiently, and\nsmoothness tuned via the chosen noise amplitude. We also show how this\nframework can be connected to a family of losses developed in structured\nprediction, and give theoretical guarantees for their use in learning tasks. We\ndemonstrate experimentally the performance of our approach on various tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:11:32 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:09:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Berthet", "Quentin", ""], ["Blondel", "Mathieu", ""], ["Teboul", "Olivier", ""], ["Cuturi", "Marco", ""], ["Vert", "Jean-Philippe", ""], ["Bach", "Francis", ""]]}, {"id": "2002.08681", "submitter": "Yabin Zhang", "authors": "Yabin Zhang, Bin Deng, Hui Tang, Lei Zhang, and Kui Jia", "title": "Unsupervised Multi-Class Domain Adaptation: Theory, Algorithms, and\n  Practice", "comments": "CVPR extension; TPAMI camera ready version:\n  https://ieeexplore.ieee.org/document/9253700; IEEE copyright; Codes are\n  available at: https://github.com/YBZh/MultiClassDA", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (TPAMI),10 November 2020", "doi": "10.1109/TPAMI.2020.3036956", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the formalism of unsupervised multi-class domain\nadaptation (multi-class UDA), which underlies a few recent algorithms whose\nlearning objectives are only motivated empirically. Multi-Class Scoring\nDisagreement (MCSD) divergence is presented by aggregating the absolute margin\nviolations in multi-class classification, and this proposed MCSD is able to\nfully characterize the relations between any pair of multi-class scoring\nhypotheses. By using MCSD as a measure of domain distance, we develop a new\ndomain adaptation bound for multi-class UDA; its data-dependent, probably\napproximately correct bound is also developed that naturally suggests\nadversarial learning objectives to align conditional feature distributions\nacross source and target domains. Consequently, an algorithmic framework of\nMulti-class Domain-adversarial learning Networks (McDalNets) is developed, and\nits different instantiations via surrogate learning objectives either coincide\nwith or resemble a few recently popular methods, thus (partially) underscoring\ntheir practical effectiveness. Based on our identical theory for multi-class\nUDA, we also introduce a new algorithm of Domain-Symmetric Networks (SymmNets),\nwhich is featured by a novel adversarial strategy of domain confusion and\ndiscrimination. SymmNets affords simple extensions that work equally well under\nthe problem settings of either closed set, partial, or open set UDA. We conduct\ncareful empirical studies to compare different algorithms of McDalNets and our\nnewly introduced SymmNets. Experiments verify our theoretical analysis and show\nthe efficacy of our proposed SymmNets. In addition, we have made our\nimplementation code publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:26:45 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 09:36:34 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhang", "Yabin", ""], ["Deng", "Bin", ""], ["Tang", "Hui", ""], ["Zhang", "Lei", ""], ["Jia", "Kui", ""]]}, {"id": "2002.08695", "submitter": "Quentin Berthet", "authors": "Marin Ballu, Quentin Berthet, Francis Bach", "title": "Stochastic Optimization for Regularized Wasserstein Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport is a foundational problem in optimization, that allows to\ncompare probability distributions while taking into account geometric aspects.\nIts optimal objective value, the Wasserstein distance, provides an important\nloss between distributions that has been used in many applications throughout\nmachine learning and statistics. Recent algorithmic progress on this problem\nand its regularized versions have made these tools increasingly popular.\nHowever, existing techniques require solving an optimization problem to obtain\na single gradient of the loss, thus slowing down first-order methods to\nminimize the sum of losses, that require many such gradient computations. In\nthis work, we introduce an algorithm to solve a regularized version of this\nproblem of Wasserstein estimators, with a time per step which is sublinear in\nthe natural dimensions of the problem. We introduce a dual formulation, and\noptimize it with stochastic gradient steps that can be computed directly from\nsamples, without solving additional optimization problems at each step. Doing\nso, the estimation and computation tasks are performed jointly. We show that\nthis algorithm can be extended to other tasks, including estimation of\nWasserstein barycenters. We provide theoretical guarantees and illustrate the\nperformance of our algorithm with experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 12:04:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ballu", "Marin", ""], ["Berthet", "Quentin", ""], ["Bach", "Francis", ""]]}, {"id": "2002.08697", "submitter": "Valentin Radu", "authors": "Valentin Radu, Kuba Kaszyk, Yuan Wen, Jack Turner, Jose Cano, Elliot\n  J. Crowley, Bjorn Franke, Amos Storkey, Michael O'Boyle", "title": "Performance Aware Convolutional Neural Network Channel Pruning for\n  Embedded GPUs", "comments": "A copy of this was published in IISWC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) are becoming a common presence in many\napplications and services, due to their superior recognition accuracy. They are\nincreasingly being used on mobile devices, many times just by porting large\nmodels designed for server space, although several model compression techniques\nhave been considered. One model compression technique intended to reduce\ncomputations is channel pruning. Mobile and embedded systems now have GPUs\nwhich are ideal for the parallel computations of neural networks and for their\nlower energy cost per operation. Specialized libraries perform these neural\nnetwork computations through highly optimized routines. As we find in our\nexperiments, these libraries are optimized for the most common network shapes,\nmaking uninstructed channel pruning inefficient. We evaluate higher level\nlibraries, which analyze the input characteristics of a convolutional layer,\nbased on which they produce optimized OpenCL (Arm Compute Library and TVM) and\nCUDA (cuDNN) code. However, in reality, these characteristics and subsequent\nchoices intended for optimization can have the opposite effect. We show that a\nreduction in the number of convolutional channels, pruning 12% of the initial\nsize, is in some cases detrimental to performance, leading to 2x slowdown. On\nthe other hand, we also find examples where performance-aware pruning achieves\nthe intended results, with performance speedups of 3x with cuDNN and above 10x\nwith Arm Compute Library and TVM. Our findings expose the need for\nhardware-instructed neural network pruning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 12:07:44 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Radu", "Valentin", ""], ["Kaszyk", "Kuba", ""], ["Wen", "Yuan", ""], ["Turner", "Jack", ""], ["Cano", "Jose", ""], ["Crowley", "Elliot J.", ""], ["Franke", "Bjorn", ""], ["Storkey", "Amos", ""], ["O'Boyle", "Michael", ""]]}, {"id": "2002.08709", "submitter": "Takashi Ishida", "authors": "Takashi Ishida, Ikko Yamane, Tomoya Sakai, Gang Niu, and Masashi\n  Sugiyama", "title": "Do We Need Zero Training Loss After Achieving Zero Training Error?", "comments": "ICML 2020 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized deep networks have the capacity to memorize training data\nwith zero \\emph{training error}. Even after memorization, the \\emph{training\nloss} continues to approach zero, making the model overconfident and the test\nperformance degraded. Since existing regularizers do not directly aim to avoid\nzero training loss, it is hard to tune their hyperparameters in order to\nmaintain a fixed/preset level of training loss. We propose a direct solution\ncalled \\emph{flooding} that intentionally prevents further reduction of the\ntraining loss when it reaches a reasonably small value, which we call the\n\\emph{flood level}. Our approach makes the loss float around the flood level by\ndoing mini-batched gradient descent as usual but gradient ascent if the\ntraining loss is below the flood level. This can be implemented with one line\nof code and is compatible with any stochastic optimizer and other regularizers.\nWith flooding, the model will continue to \"random walk\" with the same non-zero\ntraining loss, and we expect it to drift into an area with a flat loss\nlandscape that leads to better generalization. We experimentally show that\nflooding improves performance and, as a byproduct, induces a double descent\ncurve of the test loss.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 12:50:49 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 07:22:24 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Ishida", "Takashi", ""], ["Yamane", "Ikko", ""], ["Sakai", "Tomoya", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.08724", "submitter": "Milana Gataric", "authors": "Milana Gataric", "title": "High-resolution signal recovery via generalized sampling and functional\n  principal component analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA eess.SP math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a computational framework for recovering a\nhigh-resolution approximation of an unknown function from its low-resolution\nindirect measurements as well as high-resolution training observations by\nmerging the frameworks of generalized sampling and functional principal\ncomponent analysis. In particular, we increase the signal resolution via a data\ndriven approach, which models the function of interest as a realization of a\nrandom field and leverages a training set of observations generated via the\nsame underlying random process. We study the performance of the resulting\nestimation procedure and show that high-resolution recovery is indeed possible\nprovided appropriate low-rank and angle conditions hold and provided the\ntraining set is sufficiently large relative to the desired resolution.\nMoreover, we show that the size of the training set can be reduced by\nleveraging sparse representations of the functional principal components.\nFurthermore, the effectiveness of the proposed reconstruction procedure is\nillustrated by various numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:44:24 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 17:38:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gataric", "Milana", ""]]}, {"id": "2002.08740", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson", "title": "Towards Certifiable Adversarial Sample Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) are deployed in more and more\nclassification systems, but adversarial samples can be maliciously crafted to\ntrick them, and are becoming a real threat. There have been various proposals\nto improve CNNs' adversarial robustness but these all suffer performance\npenalties or other limitations. In this paper, we provide a new approach in the\nform of a certifiable adversarial detection scheme, the Certifiable Taboo Trap\n(CTT). The system can provide certifiable guarantees of detection of\nadversarial inputs for certain $l_{\\infty}$ sizes on a reasonable assumption,\nnamely that the training data have the same distribution as the test data. We\ndevelop and evaluate several versions of CTT with a range of defense\ncapabilities, training overheads and certifiability on adversarial samples.\nAgainst adversaries with various $l_p$ norms, CTT outperforms existing defense\nmethods that focus purely on improving network robustness. We show that CTT has\nsmall false positive rates on clean test data, minimal compute overheads when\ndeployed, and can support complex security policies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:10:00 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2002.08762", "submitter": "Konstantinos Bougiatiotis", "authors": "K. Bougiatiotis, R. Fasoulis, F. Aisopos, A. Nentidis, G. Paliouras", "title": "Guiding Graph Embeddings using Path-Ranking Methods for Error Detection\n  innoisy Knowledge Graphs", "comments": "9 pages, 2 figures. To appear in GCLR 2021: AAAI 2021 Workshop on\n  Graphs and more Complex structures for Learning and Reasonin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays Knowledge Graphs constitute a mainstream approach for the\nrepresentation of relational information on big heterogeneous data, however,\nthey may contain a big amount of imputed noise when constructed automatically.\nTo address this problem, different error detection methodologies have been\nproposed, mainly focusing on path ranking and representation learning. This\nwork presents various mainstream approaches and proposes a hybrid and modular\nmethodology for the task. We compare different methods on two benchmarks and\none real-world biomedical publications dataset, showcasing the potential of our\napproach and providing insights on graph embeddings when dealing with noisy\nKnowledge Graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:04:11 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 20:43:10 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bougiatiotis", "K.", ""], ["Fasoulis", "R.", ""], ["Aisopos", "F.", ""], ["Nentidis", "A.", ""], ["Paliouras", "G.", ""]]}, {"id": "2002.08772", "submitter": "Yaron Lipman", "authors": "Hadar Serviansky, Nimrod Segol, Jonathan Shlomi, Kyle Cranmer, Eilam\n  Gross, Haggai Maron, Yaron Lipman", "title": "Set2Graph: Learning Graphs From Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning can be cast as learning functions from sets\nto graphs, or more generally to hypergraphs; in short, Set2Graph functions.\nExamples include clustering, learning vertex and edge features on graphs, and\nlearning features on triplets in a collection. A natural approach for building\nSet2Graph models is to characterize all linear equivariant set-to-hypergraph\nlayers and stack them with non-linear activations. This poses two challenges:\n(i) the expressive power of these networks is not well understood; and (ii)\nthese models would suffer from high, often intractable computational and memory\ncomplexity, as their dimension grows exponentially. This paper advocates a\nfamily of neural network models for learning Set2Graph functions that is both\npractical and of maximal expressive power (universal), that is, can approximate\narbitrary continuous Set2Graph functions over compact sets. Testing these\nmodels on different machine learning tasks, mainly an application to particle\nphysics, we find them favorable to existing baselines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:53:20 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 07:28:05 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 08:17:03 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Serviansky", "Hadar", ""], ["Segol", "Nimrod", ""], ["Shlomi", "Jonathan", ""], ["Cranmer", "Kyle", ""], ["Gross", "Eilam", ""], ["Maron", "Haggai", ""], ["Lipman", "Yaron", ""]]}, {"id": "2002.08774", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel and Marco Avella-Medina", "title": "Propose, Test, Release: Differentially private estimation with high\n  probability", "comments": "arXiv admin note: text overlap with arXiv:1906.11923", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive concentration inequalities for differentially private median and\nmean estimators building on the \"Propose, Test, Release\" (PTR) mechanism\nintroduced by Dwork and Lei (2009). We introduce a new general version of the\nPTR mechanism that allows us to derive high probability error bounds for\ndifferentially private estimators. Our algorithms provide the first statistical\nguarantees for differentially private estimation of the median and mean without\nany boundedness assumptions on the data, and without assuming that the target\npopulation parameter lies in some known bounded interval. Our procedures do not\nrely on any truncation of the data and provide the first sub-Gaussian high\nprobability bounds for differentially private median and mean estimation, for\npossibly heavy tailed random variables.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:29:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""], ["Avella-Medina", "Marco", ""]]}, {"id": "2002.08782", "submitter": "Elsa Rizk", "authors": "Elsa Rizk, Stefan Vlaski, Ali H. Sayed", "title": "Dynamic Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has emerged as an umbrella term for centralized\ncoordination strategies in multi-agent environments. While many federated\nlearning architectures process data in an online manner, and are hence adaptive\nby nature, most performance analyses assume static optimization problems and\noffer no guarantees in the presence of drifts in the problem solution or data\ncharacteristics. We consider a federated learning model where at every\niteration, a random subset of available agents perform local updates based on\ntheir data. Under a non-stationary random walk model on the true minimizer for\nthe aggregate optimization problem, we establish that the performance of the\narchitecture is determined by three factors, namely, the data variability at\neach agent, the model variability across all agents, and a tracking term that\nis inversely proportional to the learning rate of the algorithm. The results\nclarify the trade-off between convergence and tracking performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:00:54 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 09:26:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Rizk", "Elsa", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2002.08791", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Pavel Izmailov", "title": "Bayesian Deep Learning and a Probabilistic Perspective of Generalization", "comments": "30 pages, 19 figures. Updated to add new results showing Bayesian\n  model averaging mitigates double descent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key distinguishing property of a Bayesian approach is marginalization,\nrather than using a single setting of weights. Bayesian marginalization can\nparticularly improve the accuracy and calibration of modern deep neural\nnetworks, which are typically underspecified by the data, and can represent\nmany compelling but different solutions. We show that deep ensembles provide an\neffective mechanism for approximate Bayesian marginalization, and propose a\nrelated approach that further improves the predictive distribution by\nmarginalizing within basins of attraction, without significant overhead. We\nalso investigate the prior over functions implied by a vague distribution over\nneural network weights, explaining the generalization properties of such models\nfrom a probabilistic perspective. From this perspective, we explain results\nthat have been presented as mysterious and distinct to neural network\ngeneralization, such as the ability to fit images with random labels, and show\nthat these results can be reproduced with Gaussian processes. We also show that\nBayesian model averaging alleviates double descent, resulting in monotonic\nperformance improvements with increased flexibility. Finally, we provide a\nBayesian perspective on tempering for calibrating predictive distributions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:13:27 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 17:46:10 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 14:59:55 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Izmailov", "Pavel", ""]]}, {"id": "2002.08797", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, Yee Whye Teh", "title": "Robust Pruning at Initialization", "comments": "37 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized Neural Networks (NN) display state-of-the-art performance.\nHowever, there is a growing need for smaller, energy-efficient, neural networks\ntobe able to use machine learning applications on devices with limited\ncomputational resources. A popular approach consists of using pruning\ntechniques. While these techniques have traditionally focused on pruning\npre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et\nal. (2018) has shown promising results when pruning at initialization. However,\nfor Deep NNs, such procedures remain unsatisfactory as the resulting pruned\nnetworks can be difficult to train and, for instance, they do not prevent one\nlayer from being fully pruned. In this paper, we provide a comprehensive\ntheoretical analysis of Magnitude and Gradient based pruning at initialization\nand training of sparse architectures. This allows us to propose novel\nprincipled approaches which we validate experimentally on a variety of NN\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:09:50 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 18:26:19 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 11:14:29 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 17:12:50 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 22:43:36 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hayou", "Soufiane", ""], ["Ton", "Jean-Francois", ""], ["Doucet", "Arnaud", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2002.08799", "submitter": "Carlo Ciliberto", "authors": "Ruohan Wang, Yiannis Demiris, Carlo Ciliberto", "title": "Structured Prediction for Conditional Meta-Learning", "comments": "25 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of optimization-based meta-learning is to find a single\ninitialization shared across a distribution of tasks to speed up the process of\nlearning new tasks. Conditional meta-learning seeks task-specific\ninitialization to better capture complex task distributions and improve\nperformance. However, many existing conditional methods are difficult to\ngeneralize and lack theoretical guarantees. In this work, we propose a new\nperspective on conditional meta-learning via structured prediction. We derive\ntask-adaptive structured meta-learning (TASML), a principled framework that\nyields task-specific objective functions by weighing meta-training data on\ntarget tasks. Our non-parametric approach is model-agnostic and can be combined\nwith existing meta-learning methods to achieve conditioning. Empirically, we\nshow that TASML improves the performance of existing meta-learning models, and\noutperforms the state-of-the-art on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:24:15 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 17:18:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Ruohan", ""], ["Demiris", "Yiannis", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2002.08803", "submitter": "Ruohan Wang", "authors": "Ruohan Wang, Carlo Ciliberto, Pierluigi Amadori, Yiannis Demiris", "title": "Support-weighted Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Imitation Learning (AIL) is a broad family of imitation learning\nmethods designed to mimic expert behaviors from demonstrations. While AIL has\nshown state-of-the-art performance on imitation learning with only small number\nof demonstrations, it faces several practical challenges such as potential\ntraining instability and implicit reward bias. To address the challenges, we\npropose Support-weighted Adversarial Imitation Learning (SAIL), a general\nframework that extends a given AIL algorithm with information derived from\nsupport estimation of the expert policies. SAIL improves the quality of the\nreinforcement signals by weighing the adversarial reward with a confidence\nscore from support estimation of the expert policy. We also show that SAIL is\nalways at least as efficient as the underlying AIL algorithm that SAIL uses for\nlearning the adversarial reward. Empirically, we show that the proposed method\nachieves better performance and training stability than baseline methods on a\nwide range of benchmark control tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:34:30 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Ruohan", ""], ["Ciliberto", "Carlo", ""], ["Amadori", "Pierluigi", ""], ["Demiris", "Yiannis", ""]]}, {"id": "2002.08837", "submitter": "Chara Podimata", "authors": "Rupert Freeman, David M. Pennock, Chara Podimata, and Jennifer Wortman\n  Vaughan", "title": "No-Regret and Incentive-Compatible Online Learning", "comments": "Appears in ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning settings in which experts act strategically to\nmaximize their influence on the learning algorithm's predictions by potentially\nmisreporting their beliefs about a sequence of binary events. Our goal is\ntwofold. First, we want the learning algorithm to be no-regret with respect to\nthe best fixed expert in hindsight. Second, we want incentive compatibility, a\nguarantee that each expert's best strategy is to report his true beliefs about\nthe realization of each event. To achieve this goal, we build on the literature\non wagering mechanisms, a type of multi-agent scoring rule. We provide\nalgorithms that achieve no regret and incentive compatibility for myopic\nexperts for both the full and partial information settings. In experiments on\ndatasets from FiveThirtyEight, our algorithms have regret comparable to classic\nno-regret algorithms, which are not incentive-compatible. Finally, we identify\nan incentive-compatible algorithm for forward-looking strategic agents that\nexhibits diminishing regret in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:21:34 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 18:57:41 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Freeman", "Rupert", ""], ["Pennock", "David M.", ""], ["Podimata", "Chara", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "2002.08838", "submitter": "Adel Bibi", "authors": "Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar and Bernard\n  Ghanem", "title": "On the Decision Boundaries of Neural Networks: A Tropical Geometry\n  Perspective", "comments": "First two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of characterizing and understanding the\ndecision boundaries of neural networks with piecewise linear non-linearity\nactivations. We use tropical geometry, a new development in the area of\nalgebraic geometry, to characterize the decision boundaries of a simple network\nof the form (Affine, ReLU, Affine). Our main finding is that the decision\nboundaries are a subset of a tropical hypersurface, which is intimately related\nto a polytope formed by the convex hull of two zonotopes. The generators of\nthese zonotopes are functions of the network parameters. This geometric\ncharacterization provides new perspectives to three tasks. (i) We propose a new\ntropical perspective to the lottery ticket hypothesis, where we view the effect\nof different initializations on the tropical geometric representation of a\nnetwork's decision boundaries. (ii) Moreover, we propose new tropical based\noptimization reformulations that directly influence the decision boundaries of\nthe network for the task of network pruning. (iii) At last, we discuss the\nreformulation of the generation of adversarial attacks in a tropical sense. We\ndemonstrate that one can construct adversaries in a new tropical setting by\nperturbing a specific set of decision boundaries by perturbing a set of\nparameters in the network.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:22:44 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 17:03:45 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Alfarra", "Motasem", ""], ["Bibi", "Adel", ""], ["Hammoud", "Hasan", ""], ["Gaafar", "Mohamed", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2002.08853", "submitter": "Yiming Xu", "authors": "Ruijian Han, Yiming Xu and Kani Chen", "title": "A General Pairwise Comparison Model for Extremely Sparse Networks", "comments": "25 pages, 4 figures, included more numerical simulations, changed\n  some phrasing in the statements and updated citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference using pairwise comparison data has been an effective\napproach to analyzing complex and sparse networks. In this paper we propose a\ngeneral framework for modeling the mutual interaction in a network, which\nenjoys ample flexibility in terms of parametrization. Within this setup, we\nestablish that the maximum likelihood estimator (MLE) for the latent scores of\nthe subjects is uniformly consistent under a near-minimal condition on network\nsparsity. This condition is sharp in terms of the leading order asymptotics\ndescribing the sparsity. The proof utilizes a novel chaining technique based on\nthe error-induced metric as well as careful counting of comparison graph\nstructures. Our results guarantee that the MLE is a valid estimator for\ninference in large-scale comparison networks where data is asymptotically\ndeficient. Numerical simulations are provided to complement the theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:39:55 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 17:29:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Han", "Ruijian", ""], ["Xu", "Yiming", ""], ["Chen", "Kani", ""]]}, {"id": "2002.08856", "submitter": "Thomas Flynn", "authors": "Thomas Flynn, Kwang Min Yu, Abid Malik, Nicolas D'Imperio, Shinjae Yoo", "title": "Bounding the expected run-time of nonconvex optimization with early\n  stopping", "comments": "Camera ready version for UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the convergence of stochastic gradient-based optimization\nalgorithms that use early stopping based on a validation function. The form of\nearly stopping we consider is that optimization terminates when the norm of the\ngradient of a validation function falls below a threshold. We derive conditions\nthat guarantee this stopping rule is well-defined, and provide bounds on the\nexpected number of iterations and gradient evaluations needed to meet this\ncriterion. The guarantee accounts for the distance between the training and\nvalidation sets, measured with the Wasserstein distance. We develop the\napproach in the general setting of a first-order optimization algorithm, with\npossibly biased update directions subject to a geometric drift condition. We\nthen derive bounds on the expected running time for early stopping variants of\nseveral algorithms, including stochastic gradient descent (SGD), decentralized\nSGD (DSGD), and the stochastic variance reduced gradient (SVRG) algorithm.\nFinally, we consider the generalization properties of the iterate returned by\nearly stopping.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:43:37 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 20:50:55 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 15:27:06 GMT"}, {"version": "v4", "created": "Wed, 22 Jul 2020 17:56:23 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Flynn", "Thomas", ""], ["Yu", "Kwang Min", ""], ["Malik", "Abid", ""], ["D'Imperio", "Nicolas", ""], ["Yoo", "Shinjae", ""]]}, {"id": "2002.08859", "submitter": "Eitan Richardson", "authors": "Eitan Richardson and Yair Weiss", "title": "A Bayes-Optimal View on Adversarial Examples", "comments": "Minor revision per journal review, 28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since the discovery of adversarial examples - the ability to fool modern CNN\nclassifiers with tiny perturbations of the input, there has been much\ndiscussion whether they are a \"bug\" that is specific to current neural\narchitectures and training methods or an inevitable \"feature\" of high\ndimensional geometry. In this paper, we argue for examining adversarial\nexamples from the perspective of Bayes-Optimal classification. We construct\nrealistic image datasets for which the Bayes-Optimal classifier can be\nefficiently computed and derive analytic conditions on the distributions under\nwhich these classifiers are provably robust against any adversarial attack even\nin high dimensions. Our results show that even when these \"gold standard\"\noptimal classifiers are robust, CNNs trained on the same datasets consistently\nlearn a vulnerable classifier, indicating that adversarial examples are often\nan avoidable \"bug\". We further show that RBF SVMs trained on the same data\nconsistently learn a robust classifier. The same trend is observed in\nexperiments with real images in different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:43:47 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 09:47:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Richardson", "Eitan", ""], ["Weiss", "Yair", ""]]}, {"id": "2002.08860", "submitter": "Biswadip Dey", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "title": "Dissipative SymODEN: Encoding Hamiltonian Dynamics with Dissipation and\n  Control into Deep Learning", "comments": "Published at ICLR 2020 Workshop on Integration of Deep Neural Models\n  and Differential Equations (DeepDiffEq)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce Dissipative SymODEN, a deep learning architecture\nwhich can infer the dynamics of a physical system with dissipation from\nobserved state trajectories. To improve prediction accuracy while reducing\nnetwork size, Dissipative SymODEN encodes the port-Hamiltonian dynamics with\nenergy dissipation and external input into the design of its computation graph\nand learns the dynamics in a structured way. The learned model, by revealing\nkey aspects of the system, such as the inertia, dissipation, and potential\nenergy, paves the way for energy-based controllers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:44:10 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 03:59:58 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 02:53:24 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Dey", "Biswadip", ""], ["Chakraborty", "Amit", ""]]}, {"id": "2002.08871", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Olivier Teboul, Quentin Berthet, Josip Djolonga", "title": "Fast Differentiable Sorting and Ranking", "comments": "In proceedings of ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sorting operation is one of the most commonly used building blocks in\ncomputer programming. In machine learning, it is often used for robust\nstatistics. However, seen as a function, it is piecewise linear and as a result\nincludes many kinks where it is non-differentiable. More problematic is the\nrelated ranking operator, often used for order statistics and ranking metrics.\nIt is a piecewise constant function, meaning that its derivatives are null or\nundefined. While numerous works have proposed differentiable proxies to sorting\nand ranking, they do not achieve the $O(n \\log n)$ time complexity one would\nexpect from sorting and ranking operations. In this paper, we propose the first\ndifferentiable sorting and ranking operators with $O(n \\log n)$ time and $O(n)$\nspace complexity. Our proposal in addition enjoys exact computation and\ndifferentiation. We achieve this feat by constructing differentiable operators\nas projections onto the permutahedron, the convex hull of permutations, and\nusing a reduction to isotonic optimization. Empirically, we confirm that our\napproach is an order of magnitude faster than existing approaches and showcase\ntwo novel applications: differentiable Spearman's rank correlation coefficient\nand least trimmed squares.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:11:09 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:11:03 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Blondel", "Mathieu", ""], ["Teboul", "Olivier", ""], ["Berthet", "Quentin", ""], ["Djolonga", "Josip", ""]]}, {"id": "2002.08898", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Peter Ku, Anuj Kumar Goyal, Angeliki Metallinou, Dilek\n  Hakkani-Tur", "title": "MA-DST: Multi-Attention Based Scalable Dialog State Tracking", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented dialog agents provide a natural language interface for users to\ncomplete their goal. Dialog State Tracking (DST), which is often a core\ncomponent of these systems, tracks the system's understanding of the user's\ngoal throughout the conversation. To enable accurate multi-domain DST, the\nmodel needs to encode dependencies between past utterances and slot semantics\nand understand the dialog context, including long-range cross-domain\nreferences. We introduce a novel architecture for this task to encode the\nconversation history and slot semantics more robustly by using attention\nmechanisms at multiple granularities. In particular, we use cross-attention to\nmodel relationships between the context and slots at different semantic levels\nand self-attention to resolve cross-domain coreferences. In addition, our\nproposed architecture does not rely on knowing the domain ontologies beforehand\nand can also be used in a zero-shot setting for new domains or unseen slot\nvalues. Our model improves the joint goal accuracy by 5% (absolute) in the\nfull-data setting and by up to 2% (absolute) in the zero-shot setting over the\npresent state-of-the-art on the MultiWoZ 2.1 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 05:34:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kumar", "Adarsh", ""], ["Ku", "Peter", ""], ["Goyal", "Anuj Kumar", ""], ["Metallinou", "Angeliki", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2002.08902", "submitter": "Yu Wang", "authors": "Yu Wang, Yining Sun, Zuchang Ma, Lisheng Gao, Yang Xu, Ting Sun", "title": "Application of Pre-training Models in Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is a fundamental Natural Language Processing\n(NLP) task to extract entities from unstructured data. The previous methods for\nNER were based on machine learning or deep learning. Recently, pre-training\nmodels have significantly improved performance on multiple NLP tasks. In this\npaper, firstly, we introduce the architecture and pre-training tasks of four\ncommon pre-training models: BERT, ERNIE, ERNIE2.0-tiny, and RoBERTa. Then, we\napply these pre-training models to a NER task by fine-tuning, and compare the\neffects of the different model architecture and pre-training tasks on the NER\ntask. The experiment results showed that RoBERTa achieved state-of-the-art\nresults on the MSRA-2006 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 08:18:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Yu", ""], ["Sun", "Yining", ""], ["Ma", "Zuchang", ""], ["Gao", "Lisheng", ""], ["Xu", "Yang", ""], ["Sun", "Ting", ""]]}, {"id": "2002.08907", "submitter": "Alejandro Carderera", "authors": "Alejandro Carderera and Sebastian Pokutta", "title": "Second-order Conditional Gradient Sliding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained second-order convex optimization algorithms are the method of\nchoice when a high accuracy solution to a problem is needed, due to their local\nquadratic convergence. These algorithms require the solution of a constrained\nquadratic subproblem at every iteration. We present the \\emph{Second-Order\nConditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free\nalgorithm to solve the constrained quadratic subproblems inexactly. When the\nfeasible region is a polytope the algorithm converges quadratically in primal\ngap after a finite number of linearly convergent iterations. Once in the\nquadratic regime the SOCGS algorithm requires $\\mathcal{O}(\\log(\\log\n1/\\varepsilon))$ first-order and Hessian oracle calls and $\\mathcal{O}(\\log\n(1/\\varepsilon) \\log(\\log1/\\varepsilon))$ linear minimization oracle calls to\nachieve an $\\varepsilon$-optimal solution. This algorithm is useful when the\nfeasible region can only be accessed efficiently through a linear optimization\noracle, and computing first-order information of the function, although\npossible, is costly.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:52:18 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:57:53 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Carderera", "Alejandro", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2002.08910", "submitter": "Colin Raffel", "authors": "Adam Roberts, Colin Raffel, and Noam Shazeer", "title": "How Much Knowledge Can You Pack Into the Parameters of a Language Model?", "comments": "Camera-ready version for EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been observed that neural language models trained on\nunstructured text can implicitly store and retrieve knowledge using natural\nlanguage queries. In this short paper, we measure the practical utility of this\napproach by fine-tuning pre-trained models to answer questions without access\nto any external context or knowledge. We show that this approach scales with\nmodel size and performs competitively with open-domain systems that explicitly\nretrieve answers from an external knowledge source when answering questions. To\nfacilitate reproducibility and future work, we release our code and trained\nmodels at https://goo.gle/t5-cbqa.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:55:58 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 04:54:34 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 16:04:06 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 21:26:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roberts", "Adam", ""], ["Raffel", "Colin", ""], ["Shazeer", "Noam", ""]]}, {"id": "2002.08927", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Ben Poole, Kevin Murphy", "title": "Regularized Autoencoders via Relaxed Injective Probability Flow", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invertible flow-based generative models are an effective method for learning\nto generate samples, while allowing for tractable likelihood computation and\ninference. However, the invertibility requirement restricts models to have the\nsame latent dimensionality as the inputs. This imposes significant\narchitectural, memory, and computational costs, making them more challenging to\nscale than other classes of generative models such as Variational Autoencoders\n(VAEs). We propose a generative model based on probability flows that does away\nwith the bijectivity requirement on the model and only assumes injectivity.\nThis also provides another perspective on regularized autoencoders (RAEs), with\nour final objectives resembling RAEs with specific regularizers that are\nderived by lower bounding the probability flow objective. We empirically\ndemonstrate the promise of the proposed model, improving over VAEs and AEs in\nterms of sample quality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:22:46 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kumar", "Abhishek", ""], ["Poole", "Ben", ""], ["Murphy", "Kevin", ""]]}, {"id": "2002.08930", "submitter": "Jihoon Moon", "authors": "J. H. Moon, Debasmit Das and C. S. George Lee", "title": "Multi-step Online Unsupervised Domain Adaptation", "comments": "To appear in ICASSP 2020. Copyright 2020 IEEE", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9052976", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the Online Unsupervised Domain Adaptation (OUDA)\nproblem, where the target data are unlabelled and arriving sequentially. The\ntraditional methods on the OUDA problem mainly focus on transforming each\narriving target data to the source domain, and they do not sufficiently\nconsider the temporal coherency and accumulative statistics among the arriving\ntarget data. We propose a multi-step framework for the OUDA problem, which\ninstitutes a novel method to compute the mean-target subspace inspired by the\ngeometrical interpretation on the Euclidean space. This mean-target subspace\ncontains accumulative temporal information among the arrived target data.\nMoreover, the transformation matrix computed from the mean-target subspace is\napplied to the next target data as a preprocessing step, aligning the target\ndata closer to the source domain. Experiments on four datasets demonstrated the\ncontribution of each step in our proposed multi-step OUDA framework and its\nperformance over previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:26:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Moon", "J. H.", ""], ["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "2002.08933", "submitter": "Neil Zeghidour", "authors": "Neil Zeghidour and David Grangier", "title": "Wavesplit: End-to-End Speech Separation by Speaker Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Wavesplit, an end-to-end source separation system. From a single\nmixture, the model infers a representation for each source and then estimates\neach source signal given the inferred representations. The model is trained to\njointly perform both tasks from the raw waveform. Wavesplit infers a set of\nsource representations via clustering, which addresses the fundamental\npermutation problem of separation. For speech separation, our sequence-wide\nspeaker representations provide a more robust separation of long, challenging\nrecordings compared to prior work. Wavesplit redefines the state-of-the-art on\nclean mixtures of 2 or 3 speakers (WSJ0-2/3mix), as well as in noisy and\nreverberated settings (WHAM/WHAMR). We also set a new benchmark on the recent\nLibriMix dataset. Finally, we show that Wavesplit is also applicable to other\ndomains, by separating fetal and maternal heart rates from a single abdominal\nelectrocardiogram.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:30:36 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 13:57:33 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zeghidour", "Neil", ""], ["Grangier", "David", ""]]}, {"id": "2002.08934", "submitter": "Jicong Fan", "authors": "Jicong Fan and Madeleine Udell", "title": "Online high rank matrix completion", "comments": "The paper was published by the proceedings of IEEE CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in matrix completion enable data imputation in full-rank\nmatrices by exploiting low dimensional (nonlinear) latent structure. In this\npaper, we develop a new model for high rank matrix completion (HRMC), together\nwith batch and online methods to fit the model and out-of-sample extension to\ncomplete new data. The method works by (implicitly) mapping the data into a\nhigh dimensional polynomial feature space using the kernel trick; importantly,\nthe data occupies a low dimensional subspace in this feature space, even when\nthe original data matrix is of full-rank. We introduce an explicit\nparametrization of this low dimensional subspace, and an online fitting\nprocedure, to reduce computational complexity compared to the state of the art.\nThe online method can also handle streaming or sequential data and adapt to\nnon-stationary latent structure. We provide guidance on the sampling rate\nrequired these methods to succeed. Experimental results on synthetic data and\nmotion capture data validate the performance of the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:31:04 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fan", "Jicong", ""], ["Udell", "Madeleine", ""]]}, {"id": "2002.08936", "submitter": "Weihao Kong", "authors": "Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, Sewoong Oh", "title": "Meta-learning for mixed linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern supervised learning, there are a large number of tasks, but many of\nthem are associated with only a small amount of labeled data. These include\ndata from medical image processing and robotic interaction. Even though each\nindividual task cannot be meaningfully trained in isolation, one seeks to\nmeta-learn across the tasks from past experiences by exploiting some\nsimilarities. We study a fundamental question of interest: When can abundant\ntasks with small data compensate for lack of tasks with big data? We focus on a\ncanonical scenario where each task is drawn from a mixture of $k$ linear\nregressions, and identify sufficient conditions for such a graceful exchange to\nhold; The total number of examples necessary with only small data tasks scales\nsimilarly as when big data tasks are available. To this end, we introduce a\nnovel spectral approach and show that we can efficiently utilize small data\ntasks with the help of $\\tilde\\Omega(k^{3/2})$ medium data tasks each with\n$\\tilde\\Omega(k^{1/2})$ examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:34:28 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kong", "Weihao", ""], ["Somani", "Raghav", ""], ["Song", "Zhao", ""], ["Kakade", "Sham", ""], ["Oh", "Sewoong", ""]]}, {"id": "2002.08937", "submitter": "Weida Li", "authors": "Weida Li, Mingxia Liu, Daoqiang Zhang", "title": "Nystr\\\"om Subspace Learning for Large-scale SVMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an implementation of the Nystr\\\"{o}m method, Nystr\\\"{o}m computational\nregularization (NCR) imposed on kernel classification and kernel ridge\nregression has proven capable of achieving optimal bounds in the large-scale\nstatistical learning setting, while enjoying much better time complexity. In\nthis study, we propose a Nystr\\\"{o}m subspace learning (NSL) framework to\nreveal that all you need for employing the Nystr\\\"{o}m method, including NCR,\nupon any kernel SVM is to use the efficient off-the-shelf linear SVM solvers as\na black box. Based on our analysis, the bounds developed for the Nystr\\\"{o}m\nmethod are linked to NSL, and the analytical difference between two distinct\nimplementations of the Nystr\\\"{o}m method is clearly presented. Besides, NSL\nalso leads to sharper theoretical results for the clustered Nystr\\\"{o}m method.\nFinally, both regression and classification tasks are performed to compare two\nimplementations of the Nystr\\\"{o}m method.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:36:16 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Li", "Weida", ""], ["Liu", "Mingxia", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2002.08943", "submitter": "Quentin Bertrand", "authors": "Quentin Bertrand and Quentin Klopfenstein and Mathieu Blondel and\n  Samuel Vaiter and Alexandre Gramfort and Joseph Salmon", "title": "Implicit differentiation of Lasso-type models for hyperparameter\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Setting regularization parameters for Lasso-type estimators is notoriously\ndifficult, though crucial in practice. The most popular hyperparameter\noptimization approach is grid-search using held-out validation data.\nGrid-search however requires to choose a predefined grid for each parameter,\nwhich scales exponentially in the number of parameters. Another approach is to\ncast hyperparameter optimization as a bi-level optimization problem, one can\nsolve by gradient descent. The key challenge for these methods is the\nestimation of the gradient with respect to the hyperparameters. Computing this\ngradient via forward or backward automatic differentiation is possible yet\nusually suffers from high memory consumption. Alternatively implicit\ndifferentiation typically involves solving a linear system which can be\nprohibitive and numerically unstable in high dimension. In addition, implicit\ndifferentiation usually assumes smooth loss functions, which is not the case\nfor Lasso-type problems. This work introduces an efficient implicit\ndifferentiation algorithm, without matrix inversion, tailored for Lasso-type\nproblems. Our approach scales to high-dimensional data by leveraging the\nsparsity of the solutions. Experiments demonstrate that the proposed method\noutperforms a large number of standard methods to optimize the error on\nheld-out data, or the Stein Unbiased Risk Estimator (SURE).\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:43:42 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 21:26:41 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:53:44 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bertrand", "Quentin", ""], ["Klopfenstein", "Quentin", ""], ["Blondel", "Mathieu", ""], ["Vaiter", "Samuel", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "2002.08948", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Suchi Saria", "title": "I-SPEC: An End-to-End Framework for Learning Transportable, Shift-Stable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shifts in environment between development and deployment cause classical\nsupervised learning to produce models that fail to generalize well to new\ntarget distributions. Recently, many solutions which find invariant predictive\ndistributions have been developed. Among these, graph-based approaches do not\nrequire data from the target environment and can capture more stable\ninformation than alternative methods which find stable feature sets. However,\nthese approaches assume that the data generating process is known in the form\nof a full causal graph, which is generally not the case. In this paper, we\npropose I-SPEC, an end-to-end framework that addresses this shortcoming by\nusing data to learn a partial ancestral graph (PAG). Using the PAG we develop\nan algorithm that determines an interventional distribution that is stable to\nthe declared shifts; this subsumes existing approaches which find stable\nfeature sets that are less accurate. We apply I-SPEC to a mortality prediction\nproblem to show it can learn a model that is robust to shifts without needing\nupfront knowledge of the full causal DAG.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:56:04 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Saria", "Suchi", ""]]}, {"id": "2002.08949", "submitter": "Ruilin Li", "authors": "Ruilin Li, Xin Wang, Hongyuan Zha and Molei Tao", "title": "Improving Sampling Accuracy of Stochastic Gradient MCMC Methods via\n  Non-uniform Subsampling of Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic Gradient (SG-)MCMC methods for sampling statistical distributions\napproximate gradients by stochastic ones, commonly via uniformly subsampled\ndata points. We propose a non-uniform subsampling scheme to improve the\nsampling accuracy. The proposed exponentially weighted stochastic gradient\n(EWSG) is designed so that a non-uniform-SG-MCMC method mimics the statistical\nbehavior of a batch-gradient-MCMC method, and hence the inaccuracy due to SG\napproximation is reduced. EWSG differs from Variance Reduction (VR) techniques\nas it focuses on the entire distribution instead of just the variance;\nnevertheless, its reduced local variance is also proved. EWSG can also be\nviewed as an extension of the importance sampling idea, successful for SG-based\noptimizations, to sampling tasks. In our practical implementation of EWSG, the\nnon-uniform subsampling is performed efficiently via a Metropolis-Hasting chain\non the data index, which is coupled to the MCMC algorithm. Numerical\nexperiments are provided, not only to demonstrate EWSG's effectiveness, but\nalso to guide hyperparameter choices, and validate our \\emph{non-asymptotic\nglobal error bound} despite of approximations in the implementation. Notably,\nwhile statistical accuracy is improved, convergence speed can be comparable to\nthe uniform version, which renders EWSG a practical alternative to VR (but EWSG\nand VR can be combined too).\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:56:18 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:12:34 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Li", "Ruilin", ""], ["Wang", "Xin", ""], ["Zha", "Hongyuan", ""], ["Tao", "Molei", ""]]}, {"id": "2002.08958", "submitter": "Mher Safaryan", "authors": "Mher Safaryan and Egor Shulgin and Peter Richt\\'arik", "title": "Uncertainty Principle for Communication Compression in Distributed and\n  Federated Learning and the Search for an Optimal Compressor", "comments": "23 pages, 6 figures, 2 tables", "journal-ref": "Information and Inference: A Journal of the IMA, 2021", "doi": "10.1093/imaiai/iaab006", "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to mitigate the high communication cost in distributed and federated\nlearning, various vector compression schemes, such as quantization,\nsparsification and dithering, have become very popular. In designing a\ncompression method, one aims to communicate as few bits as possible, which\nminimizes the cost per communication round, while at the same time attempting\nto impart as little distortion (variance) to the communicated messages as\npossible, which minimizes the adverse effect of the compression on the overall\nnumber of communication rounds. However, intuitively, these two goals are\nfundamentally in conflict: the more compression we allow, the more distorted\nthe messages become. We formalize this intuition and prove an {\\em uncertainty\nprinciple} for randomized compression operators, thus quantifying this\nlimitation mathematically, and {\\em effectively providing asymptotically tight\nlower bounds on what might be achievable with communication compression}.\nMotivated by these developments, we call for the search for the optimal\ncompression operator. In an attempt to take a first step in this direction, we\nconsider an unbiased compression method inspired by the Kashin representation\nof vectors, which we call {\\em Kashin compression (KC)}. In contrast to all\npreviously proposed compression mechanisms, KC enjoys a {\\em dimension\nindependent} variance bound for which we derive an explicit formula even in the\nregime when only a few bits need to be communicate per each vector entry.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:20:51 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 09:40:43 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 11:13:35 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Safaryan", "Mher", ""], ["Shulgin", "Egor", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.08972", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Efe Bozkir and Onur G\\\"unl\\\"u, Wolfgang Fuhl, Rafael F. Schaefer, and\n  Enkelejda Kasneci", "title": "Differential Privacy for Eye Tracking with Temporal Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New generation head-mounted displays, such as VR and AR glasses, are coming\ninto the market with already integrated eye tracking and are expected to enable\nnovel ways of human-computer interaction in many applications. However, since\neye movement properties contain biometric information, privacy concerns have to\nbe handled properly. Privacy-preservation techniques such as differential\nprivacy mechanisms have recently been applied to the eye movement data obtained\nfrom such displays. Standard differential privacy mechanisms; however, are\nvulnerable to temporal correlations in the eye movement features. In this work,\nwe propose a novel transform-coding based differential privacy mechanism to\nfurther adapt it to the statistics of eye movement feature data by comparing\nvarious low-complexity methods. We extent Fourier Perturbation Algorithm, which\nis a differential privacy mechanism, and correct a scaling mistake in its\nproof. Furthermore, we illustrate significant reductions in sample correlations\nin addition to query sensitivities, which provide the best utility-privacy\ntrade-off in the eye tracking literature. Our results show significantly high\nprivacy without loss in classification accuracies as well.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:01:34 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 14:04:54 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Bozkir", "Efe", ""], ["G\u00fcnl\u00fc", "Onur", ""], ["Fuhl", "Wolfgang", ""], ["Schaefer", "Rafael F.", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.08973", "submitter": "Raphael Gontijo-Lopes", "authors": "Raphael Gontijo-Lopes, Sylvia J. Smullin, Ekin D. Cubuk, Ethan Dyer", "title": "Affinity and Diversity: Quantifying Mechanisms of Data Augmentation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though data augmentation has become a standard component of deep neural\nnetwork training, the underlying mechanism behind the effectiveness of these\ntechniques remains poorly understood. In practice, augmentation policies are\noften chosen using heuristics of either distribution shift or augmentation\ndiversity. Inspired by these, we seek to quantify how data augmentation\nimproves model generalization. To this end, we introduce interpretable and\neasy-to-compute measures: Affinity and Diversity. We find that augmentation\nperformance is predicted not by either of these alone but by jointly optimizing\nthe two.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:02:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 19:04:48 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Gontijo-Lopes", "Raphael", ""], ["Smullin", "Sylvia J.", ""], ["Cubuk", "Ekin D.", ""], ["Dyer", "Ethan", ""]]}, {"id": "2002.08981", "submitter": "Stathi Fotiadis", "authors": "Stathi Fotiadis, Eduardo Pignatelli, Mario Lino Valencia, Chris\n  Cantwell, Amos Storkey, Anil A. Bharath", "title": "Comparing recurrent and convolutional neural networks for predicting\n  wave propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems can be modelled by partial differential equations and\nnumerical computations are used everywhere in science and engineering. In this\nwork, we investigate the performance of recurrent and convolutional deep neural\nnetwork architectures to predict the surface waves. The system is governed by\nthe Saint-Venant equations. We improve on the long-term prediction over\nprevious methods while keeping the inference time at a fraction of numerical\nsimulations. We also show that convolutional networks perform at least as well\nas recurrent networks in this task. Finally, we assess the generalisation\ncapability of each network by extrapolating in longer time-frames and in\ndifferent physical settings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:15:04 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 18:05:20 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 14:28:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Fotiadis", "Stathi", ""], ["Pignatelli", "Eduardo", ""], ["Valencia", "Mario Lino", ""], ["Cantwell", "Chris", ""], ["Storkey", "Amos", ""], ["Bharath", "Anil A.", ""]]}, {"id": "2002.08994", "submitter": "Christopher Liaw", "authors": "Nicholas J. A. Harvey, Christopher Liaw, Edwin Perkins, Sikander\n  Randhawa", "title": "Optimal anytime regret with two experts", "comments": "41 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiplicative weights method is an algorithm for the problem of\nprediction with expert advice. It achieves the minimax regret asymptotically if\nthe number of experts is large, and the time horizon is known in advance.\nOptimal algorithms are also known if there are exactly two or three experts,\nand the time horizon is known in advance.\n  In the anytime setting, where the time horizon is not known in advance,\nalgorithms can be obtained by the doubling trick, but they are not optimal, let\nalone practical. No minimax optimal algorithm was previously known in the\nanytime setting, regardless of the number of experts.\n  We design the first minimax optimal algorithm for minimizing regret in the\nanytime setting. We consider the case of two experts, and prove that the\noptimal regret is $\\gamma \\sqrt{t} / 2$ at all time steps $t$, where $\\gamma$\nis a natural constant that arose 35 years ago in studying fundamental\nproperties of Brownian motion. The algorithm is designed by considering a\ncontinuous analogue, which is solved using ideas from stochastic calculus.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 20:04:32 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Harvey", "Nicholas J. A.", ""], ["Liaw", "Christopher", ""], ["Perkins", "Edwin", ""], ["Randhawa", "Sikander", ""]]}, {"id": "2002.09000", "submitter": "Kevin Amaral", "authors": "Kevin M. Amaral, Zihan Li, Wei Ding, Scott Crouter, Ping Chen", "title": "SummerTime: Variable-length Time SeriesSummarization with Applications\n  to PhysicalActivity Analysis", "comments": "11 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textit{SummerTime} seeks to summarize globally time series signals and\nprovides a fixed-length, robust summarization of the variable-length time\nseries. Many classical machine learning methods for classification and\nregression depend on data instances with a fixed number of features. As a\nresult, those methods cannot be directly applied to variable-length time series\ndata. One common approach is to perform classification over a sliding window on\nthe data and aggregate the decisions made at local sections of the time series\nin some way, through majority voting for classification or averaging for\nregression. The downside to this approach is that minority local information is\nlost in the voting process and averaging assumes that each time series\nmeasurement is equal in significance. Also, since time series can be of varying\nlength, the quality of votes and averages could vary greatly in cases where\nthere is a close voting tie or bimodal distribution of regression domain.\nSummarization conducted by the \\textit{SummerTime} method will be a\nfixed-length feature vector which can be used in-place of the time series\ndataset for use with classical machine learning methods. We use Gaussian\nMixture models (GMM) over small same-length disjoint windows in the time series\nto group local data into clusters. The time series' rate of membership for each\ncluster will be a feature in the summarization. The model is naturally capable\nof converging to an appropriate cluster count. We compare our results to\nstate-of-the-art studies in physical activity classification and show\nhigh-quality improvement by classifying with only the summarization. Finally,\nwe show that regression using the summarization can augment energy expenditure\nestimation, producing more robust and precise results.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 20:20:06 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Amaral", "Kevin M.", ""], ["Li", "Zihan", ""], ["Ding", "Wei", ""], ["Crouter", "Scott", ""], ["Chen", "Ping", ""]]}, {"id": "2002.09018", "submitter": "Rohan Anil", "authors": "Rohan Anil, Vineet Gupta, Tomer Koren, Kevin Regan and Yoram Singer", "title": "Scalable Second Order Optimization for Deep Learning", "comments": "24 pages, Code available here: https://bit.ly/3uXXtKy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization in machine learning, both theoretical and applied, is presently\ndominated by first-order gradient methods such as stochastic gradient descent.\nSecond-order optimization methods, that involve second derivatives and/or\nsecond order statistics of the data, are far less prevalent despite strong\ntheoretical properties, due to their prohibitive computation, memory and\ncommunication costs. In an attempt to bridge this gap between theoretical and\npractical optimization, we present a scalable implementation of a second-order\npreconditioned method (concretely, a variant of full-matrix Adagrad), that\nalong with several critical algorithmic and numerical improvements, provides\nsignificant convergence and wall-clock time improvements compared to\nconventional first-order methods on state-of-the-art deep models. Our novel\ndesign effectively utilizes the prevalent heterogeneous hardware architecture\nfor training deep models, consisting of a multicore CPU coupled with multiple\naccelerator units. We demonstrate superior performance compared to\nstate-of-the-art on very large learning tasks such as machine translation with\nTransformers, language modeling with BERT, click-through rate prediction on\nCriteo, and image classification on ImageNet with ResNet-50.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 20:51:33 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 06:29:48 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Anil", "Rohan", ""], ["Gupta", "Vineet", ""], ["Koren", "Tomer", ""], ["Regan", "Kevin", ""], ["Singer", "Yoram", ""]]}, {"id": "2002.09024", "submitter": "Chengyue Gong", "authors": "Chengyue Gong, Tongzheng Ren, Mao Ye, Qiang Liu", "title": "MaxUp: A Simple Way to Improve Generalization of Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose \\emph{MaxUp}, an embarrassingly simple, highly effective technique\nfor improving the generalization performance of machine learning models,\nespecially deep neural networks. The idea is to generate a set of augmented\ndata with some random perturbations or transforms and minimize the maximum, or\nworst case loss over the augmented data. By doing so, we implicitly introduce a\nsmoothness or robustness regularization against the random perturbations, and\nhence improve the generation performance. For example, in the case of Gaussian\nperturbation,\n  \\emph{MaxUp} is asymptotically equivalent to using the gradient norm of the\nloss as a penalty to encourage smoothness. We test \\emph{MaxUp} on a range of\ntasks, including image classification, language modeling, and adversarial\ncertification, on which \\emph{MaxUp} consistently outperforms the existing best\nbaseline methods, without introducing substantial computational overhead. In\nparticular, we improve ImageNet classification from the state-of-the-art top-1\naccuracy $85.5\\%$ without extra data to $85.8\\%$. Code will be released soon.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:20:28 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Gong", "Chengyue", ""], ["Ren", "Tongzheng", ""], ["Ye", "Mao", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09027", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Yi Ouyang, I-Te Danny Hung,\n  Chin-Hui Lee, Xiaoli Ma", "title": "Enhanced Adversarial Strategically-Timed Attacks against Deep\n  Reinforcement Learning", "comments": "Accepted to IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent deep neural networks based techniques, especially those equipped with\nthe ability of self-adaptation in the system level such as deep reinforcement\nlearning (DRL), are shown to possess many advantages of optimizing robot\nlearning systems (e.g., autonomous navigation and continuous robot arm\ncontrol.) However, the learning-based systems and the associated models may be\nthreatened by the risks of intentionally adaptive (e.g., noisy sensor\nconfusion) and adversarial perturbations from real-world scenarios. In this\npaper, we introduce timing-based adversarial strategies against a DRL-based\nnavigation system by jamming in physical noise patterns on the selected time\nframes. To study the vulnerability of learning-based navigation systems, we\npropose two adversarial agent models: one refers to online learning; another\none is based on evolutionary learning. Besides, three open-source robot\nlearning and navigation control environments are employed to study the\nvulnerability under adversarial timing attacks. Our experimental results show\nthat the adversarial timing attacks can lead to a significant performance drop,\nand also suggest the necessity of enhancing the robustness of robot learning\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:39:25 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ouyang", "Yi", ""], ["Hung", "I-Te Danny", ""], ["Lee", "Chin-Hui", ""], ["Ma", "Xiaoli", ""]]}, {"id": "2002.09038", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Ilija Bogunovic, Stefanie Jegelka, Andreas Krause", "title": "Distributionally Robust Bayesian Optimization", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to distributional shift is one of the key challenges of\ncontemporary machine learning. Attaining such robustness is the goal of\ndistributionally robust optimization, which seeks a solution to an optimization\nproblem that is worst-case robust under a specified distributional shift of an\nuncontrolled covariate. In this paper, we study such a problem when the\ndistributional shift is measured via the maximum mean discrepancy (MMD). For\nthe setting of zeroth-order, noisy optimization, we present a novel\ndistributionally robust Bayesian optimization algorithm (DRBO). Our algorithm\nprovably obtains sub-linear robust regret in various settings that differ in\nhow the uncertain covariate is observed. We demonstrate the robust performance\nof our method on both synthetic and real-world benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:04:30 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 08:23:36 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 10:40:30 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Kirschner", "Johannes", ""], ["Bogunovic", "Ilija", ""], ["Jegelka", "Stefanie", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.09043", "submitter": "David Venuto", "authors": "David Venuto, Jhelum Chakravorty, Leonard Boussioux, Junhao Wang,\n  Gavin McCracken, Doina Precup", "title": "oIRL: Robust Adversarial Inverse Reinforcement Learning with Temporally\n  Extended Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Explicit engineering of reward functions for given environments has been a\nmajor hindrance to reinforcement learning methods. While Inverse Reinforcement\nLearning (IRL) is a solution to recover reward functions from demonstrations\nonly, these learned rewards are generally heavily \\textit{entangled} with the\ndynamics of the environment and therefore not portable or \\emph{robust} to\nchanging environments. Modern adversarial methods have yielded some success in\nreducing reward entanglement in the IRL setting. In this work, we leverage one\nsuch method, Adversarial Inverse Reinforcement Learning (AIRL), to propose an\nalgorithm that learns hierarchical disentangled rewards with a policy over\noptions. We show that this method has the ability to learn \\emph{generalizable}\npolicies and reward functions in complex transfer learning tasks, while\nyielding results in continuous control benchmarks that are comparable to those\nof the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:21:41 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Venuto", "David", ""], ["Chakravorty", "Jhelum", ""], ["Boussioux", "Leonard", ""], ["Wang", "Junhao", ""], ["McCracken", "Gavin", ""], ["Precup", "Doina", ""]]}, {"id": "2002.09046", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Huan Wang, Caiming Xiong, Richard Socher, Yoshua Bengio", "title": "Neural Bayes: A Generic Parameterization Method for Unsupervised\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a parameterization method called Neural Bayes which allows\ncomputing statistical quantities that are in general difficult to compute and\nopens avenues for formulating new objectives for unsupervised representation\nlearning. Specifically, given an observed random variable $\\mathbf{x}$ and a\nlatent discrete variable $z$, we can express $p(\\mathbf{x}|z)$,\n$p(z|\\mathbf{x})$ and $p(z)$ in closed form in terms of a sufficiently\nexpressive function (Eg. neural network) using our parameterization without\nrestricting the class of these distributions. To demonstrate its usefulness, we\ndevelop two independent use cases for this parameterization:\n  1. Mutual Information Maximization (MIM): MIM has become a popular means for\nself-supervised representation learning. Neural Bayes allows us to compute\nmutual information between observed random variables $\\mathbf{x}$ and latent\ndiscrete random variables $z$ in closed form. We use this for learning image\nrepresentations and show its usefulness on downstream classification tasks.\n  2. Disjoint Manifold Labeling: Neural Bayes allows us to formulate an\nobjective which can optimally label samples from disjoint manifolds present in\nthe support of a continuous distribution. This can be seen as a specific form\nof clustering where each disjoint manifold in the support is a separate\ncluster. We design clustering tasks that obey this formulation and empirically\nshow that the model optimally labels the disjoint manifolds. Our code is\navailable at \\url{https://github.com/salesforce/NeuralBayes}\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:28:53 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Arpit", "Devansh", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.09049", "submitter": "Xingchao Liu", "authors": "Xingchao Liu, Mao Ye, Dengyong Zhou, Qiang Liu", "title": "Post-training Quantization with Multiple Points: Mixed Precision without\n  Mixed Precision", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the post-training quantization problem, which discretizes the\nweights of pre-trained deep neural networks without re-training the model. We\npropose multipoint quantization, a quantization method that approximates a\nfull-precision weight vector using a linear combination of multiple vectors of\nlow-bit numbers; this is in contrast to typical quantization methods that\napproximate each weight using a single low precision number. Computationally,\nwe construct the multipoint quantization with an efficient greedy selection\nprocedure, and adaptively decides the number of low precision points on each\nquantized weight vector based on the error of its output. This allows us to\nachieve higher precision levels for important weights that greatly influence\nthe outputs, yielding an 'effect of mixed precision' but without physical mixed\nprecision implementations (which requires specialized hardware accelerators).\nEmpirically, our method can be implemented by common operands, bringing almost\nno memory and computation overhead. We show that our method outperforms a range\nof state-of-the-art methods on ImageNet classification and it can be\ngeneralized to more challenging tasks like PASCAL VOC object detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:37:45 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 07:20:56 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 15:25:38 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Liu", "Xingchao", ""], ["Ye", "Mao", ""], ["Zhou", "Dengyong", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09051", "submitter": "Vincent Roulet", "authors": "Vincent Roulet and Zaid Harchaoui", "title": "An Elementary Approach to Convergence Guarantees of Optimization\n  Algorithms for Deep Networks", "comments": "The changes from v1 to v2 include i) slightly more general results;\n  ii) slightly more concise proofs; iii) highway and residual networks; iv)\n  implicitly defined network layers; v) additional algorithm boxes and\n  illustration figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to obtain convergence guarantees of optimization\nalgorithms for deep networks based on elementary arguments and computations.\nThe convergence analysis revolves around the analytical and computational\nstructures of optimization oracles central to the implementation of deep\nnetworks in machine learning software. We provide a systematic way to compute\nestimates of the smoothness constants that govern the convergence behavior of\nfirst-order optimization algorithms used to train deep networks. A diverse set\nof example components and architectures arising in modern deep networks\nintersperse the exposition to illustrate the approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:40:52 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 02:47:52 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Roulet", "Vincent", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2002.09062", "submitter": "Weiqi Ji", "authors": "Weiqi Ji and Sili Deng", "title": "Autonomous Discovery of Unknown Reaction Pathways from Data by Chemical\n  Reaction Neural Network", "comments": null, "journal-ref": "The Journal of Physical Chemistry A, 2021", "doi": "10.1021/acs.jpca.0c09316", "report-no": null, "categories": "q-bio.MN cs.LG physics.chem-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Chemical reactions occur in energy, environmental, biological, and many other\nnatural systems, and the inference of the reaction networks is essential to\nunderstand and design the chemical processes in engineering and life sciences.\nYet, revealing the reaction pathways for complex systems and processes is still\nchallenging due to the lack of knowledge of the involved species and reactions.\nHere, we present a neural network approach that autonomously discovers reaction\npathways from the time-resolved species concentration data. The proposed\nChemical Reaction Neural Network (CRNN), by design, satisfies the fundamental\nphysics laws, including the Law of Mass Action and the Arrhenius Law.\nConsequently, the CRNN is physically interpretable such that the reaction\npathways can be interpreted, and the kinetic parameters can be quantified\nsimultaneously from the weights of the neural network. The inference of the\nchemical pathways is accomplished by training the CRNN with species\nconcentration data via stochastic gradient descent. We demonstrate the\nsuccessful implementations and the robustness of the approach in elucidating\nthe chemical reaction pathways of several chemical engineering and biochemical\nsystems. The autonomous inference by the CRNN approach precludes the need for\nexpert knowledge in proposing candidate networks and addresses the curse of\ndimensionality in complex systems. The physical interpretability also makes the\nCRNN capable of not only fitting the data for a given system but also\ndeveloping knowledge of unknown pathways that could be generalized to similar\nchemical systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 23:36:46 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 22:18:36 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Ji", "Weiqi", ""], ["Deng", "Sili", ""]]}, {"id": "2002.09067", "submitter": "Kensen Shi", "authors": "Kensen Shi, David Bieber, Charles Sutton", "title": "Incremental Sampling Without Replacement for Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is a fundamental technique, and sampling without replacement is\noften desirable when duplicate samples are not beneficial. Within machine\nlearning, sampling is useful for generating diverse outputs from a trained\nmodel. We present an elegant procedure for sampling without replacement from a\nbroad class of randomized programs, including generative neural models that\nconstruct outputs sequentially. Our procedure is efficient even for\nexponentially-large output spaces. Unlike prior work, our approach is\nincremental, i.e., samples can be drawn one at a time, allowing for increased\nflexibility. We also present a new estimator for computing expectations from\nsamples drawn without replacement. We show that incremental sampling without\nreplacement is applicable to many domains, e.g., program synthesis and\ncombinatorial optimization.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:12:01 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 00:09:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Shi", "Kensen", ""], ["Bieber", "David", ""], ["Sutton", "Charles", ""]]}, {"id": "2002.09070", "submitter": "Mao Ye", "authors": "Mao Ye, Tongzheng Ren, Qiang Liu", "title": "Stein Self-Repulsive Dynamics: Benefits From Past Samples", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Stein self-repulsive dynamics for obtaining diversified\nsamples from intractable un-normalized distributions. Our idea is to introduce\nStein variational gradient as a repulsive force to push the samples of Langevin\ndynamics away from the past trajectories. This simple idea allows us to\nsignificantly decrease the auto-correlation in Langevin dynamics and hence\nincrease the effective sample size. Importantly, as we establish in our\ntheoretical analysis, the asymptotic stationary distribution remains correct\neven with the addition of the repulsive force, thanks to the special properties\nof the Stein variational gradient. We perform extensive empirical studies of\nour new algorithm, showing that our method yields much higher sample efficiency\nand better uncertainty estimation than vanilla Langevin dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:26:38 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 05:36:41 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ye", "Mao", ""], ["Ren", "Tongzheng", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09072", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Bo Dai, Lihong Li, Dale Schuurmans", "title": "GenDICE: Generalized Offline Estimation of Stationary Values", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem that arises in reinforcement learning and Monte Carlo\nmethods is estimating quantities defined by the stationary distribution of a\nMarkov chain. In many real-world applications, access to the underlying\ntransition operator is limited to a fixed set of data that has already been\ncollected, without additional interaction with the environment being available.\nWe show that consistent estimation remains possible in this challenging\nscenario, and that effective estimation can still be achieved in important\napplications. Our approach is based on estimating a ratio that corrects for the\ndiscrepancy between the stationary and empirical distributions, derived from\nfundamental properties of the stationary distribution, and exploiting\nconstraint reformulations based on variational divergence minimization. The\nresulting algorithm, GenDICE, is straightforward and effective. We prove its\nconsistency under general conditions, provide an error analysis, and\ndemonstrate strong empirical performance on benchmark problems, including\noff-line PageRank and off-policy policy evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:27:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Dai", "Bo", ""], ["Li", "Lihong", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2002.09073", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Rajiv Khanna and Michael W. Mahoney", "title": "Improved guarantees and a multiple-descent curve for Column Subset\n  Selection and the Nystr\\\"om method", "comments": "Minor typo corrections and clarifications; slight change in the\n  title; moved part of the related work and background discussion to the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Column Subset Selection Problem (CSSP) and the Nystr\\\"om method are among\nthe leading tools for constructing small low-rank approximations of large\ndatasets in machine learning and scientific computing. A fundamental question\nin this area is: how well can a data subset of size k compete with the best\nrank k approximation? We develop techniques which exploit spectral properties\nof the data matrix to obtain improved approximation guarantees which go beyond\nthe standard worst-case analysis. Our approach leads to significantly better\nbounds for datasets with known rates of singular value decay, e.g., polynomial\nor exponential decay. Our analysis also reveals an intriguing phenomenon: the\napproximation factor as a function of k may exhibit multiple peaks and valleys,\nwhich we call a multiple-descent curve. A lower bound we establish shows that\nthis behavior is not an artifact of our analysis, but rather it is an inherent\nproperty of the CSSP and Nystr\\\"om tasks. Finally, using the example of a\nradial basis function (RBF) kernel, we show that both our improved bounds and\nthe multiple-descent curve can be observed on real datasets simply by varying\nthe RBF parameter.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:43:06 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 01:22:04 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 21:19:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Khanna", "Rajiv", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.09077", "submitter": "Guannan Zhang", "authors": "Jiaxing Zhang, Hoang Tran, Guannan Zhang", "title": "Accelerating Reinforcement Learning with a\n  Directional-Gaussian-Smoothing Evolution Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution strategy (ES) has been shown great promise in many challenging\nreinforcement learning (RL) tasks, rivaling other state-of-the-art deep RL\nmethods. Yet, there are two limitations in the current ES practice that may\nhinder its otherwise further capabilities. First, most current methods rely on\nMonte Carlo type gradient estimators to suggest search direction, where the\npolicy parameter is, in general, randomly sampled. Due to the low accuracy of\nsuch estimators, the RL training may suffer from slow convergence and require\nmore iterations to reach optimal solution. Secondly, the landscape of reward\nfunctions can be deceptive and contains many local maxima, causing ES\nalgorithms to prematurely converge and be unable to explore other parts of the\nparameter space with potentially greater rewards. In this work, we employ a\nDirectional Gaussian Smoothing Evolutionary Strategy (DGS-ES) to accelerate RL\ntraining, which is well-suited to address these two challenges with its ability\nto i) provide gradient estimates with high accuracy, and ii) find nonlocal\nsearch direction which lays stress on large-scale variation of the reward\nfunction and disregards local fluctuation. Through several benchmark RL tasks\ndemonstrated herein, we show that DGS-ES is highly scalable, possesses superior\nwall-clock time, and achieves competitive reward scores to other popular policy\ngradient and ES approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 01:05:57 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Jiaxing", ""], ["Tran", "Hoang", ""], ["Zhang", "Guannan", ""]]}, {"id": "2002.09080", "submitter": "Essam Rashed", "authors": "Essam A. Rashed and Jose Gomez-Tames and Akimasa Hirata", "title": "Development of accurate human head models for personalized\n  electromagnetic dosimetry using deep learning", "comments": null, "journal-ref": "NeuroImage 202, pp. 116132, 2019", "doi": "10.1016/j.neuroimage.2019.116132", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of personalized human head models from medical images has\nbecome an important topic in the electromagnetic dosimetry field, including the\noptimization of electrostimulation, safety assessments, etc. Human head models\nare commonly generated via the segmentation of magnetic resonance images into\ndifferent anatomical tissues. This process is time consuming and requires\nspecial experience for segmenting a relatively large number of tissues. Thus,\nit is challenging to accurately compute the electric field in different\nspecific brain regions. Recently, deep learning has been applied for the\nsegmentation of the human brain. However, most studies have focused on the\nsegmentation of brain tissue only and little attention has been paid to other\ntissues, which are considerably important for electromagnetic dosimetry.\n  In this study, we propose a new architecture for a convolutional neural\nnetwork, named ForkNet, to perform the segmentation of whole human head\nstructures, which is essential for evaluating the electrical field distribution\nin the brain. The proposed network can be used to generate personalized head\nmodels and applied for the evaluation of the electric field in the brain during\ntranscranial magnetic stimulation. Our computational results indicate that the\nhead models generated using the proposed network exhibit strong matching with\nthose created via manual segmentation in an intra-scanner segmentation task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 01:21:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Rashed", "Essam A.", ""], ["Gomez-Tames", "Jose", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2002.09089", "submitter": "Daniel Brown", "authors": "Daniel S. Brown, Russell Coleman, Ravi Srinivasan, Scott Niekum", "title": "Safe Imitation Learning via Fast Bayesian Reward Inference from\n  Preferences", "comments": "In proceedings ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian reward learning from demonstrations enables rigorous safety and\nuncertainty analysis when performing imitation learning. However, Bayesian\nreward learning methods are typically computationally intractable for complex\ncontrol problems. We propose Bayesian Reward Extrapolation (Bayesian REX), a\nhighly efficient Bayesian reward learning algorithm that scales to\nhigh-dimensional imitation learning problems by pre-training a low-dimensional\nfeature encoding via self-supervised tasks and then leveraging preferences over\ndemonstrations to perform fast Bayesian inference. Bayesian REX can learn to\nplay Atari games from demonstrations, without access to the game score and can\ngenerate 100,000 samples from the posterior over reward functions in only 5\nminutes on a personal laptop. Bayesian REX also results in imitation learning\nperformance that is competitive with or better than state-of-the-art methods\nthat only learn point estimates of the reward function. Finally, Bayesian REX\nenables efficient high-confidence policy evaluation without having access to\nsamples of the reward function. These high-confidence performance bounds can be\nused to rank the performance and risk of a variety of evaluation policies and\nprovide a way to detect reward hacking behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:04:54 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 04:42:38 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 17:55:39 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 21:48:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Brown", "Daniel S.", ""], ["Coleman", "Russell", ""], ["Srinivasan", "Ravi", ""], ["Niekum", "Scott", ""]]}, {"id": "2002.09094", "submitter": "Kazuo Aoyama", "authors": "Kazuo Aoyama, Kazumi Saito, and Tetsuo Ikeda", "title": "Inverted-File k-Means Clustering: Performance Analysis", "comments": "15 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an inverted-file k-means clustering algorithm (IVF)\nsuitable for a large-scale sparse data set with potentially numerous classes.\nGiven such a data set, IVF efficiently works at high-speed and with low memory\nconsumption, which keeps the same solution as a standard Lloyd's algorithm. The\nhigh performance arises from two distinct data representations. One is a sparse\nexpression for both the object and mean feature vectors. The other is an\ninverted-file data structure for a set of the mean feature vectors. To confirm\nthe effect of these representations, we design three algorithms using distinct\ndata structures and expressions for comparison. We experimentally demonstrate\nthat IVF achieves better performance than the designed algorithms when they are\napplied to large-scale real document data sets in a modern computer system\nequipped with superscalar out-of-order processors and a deep hierarchical\nmemory system. We also introduce a simple yet practical clock-cycle per\ninstruction (CPI) model for speed-performance analysis. Analytical results\nreveal that IVF suppresses three performance degradation factors: the numbers\nof cache misses, branch mispredictions, and the completed instructions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:20:33 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Aoyama", "Kazuo", ""], ["Saito", "Kazumi", ""], ["Ikeda", "Tetsuo", ""]]}, {"id": "2002.09103", "submitter": "Arsenii Ashukha", "authors": "Dmitry Molchanov, Alexander Lyzhov, Yuliya Molchanova, Arsenii\n  Ashukha, Dmitry Vetrov", "title": "Greedy Policy Search: A Simple Baseline for Learnable Test-Time\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test-time data augmentation$-$averaging the predictions of a machine learning\nmodel across multiple augmented samples of data$-$is a widely used technique\nthat improves the predictive performance. While many advanced learnable data\naugmentation techniques have emerged in recent years, they are focused on the\ntraining phase. Such techniques are not necessarily optimal for test-time\naugmentation and can be outperformed by a policy consisting of simple crops and\nflips. The primary goal of this paper is to demonstrate that test-time\naugmentation policies can be successfully learned too. We introduce greedy\npolicy search (GPS), a simple but high-performing method for learning a policy\nof test-time augmentation. We demonstrate that augmentation policies learned\nwith GPS achieve superior predictive performance on image classification\nproblems, provide better in-domain uncertainty estimation, and improve the\nrobustness to domain shift.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:57:13 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 13:10:23 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Molchanov", "Dmitry", ""], ["Lyzhov", "Alexander", ""], ["Molchanova", "Yuliya", ""], ["Ashukha", "Arsenii", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2002.09112", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak, Geoff Pleiss, Jacob R. Gardner", "title": "Deep Sigma Point Processes", "comments": "15 pages, 13 figures; as appeared in UAI 2020", "journal-ref": "Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI), PMLR 124:789-798, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Sigma Point Processes, a class of parametric models\ninspired by the compositional structure of Deep Gaussian Processes (DGPs). Deep\nSigma Point Processes (DSPPs) retain many of the attractive features of\n(variational) DGPs, including mini-batch training and predictive uncertainty\nthat is controlled by kernel basis functions. Importantly, since DSPPs admit a\nsimple maximum likelihood inference procedure, the resulting predictive\ndistributions are not degraded by any posterior approximations. In an extensive\nempirical comparison on univariate and multivariate regression tasks we find\nthat the resulting predictive distributions are significantly better calibrated\nthan those obtained with other probabilistic methods for scalable regression,\nincluding variational DGPs--often by as much as a nat per datapoint.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 03:40:35 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 17:27:19 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jankowiak", "Martin", ""], ["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""]]}, {"id": "2002.09116", "submitter": "Danica J. Sutherland", "authors": "Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, Danica\n  J. Sutherland", "title": "Learning Deep Kernels for Non-Parametric Two-Sample Tests", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML 2020), PMLR 119:6316-6326", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of kernel-based two-sample tests, which aim to determine\nwhether two sets of samples are drawn from the same distribution. Our tests are\nconstructed from kernels parameterized by deep neural nets, trained to maximize\ntest power. These tests adapt to variations in distribution smoothness and\nshape over space, and are especially suited to high dimensions and complex\ndata. By contrast, the simpler kernels used in prior kernel testing work are\nspatially homogeneous, and adaptive only in lengthscale. We explain how this\nscheme includes popular classifier-based two-sample tests as a special case,\nbut improves on them in general. We provide the first proof of consistency for\nthe proposed adaptation method, which applies both to kernels on deep features\nand to simpler radial basis kernels or multiple kernel learning. In\nexperiments, we establish the superior performance of our deep kernels in\nhypothesis testing on benchmark and real-world data. The code of our\ndeep-kernel-based two sample tests is available at\nhttps://github.com/fengliu90/DK-for-TST.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 03:54:23 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 18:23:31 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 05:29:18 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Liu", "Feng", ""], ["Xu", "Wenkai", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""], ["Gretton", "Arthur", ""], ["Sutherland", "Danica J.", ""]]}, {"id": "2002.09124", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, Asuman Ozdaglar", "title": "GANs May Have No Nash Equilibria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) represent a zero-sum game between two\nmachine players, a generator and a discriminator, designed to learn the\ndistribution of data. While GANs have achieved state-of-the-art performance in\nseveral benchmark learning tasks, GAN minimax optimization still poses great\ntheoretical and empirical challenges. GANs trained using first-order\noptimization methods commonly fail to converge to a stable solution where the\nplayers cannot improve their objective, i.e., the Nash equilibrium of the\nunderlying game. Such issues raise the question of the existence of Nash\nequilibrium solutions in the GAN zero-sum game. In this work, we show through\nseveral theoretical and numerical results that indeed GAN zero-sum games may\nnot have any local Nash equilibria. To characterize an equilibrium notion\napplicable to GANs, we consider the equilibrium of a new zero-sum game with an\nobjective function given by a proximal operator applied to the original\nobjective, a solution we call the proximal equilibrium. Unlike the Nash\nequilibrium, the proximal equilibrium captures the sequential nature of GANs,\nin which the generator moves first followed by the discriminator. We prove that\nthe optimal generative model in Wasserstein GAN problems provides a proximal\nequilibrium. Inspired by these results, we propose a new approach, which we\ncall proximal training, for solving GAN problems. We discuss several numerical\nexperiments demonstrating the existence of proximal equilibrium solutions in\nGAN minimax problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:30:05 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Farnia", "Farzan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.09128", "submitter": "Sirui Xie", "authors": "Shoukang Hu, Sirui Xie, Hehui Zheng, Chunxiao Liu, Jianping Shi,\n  Xunying Liu, Dahua Lin", "title": "DSNAS: Direct Neural Architecture Search without Parameter Retraining", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  If NAS methods are solutions, what is the problem? Most existing NAS methods\nrequire two-stage parameter optimization. However, performance of the same\narchitecture in the two stages correlates poorly. In this work, we propose a\nnew problem definition for NAS, task-specific end-to-end, based on this\nobservation. We argue that given a computer vision task for which a NAS method\nis expected, this definition can reduce the vaguely-defined NAS evaluation to\ni) accuracy of this task and ii) the total computation consumed to finally\nobtain a model with satisfying accuracy. Seeing that most existing methods do\nnot solve this problem directly, we propose DSNAS, an efficient differentiable\nNAS framework that simultaneously optimizes architecture and parameters with a\nlow-biased Monte Carlo estimate. Child networks derived from DSNAS can be\ndeployed directly without parameter retraining. Comparing with two-stage\nmethods, DSNAS successfully discovers networks with comparable accuracy (74.4%)\non ImageNet in 420 GPU hours, reducing the total time by more than 34%. Our\nimplementation is available at https://github.com/SNAS-Series/SNAS-Series.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:41:47 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 00:31:37 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Hu", "Shoukang", ""], ["Xie", "Sirui", ""], ["Zheng", "Hehui", ""], ["Liu", "Chunxiao", ""], ["Shi", "Jianping", ""], ["Liu", "Xunying", ""], ["Lin", "Dahua", ""]]}, {"id": "2002.09131", "submitter": "Wonmin Byeon", "authors": "Jiahao Su, Wonmin Byeon, Jean Kossaifi, Furong Huang, Jan Kautz,\n  Animashree Anandkumar", "title": "Convolutional Tensor-Train LSTM for Spatio-temporal Learning", "comments": "Jiahao Su and Wonmin Byeon contributed equally to this work. 22\n  pages, 14 figures, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from spatio-temporal data has numerous applications such as\nhuman-behavior analysis, object tracking, video compression, and physics\nsimulation.However, existing methods still perform poorly on challenging video\ntasks such as long-term forecasting. This is because these kinds of challenging\ntasks require learning long-term spatio-temporal correlations in the video\nsequence. In this paper, we propose a higher-order convolutional LSTM model\nthat can efficiently learn these correlations, along with a succinct\nrepresentations of the history. This is accomplished through a novel tensor\ntrain module that performs prediction by combining convolutional features\nacross time. To make this feasible in terms of computation and memory\nrequirements, we propose a novel convolutional tensor-train decomposition of\nthe higher-order model. This decomposition reduces the model complexity by\njointly approximating a sequence of convolutional kernels asa low-rank\ntensor-train factorization. As a result, our model outperforms existing\napproaches, but uses only a fraction of parameters, including the baseline\nmodels.Our results achieve state-of-the-art performance in a wide range of\napplications and datasets, including the multi-steps video prediction on the\nMoving-MNIST-2and KTH action datasets as well as early activity recognition on\nthe Something-Something V2 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:00:01 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:31:38 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 19:27:44 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 18:30:12 GMT"}, {"version": "v5", "created": "Sun, 4 Oct 2020 23:14:31 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Su", "Jiahao", ""], ["Byeon", "Wonmin", ""], ["Kossaifi", "Jean", ""], ["Huang", "Furong", ""], ["Kautz", "Jan", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "2002.09132", "submitter": "Duy Vo Nguyen Le", "authors": "Vo Nguyen Le Duy, Hiroki Toda, Ryota Sugiyama, Ichiro Takeuchi", "title": "Computing Valid p-value for Optimal Changepoint by Selective Inference\n  using Dynamic Programming", "comments": "Spotlight Presentation at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a vast body of literature related to methods for detecting\nchangepoints (CP). However, less attention has been paid to assessing the\nstatistical reliability of the detected CPs. In this paper, we introduce a\nnovel method to perform statistical inference on the significance of the CPs,\nestimated by a Dynamic Programming (DP)-based optimal CP detection algorithm.\nBased on the selective inference (SI) framework, we propose an exact\n(non-asymptotic) approach to compute valid p-values for testing the\nsignificance of the CPs. Although it is well-known that SI has low statistical\npower because of over-conditioning, we address this disadvantage by introducing\nparametric programming techniques. Then, we propose an efficient method to\nconduct SI with the minimum amount of conditioning, leading to high statistical\npower. We conduct experiments on both synthetic and real-world datasets,\nthrough which we offer evidence that our proposed method is more powerful than\nexisting methods, has decent performance in terms of computational efficiency,\nand provides good results in many practical applications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:07:22 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 13:06:56 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Toda", "Hiroki", ""], ["Sugiyama", "Ryota", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2002.09133", "submitter": "R. Jyothi", "authors": "R. Jyothi and P. Babu", "title": "PIANO: A Fast Parallel Iterative Algorithm for Multinomial and Sparse\n  Multinomial Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multinomial Logistic Regression is a well-studied tool for classification and\nhas been widely used in fields like image processing, computer vision and,\nbioinformatics, to name a few. Under a supervised classification scenario, a\nMultinomial Logistic Regression model learns a weight vector to differentiate\nbetween any two classes by optimizing over the likelihood objective. With the\nadvent of big data, the inundation of data has resulted in large dimensional\nweight vector and has also given rise to a huge number of classes, which makes\nthe classical methods applicable for model estimation not computationally\nviable. To handle this issue, we here propose a parallel iterative algorithm:\nParallel Iterative Algorithm for MultiNomial LOgistic Regression (PIANO) which\nis based on the Majorization Minimization procedure, and can parallely update\neach element of the weight vectors. Further, we also show that PIANO can be\neasily extended to solve the Sparse Multinomial Logistic Regression problem -\nan extensively studied problem because of its attractive feature selection\nproperty. In particular, we work out the extension of PIANO to solve the Sparse\nMultinomial Logistic Regression problem with l1 and l0 regularizations. We also\nprove that PIANO converges to a stationary point of the Multinomial and the\nSparse Multinomial Logistic Regression problems. Simulations were conducted to\ncompare PIANO with the existing methods, and it was found that the proposed\nalgorithm performs better than the existing methods in terms of speed of\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:15:48 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jyothi", "R.", ""], ["Babu", "P.", ""]]}, {"id": "2002.09136", "submitter": "Yuanyi Zhong", "authors": "Yuanyi Zhong, Alexander Schwing, Jian Peng", "title": "Disentangling Controllable Object through Video Prediction Improves\n  Visual Reinforcement Learning", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many vision-based reinforcement learning (RL) problems, the agent controls\na movable object in its visual field, e.g., the player's avatar in video games\nand the robotic arm in visual grasping and manipulation. Leveraging\naction-conditioned video prediction, we propose an end-to-end learning\nframework to disentangle the controllable object from the observation signal.\nThe disentangled representation is shown to be useful for RL as additional\nobservation channels to the agent. Experiments on a set of Atari games with the\npopular Double DQN algorithm demonstrate improved sample efficiency and game\nperformance (from 222.8% to 261.4% measured in normalized game scores, with\nprediction bonus reward).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:43:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhong", "Yuanyi", ""], ["Schwing", "Alexander", ""], ["Peng", "Jian", ""]]}, {"id": "2002.09142", "submitter": "Sina Aghaei", "authors": "Sina Aghaei, Andres Gomez, Phebe Vayanos", "title": "Learning Optimal Classification Trees: Strong Max-Flow Formulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning optimal binary classification trees.\nLiterature on the topic has burgeoned in recent years, motivated both by the\nempirical suboptimality of heuristic approaches and the tremendous improvements\nin mixed-integer programming (MIP) technology. Yet, existing approaches from\nthe literature do not leverage the power of MIP to its full extent. Indeed,\nthey rely on weak formulations, resulting in slow convergence and large\noptimality gaps. To fill this gap in the literature, we propose a flow-based\nMIP formulation for optimal binary classification trees that has a stronger\nlinear programming relaxation. Our formulation presents an attractive\ndecomposable structure. We exploit this structure and max-flow/min-cut duality\nto derive a Benders' decomposition method, which scales to larger instances. We\nconduct extensive computational experiments on standard benchmark datasets on\nwhich we show that our proposed approaches are 50 times faster than\nstate-of-the art MIP-based techniques and improve out of sample performance up\nto 13.8%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:58:17 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 02:24:34 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Aghaei", "Sina", ""], ["Gomez", "Andres", ""], ["Vayanos", "Phebe", ""]]}, {"id": "2002.09143", "submitter": "Bowen Shi", "authors": "Bowen Shi, Ming Sun, Krishna C. Puvvada, Chieh-Chi Kao, Spyros\n  Matsoukas, Chao Wang", "title": "Few-shot acoustic event detection via meta-learning", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study few-shot acoustic event detection (AED) in this paper. Few-shot\nlearning enables detection of new events with very limited labeled data.\nCompared to other research areas like computer vision, few-shot learning for\naudio recognition has been under-studied. We formulate few-shot AED problem and\nexplore different ways of utilizing traditional supervised methods for this\nsetting as well as a variety of meta-learning approaches, which are\nconventionally used to solve few-shot classification problem. Compared to\nsupervised baselines, meta-learning models achieve superior performance, thus\nshowing its effectiveness on generalization to new audio events. Our analysis\nincluding impact of initialization and domain discrepancy further validate the\nadvantage of meta-learning approaches in few-shot AED.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 06:02:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Shi", "Bowen", ""], ["Sun", "Ming", ""], ["Puvvada", "Krishna C.", ""], ["Kao", "Chieh-Chi", ""], ["Matsoukas", "Spyros", ""], ["Wang", "Chao", ""]]}, {"id": "2002.09145", "submitter": "Yuan Jin", "authors": "Yuan Jin, He Zhao, Ming Liu, Ye Zhu, Lan Du, Longxiang Gao, Wray\n  Buntine", "title": "Leveraging Cross Feedback of User and Item Embeddings with Attention for\n  Variational Autoencoder based Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Matrix factorization (MF) has been widely applied to collaborative filtering\nin recommendation systems. Its Bayesian variants can derive posterior\ndistributions of user and item embeddings, and are more robust to sparse\nratings. However, the Bayesian methods are restricted by their update rules for\nthe posterior parameters due to the conjugacy of the priors and the likelihood.\nVariational autoencoders (VAE) can address this issue by capturing complex\nmappings between the posterior parameters and the data. However, current\nresearch on VAEs for collaborative filtering only considers the mappings based\non the explicit data information while the implicit embedding information is\noverlooked. In this paper, we first derive evidence lower bounds (ELBO) for\nBayesian MF models from two viewpoints: user-oriented and item-oriented. Based\non the ELBOs, we propose a VAE-based Bayesian MF framework. It leverages not\nonly the data but also the embedding information to approximate the user-item\njoint distribution. As suggested by the ELBOs, the approximation is iterative\nwith cross feedback of user and item embeddings into each other's encoders.\nMore specifically, user embeddings sampled at the previous iteration are fed to\nthe item-side encoders to estimate the posterior parameters for the item\nembeddings at the current iteration, and vice versa. The estimation also\nattends to the cross-fed embeddings to further exploit useful information. The\ndecoder then reconstructs the data via the matrix factorization over the\ncurrently re-sampled user and item embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 06:05:06 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 21:32:43 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Jin", "Yuan", ""], ["Zhao", "He", ""], ["Liu", "Ming", ""], ["Zhu", "Ye", ""], ["Du", "Lan", ""], ["Gao", "Longxiang", ""], ["Buntine", "Wray", ""]]}, {"id": "2002.09161", "submitter": "Xinwei Shen", "authors": "Xinwei Shen, Tong Zhang, Kani Chen", "title": "Bidirectional Generative Modeling Using Adversarial Gradient Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the general $f$-divergence formulation of bidirectional\ngenerative modeling, which includes VAE and BiGAN as special cases. We present\na new optimization method for this formulation, where the gradient is computed\nusing an adversarially learned discriminator. In our framework, we show that\ndifferent divergences induce similar algorithms in terms of gradient\nevaluation, except with different scaling. Therefore this paper gives a general\nrecipe for a class of principled $f$-divergence based generative modeling\nmethods. Theoretical justifications and extensive empirical studies are\nprovided to demonstrate the advantage of our approach over existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:28:56 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 10:43:09 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 03:59:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Shen", "Xinwei", ""], ["Zhang", "Tong", ""], ["Chen", "Kani", ""]]}, {"id": "2002.09162", "submitter": "Daniel Andrade", "authors": "Daniel Andrade and Yuzuru Okajima", "title": "Adaptive Covariate Acquisition for Minimizing Total Cost of\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some applications, acquiring covariates comes at a cost which is not\nnegligible. For example in the medical domain, in order to classify whether a\npatient has diabetes or not, measuring glucose tolerance can be expensive.\nAssuming that the cost of each covariate, and the cost of misclassification can\nbe specified by the user, our goal is to minimize the (expected) total cost of\nclassification, i.e. the cost of misclassification plus the cost of the\nacquired covariates. We formalize this optimization goal using the\n(conditional) Bayes risk and describe the optimal solution using a recursive\nprocedure. Since the procedure is computationally infeasible, we consequently\nintroduce two assumptions: (1) the optimal classifier can be represented by a\ngeneralized additive model, (2) the optimal sets of covariates are limited to a\nsequence of sets of increasing size. We show that under these two assumptions,\na computationally efficient solution exists. Furthermore, on several medical\ndatasets, we show that the proposed method achieves in most situations the\nlowest total costs when compared to various previous methods. Finally, we\nweaken the requirement on the user to specify all misclassification costs by\nallowing the user to specify the minimally acceptable recall (target recall).\nOur experiments confirm that the proposed method achieves the target recall\nwhile minimizing the false discovery rate and the covariate acquisition costs\nbetter than previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:30:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Andrade", "Daniel", ""], ["Okajima", "Yuzuru", ""]]}, {"id": "2002.09168", "submitter": "Yujun Shen", "authors": "Mengya Gao, Yujun Shen, Quanquan Li, Chen Change Loy", "title": "Residual Knowledge Distillation", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is one of the most potent ways for model\ncompression. The key idea is to transfer the knowledge from a deep teacher\nmodel (T) to a shallower student (S). However, existing methods suffer from\nperformance degradation due to the substantial gap between the learning\ncapacities of S and T. To remedy this problem, this work proposes Residual\nKnowledge Distillation (RKD), which further distills the knowledge by\nintroducing an assistant (A). Specifically, S is trained to mimic the feature\nmaps of T, and A aids this process by learning the residual error between them.\nIn this way, S and A complement with each other to get better knowledge from T.\nFurthermore, we devise an effective method to derive S and A from a given model\nwithout increasing the total computational cost. Extensive experiments show\nthat our approach achieves appealing results on popular classification\ndatasets, CIFAR-100 and ImageNet, surpassing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:49:26 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Gao", "Mengya", ""], ["Shen", "Yujun", ""], ["Li", "Quanquan", ""], ["Loy", "Chen Change", ""]]}, {"id": "2002.09169", "submitter": "Dinghuai Zhang", "authors": "Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, Qiang Liu", "title": "Black-Box Certification with Randomized Smoothing: A Functional\n  Optimization Based Framework", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized classifiers have been shown to provide a promising approach for\nachieving certified robustness against adversarial attacks in deep learning.\nHowever, most existing methods only leverage Gaussian smoothing noise and only\nwork for $\\ell_2$ perturbation. We propose a general framework of adversarial\ncertification with non-Gaussian noise and for more general types of attacks,\nfrom a unified functional optimization perspective. Our new framework allows us\nto identify a key trade-off between accuracy and robustness via designing\nsmoothing distributions, helping to design new families of non-Gaussian\nsmoothing distributions that work more efficiently for different $\\ell_p$\nsettings, including $\\ell_1$, $\\ell_2$ and $\\ell_\\infty$ attacks. Our proposed\nmethods achieve better certification results than previous works and provide a\nnew perspective on randomized smoothing certification.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:52:47 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:27:06 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Zhang", "Dinghuai", ""], ["Ye", "Mao", ""], ["Gong", "Chengyue", ""], ["Zhu", "Zhanxing", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09174", "submitter": "Quanquan Gu", "authors": "Tianyuan Jin and Pan Xu and Xiaokui Xiao and Quanquan Gu", "title": "Double Explore-then-Commit: Asymptotic Optimality and Beyond", "comments": "46 pages. This version improves the presentation, and adds new\n  algorithms and theoretical results: an anytime algorithm with asymptotic\n  optimality guarantee, and an extension to K-armed bandits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-armed bandit problem with subgaussian rewards. The\nexplore-then-commit (ETC) strategy, which consists of an exploration phase\nfollowed by an exploitation phase, is one of the most widely used algorithms in\na variety of online decision applications. Nevertheless, it has been shown in\nGarivier et al. (2016) that ETC is suboptimal in the asymptotic sense as the\nhorizon grows, and thus, is worse than fully sequential strategies such as\nUpper Confidence Bound (UCB). In this paper, we show that a variant of ETC\nalgorithm can actually achieve the asymptotic optimality for multi-armed bandit\nproblems as UCB-type algorithms do and extend it to the batched bandit setting.\nSpecifically, we propose a double explore-then-commit (DETC) algorithm that has\ntwo exploration and exploitation phases and prove that DETC achieves the\nasymptotically optimal regret bound. To our knowledge, DETC is the first\nnon-fully-sequential algorithm that achieves such asymptotic optimality. In\naddition, we extend DETC to batched bandit problems, where (i) the exploration\nprocess is split into a small number of batches and (ii) the round complexity\nis of central interest. We prove that a batched version of DETC can achieve the\nasymptotic optimality with only a constant round complexity. This is the first\nbatched bandit algorithm that can attain the optimal asymptotic regret bound\nand optimal round complexity simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 08:07:56 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 07:40:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Jin", "Tianyuan", ""], ["Xu", "Pan", ""], ["Xiao", "Xiaokui", ""], ["Gu", "Quanquan", ""]]}, {"id": "2002.09188", "submitter": "Shuichi Kawano", "authors": "Shuichi Kawano", "title": "Sparse principal component regression via singular value decomposition\n  approach", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component regression (PCR) is a two-stage procedure: the first\nstage performs principal component analysis (PCA) and the second stage\nconstructs a regression model whose explanatory variables are replaced by\nprincipal components obtained by the first stage. Since PCA is performed by\nusing only explanatory variables, the principal components have no information\nabout the response variable. To address the problem, we propose a one-stage\nprocedure for PCR in terms of singular value decomposition approach. Our\napproach is based upon two loss functions, a regression loss and a PCA loss,\nwith sparse regularization. The proposed method enables us to obtain principal\ncomponent loadings that possess information about both explanatory variables\nand a response variable. An estimation algorithm is developed by using\nalternating direction method of multipliers. We conduct numerical studies to\nshow the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:03:05 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Kawano", "Shuichi", ""]]}, {"id": "2002.09192", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Renuka Sindhgatta and Chun Ouyang and Peter Bruza\n  and Andreas Wichert", "title": "An Investigation of Interpretability Techniques for Deep Learning in\n  Predictive Process Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores interpretability techniques for two of the most\nsuccessful learning algorithms in medical decision-making literature: deep\nneural networks and random forests. We applied these algorithms in a real-world\nmedical dataset containing information about patients with cancer, where we\nlearn models that try to predict the type of cancer of the patient, given their\nset of medical activity records.\n  We explored different algorithms based on neural network architectures using\nlong short term deep neural networks, and random forests. Since there is a\ngrowing need to provide decision-makers understandings about the logic of\npredictions of black boxes, we also explored different techniques that provide\ninterpretations for these classifiers. In one of the techniques, we intercepted\nsome hidden layers of these neural networks and used autoencoders in order to\nlearn what is the representation of the input in the hidden layers. In another,\nwe investigated an interpretable model locally around the random forest's\nprediction.\n  Results show learning an interpretable model locally around the model's\nprediction leads to a higher understanding of why the algorithm is making some\ndecision. Use of local and linear model helps identify the features used in\nprediction of a specific instance or data point. We see certain distinct\nfeatures used for predictions that provide useful insights about the type of\ncancer, along with features that do not generalize well. In addition, the\nstructured deep learning approach using autoencoders provided meaningful\nprediction insights, which resulted in the identification of nonlinear clusters\ncorrespondent to the patients' different types of cancer.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:14:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Moreira", "Catarina", ""], ["Sindhgatta", "Renuka", ""], ["Ouyang", "Chun", ""], ["Bruza", "Peter", ""], ["Wichert", "Andreas", ""]]}, {"id": "2002.09219", "submitter": "Jean-Yves Franceschi", "authors": "Jean-Yves Franceschi (MLIA), Edouard Delasalles (MLIA), Micka\\\"el Chen\n  (MLIA), Sylvain Lamprier (MLIA), Patrick Gallinari (MLIA)", "title": "Stochastic Latent Residual Video Prediction", "comments": null, "journal-ref": "Thirty-seventh International Conference on Machine Learning,\n  International Machine Learning Society, Jul 2020, Vienne, Austria. pp.89--102", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing video prediction models that account for the inherent uncertainty\nof the future is challenging. Most works in the literature are based on\nstochastic image-autoregressive recurrent networks, which raises several\nperformance and applicability issues. An alternative is to use fully latent\ntemporal models which untie frame synthesis and temporal dynamics. However, no\nsuch model for stochastic video prediction has been proposed in the literature\nyet, due to design and training difficulties. In this paper, we overcome these\ndifficulties by introducing a novel stochastic temporal model whose dynamics\nare governed in a latent space by a residual update rule. This first-order\nscheme is motivated by discretization schemes of differential equations. It\nnaturally models video dynamics as it allows our simpler, more interpretable,\nlatent model to outperform prior state-of-the-art methods on challenging\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:44:01 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 15:50:43 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 14:34:16 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 14:37:21 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Franceschi", "Jean-Yves", "", "MLIA"], ["Delasalles", "Edouard", "", "MLIA"], ["Chen", "Micka\u00ebl", "", "MLIA"], ["Lamprier", "Sylvain", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2002.09225", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Wittawat Jitkrittum, Jonas K\\\"ubler", "title": "Kernel Conditional Moment Test via Maximum Moment Restriction", "comments": "In Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of specification tests called kernel conditional\nmoment (KCM) tests. Our tests are built on a novel representation of\nconditional moment restrictions in a reproducing kernel Hilbert space (RKHS)\ncalled conditional moment embedding (CMME). After transforming the conditional\nmoment restrictions into a continuum of unconditional counterparts, the test\nstatistic is defined as the maximum moment restriction (MMR) within the unit\nball of the RKHS. We show that the MMR not only fully characterizes the\noriginal conditional moment restrictions, leading to consistency in both\nhypothesis testing and parameter estimation, but also has an analytic\nexpression that is easy to compute as well as closed-form asymptotic\ndistributions. Our empirical studies show that the KCM test has a promising\nfinite-sample performance compared to existing tests.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:58:57 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 14:05:18 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 18:08:23 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Muandet", "Krikamol", ""], ["Jitkrittum", "Wittawat", ""], ["K\u00fcbler", "Jonas", ""]]}, {"id": "2002.09237", "submitter": "S\\\"oren Klemm", "authors": "Karim Huesmann, Soeren Klemm, Lars Linsen and Benjamin Risse", "title": "Exploiting the Full Capacity of Deep Neural Networks while Avoiding\n  Overfitting by Targeted Sparsity Regularization", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Overfitting is one of the most common problems when training deep neural\nnetworks on comparatively small datasets. Here, we demonstrate that neural\nnetwork activation sparsity is a reliable indicator for overfitting which we\nutilize to propose novel targeted sparsity visualization and regularization\nstrategies. Based on these strategies we are able to understand and counteract\noverfitting caused by activation sparsity and filter correlation in a targeted\nlayer-by-layer manner. Our results demonstrate that targeted sparsity\nregularization can efficiently be used to regularize well-known datasets and\narchitectures with a significant increase in image classification performance\nwhile outperforming both dropout and batch normalization. Ultimately, our study\nreveals novel insights into the contradicting concepts of activation sparsity\nand network capacity by demonstrating that targeted sparsity regularization\nenables salient and discriminative feature learning while exploiting the full\ncapacity of deep models without suffering from overfitting, even when trained\nexcessively.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 11:38:17 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Huesmann", "Karim", ""], ["Klemm", "Soeren", ""], ["Linsen", "Lars", ""], ["Risse", "Benjamin", ""]]}, {"id": "2002.09249", "submitter": "Marcell Beregi-Kov\\'acs", "authors": "Marcell Beregi-Kov\\'acs, \\'Agnes Baran and Andr\\'as Hajdu", "title": "Efficient Learning of Model Weights via Changing Features During\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a machine learning model, which dynamically changes\nthe features during training. Our main motivation is to update the model in a\nsmall content during the training process with replacing less descriptive\nfeatures to new ones from a large pool. The main benefit is coming from the\nfact that opposite to the common practice we do not start training a new model\nfrom the scratch, but can keep the already learned weights. This procedure\nallows the scan of a large feature pool which together with keeping the\ncomplexity of the model leads to an increase of the model accuracy within the\nsame training time. The efficiency of our approach is demonstrated in several\nclassic machine learning scenarios including linear regression and neural\nnetwork-based training. As a specific analysis towards signal processing, we\nhave successfully tested our approach on the database MNIST for digit\nclassification considering single pixel and pixel-pairs intensities as possible\nfeatures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:38:14 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Beregi-Kov\u00e1cs", "Marcell", ""], ["Baran", "\u00c1gnes", ""], ["Hajdu", "Andr\u00e1s", ""]]}, {"id": "2002.09261", "submitter": "Jerome Dockes", "authors": "J\\'er\\^ome Dock\\`es (Inria), Russell Poldrack, Romain Primet (Inria),\n  Hande G\\\"oz\\\"ukan (Inria), Tal Yarkoni (University of Texas), Fabian\n  Suchanek, Bertrand Thirion (Inria), Ga\\\"el Varoquaux (Inria)", "title": "NeuroQuery: comprehensive meta-analysis of human brain mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reaching a global view of brain organization requires assembling evidence on\nwidely different mental processes and mechanisms. The variety of human\nneuroscience concepts and terminology poses a fundamental challenge to relating\nbrain imaging results across the scientific literature. Existing meta-analysis\nmethods perform statistical tests on sets of publications associated with a\nparticular concept. Thus, large-scale meta-analyses only tackle single terms\nthat occur frequently. We propose a new paradigm, focusing on prediction rather\nthan inference. Our multivariate model predicts the spatial distribution of\nneurological observations, given text describing an experiment, cognitive\nprocess, or disease. This approach handles text of arbitrary length and terms\nthat are too rare for standard meta-analysis. We capture the relationships and\nneural correlates of 7 547 neuroscience terms across 13 459 neuroimaging\npublications. The resulting meta-analytic tool, neuroquery.org, can ground\nhypothesis generation and data-analysis priors on a comprehensive view of\npublished findings on the brain.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:13:22 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Dock\u00e8s", "J\u00e9r\u00f4me", "", "Inria"], ["Poldrack", "Russell", "", "Inria"], ["Primet", "Romain", "", "Inria"], ["G\u00f6z\u00fckan", "Hande", "", "Inria"], ["Yarkoni", "Tal", "", "University of Texas"], ["Suchanek", "Fabian", "", "Inria"], ["Thirion", "Bertrand", "", "Inria"], ["Varoquaux", "Ga\u00ebl", "", "Inria"]]}, {"id": "2002.09268", "submitter": "Peter Davies", "authors": "Peter Davies, Vijaykrishna Gurunathan, Niusha Moshrefi, Saleh\n  Ashkboos, Dan Alistarh", "title": "New Bounds For Distributed Mean Estimation and Variance Reduction", "comments": "42 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed mean estimation (DME), in which $n$\nmachines are each given a local $d$-dimensional vector $x_v \\in \\mathbb{R}^d$,\nand must cooperate to estimate the mean of their inputs $\\mu = \\frac 1n\\sum_{v\n= 1}^n x_v$, while minimizing total communication cost.\n  DME is a fundamental construct in distributed machine learning, and there has\nbeen considerable work on variants of this problem, especially in the context\nof distributed variance reduction for stochastic gradients in parallel SGD.\nPrevious work typically assumes an upper bound on the norm of the input\nvectors, and achieves an error bound in terms of this norm. However, in many\nreal applications, the input vectors are concentrated around the correct output\n$\\mu$, but $\\mu$ itself has large norm. In such cases, previous output error\nbounds perform poorly.\n  In this paper, we show that output error bounds need not depend on input\nnorm. We provide a method of quantization which allows distributed mean\nestimation to be performed with solution quality dependent only on the distance\nbetween inputs, not on input norm, and show an analogous result for distributed\nvariance reduction. The technique is based on a new connection with lattice\ntheory. We also provide lower bounds showing that the communication to error\ntrade-off of our algorithms is asymptotically optimal.\n  As the lattices achieving optimal bounds under $\\ell_2$-norm can be\ncomputationally impractical, we also present an extension which leverages\neasy-to-use cubic lattices, and is loose only up to a logarithmic factor in\n$d$. We show experimentally that our method yields practical improvements for\ncommon applications, relative to prior approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:27:13 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 14:33:28 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 14:03:21 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 15:50:18 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Davies", "Peter", ""], ["Gurunathan", "Vijaykrishna", ""], ["Moshrefi", "Niusha", ""], ["Ashkboos", "Saleh", ""], ["Alistarh", "Dan", ""]]}, {"id": "2002.09269", "submitter": "Binh T. Nguyen", "authors": "Tuan-Binh Nguyen, J\\'er\\^ome-Alexis Chevalier, Bertrand Thirion,\n  Sylvain Arlot", "title": "Aggregation of Multiple Knockoffs", "comments": "Accepted to ICML 2020 (Thirty-seventh International Conference on\n  Machine Learning). This version includes both the main text of the conference\n  paper and supplementary materials (as appendices). 35 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an extension of the Knockoff Inference procedure, introduced by\nBarber and Candes (2015). This new method, called Aggregation of Multiple\nKnockoffs (AKO), addresses the instability inherent to the random nature of\nKnockoff-based inference. Specifically, AKO improves both the stability and\npower compared with the original Knockoff algorithm while still maintaining\nguarantees for False Discovery Rate control. We provide a new inference\nprocedure, prove its core properties, and demonstrate its benefits in a set of\nexperiments on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:28:40 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 14:26:21 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Nguyen", "Tuan-Binh", ""], ["Chevalier", "J\u00e9r\u00f4me-Alexis", ""], ["Thirion", "Bertrand", ""], ["Arlot", "Sylvain", ""]]}, {"id": "2002.09277", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Suriya Gunasekar, Jason D. Lee, Edward Moroshko,\n  Pedro Savarese, Itay Golan, Daniel Soudry, Nathan Srebro", "title": "Kernel and Rich Regimes in Overparametrized Models", "comments": "This updates and significantly extends a previous article\n  (arXiv:1906.05827), Sections 6 and 7 are the most major additions. 31 pages.\n  arXiv admin note: text overlap with arXiv:1906.05827", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work studies overparametrized neural networks in the \"kernel\nregime,\" i.e. when the network behaves during training as a kernelized linear\npredictor, and thus training with gradient descent has the effect of finding\nthe minimum RKHS norm solution. This stands in contrast to other studies which\ndemonstrate how gradient descent on overparametrized multilayer networks can\ninduce rich implicit biases that are not RKHS norms. Building on an observation\nby Chizat and Bach, we show how the scale of the initialization controls the\ntransition between the \"kernel\" (aka lazy) and \"rich\" (aka active) regimes and\naffects generalization properties in multilayer homogeneous models. We also\nhighlight an interesting role for the width of a model in the case that the\npredictor is not identically zero at initialization. We provide a complete and\ndetailed analysis for a family of simple depth-$D$ models that already exhibit\nan interesting and meaningful transition between the kernel and rich regimes,\nand we also demonstrate this transition empirically for more complex matrix\nfactorization models and multilayer non-linear networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:43:02 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:41:49 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 15:04:41 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Woodworth", "Blake", ""], ["Gunasekar", "Suriya", ""], ["Lee", "Jason D.", ""], ["Moroshko", "Edward", ""], ["Savarese", "Pedro", ""], ["Golan", "Itay", ""], ["Soudry", "Daniel", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.09286", "submitter": "M. Umut Isik", "authors": "Jonah Casebeer, Umut Isik, Shrikant Venkataramani, Arvindh\n  Krishnaswamy", "title": "Efficient Trainable Front-Ends for Neural Speech Enhancement", "comments": "5 pages, 5 figures, ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural speech enhancement and source separation systems operate in the\ntime-frequency domain. Such models often benefit from making their Short-Time\nFourier Transform (STFT) front-ends trainable. In current literature, these are\nimplemented as large Discrete Fourier Transform matrices; which are\nprohibitively inefficient for low-compute systems. We present an efficient,\ntrainable front-end based on the butterfly mechanism to compute the Fast\nFourier Transform, and show its accuracy and efficiency benefits for\nlow-compute neural speech enhancement models. We also explore the effects of\nmaking the STFT window trainable.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:51:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Casebeer", "Jonah", ""], ["Isik", "Umut", ""], ["Venkataramani", "Shrikant", ""], ["Krishnaswamy", "Arvindh", ""]]}, {"id": "2002.09291", "submitter": "Simiao Zuo", "authors": "Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, Hongyuan Zha", "title": "Transformer Hawkes Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data acquisition routinely produce massive amounts of event sequence\ndata in various domains, such as social media, healthcare, and financial\nmarkets. These data often exhibit complicated short-term and long-term temporal\ndependencies. However, most of the existing recurrent neural network based\npoint process models fail to capture such dependencies, and yield unreliable\nprediction performance. To address this issue, we propose a Transformer Hawkes\nProcess (THP) model, which leverages the self-attention mechanism to capture\nlong-term dependencies and meanwhile enjoys computational efficiency. Numerical\nexperiments on various datasets show that THP outperforms existing models in\nterms of both likelihood and event prediction accuracy by a notable margin.\nMoreover, THP is quite general and can incorporate additional structural\nknowledge. We provide a concrete example, where THP achieves improved\nprediction performance for learning multiple point processes when incorporating\ntheir relational information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:48:13 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 20:43:41 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 21:57:17 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 15:44:31 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 01:59:26 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zuo", "Simiao", ""], ["Jiang", "Haoming", ""], ["Li", "Zichong", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.09301", "submitter": "Hans Kersting", "authors": "Hans Kersting, Nicholas Kr\\\"amer, Martin Schiegg, Christian Daniel,\n  Michael Tiemann, Philipp Hennig", "title": "Differentiable Likelihoods for Fast Inversion of 'Likelihood-Free'\n  Dynamical Systems", "comments": "11 pages (+ 5 pages appendix), 6 figures", "journal-ref": null, "doi": null, "report-no": "Published at ICML 2020", "categories": "stat.ML cs.LG cs.NA math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free (a.k.a. simulation-based) inference problems are inverse\nproblems with expensive, or intractable, forward models. ODE inverse problems\nare commonly treated as likelihood-free, as their forward map has to be\nnumerically approximated by an ODE solver. This, however, is not a fundamental\nconstraint but just a lack of functionality in classic ODE solvers, which do\nnot return a likelihood but a point estimate. To address this shortcoming, we\nemploy Gaussian ODE filtering (a probabilistic numerical method for ODEs) to\nconstruct a local Gaussian approximation to the likelihood. This approximation\nyields tractable estimators for the gradient and Hessian of the\n(log-)likelihood. Insertion of these estimators into existing gradient-based\noptimization and sampling methods engenders new solvers for ODE inverse\nproblems. We demonstrate that these methods outperform standard likelihood-free\napproaches on three benchmark-systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:00:15 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:06:37 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kersting", "Hans", ""], ["Kr\u00e4mer", "Nicholas", ""], ["Schiegg", "Martin", ""], ["Daniel", "Christian", ""], ["Tiemann", "Michael", ""], ["Hennig", "Philipp", ""]]}, {"id": "2002.09304", "submitter": "Gabriel Turinici", "authors": "Imen Ayadi (CEREMADE), Gabriel Turinici (CEREMADE)", "title": "Stochastic Runge-Kutta methods and adaptive SGD-G2 stochastic gradient\n  descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of the loss function is of paramount importance in deep\nneural networks. On the other hand, many popular optimization algorithms have\nbeen shown to correspond to some evolution equation of gradient flow type.\nInspired by the numerical schemes used for general evolution equations we\nintroduce a second order stochastic Runge Kutta method and show that it yields\na consistent procedure for the minimization of the loss function. In addition\nit can be coupled, in an adaptive framework, with a Stochastic Gradient Descent\n(SGD) to adjust automatically the learning rate of the SGD, without the need of\nany additional information on the Hessian of the loss functional. The adaptive\nSGD, called SGD-G2, is successfully tested on standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:45:53 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ayadi", "Imen", "", "CEREMADE"], ["Turinici", "Gabriel", "", "CEREMADE"]]}, {"id": "2002.09309", "submitter": "Alexander Terenin", "authors": "James T. Wilson and Viacheslav Borovitskiy and Alexander Terenin and\n  Peter Mostowsky and Marc Peter Deisenroth", "title": "Efficiently Sampling Functions from Gaussian Process Posteriors", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are the gold standard for many real-world modeling\nproblems, especially in cases where a model's success hinges upon its ability\nto faithfully represent predictive uncertainty. These problems typically exist\nas parts of larger frameworks, wherein quantities of interest are ultimately\ndefined by integrating over posterior distributions. These quantities are\nfrequently intractable, motivating the use of Monte Carlo methods. Despite\nsubstantial progress in scaling up Gaussian processes to large training sets,\nmethods for accurately generating draws from their posterior distributions\nstill scale cubically in the number of test locations. We identify a\ndecomposition of Gaussian processes that naturally lends itself to scalable\nsampling by separating out the prior from the data. Building off of this\nfactorization, we propose an easy-to-use and general-purpose approach for fast\nposterior sampling, which seamlessly pairs with sparse approximations to afford\nscalability both during training and at test time. In a series of experiments\ndesigned to test competing sampling schemes' statistical properties and\npractical ramifications, we demonstrate how decoupled sample paths accurately\nrepresent Gaussian process posteriors at a fraction of the usual cost.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:03:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 16:22:27 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 18:13:39 GMT"}, {"version": "v4", "created": "Sun, 16 Aug 2020 13:37:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wilson", "James T.", ""], ["Borovitskiy", "Viacheslav", ""], ["Terenin", "Alexander", ""], ["Mostowsky", "Peter", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2002.09339", "submitter": "Bruno Loureiro", "authors": "Federica Gerace, Bruno Loureiro, Florent Krzakala, Marc M\\'ezard and\n  Lenka Zdeborov\\'a", "title": "Generalisation error in learning with random features and the hidden\n  manifold model", "comments": "v2: ICML 2020 camera-ready", "journal-ref": "International Conference on Machine Learning, ICML 2020", "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalised linear regression and classification for a synthetically\ngenerated dataset encompassing different problems of interest, such as learning\nwith random features, neural networks in the lazy training regime, and the\nhidden manifold model. We consider the high-dimensional regime and using the\nreplica method from statistical physics, we provide a closed-form expression\nfor the asymptotic generalisation performance in these problems, valid in both\nthe under- and over-parametrised regimes and for a broad choice of generalised\nlinear model loss functions. In particular, we show how to obtain analytically\nthe so-called double descent behaviour for logistic regression with a peak at\nthe interpolation threshold, we illustrate the superiority of orthogonal\nagainst random Gaussian projections in learning with random features, and\ndiscuss the role played by correlations in the data generated by the hidden\nmanifold model. Beyond the interest in these particular problems, the\ntheoretical formalism introduced in this manuscript provides a path to further\nextensions to more complex tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:49:41 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 08:32:53 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Gerace", "Federica", ""], ["Loureiro", "Bruno", ""], ["Krzakala", "Florent", ""], ["M\u00e9zard", "Marc", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2002.09343", "submitter": "Wenshuo Guo", "authors": "Serena Wang, Wenshuo Guo, Harikrishna Narasimhan, Andrew Cotter, Maya\n  Gupta, Michael I. Jordan", "title": "Robust Optimization for Fairness with Noisy Protected Groups", "comments": "To appear at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020); first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing fairness criteria for machine learning involve equalizing some\nmetric across protected groups such as race or gender. However, practitioners\ntrying to audit or enforce such group-based criteria can easily face the\nproblem of noisy or biased protected group information. First, we study the\nconsequences of naively relying on noisy protected group labels: we provide an\nupper bound on the fairness violations on the true groups G when the fairness\ncriteria are satisfied on noisy groups $\\hat{G}$. Second, we introduce two new\napproaches using robust optimization that, unlike the naive approach of only\nrelying on $\\hat{G}$, are guaranteed to satisfy fairness criteria on the true\nprotected groups G while minimizing a training objective. We provide\ntheoretical guarantees that one such approach converges to an optimal feasible\nsolution. Using two case studies, we show empirically that the robust\napproaches achieve better true group fairness guarantees than the naive\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:58:37 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:21:20 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 05:37:29 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Serena", ""], ["Guo", "Wenshuo", ""], ["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""], ["Gupta", "Maya", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.09358", "submitter": "Achraf Bennis", "authors": "Achraf Bennis (IRIT), Sandrine Mouysset (IRIT), Mathieu Serrurier\n  (IRIT)", "title": "Estimation of conditional mixture Weibull distribution with\n  right-censored data using neural network for time-to-event analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider survival analysis with right-censored data which\nis a common situation in predictive maintenance and health field. We propose a\nmodel based on the estimation of two-parameter Weibull distribution\nconditionally to the features. To achieve this result, we describe a neural\nnetwork architecture and the associated loss functions that takes into account\nthe right-censored data. We extend the approach to a finite mixture of\ntwo-parameter Weibull distributions. We first validate that our model is able\nto precisely estimate the right parameters of the conditional Weibull\ndistribution on synthetic datasets. In numerical experiments on two real-word\ndatasets (METABRIC and SEER), our model outperforms the state-of-the-art\nmethods. We also demonstrate that our approach can consider any survival time\nhorizon.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 15:32:06 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Bennis", "Achraf", "", "IRIT"], ["Mouysset", "Sandrine", "", "IRIT"], ["Serrurier", "Mathieu", "", "IRIT"]]}, {"id": "2002.09364", "submitter": "Arnaud Van Looveren", "authors": "Giovanni Vacanti and Arnaud Van Looveren", "title": "Adversarial Detection and Correction by Matching Prediction\n  Distributions", "comments": "13 pages, 16 figures. For an open source implementation of the\n  algorithm, see https://github.com/SeldonIO/alibi-detect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel adversarial detection and correction method for machine\nlearning classifiers.The detector consists of an autoencoder trained with a\ncustom loss function based on the Kullback-Leibler divergence between the\nclassifier predictions on the original and reconstructed instances.The method\nis unsupervised, easy to train and does not require any knowledge about the\nunderlying attack. The detector almost completely neutralises powerful attacks\nlike Carlini-Wagner or SLIDE on MNIST and Fashion-MNIST, and remains very\neffective on CIFAR-10 when the attack is granted full access to the\nclassification model but not the defence. We show that our method is still able\nto detect the adversarial examples in the case of a white-box attack where the\nattacker has full knowledge of both the model and the defence and investigate\nthe robustness of the attack. The method is very flexible and can also be used\nto detect common data corruptions and perturbations which negatively impact the\nmodel performance. We illustrate this capability on the CIFAR-10-C dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 15:45:42 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Vacanti", "Giovanni", ""], ["Van Looveren", "Arnaud", ""]]}, {"id": "2002.09377", "submitter": "Owen Thomas", "authors": "Owen Thomas, Henri Pesonen, Raquel S\\'a-Le\\~ao, Herm\\'inia de\n  Lencastre, Samuel Kaski, Jukka Corander", "title": "Split-BOLFI for for misspecification-robust likelihood free inference in\n  high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free inference for simulator-based statistical models has recently\ngrown rapidly from its infancy to a useful tool for practitioners. However,\nmodels with more than a very small number of parameters as the target of\ninference have remained an enigma, in particular for the approximate Bayesian\ncomputation (ABC) community. To advance the possibilities for performing\nlikelihood-free inference in high-dimensional parameter spaces, here we\nintroduce an extension of the popular Bayesian optimisation based approach to\napproximate discrepancy functions in a probabilistic manner which lends itself\nto an efficient exploration of the parameter space. Our method achieves\ncomputational scalability by using separate acquisition procedures for the\ndiscrepancies defined for different parameters. These efficient\nhigh-dimensional simulation acquisitions are combined with exponentiated\nloss-likelihoods to provide a misspecification-robust characterisation of the\nmarginal posterior distribution for all model parameters. The method\nsuccessfully performs computationally efficient inference in a 100-dimensional\nspace on canonical examples and compares favourably to existing Copula-ABC\nmethods. We further illustrate the potential of this approach by fitting a\nbacterial transmission dynamics model to daycare centre data, which provides\nbiologically coherent results on the strain competition in a 30-dimensional\nparameter space.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:06:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Thomas", "Owen", ""], ["Pesonen", "Henri", ""], ["S\u00e1-Le\u00e3o", "Raquel", ""], ["de Lencastre", "Herm\u00ednia", ""], ["Kaski", "Samuel", ""], ["Corander", "Jukka", ""]]}, {"id": "2002.09398", "submitter": "Moshe Gabel", "authors": "Gal Yehuda, Moshe Gabel, Assaf Schuster", "title": "It's Not What Machines Can Learn, It's What We Cannot Teach", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can deep neural networks learn to solve any task, and in particular problems\nof high complexity? This question attracts a lot of interest, with recent works\ntackling computationally hard tasks such as the traveling salesman problem and\nsatisfiability. In this work we offer a different perspective on this question.\nGiven the common assumption that $\\textit{NP} \\neq \\textit{coNP}$ we prove that\nany polynomial-time sample generator for an $\\textit{NP}$-hard problem samples,\nin fact, from an easier sub-problem. We empirically explore a case study,\nConjunctive Query Containment, and show how common data generation techniques\ngenerate biased datasets that lead practitioners to over-estimate model\naccuracy. Our results suggest that machine learning approaches that require\ntraining on a dense uniform sampling from the target distribution cannot be\nused to solve computationally hard problems, the reason being the difficulty of\ngenerating sufficiently large and unbiased training sets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:26:55 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 16:43:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yehuda", "Gal", ""], ["Gabel", "Moshe", ""], ["Schuster", "Assaf", ""]]}, {"id": "2002.09402", "submitter": "Sainbayar Sukhbaatar", "authors": "Angela Fan, Thibaut Lavril, Edouard Grave, Armand Joulin, Sainbayar\n  Sukhbaatar", "title": "Addressing Some Limitations of Transformers with Feedback Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have been successfully applied to sequential, auto-regressive\ntasks despite being feedforward networks. Unlike recurrent neural networks,\nTransformers use attention to capture temporal relations while processing input\ntokens in parallel. While this parallelization makes them computationally\nefficient, it restricts the model from fully exploiting the sequential nature\nof the input. The representation at a given layer can only access\nrepresentations from lower layers, rather than the higher level representations\nalready available. In this work, we propose the Feedback Transformer\narchitecture that exposes all previous representations to all future\nrepresentations, meaning the lowest representation of the current timestep is\nformed from the highest-level abstract representation of the past. We\ndemonstrate on a variety of benchmarks in language modeling, machine\ntranslation, and reinforcement learning that the increased representation\ncapacity can create small, shallow models with much stronger performance than\ncomparable Transformers.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:37:57 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 09:21:14 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 13:12:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fan", "Angela", ""], ["Lavril", "Thibaut", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Sukhbaatar", "Sainbayar", ""]]}, {"id": "2002.09405", "submitter": "Alvaro Sanchez-Gonzalez", "authors": "Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure\n  Leskovec, Peter W. Battaglia", "title": "Learning to Simulate Complex Physics with Graph Networks", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a machine learning framework and model implementation that\ncan learn to simulate a wide variety of challenging physical domains, involving\nfluids, rigid solids, and deformable materials interacting with one another.\nOur framework---which we term \"Graph Network-based Simulators\"\n(GNS)---represents the state of a physical system with particles, expressed as\nnodes in a graph, and computes dynamics via learned message-passing. Our\nresults show that our model can generalize from single-timestep predictions\nwith thousands of particles during training, to different initial conditions,\nthousands of timesteps, and at least an order of magnitude more particles at\ntest time. Our model was robust to hyperparameter choices across various\nevaluation metrics: the main determinants of long-term performance were the\nnumber of message-passing steps, and mitigating the accumulation of error by\ncorrupting the training data with noise. Our GNS framework advances the\nstate-of-the-art in learned physical simulation, and holds promise for solving\na wide range of complex forward and inverse problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:44:28 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 16:52:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sanchez-Gonzalez", "Alvaro", ""], ["Godwin", "Jonathan", ""], ["Pfaff", "Tobias", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "2002.09420", "submitter": "Robin Vogel", "authors": "Stephan Cl\\'emen\\c{c}on, Robin Vogel", "title": "A Multiclass Classification Approach to Label Ranking", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiclass classification, the goal is to learn how to predict a random\nlabel $Y$, valued in $\\mathcal{Y}=\\{1,\\; \\ldots,\\; K \\}$ with $K\\geq 3$, based\nupon observing a r.v. $X$, taking its values in $\\mathbb{R}^q$ with $q\\geq 1$\nsay, by means of a classification rule $g:\\mathbb{R}^q\\to \\mathcal{Y}$ with\nminimum probability of error $\\mathbb{P}\\{Y\\neq g(X) \\}$. However, in a wide\nvariety of situations, the task targeted may be more ambitious, consisting in\nsorting all the possible label values $y$ that may be assigned to $X$ by\ndecreasing order of the posterior probability $\\eta_y(X)=\\mathbb{P}\\{Y=y \\mid X\n\\}$. This article is devoted to the analysis of this statistical learning\nproblem, halfway between multiclass classification and posterior probability\nestimation (regression) and referred to as label ranking here. We highlight the\nfact that it can be viewed as a specific variant of ranking median regression\n(RMR), where, rather than observing a random permutation $\\Sigma$ assigned to\nthe input vector $X$ and drawn from a Bradley-Terry-Luce-Plackett model with\nconditional preference vector $(\\eta_1(X),\\; \\ldots,\\; \\eta_K(X))$, the sole\ninformation available for training a label ranking rule is the label $Y$ ranked\non top, namely $\\Sigma^{-1}(1)$. Inspired by recent results in RMR, we prove\nthat under appropriate noise conditions, the One-Versus-One (OVO) approach to\nmulticlassification yields, as a by-product, an optimal ranking of the labels\nwith overwhelming probability. Beyond theoretical guarantees, the relevance of\nthe approach to label ranking promoted in this article is supported by\nexperimental results.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:12:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Cl\u00e9men\u00e7on", "Stephan", ""], ["Vogel", "Robin", ""]]}, {"id": "2002.09422", "submitter": "Sharon Qian", "authors": "Sharon Qian, Dimitris Kalimeris, Gal Kaplun, Yaron Singer", "title": "Robustness from Simple Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the vast success of Deep Neural Networks in numerous application\ndomains, it has been shown that such models are not robust i.e., they are\nvulnerable to small adversarial perturbations of the input. While extensive\nwork has been done on why such perturbations occur or how to successfully\ndefend against them, we still do not have a complete understanding of\nrobustness. In this work, we investigate the connection between robustness and\nsimplicity. We find that simpler classifiers, formed by reducing the number of\noutput classes, are less susceptible to adversarial perturbations.\nConsequently, we demonstrate that decomposing a complex multiclass model into\nan aggregation of binary models enhances robustness. This behavior is\nconsistent across different datasets and model architectures and can be\ncombined with known defense techniques such as adversarial training. Moreover,\nwe provide further evidence of a disconnect between standard and robust\nlearning regimes. In particular, we show that elaborate label information can\nhelp standard accuracy but harm robustness.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:13:37 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Qian", "Sharon", ""], ["Kalimeris", "Dimitris", ""], ["Kaplun", "Gal", ""], ["Singer", "Yaron", ""]]}, {"id": "2002.09423", "submitter": "David Torpey", "authors": "David Torpey and Turgay Celik", "title": "Human Action Recognition using Local Two-Stream Convolution Neural\n  Network Features and Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple yet effective method for human action\nrecognition in video. The proposed method separately extracts local appearance\nand motion features using state-of-the-art three-dimensional convolutional\nneural networks from sampled snippets of a video. These local features are then\nconcatenated to form global representations which are then used to train a\nlinear SVM to perform the action classification using full context of the\nvideo, as partial context as used in previous works. The videos undergo two\nsimple proposed preprocessing techniques, optical flow scaling and crop\nfilling. We perform an extensive evaluation on three common benchmark dataset\nto empirically show the benefit of the SVM, and the two preprocessing steps.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:26:32 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Torpey", "David", ""], ["Celik", "Turgay", ""]]}, {"id": "2002.09424", "submitter": "David Torpey", "authors": "Ziyad Jappie and David Torpey and Turgay Celik", "title": "SummaryNet: A Multi-Stage Deep Learning Model for Automatic Video\n  Summarisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video summarisation can be posed as the task of extracting important parts of\na video in order to create an informative summary of what occurred in the\nvideo. In this paper we introduce SummaryNet as a supervised learning framework\nfor automated video summarisation. SummaryNet employs a two-stream\nconvolutional network to learn spatial (appearance) and temporal (motion)\nrepresentations. It utilizes an encoder-decoder model to extract the most\nsalient features from the learned video representations. Lastly, it uses a\nsigmoid regression network with bidirectional long short-term memory cells to\npredict the probability of a frame being a summary frame. Experimental results\non benchmark datasets show that the proposed method achieves comparable or\nsignificantly better results than the state-of-the-art video summarisation\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:24:35 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jappie", "Ziyad", ""], ["Torpey", "David", ""], ["Celik", "Turgay", ""]]}, {"id": "2002.09434", "submitter": "Qi Lei", "authors": "Simon S. Du, Wei Hu, Sham M. Kakade, Jason D. Lee, Qi Lei", "title": "Few-Shot Learning via Learning the Representation, Provably", "comments": "ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies few-shot learning via representation learning, where one\nuses $T$ source tasks with $n_1$ data per task to learn a representation in\norder to reduce the sample complexity of a target task for which there is only\n$n_2 (\\ll n_1)$ data. Specifically, we focus on the setting where there exists\na good \\emph{common representation} between source and target, and our goal is\nto understand how much of a sample size reduction is possible. First, we study\nthe setting where this common representation is low-dimensional and provide a\nfast rate of $O\\left(\\frac{\\mathcal{C}\\left(\\Phi\\right)}{n_1T} +\n\\frac{k}{n_2}\\right)$; here, $\\Phi$ is the representation function class,\n$\\mathcal{C}\\left(\\Phi\\right)$ is its complexity measure, and $k$ is the\ndimension of the representation. When specialized to linear representation\nfunctions, this rate becomes $O\\left(\\frac{dk}{n_1T} + \\frac{k}{n_2}\\right)$\nwhere $d (\\gg k)$ is the ambient input dimension, which is a substantial\nimprovement over the rate without using representation learning, i.e. over the\nrate of $O\\left(\\frac{d}{n_2}\\right)$. This result bypasses the\n$\\Omega(\\frac{1}{T})$ barrier under the i.i.d. task assumption, and can capture\nthe desired property that all $n_1T$ samples from source tasks can be\n\\emph{pooled} together for representation learning. Next, we consider the\nsetting where the common representation may be high-dimensional but is\ncapacity-constrained (say in norm); here, we again demonstrate the advantage of\nrepresentation learning in both high-dimensional linear regression and neural\nnetwork learning. Our results demonstrate representation learning can fully\nutilize all $n_1T$ samples from source tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:30:00 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 04:06:04 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2002.09437", "submitter": "Viveka Kulharia", "authors": "Jishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz,\n  Philip H.S. Torr, Puneet K. Dokania", "title": "Calibrating Deep Neural Networks using Focal Loss", "comments": "This paper was accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Miscalibration - a mismatch between a model's confidence and its correctness\n- of Deep Neural Networks (DNNs) makes their predictions hard to rely on.\nIdeally, we want networks to be accurate, calibrated and confident. We show\nthat, as opposed to the standard cross-entropy loss, focal loss [Lin et. al.,\n2017] allows us to learn models that are already very well calibrated. When\ncombined with temperature scaling, whilst preserving accuracy, it yields\nstate-of-the-art calibrated models. We provide a thorough analysis of the\nfactors causing miscalibration, and use the insights we glean from this to\njustify the empirically excellent performance of focal loss. To facilitate the\nuse of focal loss in practice, we also provide a principled approach to\nautomatically select the hyperparameter involved in the loss function. We\nperform extensive experiments on a variety of computer vision and NLP datasets,\nand with a wide variety of network architectures, and show that our approach\nachieves state-of-the-art calibration without compromising on accuracy in\nalmost all cases. Code is available at\nhttps://github.com/torrvision/focal_calibration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:35:50 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:22:17 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mukhoti", "Jishnu", ""], ["Kulharia", "Viveka", ""], ["Sanyal", "Amartya", ""], ["Golodetz", "Stuart", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "2002.09438", "submitter": "Guang Cheng", "authors": "Chi-Hua Wang, Guang Cheng", "title": "Online Batch Decision-Making with High-Dimensional Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate a class of new algorithms for sequential decision\nmaking that interacts with \\textit{a batch of users} simultaneously instead of\n\\textit{a user} at each decision epoch. This type of batch models is motivated\nby interactive marketing and clinical trial, where a group of people are\ntreated simultaneously and the outcomes of the whole group are collected before\nthe next stage of decision. In such a scenario, our goal is to allocate a batch\nof treatments to maximize treatment efficacy based on observed high-dimensional\nuser covariates. We deliver a solution, named \\textit{Teamwork LASSO Bandit\nalgorithm}, that resolves a batch version of explore-exploit dilemma via\nswitching between teamwork stage and selfish stage during the whole decision\nprocess. This is made possible based on statistical properties of LASSO\nestimate of treatment efficacy that adapts to a sequence of batch observations.\nIn general, a rate of optimal allocation condition is proposed to delineate the\nexploration and exploitation trade-off on the data collection scheme, which is\nsufficient for LASSO to identify the optimal treatment for observed user\ncovariates. An upper bound on expected cumulative regret of the proposed\nalgorithm is provided.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:36:15 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 20:43:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Wang", "Chi-Hua", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.09463", "submitter": "Huanyu Zhang", "authors": "Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, Zhiwei Steven Wu", "title": "Privately Learning Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning Markov Random Fields (including the\nprototypical example, the Ising model) under the constraint of differential\nprivacy. Our learning goals include both structure learning, where we try to\nestimate the underlying graph structure of the model, as well as the harder\ngoal of parameter learning, in which we additionally estimate the parameter on\neach edge. We provide algorithms and lower bounds for both problems under a\nvariety of privacy constraints -- namely pure, concentrated, and approximate\ndifferential privacy. While non-privately, both learning goals enjoy roughly\nthe same complexity, we show that this is not the case under differential\nprivacy. In particular, only structure learning under approximate differential\nprivacy maintains the non-private logarithmic dependence on the dimensionality\nof the data, while a change in either the learning goal or the privacy notion\nwould necessitate a polynomial dependence. As a result, we show that the\nprivacy constraint imposes a strong separation between these two learning\nproblems in the high-dimensional data regime.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 14:24:58 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhang", "Huanyu", ""], ["Kamath", "Gautam", ""], ["Kulkarni", "Janardhan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.09464", "submitter": "Vikrant Singhal", "authors": "Gautam Kamath, Vikrant Singhal, Jonathan Ullman", "title": "Private Mean Estimation of Heavy-Tailed Distributions", "comments": "Appeared in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new upper and lower bounds on the minimax sample complexity of\ndifferentially private mean estimation of distributions with bounded $k$-th\nmoments. Roughly speaking, in the univariate case, we show that $n =\n\\Theta\\left(\\frac{1}{\\alpha^2} +\n\\frac{1}{\\alpha^{\\frac{k}{k-1}}\\varepsilon}\\right)$ samples are necessary and\nsufficient to estimate the mean to $\\alpha$-accuracy under\n$\\varepsilon$-differential privacy, or any of its common relaxations. This\nresult demonstrates a qualitatively different behavior compared to estimation\nabsent privacy constraints, for which the sample complexity is identical for\nall $k \\geq 2$. We also give algorithms for the multivariate setting whose\nsample complexity is a factor of $O(d)$ larger than the univariate case.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 22:24:31 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:06:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kamath", "Gautam", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2002.09465", "submitter": "Gautam Kamath", "authors": "Sivakanth Gopi, Gautam Kamath, Janardhan Kulkarni, Aleksandar Nikolov,\n  Zhiwei Steven Wu, Huanyu Zhang", "title": "Locally Private Hypothesis Selection", "comments": "To appear in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of hypothesis selection under local differential\nprivacy. Given samples from an unknown probability distribution $p$ and a set\nof $k$ probability distributions $\\mathcal{Q}$, we aim to output, under the\nconstraints of $\\varepsilon$-local differential privacy, a distribution from\n$\\mathcal{Q}$ whose total variation distance to $p$ is comparable to the best\nsuch distribution. This is a generalization of the classic problem of $k$-wise\nsimple hypothesis testing, which corresponds to when $p \\in \\mathcal{Q}$, and\nwe wish to identify $p$. Absent privacy constraints, this problem requires\n$O(\\log k)$ samples from $p$, and it was recently shown that the same\ncomplexity is achievable under (central) differential privacy. However, the\nnaive approach to this problem under local differential privacy would require\n$\\tilde O(k^2)$ samples.\n  We first show that the constraint of local differential privacy incurs an\nexponential increase in cost: any algorithm for this problem requires at least\n$\\Omega(k)$ samples. Second, for the special case of $k$-wise simple hypothesis\ntesting, we provide a non-interactive algorithm which nearly matches this\nbound, requiring $\\tilde O(k)$ samples. Finally, we provide sequentially\ninteractive algorithms for the general case, requiring $\\tilde O(k)$ samples\nand only $O(\\log \\log k)$ rounds of interactivity. Our algorithms are achieved\nthrough a reduction to maximum selection with adversarial comparators, a\nproblem of independent interest for which we initiate study in the parallel\nsetting. For this problem, we provide a family of algorithms for each number of\nallowed rounds of interaction $t$, as well as lower bounds showing that they\nare near-optimal for every $t$. Notably, our algorithms result in exponential\nimprovements on the round complexity of previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 02:58:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Kamath", "Gautam", ""], ["Kulkarni", "Janardhan", ""], ["Nikolov", "Aleksandar", ""], ["Wu", "Zhiwei Steven", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2002.09469", "submitter": "Joao Monteiro", "authors": "Joao Monteiro, Isabela Albuquerque, Jahangir Alam, R Devon Hjelm,\n  Tiago Falk", "title": "An end-to-end approach for the verification problem: learning the right\n  distance", "comments": "ICML 2020 final camera ready. Code is available at:\n  https://github.com/joaomonteirof/e2e_verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we augment the metric learning setting by introducing a\nparametric pseudo-distance, trained jointly with the encoder. Several\ninterpretations are thus drawn for the learned distance-like model's output. We\nfirst show it approximates a likelihood ratio which can be used for hypothesis\ntests, and that it further induces a large divergence across the joint\ndistributions of pairs of examples from the same and from different classes.\nEvaluation is performed under the verification setting consisting of\ndetermining whether sets of examples belong to the same class, even if such\nclasses are novel and were never presented to the model during training.\nEmpirical evaluation shows such method defines an end-to-end approach for the\nverification problem, able to attain better performance than simple scorers\nsuch as those based on cosine similarity and further outperforming widely used\ndownstream classifiers. We further observe training is much simplified under\nthe proposed approach compared to metric learning with actual distances,\nrequiring no complex scheme to harvest pairs of examples.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:46:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 00:09:11 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 21:46:22 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:20:28 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Monteiro", "Joao", ""], ["Albuquerque", "Isabela", ""], ["Alam", "Jahangir", ""], ["Hjelm", "R Devon", ""], ["Falk", "Tiago", ""]]}, {"id": "2002.09471", "submitter": "Yue Zhang", "authors": "Yue Zhang, Arti Ramesh", "title": "Learning Fairness-aware Relational Structures", "comments": "Accepted for publication in ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of fair machine learning models that effectively avert bias\nand discrimination is an important problem that has garnered attention in\nrecent years. The necessity of encoding complex relational dependencies among\nthe features and variables for competent predictions require the development of\nfair, yet expressive relational models. In this work, we introduce Fair-A3SL, a\nfairness-aware structure learning algorithm for learning relational structures,\nwhich incorporates fairness measures while learning relational graphical model\nstructures. Our approach is versatile in being able to encode a wide range of\nfairness metrics such as statistical parity difference, overestimation,\nequalized odds, and equal opportunity, including recently proposed relational\nfairness measures. While existing approaches employ the fairness measures on\npre-determined model structures post prediction, Fair-A3SL directly learns the\nstructure while optimizing for the fairness measures and hence is able to\nremove any structural bias in the model. We demonstrate the effectiveness of\nour learned model structures when compared with the state-of-the-art fairness\nmodels quantitatively and qualitatively on datasets representing three\ndifferent modeling scenarios: i) a relational dataset, ii) a recidivism\nprediction dataset widely used in studying discrimination, and iii) a\nrecommender systems dataset. Our results show that Fair-A3SL can learn fair,\nyet interpretable and expressive structures capable of making accurate\npredictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:53:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Yue", ""], ["Ramesh", "Arti", ""]]}, {"id": "2002.09473", "submitter": "Hegler Tissot", "authors": "Jianyu Liu and Hegler Tissot", "title": "Clustering as an Evaluation Protocol for Knowledge Embedding\n  Representation of Categorised Multi-relational Data in the Clinical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge representation is an increasingly important technology\napplicable in many domain-specific machine learning problems. We discuss the\neffectiveness of traditional Link Prediction or Knowledge Graph Completion\nevaluation protocol when embedding knowledge representation for categorised\nmulti-relational data in the clinical domain. Link prediction uses to split the\ndata into training and evaluation subsets, leading to loss of information along\ntraining and harming the knowledge representation model accuracy. We propose a\nClustering Evaluation Protocol as a replacement alternative to the\ntraditionally used evaluation tasks. We used embedding models trained by a\nknowledge embedding approach which has been evaluated with clinical datasets.\nExperimental results with Pearson and Spearman correlations show strong\nevidence that the novel proposed evaluation protocol is pottentially able to\nreplace link prediction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 16:04:22 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Liu", "Jianyu", ""], ["Tissot", "Hegler", ""]]}, {"id": "2002.09478", "submitter": "Ran Wang", "authors": "Ran Wang, Karthikeya S. Parunandi, Aayushman Sharma, Raman Goyal,\n  Suman Chakravorty", "title": "On the Search for Feedback in Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.08361", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Reinforcement Learning (RL) in an unknown nonlinear dynamical\nsystem is equivalent to the search for an optimal feedback law utilizing the\nsimulations/ rollouts of the unknown dynamical system. Most RL techniques\nsearch over a complex global nonlinear feedback parametrization making them\nsuffer from high training times as well as variance. Instead, we advocate\nsearching over a local feedback representation consisting of an open-loop\nsequence, and an associated optimal linear feedback law completely determined\nby the open-loop. We show that this alternate approach results in highly\nefficient training, the answers obtained are repeatable and hence reliable, and\nthe resulting closed performance is superior to global state-of-the-art RL\ntechniques. Finally, if we replan, whenever required, which is feasible due to\nthe fast and reliable local solution, allows us to recover global optimality of\nthe resulting feedback law.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:44:56 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:01:49 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 17:15:23 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 03:33:41 GMT"}, {"version": "v5", "created": "Fri, 16 Jul 2021 22:48:19 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Ran", ""], ["Parunandi", "Karthikeya S.", ""], ["Sharma", "Aayushman", ""], ["Goyal", "Raman", ""], ["Chakravorty", "Suman", ""]]}, {"id": "2002.09505", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Himanshu Sahni, Rosanne Liu, Jane Hung, Ankit Jain,\n  Rui Wang, Adrien Ecoffet, Thomas Miconi, Charles Isbell, Jason Yosinski", "title": "Estimating Q(s,s') with Deep Deterministic Dynamics Gradients", "comments": "Accepted into ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel form of value function, $Q(s, s')$, that\nexpresses the utility of transitioning from a state $s$ to a neighboring state\n$s'$ and then acting optimally thereafter. In order to derive an optimal\npolicy, we develop a forward dynamics model that learns to make next-state\npredictions that maximize this value. This formulation decouples actions from\nvalues while still learning off-policy. We highlight the benefits of this\napproach in terms of value function transfer, learning within redundant action\nspaces, and learning off-policy from state observations generated by\nsub-optimal or completely random policies. Code and videos are available at\nhttp://sites.google.com/view/qss-paper.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:05:24 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 18:13:00 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Sahni", "Himanshu", ""], ["Liu", "Rosanne", ""], ["Hung", "Jane", ""], ["Jain", "Ankit", ""], ["Wang", "Rui", ""], ["Ecoffet", "Adrien", ""], ["Miconi", "Thomas", ""], ["Isbell", "Charles", ""], ["Yosinski", "Jason", ""]]}, {"id": "2002.09516", "submitter": "Yaqi Duan", "authors": "Yaqi Duan, Mengdi Wang", "title": "Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the statistical theory of batch data reinforcement\nlearning with function approximation. Consider the off-policy evaluation\nproblem, which is to estimate the cumulative value of a new target policy from\nlogged history generated by unknown behavioral policies. We study a\nregression-based fitted Q iteration method, and show that it is equivalent to a\nmodel-based method that estimates a conditional mean embedding of the\ntransition operator. We prove that this method is information-theoretically\noptimal and has nearly minimal estimation error. In particular, by leveraging\ncontraction property of Markov processes and martingale concentration, we\nestablish a finite-sample instance-dependent error upper bound and a\nnearly-matching minimax lower bound. The policy evaluation error depends\nsharply on a restricted $\\chi^2$-divergence over the function class between the\nlong-term distribution of the target policy and the distribution of past data.\nThis restricted $\\chi^2$-divergence is both instance-dependent and\nfunction-class-dependent. It characterizes the statistical limit of off-policy\nevaluation. Further, we provide an easily computable confidence bound for the\npolicy evaluator, which may be useful for optimistic planning and safe policy\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:20:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Duan", "Yaqi", ""], ["Wang", "Mengdi", ""]]}, {"id": "2002.09518", "submitter": "Kaveh Hassani", "authors": "Amir Hosein Khasahmadi, Kaveh Hassani, Parsa Moradi, Leo Lee, Quaid\n  Morris", "title": "Memory-Based Graph Networks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a class of deep models that operate on data\nwith arbitrary topology represented as graphs. We introduce an efficient memory\nlayer for GNNs that can jointly learn node representations and coarsen the\ngraph. We also introduce two new networks based on this layer: memory-based GNN\n(MemGNN) and graph memory network (GMN) that can learn hierarchical graph\nrepresentations. The experimental results shows that the proposed models\nachieve state-of-the-art results in eight out of nine graph classification and\nregression benchmarks. We also show that the learned representations could\ncorrespond to chemical features in the molecule data. Code and reference\nimplementations are released at: https://github.com/amirkhas/GraphMemoryNet\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:26:31 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 04:50:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Khasahmadi", "Amir Hosein", ""], ["Hassani", "Kaveh", ""], ["Moradi", "Parsa", ""], ["Lee", "Leo", ""], ["Morris", "Quaid", ""]]}, {"id": "2002.09523", "submitter": "Yue Zhang", "authors": "Yue Zhang, Arti Ramesh", "title": "Struct-MMSB: Mixed Membership Stochastic Blockmodels with Interpretable\n  Structured Priors", "comments": "ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixed membership stochastic blockmodel (MMSB) is a popular framework for\ncommunity detection and network generation. It learns a low-rank mixed\nmembership representation for each node across communities by exploiting the\nunderlying graph structure. MMSB assumes that the membership distributions of\nthe nodes are independently drawn from a Dirichlet distribution, which limits\nits capability to model highly correlated graph structures that exist in\nreal-world networks. In this paper, we present a flexible richly structured\nMMSB model, \\textit{Struct-MMSB}, that uses a recently developed statistical\nrelational learning model, hinge-loss Markov random fields (HL-MRFs), as a\nstructured prior to model complex dependencies among node attributes,\nmulti-relational links, and their relationship with mixed-membership\ndistributions. Our model is specified using a probabilistic programming\ntemplating language that uses weighted first-order logic rules, which enhances\nthe model's interpretability. Further, our model is capable of learning latent\ncharacteristics in real-world networks via meaningful latent variables encoded\nas a complex combination of observed features and membership distributions. We\npresent an expectation-maximization based inference algorithm that learns\nlatent variables and parameters iteratively, a scalable stochastic variation of\nthe inference algorithm, and a method to learn the weights of HL-MRF structured\npriors. We evaluate our model on six datasets across three different types of\nnetworks and corresponding modeling scenarios and demonstrate that our models\nare able to achieve an improvement of 15\\% on average in test log-likelihood\nand faster convergence when compared to state-of-the-art network models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:32:32 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Yue", ""], ["Ramesh", "Arti", ""]]}, {"id": "2002.09535", "submitter": "Qingsong Wen", "authors": "Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, Huan Xu", "title": "RobustPeriod: Time-Frequency Mining for Robust Multiple Periodicity\n  Detection", "comments": "Accepted by SIGMOD 2021; 10 pages, 6 figures, 8 tables, and 70\n  referred papers", "journal-ref": null, "doi": "10.1145/3448016.3452779", "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Periodicity detection is a crucial step in time series tasks, including\nmonitoring and forecasting of metrics in many areas, such as IoT applications\nand self-driving database management system. In many of these applications,\nmultiple periodic components exist and are often interlaced with each other.\nSuch dynamic and complicated periodic patterns make the accurate periodicity\ndetection difficult. In addition, other components in the time series, such as\ntrend, outliers and noises, also pose additional challenges for accurate\nperiodicity detection. In this paper, we propose a robust and general framework\nfor multiple periodicity detection. Our algorithm applies maximal overlap\ndiscrete wavelet transform to transform the time series into multiple\ntemporal-frequency scales such that different periodic components can be\nisolated. We rank them by wavelet variance, and then at each scale detect\nsingle periodicity by our proposed Huber-periodogram and Huber-ACF robustly. We\nrigorously prove the theoretical properties of Huber-periodogram and justify\nthe use of Fisher's test on Huber-periodogram for periodicity detection. To\nfurther refine the detected periods, we compute unbiased autocorrelation\nfunction based on Wiener-Khinchin theorem from Huber-periodogram for improved\nrobustness and efficiency. Experiments on synthetic and real-world datasets\nshow that our algorithm outperforms other popular ones for both single and\nmultiple periodicity detection.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:10:36 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 00:59:11 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wen", "Qingsong", ""], ["He", "Kai", ""], ["Sun", "Liang", ""], ["Zhang", "Yingying", ""], ["Ke", "Min", ""], ["Xu", "Huan", ""]]}, {"id": "2002.09538", "submitter": "Nathaniel Garton", "authors": "Nathaniel Garton, Jarad Niemi, Alicia Carriquiry", "title": "Knot Selection in Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knot-based, sparse Gaussian processes have enjoyed considerable success as\nscalable approximations to full Gaussian processes. Problems can occur,\nhowever, when knot selection is done by optimizing the marginal likelihood. For\nexample, the marginal likelihood surface is highly multimodal, which can cause\nsuboptimal knot placement where some knots serve practically no function. This\nis especially a problem when many more knots are used than are necessary,\nresulting in extra computational cost for little to no gains in accuracy.\n  We propose a one-at-a-time knot selection algorithm to select both the number\nand placement of knots. Our algorithm uses Bayesian optimization to efficiently\npropose knots that are likely to be good and largely avoids the pathologies\nencountered when using the marginal likelihood as the objective function. We\nprovide empirical results showing improved accuracy and speed over the current\nstandard approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:32:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Garton", "Nathaniel", ""], ["Niemi", "Jarad", ""], ["Carriquiry", "Alicia", ""]]}, {"id": "2002.09539", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Hao Liang, Gauri Joshi", "title": "Overlap Local-SGD: An Algorithmic Approach to Hide Communication Delays\n  in Distributed SGD", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stochastic gradient descent (SGD) is essential for scaling the\nmachine learning algorithms to a large number of computing nodes. However, the\ninfrastructures variability such as high communication delay or random node\nslowdown greatly impedes the performance of distributed SGD algorithm,\nespecially in a wireless system or sensor networks. In this paper, we propose\nan algorithmic approach named Overlap-Local-SGD (and its momentum variant) to\noverlap the communication and computation so as to speedup the distributed\ntraining procedure. The approach can help to mitigate the straggler effects as\nwell. We achieve this by adding an anchor model on each node. After multiple\nlocal updates, locally trained models will be pulled back towards the\nsynchronized anchor model rather than communicating with others. Experimental\nresults of training a deep neural network on CIFAR-10 dataset demonstrate the\neffectiveness of Overlap-Local-SGD. We also provide a convergence guarantee for\nthe proposed algorithm under non-convex objective functions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:33:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Jianyu", ""], ["Liang", "Hao", ""], ["Joshi", "Gauri", ""]]}, {"id": "2002.09545", "submitter": "Qingsong Wen", "authors": "Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, Huan\n  Xu", "title": "RobustTAD: Robust Time Series Anomaly Detection via Decomposition and\n  Convolutional Neural Networks", "comments": "9 pages, 5 figures, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monitoring and management of numerous and diverse time series data at\nAlibaba Group calls for an effective and scalable time series anomaly detection\nservice. In this paper, we propose RobustTAD, a Robust Time series Anomaly\nDetection framework by integrating robust seasonal-trend decomposition and\nconvolutional neural network for time series data. The seasonal-trend\ndecomposition can effectively handle complicated patterns in time series, and\nmeanwhile significantly simplifies the architecture of the neural network,\nwhich is an encoder-decoder architecture with skip connections. This\narchitecture can effectively capture the multi-scale information from time\nseries, which is very useful in anomaly detection. Due to the limited labeled\ndata in time series anomaly detection, we systematically investigate data\naugmentation methods in both time and frequency domains. We also introduce\nlabel-based weight and value-based weight in the loss function by utilizing the\nunbalanced nature of the time series anomaly detection problem. Compared with\nthe widely used forecasting-based anomaly detection algorithms,\ndecomposition-based algorithms, traditional statistical algorithms, as well as\nrecent neural network based algorithms, RobustTAD performs significantly better\non public benchmark datasets. It is deployed as a public online service and\nwidely adopted in different business scenarios at Alibaba Group.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:43:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gao", "Jingkun", ""], ["Song", "Xiaomin", ""], ["Wen", "Qingsong", ""], ["Wang", "Pichao", ""], ["Sun", "Liang", ""], ["Xu", "Huan", ""]]}, {"id": "2002.09547", "submitter": "Liam Hodgkinson", "authors": "Liam Hodgkinson, Chris van der Heide, Fred Roosta, Michael W. Mahoney", "title": "Stochastic Normalizing Flows", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce stochastic normalizing flows, an extension of continuous\nnormalizing flows for maximum likelihood estimation and variational inference\n(VI) using stochastic differential equations (SDEs). Using the theory of rough\npaths, the underlying Brownian motion is treated as a latent variable and\napproximated, enabling efficient training of neural SDEs as random neural\nordinary differential equations. These SDEs can be used for constructing\nefficient Markov chains to sample from the underlying distribution of a given\ndataset. Furthermore, by considering families of targeted SDEs with prescribed\nstationary distribution, we can apply VI to the optimization of hyperparameters\nin stochastic MCMC.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:47:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:17:18 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Hodgkinson", "Liam", ""], ["van der Heide", "Chris", ""], ["Roosta", "Fred", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.09558", "submitter": "Jonathan Ventura", "authors": "Wesley Khademi, Sonia Rao, Clare Minnerath, Guy Hagen, and Jonathan\n  Ventura", "title": "Self-Supervised Poisson-Gaussian Denoising", "comments": "to appear in IEEE WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the blindspot model for self-supervised denoising to handle\nPoisson-Gaussian noise and introduce an improved training scheme that avoids\nhyperparameters and adapts the denoiser to the test data. Self-supervised\nmodels for denoising learn to denoise from only noisy data and do not require\ncorresponding clean images, which are difficult or impossible to acquire in\nsome application areas of interest such as low-light microscopy. We introduce a\nnew training strategy to handle Poisson-Gaussian noise which is the standard\nnoise model for microscope images. Our new strategy eliminates hyperparameters\nfrom the loss function, which is important in a self-supervised regime where no\nground truth data is available to guide hyperparameter tuning. We show how our\ndenoiser can be adapted to the test data to improve performance. Our\nevaluations on microscope image denoising benchmarks validate our approach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 21:34:33 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 01:13:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Khademi", "Wesley", ""], ["Rao", "Sonia", ""], ["Minnerath", "Clare", ""], ["Hagen", "Guy", ""], ["Ventura", "Jonathan", ""]]}, {"id": "2002.09564", "submitter": "Shadab Khan", "authors": "Prateek Munjal, Nasir Hayat, Munawar Hayat, Jamshid Sourati, Shadab\n  Khan", "title": "Towards Robust and Reproducible Active Learning Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) is a promising ML paradigm that has the potential to\nparse through large unlabeled data and help reduce annotation cost in domains\nwhere labeling entire data can be prohibitive. Recently proposed neural network\nbased AL methods use different heuristics to accomplish this goal. In this\nstudy, we show that recent AL methods offer a gain over random baseline under a\nbrittle combination of experimental conditions. We demonstrate that such\nmarginal gains vanish when experimental factors are changed, leading to\nreproducibility issues and suggesting that AL methods lack robustness. We also\nobserve that with a properly tuned model, which employs recently proposed\nregularization techniques, the performance significantly improves for all AL\nmethods including the random sampling baseline, and performance differences\namong the AL methods become negligible. Based on these observations, we suggest\na set of experiments that are critical to assess the true effectiveness of an\nAL method. To facilitate these experiments we also present an open source\ntoolkit. We believe our findings and recommendations will help advance\nreproducible research in robust AL using neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:01:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Munjal", "Prateek", ""], ["Hayat", "Nasir", ""], ["Hayat", "Munawar", ""], ["Sourati", "Jamshid", ""], ["Khan", "Shadab", ""]]}, {"id": "2002.09571", "submitter": "Nicholas Cheney", "authors": "Shawn Beaulieu, Lapo Frati, Thomas Miconi, Joel Lehman, Kenneth O.\n  Stanley, Jeff Clune, Nick Cheney", "title": "Learning to Continually Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual lifelong learning requires an agent or model to learn many\nsequentially ordered tasks, building on previous knowledge without\ncatastrophically forgetting it. Much work has gone towards preventing the\ndefault tendency of machine learning models to catastrophically forget, yet\nvirtually all such work involves manually-designed solutions to the problem. We\ninstead advocate meta-learning a solution to catastrophic forgetting, allowing\nAI to learn to continually learn. Inspired by neuromodulatory processes in the\nbrain, we propose A Neuromodulated Meta-Learning Algorithm (ANML). It\ndifferentiates through a sequential learning process to meta-learn an\nactivation-gating function that enables context-dependent selective activation\nwithin a deep neural network. Specifically, a neuromodulatory (NM) neural\nnetwork gates the forward pass of another (otherwise normal) neural network\ncalled the prediction learning network (PLN). The NM network also thus\nindirectly controls selective plasticity (i.e. the backward pass of) the PLN.\nANML enables continual learning without catastrophic forgetting at scale: it\nproduces state-of-the-art continual learning performance, sequentially learning\nas many as 600 classes (over 9,000 SGD updates).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:52:00 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:22:48 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Beaulieu", "Shawn", ""], ["Frati", "Lapo", ""], ["Miconi", "Thomas", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""], ["Cheney", "Nick", ""]]}, {"id": "2002.09572", "submitter": "Stanis{\\l}aw Jastrz\\k{e}bski", "authors": "Stanislaw Jastrzebski, Maciej Szymczak, Stanislav Fort, Devansh Arpit,\n  Jacek Tabor, Kyunghyun Cho, Krzysztof Geras", "title": "The Break-Even Point on Optimization Trajectories of Deep Neural\n  Networks", "comments": "Accepted as a spotlight at ICLR 2020. The last two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early phase of training of deep neural networks is critical for their\nfinal performance. In this work, we study how the hyperparameters of stochastic\ngradient descent (SGD) used in the early phase of training affect the rest of\nthe optimization trajectory. We argue for the existence of the \"break-even\"\npoint on this trajectory, beyond which the curvature of the loss surface and\nnoise in the gradient are implicitly regularized by SGD. In particular, we\ndemonstrate on multiple classification tasks that using a large learning rate\nin the initial phase of training reduces the variance of the gradient, and\nimproves the conditioning of the covariance of gradients. These effects are\nbeneficial from the optimization perspective and become visible after the\nbreak-even point. Complementing prior work, we also show that using a low\nlearning rate results in bad conditioning of the loss surface even for a neural\nnetwork with batch normalization layers. In short, our work shows that key\nproperties of the loss surface are strongly influenced by SGD in the early\nphase of training. We argue that studying the impact of the identified effects\non generalization is a promising future direction.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:55:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jastrzebski", "Stanislaw", ""], ["Szymczak", "Maciej", ""], ["Fort", "Stanislav", ""], ["Arpit", "Devansh", ""], ["Tabor", "Jacek", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof", ""]]}, {"id": "2002.09573", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Martin E Jakobsen, Phillip B Mogensen, Lasse\n  Petersen, Nikolaj Thams, Gherardo Varando", "title": "Causal structure learning from time series: Large regression\n  coefficients may predict causal links better in practice than small p-values", "comments": null, "journal-ref": "Proceedings of the NeurIPS 2019 Competition and Demonstration\n  Track, Proceedings of Machine Learning Research, 123:27-36, 2020 (\n  http://proceedings.mlr.press/v123/weichwald20a.html )", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe the algorithms for causal structure learning\nfrom time series data that won the Causality 4 Climate competition at the\nConference on Neural Information Processing Systems 2019 (NeurIPS). We examine\nhow our combination of established ideas achieves competitive performance on\nsemi-realistic and realistic time series data exhibiting common challenges in\nreal-world Earth sciences data. In particular, we discuss a) a rationale for\nleveraging linear methods to identify causal links in non-linear systems, b) a\nsimulation-backed explanation as to why large regression coefficients may\npredict causal links better in practice than small p-values and thus why\nnormalising the data may sometimes hinder causal structure learning.\n  For benchmark usage, we detail the algorithms here and provide\nimplementations at https://github.com/sweichwald/tidybench . We propose the\npresented competition-proven methods for baseline benchmark comparisons to\nguide the development of novel algorithms for structure learning from time\nseries.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:02:00 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 09:24:53 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Jakobsen", "Martin E", ""], ["Mogensen", "Phillip B", ""], ["Petersen", "Lasse", ""], ["Thams", "Nikolaj", ""], ["Varando", "Gherardo", ""]]}, {"id": "2002.09574", "submitter": "Saurav Prakash", "authors": "Sagar Dhakal, Saurav Prakash, Yair Yona, Shilpa Talwar, Nageen Himayat", "title": "Coded Federated Learning", "comments": "Presented at the Wireless Edge Intelligence Workshop, IEEE GLOBECOM\n  2019", "journal-ref": null, "doi": "10.1109/GCWkshps45667.2019.9024521", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a method of training a global model from decentralized\ndata distributed across client devices. Here, model parameters are computed\nlocally by each client device and exchanged with a central server, which\naggregates the local models for a global view, without requiring sharing of\ntraining data. The convergence performance of federated learning is severely\nimpacted in heterogeneous computing platforms such as those at the wireless\nedge, where straggling computations and communication links can significantly\nlimit timely model parameter updates. This paper develops a novel coded\ncomputing technique for federated learning to mitigate the impact of\nstragglers. In the proposed Coded Federated Learning (CFL) scheme, each client\ndevice privately generates parity training data and shares it with the central\nserver only once at the start of the training phase. The central server can\nthen preemptively perform redundant gradient computations on the composite\nparity data to compensate for the erased or delayed parameter updates. Our\nresults show that CFL allows the global model to converge nearly four times\nfaster when compared to an uncoded approach\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:06:20 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:24:43 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Dhakal", "Sagar", ""], ["Prakash", "Saurav", ""], ["Yona", "Yair", ""], ["Talwar", "Shilpa", ""], ["Himayat", "Nageen", ""]]}, {"id": "2002.09575", "submitter": "Tian Gao", "authors": "Tian Gao, Dharmashankar Subramanian, Karthikeyan Shanmugam, Debarun\n  Bhattacharjya, Nicholas Mattei", "title": "A Multi-Channel Neural Graphical Event Model with Negative Evidence", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Event datasets are sequences of events of various types occurring irregularly\nover the time-line, and they are increasingly prevalent in numerous domains.\nExisting work for modeling events using conditional intensities rely on either\nusing some underlying parametric form to capture historical dependencies, or on\nnon-parametric models that focus primarily on tasks such as prediction. We\npropose a non-parametric deep neural network approach in order to estimate the\nunderlying intensity functions. We use a novel multi-channel RNN that optimally\nreinforces the negative evidence of no observable events with the introduction\nof fake event epochs within each consecutive inter-event interval. We evaluate\nour method against state-of-the-art baselines on model fitting tasks as gauged\nby log-likelihood. Through experiments on both synthetic and real-world\ndatasets, we find that our proposed approach outperforms existing baselines on\nmost of the datasets studied.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:10:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gao", "Tian", ""], ["Subramanian", "Dharmashankar", ""], ["Shanmugam", "Karthikeyan", ""], ["Bhattacharjya", "Debarun", ""], ["Mattei", "Nicholas", ""]]}, {"id": "2002.09579", "submitter": "Yuhao Zhang", "authors": "Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni", "title": "Robustness to Programmable String Transformations via Augmented Abstract\n  Training", "comments": "12 pages, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks for natural language processing tasks are vulnerable to\nadversarial input perturbations. In this paper, we present a versatile language\nfor programmatically specifying string transformations -- e.g., insertions,\ndeletions, substitutions, swaps, etc. -- that are relevant to the task at hand.\nWe then present an approach to adversarially training models that are robust to\nsuch user-defined string transformations. Our approach combines the advantages\nof search-based techniques for adversarial training with abstraction-based\ntechniques. Specifically, we show how to decompose a set of user-defined string\ntransformations into two component specifications, one that benefits from\nsearch and another from abstraction. We use our technique to train models on\nthe AG and SST2 datasets and show that the resulting models are robust to\ncombinations of user-defined transformations mimicking spelling mistakes and\nother meaning-preserving transformations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:06:09 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:53:49 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 23:03:53 GMT"}, {"version": "v4", "created": "Wed, 2 Sep 2020 14:41:25 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Zhang", "Yuhao", ""], ["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""]]}, {"id": "2002.09580", "submitter": "Can Bakiskan", "authors": "Can Bakiskan, Soorya Gopalakrishnan, Metehan Cekic, Upamanyu Madhow,\n  Ramtin Pedarsani", "title": "Polarizing Front Ends for Robust CNNs", "comments": "Published in 45th International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks to small, adversarially designed\nperturbations can be attributed to their \"excessive linearity.\" In this paper,\nwe propose a bottom-up strategy for attenuating adversarial perturbations using\na nonlinear front end which polarizes and quantizes the data. We observe that\nideal polarization can be utilized to completely eliminate perturbations,\ndevelop algorithms to learn approximately polarizing bases for data, and\ninvestigate the effectiveness of the proposed strategy on the MNIST and Fashion\nMNIST datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:28:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Bakiskan", "Can", ""], ["Gopalakrishnan", "Soorya", ""], ["Cekic", "Metehan", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2002.09587", "submitter": "Zhanyu Wang", "authors": "Zhanyu Wang and Jean Honorio", "title": "The Sample Complexity of Meta Sparse Regression", "comments": null, "journal-ref": "Artificial Intelligence and Statistics (AISTATS), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the meta-learning problem in sparse linear regression\nwith infinite tasks. We assume that the learner can access several similar\ntasks. The goal of the learner is to transfer knowledge from the prior tasks to\na similar but novel task. For p parameters, size of the support set k , and l\nsamples per task, we show that T \\in O (( k log(p) ) /l ) tasks are sufficient\nin order to recover the common support of all tasks. With the recovered\nsupport, we can greatly reduce the sample complexity for estimating the\nparameter of the novel task, i.e., l \\in O (1) with respect to T and p . We\nalso prove that our rates are minimax optimal. A key difference between\nmeta-learning and the classical multi-task learning, is that meta-learning\nfocuses only on the recovery of the parameters of the novel task, while\nmulti-task learning estimates the parameter of all tasks, which requires l to\ngrow with T . Instead, our efficient meta-learning estimator allows for l to be\nconstant with respect to T (i.e., few-shot learning).\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:59:53 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 18:35:21 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Wang", "Zhanyu", ""], ["Honorio", "Jean", ""]]}, {"id": "2002.09589", "submitter": "Vaishakh Ravindrakumar", "authors": "Yi Hao, Ayush Jain, Alon Orlitsky, Vaishakh Ravindrakumar", "title": "SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm", "comments": "27 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample- and computationally-efficient distribution estimation is a\nfundamental tenet in statistics and machine learning. We present SURF, an\nalgorithm for approximating distributions by piecewise polynomials. SURF is:\nsimple, replacing prior complex optimization techniques by straight-forward\n{empirical probability} approximation of each potential polynomial piece\n{through simple empirical-probability interpolation}, and using plain\ndivide-and-conquer to merge the pieces; universal, as well-known\npolynomial-approximation results imply that it accurately approximates a large\nclass of common distributions; robust to distribution mis-specification as for\nany degree $d \\le 8$, it estimates any distribution to an $\\ell_1$ distance $<\n3$ times that of the nearest degree-$d$ piecewise polynomial, improving known\nfactor upper bounds of 3 for single polynomials and 15 for polynomials with\narbitrarily many pieces; fast, using optimal sample complexity, running in near\nsample-linear time, and if given sorted samples it may be parallelized to run\nin sub-linear time. In experiments, SURF outperforms state-of-the art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:03:33 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 19:10:43 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hao", "Yi", ""], ["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""], ["Ravindrakumar", "Vaishakh", ""]]}, {"id": "2002.09594", "submitter": "Xuhong Wang", "authors": "Xuhong Wang, Baihong Jin, Ying Du, Ping Cui and Yupu Yang", "title": "One-Class Graph Neural Networks for Anomaly Detection in Attributed\n  Networks", "comments": "16 pages, 4 figures. Neural Comput & Applic (2021)", "journal-ref": null, "doi": "10.1007/s00521-021-05924-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, graph-structured data are increasingly used to model complex\nsystems. Meanwhile, detecting anomalies from graph has become a vital research\nproblem of pressing societal concerns. Anomaly detection is an unsupervised\nlearning task of identifying rare data that differ from the majority. As one of\nthe dominant anomaly detection algorithms, One Class Support Vector Machine has\nbeen widely used to detect outliers. However, those traditional anomaly\ndetection methods lost their effectiveness in graph data. Since traditional\nanomaly detection methods are stable, robust and easy to use, it is vitally\nimportant to generalize them to graph data. In this work, we propose One Class\nGraph Neural Network (OCGNN), a one-class classification framework for graph\nanomaly detection. OCGNN is designed to combine the powerful representation\nability of Graph Neural Networks along with the classical one-class objective.\nCompared with other baselines, OCGNN achieves significant improvements in\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:25:49 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 11:28:03 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wang", "Xuhong", ""], ["Jin", "Baihong", ""], ["Du", "Ying", ""], ["Cui", "Ping", ""], ["Yang", "Yupu", ""]]}, {"id": "2002.09609", "submitter": "Raman Arora", "authors": "Raman Arora, Teodor V. Marinov, Enayat Ullah", "title": "Private Stochastic Convex Optimization: Efficient Algorithms for\n  Non-smooth Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the problem of private stochastic convex\noptimization. We propose an algorithm based on noisy mirror descent, which\nachieves optimal rates both in terms of statistical complexity and number of\nqueries to a first-order stochastic oracle in the regime when the privacy\nparameter is inversely proportional to the number of samples.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 03:03:43 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 18:59:44 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 05:30:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Arora", "Raman", ""], ["Marinov", "Teodor V.", ""], ["Ullah", "Enayat", ""]]}, {"id": "2002.09615", "submitter": "Amanda Bower", "authors": "Amanda Bower and Laura Balzano", "title": "Preference Modeling with Context-Dependent Salient Features", "comments": "This is the ICML camera ready version. The main difference is that\n  the statements of the theorems now hold with arbitrary probability \\delta\n  instead of with probability 1-2/d", "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a ranking on a set of items from noisy\npairwise comparisons given item features. We address the fact that pairwise\ncomparison data often reflects irrational choice, e.g. intransitivity. Our key\nobservation is that two items compared in isolation from other items may be\ncompared based on only a salient subset of features. Formalizing this\nframework, we propose the salient feature preference model and prove a finite\nsample complexity result for learning the parameters of our model and the\nunderlying ranking with maximum likelihood estimation. We also provide\nempirical results that support our theoretical bounds and illustrate how our\nmodel explains systematic intransitivity. Finally we demonstrate strong\nperformance of maximum likelihood estimation of our model on both synthetic\ndata and two real data sets: the UT Zappos50K data set and comparison data\nabout the compactness of legislative districts in the US.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:05:16 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 01:45:10 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bower", "Amanda", ""], ["Balzano", "Laura", ""]]}, {"id": "2002.09621", "submitter": "Junchi Yang", "authors": "Junchi Yang, Negar Kiyavash, Niao He", "title": "Global Convergence and Variance-Reduced Optimization for a Class of\n  Nonconvex-Nonconcave Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex minimax problems appear frequently in emerging machine learning\napplications, such as generative adversarial networks and adversarial learning.\nSimple algorithms such as the gradient descent ascent (GDA) are the common\npractice for solving these nonconvex games and receive lots of empirical\nsuccess. Yet, it is known that these vanilla GDA algorithms with constant step\nsize can potentially diverge even in the convex setting. In this work, we show\nthat for a subclass of nonconvex-nonconcave objectives satisfying a so-called\ntwo-sided Polyak-{\\L}ojasiewicz inequality, the alternating gradient descent\nascent (AGDA) algorithm converges globally at a linear rate and the stochastic\nAGDA achieves a sublinear rate. We further develop a variance reduced algorithm\nthat attains a provably faster rate than AGDA when the problem has the\nfinite-sum structure.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:20:37 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yang", "Junchi", ""], ["Kiyavash", "Negar", ""], ["He", "Niao", ""]]}, {"id": "2002.09632", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "Using Single-Step Adversarial Training to Defend Iterative Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have become one of the largest challenges that machine\nlearning models, especially neural network classifiers, face. These adversarial\nexamples break the assumption of attack-free scenario and fool state-of-the-art\n(SOTA) classifiers with insignificant perturbations to human. So far,\nresearchers achieved great progress in utilizing adversarial training as a\ndefense. However, the overwhelming computational cost degrades its\napplicability and little has been done to overcome this issue. Single-Step\nadversarial training methods have been proposed as computationally viable\nsolutions, however they still fail to defend against iterative adversarial\nexamples. In this work, we first experimentally analyze several different SOTA\ndefense methods against adversarial examples. Then, based on observations from\nexperiments, we propose a novel single-step adversarial training method which\ncan defend against both single-step and iterative adversarial examples. Lastly,\nthrough extensive evaluations, we demonstrate that our proposed method\noutperforms the SOTA single-step and iterative adversarial training defense.\nCompared with ATDA (single-step method) on CIFAR10 dataset, our proposed method\nachieves 35.67% enhancement in test accuracy and 19.14% reduction in training\ntime. When compared with methods that use BIM or Madry examples (iterative\nmethods) on CIFAR10 dataset, it saves up to 76.03% in training time with less\nthan 3.78% degeneration in test accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:36:35 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 17:24:24 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "2002.09650", "submitter": "Xiaojing Ye", "authors": "Shaojun Ma, Haodong Sun, Xiaojing Ye, Hongyuan Zha, Haomin Zhou", "title": "Learning Cost Functions for Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse optimal transport (OT) refers to the problem of learning the cost\nfunction for OT from observed transport plan or its samples. In this paper, we\nderive an unconstrained convex optimization formulation of the inverse OT\nproblem, which can be further augmented by any customizable regularization. We\nprovide a comprehensive characterization of the properties of inverse OT,\nincluding uniqueness of solutions. We also develop two numerical algorithms,\none is a fast matrix scaling method based on the Sinkhorn-Knopp algorithm for\ndiscrete OT, and the other one is a learning based algorithm that parameterizes\nthe cost function as a deep neural network for continuous OT. The novel\nframework proposed in the work avoids repeatedly solving a forward OT in each\niteration which has been a thorny computational bottleneck for the bi-level\noptimization in existing inverse OT approaches. Numerical results demonstrate\npromising efficiency and accuracy advantages of the proposed algorithms over\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 07:27:17 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 15:36:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ma", "Shaojun", ""], ["Sun", "Haodong", ""], ["Ye", "Xiaojing", ""], ["Zha", "Hongyuan", ""], ["Zhou", "Haomin", ""]]}, {"id": "2002.09656", "submitter": "Yifan Yang", "authors": "Yang Yifan, Guo Ju'e, Sun Shaolong, and Li Yixin", "title": "A new hybrid approach for crude oil price forecasting: Evidence from\n  multi-scale data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faced with the growing research towards crude oil price fluctuations\ninfluential factors following the accelerated development of Internet\ntechnology, accessible data such as Google search volume index are increasingly\nquantified and incorporated into forecasting approaches. In this paper, we\napply multi-scale data that including both GSVI data and traditional economic\ndata related to crude oil price as independent variables and propose a new\nhybrid approach for monthly crude oil price forecasting. This hybrid approach,\nbased on divide and conquer strategy, consists of K-means method, kernel\nprincipal component analysis and kernel extreme learning machine , where\nK-means method is adopted to divide input data into certain clusters, KPCA is\napplied to reduce dimension, and KELM is employed for final crude oil price\nforecasting. The empirical result can be analyzed from data and method levels.\nAt the data level, GSVI data perform better than economic data in level\nforecasting accuracy but with opposite performance in directional forecasting\naccuracy because of Herd Behavior, while hybrid data combined their advantages\nand obtain best forecasting performance in both level and directional accuracy.\nAt the method level, the approaches with K-means perform better than those\nwithout K-means, which demonstrates that divide and conquer strategy can\neffectively improve the forecasting performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 07:56:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yifan", "Yang", ""], ["Ju'e", "Guo", ""], ["Shaolong", "Sun", ""], ["Yixin", "Li", ""]]}, {"id": "2002.09670", "submitter": "Kian Hsiang Low", "authors": "Dmitrii Kharkovskii, Chun Kai Ling, Kian Hsiang Low", "title": "Nonmyopic Gaussian Process Optimization with Macro-Actions", "comments": "23rd International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2020), Extended version with proofs, 32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-staged approach to nonmyopic adaptive Gaussian\nprocess optimization (GPO) for Bayesian optimization (BO) of unknown, highly\ncomplex objective functions that, in contrast to existing nonmyopic adaptive BO\nalgorithms, exploits the notion of macro-actions for scaling up to a further\nlookahead to match up to a larger available budget. To achieve this, we\ngeneralize GP upper confidence bound to a new acquisition function defined\nw.r.t. a nonmyopic adaptive macro-action policy, which is intractable to be\noptimized exactly due to an uncountable set of candidate outputs. The\ncontribution of our work here is thus to derive a nonmyopic adaptive\nepsilon-Bayes-optimal macro-action GPO (epsilon-Macro-GPO) policy. To perform\nnonmyopic adaptive BO in real time, we then propose an asymptotically optimal\nanytime variant of our epsilon-Macro-GPO policy with a performance guarantee.\nWe empirically evaluate the performance of our epsilon-Macro-GPO policy and its\nanytime variant in BO with synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 09:56:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kharkovskii", "Dmitrii", ""], ["Ling", "Chun Kai", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "2002.09671", "submitter": "Yan Lin", "authors": "Jun Li, Zhichao Xing, Weibin Zhang, Yan Lin, and Feng Shu", "title": "Vehicle Tracking in Wireless Sensor Networks via Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle tracking has become one of the key applications of wireless sensor\nnetworks (WSNs) in the fields of rescue, surveillance, traffic monitoring, etc.\nHowever, the increased tracking accuracy requires more energy consumption. In\nthis letter, a decentralized vehicle tracking strategy is conceived for\nimproving both tracking accuracy and energy saving, which is based on adjusting\nthe intersection area between the fixed sensing area and the dynamic activation\narea. Then, two deep reinforcement learning (DRL) aided solutions are proposed\nrelying on the dynamic selection of the activation area radius. Finally,\nsimulation results show the superiority of our DRL aided design.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:01:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Jun", ""], ["Xing", "Zhichao", ""], ["Zhang", "Weibin", ""], ["Lin", "Yan", ""], ["Shu", "Feng", ""]]}, {"id": "2002.09677", "submitter": "Ayoub Belhadji", "authors": "Ayoub Belhadji, R\\'emi Bardenet, Pierre Chainais", "title": "Kernel interpolation with continuous volume sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental task in kernel methods is to pick nodes and weights, so as to\napproximate a given function from an RKHS by the weighted sum of kernel\ntranslates located at the nodes. This is the crux of kernel density estimation,\nkernel quadrature, or interpolation from discrete samples. Furthermore, RKHSs\noffer a convenient mathematical and computational framework. We introduce and\nanalyse continuous volume sampling (VS), the continuous counterpart -- for\nchoosing node locations -- of a discrete distribution introduced in (Deshpande\n& Vempala, 2006). Our contribution is theoretical: we prove almost optimal\nbounds for interpolation and quadrature under VS. While similar bounds already\nexist for some specific RKHSs using ad-hoc node constructions, VS offers bounds\nthat apply to any Mercer kernel and depend on the spectrum of the associated\nintegration operator. We emphasize that, unlike previous randomized approaches\nthat rely on regularized leverage scores or determinantal point processes,\nevaluating the pdf of VS only requires pointwise evaluations of the kernel. VS\nis thus naturally amenable to MCMC samplers.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:34:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Belhadji", "Ayoub", ""], ["Bardenet", "R\u00e9mi", ""], ["Chainais", "Pierre", ""]]}, {"id": "2002.09692", "submitter": "Zhenheng Tang", "authors": "Zhenheng Tang, Shaohuai Shi, Xiaowen Chu", "title": "Communication-Efficient Decentralized Learning with Sparsification and\n  Adaptive Peer Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning techniques such as federated learning have enabled\nmultiple workers to train machine learning models together to reduce the\noverall training time. However, current distributed training algorithms\n(centralized or decentralized) suffer from the communication bottleneck on\nmultiple low-bandwidth workers (also on the server under the centralized\narchitecture). Although decentralized algorithms generally have lower\ncommunication complexity than the centralized counterpart, they still suffer\nfrom the communication bottleneck for workers with low network bandwidth. To\ndeal with the communication problem while being able to preserve the\nconvergence performance, we introduce a novel decentralized training algorithm\nwith the following key features: 1) It does not require a parameter server to\nmaintain the model during training, which avoids the communication pressure on\nany single peer. 2) Each worker only needs to communicate with a single peer at\neach communication round with a highly compressed model, which can\nsignificantly reduce the communication traffic on the worker. We theoretically\nprove that our sparsification algorithm still preserves convergence properties.\n3) Each worker dynamically selects its peer at different communication rounds\nto better utilize the bandwidth resources. We conduct experiments with\nconvolutional neural networks on 32 workers to verify the effectiveness of our\nproposed algorithm compared to seven existing methods. Experimental results\nshow that our algorithm significantly reduces the communication traffic and\ngenerally select relatively high bandwidth peers.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 12:31:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tang", "Zhenheng", ""], ["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2002.09695", "submitter": "Yifan Yang", "authors": "Guowei Zhang, Tao Ren, and Yifan Yang", "title": "A New Unified Deep Learning Approach with\n  Decomposition-Reconstruction-Ensemble Framework for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new variational mode decomposition (VMD) based deep learning approach is\nproposed in this paper for time series forecasting problem. Firstly, VMD is\nadopted to decompose the original time series into several sub-signals. Then, a\nconvolutional neural network (CNN) is applied to learn the reconstruction\npatterns on the decomposed sub-signals to obtain several reconstructed\nsub-signals. Finally, a long short term memory (LSTM) network is employed to\nforecast the time series with the decomposed sub-signals and the reconstructed\nsub-signals as inputs. The proposed VMD-CNN-LSTM approach is originated from\nthe decomposition-reconstruction-ensemble framework, and innovated by embedding\nthe reconstruction, single forecasting, and ensemble steps in a unified deep\nlearning approach. To verify the forecasting performance of the proposed\napproach, four typical time series datasets are introduced for empirical\nanalysis. The empirical results demonstrate that the proposed approach\noutperforms consistently the benchmark approaches in terms of forecasting\naccuracy, and also indicate that the reconstructed sub-signals obtained by CNN\nis of importance for further improving the forecasting performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 12:57:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Guowei", ""], ["Ren", "Tao", ""], ["Yang", "Yifan", ""]]}, {"id": "2002.09699", "submitter": "Rongfei Zeng", "authors": "Rongfei Zeng, Shixun Zhang, Jiaqi Wang and Xiaowen Chu", "title": "FMore: An Incentive Scheme of Multi-dimensional Auction for Federated\n  Learning in MEC", "comments": null, "journal-ref": null, "doi": "10.1109/ICDCS47774.2020.00094", "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promising federated learning coupled with Mobile Edge Computing (MEC) is\nconsidered as one of the most promising solutions to the AI-driven service\nprovision. Plenty of studies focus on federated learning from the performance\nand security aspects, but they neglect the incentive mechanism. In MEC, edge\nnodes would not like to voluntarily participate in learning, and they differ in\nthe provision of multi-dimensional resources, both of which might deteriorate\nthe performance of federated learning. Also, lightweight schemes appeal to edge\nnodes in MEC. These features require the incentive mechanism to be well\ndesigned for MEC. In this paper, we present an incentive mechanism FMore with\nmulti-dimensional procurement auction of K winners. Our proposal FMore not only\nis lightweight and incentive compatible, but also encourages more high-quality\nedge nodes with low cost to participate in learning and eventually improve the\nperformance of federated learning. We also present theoretical results of Nash\nequilibrium strategy to edge nodes and employ the expected utility theory to\nprovide guidance to the aggregator. Both extensive simulations and real-world\nexperiments demonstrate that the proposed scheme can effectively reduce the\ntraining rounds and drastically improve the model accuracy for challenging AI\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 13:43:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zeng", "Rongfei", ""], ["Zhang", "Shixun", ""], ["Wang", "Jiaqi", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2002.09718", "submitter": "Yifan Sun", "authors": "Yifan Sun and Francis Bach", "title": "Safe Screening for the Generalized Conditional Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional gradient method (CGM) has been widely used for fast sparse\napproximation, having a low per iteration computational cost for structured\nsparse regularizers. We explore the sparsity acquiring properties of a\ngeneralized CGM (gCGM), where the constraint is replaced by a penalty function\nbased on a gauge penalty; this can be done without significantly increasing the\nper-iteration computation, and applies to general notions of sparsity. Without\nassuming bounded iterates, we show $O(1/t)$ convergence of the function values\nand gap of gCGM. We couple this with a safe screening rule, and show that at a\nrate $O(1/(t\\delta^2))$, the screened support matches the support at the\nsolution, where $\\delta \\geq 0$ measures how close the problem is to being\ndegenerate. In our experiments, we show that the gCGM for these modified\npenalties have similar feature selection properties as common penalties, but\nwith potentially more stability over the choice of hyperparameter.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 15:07:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sun", "Yifan", ""], ["Bach", "Francis", ""]]}, {"id": "2002.09723", "submitter": "Cristian Rusu", "authors": "Cristian Rusu and Lorenzo Rosasco", "title": "Constructing fast approximate eigenspaces with application to the fast\n  graph Fourier transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.SP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate numerically efficient approximations of eigenspaces associated\nto symmetric and general matrices. The eigenspaces are factored into a fixed\nnumber of fundamental components that can be efficiently manipulated (we\nconsider extended orthogonal Givens or scaling and shear transformations). The\nnumber of these components controls the trade-off between approximation\naccuracy and the computational complexity of projecting on the eigenspaces. We\nwrite minimization problems for the single fundamental components and provide\nclosed-form solutions. Then we propose algorithms that iterative update all\nthese components until convergence. We show results on random matrices and an\napplication on the approximation of graph Fourier transforms for directed and\nundirected graphs.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 15:55:50 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:32:39 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 20:32:41 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Rusu", "Cristian", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2002.09726", "submitter": "Boris Kramer", "authors": "Peter Benner and Pawan Goyal and Boris Kramer and Benjamin\n  Peherstorfer and Karen Willcox", "title": "Operator inference for non-intrusive model reduction of systems with\n  non-polynomial nonlinear terms", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113433", "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a non-intrusive model reduction method to learn\nlow-dimensional models of dynamical systems with non-polynomial nonlinear terms\nthat are spatially local and that are given in analytic form. In contrast to\nstate-of-the-art model reduction methods that are intrusive and thus require\nfull knowledge of the governing equations and the operators of a full model of\nthe discretized dynamical system, the proposed approach requires only the\nnon-polynomial terms in analytic form and learns the rest of the dynamics from\nsnapshots computed with a potentially black-box full-model solver. The proposed\nmethod learns operators for the linear and polynomially nonlinear dynamics via\na least-squares problem, where the given non-polynomial terms are incorporated\nin the right-hand side. The least-squares problem is linear and thus can be\nsolved efficiently in practice. The proposed method is demonstrated on three\nproblems governed by partial differential equations, namely the\ndiffusion-reaction Chafee-Infante model, a tubular reactor model for reactive\nflows, and a batch-chromatography model that describes a chemical separation\nprocess. The numerical results provide evidence that the proposed approach\nlearns reduced models that achieve comparable accuracy as models constructed\nwith state-of-the-art intrusive model reduction methods that require full\nknowledge of the governing equations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 16:27:05 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 22:11:28 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Benner", "Peter", ""], ["Goyal", "Pawan", ""], ["Kramer", "Boris", ""], ["Peherstorfer", "Benjamin", ""], ["Willcox", "Karen", ""]]}, {"id": "2002.09735", "submitter": "Will Wei Sun", "authors": "Jie Zhou and Will Wei Sun and Jingfei Zhang and Lexin Li", "title": "Partially Observed Dynamic Tensor Response Regression", "comments": "Improved lower bound on observation probability (Assumptions 2,6);\n  Improved sample complexity conditions (Assumptions 5,10); Improved final\n  statistical error rate in Theorems 1-2; add a new initialization section;\n  extend to sub-Gaussian error tensor", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data science, dynamic tensor data is prevailing in numerous\napplications. An important task is to characterize the relationship between\nsuch dynamic tensor and external covariates. However, the tensor data is often\nonly partially observed, rendering many existing methods inapplicable. In this\narticle, we develop a regression model with partially observed dynamic tensor\nas the response and external covariates as the predictor. We introduce the\nlow-rank, sparsity and fusion structures on the regression coefficient tensor,\nand consider a loss function projected over the observed entries. We develop an\nefficient non-convex alternating updating algorithm, and derive the\nfinite-sample error bound of the actual estimator from each step of our\noptimization algorithm. Unobserved entries in tensor response have imposed\nserious challenges. As a result, our proposal differs considerably in terms of\nestimation algorithm, regularity conditions, as well as theoretical properties,\ncompared to the existing tensor completion or tensor response regression\nsolutions. We illustrate the efficacy of our proposed method using simulations,\nand two real applications, a neuroimaging dementia study and a digital\nadvertising study.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 17:14:10 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 22:09:53 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 23:30:56 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zhou", "Jie", ""], ["Sun", "Will Wei", ""], ["Zhang", "Jingfei", ""], ["Li", "Lexin", ""]]}, {"id": "2002.09737", "submitter": "Li Wenliang", "authors": "Li K. Wenliang, Theodore Moskovitz, Heishiro Kanagawa, Maneesh Sahani", "title": "Amortised Learning by Wake-Sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Models that employ latent variables to capture structure in observed data lie\nat the heart of many current unsupervised learning algorithms, but exact\nmaximum-likelihood learning for powerful and flexible latent-variable models is\nalmost always intractable. Thus, state-of-the-art approaches either abandon the\nmaximum-likelihood framework entirely, or else rely on a variety of variational\napproximations to the posterior distribution over the latents. Here, we propose\nan alternative approach that we call amortised learning. Rather than computing\nan approximation to the posterior over latents, we use a wake-sleep Monte-Carlo\nstrategy to learn a function that directly estimates the maximum-likelihood\nparameter updates. Amortised learning is possible whenever samples of latents\nand observations can be simulated from the generative model, treating the model\nas a \"black box\". We demonstrate its effectiveness on a wide range of complex\nmodels, including those with latents that are discrete or supported on\nnon-Euclidean spaces.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 17:24:28 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 22:37:41 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wenliang", "Li K.", ""], ["Moskovitz", "Theodore", ""], ["Kanagawa", "Heishiro", ""], ["Sahani", "Maneesh", ""]]}, {"id": "2002.09741", "submitter": "Cheng Lu", "authors": "Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, Tian Tian", "title": "VFlow: More Expressive Generative Flows with Variational Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative flows are promising tractable models for density modeling that\ndefine probabilistic distributions with invertible transformations. However,\ntractability imposes architectural constraints on generative flows, making them\nless expressive than other types of generative models. In this work, we study a\npreviously overlooked constraint that all the intermediate representations must\nhave the same dimensionality with the original data due to invertibility,\nlimiting the width of the network. We tackle this constraint by augmenting the\ndata with some extra dimensions and jointly learning a generative flow for\naugmented data as well as the distribution of augmented dimensions under a\nvariational inference framework. Our approach, VFlow, is a generalization of\ngenerative flows and therefore always performs better. Combining with existing\ngenerative flows, VFlow achieves a new state-of-the-art 2.98 bits per dimension\non the CIFAR-10 dataset and is more compact than previous models to reach\nsimilar modeling quality.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 18:03:44 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 15:27:12 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Chen", "Jianfei", ""], ["Lu", "Cheng", ""], ["Chenli", "Biqi", ""], ["Zhu", "Jun", ""], ["Tian", "Tian", ""]]}, {"id": "2002.09745", "submitter": "Judy Hanwen Shen", "authors": "Sivakanth Gopi, Pankaj Gulhane, Janardhan Kulkarni, Judy Hanwen Shen,\n  Milad Shokouhi and Sergey Yekhanin", "title": "Differentially Private Set Union", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n  Known algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 18:33:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Gulhane", "Pankaj", ""], ["Kulkarni", "Janardhan", ""], ["Shen", "Judy Hanwen", ""], ["Shokouhi", "Milad", ""], ["Yekhanin", "Sergey", ""]]}, {"id": "2002.09763", "submitter": "Hong-Li Zeng", "authors": "Kristiaan Pelckmans and Hong-Li Zeng", "title": "Longitudinal Support Vector Machines for High Dimensional Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a classifier from observed functional\ndata. Here, each data-point takes the form of a single time-series and contains\nnumerous features. Assuming that each such series comes with a binary label,\nthe problem of learning to predict the label of a new coming time-series is\nconsidered. Hereto, the notion of {\\em margin} underlying the classical support\nvector machine is extended to the continuous version for such data. The\nlongitudinal support vector machine is also a convex optimization problem and\nits dual form is derived as well. Empirical results for specified cases with\nsignificance tests indicate the efficacy of this innovative algorithm for\nanalyzing such long-term multivariate data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 20:01:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Pelckmans", "Kristiaan", ""], ["Zeng", "Hong-Li", ""]]}, {"id": "2002.09766", "submitter": "Chen Zhu", "authors": "Chen Zhu, Renkun Ni, Ping-yeh Chiang, Hengduo Li, Furong Huang, Tom\n  Goldstein", "title": "Improving the Tightness of Convex Relaxation Bounds for Training\n  Certifiably Robust Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex relaxations are effective for training and certifying neural networks\nagainst norm-bounded adversarial attacks, but they leave a large gap between\ncertifiable and empirical robustness. In principle, convex relaxation can\nprovide tight bounds if the solution to the relaxed problem is feasible for the\noriginal non-convex problem. We propose two regularizers that can be used to\ntrain neural networks that yield tighter convex relaxation bounds for\nrobustness. In all of our experiments, the proposed regularizers result in\nhigher certified accuracy than non-regularized baselines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 20:19:53 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhu", "Chen", ""], ["Ni", "Renkun", ""], ["Chiang", "Ping-yeh", ""], ["Li", "Hengduo", ""], ["Huang", "Furong", ""], ["Goldstein", "Tom", ""]]}, {"id": "2002.09769", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Ata Kaban", "title": "Optimistic bounds for multi-output prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the challenge of multi-output learning, where the goal is to\nlearn a vector-valued function based on a supervised data set. This includes a\nrange of important problems in Machine Learning including multi-target\nregression, multi-class classification and multi-label classification. We begin\nour analysis by introducing the self-bounding Lipschitz condition for\nmulti-output loss functions, which interpolates continuously between a\nclassical Lipschitz condition and a multi-dimensional analogue of a smoothness\ncondition. We then show that the self-bounding Lipschitz condition gives rise\nto optimistic bounds for multi-output learning, which are minimax optimal up to\nlogarithmic factors. The proof exploits local Rademacher complexity combined\nwith a powerful minoration inequality due to Srebro, Sridharan and Tewari. As\nan application we derive a state-of-the-art generalization bound for\nmulti-class gradient boosting.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 20:54:17 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Kaban", "Ata", ""]]}, {"id": "2002.09772", "submitter": "Aly El Gamal", "authors": "Kirthi Shankar Sivamani, Rajeev Sahay, Aly El Gamal", "title": "Non-Intrusive Detection of Adversarial Deep Learning Attacks via\n  Observer Networks", "comments": "5 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep learning models are vulnerable to\nspecifically crafted adversarial inputs that are quasi-imperceptible to humans.\nIn this letter, we propose a novel method to detect adversarial inputs, by\naugmenting the main classification network with multiple binary detectors\n(observer networks) which take inputs from the hidden layers of the original\nnetwork (convolutional kernel outputs) and classify the input as clean or\nadversarial. During inference, the detectors are treated as a part of an\nensemble network and the input is deemed adversarial if at least half of the\ndetectors classify it as so. The proposed method addresses the trade-off\nbetween accuracy of classification on clean and adversarial samples, as the\noriginal classification network is not modified during the detection process.\nThe use of multiple observer networks makes attacking the detection mechanism\nnon-trivial even when the attacker is aware of the victim classifier. We\nachieve a 99.5% detection accuracy on the MNIST dataset and 97.5% on the\nCIFAR-10 dataset using the Fast Gradient Sign Attack in a semi-white box setup.\nThe number of false positive detections is a mere 0.12% in the worst case\nscenario.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 21:13:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sivamani", "Kirthi Shankar", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2002.09773", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Mert Pilanci", "title": "Revealing the Structure of Deep Neural Networks via Convex Duality", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study regularized deep neural networks (DNNs) and introduce a convex\nanalytic framework to characterize the structure of the hidden layers. We show\nthat a set of optimal hidden layer weights for a norm regularized DNN training\nproblem can be explicitly found as the extreme points of a convex set. For the\nspecial case of deep linear networks, we prove that each optimal weight matrix\naligns with the previous layers via duality. More importantly, we apply the\nsame characterization to deep ReLU networks with whitened data and prove the\nsame weight alignment holds. As a corollary, we also prove that norm\nregularized deep ReLU networks yield spline interpolation for one-dimensional\ndatasets which was previously known only for two-layer networks. Furthermore,\nwe provide closed-form solutions for the optimal layer weights when data is\nrank-one or whitened. The same analysis also applies to architectures with\nbatch normalization even for arbitrary data. Therefore, we obtain a complete\nexplanation for a recent empirical observation termed Neural Collapse where\nclass means collapse to the vertices of a simplex equiangular tight frame.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 21:13:44 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:27:45 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 02:36:15 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 17:21:01 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ergen", "Tolga", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.09779", "submitter": "Alexandra Volokhova", "authors": "Viktor Oganesyan, Alexandra Volokhova, Dmitry Vetrov", "title": "Stochasticity in Neural ODEs: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic regularization of neural networks (e.g. dropout) is a wide-spread\ntechnique in deep learning that allows for better generalization. Despite its\nsuccess, continuous-time models, such as neural ordinary differential equation\n(ODE), usually rely on a completely deterministic feed-forward operation. This\nwork provides an empirical study of stochastically regularized neural ODE on\nseveral image-classification tasks (CIFAR-10, CIFAR-100, TinyImageNet).\nBuilding upon the formalism of stochastic differential equations (SDEs), we\ndemonstrate that neural SDE is able to outperform its deterministic\ncounterpart. Further, we show that data augmentation during the training\nimproves the performance of both deterministic and stochastic versions of the\nsame model. However, the improvements obtained by the data augmentation\ncompletely eliminate the empirical gains of the stochastic regularization,\nmaking the difference in the performance of neural ODE and neural SDE\nnegligible.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:12:56 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 17:02:20 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Oganesyan", "Viktor", ""], ["Volokhova", "Alexandra", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2002.09781", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amir Globerson", "title": "An Optimization and Generalization Analysis for Max-Pooling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-Pooling operations are a core component of deep learning architectures.\nIn particular, they are part of most convolutional architectures used in\nmachine vision, since pooling is a natural approach to pattern detection\nproblems. However, these architectures are not well understood from a\ntheoretical perspective. For example, we do not understand when they can be\nglobally optimized, and what is the effect of over-parameterization on\ngeneralization. Here we perform a theoretical analysis of a convolutional\nmax-pooling architecture, proving that it can be globally optimized, and can\ngeneralize well even for highly over-parameterized models. Our analysis focuses\non a data generating distribution inspired by pattern detection problem, where\na \"discriminative\" pattern needs to be detected among \"spurious\" patterns. We\nempirically validate that CNNs significantly outperform fully connected\nnetworks in our setting, as predicted by our theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:26:26 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 20:13:27 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 09:10:23 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 11:45:12 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""]]}, {"id": "2002.09786", "submitter": "Abdulrahman Mahmoud", "authors": "Abdulrahman Mahmoud, Siva Kumar Sastry Hari, Christopher W. Fletcher,\n  Sarita V. Adve, Charbel Sakr, Naresh Shanbhag, Pavlo Molchanov, Michael B.\n  Sullivan, Timothy Tsai, Stephen W. Keckler", "title": "HarDNN: Feature Map Vulnerability Evaluation in CNNs", "comments": "14 pages, 5 figures, a short version accepted for publication in\n  First Workshop on Secure and Resilient Autonomy (SARA) co-located with\n  MLSys2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Convolutional Neural Networks (CNNs) are increasingly being employed in\nsafety-critical applications, it is important that they behave reliably in the\nface of hardware errors. Transient hardware errors may percolate undesirable\nstate during execution, resulting in software-manifested errors which can\nadversely affect high-level decision making. This paper presents HarDNN, a\nsoftware-directed approach to identify vulnerable computations during a CNN\ninference and selectively protect them based on their propensity towards\ncorrupting the inference output in the presence of a hardware error. We show\nthat HarDNN can accurately estimate relative vulnerability of a feature map\n(fmap) in CNNs using a statistical error injection campaign, and explore\nheuristics for fast vulnerability assessment. Based on these results, we\nanalyze the tradeoff between error coverage and computational overhead that the\nsystem designers can use to employ selective protection. Results show that the\nimprovement in resilience for the added computation is superlinear with HarDNN.\nFor example, HarDNN improves SqueezeNet's resilience by 10x with just 30%\nadditional computations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 23:05:03 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 11:07:36 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mahmoud", "Abdulrahman", ""], ["Hari", "Siva Kumar Sastry", ""], ["Fletcher", "Christopher W.", ""], ["Adve", "Sarita V.", ""], ["Sakr", "Charbel", ""], ["Shanbhag", "Naresh", ""], ["Molchanov", "Pavlo", ""], ["Sullivan", "Michael B.", ""], ["Tsai", "Timothy", ""], ["Keckler", "Stephen W.", ""]]}, {"id": "2002.09794", "submitter": "Sivakumar Chidambaram", "authors": "Sivakumar Chidambaram, J.M. Pierre Langlois, Jean Pierre David", "title": "PoET-BiN: Power Efficient Tiny Binary Neurons", "comments": "Accepted in MLSys 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks in image classification has inspired various\nhardware implementations on embedded platforms such as Field Programmable Gate\nArrays, embedded processors and Graphical Processing Units. These embedded\nplatforms are constrained in terms of power, which is mainly consumed by the\nMultiply Accumulate operations and the memory accesses for weight fetching.\nQuantization and pruning have been proposed to address this issue. Though\neffective, these techniques do not take into account the underlying\narchitecture of the embedded hardware. In this work, we propose PoET-BiN, a\nLook-Up Table based power efficient implementation on resource constrained\nembedded devices. A modified Decision Tree approach forms the backbone of the\nproposed implementation in the binary domain. A LUT access consumes far less\npower than the equivalent Multiply Accumulate operation it replaces, and the\nmodified Decision Tree algorithm eliminates the need for memory accesses. We\napplied the PoET-BiN architecture to implement the classification layers of\nnetworks trained on MNIST, SVHN and CIFAR-10 datasets, with near state-of-the\nart results. The energy reduction for the classifier portion reaches up to six\norders of magnitude compared to a floating point implementations and up to\nthree orders of magnitude when compared to recent binary quantized neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 00:32:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chidambaram", "Sivakumar", ""], ["Langlois", "J. M. Pierre", ""], ["David", "Jean Pierre", ""]]}, {"id": "2002.09795", "submitter": "Donghwan Lee", "authors": "Donghwan Lee and Niao He", "title": "Periodic Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of target networks is a common practice in deep reinforcement\nlearning for stabilizing the training; however, theoretical understanding of\nthis technique is still limited. In this paper, we study the so-called periodic\nQ-learning algorithm (PQ-learning for short), which resembles the technique\nused in deep Q-learning for solving infinite-horizon discounted Markov decision\nprocesses (DMDP) in the tabular setting. PQ-learning maintains two separate\nQ-value estimates - the online estimate and target estimate. The online\nestimate follows the standard Q-learning update, while the target estimate is\nupdated periodically. In contrast to the standard Q-learning, PQ-learning\nenjoys a simple finite time analysis and achieves better sample complexity for\nfinding an epsilon-optimal policy. Our result provides a preliminary\njustification of the effectiveness of utilizing target estimates or networks in\nQ-learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 00:33:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lee", "Donghwan", ""], ["He", "Niao", ""]]}, {"id": "2002.09797", "submitter": "Seong Joon Oh", "authors": "Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi,\n  Jaejun Yoo", "title": "Reliable Fidelity and Diversity Metrics for Generative Models", "comments": "First two authors have contributed equally; ICML 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devising indicative evaluation metrics for the image generation task remains\nan open problem. The most widely used metric for measuring the similarity\nbetween real and generated images has been the Fr\\'echet Inception Distance\n(FID) score. Because it does not differentiate the fidelity and diversity\naspects of the generated images, recent papers have introduced variants of\nprecision and recall metrics to diagnose those properties separately. In this\npaper, we show that even the latest version of the precision and recall metrics\nare not reliable yet. For example, they fail to detect the match between two\nidentical distributions, they are not robust against outliers, and the\nevaluation hyperparameters are selected arbitrarily. We propose density and\ncoverage metrics that solve the above issues. We analytically and\nexperimentally show that density and coverage provide more interpretable and\nreliable signals for practitioners than the existing metrics. Code:\nhttps://github.com/clovaai/generative-evaluation-prdc.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 00:50:01 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 20:37:50 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Naeem", "Muhammad Ferjad", ""], ["Oh", "Seong Joon", ""], ["Uh", "Youngjung", ""], ["Choi", "Yunjey", ""], ["Yoo", "Jaejun", ""]]}, {"id": "2002.09806", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Zhengyuan Zhou, Panayotis Mertikopoulos and Michael I.\n  Jordan", "title": "Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games", "comments": "Accepted by ICML 2020; The first two authors contributed equally to\n  this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider multi-agent learning via online gradient descent\nin a class of games called $\\lambda$-cocoercive games, a fairly broad class of\ngames that admits many Nash equilibria and that properly includes unconstrained\nstrongly monotone games. We characterize the finite-time last-iterate\nconvergence rate for joint OGD learning on $\\lambda$-cocoercive games; further,\nbuilding on this result, we develop a fully adaptive OGD learning algorithm\nthat does not require any knowledge of problem parameter (e.g. cocoercive\nconstant $\\lambda$) and show, via a novel double-stopping time technique, that\nthis adaptive algorithm achieves same finite-time last-iterate convergence rate\nas non-adaptive counterpart. Subsequently, we extend OGD learning to the noisy\ngradient feedback case and establish last-iterate convergence results -- first\nqualitative almost sure convergence, then quantitative finite-time convergence\nrates -- all under non-decreasing step-sizes. To our knowledge, we provide the\nfirst set of results that fill in several gaps of the existing multi-agent\nonline learning literature, where three aspects -- finite-time convergence\nrates, non-decreasing step-sizes, and fully adaptive algorithms have been\nunexplored before.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 01:46:34 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:11:10 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 19:53:12 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 19:10:04 GMT"}, {"version": "v5", "created": "Sat, 17 Jul 2021 06:09:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lin", "Tianyi", ""], ["Zhou", "Zhengyuan", ""], ["Mertikopoulos", "Panayotis", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.09814", "submitter": "Sanath Kumar Krishnamurthy", "authors": "Sanath Kumar Krishnamurthy, Susan Athey", "title": "Survey Bandits with Regret Guarantees", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the contextual bandit problem. In standard\ncontextual bandits, when a user arrives we get the user's complete feature\nvector and then assign a treatment (arm) to that user. In a number of\napplications (like healthcare), collecting features from users can be costly.\nTo address this issue, we propose algorithms that avoid needless feature\ncollection while maintaining strong regret guarantees.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:24:03 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Krishnamurthy", "Sanath Kumar", ""], ["Athey", "Susan", ""]]}, {"id": "2002.09815", "submitter": "Amirata Ghorbani", "authors": "Amirata Ghorbani and James Zou", "title": "Neuron Shapley: Discovering the Responsible Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop Neuron Shapley as a new framework to quantify the contribution of\nindividual neurons to the prediction and performance of a deep network. By\naccounting for interactions across neurons, Neuron Shapley is more effective in\nidentifying important filters compared to common approaches based on activation\npatterns. Interestingly, removing just 30 filters with the highest Shapley\nscores effectively destroys the prediction accuracy of Inception-v3 on\nImageNet. Visualization of these few critical filters provides insights into\nhow the network functions. Neuron Shapley is a flexible framework and can be\napplied to identify responsible neurons in many tasks. We illustrate additional\napplications of identifying filters that are responsible for biased prediction\nin facial recognition and filters that are vulnerable to adversarial attacks.\nRemoving these filters is a quick way to repair models. Enabling all these\napplications is a new multi-arm bandit algorithm that we developed to\nefficiently estimate Neuron Shapley values.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:29:58 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 06:57:29 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 22:06:48 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "2002.09831", "submitter": "Samet Oymak", "authors": "Yuan Zhao, Jiasi Chen, Samet Oymak", "title": "On the Role of Dataset Quality and Heterogeneity in Model Confidence", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety-critical applications require machine learning models that output\naccurate and calibrated probabilities. While uncalibrated deep networks are\nknown to make over-confident predictions, it is unclear how model confidence is\nimpacted by the variations in the data, such as label noise or class size. In\nthis paper, we investigate the role of the dataset quality by studying the\nimpact of dataset size and the label noise on the model confidence. We\ntheoretically explain and experimentally demonstrate that, surprisingly, label\nnoise in the training data leads to under-confident networks, while reduced\ndataset size leads to over-confident models. We then study the impact of\ndataset heterogeneity, where data quality varies across classes, on model\nconfidence. We demonstrate that this leads to heterogenous confidence/accuracy\nbehavior in the test data and is poorly handled by the standard calibration\nalgorithms. To overcome this, we propose an intuitive heterogenous calibration\ntechnique and show that the proposed approach leads to improved calibration\nmetrics (both average and worst-case errors) on the CIFAR datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:13:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhao", "Yuan", ""], ["Chen", "Jiasi", ""], ["Oymak", "Samet", ""]]}, {"id": "2002.09841", "submitter": "Chao Wang", "authors": "Chao Wang, Hengshu Zhu, Chen Zhu, Chuan Qin, Hui Xiong", "title": "SetRank: A Setwise Bayesian Approach for Collaborative Ranking from\n  Implicit Feedback", "comments": "This paper has been accepted in AAAI'20", "journal-ref": "The Thirty-Fourth AAAI Conference on Artificial Intelligenc\n  (AAAI'20), New York, New York, USA, 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of online recommender systems has a focus on\ncollaborative ranking from implicit feedback, such as user clicks and\npurchases. Different from explicit ratings, which reflect graded user\npreferences, the implicit feedback only generates positive and unobserved\nlabels. While considerable efforts have been made in this direction, the\nwell-known pairwise and listwise approaches have still been limited by various\nchallenges. Specifically, for the pairwise approaches, the assumption of\nindependent pairwise preference is not always held in practice. Also, the\nlistwise approaches cannot efficiently accommodate \"ties\" due to the\nprecondition of the entire list permutation. To this end, in this paper, we\npropose a novel setwise Bayesian approach for collaborative ranking, namely\nSetRank, to inherently accommodate the characteristics of implicit feedback in\nrecommender system. Specifically, SetRank aims at maximizing the posterior\nprobability of novel setwise preference comparisons and can be implemented with\nmatrix factorization and neural networks. Meanwhile, we also present the\ntheoretical analysis of SetRank to show that the bound of excess risk can be\nproportional to $\\sqrt{M/N}$, where $M$ and $N$ are the numbers of items and\nusers, respectively. Finally, extensive experiments on four real-world datasets\nclearly validate the superiority of SetRank compared with various\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:40:48 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Chao", ""], ["Zhu", "Hengshu", ""], ["Zhu", "Chen", ""], ["Qin", "Chuan", ""], ["Xiong", "Hui", ""]]}, {"id": "2002.09843", "submitter": "Yan Feng", "authors": "Xue Yang, Yan Feng, Weijun Fang, Jun Shao, Xiaohu Tang, Shu-Tao Xia,\n  Rongxing Lu", "title": "Computation-efficient Deep Model Training for Ciphertext-based\n  Cross-silo Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cross-silo federated learning improves privacy of training data by\nexchanging model updates rather than raw data, sharing updates (e.g., local\ngradients or parameters) may still involve risks. To ensure no updates are\nrevealed to the server, industrial FL schemes allow clients (e.g., financial or\nmedical) to mask local gradients by homomorphic encryption (HE). In this case,\nthe server cannot obtain the updates, but the curious clients can obtain this\ninformation to infer other clients' private data. To alleviate this situation,\nthe most direct idea is to let clients train deep models on encrypted domain.\nUnfortunately, the resulting solution is of poor accuracy and high cost, since\nthe existing advanced HE is incompatible with non-linear activation functions\nand inefficient in terms of computational cost. In this paper, we propose a\n\\emph{computational-efficient deep model training scheme for ciphertext-based\ncross-silo federated learning} to comprehensively guarantee privacy. First, we\ncustomize \\emph{a novel one-time-pad-style model encryption method} to directly\nsupports non-linear activation functions and decimal arithmetic operations on\nthe encrypted domain. Then, we design a hybrid privacy-preserving scheme by\ncombining our model encryption method with secret sharing techniques to keep\nupdates secret from the clients and prevent the server from obtaining local\ngradients of each client. Extensive experiments demonstrate that for both\nregression and classification tasks, our scheme achieves the same accuracy as\nnon-private approaches and outperforms the state-of-the-art HE-based scheme.\nBesides, training time of our scheme is almost the same as non-private\napproaches and much more efficient than HE-based schemes. Our scheme trains a\n$9$-layer neural network on the MNIST dataset in less than one hour.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:50:20 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:24:04 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 15:10:37 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 08:35:48 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yang", "Xue", ""], ["Feng", "Yan", ""], ["Fang", "Weijun", ""], ["Shao", "Jun", ""], ["Tang", "Xiaohu", ""], ["Xia", "Shu-Tao", ""], ["Lu", "Rongxing", ""]]}, {"id": "2002.09846", "submitter": "Wei Ye", "authors": "Wei Ye, Zhen Wang, Rachel Redberg, Ambuj Singh", "title": "Tree++: Truncated Tree Based Graph Kernels", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2019.2946149", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph-structured data arise ubiquitously in many application domains. A\nfundamental problem is to quantify their similarities. Graph kernels are often\nused for this purpose, which decompose graphs into substructures and compare\nthese substructures. However, most of the existing graph kernels do not have\nthe property of scale-adaptivity, i.e., they cannot compare graphs at multiple\nlevels of granularities. Many real-world graphs such as molecules exhibit\nstructure at varying levels of granularities. To tackle this problem, we\npropose a new graph kernel called Tree++ in this paper. At the heart of Tree++\nis a graph kernel called the path-pattern graph kernel. The path-pattern graph\nkernel first builds a truncated BFS tree rooted at each vertex and then uses\npaths from the root to every vertex in the truncated BFS tree as features to\nrepresent graphs. The path-pattern graph kernel can only capture graph\nsimilarity at fine granularities. In order to capture graph similarity at\ncoarse granularities, we incorporate a new concept called super path into it.\nThe super path contains truncated BFS trees rooted at the vertices in a path.\nOur evaluation on a variety of real-world graphs demonstrates that Tree++\nachieves the best classification accuracy compared with previous graph kernels.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:07:10 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ye", "Wei", ""], ["Wang", "Zhen", ""], ["Redberg", "Rachel", ""], ["Singh", "Ambuj", ""]]}, {"id": "2002.09847", "submitter": "Jong Chul Ye", "authors": "Joonyoung Song, Jae-Heon Jeong, Dae-Soon Park, Hyun-Ho Kim, Doo-Chun\n  Seo, Jong Chul Ye", "title": "Unsupervised Denoising for Satellite Imagery using Wavelet Subband\n  CycleGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-spectral satellite imaging sensors acquire various spectral band images\nsuch as red (R), green (G), blue (B), near-infrared (N), etc. Thanks to the\nunique spectroscopic property of each spectral band with respective to the\nobjects on the ground, multi-spectral satellite imagery can be used for various\ngeological survey applications. Unfortunately, image artifacts from imaging\nsensor noises often affect the quality of scenes and have negative impacts on\nthe applications of satellite imagery. Recently, deep learning approaches have\nbeen extensively explored for the removal of noises in satellite imagery. Most\ndeep learning denoising methods, however, follow a supervised learning scheme,\nwhich requires matched noisy image and clean image pairs that are difficult to\ncollect in real situations. In this paper, we propose a novel unsupervised\nmultispectral denoising method for satellite imagery using wavelet subband\ncycle-consistent adversarial network (WavCycleGAN). The proposed method is\nbased on unsupervised learning scheme using adversarial loss and\ncycle-consistency loss to overcome the lack of paired data. Moreover, in\ncontrast to the standard image domain cycleGAN, we introduce a wavelet subband\ndomain learning scheme for effective denoising without sacrificing high\nfrequency components such as edges and detail information. Experimental results\nfor the removal of vertical stripe and wave noises in satellite imaging sensors\ndemonstrate that the proposed method effectively removes noises and preserves\nimportant high frequency features of satellite images.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:11:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Song", "Joonyoung", ""], ["Jeong", "Jae-Heon", ""], ["Park", "Dae-Soon", ""], ["Kim", "Hyun-Ho", ""], ["Seo", "Doo-Chun", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2002.09864", "submitter": "Daniel Teitelman Mr", "authors": "Daniel Teitelman, Itay Naeh and Shie Mannor", "title": "Stealing Black-Box Functionality Using The Deep Neural Tree Architecture", "comments": "8 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes a substantial step towards cloning the functionality of\nblack-box models by introducing a Machine learning (ML) architecture named Deep\nNeural Trees (DNTs). This new architecture can learn to separate different\ntasks of the black-box model, and clone its task-specific behavior. We propose\nto train the DNT using an active learning algorithm to obtain faster and more\nsample-efficient training. In contrast to prior work, we study a complex\n\"victim\" black-box model based solely on input-output interactions, while at\nthe same time the attacker and the victim model may have completely different\ninternal architectures. The attacker is a ML based algorithm whereas the victim\nis a generally unknown module, such as a multi-purpose digital chip, complex\nanalog circuit, mechanical system, software logic or a hybrid of these. The\ntrained DNT module not only can function as the attacked module, but also\nprovides some level of explainability to the cloned model due to the tree-like\nnature of the proposed architecture.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:04:30 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Teitelman", "Daniel", ""], ["Naeh", "Itay", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.09866", "submitter": "Yossi Adi", "authors": "Yossi Adi, Yaniv Nemcovsky, Alex Schwing, Tamir Hazan", "title": "On the generalization of bayesian deep nets for multi-class\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization bounds which assess the difference between the true risk and\nthe empirical risk have been studied extensively. However, to obtain bounds,\ncurrent techniques use strict assumptions such as a uniformly bounded or a\nLipschitz loss function. To avoid these assumptions, in this paper, we propose\na new generalization bound for Bayesian deep nets by exploiting the\ncontractivity of the Log-Sobolev inequalities. Using these inequalities adds an\nadditional loss-gradient norm term to the generalization bound, which is\nintuitively a surrogate of the model complexity. Empirically, we analyze the\naffect of this loss-gradient norm term using different deep nets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:05:03 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Adi", "Yossi", ""], ["Nemcovsky", "Yaniv", ""], ["Schwing", "Alex", ""], ["Hazan", "Tamir", ""]]}, {"id": "2002.09869", "submitter": "Alon Cohen", "authors": "Alon Cohen, Haim Kaplan, Yishay Mansour and Aviv Rosenberg", "title": "Near-optimal Regret Bounds for Stochastic Shortest Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic shortest path (SSP) is a well-known problem in planning and\ncontrol, in which an agent has to reach a goal state in minimum total expected\ncost. In the learning formulation of the problem, the agent is unaware of the\nenvironment dynamics (i.e., the transition function) and has to repeatedly play\nfor a given number of episodes while reasoning about the problem's optimal\nsolution. Unlike other well-studied models in reinforcement learning (RL), the\nlength of an episode is not predetermined (or bounded) and is influenced by the\nagent's actions. Recently, Tarbouriech et al. (2019) studied this problem in\nthe context of regret minimization and provided an algorithm whose regret bound\nis inversely proportional to the square root of the minimum instantaneous cost.\nIn this work we remove this dependence on the minimum cost---we give an\nalgorithm that guarantees a regret bound of $\\widetilde{O}(B_\\star |S|\n\\sqrt{|A| K})$, where $B_\\star$ is an upper bound on the expected cost of the\noptimal policy, $S$ is the set of states, $A$ is the set of actions and $K$ is\nthe number of episodes. We additionally show that any learning algorithm must\nhave at least $\\Omega(B_\\star \\sqrt{|S| |A| K})$ regret in the worst case.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:10:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cohen", "Alon", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Rosenberg", "Aviv", ""]]}, {"id": "2002.09884", "submitter": "Xiao Ma", "authors": "Xiao Ma, Peter Karkus, David Hsu, Wee Sun Lee, Nan Ye", "title": "Discriminative Particle Filter Reinforcement Learning for Complex\n  Partial Observations", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is successful in decision making for\nsophisticated games, such as Atari, Go, etc. However, real-world decision\nmaking often requires reasoning with partial information extracted from complex\nvisual observations. This paper presents Discriminative Particle Filter\nReinforcement Learning (DPFRL), a new reinforcement learning framework for\ncomplex partial observations. DPFRL encodes a differentiable particle filter in\nthe neural network policy for explicit reasoning with partial observations over\ntime. The particle filter maintains a belief using learned discriminative\nupdate, which is trained end-to-end for decision making. We show that using the\ndiscriminative update instead of standard generative models results in\nsignificantly improved performance, especially for tasks with complex visual\nobservations, because they circumvent the difficulty of modeling complex\nobservations that are irrelevant to decision making. In addition, to extract\nfeatures from the particle belief, we propose a new type of belief feature\nbased on the moment generating function. DPFRL outperforms state-of-the-art\nPOMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and\nin Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark\nintroduced in this paper. Further, DPFRL performs well for visual navigation\nwith real-world data in the Habitat environment.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 11:22:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiao", ""], ["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""], ["Ye", "Nan", ""]]}, {"id": "2002.09889", "submitter": "Daniel Wilke", "authors": "D. Kafka and Daniel. N. Wilke", "title": "Investigating the interaction between gradient-only line searches and\n  different activation functions", "comments": "37 pages, 9 figures, submitted for journal review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-only line searches (GOLS) adaptively determine step sizes along\nsearch directions for discontinuous loss functions resulting from dynamic\nmini-batch sub-sampling in neural network training. Step sizes in GOLS are\ndetermined by localizing Stochastic Non-Negative Associated Gradient Projection\nPoints (SNN-GPPs) along descent directions. These are identified by a sign\nchange in the directional derivative from negative to positive along a descent\ndirection. Activation functions are a significant component of neural network\narchitectures as they introduce non-linearities essential for complex function\napproximations. The smoothness and continuity characteristics of the activation\nfunctions directly affect the gradient characteristics of the loss function to\nbe optimized. Therefore, it is of interest to investigate the relationship\nbetween activation functions and different neural network architectures in the\ncontext of GOLS. We find that GOLS are robust for a range of activation\nfunctions, but sensitive to the Rectified Linear Unit (ReLU) activation\nfunction in standard feedforward architectures. The zero-derivative in ReLU's\nnegative input domain can lead to the gradient-vector becoming sparse, which\nseverely affects training. We show that implementing architectural features\nsuch as batch normalization and skip connections can alleviate these\ndifficulties and benefit training with GOLS for all activation functions\nconsidered.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 12:28:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kafka", "D.", ""], ["Wilke", "Daniel. N.", ""]]}, {"id": "2002.09891", "submitter": "Enmei Tu", "authors": "Zihao Wang, Enmei Tu, Zhou Meng", "title": "End-To-End Graph-based Deep Semi-Supervised Learning", "comments": "5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of a graph is determined jointly by three key factors of the\ngraph: nodes, edges and similarity measure (or edge weights), and is very\ncrucial to the success of graph-based semi-supervised learning (SSL)\napproaches. Recently, dynamic graph, which means part/all its factors are\ndynamically updated during the training process, has demonstrated to be\npromising for graph-based semi-supervised learning. However, existing\napproaches only update part of the three factors and keep the rest manually\nspecified during the learning stage. In this paper, we propose a novel\ngraph-based semi-supervised learning approach to optimize all three factors\nsimultaneously in an end-to-end learning fashion. To this end, we concatenate\ntwo neural networks (feature network and similarity network) together to learn\nthe categorical label and semantic similarity, respectively, and train the\nnetworks to minimize a unified SSL objective function. We also introduce an\nextended graph Laplacian regularization term to increase training efficiency.\nExtensive experiments on several benchmark datasets demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 12:32:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Zihao", ""], ["Tu", "Enmei", ""], ["Meng", "Zhou", ""]]}, {"id": "2002.09914", "submitter": "Martijn Oldenhof", "authors": "Martijn Oldenhof, Adam Arany, Yves Moreau and Jaak Simm", "title": "ChemGrapher: Optical Graph Recognition of Chemical Compounds by Deep\n  Learning", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": "10.1021/acs.jcim.0c00459", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In drug discovery, knowledge of the graph structure of chemical compounds is\nessential. Many thousands of scientific articles in chemistry and\npharmaceutical sciences have investigated chemical compounds, but in cases the\ndetails of the structure of these chemical compounds is published only as an\nimages. A tool to analyze these images automatically and convert them into a\nchemical graph structure would be useful for many applications, such drug\ndiscovery. A few such tools are available and they are mostly derived from\noptical character recognition. However, our evaluation of the performance of\nthose tools reveals that they make often mistakes in detecting the correct bond\nmultiplicity and stereochemical information. In addition, errors sometimes even\nlead to missing atoms in the resulting graph. In our work, we address these\nissues by developing a compound recognition method based on machine learning.\nMore specifically, we develop a deep neural network model for optical compound\nrecognition. The deep learning solution presented here consists of a\nsegmentation model, followed by three classification models that predict atom\nlocations, bonds and charges. Furthermore, this model not only predicts the\ngraph structure of the molecule but also produces all information necessary to\nrelate each component of the resulting graph to the source image. This solution\nis scalable and could rapidly process thousands of images. Finally, we compare\nempirically the proposed method to a well-established tool and observe\nsignificant error reductions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 14:30:55 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Oldenhof", "Martijn", ""], ["Arany", "Adam", ""], ["Moreau", "Yves", ""], ["Simm", "Jaak", ""]]}, {"id": "2002.09917", "submitter": "Xiangrui Li", "authors": "Xiangrui Li, Deng Pan, Xin Li, Dongxiao Zhu", "title": "Improve SGD Training via Aligning Mini-batches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) for supervised learning can be viewed as a\npipeline of a feature extractor (i.e. last hidden layer) and a linear\nclassifier (i.e. output layer) that is trained jointly with stochastic gradient\ndescent (SGD). In each iteration of SGD, a mini-batch from the training data is\nsampled and the true gradient of the loss function is estimated as the noisy\ngradient calculated on this mini-batch. From the feature learning perspective,\nthe feature extractor should be updated to learn meaningful features with\nrespect to the entire data, and reduce the accommodation to noise in the\nmini-batch. With this motivation, we propose In-Training Distribution Matching\n(ITDM) to improve DNN training and reduce overfitting. Specifically, along with\nthe loss function, ITDM regularizes the feature extractor by matching the\nmoments of distributions of different mini-batches in each iteration of SGD,\nwhich is fulfilled by minimizing the maximum mean discrepancy. As such, ITDM\ndoes not assume any explicit parametric form of data distribution in the latent\nfeature space. Extensive experiments are conducted to demonstrate the\neffectiveness of our proposed strategy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:10:59 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:59:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Li", "Xiangrui", ""], ["Pan", "Deng", ""], ["Li", "Xin", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "2002.09927", "submitter": "Setareh Ariafar", "authors": "Setareh Ariafar, Zelda Mariet, Ehsan Elhamifar, Dana Brooks, Jennifer\n  Dy and Jasper Snoek", "title": "Weighting Is Worth the Wait: Bayesian Optimization with Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many contemporary machine learning models require extensive tuning of\nhyperparameters to perform well. A variety of methods, such as Bayesian\noptimization, have been developed to automate and expedite this process.\nHowever, tuning remains extremely costly as it typically requires repeatedly\nfully training models. We propose to accelerate the Bayesian optimization\napproach to hyperparameter tuning for neural networks by taking into account\nthe relative amount of information contributed by each training example. To do\nso, we leverage importance sampling (IS); this significantly increases the\nquality of the black-box function evaluations, but also their runtime, and so\nmust be done carefully. Casting hyperparameter search as a multi-task Bayesian\noptimization problem over both hyperparameters and importance sampling design\nachieves the best of both worlds: by learning a parameterization of IS that\ntrades-off evaluation complexity and quality, we improve upon Bayesian\noptimization state-of-the-art runtime and final validation error across a\nvariety of datasets and complex neural architectures.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:52:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ariafar", "Setareh", ""], ["Mariet", "Zelda", ""], ["Elhamifar", "Ehsan", ""], ["Brooks", "Dana", ""], ["Dy", "Jennifer", ""], ["Snoek", "Jasper", ""]]}, {"id": "2002.09928", "submitter": "Auke Wiggers", "authors": "Auke Wiggers, Emiel Hoogeboom", "title": "Predictive Sampling with Forecasting Autoregressive Models", "comments": "Accepted at the 37th International Conference on Machine Learning\n  (ICML 2020). 14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoregressive models (ARMs) currently hold state-of-the-art performance in\nlikelihood-based modeling of image and audio data. Generally, neural network\nbased ARMs are designed to allow fast inference, but sampling from these models\nis impractically slow. In this paper, we introduce the predictive sampling\nalgorithm: a procedure that exploits the fast inference property of ARMs in\norder to speed up sampling, while keeping the model intact. We propose two\nvariations of predictive sampling, namely sampling with ARM fixed-point\niteration and learned forecasting modules. Their effectiveness is demonstrated\nin two settings: i) explicit likelihood modeling on binary MNIST, SVHN and\nCIFAR10, and ii) discrete latent modeling in an autoencoder trained on SVHN,\nCIFAR10 and Imagenet32. Empirically, we show considerable improvements over\nbaselines in number of ARM inference calls and sampling speed.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:58:47 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 10:02:57 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wiggers", "Auke", ""], ["Hoogeboom", "Emiel", ""]]}, {"id": "2002.09931", "submitter": "Carlos Sarraute PhD", "authors": "Mar\\'ia \\'Oskarsd\\'ottir, Cristi\\'an Bravo, Carlos Sarraute, Jan\n  Vanthienen, Bart Baesens", "title": "The Value of Big Data for Credit Scoring: Enhancing Financial Inclusion\n  using Mobile Phone Data and Social Network Analytics", "comments": null, "journal-ref": "Applied Soft Computing, Volume 74, January 2019, Pages 26-39", "doi": "10.1016/j.asoc.2018.10.004", "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Credit scoring is without a doubt one of the oldest applications of\nanalytics. In recent years, a multitude of sophisticated classification\ntechniques have been developed to improve the statistical performance of credit\nscoring models. Instead of focusing on the techniques themselves, this paper\nleverages alternative data sources to enhance both statistical and economic\nmodel performance. The study demonstrates how including call networks, in the\ncontext of positive credit information, as a new Big Data source has added\nvalue in terms of profit by applying a profit measure and profit-based feature\nselection. A unique combination of datasets, including call-detail records,\ncredit and debit account information of customers is used to create scorecards\nfor credit card applicants. Call-detail records are used to build call networks\nand advanced social network analytics techniques are applied to propagate\ninfluence from prior defaulters throughout the network to produce influence\nscores. The results show that combining call-detail records with traditional\ndata in credit scoring models significantly increases their performance when\nmeasured in AUC. In terms of profit, the best model is the one built with only\ncalling behavior features. In addition, the calling behavior features are the\nmost predictive in other models, both in terms of statistical and economic\nperformance. The results have an impact in terms of ethical use of call-detail\nrecords, regulatory implications, financial inclusion, as well as data sharing\nand privacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 16:13:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""], ["Bravo", "Cristi\u00e1n", ""], ["Sarraute", "Carlos", ""], ["Vanthienen", "Jan", ""], ["Baesens", "Bart", ""]]}, {"id": "2002.09943", "submitter": "Cong Ye", "authors": "Cong Ye, Konstantinos Slavakis, Pratik V. Patil, Johan Nakuci, Sarah\n  F. Muldoon, John Medaglia", "title": "Network Clustering Via Kernel-ARMA Modeling and the Grassmannian The\n  Brain-Network Case", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.02292", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a clustering framework for networks with nodes\nannotated with time-series data. The framework addresses all types of\nnetwork-clustering problems: State clustering, node clustering within states\n(a.k.a. topology identification or community detection), and even\nsubnetwork-state-sequence identification/tracking. Via a bottom-up approach,\nfeatures are first extracted from the raw nodal time-series data by kernel\nautoregressive-moving-average modeling to reveal non-linear dependencies and\nlow-rank representations, and then mapped onto the Grassmann manifold\n(Grassmannian). All clustering tasks are performed by leveraging the underlying\nRiemannian geometry of the Grassmannian in a novel way. To validate the\nproposed framework, brain-network clustering is considered, where extensive\nnumerical tests on synthetic and real functional magnetic resonance imaging\n(fMRI) data demonstrate that the advocated learning framework compares\nfavorably versus several state-of-the-art clustering schemes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:48:38 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ye", "Cong", ""], ["Slavakis", "Konstantinos", ""], ["Patil", "Pratik V.", ""], ["Nakuci", "Johan", ""], ["Muldoon", "Sarah F.", ""], ["Medaglia", "John", ""]]}, {"id": "2002.09954", "submitter": "Luigi Carratino", "authors": "Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal\n  Valko, Lorenzo Rosasco", "title": "Near-linear Time Gaussian Process Optimization with Adaptive Batching\n  and Resparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are one of the most successful frameworks to model\nuncertainty. However, GP optimization (e.g., GP-UCB) suffers from major\nscalability issues. Experimental time grows linearly with the number of\nevaluations, unless candidates are selected in batches (e.g., using GP-BUCB)\nand evaluated in parallel. Furthermore, computational cost is often prohibitive\nsince algorithms such as GP-BUCB require a time at least quadratic in the\nnumber of dimensions and iterations to select each batch. In this paper, we\nintroduce BBKB (Batch Budgeted Kernel Bandits), the first no-regret GP\noptimization algorithm that provably runs in near-linear time and selects\ncandidates in batches. This is obtained with a new guarantee for the tracking\nof the posterior variances that allows BBKB to choose increasingly larger\nbatches, improving over GP-BUCB. Moreover, we show that the same bound can be\nused to adaptively delay costly updates to the sparse GP approximation used by\nBBKB, achieving a near-constant per-step amortized cost. These findings are\nthen confirmed in several experiments, where BBKB is much faster than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:43:29 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:45:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Calandriello", "Daniele", ""], ["Carratino", "Luigi", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2002.09956", "submitter": "Yingxue Zhou", "authors": "Arindam Banerjee, Tiancong Chen and Yingxue Zhou", "title": "De-randomized PAC-Bayes Margin Bounds: Applications to Non-convex and\n  Non-smooth Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of several notable efforts, explaining the generalization of\ndeterministic non-smooth deep nets, e.g., ReLU-nets, has remained challenging.\nExisting approaches for deterministic non-smooth deep nets typically need to\nbound the Lipschitz constant of such deep nets but such bounds are quite large,\nmay even increase with the training set size yielding vacuous generalization\nbounds. In this paper, we present a new family of de-randomized PAC-Bayes\nmargin bounds for deterministic non-convex and non-smooth predictors, e.g.,\nReLU-nets. Unlike PAC-Bayes, which applies to Bayesian predictors, the\nde-randomized bounds apply to deterministic predictors like ReLU-nets. A\nspecific instantiation of the bound depends on a trade-off between the\n(weighted) distance of the trained weights from the initialization and the\neffective curvature (`flatness') of the trained predictor.\n  To get to these bounds, we first develop a de-randomization argument for\nnon-convex but smooth predictors, e.g., linear deep networks (LDNs), which\nconnects the performance of the deterministic predictor with a Bayesian\npredictor. We then consider non-smooth predictors which for any given input\nrealized as a smooth predictor, e.g., ReLU-nets become some LDNs for any given\ninput, but the realized smooth predictors can be different for different\ninputs. For such non-smooth predictors, we introduce a new PAC-Bayes analysis\nwhich takes advantage of the smoothness of the realized predictors, e.g., LDN,\nfor a given input, and avoids dependency on the Lipschitz constant of the\nnon-smooth predictor. After careful de-randomization, we get a bound for the\ndeterministic non-smooth predictor. We also establish non-uniform sample\ncomplexity results based on such bounds. Finally, we present extensive\nempirical results of our bounds over changing training set size and randomness\nin labels.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:54:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 06:56:39 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 01:29:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Banerjee", "Arindam", ""], ["Chen", "Tiancong", ""], ["Zhou", "Yingxue", ""]]}, {"id": "2002.09958", "submitter": "Sai Aparna Aketi", "authors": "Sai Aparna Aketi, Sourjya Roy, Anand Raghunathan, Kaushik Roy", "title": "Gradual Channel Pruning while Training using Feature Relevance Scores\n  for Convolutional Neural Networks", "comments": "15 pages, 2 figures, 4 tables", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3024992", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enormous inference cost of deep neural networks can be scaled down by\nnetwork compression. Pruning is one of the predominant approaches used for deep\nnetwork compression. However, existing pruning techniques have one or more of\nthe following limitations: 1) Additional energy cost on top of the compute\nheavy training stage due to pruning and fine-tuning stages, 2) Layer-wise\npruning based on the statistics of a particular, ignoring the effect of error\npropagation in the network, 3) Lack of an efficient estimate for determining\nthe important channels globally, 4) Unstructured pruning requires specialized\nhardware for effective use. To address all the above issues, we present a\nsimple-yet-effective gradual channel pruning while training methodology using a\nnovel data-driven metric referred to as feature relevance score. The proposed\ntechnique gets rid of the additional retraining cycles by pruning the least\nimportant channels in a structured fashion at fixed intervals during the actual\ntraining phase. Feature relevance scores help in efficiently evaluating the\ncontribution of each channel towards the discriminative power of the network.\nWe demonstrate the effectiveness of the proposed methodology on architectures\nsuch as VGG and ResNet using datasets such as CIFAR-10, CIFAR-100 and ImageNet,\nand successfully achieve significant model compression while trading off less\nthan $1\\%$ accuracy. Notably on CIFAR-10 dataset trained on ResNet-110, our\napproach achieves $2.4\\times$ compression and a $56\\%$ reduction in FLOPs with\nan accuracy drop of $0.01\\%$ compared to the unpruned network.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:56:18 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 15:01:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Aketi", "Sai Aparna", ""], ["Roy", "Sourjya", ""], ["Raghunathan", "Anand", ""], ["Roy", "Kaushik", ""]]}, {"id": "2002.09963", "submitter": "Matthew Almeida", "authors": "Matthew Almeida, Wei Ding, Scott Crouter, Ping Chen", "title": "Mitigating Class Boundary Label Uncertainty to Reduce Both Model Bias\n  and Variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of model bias and variance with respect to decision boundaries is\ncritically important in supervised classification. There is generally a\ntradeoff between the two, as fine-tuning of the decision boundary of a\nclassification model to accommodate more boundary training samples (i.e.,\nhigher model complexity) may improve training accuracy (i.e., lower bias) but\nhurt generalization against unseen data (i.e., higher variance). By focusing on\njust classification boundary fine-tuning and model complexity, it is difficult\nto reduce both bias and variance. To overcome this dilemma, we take a different\nperspective and investigate a new approach to handle inaccuracy and uncertainty\nin the training data labels, which are inevitable in many applications where\nlabels are conceptual and labeling is performed by human annotators. The\nprocess of classification can be undermined by uncertainty in the labels of the\ntraining data; extending a boundary to accommodate an inaccurately labeled\npoint will increase both bias and variance. Our novel method can reduce both\nbias and variance by estimating the pointwise label uncertainty of the training\nset and accordingly adjusting the training sample weights such that those\nsamples with high uncertainty are weighted down and those with low uncertainty\nare weighted up. In this way, uncertain samples have a smaller contribution to\nthe objective function of the model's learning algorithm and exert less pull on\nthe decision boundary. In a real-world physical activity recognition case\nstudy, the data presents many labeling challenges, and we show that this new\napproach improves model performance and reduces model variance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:24:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Almeida", "Matthew", ""], ["Ding", "Wei", ""], ["Crouter", "Scott", ""], ["Chen", "Ping", ""]]}, {"id": "2002.09971", "submitter": "Sabina Tomkins", "authors": "Sabina Tomkins, Peng Liao, Predrag Klasnja, Serena Yeung, Susan Murphy", "title": "Rapidly Personalizing Mobile Health Treatment Policies with Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile health (mHealth), reinforcement learning algorithms that adapt to\none's context without learning personalized policies might fail to distinguish\nbetween the needs of individuals. Yet the high amount of noise due to the in\nsitu delivery of mHealth interventions can cripple the ability of an algorithm\nto learn when given access to only a single user's data, making personalization\nchallenging. We present IntelligentPooling, which learns personalized policies\nvia an adaptive, principled use of other users' data. We show that\nIntelligentPooling achieves an average of 26% lower regret than\nstate-of-the-art across all generative models. Additionally, we inspect the\nbehavior of this approach in a live clinical trial, demonstrating its ability\nto learn from even a small group of users.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:59:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tomkins", "Sabina", ""], ["Liao", "Peng", ""], ["Klasnja", "Predrag", ""], ["Yeung", "Serena", ""], ["Murphy", "Susan", ""]]}, {"id": "2002.09996", "submitter": "Janis Klaise", "authors": "Michael Pearce, Janis Klaise, Matthew Groves", "title": "Practical Bayesian Optimization of Objectives with Conditioning\n  Variables", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a class of data efficient model based algorithms\ntypically focused on global optimization. We consider the more general case\nwhere a user is faced with multiple problems that each need to be optimized\nconditional on a state variable, for example given a range of cities with\ndifferent patient distributions, we optimize the ambulance locations\nconditioned on patient distribution. Given partitions of CIFAR-10, we optimize\nCNN hyperparameters for each partition. Similarity across objectives boosts\noptimization of each objective in two ways: in modelling by data sharing across\nobjectives, and also in acquisition by quantifying how a single point on one\nobjective can provide benefit to all objectives. For this we propose a\nframework for conditional optimization: ConBO. This can be built on top of a\nrange of acquisition functions and we propose a new Hybrid Knowledge Gradient\nacquisition function. The resulting method is intuitive and theoretically\ngrounded, performs either similar to or significantly better than recently\npublished works on a range of problems, and is easily parallelized to collect a\nbatch of points.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:06:26 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 21:21:40 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Pearce", "Michael", ""], ["Klaise", "Janis", ""], ["Groves", "Matthew", ""]]}, {"id": "2002.09998", "submitter": "Ayman Boustati", "authors": "Ayman Boustati, \\\"Omer Deniz Akyildiz, Theodoros Damoulas, Adam M.\n  Johansen", "title": "Generalized Bayesian Filtering via Sequential Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for inference in general state-space hidden Markov\nmodels (HMMs) under likelihood misspecification. In particular, we leverage the\nloss-theoretic perspective of Generalized Bayesian Inference (GBI) to define\ngeneralised filtering recursions in HMMs, that can tackle the problem of\ninference under model misspecification. In doing so, we arrive at principled\nprocedures for robust inference against observation contamination by utilising\nthe $\\beta$-divergence. Operationalising the proposed framework is made\npossible via sequential Monte Carlo methods (SMC), where most standard particle\nmethods, and their associated convergence results, are readily adapted to the\nnew setting. We apply our approach to object tracking and Gaussian process\nregression problems, and observe improved performance over both standard\nfiltering algorithms and other robust filters.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:15:52 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:05:58 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Boustati", "Ayman", ""], ["Akyildiz", "\u00d6mer Deniz", ""], ["Damoulas", "Theodoros", ""], ["Johansen", "Adam M.", ""]]}, {"id": "2002.10002", "submitter": "Eric Mazumdar", "authors": "Eric Mazumdar, Aldo Pacchiano, Yi-an Ma, Peter L. Bartlett, Michael I.\n  Jordan", "title": "On Thompson Sampling with Langevin Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling for multi-armed bandit problems is known to enjoy favorable\nperformance in both theory and practice. However, it suffers from a significant\nlimitation computationally, arising from the need for samples from posterior\ndistributions at every iteration. We propose two Markov Chain Monte Carlo\n(MCMC) methods tailored to Thompson sampling to address this issue. We\nconstruct quickly converging Langevin algorithms to generate approximate\nsamples that have accuracy guarantees, and we leverage novel posterior\nconcentration rates to analyze the regret of the resulting approximate Thompson\nsampling algorithm. Further, we specify the necessary hyperparameters for the\nMCMC procedure to guarantee optimal instance-dependent frequentist regret while\nhaving low computational complexity. In particular, our algorithms take\nadvantage of both posterior concentration and a sample reuse mechanism to\nensure that only a constant number of iterations and a constant amount of data\nis needed in each round. The resulting approximate Thompson sampling algorithm\nhas logarithmic regret and its computational complexity does not scale with the\ntime horizon of the algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:35:29 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 02:02:30 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mazumdar", "Eric", ""], ["Pacchiano", "Aldo", ""], ["Ma", "Yi-an", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.10003", "submitter": "Maximilian Seitzer", "authors": "Maximilian Seitzer", "title": "NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through\n  Aggregated Convolutional Feature Maps", "comments": "Disentanglement Challenge - 33rd Conference on Neural Information\n  Processing Systems (NeurIPS) - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report to our stage 1 submission to the NeurIPS 2019 disentanglement\nchallenge presents a simple image preprocessing method for training VAEs\nleading to improved disentanglement compared to directly using the images. In\nparticular, we propose to use regionally aggregated feature maps extracted from\nCNNs pretrained on ImageNet. Our method achieved the 2nd place in stage 1 of\nthe challenge. Code is available at\nhttps://github.com/mseitzer/neurips2019-disentanglement-challenge.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:35:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Seitzer", "Maximilian", ""]]}, {"id": "2002.10006", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Lior Wolf", "title": "On the Modularity of Hypernetworks", "comments": "Accepted to Advances in Neural Information Processing Systems\n  (NeurIPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of learning to map an input $I$ to a function\n$h_I:\\mathcal{X}\\to \\mathbb{R}$, two alternative methods are compared: (i) an\nembedding-based method, which learns a fixed function in which $I$ is encoded\nas a conditioning signal $e(I)$ and the learned function takes the form $h_I(x)\n= q(x,e(I))$, and (ii) hypernetworks, in which the weights $\\theta_I$ of the\nfunction $h_I(x) = g(x;\\theta_I)$ are given by a hypernetwork $f$ as\n$\\theta_I=f(I)$. In this paper, we define the property of modularity as the\nability to effectively learn a different function for each input instance $I$.\nFor this purpose, we adopt an expressivity perspective of this property and\nextend the theory of Devore et al. 1996 and provide a lower bound on the\ncomplexity (number of trainable parameters) of neural networks as function\napproximators, by eliminating the requirements for the approximation method to\nbe robust. Our results are then used to compare the complexities of $q$ and\n$g$, showing that under certain conditions and when letting the functions $e$\nand $f$ be as large as we wish, $g$ can be smaller than $q$ by orders of\nmagnitude. This sheds light on the modularity of hypernetworks in comparison\nwith the embedding-based method. Besides, we show that for a structured target\nfunction, the overall number of trainable parameters in a hypernetwork is\nsmaller by orders of magnitude than the number of trainable parameters of a\nstandard neural network and an embedding method.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:51:52 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 12:22:00 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Galanti", "Tomer", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.10007", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Ofir Nabati, Lior Wolf", "title": "A Critical View of the Structural Causal Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the univariate case, we show that by comparing the individual complexities\nof univariate cause and effect, one can identify the cause and the effect,\nwithout considering their interaction at all. In our framework, complexities\nare captured by the reconstruction error of an autoencoder that operates on the\nquantiles of the distribution. Comparing the reconstruction errors of the two\nautoencoders, one for each variable, is shown to perform surprisingly well on\nthe accepted causality directionality benchmarks. Hence, the decision as to\nwhich of the two is the cause and which is the effect may not be based on\ncausality but on complexity.\n  In the multivariate case, where one can ensure that the complexities of the\ncause and effect are balanced, we propose a new adversarial training method\nthat mimics the disentangled structure of the causal model. We prove that in\nthe multidimensional case, such modeling is likely to fit the data only in the\ndirection of causality. Furthermore, a uniqueness result shows that the learned\nmodel is able to identify the underlying causal and residual (noise)\ncomponents. Our multidimensional method outperforms the literature methods on\nboth synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:52:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Galanti", "Tomer", ""], ["Nabati", "Ofir", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.10021", "submitter": "Jacob Tyo", "authors": "Jacob Tyo and Zachary Lipton", "title": "How Transferable are the Representations Learned by Deep Q Agents?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we consider the source of Deep Reinforcement Learning (DRL)'s\nsample complexity, asking how much derives from the requirement of learning\nuseful representations of environment states and how much is due to the sample\ncomplexity of learning a policy. While for DRL agents, the distinction between\nrepresentation and policy may not be clear, we seek new insight through a set\nof transfer learning experiments. In each experiment, we retain some fraction\nof layers trained on either the same game or a related game, comparing the\nbenefits of transfer learning to learning a policy from scratch. Interestingly,\nwe find that benefits due to transfer are highly variable in general and\nnon-symmetric across pairs of tasks. Our experiments suggest that perhaps\ntransfer from simpler environments can boost performance on more complex\ndownstream tasks and that the requirements of learning a useful representation\ncan range from negligible to the majority of the sample complexity, based on\nthe environment. Furthermore, we find that fine-tuning generally outperforms\ntraining with the transferred layers frozen, confirming an insight first noted\nin the classification setting.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 00:23:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tyo", "Jacob", ""], ["Lipton", "Zachary", ""]]}, {"id": "2002.10022", "submitter": "Amir Mosavi Prof", "authors": "Shahab Shamshirband, Amir Mosavi, Narjes Nabipour, Kwok-wing Chau", "title": "Application of ERA5 and MENA simulations to predict offshore wind energy\n  potential", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study explores wind energy resources in different locations through the\nGulf of Oman and also their future variability due climate change impacts. In\nthis regard, EC-EARTH near surface wind outputs obtained from CORDEX-MENA\nsimulations are used for historical and future projection of the energy. The\nERA5 wind data are employed to assess suitability of the climate model.\nMoreover, the ERA5 wave data over the study area are applied to compute sea\nsurface roughness as an important variable for converting near surface wind\nspeeds to those of wind speed at turbine hub-height. Considering the power\ndistribution, bathymetry and distance from the coats, some spots as tentative\nenergy hotspots to provide detailed assessment of directional and temporal\nvariability and also to investigate climate change impact studies. RCP8.5 as a\ncommon climatic scenario is used to project and extract future variation of the\nenergy in the selected sites. The results of this study demonstrate that the\nselected locations have a suitable potential for wind power turbine plan and\nconstructions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 00:25:29 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shamshirband", "Shahab", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Chau", "Kwok-wing", ""]]}, {"id": "2002.10043", "submitter": "Yifei Shen", "authors": "Yifei Shen, Ye Xue, Jun Zhang, Khaled B. Letaief, and Vincent Lau", "title": "Complete Dictionary Learning via $\\ell_p$-norm Maximization", "comments": "accepted by UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning is a classic representation learning method that has been\nwidely applied in signal processing and data analytics. In this paper, we\ninvestigate a family of $\\ell_p$-norm ($p>2,p \\in \\mathbb{N}$) maximization\napproaches for the complete dictionary learning problem from theoretical and\nalgorithmic aspects. Specifically, we prove that the global maximizers of these\nformulations are very close to the true dictionary with high probability, even\nwhen Gaussian noise is present. Based on the generalized power method (GPM), an\nefficient algorithm is then developed for the $\\ell_p$-based formulations. We\nfurther show the efficacy of the developed algorithm: for the population GPM\nalgorithm over the sphere constraint, it first quickly enters the neighborhood\nof a global maximizer, and then converges linearly in this region. Extensive\nexperiments will demonstrate that the $\\ell_p$-based approaches enjoy a higher\ncomputational efficiency and better robustness than conventional approaches and\n$p=3$ performs the best.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 02:33:01 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 13:07:36 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 11:58:45 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Shen", "Yifei", ""], ["Xue", "Ye", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""], ["Lau", "Vincent", ""]]}, {"id": "2002.10046", "submitter": "Anderson Winkler", "authors": "Anderson M. Winkler, Olivier Renaud, Stephen M. Smith, Thomas E.\n  Nichols", "title": "Permutation Inference for Canonical Correlation Analysis", "comments": "49 pages, 2 figures, 10 tables, 3 algorithms, 119 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) has become a key tool for population\nneuroimaging, allowing investigation of associations between many imaging and\nnon-imaging measurements. As other variables are often a source of variability\nnot of direct interest, previous work has used CCA on residuals from a model\nthat removes these effects, then proceeded directly to permutation inference.\nWe show that such a simple permutation test leads to inflated error rates. The\nreason is that residualisation introduces dependencies among the observations\nthat violate the exchangeability assumption. Even in the absence of nuisance\nvariables, however, a simple permutation test for CCA also leads to excess\nerror rates for all canonical correlations other than the first. The reason is\nthat a simple permutation scheme does not ignore the variability already\nexplained by previous canonical variables. Here we propose solutions for both\nproblems: in the case of nuisance variables, we show that transforming the\nresiduals to a lower dimensional basis where exchangeability holds results in a\nvalid permutation test; for more general cases, with or without nuisance\nvariables, we propose estimating the canonical correlations in a stepwise\nmanner, removing at each iteration the variance already explained, while\ndealing with different number of variables in both sides. We also discuss how\nto address the multiplicity of tests, proposing an admissible test that is not\nconservative, and provide a complete algorithm for permutation inference for\nCCA.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 02:47:01 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 22:45:59 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 18:23:36 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 01:15:58 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Winkler", "Anderson M.", ""], ["Renaud", "Olivier", ""], ["Smith", "Stephen M.", ""], ["Nichols", "Thomas E.", ""]]}, {"id": "2002.10060", "submitter": "Wu Lin", "authors": "Wu Lin, Mark Schmidt, Mohammad Emtiyaz Khan", "title": "Handling the Positive-Definite Constraint in the Bayesian Learning Rule", "comments": "Fixed typos and updated the abstract (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian learning rule is a natural-gradient variational inference\nmethod, which not only contains many existing learning algorithms as special\ncases but also enables the design of new algorithms. Unfortunately, when\nvariational parameters lie in an open constraint set, the rule may not satisfy\nthe constraint and requires line-searches which could slow down the algorithm.\nIn this work, we address this issue for positive-definite constraints by\nproposing an improved rule that naturally handles the constraints. Our\nmodification is obtained by using Riemannian gradient methods, and is valid\nwhen the approximation attains a \\emph{block-coordinate natural\nparameterization} (e.g., Gaussian distributions and their mixtures). We propose\na principled way to derive Riemannian gradients and retractions from scratch.\nOur method outperforms existing methods without any significant increase in\ncomputation. Our work makes it easier to apply the rule in the presence of\npositive-definite constraints in parameter spaces.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:29:39 GMT"}, {"version": "v10", "created": "Thu, 23 Jul 2020 16:19:52 GMT"}, {"version": "v11", "created": "Mon, 17 Aug 2020 15:52:27 GMT"}, {"version": "v12", "created": "Fri, 4 Sep 2020 05:37:10 GMT"}, {"version": "v13", "created": "Sun, 25 Oct 2020 04:28:55 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:13:54 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 10:19:13 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 19:44:16 GMT"}, {"version": "v5", "created": "Mon, 11 May 2020 15:43:05 GMT"}, {"version": "v6", "created": "Mon, 8 Jun 2020 04:35:11 GMT"}, {"version": "v7", "created": "Tue, 30 Jun 2020 06:59:14 GMT"}, {"version": "v8", "created": "Thu, 2 Jul 2020 11:16:36 GMT"}, {"version": "v9", "created": "Tue, 21 Jul 2020 16:01:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lin", "Wu", ""], ["Schmidt", "Mark", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2002.10061", "submitter": "Wensi Tang", "authors": "Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Jing Jiang, Michael\n  Blumenstein", "title": "Rethinking 1D-CNN for Time Series Classification: A Stronger Baseline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For time series classification task using 1D-CNN, the selection of kernel\nsize is critically important to ensure the model can capture the right scale\nsalient signal from a long time-series. Most of the existing work on 1D-CNN\ntreats the kernel size as a hyper-parameter and tries to find the proper kernel\nsize through a grid search which is time-consuming and is inefficient. This\npaper theoretically analyses how kernel size impacts the performance of 1D-CNN.\nConsidering the importance of kernel size, we propose a novel Omni-Scale 1D-CNN\n(OS-CNN) architecture to capture the proper kernel size during the model\nlearning period. A specific design for kernel size configuration is developed\nwhich enables us to assemble very few kernel-size options to represent more\nreceptive fields. The proposed OS-CNN method is evaluated using the UCR archive\nwith 85 datasets. The experiment results demonstrate that our method is a\nstronger baseline in multiple performance indicators, including the critical\ndifference diagram, counts of wins, and average accuracy. We also published the\nexperimental source codes at GitHub (https://github.com/Wensi-Tang/OS-CNN/).\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:33:58 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 00:28:30 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Tang", "Wensi", ""], ["Long", "Guodong", ""], ["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Jiang", "Jing", ""], ["Blumenstein", "Michael", ""]]}, {"id": "2002.10064", "submitter": "Abhronil Sengupta", "authors": "Sen Lu, Abhronil Sengupta", "title": "Exploring the Connection Between Binary and Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2020.00535", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-chip edge intelligence has necessitated the exploration of algorithmic\ntechniques to reduce the compute requirements of current machine learning\nframeworks. This work aims to bridge the recent algorithmic progress in\ntraining Binary Neural Networks and Spiking Neural Networks - both of which are\ndriven by the same motivation and yet synergies between the two have not been\nfully explored. We show that training Spiking Neural Networks in the extreme\nquantization regime results in near full precision accuracies on large-scale\ndatasets like CIFAR-$100$ and ImageNet. An important implication of this work\nis that Binary Spiking Neural Networks can be enabled by \"In-Memory\" hardware\naccelerators catered for Binary Neural Networks without suffering any accuracy\ndegradation due to binarization. We utilize standard training techniques for\nnon-spiking networks to generate our spiking networks by conversion process and\nalso perform an extensive empirical analysis and explore simple design-time and\nrun-time optimization techniques for reducing inference latency of spiking\nnetworks (both for binary and full-precision models) by an order of magnitude\nover prior work.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:46:51 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 19:49:59 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 21:53:42 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lu", "Sen", ""], ["Sengupta", "Abhronil", ""]]}, {"id": "2002.10066", "submitter": "Yonadav Shavit", "authors": "Yonadav Shavit, Benjamin Edelman, Brian Axelrod", "title": "Causal Strategic Linear Regression", "comments": "18 pages; to appear in the proceedings of ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many predictive decision-making scenarios, such as credit scoring and\nacademic testing, a decision-maker must construct a model that accounts for\nagents' propensity to \"game\" the decision rule by changing their features so as\nto receive better decisions. Whereas the strategic classification literature\nhas previously assumed that agents' outcomes are not causally affected by their\nfeatures (and thus that strategic agents' goal is deceiving the\ndecision-maker), we join concurrent work in modeling agents' outcomes as a\nfunction of their changeable attributes. As our main contribution, we provide\nefficient algorithms for learning decision rules that optimize three distinct\ndecision-maker objectives in a realizable linear setting: accurately predicting\nagents' post-gaming outcomes (prediction risk minimization), incentivizing\nagents to improve these outcomes (agent outcome maximization), and estimating\nthe coefficients of the true underlying model (parameter estimation). Our\nalgorithms circumvent a hardness result of Miller et al. (2020) by allowing the\ndecision maker to test a sequence of decision rules and observe agents'\nresponses, in effect performing causal interventions through the decision\nrules.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:57:22 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 22:24:19 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Shavit", "Yonadav", ""], ["Edelman", "Benjamin", ""], ["Axelrod", "Brian", ""]]}, {"id": "2002.10069", "submitter": "Benjamin Gravell", "authors": "Benjamin Gravell and Tyler Summers", "title": "Robust Learning-Based Control via Bootstrapped Multiplicative Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite decades of research and recent progress in adaptive control and\nreinforcement learning, there remains a fundamental lack of understanding in\ndesigning controllers that provide robustness to inherent non-asymptotic\nuncertainties arising from models estimated with finite, noisy data. We propose\na robust adaptive control algorithm that explicitly incorporates such\nnon-asymptotic uncertainties into the control design. The algorithm has three\ncomponents: (1) a least-squares nominal model estimator; (2) a bootstrap\nresampling method that quantifies non-asymptotic variance of the nominal model\nestimate; and (3) a non-conventional robust control design method using an\noptimal linear quadratic regulator (LQR) with multiplicative noise. A key\nadvantage of the proposed approach is that the system identification and robust\ncontrol design procedures both use stochastic uncertainty representations, so\nthat the actual inherent statistical estimation uncertainty directly aligns\nwith the uncertainty the robust controller is being designed against. We show\nthrough numerical experiments that the proposed robust adaptive controller can\nsignificantly outperform the certainty equivalent controller on both expected\nregret and measures of regret risk.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 04:12:52 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 19:26:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gravell", "Benjamin", ""], ["Summers", "Tyler", ""]]}, {"id": "2002.10077", "submitter": "Zachary Izzo", "authors": "Zachary Izzo, Mary Anne Smart, Kamalika Chaudhuri, James Zou", "title": "Approximate Data Deletion from Machine Learning Models", "comments": "20 pages, 1 figure, accepted for publication at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deleting data from a trained machine learning (ML) model is a critical task\nin many applications. For example, we may want to remove the influence of\ntraining points that might be out of date or outliers. Regulations such as EU's\nGeneral Data Protection Regulation also stipulate that individuals can request\nto have their data deleted. The naive approach to data deletion is to retrain\nthe ML model on the remaining data, but this is too time consuming. In this\nwork, we propose a new approximate deletion method for linear and logistic\nmodels whose computational cost is linear in the the feature dimension $d$ and\nindependent of the number of training data $n$. This is a significant gain over\nall existing methods, which all have superlinear time dependence on the\ndimension. We also develop a new feature-injection test to evaluate the\nthoroughness of data deletion from ML models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:12:03 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 18:56:03 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Izzo", "Zachary", ""], ["Smart", "Mary Anne", ""], ["Chaudhuri", "Kamalika", ""], ["Zou", "James", ""]]}, {"id": "2002.10078", "submitter": "Chuan Guo", "authors": "Chuan Guo, Ruihan Wu, Kilian Q. Weinberger", "title": "On Hiding Neural Networks Inside Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern neural networks often contain significantly more parameters than the\nsize of their training data. We show that this excess capacity provides an\nopportunity for embedding secret machine learning models within a trained\nneural network. Our novel framework hides the existence of a secret neural\nnetwork with arbitrary desired functionality within a carrier network. We prove\ntheoretically that the secret network's detection is computationally infeasible\nand demonstrate empirically that the carrier network does not compromise the\nsecret network's disguise. Our paper introduces a previously unknown\nsteganographic technique that can be exploited by adversaries if left\nunchecked.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:18:29 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 17:27:10 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 00:27:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Guo", "Chuan", ""], ["Wu", "Ruihan", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.10097", "submitter": "Leo Schwinn", "authors": "Leo Schwinn, Ren\\'e Raab, Bj\\\"orn Eskofier", "title": "Towards Rapid and Robust Adversarial Training with One-Step Attacks", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is the most successful empirical method for increasing\nthe robustness of neural networks against adversarial attacks. However, the\nmost effective approaches, like training with Projected Gradient Descent (PGD)\nare accompanied by high computational complexity. In this paper, we present two\nideas that, in combination, enable adversarial training with the\ncomputationally less expensive Fast Gradient Sign Method (FGSM). First, we add\nuniform noise to the initial data point of the FGSM attack, which creates a\nwider variety of adversaries, thus prohibiting overfitting to one particular\nperturbation bound. Further, we add a learnable regularization step prior to\nthe neural network, which we call Pixelwise Noise Injection Layer (PNIL).\nInputs propagated trough the PNIL are resampled from a learned Gaussian\ndistribution. The regularization induced by the PNIL prevents the model form\nlearning to obfuscate its gradients, a factor that hindered prior approaches\nfrom successfully applying one-step methods for adversarial training. We show\nthat noise injection in conjunction with FGSM-based adversarial training\nachieves comparable results to adversarial training with PGD while being\nconsiderably faster. Moreover, we outperform PGD-based adversarial training by\ncombining noise injection and PNIL.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:28:43 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:32:31 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 06:41:20 GMT"}, {"version": "v4", "created": "Tue, 17 Mar 2020 07:52:57 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Schwinn", "Leo", ""], ["Raab", "Ren\u00e9", ""], ["Eskofier", "Bj\u00f6rn", ""]]}, {"id": "2002.10099", "submitter": "Amos Gropp", "authors": "Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman", "title": "Implicit Geometric Regularization for Learning Shapes", "comments": "37th International Conference on Machine Learning, Vienna, Austria,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing shapes as level sets of neural networks has been recently proved\nto be useful for different shape analysis and reconstruction tasks. So far,\nsuch representations were computed using either: (i) pre-computed implicit\nshape representations; or (ii) loss functions explicitly defined over the\nneural level sets. In this paper we offer a new paradigm for computing high\nfidelity implicit neural representations directly from raw data (i.e., point\nclouds, with or without normal information). We observe that a rather simple\nloss function, encouraging the neural network to vanish on the input point\ncloud and to have a unit norm gradient, possesses an implicit geometric\nregularization property that favors smooth and natural zero level set surfaces,\navoiding bad zero-loss solutions. We provide a theoretical analysis of this\nproperty for the linear case, and show that, in practice, our method leads to\nstate of the art implicit neural representations with higher level-of-details\nand fidelity compared to previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:36:32 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:32:45 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Gropp", "Amos", ""], ["Yariv", "Lior", ""], ["Haim", "Niv", ""], ["Atzmon", "Matan", ""], ["Lipman", "Yaron", ""]]}, {"id": "2002.10113", "submitter": "Alex Tong Lin", "authors": "Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, Stanley J.\n  Osher", "title": "Alternating the Population and Control Neural Networks to Solve\n  High-Dimensional Stochastic Mean-Field Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present APAC-Net, an alternating population and agent control neural\nnetwork for solving stochastic mean field games (MFGs). Our algorithm is geared\ntoward high-dimensional instances of MFGs that are beyond reach with existing\nsolution methods. We achieve this in two steps. First, we take advantage of the\nunderlying variational primal-dual structure that MFGs exhibit and phrase it as\na convex-concave saddle point problem. Second, we parameterize the value and\ndensity functions by two neural networks, respectively. By phrasing the problem\nin this manner, solving the MFG can be interpreted as a special case of\ntraining a generative adversarial network (GAN). We show the potential of our\nmethod on up to 100-dimensional MFG problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:24:52 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:23:39 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 23:36:31 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Lin", "Alex Tong", ""], ["Fung", "Samy Wu", ""], ["Li", "Wuchen", ""], ["Nurbekyan", "Levon", ""], ["Osher", "Stanley J.", ""]]}, {"id": "2002.10118", "submitter": "Agustinus Kristiadi", "authors": "Agustinus Kristiadi, Matthias Hein, Philipp Hennig", "title": "Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The point estimates of ReLU classification networks---arguably the most\nwidely used neural network architecture---have been shown to yield arbitrarily\nhigh confidence far away from the training data. This architecture, in\nconjunction with a maximum a posteriori estimation scheme, is thus not\ncalibrated nor robust. Approximate Bayesian inference has been empirically\ndemonstrated to improve predictive uncertainty in neural networks, although the\ntheoretical analysis of such Bayesian approximations is limited. We\ntheoretically analyze approximate Gaussian distributions on the weights of ReLU\nnetworks and show that they fix the overconfidence problem. Furthermore, we\nshow that even a simplistic, thus cheap, Bayesian approximation, also fixes\nthese issues. This indicates that a sufficient condition for a calibrated\nuncertainty on a ReLU network is \"to be a bit Bayesian\". These theoretical\nresults validate the usage of last-layer Bayesian approximation and motivate a\nrange of a fidelity-cost trade-off. We further validate these findings\nempirically via various standard experiments using common deep ReLU networks\nand Laplace approximations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:52:06 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 15:04:19 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["Hein", "Matthias", ""], ["Hennig", "Philipp", ""]]}, {"id": "2002.10121", "submitter": "Khashayar Khosravi", "authors": "Mohsen Bayati, Nima Hamidi, Ramesh Johari, Khashayar Khosravi", "title": "The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed\n  Bandit with Many Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the structure of regret-minimizing policies in the many-armed\nBayesian multi-armed bandit problem: in particular, with k the number of arms\nand T the time horizon, we consider the case where k > \\sqrt{T}. We first show\nthat subsampling is a critical step for designing optimal policies. In\nparticular, the standard UCB algorithm leads to sub-optimal regret bounds in\nthis regime. However, a subsampled UCB (SS-UCB), which samples \\sqrt{T} arms\nand executes UCB only on that subset, is rate-optimal. Despite theoretically\noptimal regret, even SS-UCB performs poorly due to excessive exploration of\nsuboptimal arms. In fact, in numerical experiments SS-UCB performs worse than a\nsimple greedy algorithm (and its subsampled version) that pulls the current\nempirical best arm at every time period. We show that these insights hold even\nin a contextual setting, using real-world data. These empirical results suggest\na novel form of free exploration in the many-armed regime that benefits greedy\nalgorithms. We theoretically study this new source of free exploration and find\nthat it is deeply connected to the distribution of a certain tail event for the\nprior distribution of arm rewards. This is a fundamentally distinct phenomenon\nfrom free exploration as discussed in the recent literature on contextual\nbandits, where free exploration arises due to variation in contexts. We prove\nthat the subsampled greedy algorithm is rate-optimal for Bernoulli bandits when\nk > \\sqrt{T}, and achieves sublinear regret with more general distributions.\nThis is a case where theoretical rate optimality does not tell the whole story:\nwhen complemented by the empirical observations of our paper, the power of\ngreedy algorithms becomes quite evident. Taken together, from a practical\nstandpoint, our results suggest that in applications it may be preferable to\nuse a variant of the greedy algorithm in the many-armed regime.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:56:39 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bayati", "Mohsen", ""], ["Hamidi", "Nima", ""], ["Johari", "Ramesh", ""], ["Khosravi", "Khashayar", ""]]}, {"id": "2002.10127", "submitter": "Ahmad Mel", "authors": "Ahmad Mel, Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "FONDUE: A Framework for Node Disambiguation Using Network Embeddings", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data often presents itself in the form of a network. Examples\ninclude social networks, citation networks, biological networks, and knowledge\ngraphs. In their simplest form, networks represent real-life entities (e.g.\npeople, papers, proteins, concepts) as nodes, and describe them in terms of\ntheir relations with other entities by means of edges between these nodes. This\ncan be valuable for a range of purposes from the study of information diffusion\nto bibliographic analysis, bioinformatics research, and question-answering.\n  The quality of networks is often problematic though, affecting downstream\ntasks. This paper focuses on the common problem where a node in the network in\nfact corresponds to multiple real-life entities. In particular, we introduce\nFONDUE, an algorithm based on network embedding for node disambiguation. Given\na network, FONDUE identifies nodes that correspond to multiple entities, for\nsubsequent splitting. Extensive experiments on twelve benchmark datasets\ndemonstrate that FONDUE is substantially and uniformly more accurate for\nambiguous node identification compared to the existing state-of-the-art, at a\ncomparable computational cost, while less optimal for determining the best way\nto split ambiguous nodes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 09:34:18 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mel", "Ahmad", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.10148", "submitter": "Markus Sch\\\"oberl", "authors": "Markus Sch\\\"oberl, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis", "title": "Embedded-physics machine learning for coarse-graining and collective\n  variable discovery without data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel learning framework that consistently embeds underlying\nphysics while bypassing a significant drawback of most modern, data-driven\ncoarse-grained approaches in the context of molecular dynamics (MD), i.e., the\navailability of big data. The generation of a sufficiently large training\ndataset poses a computationally demanding task, while complete coverage of the\natomistic configuration space is not guaranteed. As a result, the explorative\ncapabilities of data-driven coarse-grained models are limited and may yield\nbiased \"predictive\" tools. We propose a novel objective based on reverse\nKullback-Leibler divergence that fully incorporates the available physics in\nthe form of the atomistic force field. Rather than separating model learning\nfrom the data-generation procedure - the latter relies on simulating atomistic\nmotions governed by force fields - we query the atomistic force field at sample\nconfigurations proposed by the predictive coarse-grained model. Thus, learning\nrelies on the evaluation of the force field but does not require any MD\nsimulation. The resulting generative coarse-grained model serves as an\nefficient surrogate model for predicting atomistic configurations and\nestimating relevant observables. Beyond obtaining a predictive coarse-grained\nmodel, we demonstrate that in the discovered lower-dimensional representation,\nthe collective variables (CVs) are related to physicochemical properties, which\nare essential for gaining understanding of unexplored complex systems. We\ndemonstrate the algorithmic advances in terms of predictive ability and the\nphysical meaning of the revealed CVs for a bimodal potential energy function\nand the alanine dipeptide.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:28:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sch\u00f6berl", "Markus", ""], ["Zabaras", "Nicholas", ""], ["Koutsourelakis", "Phaedon-Stelios", ""]]}, {"id": "2002.10199", "submitter": "Tuomo Alasalmi", "authors": "Tuomo Alasalmi, Jaakko Suutala, Heli Koskim\\\"aki, and Juha R\\\"oning", "title": "Better Classifier Calibration for Small Data Sets", "comments": null, "journal-ref": "ACM Transactions on Knowledge Discovery from Data, 14(3), Article\n  34 (May 2020)", "doi": "10.1145/3385656", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier calibration does not always go hand in hand with the classifier's\nability to separate the classes. There are applications where good classifier\ncalibration, i.e. the ability to produce accurate probability estimates, is\nmore important than class separation. When the amount of data for training is\nlimited, the traditional approach to improve calibration starts to crumble. In\nthis article we show how generating more data for calibration is able to\nimprove calibration algorithm performance in many cases where a classifier is\nnot naturally producing well-calibrated outputs and the traditional approach\nfails. The proposed approach adds computational cost but considering that the\nmain use case is with small data sets this extra computational cost stays\ninsignificant and is comparable to other methods in prediction time. From the\ntested classifiers the largest improvement was detected with the random forest\nand naive Bayes classifiers. Therefore, the proposed approach can be\nrecommended at least for those classifiers when the amount of data available\nfor training is limited and good calibration is essential.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:27:21 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 09:15:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Alasalmi", "Tuomo", ""], ["Suutala", "Jaakko", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "2002.10208", "submitter": "Abhishake Rastogi", "authors": "Abhishake Rastogi and Peter Math\\'e", "title": "Inverse learning in Hilbert scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the linear ill-posed inverse problem with noisy data in the\nstatistical learning setting. Approximate reconstructions from random noisy\ndata are sought with general regularization schemes in Hilbert scale. We\ndiscuss the rates of convergence for the regularized solution under the prior\nassumptions and a certain link condition. We express the error in terms of\ncertain distance functions. For regression functions with smoothness given in\nterms of source conditions the error bound can then be explicitly established.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:49:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Rastogi", "Abhishake", ""], ["Math\u00e9", "Peter", ""]]}, {"id": "2002.10211", "submitter": "Yaoyao Liu", "authors": "Yaoyao Liu, Yuting Su, An-An Liu, Bernt Schiele, Qianru Sun", "title": "Mnemonics Training: Multi-Class Incremental Learning without Forgetting", "comments": "Experiment results updated (different from the conference version).\n  Code is available at https://github.com/yaoyao-liu/mnemonics-training", "journal-ref": null, "doi": "10.1109/CVPR42600.2020.01226", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multi-Class Incremental Learning (MCIL) aims to learn new concepts by\nincrementally updating a model trained on previous concepts. However, there is\nan inherent trade-off to effectively learning new concepts without catastrophic\nforgetting of previous ones. To alleviate this issue, it has been proposed to\nkeep around a few examples of the previous concepts but the effectiveness of\nthis approach heavily depends on the representativeness of these examples. This\npaper proposes a novel and automatic framework we call mnemonics, where we\nparameterize exemplars and make them optimizable in an end-to-end manner. We\ntrain the framework through bilevel optimizations, i.e., model-level and\nexemplar-level. We conduct extensive experiments on three MCIL benchmarks,\nCIFAR-100, ImageNet-Subset and ImageNet, and show that using mnemonics\nexemplars can surpass the state-of-the-art by a large margin. Interestingly and\nquite intriguingly, the mnemonics exemplars tend to be on the boundaries\nbetween different classes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:55:25 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:35:05 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 01:46:46 GMT"}, {"version": "v4", "created": "Sun, 23 Aug 2020 12:49:51 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 19:44:51 GMT"}, {"version": "v6", "created": "Sun, 4 Apr 2021 12:24:40 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liu", "Yaoyao", ""], ["Su", "Yuting", ""], ["Liu", "An-An", ""], ["Schiele", "Bernt", ""], ["Sun", "Qianru", ""]]}, {"id": "2002.10214", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Federico Baldo, Michele Lombardi, Michela Milano", "title": "Injective Domain Knowledge in Neural Networks for Transprecision\n  Computing", "comments": null, "journal-ref": "Nicosia G. et al. (eds) Machine Learning, Optimization, and Data\n  Science. LOD 2020. Lecture Notes in Computer Science, vol 12565. Springer,\n  Cham", "doi": "10.1007/978-3-030-64583-0_52", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) models are very effective in many learning tasks, due\nto the capability to extract meaningful information from large data sets.\nNevertheless, there are learning problems that cannot be easily solved relying\non pure data, e.g. scarce data or very complex functions to be approximated.\nFortunately, in many contexts domain knowledge is explicitly available and can\nbe used to train better ML models. This paper studies the improvements that can\nbe obtained by integrating prior knowledge when dealing with a non-trivial\nlearning task, namely precision tuning of transprecision computing\napplications. The domain information is injected in the ML models in different\nways: I) additional features, II) ad-hoc graph-based network topology, III)\nregularization schemes. The results clearly show that ML models exploiting\nproblem-specific information outperform the purely data-driven ones, with an\naverage accuracy improvement around 38%.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:58:56 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Borghesi", "Andrea", ""], ["Baldo", "Federico", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10234", "submitter": "Yuji Roh", "authors": "Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh", "title": "FR-Train: A Mutual Information-Based Approach to Fair and Robust\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trustworthy AI is a critical issue in machine learning where, in addition to\ntraining a model that is accurate, one must consider both fair and robust\ntraining in the presence of data bias and poisoning. However, the existing\nmodel fairness techniques mistakenly view poisoned data as an additional bias\nto be fixed, resulting in severe performance degradation. To address this\nproblem, we propose FR-Train, which holistically performs fair and robust model\ntraining. We provide a mutual information-based interpretation of an existing\nadversarial training-based fairness-only method, and apply this idea to\narchitect an additional discriminator that can identify poisoned data using a\nclean validation set and reduce its influence. In our experiments, FR-Train\nshows almost no decrease in fairness and accuracy in the presence of data\npoisoning by both mitigating the bias and defending against poisoning. We also\ndemonstrate how to construct clean validation sets using crowdsourcing, and\nrelease new benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:37:29 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 07:46:37 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Roh", "Yuji", ""], ["Lee", "Kangwook", ""], ["Whang", "Steven Euijong", ""], ["Suh", "Changho", ""]]}, {"id": "2002.10235", "submitter": "Xuhui Fan", "authors": "Yaqiong Li, Xuhui Fan, Ling Chen, Bin Li, Zheng Yu, Scott A. Sisson", "title": "Recurrent Dirichlet Belief Networks for Interpretable Dynamic Relational\n  Data Modelling", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dirichlet Belief Network~(DirBN) has been recently proposed as a\npromising approach in learning interpretable deep latent representations for\nobjects. In this work, we leverage its interpretable modelling architecture and\npropose a deep dynamic probabilistic framework -- the Recurrent Dirichlet\nBelief Network~(Recurrent-DBN) -- to study interpretable hidden structures from\ndynamic relational data. The proposed Recurrent-DBN has the following merits:\n(1) it infers interpretable and organised hierarchical latent structures for\nobjects within and across time steps; (2) it enables recurrent long-term\ntemporal dependence modelling, which outperforms the one-order Markov\ndescriptions in most of the dynamic probabilistic frameworks. In addition, we\ndevelop a new inference strategy, which first upward-and-backward propagates\nlatent counts and then downward-and-forward samples variables, to enable\nefficient Gibbs sampling for the Recurrent-DBN. We apply the Recurrent-DBN to\ndynamic relational data problems. The extensive experiment results on\nreal-world data validate the advantages of the Recurrent-DBN over the\nstate-of-the-art models in interpretable latent structure discovery and\nimproved link prediction performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:40:24 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 10:54:50 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Li", "Yaqiong", ""], ["Fan", "Xuhui", ""], ["Chen", "Ling", ""], ["Li", "Bin", ""], ["Yu", "Zheng", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2002.10241", "submitter": "Sujoy Chatterjee", "authors": "Sujoy Chatterjee, Nicolas Pasquier, Simon Nanty, Maria A. Zuluaga", "title": "Multi-objective Consensus Clustering Framework for Flight Search\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the travel industry, online customers book their travel itinerary\naccording to several features, like cost and duration of the travel or the\nquality of amenities. To provide personalized recommendations for travel\nsearches, an appropriate segmentation of customers is required. Clustering\nensemble approaches were developed to overcome well-known problems of classical\nclustering approaches, that each rely on a different theoretical model and can\nthus identify in the data space only clusters corresponding to this model.\nClustering ensemble approaches combine multiple clustering results, each from a\ndifferent algorithmic configuration, for generating more robust consensus\nclusters corresponding to agreements between initial clusters. We present a new\nclustering ensemble multi-objective optimization-based framework developed for\nanalyzing Amadeus customer search data and improve personalized\nrecommendations. This framework optimizes diversity in the clustering ensemble\nsearch space and automatically determines an appropriate number of clusters\nwithout requiring user's input. Experimental results compare the efficiency of\nthis approach with other existing approaches on Amadeus customer search data in\nterms of internal (Adjusted Rand Index) and external (Amadeus business metric)\nvalidations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 03:56:02 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:41:59 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Chatterjee", "Sujoy", ""], ["Pasquier", "Nicolas", ""], ["Nanty", "Simon", ""], ["Zuluaga", "Maria A.", ""]]}, {"id": "2002.10243", "submitter": "Tianyu Cui", "authors": "Tianyu Cui, Aki Havulinna, Pekka Marttinen, Samuel Kaski", "title": "Informative Bayesian Neural Network Priors for Weak Signals", "comments": "25 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding domain knowledge into the prior over the high-dimensional weight\nspace of a neural network is challenging but essential in applications with\nlimited data and weak signals. Two types of domain knowledge are commonly\navailable in scientific applications: 1. feature sparsity (fraction of features\ndeemed relevant); 2. signal-to-noise ratio, quantified, for instance, as the\nproportion of variance explained (PVE). We show how to encode both types of\ndomain knowledge into the widely used Gaussian scale mixture priors with\nAutomatic Relevance Determination. Specifically, we propose a new joint prior\nover the local (i.e., feature-specific) scale parameters that encodes knowledge\nabout feature sparsity, and a Stein gradient optimization to tune the\nhyperparameters in such a way that the distribution induced on the model's PVE\nmatches the prior distribution. We show empirically that the new prior improves\nprediction accuracy, compared to existing neural network priors, on several\npublicly available datasets and in a genetics application where signals are\nweak and sparse, often outperforming even computationally intensive\ncross-validation for hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:43:44 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 14:55:29 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Cui", "Tianyu", ""], ["Havulinna", "Aki", ""], ["Marttinen", "Pekka", ""], ["Kaski", "Samuel", ""]]}, {"id": "2002.10247", "submitter": "Manav Kaushik", "authors": "Manav Kaushik and A K Giri", "title": "Forecasting Foreign Exchange Rate: A Multivariate Comparative Analysis\n  between Traditional Econometric, Contemporary Machine Learning & Deep\n  Learning Techniques", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays global economy, accuracy in predicting macro-economic parameters\nsuch as the foreign the exchange rate or at least estimating the trend\ncorrectly is of key importance for any future investment. In recent times, the\nuse of computational intelligence-based techniques for forecasting\nmacroeconomic variables has been proven highly successful. This paper tries to\ncome up with a multivariate time series approach to forecast the exchange rate\n(USD/INR) while parallelly comparing the performance of three multivariate\nprediction modelling techniques: Vector Auto Regression (a Traditional\nEconometric Technique), Support Vector Machine (a Contemporary Machine Learning\nTechnique), and Recurrent Neural Networks (a Contemporary Deep Learning\nTechnique). We have used monthly historical data for several macroeconomic\nvariables from April 1994 to December 2018 for USA and India to predict USD-INR\nForeign Exchange Rate. The results clearly depict that contemporary techniques\nof SVM and RNN (Long Short-Term Memory) outperform the widely used traditional\nmethod of Auto Regression. The RNN model with Long Short-Term Memory (LSTM)\nprovides the maximum accuracy (97.83%) followed by SVM Model (97.17%) and VAR\nModel (96.31%). At last, we present a brief analysis of the correlation and\ninterdependencies of the variables used for forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:11:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kaushik", "Manav", ""], ["Giri", "A K", ""]]}, {"id": "2002.10248", "submitter": "Serena Booth", "authors": "Serena Booth, Yilun Zhou, Ankit Shah, Julie Shah", "title": "Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by\n  Example", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanation methods are gaining popularity for interpreting,\nunderstanding, and debugging neural networks. Most analyses using such methods\nexplain decisions in response to inputs drawn from the test set. However, the\ntest set may have few examples that trigger some model behaviors, such as\nhigh-confidence failures or ambiguous classifications. To address these\nchallenges, we introduce a flexible model inspection framework: Bayes-TrEx.\nGiven a data distribution, Bayes-TrEx finds in-distribution examples with a\nspecified prediction confidence. We demonstrate several use cases of\nBayes-TrEx, including revealing highly confident (mis)classifications,\nvisualizing class boundaries via ambiguous examples, understanding novel-class\nextrapolation behavior, and exposing neural network overconfidence. We use\nBayes-TrEx to study classifiers trained on CLEVR, MNIST, and Fashion-MNIST, and\nwe show that this framework enables more flexible holistic model analysis than\njust inspecting the test set. Code is available at\nhttps://github.com/serenabooth/Bayes-TrEx.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:49:00 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 14:11:24 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 16:24:24 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 16:44:55 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Booth", "Serena", ""], ["Zhou", "Yilun", ""], ["Shah", "Ankit", ""], ["Shah", "Julie", ""]]}, {"id": "2002.10252", "submitter": "Negin Entezari", "authors": "Negin Entezari, Evangelos E. Papalexakis", "title": "TensorShield: Tensor-based Defense Against Adversarial Attacks on Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that machine learning approaches like deep\nneural networks (DNNs) are easily fooled by adversarial attacks. Subtle and\nimperceptible perturbations of the data are able to change the result of deep\nneural networks. Leveraging vulnerable machine learning methods raises many\nconcerns especially in domains where security is an important factor.\nTherefore, it is crucial to design defense mechanisms against adversarial\nattacks. For the task of image classification, unnoticeable perturbations\nmostly occur in the high-frequency spectrum of the image. In this paper, we\nutilize tensor decomposition techniques as a preprocessing step to find a\nlow-rank approximation of images which can significantly discard high-frequency\nperturbations. Recently a defense framework called Shield could \"vaccinate\"\nConvolutional Neural Networks (CNN) against adversarial examples by performing\nrandom-quality JPEG compressions on local patches of images on the ImageNet\ndataset. Our tensor-based defense mechanism outperforms the SLQ method from\nShield by 14% against FastGradient Descent (FGSM) adversarial attacks, while\nmaintaining comparable speed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:39:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Entezari", "Negin", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2002.10254", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri, Sajid Hussain, Aditya Nongmeikapam", "title": "Empirical Study on Airline Delay Analysis and Prediction", "comments": "Figure 13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Big Data analytics are a logical analysis of very large scale datasets.\nThe data analysis enhances an organization and improve the decision making\nprocess. In this article, we present Airline Delay Analysis and Prediction to\nanalyze airline datasets with the combination of weather dataset. In this\nresearch work, we consider various attributes to analyze flight delay, for\nexample, day-wise, airline-wise, cloud cover, temperature, etc. Moreover, we\npresent rigorous experiments on various machine learning model to predict\ncorrectly the delay of a flight, namely, logistic regression with L2\nregularization, Gaussian Naive Bayes, K-Nearest Neighbors, Decision Tree\nclassifier and Random forest model. The accuracy of the Random Forest model is\n82% with a delay threshold of 15 minutes of flight delay. The analysis is\ncarried out using dataset from 1987 to 2008, the training is conducted with\ndataset from 2000 to 2007 and validated prediction result using 2008 data.\nMoreover, we have got recall 99% in the Random Forest model.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:32:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Patgiri", "Ripon", ""], ["Hussain", "Sajid", ""], ["Nongmeikapam", "Aditya", ""]]}, {"id": "2002.10257", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh", "title": "Using Wavelets to Analyze Similarities in Image-Classification Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning image classifiers usually rely on huge training sets and their\ntraining process can be described as learning the similarities and differences\namong training images. But, images in large training sets are not usually\nstudied from this perspective and fine-level similarities and differences among\nimages is usually overlooked. This is due to lack of fast and efficient\ncomputational methods to analyze the contents of these datasets. Some studies\naim to identify the influential and redundant training images, but such methods\nrequire a model that is already trained on the entire training set. Here, using\nimage processing and numerical analysis tools we develop a practical and fast\nmethod to analyze the similarities in image classification datasets. We show\nthat such analysis can provide valuable insights about the datasets and the\nclassification task at hand, prior to training a model. Our method uses wavelet\ndecomposition of images and other numerical analysis tools, with no need for a\npre-trained model. Interestingly, the results we obtain corroborate the\nprevious results in the literature that analyzed the similarities using\npre-trained CNNs. We show that similar images in standard datasets (such as\nCIFAR) can be identified in a few seconds, a significant speed-up compared to\nalternative methods in the literature. By removing the computational speed\nobstacle, it becomes practical to gain new insights about the contents of\ndatasets and the models trained on them. We show that similarities between\ntraining and testing images may provide insights about the generalization of\nmodels. Finally, we investigate the similarities between images in relation to\ndecision boundaries of a trained model.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:46:28 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 01:42:54 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""]]}, {"id": "2002.10261", "submitter": "Zayd Hammoudeh", "authors": "Zayd Hammoudeh and Daniel Lowd", "title": "Learning from Positive and Unlabeled Data with Arbitrary Positive Shift", "comments": "Accepted at NeurIPS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive-unlabeled (PU) learning trains a binary classifier using only\npositive and unlabeled data. A common simplifying assumption is that the\npositive data is representative of the target positive class. This assumption\nrarely holds in practice due to temporal drift, domain shift, and/or\nadversarial manipulation. This paper shows that PU learning is possible even\nwith arbitrarily non-representative positive data given unlabeled data from the\nsource and target distributions. Our key insight is that only the negative\nclass's distribution need be fixed. We integrate this into two statistically\nconsistent methods to address arbitrary positive bias - one approach combines\nnegative-unlabeled learning with unlabeled-unlabeled learning while the other\nuses a novel, recursive risk estimator. Experimental results demonstrate our\nmethods' effectiveness across numerous real-world datasets and forms of\npositive bias, including disjoint positive class-conditional supports.\nAdditionally, we propose a general, simplified approach to address PU risk\nestimation overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:53:22 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 00:48:59 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 02:00:34 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 12:20:05 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hammoudeh", "Zayd", ""], ["Lowd", "Daniel", ""]]}, {"id": "2002.10266", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Stephanie Van Laere, Tim Verbelen, Bart Dhoedt", "title": "Rhythm, Chord and Melody Generation for Lead Sheets using Recurrent\n  Neural Networks", "comments": "8 pages, 2 figures, 3 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music that is generated by recurrent neural networks often lacks a sense of\ndirection and coherence. We therefore propose a two-stage LSTM-based model for\nlead sheet generation, in which the harmonic and rhythmic templates of the song\nare produced first, after which, in a second stage, a sequence of melody notes\nis generated conditioned on these templates. A subjective listening test shows\nthat our approach outperforms the baselines and increases perceived musical\ncoherence.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:36:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["De Boom", "Cedric", ""], ["Van Laere", "Stephanie", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2002.10268", "submitter": "Martin Lellep", "authors": "Martin Lellep, Jonathan Prexl, Moritz Linkmann, and Bruno Eckhardt", "title": "Using Machine Learning to predict extreme events in the H\\'enon map", "comments": "9 pages, 12 figures", "journal-ref": "Chaos: An Interdisciplinary Journal of Nonlinear Science 30.1\n  (2020): 013113", "doi": "10.1063/1.5121844", "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) inspired algorithms provide a flexible set of tools for\nanalyzing and forecasting chaotic dynamical systems. We here analyze the\nperformance of one algorithm for the prediction of extreme events in the\ntwo-dimensional H\\'enon map at the classical parameters. The task is to\ndetermine whether a trajectory will exceed a threshold after a set number of\ntime steps into the future. This task has a geometric interpretation within the\ndynamics of the H\\'enon map, which we use to gauge the performance of the\nneural networks that are used in this work. We analyze the dependence of the\nsuccess rate of the ML models on the prediction time $T$ , the number of\ntraining samples $N_T$ and the size of the network $N_p$. We observe that in\norder to maintain a certain accuracy, $N_T \\propto exp(2 h T)$ and $N_p \\propto\nexp(hT)$, where $h$ is the topological entropy. Similar relations between the\nintrinsic chaotic properties of the dynamics and ML parameters might be\nobservable in other systems as well.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:56:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lellep", "Martin", ""], ["Prexl", "Jonathan", ""], ["Linkmann", "Moritz", ""], ["Eckhardt", "Bruno", ""]]}, {"id": "2002.10271", "submitter": "Wittawat Jitkrittum", "authors": "Wittawat Jitkrittum, Heishiro Kanagawa, Bernhard Sch\\\"olkopf", "title": "Testing Goodness of Fit of Conditional Density Models with Kernels", "comments": "In UAI 2020. http://auai.org/uai2020/accepted.php", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two nonparametric statistical tests of goodness of fit for\nconditional distributions: given a conditional probability density function\n$p(y|x)$ and a joint sample, decide whether the sample is drawn from\n$p(y|x)r_x(x)$ for some density $r_x$. Our tests, formulated with a Stein\noperator, can be applied to any differentiable conditional density model, and\nrequire no knowledge of the normalizing constant. We show that 1) our tests are\nconsistent against any fixed alternative conditional model; 2) the statistics\ncan be estimated easily, requiring no density estimation as an intermediate\nstep; and 3) our second test offers an interpretable test result providing\ninsight on where the conditional model does not fit well in the domain of the\ncovariate. We demonstrate the interpretability of our test on a task of\nmodeling the distribution of New York City's taxi drop-off location given a\npick-up point. To our knowledge, our work is the first to propose such\nconditional goodness-of-fit tests that simultaneously have all these desirable\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:04:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:27:09 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jitkrittum", "Wittawat", ""], ["Kanagawa", "Heishiro", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2002.10286", "submitter": "Idan Amir", "authors": "Idan Amir, Idan Attias, Tomer Koren, Roi Livni, Yishay Mansour", "title": "Prediction with Corrupted Expert Advice", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": "Conference on Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the fundamental problem of prediction with expert advice, in a\nsetting where the environment is benign and generates losses stochastically,\nbut the feedback observed by the learner is subject to a moderate adversarial\ncorruption. We prove that a variant of the classical Multiplicative Weights\nalgorithm with decreasing step sizes achieves constant regret in this setting\nand performs optimally in a wide range of environments, regardless of the\nmagnitude of the injected corruption. Our results reveal a surprising disparity\nbetween the often comparable Follow the Regularized Leader (FTRL) and Online\nMirror Descent (OMD) frameworks: we show that for experts in the corrupted\nstochastic regime, the regret performance of OMD is in fact strictly inferior\nto that of FTRL.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:39:55 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:17:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Amir", "Idan", ""], ["Attias", "Idan", ""], ["Koren", "Tomer", ""], ["Livni", "Roi", ""], ["Mansour", "Yishay", ""]]}, {"id": "2002.10295", "submitter": "David P\\\"atzel", "authors": "Michael Heider and David P\\\"atzel and J\\\"org H\\\"ahner", "title": "SupRB: A Supervised Rule-based Learning System for Continuous Problems", "comments": "Submitted to the Genetic and Evolutionary Computation Conference 2020\n  (GECCO 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the SupRB learning system, a new Pittsburgh-style learning\nclassifier system (LCS) for supervised learning on multi-dimensional continuous\ndecision problems. SupRB learns an approximation of a quality function from\nexamples (consisting of situations, choices and associated qualities) and is\nthen able to make an optimal choice as well as predict the quality of a choice\nin a given situation. One area of application for SupRB is parametrization of\nindustrial machinery. In this field, acceptance of the recommendations of\nmachine learning systems is highly reliant on operators' trust. While an\nessential and much-researched ingredient for that trust is prediction quality,\nit seems that this alone is not enough. At least as important is a\nhuman-understandable explanation of the reasoning behind a recommendation.\nWhile many state-of-the-art methods such as artificial neural networks fall\nshort of this, LCSs such as SupRB provide human-readable rules that can be\nunderstood very easily. The prevalent LCSs are not directly applicable to this\nproblem as they lack support for continuous choices. This paper lays the\nfoundations for SupRB and shows its general applicability on a simplified model\nof an additive manufacturing problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:54:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Heider", "Michael", ""], ["P\u00e4tzel", "David", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.10301", "submitter": "Adithya M Devraj", "authors": "Adithya M. Devraj and Sean P. Meyn", "title": "Q-learning with Uniformly Bounded Variance: Large Discounting is Not a\n  Barrier to Fast Learning", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample complexity bounds are a common performance metric in the Reinforcement\nLearning literature. In the discounted cost, infinite horizon setting, all of\nthe known bounds have a factor that is a polynomial in $1/(1-\\gamma)$, where\n$\\gamma < 1$ is the discount factor. For a large discount factor, these bounds\nseem to imply that a very large number of samples is required to achieve an\n$\\varepsilon$-optimal policy. The objective of the present work is to introduce\na new class of algorithms that have sample complexity uniformly bounded for all\n$\\gamma < 1$. One may argue that this is impossible, due to a recent min-max\nlower bound. The explanation is that this previous lower bound is for a\nspecific problem, which we modify, without compromising the ultimate objective\nof obtaining an $\\varepsilon$-optimal policy. Specifically, we show that the\nasymptotic covariance of the Q-learning algorithm with an optimized step-size\nsequence is a quadratic function of $1/(1-\\gamma)$; an expected, and\nessentially known result. The new relative Q-learning algorithm proposed here\nis shown to have asymptotic covariance that is a quadratic in $1/(1- \\rho^*\n\\gamma)$, where $1 - \\rho^* > 0$ is an upper bound on the spectral gap of an\noptimal transition matrix.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:12:41 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 21:58:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Devraj", "Adithya M.", ""], ["Meyn", "Sean P.", ""]]}, {"id": "2002.10306", "submitter": "Indro Spinelli", "authors": "Indro Spinelli, Simone Scardapane, Aurelio Uncini", "title": "Adaptive Propagation Graph Convolutional Network", "comments": "Published in IEEE Transaction on Neural Networks and Learning Systems", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3025110", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are a family of neural network models\nthat perform inference on graph data by interleaving vertex-wise operations and\nmessage-passing exchanges across nodes. Concerning the latter, two key\nquestions arise: (i) how to design a differentiable exchange protocol (e.g., a\n1-hop Laplacian smoothing in the original GCN), and (ii) how to characterize\nthe trade-off in complexity with respect to the local updates. In this paper,\nwe show that state-of-the-art results can be achieved by adapting the number of\ncommunication steps independently at every node. In particular, we endow each\nnode with a halting unit (inspired by Graves' adaptive computation time) that\nafter every exchange decides whether to continue communicating or not. We show\nthat the proposed adaptive propagation GCN (AP-GCN) achieves superior or\nsimilar results to the best proposed models so far on a number of benchmarks,\nwhile requiring a small overhead in terms of additional parameters. We also\ninvestigate a regularization term to enforce an explicit trade-off between\ncommunication and accuracy. The code for the AP-GCN experiments is released as\nan open-source library.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:31:16 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 18:28:25 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 09:28:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Spinelli", "Indro", ""], ["Scardapane", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2002.10312", "submitter": "Anian Ruoss", "authors": "Anian Ruoss, Mislav Balunovi\\'c, Marc Fischer, and Martin Vechev", "title": "Learning Certified Individually Fair Representations", "comments": "Conference Paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair representation learning provides an effective way of enforcing fairness\nconstraints without compromising utility for downstream users. A desirable\nfamily of such fairness constraints, each requiring similar treatment for\nsimilar individuals, is known as individual fairness. In this work, we\nintroduce the first method that enables data consumers to obtain certificates\nof individual fairness for existing and new data points. The key idea is to map\nsimilar individuals to close latent representations and leverage this latent\nproximity to certify individual fairness. That is, our method enables the data\nproducer to learn and certify a representation where for a data point all\nsimilar individuals are at $\\ell_\\infty$-distance at most $\\epsilon$, thus\nallowing data consumers to certify individual fairness by proving\n$\\epsilon$-robustness of their classifier. Our experimental evaluation on five\nreal-world datasets and several fairness constraints demonstrates the\nexpressivity and scalability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:41:34 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 18:17:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ruoss", "Anian", ""], ["Balunovi\u0107", "Mislav", ""], ["Fischer", "Marc", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.10316", "submitter": "Wei Tang", "authors": "Wei Tang, Chien-Ju Ho, Yang Liu", "title": "Bandit Learning with Delayed Impact of Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic multi-armed bandit (MAB) problem with delayed impact\nof actions. In our setting, actions taken in the past impact the arm rewards in\nthe subsequent future. This delayed impact of actions is prevalent in the real\nworld. For example, the capability to pay back a loan for people in a certain\nsocial group might depend on historically how frequently that group has been\napproved loan applications. If banks keep rejecting loan applications to people\nin a disadvantaged group, it could create a feedback loop and further damage\nthe chance of getting loans for people in that group. In this paper, we\nformulate this delayed and long-term impact of actions within the context of\nmulti-armed bandits. We generalize the classical bandit setting to encode the\ndependency of this \"bias\" due to the action history during learning. The goal\nis to maximize the collected utilities over time while taking into account the\ndynamics created by the delayed impacts of historical actions. We propose an\nalgorithm that achieves a regret of $\\tilde{\\mathcal{O}}(KT^{2/3})$ and show a\nmatching regret lower bound of $\\Omega(KT^{2/3})$, where $K$ is the number of\narms and $T$ is the learning horizon. Our results complement the bandit\nliterature by adding techniques to deal with actions with long-term impacts and\nhave implications in designing fair algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:43:03 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 17:13:13 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 19:28:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Tang", "Wei", ""], ["Ho", "Chien-Ju", ""], ["Liu", "Yang", ""]]}, {"id": "2002.10319", "submitter": "Lang Huang", "authors": "Lang Huang, Chao Zhang, Hongyang Zhang", "title": "Self-Adaptive Training: beyond Empirical Risk Minimization", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose self-adaptive training---a new training algorithm that dynamically\ncorrects problematic training labels by model predictions without incurring\nextra computational cost---to improve generalization of deep learning for\npotentially corrupted training data. This problem is crucial towards robustly\nlearning from data that are corrupted by, e.g., label noises and\nout-of-distribution samples. The standard empirical risk minimization (ERM) for\nsuch data, however, may easily overfit noises and thus suffers from sub-optimal\nperformance. In this paper, we observe that model predictions can substantially\nbenefit the training process: self-adaptive training significantly improves\ngeneralization over ERM under various levels of noises, and mitigates the\noverfitting issue in both natural and adversarial training. We evaluate the\nerror-capacity curve of self-adaptive training: the test error is monotonously\ndecreasing w.r.t. model capacity. This is in sharp contrast to the\nrecently-discovered double-descent phenomenon in ERM which might be a result of\noverfitting of noises. Experiments on CIFAR and ImageNet datasets verify the\neffectiveness of our approach in two applications: classification with label\nnoise and selective classification. We release our code at\nhttps://github.com/LayneH/self-adaptive-training.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:47:10 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:14:50 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Huang", "Lang", ""], ["Zhang", "Chao", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2002.10330", "submitter": "Francisco Arag\\'on-Roy\\'on", "authors": "F. Arag\\'on-Roy\\'on, A. Jim\\'enez-V\\'ilchez, A. Arauzo-Azofra, J. M.\n  Ben\\'itez", "title": "FSinR: an exhaustive package for feature selection", "comments": "17 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Selection (FS) is a key task in Machine Learning. It consists in\nselecting a number of relevant variables for the model construction or data\nanalysis. We present the R package, FSinR, which implements a variety of widely\nknown filter and wrapper methods, as well as search algorithms. Thus, the\npackage provides the possibility to perform the feature selection process,\nwhich consists in the combination of a guided search on the subsets of features\nwith the filter or wrapper methods that return an evaluation measure of those\nsubsets. In this article, we also present some examples on the usage of the\npackage and a comparison with other packages available in R that contain\nmethods for feature selection.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:59:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Arag\u00f3n-Roy\u00f3n", "F.", ""], ["Jim\u00e9nez-V\u00edlchez", "A.", ""], ["Arauzo-Azofra", "A.", ""], ["Ben\u00edtez", "J. M.", ""]]}, {"id": "2002.10349", "submitter": "Giuseppe Ughi", "authors": "Giuseppe Ughi, Vinayak Abrol, Jared Tanner", "title": "A Model-Based Derivative-Free Approach to Black-Box Adversarial\n  Examples: BOBYQA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that model-based derivative free optimisation algorithms can\ngenerate adversarial targeted misclassification of deep networks using fewer\nnetwork queries than non-model-based methods. Specifically, we consider the\nblack-box setting, and show that the number of networks queries is less\nimpacted by making the task more challenging either through reducing the\nallowed $\\ell^{\\infty}$ perturbation energy or training the network with\ndefences against adversarial misclassification. We illustrate this by\ncontrasting the BOBYQA algorithm with the state-of-the-art model-free\nadversarial targeted misclassification approaches based on genetic,\ncombinatorial, and direct-search algorithms. We observe that for high\n$\\ell^{\\infty}$ energy perturbations on networks, the aforementioned simpler\nmodel-free methods require the fewest queries. In contrast, the proposed BOBYQA\nbased method achieves state-of-the-art results when the perturbation energy\ndecreases, or if the network is trained against adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:23:09 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ughi", "Giuseppe", ""], ["Abrol", "Vinayak", ""], ["Tanner", "Jared", ""]]}, {"id": "2002.10365", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and David J. Schwab and Ari S. Morcos", "title": "The Early Phase of Neural Network Training", "comments": "ICLR 2020 Camera Ready. Available on OpenReview at\n  https://openreview.net/forum?id=Hkl1iRNFwS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that many important aspects of neural network\nlearning take place within the very earliest iterations or epochs of training.\nFor example, sparse, trainable sub-networks emerge (Frankle et al., 2019),\ngradient descent moves into a small subspace (Gur-Ari et al., 2018), and the\nnetwork undergoes a critical period (Achille et al., 2019). Here, we examine\nthe changes that deep neural networks undergo during this early phase of\ntraining. We perform extensive measurements of the network state during these\nearly iterations of training and leverage the framework of Frankle et al.\n(2019) to quantitatively probe the weight distribution and its reliance on\nvarious aspects of the dataset. We find that, within this framework, deep\nnetworks are not robust to reinitializing with random weights while maintaining\nsigns, and that weight distributions are highly non-independent even after only\na few hundred iterations. Despite this behavior, pre-training with blurred\ninputs or an auxiliary self-supervised task can approximate the changes in\nsupervised networks, suggesting that these changes are not inherently\nlabel-dependent, though labels significantly accelerate this process. Together,\nthese results help to elucidate the network changes occurring during this\npivotal initial period of learning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:51:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Frankle", "Jonathan", ""], ["Schwab", "David J.", ""], ["Morcos", "Ari S.", ""]]}, {"id": "2002.10376", "submitter": "Guillaume Leclerc", "authors": "Guillaume Leclerc, Aleksander Madry", "title": "The Two Regimes of Deep Network Training", "comments": "14 pages (5 of appendix), 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate schedule has a major impact on the performance of deep learning\nmodels. Still, the choice of a schedule is often heuristical. We aim to develop\na precise understanding of the effects of different learning rate schedules and\nthe appropriate way to select them. To this end, we isolate two distinct phases\nof training, the first, which we refer to as the \"large-step\" regime, exhibits\na rather poor performance from an optimization point of view but is the primary\ncontributor to model generalization; the latter, \"small-step\" regime exhibits\nmuch more \"convex-like\" optimization behavior but used in isolation produces\nmodels that generalize poorly. We find that by treating these regimes\nseparately-and em specializing our training algorithm to each one of them, we\ncan significantly simplify learning rate schedules.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:08:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Leclerc", "Guillaume", ""], ["Madry", "Aleksander", ""]]}, {"id": "2002.10378", "submitter": "Shanshan Qin", "authors": "Shanshan Qin, Nayantara Mudur and Cengiz Pehlevan", "title": "Contrastive Similarity Matching for Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel biologically-plausible solution to the credit assignment\nproblem motivated by observations in the ventral visual pathway and trained\ndeep neural networks. In both, representations of objects in the same category\nbecome progressively more similar, while objects belonging to different\ncategories become less similar. We use this observation to motivate a\nlayer-specific learning goal in a deep network: each layer aims to learn a\nrepresentational similarity matrix that interpolates between previous and later\nlayers. We formulate this idea using a contrastive similarity matching\nobjective function and derive from it deep neural networks with feedforward,\nlateral, and feedback connections, and neurons that exhibit\nbiologically-plausible Hebbian and anti-Hebbian plasticity. Contrastive\nsimilarity matching can be interpreted as an energy-based learning algorithm,\nbut with significant differences from others in how a contrastive function is\nconstructed.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:10:21 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:48:47 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 16:56:36 GMT"}, {"version": "v4", "created": "Mon, 17 Aug 2020 14:21:49 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 02:09:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Qin", "Shanshan", ""], ["Mudur", "Nayantara", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2002.10384", "submitter": "Nikola Konstantinov", "authors": "Nikola Konstantinov, Elias Frantar, Dan Alistarh, Christoph H. Lampert", "title": "On the Sample Complexity of Adversarial Multi-Source PAC Learning", "comments": "International Conference on Machine Learning (ICML) 2020:\n  Camera-ready. Strengthened the definition of adversarial PAC-learnability,\n  added explicit bounds on sample complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning from multiple untrusted data sources, a\nscenario of increasing practical relevance given the recent emergence of\ncrowdsourcing and collaborative learning paradigms. Specifically, we analyze\nthe situation in which a learning system obtains datasets from multiple\nsources, some of which might be biased or even adversarially perturbed. It is\nknown that in the single-source case, an adversary with the power to corrupt a\nfixed fraction of the training data can prevent PAC-learnability, that is, even\nin the limit of infinitely much training data, no learning system can approach\nthe optimal test error. In this work we show that, surprisingly, the same is\nnot true in the multi-source setting, where the adversary can arbitrarily\ncorrupt a fixed fraction of the data sources. Our main results are a\ngeneralization bound that provides finite-sample guarantees for this learning\nsetting, as well as corresponding lower bounds. Besides establishing\nPAC-learnability our results also show that in a cooperative learning setting\nsharing data with other parties has provable benefits, even if some\nparticipants are malicious.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:19:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:22:51 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Konstantinov", "Nikola", ""], ["Frantar", "Elias", ""], ["Alistarh", "Dan", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2002.10385", "submitter": "Ben Moews", "authors": "Ben Moews and Gbenga Ibikunle", "title": "Predictive intraday correlations in stable and volatile market\n  environments: Evidence from deep learning", "comments": "15 pages, 6 figures, preprint submitted to Physica A", "journal-ref": null, "doi": "10.1016/j.physa.2020.124392", "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods and theories in finance can be ill-equipped to capture\nhighly non-linear interactions in financial prediction problems based on\nlarge-scale datasets, with deep learning offering a way to gain insights into\ncorrelations in markets as complex systems. In this paper, we apply deep\nlearning to econometrically constructed gradients to learn and exploit lagged\ncorrelations among S&P 500 stocks to compare model behaviour in stable and\nvolatile market environments, and under the exclusion of target stock\ninformation for predictions. In order to measure the effect of time horizons,\nwe predict intraday and daily stock price movements in varying interval lengths\nand gauge the complexity of the problem at hand with a modification of our\nmodel architecture. Our findings show that accuracies, while remaining\nsignificant and demonstrating the exploitability of lagged correlations in\nstock markets, decrease with shorter prediction horizons. We discuss\nimplications for modern finance theory and our work's applicability as an\ninvestigative tool for portfolio managers. Lastly, we show that our model's\nperformance is consistent in volatile markets by exposing it to the environment\nof the recent financial crisis of 2007/2008.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:19:54 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Moews", "Ben", ""], ["Ibikunle", "Gbenga", ""]]}, {"id": "2002.10389", "submitter": "Renqian Luo", "authors": "Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Enhong Chen, Tie-Yan Liu", "title": "Semi-Supervised Neural Architecture Search", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) relies on a good controller to generate\nbetter architectures or predict the accuracy of given architectures. However,\ntraining the controller requires both abundant and high-quality pairs of\narchitectures and their accuracy, while it is costly to evaluate an\narchitecture and obtain its accuracy. In this paper, we propose SemiNAS, a\nsemi-supervised NAS approach that leverages numerous unlabeled architectures\n(without evaluation and thus nearly no cost). Specifically, SemiNAS 1) trains\nan initial accuracy predictor with a small set of architecture-accuracy data\npairs; 2) uses the trained accuracy predictor to predict the accuracy of large\namount of architectures (without evaluation); and 3) adds the generated data\npairs to the original data to further improve the predictor. The trained\naccuracy predictor can be applied to various NAS algorithms by predicting the\naccuracy of candidate architectures for them. SemiNAS has two advantages: 1) It\nreduces the computational cost under the same accuracy guarantee. On\nNASBench-101 benchmark dataset, it achieves comparable accuracy with\ngradient-based method while using only 1/7 architecture-accuracy pairs. 2) It\nachieves higher accuracy under the same computational cost. It achieves 94.02%\ntest accuracy on NASBench-101, outperforming all the baselines when using the\nsame number of architectures. On ImageNet, it achieves 23.5% top-1 error rate\n(under 600M FLOPS constraint) using 4 GPU-days for search. We further apply it\nto LJSpeech text to speech task and it achieves 97% intelligibility rate in the\nlow-resource setting and 15% test error rate in the robustness setting, with\n9%, 7% improvements over the baseline respectively.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:23:00 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 16:20:23 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 06:52:02 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 09:44:09 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Luo", "Renqian", ""], ["Tan", "Xu", ""], ["Wang", "Rui", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2002.10394", "submitter": "Gr\\'egoire Jauvion", "authors": "Gr\\'egoire Jauvion, Thibaut Cassard, Boris Quennehen, David Lissmyr", "title": "DeepPlume: Very High Resolution Real-Time Air Quality Mapping", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an engine able to predict jointly the real-time\nconcentration of the main pollutants harming people's health: nitrogen dioxyde\n(NO2), ozone (O3) and particulate matter (PM2.5 and PM10, which are\nrespectively the particles whose size are below 2.5 um and 10 um).\n  The engine covers a large part of the world and is fed with real-time\nofficial stations measures, atmospheric models' forecasts, land cover data,\nroad networks and traffic estimates to produce predictions with a very high\nresolution in the range of a few dozens of meters. This resolution makes the\nengine adapted to very innovative applications like street-level air quality\nmapping or air quality adjusted routing.\n  Plume Labs has deployed a similar prediction engine to build several products\naiming at providing air quality data to individuals and businesses. For the\nsake of clarity and reproducibility, the engine presented here has been built\nspecifically for this paper and differs quite significantly from the one used\nin Plume Labs' products. A major difference is in the data sources feeding the\nengine: in particular, this prediction engine does not include mobile sensors\nmeasurements.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:05:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jauvion", "Gr\u00e9goire", ""], ["Cassard", "Thibaut", ""], ["Quennehen", "Boris", ""], ["Lissmyr", "David", ""]]}, {"id": "2002.10399", "submitter": "Niccol\\`o Dalmasso", "authors": "Niccol\\`o Dalmasso and Rafael Izbicki and Ann B. Lee", "title": "Confidence Sets and Hypothesis Testing in a Likelihood-Free Inference\n  Setting", "comments": "20 pages, 8 figures, 6 tables, 4 algorithm boxes", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:2323-2334, 2020", "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation, statistical tests and confidence sets are the\ncornerstones of classical statistics that allow scientists to make inferences\nabout the underlying process that generated the observed data. A key question\nis whether one can still construct hypothesis tests and confidence sets with\nproper coverage and high power in a so-called likelihood-free inference (LFI)\nsetting; that is, a setting where the likelihood is not explicitly known but\none can forward-simulate observable data according to a stochastic model. In\nthis paper, we present $\\texttt{ACORE}$ (Approximate Computation via Odds Ratio\nEstimation), a frequentist approach to LFI that first formulates the classical\nlikelihood ratio test (LRT) as a parametrized classification problem, and then\nuses the equivalence of tests and confidence sets to build confidence regions\nfor parameters of interest. We also present a goodness-of-fit procedure for\nchecking whether the constructed tests and confidence regions are valid.\n$\\texttt{ACORE}$ is based on the key observation that the LRT statistic, the\nrejection probability of the test, and the coverage of the confidence set are\nconditional distribution functions which often vary smoothly as a function of\nthe parameters of interest. Hence, instead of relying solely on samples\nsimulated at fixed parameter settings (as is the convention in standard Monte\nCarlo solutions), one can leverage machine learning tools and data simulated in\nthe neighborhood of a parameter to improve estimates of quantities of interest.\nWe demonstrate the efficacy of $\\texttt{ACORE}$ with both theoretical and\nempirical results. Our implementation is available on Github.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:34:49 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 02:56:38 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Dalmasso", "Niccol\u00f2", ""], ["Izbicki", "Rafael", ""], ["Lee", "Ann B.", ""]]}, {"id": "2002.10400", "submitter": "Shashank Rajput", "authors": "Shashank Rajput, Anant Gupta and Dimitris Papailiopoulos", "title": "Closing the convergence gap of SGD without replacement", "comments": "Simplified some proofs and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent without replacement sampling is widely used in\npractice for model training. However, the vast majority of SGD analyses assumes\ndata is sampled with replacement, and when the function minimized is strongly\nconvex, an $\\mathcal{O}\\left(\\frac{1}{T}\\right)$ rate can be established when\nSGD is run for $T$ iterations. A recent line of breakthrough works on SGD\nwithout replacement (SGDo) established an\n$\\mathcal{O}\\left(\\frac{n}{T^2}\\right)$ convergence rate when the function\nminimized is strongly convex and is a sum of $n$ smooth functions, and an\n$\\mathcal{O}\\left(\\frac{1}{T^2}+\\frac{n^3}{T^3}\\right)$ rate for sums of\nquadratics. On the other hand, the tightest known lower bound postulates an\n$\\Omega\\left(\\frac{1}{T^2}+\\frac{n^2}{T^3}\\right)$ rate, leaving open the\npossibility of better SGDo convergence rates in the general case. In this\npaper, we close this gap and show that SGD without replacement achieves a rate\nof $\\mathcal{O}\\left(\\frac{1}{T^2}+\\frac{n^2}{T^3}\\right)$ when the sum of the\nfunctions is a quadratic, and offer a new lower bound of\n$\\Omega\\left(\\frac{n}{T^2}\\right)$ for strongly convex functions that are sums\nof smooth functions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:37:28 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 18:32:00 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 00:11:01 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 17:37:19 GMT"}, {"version": "v5", "created": "Wed, 1 Jul 2020 01:26:54 GMT"}, {"version": "v6", "created": "Thu, 9 Jul 2020 14:18:03 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Rajput", "Shashank", ""], ["Gupta", "Anant", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "2002.10410", "submitter": "Alessandro De Palma", "authors": "Rudy Bunel, Alessandro De Palma, Alban Desmaison, Krishnamurthy\n  Dvijotham, Pushmeet Kohli, Philip H.S. Torr, M. Pawan Kumar", "title": "Lagrangian Decomposition for Neural Network Verification", "comments": "UAI 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental component of neural network verification is the computation of\nbounds on the values their outputs can take. Previous methods have either used\noff-the-shelf solvers, discarding the problem structure, or relaxed the problem\neven further, making the bounds unnecessarily loose. We propose a novel\napproach based on Lagrangian Decomposition. Our formulation admits an efficient\nsupergradient ascent algorithm, as well as an improved proximal algorithm. Both\nthe algorithms offer three advantages: (i) they yield bounds that are provably\nat least as tight as previous dual algorithms relying on Lagrangian\nrelaxations; (ii) they are based on operations analogous to forward/backward\npass of neural networks layers and are therefore easily parallelizable,\namenable to GPU implementation and able to take advantage of the convolutional\nstructure of problems; and (iii) they allow for anytime stopping while still\nproviding valid bounds. Empirically, we show that we obtain bounds comparable\nwith off-the-shelf solvers in a fraction of their running time, and obtain\ntighter bounds in the same time as previous dual algorithms. This results in an\noverall speed-up when employing the bounds for formal verification. Code for\nour algorithms is available at\nhttps://github.com/oval-group/decomposition-plnn-bounds.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:55:10 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 18:00:02 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 17:49:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Bunel", "Rudy", ""], ["De Palma", "Alessandro", ""], ["Desmaison", "Alban", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2002.10411", "submitter": "Y. A. Joarder", "authors": "Y. A. Joarder, Emran Hossain and Al Faisal Mahmud", "title": "Clustering and Classification with Non-Existence Attributes: A Sentenced\n  Discrepancy Measure Based Technique", "comments": "30 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For some or all of the data instances a number of independent-world\nclustering issues suffer from incomplete data characterization due to losing or\nabsent attributes. Typical clustering approaches cannot be applied directly to\nsuch data unless pre-processing by techniques like imputation or\nmarginalization. We have overcome this drawback by utilizing a Sentenced\nDiscrepancy Measure which we refer to as the Attribute Weighted Penalty based\nDiscrepancy (AWPD). Using the AWPD measure, we modified the K-MEANS++ and\nScalable K-MEANS++ for clustering algorithm and k Nearest Neighbor (kNN) for\nclassification so as to make them directly applicable to datasets with\nnon-existence attributes. We have presented a detailed theoretical analysis\nwhich shows that the new AWPD based K-MEANS++, Scalable K-MEANS++ and kNN\nalgorithm merge into a local prime among the number of iterations is finite. We\nhave reported in depth experiments on numerous benchmark datasets for various\nforms of Non-Existence showing that the projected clustering and classification\ntechniques usually show better results in comparison to some of the renowned\nimputation methods that are generally used to process such insufficient data.\nThis technique is designed to trace invaluable data to: directly apply our\nmethod on the datasets which have Non-Existence attributes and establish a\nmethod for detecting unstructured Non-Existence attributes with the best\naccuracy rate and minimum cost.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:56:06 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Joarder", "Y. A.", ""], ["Hossain", "Emran", ""], ["Mahmud", "Al Faisal", ""]]}, {"id": "2002.10413", "submitter": "Daniel Flam-Shepherd", "authors": "Daniel Flam-Shepherd, Tony Wu, Pascal Friederich and Alan Aspuru-Guzik", "title": "Neural Message Passing on High Order Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network have achieved impressive results in predicting molecular\nproperties, but they do not directly account for local and hidden structures in\nthe graph such as functional groups and molecular geometry. At each propagation\nstep, GNNs aggregate only over first order neighbours, ignoring important\ninformation contained in subsequent neighbours as well as the relationships\nbetween those higher order connections. In this work, we generalize graph\nneural nets to pass messages and aggregate across higher order paths. This\nallows for information to propagate over various levels and substructures of\nthe graph. We demonstrate our model on a few tasks in molecular property\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:58:02 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Flam-Shepherd", "Daniel", ""], ["Wu", "Tony", ""], ["Friederich", "Pascal", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2002.10420", "submitter": "Fahad Sohrab", "authors": "Fahad Sohrab, Jenni Raitoharju", "title": "Boosting rare benthic macroinvertebrates taxa identification with\n  one-class classification", "comments": "5 pages, 1 figure, 2 tables", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI47803.2020.9308359", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insect monitoring is crucial for understanding the consequences of rapid\necological changes, but taxa identification currently requires tedious manual\nexpert work and cannot be scaled-up efficiently. Deep convolutional neural\nnetworks (CNNs), provide a viable way to significantly increase the\nbiomonitoring volumes. However, taxa abundances are typically very imbalanced\nand the amounts of training images for the rarest classes are simply too low\nfor deep CNNs. As a result, the samples from the rare classes are often\ncompletely missed, while detecting them has biological importance. In this\npaper, we propose combining the trained deep CNN with one-class classifiers to\nimprove the rare species identification. One-class classification models are\ntraditionally trained with much fewer samples and they can provide a mechanism\nto indicate samples potentially belonging to the rare classes for human\ninspection. Our experiments confirm that the proposed approach may indeed\nsupport moving towards partial automation of the taxa identification task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:46:24 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Sohrab", "Fahad", ""], ["Raitoharju", "Jenni", ""]]}, {"id": "2002.10435", "submitter": "Sitan Chen", "authors": "Sitan Chen, Jerry Li, Ankur Moitra", "title": "Learning Structured Distributions From Untrusted Batches: Faster and\n  Simpler", "comments": "37 pages, version 2 includes experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of learning from untrusted batches introduced by Qiao\nand Valiant [QV17]. Recently, Jain and Orlitsky [JO19] gave a simple\nsemidefinite programming approach based on the cut-norm that achieves\nessentially information-theoretically optimal error in polynomial time.\nConcurrently, Chen et al. [CLM19] considered a variant of the problem where\n$\\mu$ is assumed to be structured, e.g. log-concave, monotone hazard rate,\n$t$-modal, etc. In this case, it is possible to achieve the same error with\nsample complexity sublinear in $n$, and they exhibited a quasi-polynomial time\nalgorithm for doing so using Haar wavelets.\n  In this paper, we find an appealing way to synthesize the techniques of\n[JO19] and [CLM19] to give the best of both worlds: an algorithm which runs in\npolynomial time and can exploit structure in the underlying distribution to\nachieve sublinear sample complexity. Along the way, we simplify the approach of\n[JO19] by avoiding the need for SDP rounding and giving a more direct\ninterpretation of it through the lens of soft filtering, a powerful recent\ntechnique in high-dimensional robust estimation. We validate the usefulness of\nour algorithms in preliminary experimental evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:32:10 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 17:50:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Jerry", ""], ["Moitra", "Ankur", ""]]}, {"id": "2002.10438", "submitter": "Vineel Nagisetty", "authors": "Vineel Nagisetty, Laura Graves, Joseph Scott and Vijay Ganesh", "title": "xAI-GAN: Enhancing Generative Adversarial Networks via Explainable AI\n  Systems", "comments": "7 pages (+ 2 page for reference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a revolutionary class of Deep\nNeural Networks (DNNs) that have been successfully used to generate realistic\nimages, music, text, and other data. However, GAN training presents many\nchallenges, notably it can be very resource-intensive. A potential weakness in\nGANs is that it requires a lot of data for successful training and data\ncollection can be an expensive process. Typically, the corrective feedback from\ndiscriminator DNNs to generator DNNs (namely, the discriminator's assessment of\nthe generated example) is calculated using only one real-numbered value (loss).\nBy contrast, we propose a new class of GAN we refer to as xAI-GAN that\nleverages recent advances in explainable AI (xAI) systems to provide a \"richer\"\nform of corrective feedback from discriminators to generators. Specifically, we\nmodify the gradient descent process using xAI systems that specify the reason\nas to why the discriminator made the classification it did, thus providing the\n\"richer\" corrective feedback that helps the generator to better fool the\ndiscriminator. Using our approach, we observe xAI-GANs provide an improvement\nof up to 23.18% in the quality of generated images on both MNIST and FMNIST\ndatasets over standard GANs as measured by Fr\\'echet Inception Distance (FID).\nWe further compare xAI-GAN trained on 20% of the data with standard GAN trained\non 100% of data on the CIFAR10 dataset and find that xAI-GAN still shows an\nimprovement in FID score. Further, we compare our work with Differentiable\nAugmentation - which has been shown to make GANs data-efficient - and show that\nxAI-GANs outperform GANs trained on Differentiable Augmentation. Moreover, both\ntechniques can be combined to produce even better results. Finally, we argue\nthat xAI-GAN enables users greater control over how models learn than standard\nGANs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:38:13 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:14:31 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Nagisetty", "Vineel", ""], ["Graves", "Laura", ""], ["Scott", "Joseph", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2002.10444", "submitter": "Soham De", "authors": "Soham De, Samuel L. Smith", "title": "Batch Normalization Biases Residual Blocks Towards the Identity Function\n  in Deep Networks", "comments": "Camera-ready version of NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization dramatically increases the largest trainable depth of\nresidual networks, and this benefit has been crucial to the empirical success\nof deep residual networks on a wide range of benchmarks. We show that this key\nbenefit arises because, at initialization, batch normalization downscales the\nresidual branch relative to the skip connection, by a normalizing factor on the\norder of the square root of the network depth. This ensures that, early in\ntraining, the function computed by normalized residual blocks in deep networks\nis close to the identity function (on average). We use this insight to develop\na simple initialization scheme that can train deep residual networks without\nnormalization. We also provide a detailed empirical study of residual networks,\nwhich clarifies that, although batch normalized networks can be trained with\nlarger learning rates, this effect is only beneficial in specific compute\nregimes, and has minimal benefits when the batch size is small.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:43:03 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 12:20:43 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 10:18:10 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["De", "Soham", ""], ["Smith", "Samuel L.", ""]]}, {"id": "2002.10445", "submitter": "Yedid Hoshen", "authors": "Liron Bergman and Niv Cohen and Yedid Hoshen", "title": "Deep Nearest Neighbor Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbors is a successful and long-standing technique for anomaly\ndetection. Significant progress has been recently achieved by self-supervised\ndeep methods (e.g. RotNet). Self-supervised features however typically\nunder-perform Imagenet pre-trained features. In this work, we investigate\nwhether the recent progress can indeed outperform nearest-neighbor methods\noperating on an Imagenet pretrained feature space. The simple nearest-neighbor\nbased-approach is experimentally shown to outperform self-supervised methods\nin: accuracy, few shot generalization, training time and noise robustness while\nmaking fewer assumptions on image distributions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:51:33 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Bergman", "Liron", ""], ["Cohen", "Niv", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2002.10477", "submitter": "Adel Javanmard", "authors": "Adel Javanmard, Mahdi Soltanolkotabi and Hamed Hassani", "title": "Precise Tradeoffs in Adversarial Training for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite breakthrough performance, modern learning models are known to be\nhighly vulnerable to small adversarial perturbations in their inputs. While a\nwide variety of recent \\emph{adversarial training} methods have been effective\nat improving robustness to perturbed inputs (robust accuracy), often this\nbenefit is accompanied by a decrease in accuracy on benign inputs (standard\naccuracy), leading to a tradeoff between often competing objectives.\nComplicating matters further, recent empirical evidence suggest that a variety\nof other factors (size and quality of training data, model size, etc.) affect\nthis tradeoff in somewhat surprising ways. In this paper we provide a precise\nand comprehensive understanding of the role of adversarial training in the\ncontext of linear regression with Gaussian features. In particular, we\ncharacterize the fundamental tradeoff between the accuracies achievable by any\nalgorithm regardless of computational power or size of the training data.\nFurthermore, we precisely characterize the standard/robust accuracy and the\ncorresponding tradeoff achieved by a contemporary mini-max adversarial training\napproach in a high-dimensional regime where the number of data points and the\nparameters of the model grow in proportion to each other. Our theory for\nadversarial training algorithms also facilitates the rigorous study of how a\nvariety of factors (size and quality of training data, model\noverparametrization etc.) affect the tradeoff between these two competing\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:01:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Javanmard", "Adel", ""], ["Soltanolkotabi", "Mahdi", ""], ["Hassani", "Hamed", ""]]}, {"id": "2002.10487", "submitter": "Ehsan Amid", "authors": "Ehsan Amid and Manfred K. Warmuth", "title": "Reparameterizing Mirror Descent as Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the recent successful applications of neural networks have been based\non training with gradient descent updates. However, for some small networks,\nother mirror descent updates learn provably more efficiently when the target is\nsparse. We present a general framework for casting a mirror descent update as a\ngradient descent update on a different set of parameters. In some cases, the\nmirror descent reparameterization can be described as training a modified\nnetwork with standard backpropagation. The reparameterization framework is\nversatile and covers a wide range of mirror descent updates, even cases where\nthe domain is constrained. Our construction for the reparameterization argument\nis done for the continuous versions of the updates. Finding general criteria\nfor the discrete versions to closely track their continuous counterparts\nremains an interesting open problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:09:47 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:38:47 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "2002.10501", "submitter": "Ruizhi Deng", "authors": "Ruizhi Deng, Yanshuai Cao, Bo Chang, Leonid Sigal, Greg Mori, Marcus\n  A. Brubaker", "title": "Variational Hyper RNN for Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel probabilistic sequence model that excels at\ncapturing high variability in time series data, both across sequences and\nwithin an individual sequence. Our method uses temporal latent variables to\ncapture information about the underlying data pattern and dynamically decodes\nthe latent information into modifications of weights of the base decoder and\nrecurrent model. The efficacy of the proposed method is demonstrated on a range\nof synthetic and real-world sequential data that exhibit large scale\nvariations, regime shifts, and complex dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:30:32 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Deng", "Ruizhi", ""], ["Cao", "Yanshuai", ""], ["Chang", "Bo", ""], ["Sigal", "Leonid", ""], ["Mori", "Greg", ""], ["Brubaker", "Marcus A.", ""]]}, {"id": "2002.10509", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana", "title": "HYDRA: Pruning Adversarially Robust Neural Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In safety-critical but computationally resource-constrained applications,\ndeep learning faces two key challenges: lack of robustness against adversarial\nattacks and large neural network size (often millions of parameters). While the\nresearch community has extensively explored the use of robust training and\nnetwork pruning independently to address one of these challenges, only a few\nrecent works have studied them jointly. However, these works inherit a\nheuristic pruning strategy that was developed for benign training, which\nperforms poorly when integrated with robust training techniques, including\nadversarial training and verifiable robust training. To overcome this\nchallenge, we propose to make pruning techniques aware of the robust training\nobjective and let the training objective guide the search for which connections\nto prune. We realize this insight by formulating the pruning objective as an\nempirical risk minimization problem which is solved efficiently using SGD. We\ndemonstrate that our approach, titled HYDRA, achieves compressed networks with\nstate-of-the-art benign and robust accuracy, simultaneously. We demonstrate the\nsuccess of our approach across CIFAR-10, SVHN, and ImageNet dataset with four\nrobust training techniques: iterative adversarial training, randomized\nsmoothing, MixTrain, and CROWN-IBP. We also demonstrate the existence of highly\nrobust sub-networks within non-robust networks. Our code and compressed\nnetworks are publicly available at\n\\url{https://github.com/inspire-group/compactness-robustness}.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:54:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 14:26:57 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 15:02:00 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sehwag", "Vikash", ""], ["Wang", "Shiqi", ""], ["Mittal", "Prateek", ""], ["Jana", "Suman", ""]]}, {"id": "2002.10516", "submitter": "Ruizhi Deng", "authors": "Ruizhi Deng, Bo Chang, Marcus A. Brubaker, Greg Mori, Andreas Lehrmann", "title": "Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows transform a simple base distribution into a complex target\ndistribution and have proved to be powerful models for data generation and\ndensity estimation. In this work, we propose a novel type of normalizing flow\ndriven by a differential deformation of the Wiener process. As a result, we\nobtain a rich time series model whose observable process inherits many of the\nappealing properties of its base process, such as efficient computation of\nlikelihoods and marginals. Furthermore, our continuous treatment provides a\nnatural framework for irregular time series with an independent arrival\nprocess, including straightforward interpolation. We illustrate the desirable\nproperties of the proposed model on popular stochastic processes and\ndemonstrate its superior flexibility to variational RNN and latent ODE\nbaselines in a series of experiments on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:13:43 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 00:38:32 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 21:02:05 GMT"}, {"version": "v4", "created": "Tue, 13 Jul 2021 04:10:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Deng", "Ruizhi", ""], ["Chang", "Bo", ""], ["Brubaker", "Marcus A.", ""], ["Mori", "Greg", ""], ["Lehrmann", "Andreas", ""]]}, {"id": "2002.10526", "submitter": "Michael Mahoney", "authors": "Ping Ma, Xinlian Zhang, Xin Xing, Jingyi Ma, and Michael W. Mahoney", "title": "Asymptotic Analysis of Sampling Estimators for Randomized Numerical\n  Linear Algebra Algorithms", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical analysis of Randomized Numerical Linear Algebra (RandNLA)\nalgorithms within the past few years has mostly focused on their performance as\npoint estimators. However, this is insufficient for conducting statistical\ninference, e.g., constructing confidence intervals and hypothesis testing,\nsince the distribution of the estimator is lacking. In this article, we develop\nan asymptotic analysis to derive the distribution of RandNLA sampling\nestimators for the least-squares problem. In particular, we derive the\nasymptotic distribution of a general sampling estimator with arbitrary sampling\nprobabilities. The analysis is conducted in two complementary settings, i.e.,\nwhen the objective of interest is to approximate the full sample estimator or\nis to infer the underlying ground truth model parameters. For each setting, we\nshow that the sampling estimator is asymptotically normally distributed under\nmild regularity conditions. Moreover, the sampling estimator is asymptotically\nunbiased in both settings. Based on our asymptotic analysis, we use two\ncriteria, the Asymptotic Mean Squared Error (AMSE) and the Expected Asymptotic\nMean Squared Error (EAMSE), to identify optimal sampling probabilities. Several\nof these optimal sampling probability distributions are new to the literature,\ne.g., the root leverage sampling estimator and the predictor length sampling\nestimator. Our theoretical results clarify the role of leverage in the sampling\nprocess, and our empirical results demonstrate improvements over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:34:50 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ma", "Ping", ""], ["Zhang", "Xinlian", ""], ["Xing", "Xin", ""], ["Ma", "Jingyi", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.10539", "submitter": "David Eriksson", "authors": "Eric Hans Lee, David Eriksson, Bolong Cheng, Michael McCourt, David\n  Bindel", "title": "Efficient Rollout Strategies for Bayesian Optimization", "comments": "To appear in UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a class of sample-efficient global optimization\nmethods, where a probabilistic model conditioned on previous observations is\nused to determine future evaluations via the optimization of an acquisition\nfunction. Most acquisition functions are myopic, meaning that they only\nconsider the impact of the next function evaluation. Non-myopic acquisition\nfunctions consider the impact of the next $h$ function evaluations and are\ntypically computed through rollout, in which $h$ steps of BO are simulated.\nThese rollout acquisition functions are defined as $h$-dimensional integrals,\nand are expensive to compute and optimize. We show that a combination of\nquasi-Monte Carlo, common random numbers, and control variates significantly\nreduce the computational burden of rollout. We then formulate a policy-search\nbased approach that removes the need to optimize the rollout acquisition\nfunction. Finally, we discuss the qualitative behavior of rollout policies in\nthe setting of multi-modal objectives and model error.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:54:08 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 17:52:49 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 03:40:36 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lee", "Eric Hans", ""], ["Eriksson", "David", ""], ["Cheng", "Bolong", ""], ["McCourt", "Michael", ""], ["Bindel", "David", ""]]}, {"id": "2002.10542", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Sharan Vaswani, Issam Laradji, Simon Lacoste-Julien", "title": "Stochastic Polyak Step-size for SGD: An Adaptive Learning Rate for Fast\n  Convergence", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic variant of the classical Polyak step-size (Polyak,\n1987) commonly used in the subgradient method. Although computing the Polyak\nstep-size requires knowledge of the optimal function values, this information\nis readily available for typical modern machine learning applications.\nConsequently, the proposed stochastic Polyak step-size (SPS) is an attractive\nchoice for setting the learning rate for stochastic gradient descent (SGD). We\nprovide theoretical convergence guarantees for SGD equipped with SPS in\ndifferent settings, including strongly convex, convex and non-convex functions.\nFurthermore, our analysis results in novel convergence guarantees for SGD with\na constant step-size. We show that SPS is particularly effective when training\nover-parameterized models capable of interpolating the training data. In this\nsetting, we prove that SPS enables SGD to converge to the true solution at a\nfast rate without requiring the knowledge of any problem-dependent constants or\nadditional computational overhead. We experimentally validate our theoretical\nresults via extensive experiments on synthetic and real datasets. We\ndemonstrate the strong performance of SGD with SPS compared to state-of-the-art\noptimization methods when training over-parameterized models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:57:23 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:03:46 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 14:53:59 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Loizou", "Nicolas", ""], ["Vaswani", "Sharan", ""], ["Laradji", "Issam", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2002.10543", "submitter": "Liang Mi", "authors": "Liang Mi, Tianshu Yu, Jose Bento, Wen Zhang, Baoxin Li, Yalin Wang", "title": "Variational Wasserstein Barycenters for Geometric Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to compute Wasserstein barycenters (WBs) by solving for Monge maps\nwith variational principle. We discuss the metric properties of WBs and explore\ntheir connections, especially the connections of Monge WBs, to K-means\nclustering and co-clustering. We also discuss the feasibility of Monge WBs on\nunbalanced measures and spherical domains. We propose two new problems --\nregularized K-means and Wasserstein barycenter compression. We demonstrate the\nuse of VWBs in solving these clustering-related problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:01:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mi", "Liang", ""], ["Yu", "Tianshu", ""], ["Bento", "Jose", ""], ["Zhang", "Wen", ""], ["Li", "Baoxin", ""], ["Wang", "Yalin", ""]]}, {"id": "2002.10544", "submitter": "Nikunj Saunshi", "authors": "Sanjeev Arora, Simon S. Du, Sham Kakade, Yuping Luo, and Nikunj\n  Saunshi", "title": "Provable Representation Learning for Imitation Learning via Bi-level\n  Optimization", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy in modern learning systems is to learn a representation\nthat is useful for many tasks, a.k.a. representation learning. We study this\nstrategy in the imitation learning setting for Markov decision processes (MDPs)\nwhere multiple experts' trajectories are available. We formulate representation\nlearning as a bi-level optimization problem where the \"outer\" optimization\ntries to learn the joint representation and the \"inner\" optimization encodes\nthe imitation learning setup and tries to learn task-specific parameters. We\ninstantiate this framework for the imitation learning settings of behavior\ncloning and observation-alone. Theoretically, we show using our framework that\nrepresentation learning can provide sample complexity benefits for imitation\nlearning in both settings. We also provide proof-of-concept experiments to\nverify our theory.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:03:52 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Kakade", "Sham", ""], ["Luo", "Yuping", ""], ["Saunshi", "Nikunj", ""]]}, {"id": "2002.10549", "submitter": "Zhiyuan Li", "authors": "Zhiyuan Li, Jaideep Vitthal Murkute, Prashnna Kumar Gyawali and Linwei\n  Wang", "title": "Progressive Learning and Disentanglement of Hierarchical Representations", "comments": "Main text: 9 pages, 7 figures. Supplements: 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rich representation from data is an important task for deep\ngenerative models such as variational auto-encoder (VAE). However, by\nextracting high-level abstractions in the bottom-up inference process, the goal\nof preserving all factors of variations for top-down generation is compromised.\nMotivated by the concept of \"starting small\", we present a strategy to\nprogressively learn independent hierarchical representations from high- to\nlow-levels of abstractions. The model starts with learning the most abstract\nrepresentation, and then progressively grow the network architecture to\nintroduce new representations at different levels of abstraction. We\nquantitatively demonstrate the ability of the presented model to improve\ndisentanglement in comparison to existing works on two benchmark data sets\nusing three disentanglement metrics, including a new metric we proposed to\ncomplement the previously-presented metric of mutual information gap. We\nfurther present both qualitative and quantitative evidence on how the\nprogression of learning improves disentangling of hierarchical representations.\nBy drawing on the respective advantage of hierarchical representation learning\nand progressive learning, this is to our knowledge the first attempt to improve\ndisentanglement by progressively growing the capacity of VAE to learn\nhierarchical representations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:19:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Li", "Zhiyuan", ""], ["Murkute", "Jaideep Vitthal", ""], ["Gyawali", "Prashnna Kumar", ""], ["Wang", "Linwei", ""]]}, {"id": "2002.10553", "submitter": "Tolga Ergen", "authors": "Mert Pilanci, Tolga Ergen", "title": "Neural Networks are Convex Regularizers: Exact Polynomial-time Convex\n  Optimization Formulations for Two-layer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop exact representations of training two-layer neural networks with\nrectified linear units (ReLUs) in terms of a single convex program with number\nof variables polynomial in the number of training samples and the number of\nhidden neurons. Our theory utilizes semi-infinite duality and minimum norm\nregularization. We show that ReLU networks trained with standard weight decay\nare equivalent to block $\\ell_1$ penalized convex models. Moreover, we show\nthat certain standard convolutional linear networks are equivalent\nsemi-definite programs which can be simplified to $\\ell_1$ regularized linear\nmodels in a polynomial sized discrete Fourier feature space.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:32:41 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 05:26:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pilanci", "Mert", ""], ["Ergen", "Tolga", ""]]}, {"id": "2002.10561", "submitter": "Jiefu Zhang", "authors": "Jiefu Zhang, Leonardo Zepeda-N\\'u\\~nez, Yuan Yao, Lin Lin", "title": "Learning the mapping $\\mathbf{x}\\mapsto \\sum_{i=1}^d x_i^2$: the cost of\n  finding the needle in a haystack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of using machine learning to approximate the mapping\n$\\mathbf{x}\\mapsto\\sum_{i=1}^d x_i^2$ with $x_i\\in[-1,1]$ seems to be a trivial\none. Given the knowledge of the separable structure of the function, one can\ndesign a sparse network to represent the function very accurately, or even\nexactly. When such structural information is not available, and we may only use\na dense neural network, the optimization procedure to find the sparse network\nembedded in the dense network is similar to finding the needle in a haystack,\nusing a given number of samples of the function. We demonstrate that the cost\n(measured by sample complexity) of finding the needle is directly related to\nthe Barron norm of the function. While only a small number of samples is needed\nto train a sparse network, the dense network trained with the same number of\nsamples exhibits large test loss and a large generalization gap. In order to\ncontrol the size of the generalization gap, we find that the use of explicit\nregularization becomes increasingly more important as $d$ increases. The\nnumerically observed sample complexity with explicit regularization scales as\n$\\mathcal{O}(d^{2.5})$, which is in fact better than the theoretically\npredicted sample complexity that scales as $\\mathcal{O}(d^{4})$. Without\nexplicit regularization (also called implicit regularization), the numerically\nobserved sample complexity is significantly higher and is close to\n$\\mathcal{O}(d^{4.5})$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:58:22 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 21:14:02 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Jiefu", ""], ["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""], ["Yao", "Yuan", ""], ["Lin", "Lin", ""]]}, {"id": "2002.10566", "submitter": "Ekaterina Abramova", "authors": "Ekaterina Abramova, Derek Bunn", "title": "Forecasting the Intra-Day Spread Densities of Electricity Prices", "comments": "31 pages, 25 figures. arXiv admin note: substantial text overlap with\n  arXiv:1903.06668", "journal-ref": "Energies 2020, 13(3), 687", "doi": "10.3390/en13030687", "report-no": null, "categories": "stat.AP cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intra-day price spreads are of interest to electricity traders, storage and\nelectric vehicle operators. This paper formulates dynamic density functions,\nbased upon skewed-t and similar representations, to model and forecast the\nGerman electricity price spreads between different hours of the day, as\nrevealed in the day-ahead auctions. The four specifications of the density\nfunctions are dynamic and conditional upon exogenous drivers, thereby\npermitting the location, scale and shape parameters of the densities to respond\nhourly to such factors as weather and demand forecasts. The best fitting and\nforecasting specifications for each spread are selected based on the Pinball\nLoss function, following the closed-form analytical solutions of the cumulative\ndistribution functions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:57:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Abramova", "Ekaterina", ""], ["Bunn", "Derek", ""]]}, {"id": "2002.10583", "submitter": "Tan Nguyen", "authors": "Bao Wang, Tan M. Nguyen, Andrea L. Bertozzi, Richard G. Baraniuk,\n  Stanley J. Osher", "title": "Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent", "comments": "35 pages, 16 figures, 18 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) with constant momentum and its variants\nsuch as Adam are the optimization algorithms of choice for training deep neural\nnetworks (DNNs). Since DNN training is incredibly computationally expensive,\nthere is great interest in speeding up the convergence. Nesterov accelerated\ngradient (NAG) improves the convergence rate of gradient descent (GD) for\nconvex optimization using a specially designed momentum; however, it\naccumulates error when an inexact gradient is used (such as in SGD), slowing\nconvergence at best and diverging at worst. In this paper, we propose Scheduled\nRestart SGD (SRSGD), a new NAG-style scheme for training DNNs. SRSGD replaces\nthe constant momentum in SGD by the increasing momentum in NAG but stabilizes\nthe iterations by resetting the momentum to zero according to a schedule. Using\na variety of models and benchmarks for image classification, we demonstrate\nthat, in training DNNs, SRSGD significantly improves convergence and\ngeneralization; for instance in training ResNet200 for ImageNet classification,\nSRSGD achieves an error rate of 20.93% vs. the benchmark of 22.13%. These\nimprovements become more significant as the network grows deeper. Furthermore,\non both CIFAR and ImageNet, SRSGD reaches similar or even better error rates\nwith significantly fewer training epochs compared to the SGD baseline.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 23:16:19 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 11:55:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Bao", ""], ["Nguyen", "Tan M.", ""], ["Bertozzi", "Andrea L.", ""], ["Baraniuk", "Richard G.", ""], ["Osher", "Stanley J.", ""]]}, {"id": "2002.10597", "submitter": "Lin Xiao", "authors": "Pengchuan Zhang, Hunter Lang, Qiang Liu and Lin Xiao", "title": "Statistical Adaptive Stochastic Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSR-TR-2020-3", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical adaptive procedure called SALSA for automatically\nscheduling the learning rate (step size) in stochastic gradient methods. SALSA\nfirst uses a smoothed stochastic line-search procedure to gradually increase\nthe learning rate, then automatically switches to a statistical method to\ndecrease the learning rate. The line search procedure ``warms up'' the\noptimization process, reducing the need for expensive trial and error in\nsetting an initial learning rate. The method for decreasing the learning rate\nis based on a new statistical test for detecting stationarity when using a\nconstant step size. Unlike in prior work, our test applies to a broad class of\nstochastic gradient algorithms without modification. The combined method is\nhighly robust and autonomous, and it matches the performance of the best\nhand-tuned learning rate schedules in our experiments on several deep learning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 00:04:16 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Pengchuan", ""], ["Lang", "Hunter", ""], ["Liu", "Qiang", ""], ["Xiao", "Lin", ""]]}, {"id": "2002.10610", "submitter": "M. Hadi Amini", "authors": "Ahmed Imteaj, Urmish Thakker, Shiqiang Wang, Jian Li, M. Hadi Amini", "title": "Federated Learning for Resource-Constrained IoT Devices: Panoramas and\n  State-of-the-art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, devices are equipped with advanced sensors with higher\nprocessing/computing capabilities. Further, widespread Internet availability\nenables communication among sensing devices. As a result, vast amounts of data\nare generated on edge devices to drive Internet-of-Things (IoT), crowdsourcing,\nand other emerging technologies. The collected extensive data can be\npre-processed, scaled, classified, and finally, used for predicting future\nevents using machine learning (ML) methods. In traditional ML approaches, data\nis sent to and processed in a central server, which encounters communication\noverhead, processing delay, privacy leakage, and security issues. To overcome\nthese challenges, each client can be trained locally based on its available\ndata and by learning from the global model. This decentralized learning\nstructure is referred to as Federated Learning (FL). However, in large-scale\nnetworks, there may be clients with varying computational resource\ncapabilities. This may lead to implementation and scalability challenges for FL\ntechniques. In this paper, we first introduce some recently implemented\nreal-life applications of FL. We then emphasize on the core challenges of\nimplementing the FL algorithms from the perspective of resource limitations\n(e.g., memory, bandwidth, and energy budget) of client clients. We finally\ndiscuss open issues associated with FL and highlight future directions in the\nFL area concerning resource-constrained devices.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:03:29 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Imteaj", "Ahmed", ""], ["Thakker", "Urmish", ""], ["Wang", "Shiqiang", ""], ["Li", "Jian", ""], ["Amini", "M. Hadi", ""]]}, {"id": "2002.10614", "submitter": "Yehuda Dar", "authors": "Yehuda Dar, Paul Mayer, Lorenzo Luzi, Richard G. Baraniuk", "title": "Subspace Fitting Meets Regression: The Effects of Supervision and\n  Orthonormality Constraints on Double Descent of Generalization Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the linear subspace fitting problem in the overparameterized\nsetting, where the estimated subspace can perfectly interpolate the training\nexamples. Our scope includes the least-squares solutions to subspace fitting\ntasks with varying levels of supervision in the training data (i.e., the\nproportion of input-output examples of the desired low-dimensional mapping) and\northonormality of the vectors defining the learned operator. This flexible\nfamily of problems connects standard, unsupervised subspace fitting that\nenforces strict orthonormality with a corresponding regression task that is\nfully supervised and does not constrain the linear operator structure. This\nclass of problems is defined over a supervision-orthonormality plane, where\neach coordinate induces a problem instance with a unique pair of supervision\nlevel and softness of orthonormality constraints. We explore this plane and\nshow that the generalization errors of the corresponding subspace fitting\nproblems follow double descent trends as the settings become more supervised\nand less orthonormally constrained.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:31:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 12:03:00 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:55:35 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dar", "Yehuda", ""], ["Mayer", "Paul", ""], ["Luzi", "Lorenzo", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2002.10619", "submitter": "Ananda Theertha Suresh", "authors": "Yishay Mansour and Mehryar Mohri and Jae Ro and Ananda Theertha Suresh", "title": "Three Approaches for Personalization with Applications to Federated\n  Learning", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard objective in machine learning is to train a single model for all\nusers. However, in many learning scenarios, such as cloud computing and\nfederated learning, it is possible to learn a personalized model per user. In\nthis work, we present a systematic learning-theoretic study of personalization.\nWe propose and analyze three approaches: user clustering, data interpolation,\nand model interpolation. For all three approaches, we provide\nlearning-theoretic guarantees and efficient algorithms for which we also\ndemonstrate the performance empirically. All of our algorithms are\nmodel-agnostic and work for any hypothesis class.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:36:43 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 21:02:14 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Ro", "Jae", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2002.10620", "submitter": "Zhi Xu", "authors": "Devavrat Shah, Varun Somani, Qiaomin Xie, Zhi Xu", "title": "On Reinforcement Learning for Turn-based Zero-sum Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding Nash equilibrium for two-player turn-based\nzero-sum games. Inspired by the AlphaGo Zero (AGZ) algorithm, we develop a\nReinforcement Learning based approach. Specifically, we propose\nExplore-Improve-Supervise (EIS) method that combines \"exploration\", \"policy\nimprovement\"' and \"supervised learning\" to find the value function and policy\nassociated with Nash equilibrium. We identify sufficient conditions for\nconvergence and correctness for such an approach. For a concrete instance of\nEIS where random policy is used for \"exploration\", Monte-Carlo Tree Search is\nused for \"policy improvement\" and Nearest Neighbors is used for \"supervised\nlearning\", we establish that this method finds an $\\varepsilon$-approximate\nvalue function of Nash equilibrium in $\\widetilde{O}(\\varepsilon^{-(d+4)})$\nsteps when the underlying state-space of the game is continuous and\n$d$-dimensional. This is nearly optimal as we establish a lower bound of\n$\\widetilde{\\Omega}(\\varepsilon^{-(d+2)})$ for any policy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:40:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Shah", "Devavrat", ""], ["Somani", "Varun", ""], ["Xie", "Qiaomin", ""], ["Xu", "Zhi", ""]]}, {"id": "2002.10621", "submitter": "Diego Romeres", "authors": "Alberto Dalla Libera, Diego Romeres, Devesh K. Jha, Bill Yerazunis and\n  Daniel Nikovski", "title": "Model-Based Reinforcement Learning for Physical Systems Without Velocity\n  and Acceleration Measurements", "comments": "Accepted at RA-L", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a derivative-free model learning framework for\nReinforcement Learning (RL) algorithms based on Gaussian Process Regression\n(GPR). In many mechanical systems, only positions can be measured by the\nsensing instruments. Then, instead of representing the system state as\nsuggested by the physics with a collection of positions, velocities, and\naccelerations, we define the state as the set of past position measurements.\nHowever, the equation of motions derived by physical first principles cannot be\ndirectly applied in this framework, being functions of velocities and\naccelerations. For this reason, we introduce a novel derivative-free\nphysically-inspired kernel, which can be easily combined with nonparametric\nderivative-free Gaussian Process models. Tests performed on two real platforms\nshow that the considered state definition combined with the proposed model\nimproves estimation performance and data-efficiency w.r.t. traditional models\nbased on GPR. Finally, we validate the proposed framework by solving two RL\ncontrol problems for two real robotic systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:58:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Libera", "Alberto Dalla", ""], ["Romeres", "Diego", ""], ["Jha", "Devesh K.", ""], ["Yerazunis", "Bill", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2002.10631", "submitter": "Pascal Poupart", "authors": "Amur Ghose, Abdullah Rashwan, Pascal Poupart", "title": "Batch norm with entropic regularization turns deterministic autoencoders\n  into generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder is a well defined deep generative model that\nutilizes an encoder-decoder framework where an encoding neural network outputs\na non-deterministic code for reconstructing an input. The encoder achieves this\nby sampling from a distribution for every input, instead of outputting a\ndeterministic code per input. The great advantage of this process is that it\nallows the use of the network as a generative model for sampling from the data\ndistribution beyond provided samples for training. We show in this work that\nutilizing batch normalization as a source for non-determinism suffices to turn\ndeterministic autoencoders into generative models on par with variational ones,\nso long as we add a suitable entropic regularization to the training objective.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 02:42:18 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ghose", "Amur", ""], ["Rashwan", "Abdullah", ""], ["Poupart", "Pascal", ""]]}, {"id": "2002.10637", "submitter": "Shaowu Pan", "authors": "Shaowu Pan, Nicholas Arnold-Medabalimi, Karthik Duraisamy", "title": "Sparsity-promoting algorithms for the discovery of informative Koopman\n  invariant subspaces", "comments": "48 pages", "journal-ref": null, "doi": "10.1017/jfm.2021.271", "report-no": null, "categories": "math.DS physics.flu-dyn stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Koopman decomposition is a non-linear generalization of eigen-decomposition,\nand is being increasingly utilized in the analysis of spatio-temporal dynamics.\nWell-known techniques such as the dynamic mode decomposition (DMD) and its\nlinear variants provide approximations to the Koopman operator, and have been\napplied extensively in many fluid dynamic problems. Despite being endowed with\na richer dictionary of nonlinear observables, nonlinear variants of the DMD,\nsuch as extended/kernel dynamic mode decomposition (EDMD/KDMD) are seldom\napplied to large-scale problems primarily due to the difficulty of discerning\nthe Koopman invariant subspace from thousands of resulting Koopman eigenmodes.\nTo address this issue, we propose a framework based on multi-task feature\nlearning to extract the most informative Koopman invariant subspace by removing\nredundant and spurious Koopman triplets. In particular, we develop a pruning\nprocedure that penalizes departure from linear evolution. These algorithms can\nbe viewed as sparsity promoting extensions of EDMD/KDMD. Further, we extend\nKDMD to a continuous-time setting and show a relationship between the present\nalgorithm, sparsity-promoting DMD, and an empirical criterion from the\nviewpoint of non-convex optimization. The effectiveness of our algorithm is\ndemonstrated on examples ranging from simple dynamical systems to\ntwo-dimensional cylinder wake flows at different Reynolds numbers and a\nthree-dimensional turbulent ship air-wake flow. The latter two problems are\ndesigned such that very strong nonlinear transients are present, thus requiring\nan accurate approximation of the Koopman operator. Underlying physical\nmechanisms are analyzed, with an emphasis on characterizing transient dynamics.\nThe results are compared to existing theoretical expositions and numerical\napproximations.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:02:09 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 01:10:42 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 16:31:24 GMT"}, {"version": "v4", "created": "Sat, 2 Jan 2021 23:13:28 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Pan", "Shaowu", ""], ["Arnold-Medabalimi", "Nicholas", ""], ["Duraisamy", "Karthik", ""]]}, {"id": "2002.10645", "submitter": "Marius Hofert", "authors": "Marius Hofert, Avinash Prasad, Mu Zhu", "title": "Multivariate time-series modeling with generative neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative moment matching networks (GMMNs) are introduced as dependence\nmodels for the joint innovation distribution of multivariate time series (MTS).\nFollowing the popular copula-GARCH approach for modeling dependent MTS data, a\nframework based on a GMMN-GARCH approach is presented. First, ARMA-GARCH models\nare utilized to capture the serial dependence within each univariate marginal\ntime series. Second, if the number of marginal time series is large, principal\ncomponent analysis (PCA) is used as a dimension-reduction step. Last, the\nremaining cross-sectional dependence is modeled via a GMMN, the main\ncontribution of this work. GMMNs are highly flexible and easy to simulate from,\nwhich is a major advantage over the copula-GARCH approach. Applications\ninvolving yield curve modeling and the analysis of foreign exchange-rate\nreturns demonstrate the utility of the GMMN-GARCH approach, especially in terms\nof producing better empirical predictive distributions and making better\nprobabilistic forecasts.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:26:52 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 14:54:36 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 05:21:52 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hofert", "Marius", ""], ["Prasad", "Avinash", ""], ["Zhu", "Mu", ""]]}, {"id": "2002.10648", "submitter": "Haotao Wang", "authors": "Haotao Wang, Tianlong Chen, Zhangyang Wang and Kede Ma", "title": "I Am Going MAD: Maximum Discrepancy Competition for Comparing\n  Classifiers Adaptively", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of hierarchical representations for image classification has\nexperienced an impressive series of successes due in part to the availability\nof large-scale labeled data for training. On the other hand, the trained\nclassifiers have traditionally been evaluated on small and fixed sets of test\nimages, which are deemed to be extremely sparsely distributed in the space of\nall natural images. It is thus questionable whether recent performance\nimprovements on the excessively re-used test sets generalize to real-world\nnatural images with much richer content variations. Inspired by efficient\nstimulus selection for testing perceptual models in psychophysical and\nphysiological studies, we present an alternative framework for comparing image\nclassifiers, which we name the MAximum Discrepancy (MAD) competition. Rather\nthan comparing image classifiers using fixed test images, we adaptively sample\na small test set from an arbitrarily large corpus of unlabeled images so as to\nmaximize the discrepancies between the classifiers, measured by the distance\nover WordNet hierarchy. Human labeling on the resulting model-dependent image\nsets reveals the relative performance of the competing classifiers, and\nprovides useful insights on potential ways to improve them. We report the MAD\ncompetition results of eleven ImageNet classifiers while noting that the\nframework is readily extensible and cost-effective to add future classifiers\ninto the competition. Codes can be found at https://github.com/TAMU-VITA/MAD.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:32:29 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wang", "Haotao", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""], ["Ma", "Kede", ""]]}, {"id": "2002.10657", "submitter": "Satrajit Chatterjee", "authors": "Satrajit Chatterjee", "title": "Coherent Gradients: An Approach to Understanding Generalization in\n  Gradient Descent-based Optimization", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open question in the Deep Learning community is why neural networks\ntrained with Gradient Descent generalize well on real datasets even though they\nare capable of fitting random data. We propose an approach to answering this\nquestion based on a hypothesis about the dynamics of gradient descent that we\ncall Coherent Gradients: Gradients from similar examples are similar and so the\noverall gradient is stronger in certain directions where these reinforce each\nother. Thus changes to the network parameters during training are biased\ntowards those that (locally) simultaneously benefit many examples when such\nsimilarity exists. We support this hypothesis with heuristic arguments and\nperturbative experiments and outline how this can explain several common\nempirical observations about Deep Learning. Furthermore, our analysis is not\njust descriptive, but prescriptive. It suggests a natural modification to\ngradient descent that can greatly reduce overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:59:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chatterjee", "Satrajit", ""]]}, {"id": "2002.10670", "submitter": "Eric Hulburd", "authors": "Eric Hulburd", "title": "Exploring BERT Parameter Efficiency on the Stanford Question Answering\n  Dataset v2.0", "comments": "11 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the parameter efficiency of BERT arXiv:1810.04805 on\nversion 2.0 of the Stanford Question Answering dataset (SQuAD2.0). We evaluate\nthe parameter efficiency of BERT while freezing a varying number of final\ntransformer layers as well as including the adapter layers proposed in\narXiv:1902.00751. Additionally, we experiment with the use of context-aware\nconvolutional (CACNN) filters, as described in arXiv:1709.08294v3, as a final\naugmentation layer for the SQuAD2.0 tasks.\n  This exploration is motivated in part by arXiv:1907.10597, which made a\ncompelling case for broadening the evaluation criteria of artificial\nintelligence models to include various measures of resource efficiency. While\nwe do not evaluate these models based on their floating point operation\nefficiency as proposed in arXiv:1907.10597, we examine efficiency with respect\nto training time, inference time, and total number of model parameters. Our\nresults largely corroborate those of arXiv:1902.00751 for adapter modules,\nwhile also demonstrating that gains in F1 score from adding context-aware\nconvolutional filters are not practical due to the increase in training and\ninference time.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:09:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 05:16:37 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hulburd", "Eric", ""]]}, {"id": "2002.10673", "submitter": "Lijun Ding", "authors": "Lijun Ding, Madeleine Udell", "title": "On the simplicity and conditioning of low rank semidefinite programs", "comments": "24 pages, 1 figure, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank matrix recovery problems appear widely in statistics, combinatorics,\nand imaging. One celebrated method for solving these problems is to formulate\nand solve a semidefinite program (SDP). It is often known that the exact\nsolution to the SDP with perfect data recovers the solution to the original low\nrank matrix recovery problem. It is more challenging to show that an\napproximate solution to the SDP formulated with noisy problem data acceptably\nsolves the original problem; arguments are usually ad hoc for each problem\nsetting, and can be complex.\n  In this note, we identify a set of conditions that we call simplicity that\nlimit the error due to noisy problem data or incomplete convergence. In this\nsense, simple SDPs are robust: simple SDPs can be (approximately) solved\nefficiently at scale; and the resulting approximate solutions, even with noisy\ndata, can be trusted. Moreover, we show that simplicity holds generically, and\nalso for many structured low rank matrix recovery problems, including the\nstochastic block model, $\\mathbb{Z}_2$ synchronization, and matrix completion.\nFormally, we call an SDP simple if it has a surjective constraint map, admits a\nunique primal and dual solution pair, and satisfies strong duality and strict\ncomplementarity.\n  However, simplicity is not a panacea: we show the Burer-Monteiro formulation\nof the SDP may have spurious second-order critical points, even for a simple\nSDP with a rank 1 solution.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:18:36 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 03:56:03 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ding", "Lijun", ""], ["Udell", "Madeleine", ""]]}, {"id": "2002.10678", "submitter": "Yuki Ohnishi", "authors": "Yuki Ohnishi and Jean Honorio", "title": "Novel Change of Measure Inequalities with Applications to PAC-Bayesian\n  Bounds and Monte Carlo Estimation", "comments": "20 pages", "journal-ref": "Artificial Intelligence and Statistics (AISTATS), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce several novel change of measure inequalities for two families of\ndivergences: $f$-divergences and $\\alpha$-divergences. We show how the\nvariational representation for $f$-divergences leads to novel change of measure\ninequalities. We also present a multiplicative change of measure inequality for\n$\\alpha$-divergences and a generalized version of Hammersley-Chapman-Robbins\ninequality. Finally, we present several applications of our change of measure\ninequalities, including PAC-Bayesian bounds for various classes of losses and\nnon-asymptotic intervals for Monte Carlo estimates.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:36:22 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 10:11:04 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ohnishi", "Yuki", ""], ["Honorio", "Jean", ""]]}, {"id": "2002.10689", "submitter": "Yilun Xu", "authors": "Yilun Xu, Shengjia Zhao, Jiaming Song, Russell Stewart, Stefano Ermon", "title": "A Theory of Usable Information Under Computational Constraints", "comments": "ICLR 2020 (Talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for reasoning about information in complex\nsystems. Our foundation is based on a variational extension of Shannon's\ninformation theory that takes into account the modeling power and computational\nconstraints of the observer. The resulting \\emph{predictive\n$\\mathcal{V}$-information} encompasses mutual information and other notions of\ninformativeness such as the coefficient of determination. Unlike Shannon's\nmutual information and in violation of the data processing inequality,\n$\\mathcal{V}$-information can be created through computation. This is\nconsistent with deep neural networks extracting hierarchies of progressively\nmore informative features in representation learning. Additionally, we show\nthat by incorporating computational constraints, $\\mathcal{V}$-information can\nbe reliably estimated from data even in high dimensions with PAC-style\nguarantees. Empirically, we demonstrate predictive $\\mathcal{V}$-information is\nmore effective than mutual information for structure learning and fair\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 06:09:30 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "Yilun", ""], ["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Stewart", "Russell", ""], ["Ermon", "Stefano", ""]]}, {"id": "2002.10703", "submitter": "Xiaodong Qi", "authors": "Xiaodong Qi, Lansheng Han", "title": "G\\\"odel's Sentence Is An Adversarial Example But Unsolvable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, different types of adversarial examples from different\nfields have emerged endlessly, including purely natural ones without\nperturbations. A variety of defenses are proposed and then broken quickly. Two\nfundamental questions need to be asked: What's the reason for the existence of\nadversarial examples and are adversarial examples unsolvable? In this paper, we\nwill show the reason for the existence of adversarial examples is there are\nnon-isomorphic natural explanations that can all explain data set.\nSpecifically, for two natural explanations of being true and provable,\nG\\\"odel's sentence is an adversarial example but ineliminable. It can't be\nsolved by the re-accumulation of data set or the re-improvement of learning\nalgorithm. Finally, from the perspective of computability, we will prove the\nincomputability for adversarial examples, which are unrecognizable.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:20:17 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Qi", "Xiaodong", ""], ["Han", "Lansheng", ""]]}, {"id": "2002.10709", "submitter": "Arkopal Choudhury", "authors": "Arkopal Choudhury and Michael R. Kosorok", "title": "Missing Data Imputation for Classification Problems", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imputation of missing data is a common application in various classification\nproblems where the feature training matrix has missingness. A widely used\nsolution to this imputation problem is based on the lazy learning technique,\n$k$-nearest neighbor (kNN) approach. However, most of the previous work on\nmissing data does not take into account the presence of the class label in the\nclassification problem. Also, existing kNN imputation methods use variants of\nMinkowski distance as a measure of distance, which does not work well with\nheterogeneous data. In this paper, we propose a novel iterative kNN imputation\ntechnique based on class weighted grey distance between the missing datum and\nall the training data. Grey distance works well in heterogeneous data with\nmissing instances. The distance is weighted by Mutual Information (MI) which is\na measure of feature relevance between the features and the class label. This\nensures that the imputation of the training data is directed towards improving\nclassification performance. This class weighted grey kNN imputation algorithm\ndemonstrates improved performance when compared to other kNN imputation\nalgorithms, as well as standard imputation algorithms such as MICE and\nmissForest, in imputation and classification problems. These problems are based\non simulated scenarios and UCI datasets with various rates of missingness.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:48:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Choudhury", "Arkopal", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "2002.10711", "submitter": "Javier Fernandez-Marques", "authors": "Javier Fernandez-Marques, Paul N. Whatmough, Andrew Mundy, Matthew\n  Mattina", "title": "Searching for Winograd-aware Quantized Networks", "comments": "Published as a conference paper at MLSys 2020", "journal-ref": "Proceedings of Machine Learning and Systems (2020), 14-29", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight architectural designs of Convolutional Neural Networks (CNNs)\ntogether with quantization have paved the way for the deployment of demanding\ncomputer vision applications on mobile devices. Parallel to this, alternative\nformulations to the convolution operation such as FFT, Strassen and Winograd,\nhave been adapted for use in CNNs offering further speedups. Winograd\nconvolutions are the fastest known algorithm for spatially small convolutions,\nbut exploiting their full potential comes with the burden of numerical error,\nrendering them unusable in quantized contexts. In this work we propose a\nWinograd-aware formulation of convolution layers which exposes the numerical\ninaccuracies introduced by the Winograd transformations to the learning of the\nmodel parameters, enabling the design of competitive quantized models without\nimpacting model size. We also address the source of the numerical error and\npropose a relaxation on the form of the transformation matrices, resulting in\nup to 10% higher classification accuracy on CIFAR-10. Finally, we propose\nwiNAS, a neural architecture search (NAS) framework that jointly optimizes a\ngiven macro-architecture for accuracy and latency leveraging Winograd-aware\nlayers. A Winograd-aware ResNet-18 optimized with wiNAS for CIFAR-10 results in\n2.66x speedup compared to im2row, one of the most widely used optimized\nconvolution implementations, with no loss in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:53:53 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Fernandez-Marques", "Javier", ""], ["Whatmough", "Paul N.", ""], ["Mundy", "Andrew", ""], ["Mattina", "Matthew", ""]]}, {"id": "2002.10716", "submitter": "Aditi Raghunathan", "authors": "Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi and Percy\n  Liang", "title": "Understanding and Mitigating the Tradeoff Between Robustness and\n  Accuracy", "comments": "Appearing at International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training augments the training set with perturbations to improve\nthe robust error (over worst-case perturbations), but it often leads to an\nincrease in the standard error (on unperturbed test inputs). Previous\nexplanations for this tradeoff rely on the assumption that no predictor in the\nhypothesis class has low standard and robust error. In this work, we precisely\ncharacterize the effect of augmentation on the standard error in linear\nregression when the optimal linear predictor has zero standard and robust\nerror. In particular, we show that the standard error could increase even when\nthe augmented perturbations have noiseless observations from the optimal linear\npredictor. We then prove that the recently proposed robust self-training (RST)\nestimator improves robust error without sacrificing standard error for\nnoiseless linear regression. Empirically, for neural networks, we find that RST\nwith different adversarial training methods improves both standard and robust\nerror for random and adversarial rotations and adversarial $\\ell_\\infty$\nperturbations in CIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:03:01 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 21:03:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Raghunathan", "Aditi", ""], ["Xie", "Sang Michael", ""], ["Yang", "Fanny", ""], ["Duchi", "John", ""], ["Liang", "Percy", ""]]}, {"id": "2002.10718", "submitter": "Martin Brossard", "authors": "Martin Brossard (CAOR), Silvere Bonnabel (UNC), Axel Barrau (CAOR)", "title": "Denoising IMU Gyroscopes with Deep Learning for Open-Loop Attitude\n  Estimation", "comments": "IEEE Robotics and Automation Letters, IEEE In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a learning method for denoising gyroscopes of Inertial\nMeasurement Units (IMUs) using ground truth data, and estimating in real time\nthe orientation (attitude) of a robot in dead reckoning. The obtained algorithm\noutperforms the state-of-the-art on the (unseen) test sequences. The obtained\nperformances are achieved thanks to a well-chosen model, a proper loss function\nfor orientation increments, and through the identification of key points when\ntraining with high-frequency inertial data. Our approach builds upon a neural\nnetwork based on dilated convolutions, without requiring any recurrent neural\nnetwork. We demonstrate how efficient our strategy is for 3D attitude\nestimation on the EuRoC and TUM-VI datasets. Interestingly, we observe our dead\nreckoning algorithm manages to beat top-ranked visual-inertial odometry systems\nin terms of attitude estimation although it does not use vision sensors. We\nbelieve this paper offers new perspectives for visual-inertial localization and\nconstitutes a step toward more efficient learning methods involving IMUs. Our\nopen-source implementation is available at\nhttps://github.com/mbrossar/denoise-imu-gyro.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:04:31 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 07:43:00 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Brossard", "Martin", "", "CAOR"], ["Bonnabel", "Silvere", "", "UNC"], ["Barrau", "Axel", "", "CAOR"]]}, {"id": "2002.10733", "submitter": "Alexander Levine", "authors": "Alexander Levine, Soheil Feizi", "title": "(De)Randomized Smoothing for Certifiable Defense against Patch Attacks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patch adversarial attacks on images, in which the attacker can distort pixels\nwithin a region of bounded size, are an important threat model since they\nprovide a quantitative model for physical adversarial attacks. In this paper,\nwe introduce a certifiable defense against patch attacks that guarantees for a\ngiven image and patch attack size, no patch adversarial examples exist. Our\nmethod is related to the broad class of randomized smoothing robustness schemes\nwhich provide high-confidence probabilistic robustness certificates. By\nexploiting the fact that patch attacks are more constrained than general sparse\nattacks, we derive meaningfully large robustness certificates against them.\nAdditionally, in contrast to smoothing-based defenses against L_p and sparse\nattacks, our defense method against patch attacks is de-randomized, yielding\nimproved, deterministic certificates. Compared to the existing patch\ncertification method proposed by Chiang et al. (2020), which relies on interval\nbound propagation, our method can be trained significantly faster, achieves\nhigh clean and certified robust accuracy on CIFAR-10, and provides certificates\nat ImageNet scale. For example, for a 5-by-5 patch attack on CIFAR-10, our\nmethod achieves up to around 57.6% certified accuracy (with a classifier with\naround 83.8% clean accuracy), compared to at most 30.3% certified accuracy for\nthe existing method (with a classifier with around 47.8% clean accuracy). Our\nresults effectively establish a new state-of-the-art of certifiable defense\nagainst patch attacks on CIFAR-10 and ImageNet. Code is available at\nhttps://github.com/alevine0/patchSmoothing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:39:46 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 19:09:10 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 06:36:56 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Levine", "Alexander", ""], ["Feizi", "Soheil", ""]]}, {"id": "2002.10738", "submitter": "Anji Liu", "authors": "Anji Liu, Yitao Liang, Guy Van den Broeck", "title": "Off-Policy Deep Reinforcement Learning with Analogous Disentangled\n  Exploration", "comments": "In Proc. of the 19th International Conference on Autonomous Agents\n  and Multiagent Systems, IFAAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning (RL) is concerned with learning a rewarding\npolicy by executing another policy that gathers samples of experience. While\nthe former policy (i.e. target policy) is rewarding but in-expressive (in most\ncases, deterministic), doing well in the latter task, in contrast, requires an\nexpressive policy (i.e. behavior policy) that offers guided and effective\nexploration. Contrary to most methods that make a trade-off between optimality\nand expressiveness, disentangled frameworks explicitly decouple the two\nobjectives, which each is dealt with by a distinct separate policy. Although\nbeing able to freely design and optimize the two policies with respect to their\nown objectives, naively disentangling them can lead to inefficient learning or\nstability issues. To mitigate this problem, our proposed method Analogous\nDisentangled Actor-Critic (ADAC) designs analogous pairs of actors and critics.\nSpecifically, ADAC leverages a key property about Stein variational gradient\ndescent (SVGD) to constraint the expressive energy-based behavior policy with\nrespect to the target one for effective exploration. Additionally, an analogous\ncritic pair is introduced to incorporate intrinsic rewards in a principled\nmanner, with theoretical guarantees on the overall learning stability and\neffectiveness. We empirically evaluate environment-reward-only ADAC on 14\ncontinuous-control tasks and report the state-of-the-art on 10 of them. We\nfurther demonstrate ADAC, when paired with intrinsic rewards, outperform\nalternatives in exploration-challenging tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:49:11 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 22:19:22 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liu", "Anji", ""], ["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2002.10766", "submitter": "Michele Lombardi", "authors": "Fabrizio Detassis, Michele Lombardi, Michela Milano", "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding constraint support in Machine Learning has the potential to address\noutstanding issues in data-driven AI systems, such as safety and fairness.\nExisting approaches typically apply constrained optimization techniques to ML\ntraining, enforce constraint satisfaction by adjusting the model design, or use\nconstraints to correct the output. Here, we investigate a different,\ncomplementary, strategy based on \"teaching\" constraint satisfaction to a\nsupervised ML method via the direct use of a state-of-the-art constraint\nsolver: this enables taking advantage of decades of research on constrained\noptimization with limited effort. In practice, we use a decomposition scheme\nalternating master steps (in charge of enforcing the constraints) and learner\nsteps (where any supervised ML model and training algorithm can be employed).\nThe process leads to approximate constraint satisfaction in general, and\nconvergence properties are difficult to establish; despite this fact, we found\nempirically that even a na\\\"ive setup of our approach performs well on ML tasks\nwith fairness constraints, and on classical datasets with synthetic\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:47:39 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 16:39:24 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Detassis", "Fabrizio", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10767", "submitter": "Joel Dabrowski Dr", "authors": "Joel Janek Dabrowski and Ashfaqur Rahman", "title": "Sequence-to-Sequence Imputation of Missing Sensor Data", "comments": null, "journal-ref": "In: Liu J., Bailey J. (eds) AI 2019: Advances in Artificial\n  Intelligence. AI 2019. Lecture Notes in Computer Science, vol 11919.\n  Springer, Cham", "doi": "10.1007/978-3-030-35288-2_22", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the sequence-to-sequence (encoder-decoder) model is considered the\nstate-of-the-art in deep learning sequence models, there is little research\ninto using this model for recovering missing sensor data. The key challenge is\nthat the missing sensor data problem typically comprises three sequences (a\nsequence of observed samples, followed by a sequence of missing samples,\nfollowed by another sequence of observed samples) whereas, the\nsequence-to-sequence model only considers two sequences (an input sequence and\nan output sequence). We address this problem by formulating a\nsequence-to-sequence in a novel way. A forward RNN encodes the data observed\nbefore the missing sequence and a backward RNN encodes the data observed after\nthe missing sequence. A decoder decodes the two encoders in a novel way to\npredict the missing data. We demonstrate that this model produces the lowest\nerrors in 12% more cases than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:51:20 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dabrowski", "Joel Janek", ""], ["Rahman", "Ashfaqur", ""]]}, {"id": "2002.10774", "submitter": "Pietro Di Stefano", "authors": "Pietro G. Di Stefano, James M. Hickey, Vlasios Vasileiou", "title": "Counterfactual fairness: removing direct effects through regularization", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building machine learning models that are fair with respect to an\nunprivileged group is a topical problem. Modern fairness-aware algorithms often\nignore causal effects and enforce fairness through modifications applicable to\nonly a subset of machine learning models. In this work, we propose a new\ndefinition of fairness that incorporates causality through the Controlled\nDirect Effect (CDE). We develop regularizations to tackle classical fairness\nmeasures and present a causal regularization that satisfies our new fairness\ndefinition by removing the impact of unprivileged group variables on the model\noutcomes as measured by the CDE. These regularizations are applicable to any\nmodel trained using by iteratively minimizing a loss through differentiation.\nWe demonstrate our approaches using both gradient boosting and logistic\nregression on: a synthetic dataset, the UCI Adult (Census) Dataset, and a\nreal-world credit-risk dataset. Our results were found to mitigate unfairness\nfrom the predictions with small reductions in model performance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:13:55 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 11:28:34 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Di Stefano", "Pietro G.", ""], ["Hickey", "James M.", ""], ["Vasileiou", "Vlasios", ""]]}, {"id": "2002.10778", "submitter": "Xiangming Meng", "authors": "Xiangming Meng and Roman Bachmann and Mohammad Emtiyaz Khan", "title": "Training Binary Neural Networks using the Bayesian Learning Rule", "comments": "accepted by ICML 2020, the camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with binary weights are computation-efficient and\nhardware-friendly, but their training is challenging because it involves a\ndiscrete optimization problem. Surprisingly, ignoring the discrete nature of\nthe problem and using gradient-based methods, such as the Straight-Through\nEstimator, still works well in practice. This raises the question: are there\nprincipled approaches which justify such methods? In this paper, we propose\nsuch an approach using the Bayesian learning rule. The rule, when applied to\nestimate a Bernoulli distribution over the binary weights, results in an\nalgorithm which justifies some of the algorithmic choices made by the previous\napproaches. The algorithm not only obtains state-of-the-art performance, but\nalso enables uncertainty estimation for continual learning to avoid\ncatastrophic forgetting. Our work provides a principled approach for training\nbinary neural networks which justifies and extends existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:20:10 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 09:04:24 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 14:48:33 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 00:48:15 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Meng", "Xiangming", ""], ["Bachmann", "Roman", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2002.10790", "submitter": "Yifan Hu", "authors": "Yifan Hu, Siqi Zhang, Xin Chen, Niao He", "title": "Biased Stochastic Gradient Descent for Conditional Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Stochastic Optimization (CSO) covers a variety of applications\nranging from meta-learning and causal inference to invariant learning. However,\nconstructing unbiased gradient estimates in CSO is challenging due to the\ncomposition structure. As an alternative, we propose a biased stochastic\ngradient descent (BSGD) algorithm and study the bias-variance tradeoff under\ndifferent structural assumptions. We establish the sample complexities of BSGD\nfor strongly convex, convex, and weakly convex objectives, under smooth and\nnon-smooth conditions. We also provide matching lower bounds of BSGD for convex\nCSO objectives. Extensive numerical experiments are conducted to illustrate the\nperformance of BSGD on robust logistic regression, model-agnostic meta-learning\n(MAML), and instrumental variable regression (IV).\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:57:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hu", "Yifan", ""], ["Zhang", "Siqi", ""], ["Chen", "Xin", ""], ["He", "Niao", ""]]}, {"id": "2002.10791", "submitter": "Soorya Gopalakrishnan", "authors": "Metehan Cekic, Soorya Gopalakrishnan, Upamanyu Madhow", "title": "Wireless Fingerprinting via Deep Learning: The Impact of Confounding\n  Factors", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we distinguish between two wireless transmitters sending exactly the same\nmessage, using the same protocol? The opportunity for doing so arises due to\nsubtle nonlinear variations across transmitters, even those made by the same\nmanufacturer. Since these effects are difficult to model explicitly, we\ninvestigate learning device fingerprints using complex-valued deep neural\nnetworks (DNNs) that take as input the complex baseband signal at the receiver.\nWe ask whether such fingerprints can be made robust to distribution shifts\nacross time and locations due to clock drift and variations in the wireless\nchannel. In this paper, we point out that, unless proactively discouraged from\ndoing so, DNNs learn these strong confounding features rather than the\nnonlinear device-specific characteristics that we seek to learn. We propose and\nevaluate strategies, based on augmentation and estimation, to promote\ngeneralization across realizations of these confounding factors, using data\nfrom WiFi and ADS-B protocols. We conclude that, while DNN training has the\nadvantage of not requiring explicit signal models, significant modeling\ninsights are required to focus the learning on the effects we wish to capture.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:02:45 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 20:09:07 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 10:59:29 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Cekic", "Metehan", ""], ["Gopalakrishnan", "Soorya", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "2002.10816", "submitter": "Edouard Leurent", "authors": "Edouard Leurent and Denis Efimov and Odalric-Ambrym Maillard", "title": "Robust-Adaptive Control of Linear Systems: beyond Quadratic Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust and adaptive model predictive control (MPC)\nof a linear system, with unknown parameters that are learned along the way\n(adaptive), in a critical setting where failures must be prevented (robust).\nThis problem has been studied from different perspectives by different\ncommunities. However, the existing theory deals only with the case of quadratic\ncosts (the LQ problem), which limits applications to stabilisation and tracking\ntasks only. In order to handle more general (non-convex) costs that naturally\narise in many practical problems, we carefully select and bring together\nseveral tools from different communities, namely non-asymptotic linear\nregression, recent results in interval prediction, and tree-based planning.\nCombining and adapting the theoretical guarantees at each layer is non trivial,\nand we provide the first end-to-end suboptimality analysis for this setting.\nInterestingly, our analysis naturally adapts to handle many models and combines\nwith a data-driven robust model selection strategy, which enables to relax the\nmodelling assumptions. Last, we strive to preserve tractability at any stage of\nthe method, that we illustrate on two challenging simulated environments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:24:17 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:15:40 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Leurent", "Edouard", ""], ["Efimov", "Denis", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "2002.10819", "submitter": "Darko Stern", "authors": "Stefan Eggenreich, Christian Payer, Martin Urschler, Darko \\v{S}tern", "title": "Variational Inference and Bayesian CNNs for Uncertainty Estimation in\n  Multi-Factorial Bone Age Prediction", "comments": "accepted at Medical Imaging Meets NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Additionally to the extensive use in clinical medicine, biological age (BA)\nin legal medicine is used to assess unknown chronological age (CA) in\napplications where identification documents are not available. Automatic\nmethods for age estimation proposed in the literature are predicting point\nestimates, which can be misleading without the quantification of predictive\nuncertainty. In our multi-factorial age estimation method from MRI data, we\nused the Variational Inference approach to estimate the uncertainty of a\nBayesian CNN model. Distinguishing model uncertainty from data uncertainty, we\ninterpreted data uncertainty as biological variation, i.e. the range of\npossible CA of subjects having the same BA.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:30:21 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Eggenreich", "Stefan", ""], ["Payer", "Christian", ""], ["Urschler", "Martin", ""], ["\u0160tern", "Darko", ""]]}, {"id": "2002.10837", "submitter": "Imke Mayer", "authors": "Imke Mayer, Julie Josse, F\\'elix Raimundo, Jean-Philippe Vert", "title": "MissDeepCausal: Causal Inference from Incomplete Data Using Deep Latent\n  Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring causal effects of a treatment, intervention or policy from\nobservational data is central to many applications. However, state-of-the-art\nmethods for causal inference seldom consider the possibility that covariates\nhave missing values, which is ubiquitous in many real-world analyses. Missing\ndata greatly complicate causal inference procedures as they require an adapted\nunconfoundedness hypothesis which can be difficult to justify in practice. We\ncircumvent this issue by considering latent confounders whose distribution is\nlearned through variational autoencoders adapted to missing values. They can be\nused either as a pre-processing step prior to causal inference but we also\nsuggest to embed them in a multiple imputation strategy to take into account\nthe variability due to missing values. Numerical experiments demonstrate the\neffectiveness of the proposed methodology especially for non-linear models\ncompared to competitors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:58:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mayer", "Imke", ""], ["Josse", "Julie", ""], ["Raimundo", "F\u00e9lix", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2002.10855", "submitter": "Ryohei Hisano", "authors": "Takahiro Yoshida, Ryohei Hisano, Takaaki Ohnishi", "title": "Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy\n  Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are widely used to discover the latent representation of a set\nof documents. The two canonical models are latent Dirichlet allocation, and\nGaussian latent Dirichlet allocation, where the former uses multinomial\ndistributions over words, and the latter uses multivariate Gaussian\ndistributions over pre-trained word embedding vectors as the latent topic\nrepresentations, respectively. Compared with latent Dirichlet allocation,\nGaussian latent Dirichlet allocation is limited in the sense that it does not\ncapture the polysemy of a word such as ``bank.'' In this paper, we show that\nGaussian latent Dirichlet allocation could recover the ability to capture\npolysemy by introducing a hierarchical structure in the set of topics that the\nmodel can use to represent a given document. Our Gaussian hierarchical latent\nDirichlet allocation significantly improves polysemy detection compared with\nGaussian-based models and provides more parsimonious topic representations\ncompared with hierarchical latent Dirichlet allocation. Our extensive\nquantitative experiments show that our model also achieves better topic\ncoherence and held-out document predictive accuracy over a wide range of corpus\nand word embedding vectors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 13:52:20 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yoshida", "Takahiro", ""], ["Hisano", "Ryohei", ""], ["Ohnishi", "Takaaki", ""]]}, {"id": "2002.10870", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Marco Valtorta, Pooyan Jamshidi", "title": "AMP Chain Graphs: Minimal Separators and Structure Learning Algorithms", "comments": "This is an arXiv version of the paper that has been accepted for\n  publication in the Journal of Artificial Intelligence Research (JAIR). arXiv\n  admin note: text overlap with arXiv:1211.3295 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding a minimal separator in an\nAndersson-Madigan-Perlman chain graph (AMP CG), namely, finding a set Z of\nnodes that separates a given nonadjacent pair of nodes such that no proper\nsubset of Z separates that pair. We analyze several versions of this problem\nand offer polynomial-time algorithms for each. These include finding a minimal\nseparator from a restricted set of nodes, finding a minimal separator for two\ngiven disjoint sets, and testing whether a given separator is minimal. To\naddress the problem of learning the structure of AMP CGs from data, we show\nthat the PC-like algorithm (Pena, 2012) is order-dependent, in the sense that\nthe output can depend on the order in which the variables are given. We propose\nseveral modifications of the PC-like algorithm that remove part or all of this\norder-dependence. We also extend the decomposition-based approach for learning\nBayesian networks (BNs) proposed by (Xie et al., 2006) to learn AMP CGs, which\ninclude BNs as a special case, under the faithfulness assumption. We prove the\ncorrectness of our extension using the minimal separator results. Using\nstandard benchmarks and synthetically generated models and data in our\nexperiments demonstrate the competitive performance of our decomposition-based\nmethod, called LCD-AMP, in comparison with the (modified versions of) PC-like\nalgorithm. The LCD-AMP algorithm usually outperforms the PC-like algorithm, and\nour modifications of the PC-like algorithm learn structures that are more\nsimilar to the underlying ground truth graphs than the original PC-like\nalgorithm, especially in high-dimensional settings. In particular, we\nempirically show that the results of both algorithms are more accurate and\nstabler when the sample size is reasonably large and the underlying graph is\nsparse.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:14:14 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 20:38:42 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2002.10880", "submitter": "Charlie Nash", "authors": "Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, Peter W. Battaglia", "title": "PolyGen: An Autoregressive Generative Model of 3D Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polygon meshes are an efficient representation of 3D geometry, and are of\ncentral importance in computer graphics, robotics and games development.\nExisting learning-based approaches have avoided the challenges of working with\n3D meshes, instead using alternative object representations that are more\ncompatible with neural architectures and training approaches. We present an\napproach which models the mesh directly, predicting mesh vertices and faces\nsequentially using a Transformer-based architecture. Our model can condition on\na range of inputs, including object classes, voxels, and images, and because\nthe model is probabilistic it can produce samples that capture uncertainty in\nambiguous scenarios. We show that the model is capable of producing\nhigh-quality, usable meshes, and establish log-likelihood benchmarks for the\nmesh-modelling task. We also evaluate the conditional models on surface\nreconstruction metrics against alternative methods, and demonstrate competitive\nperformance despite not training directly on this task.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:16:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Nash", "Charlie", ""], ["Ganin", "Yaroslav", ""], ["Eslami", "S. M. Ali", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "2002.10904", "submitter": "Mark Rucker", "authors": "Mark A. Rucker, Layne T. Watson, Laura E. Barnes and Matthew S. Gerber", "title": "Human Apprenticeship Learning via Kernel-based Inverse Reinforcement\n  Learning", "comments": "31 pages, 23 figures, Submitted to Journal of Artificial Intelligence\n  Research, \"for source code, see https://github.com/mrucker/kpirl-kla\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been well demonstrated that inverse reinforcement learning (IRL) is an\neffective technique for teaching machines to perform tasks at human skill\nlevels given human demonstrations (i.e., human to machine apprenticeship\nlearning). This paper seeks to show that a similar application can be\ndemonstrated with human learners. That is, given demonstrations from human\nexperts inverse reinforcement learning techniques can be used to teach other\nhumans to perform at higher skill levels (i.e., human to human apprenticeship\nlearning). To show this two experiments were conducted using a simple,\nreal-time web game where players were asked to touch targets in order to earn\nas many points as possible. For the experiment player performance was defined\nas the number of targets a player touched, irrespective of the points that a\nplayer actually earned. This allowed for in-game points to be modified and the\neffect of these alterations on performance measured. At no time were\nparticipants told the true performance metric. To determine the point\nmodifications IRL was applied on demonstrations of human experts playing the\ngame. The results of the experiment show with significance that performance\nimproved over the control for select treatment groups. Finally, in addition to\nthe experiment, we also detail the algorithmic challenges we faced when\nconducting the experiment and the techniques we used to overcome them.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:44:25 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:44:26 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rucker", "Mark A.", ""], ["Watson", "Layne T.", ""], ["Barnes", "Laura E.", ""], ["Gerber", "Matthew S.", ""]]}, {"id": "2002.10905", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Yao Rong, Enkelejda Kasneci", "title": "Fully Convolutional Neural Networks for Raw Eye Tracking Data\n  Segmentation, Generation, and Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use fully convolutional neural networks for the semantic\nsegmentation of eye tracking data. We also use these networks for\nreconstruction, and in conjunction with a variational auto-encoder to generate\neye movement data. The first improvement of our approach is that no input\nwindow is necessary, due to the use of fully convolutional networks and\ntherefore any input size can be processed directly. The second improvement is\nthat the used and generated data is raw eye tracking data (position X, Y and\ntime) without preprocessing. This is achieved by pre-initializing the filters\nin the first layer and by building the input tensor along the z axis. We\nevaluated our approach on three publicly available datasets and compare the\nresults to the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:57:09 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 07:13:46 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 12:22:08 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Rong", "Yao", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.10923", "submitter": "Luk\\'a\\v{s} Adam", "authors": "Luk\\'a\\v{s} Adam, V\\'aclav M\\'acha, V\\'aclav \\v{S}m\\'idl, Tom\\'a\\v{s}\n  Pevn\\'y", "title": "General Framework for Binary Classification on Top Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many binary classification problems minimize misclassification above (or\nbelow) a threshold. We show that instances of ranking problems, accuracy at the\ntop or hypothesis testing may be written in this form. We propose a general\nframework to handle these classes of problems and show which known methods\n(both known and newly proposed) fall into this framework. We provide a\ntheoretical analysis of this framework and mention selected possible pitfalls\nthe methods may encounter. We suggest several numerical improvements including\nthe implicit derivative and stochastic gradient descent. We provide an\nextensive numerical study. Based both on the theoretical properties and\nnumerical experiments, we conclude the paper by suggesting which method should\nbe used in which situation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:54:53 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Adam", "Luk\u00e1\u0161", ""], ["M\u00e1cha", "V\u00e1clav", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""]]}, {"id": "2002.10936", "submitter": "Matthew Leming", "authors": "Matthew Leming, John Suckling", "title": "Stochastic encoding of graphs in deep learning allows for complex\n  analysis of gender classification in resting-state and task functional brain\n  networks from the UK Biobank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of whole-brain functional connectivity MRI data with\nconvolutional neural networks (CNNs) has shown promise, but the complexity of\nthese models impedes understanding of which aspects of brain activity\ncontribute to classification. While visualization techniques have been\ndeveloped to interpret CNNs, bias inherent in the method of encoding abstract\ninput data, as well as the natural variance of deep learning models, detract\nfrom the accuracy of these techniques. We introduce a stochastic encoding\nmethod in an ensemble of CNNs to classify functional connectomes by gender. We\napplied our method to resting-state and task data from the UK BioBank, using\ntwo visualization techniques to measure the salience of three brain networks\ninvolved in task- and resting-states, and their interaction. To regress\nconfounding factors such as head motion, age, and intracranial volume, we\nintroduced a multivariate balancing algorithm to ensure equal distributions of\nsuch covariates between classes in our data. We achieved a final AUROC of\n0.8459. We found that resting-state data classifies more accurately than task\ndata, with the inner salience network playing the most important role of the\nthree networks overall in classification of resting-state data and connections\nto the central executive network in task data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:10:51 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:20:28 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Leming", "Matthew", ""], ["Suckling", "John", ""]]}, {"id": "2002.10937", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Hemant Purohit, and Huzefa Rangwala", "title": "Diversity-Based Generalization for Unsupervised Text Classification\n  under Domain Shift", "comments": "16 pages, 3 figures, 5 Tables, Source Code Available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation approaches seek to learn from a source domain and\ngeneralize it to an unseen target domain. At present, the state-of-the-art\nunsupervised domain adaptation approaches for subjective text classification\nproblems leverage unlabeled target data along with labeled source data. In this\npaper, we propose a novel method for domain adaptation of single-task text\nclassification problems based on a simple but effective idea of diversity-based\ngeneralization that does not require unlabeled target data but still matches\nthe state-of-the-art in performance. Diversity plays the role of promoting the\nmodel to better generalize and be indiscriminate towards domain shift by\nforcing the model not to rely on same features for prediction. We apply this\nconcept on the most explainable component of neural networks, the attention\nlayer. To generate sufficient diversity, we create a multi-head attention model\nand infuse a diversity constraint between the attention heads such that each\nhead will learn differently. We further expand upon our model by tri-training\nand designing a procedure with an additional diversity constraint between the\nattention heads of the tri-trained classifiers. Extensive evaluation using the\nstandard benchmark dataset of Amazon reviews and a newly constructed dataset of\nCrisis events shows that our fully unsupervised method matches with the\ncompeting baselines that uses unlabeled target data. Our results demonstrate\nthat machine learning architectures that ensure sufficient diversity can\ngeneralize better; encouraging future research to design ubiquitously usable\nlearning models without using unlabeled target data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:11:02 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 18:06:10 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Krishnan", "Jitin", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2002.10940", "submitter": "Richeng Jin", "authors": "Richeng Jin, Yufan Huang, Xiaofan He, Tianfu Wu, Huaiyu Dai", "title": "Stochastic-Sign SGD for Federated Learning with Theoretical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has emerged as a prominent distributed learning\nparadigm. FL entails some pressing needs for developing novel parameter\nestimation approaches with theoretical guarantees of convergence, which are\nalso communication efficient, differentially private and Byzantine resilient in\nthe heterogeneous data distribution settings. Quantization-based SGD solvers\nhave been widely adopted in FL and the recently proposed SIGNSGD with majority\nvote shows a promising direction. However, no existing methods enjoy all the\naforementioned properties. In this paper, we propose an intuitively-simple yet\ntheoretically-sound method based on SIGNSGD to bridge the gap. We present\nStochastic-Sign SGD which utilizes novel stochastic-sign based gradient\ncompressors enabling the aforementioned properties in a unified framework. We\nalso present an error-feedback variant of the proposed Stochastic-Sign SGD\nwhich further improves the learning performance in FL. We test the proposed\nmethod with extensive experiments using deep neural networks on the MNIST\ndataset. The experimental results corroborate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:12:15 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 02:57:54 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 18:21:03 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Jin", "Richeng", ""], ["Huang", "Yufan", ""], ["He", "Xiaofan", ""], ["Wu", "Tianfu", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2002.10947", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Sijia Liu, Pin-Yu Chen, Mengshu Sun, Caiwen Ding, Bhavya\n  Kailkhura, Xue Lin", "title": "Towards an Efficient and General Framework of Robust Training for Graph\n  Neural Networks", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have made significant advances on several\nfundamental inference tasks. As a result, there is a surge of interest in using\nthese models for making potentially important decisions in high-regret\napplications. However, despite GNNs' impressive performance, it has been\nobserved that carefully crafted perturbations on graph structures (or nodes\nattributes) lead them to make wrong predictions. Presence of these adversarial\nexamples raises serious security concerns. Most of the existing robust GNN\ndesign/training methods are only applicable to white-box settings where model\nparameters are known and gradient based methods can be used by performing\nconvex relaxation of the discrete graph domain. More importantly, these methods\nare not efficient and scalable which make them infeasible in time sensitive\ntasks and massive graph datasets. To overcome these limitations, we propose a\ngeneral framework which leverages the greedy search algorithms and zeroth-order\nmethods to obtain robust GNNs in a generic and an efficient manner. On several\napplications, we show that the proposed techniques are significantly less\ncomputationally expensive and, in some cases, more robust than the\nstate-of-the-art methods making them suitable to large-scale problems which\nwere out of the reach of traditional robust training methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:17:58 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Sun", "Mengshu", ""], ["Ding", "Caiwen", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""]]}, {"id": "2002.10964", "submitter": "Sangwoo Mo", "authors": "Sangwoo Mo, Minsu Cho, Jinwoo Shin", "title": "Freeze the Discriminator: a Simple Baseline for Fine-Tuning GANs", "comments": "Tech report; High resolution images are in\n  https://github.com/sangwoomo/FreezeD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown outstanding performance on\na wide range of problems in computer vision, graphics, and machine learning,\nbut often require numerous training data and heavy computational resources. To\ntackle this issue, several methods introduce a transfer learning technique in\nGAN training. They, however, are either prone to overfitting or limited to\nlearning small distribution shifts. In this paper, we show that simple\nfine-tuning of GANs with frozen lower layers of the discriminator performs\nsurprisingly well. This simple baseline, FreezeD, significantly outperforms\nprevious techniques used in both unconditional and conditional GANs. We\ndemonstrate the consistent effect using StyleGAN and SNGAN-projection\narchitectures on several datasets of Animal Face, Anime Face, Oxford Flower,\nCUB-200-2011, and Caltech-256 datasets. The code and results are available at\nhttps://github.com/sangwoomo/FreezeD.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:30:17 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:53:50 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mo", "Sangwoo", ""], ["Cho", "Minsu", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2002.10990", "submitter": "Matthew Dixon", "authors": "Matthew Dixon and Igor Halperin", "title": "G-Learner and GIRL: Goal Based Wealth Management with Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning approach to goal based wealth management\nproblems such as optimization of retirement plans or target dated funds. In\nsuch problems, an investor seeks to achieve a financial goal by making periodic\ninvestments in the portfolio while being employed, and periodically draws from\nthe account when in retirement, in addition to the ability to re-balance the\nportfolio by selling and buying different assets (e.g. stocks). Instead of\nrelying on a utility of consumption, we present G-Learner: a reinforcement\nlearning algorithm that operates with explicitly defined one-step rewards, does\nnot assume a data generation process, and is suitable for noisy data. Our\napproach is based on G-learning - a probabilistic extension of the Q-learning\nmethod of reinforcement learning.\n  In this paper, we demonstrate how G-learning, when applied to a quadratic\nreward and Gaussian reference policy, gives an entropy-regulated Linear\nQuadratic Regulator (LQR). This critical insight provides a novel and\ncomputationally tractable tool for wealth management tasks which scales to high\ndimensional portfolios. In addition to the solution of the direct problem of\nG-learning, we also present a new algorithm, GIRL, that extends our goal-based\nG-learning approach to the setting of Inverse Reinforcement Learning (IRL)\nwhere rewards collected by the agent are not observed, and should instead be\ninferred. We demonstrate that GIRL can successfully learn the reward parameters\nof a G-Learner agent and thus imitate its behavior. Finally, we discuss\npotential applications of the G-Learner and GIRL algorithms for wealth\nmanagement and robo-advising.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:03:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dixon", "Matthew", ""], ["Halperin", "Igor", ""]]}, {"id": "2002.10994", "submitter": "Anne-Marie Rickmann", "authors": "Anne-Marie Rickmann, Abhijit Guha Roy, Ignacio Sarasua, Christian\n  Wachinger", "title": "Recalibrating 3D ConvNets with Project & Excite", "comments": "Accepted for publication at IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.2972059", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Convolutional Neural Networks (F-CNNs) achieve state-of-the-art\nperformance for segmentation tasks in computer vision and medical imaging.\nRecently, computational blocks termed squeeze and excitation (SE) have been\nintroduced to recalibrate F-CNN feature maps both channel- and spatial-wise,\nboosting segmentation performance while only minimally increasing the model\ncomplexity. So far, the development of SE blocks has focused on 2D\narchitectures. For volumetric medical images, however, 3D F-CNNs are a natural\nchoice. In this article, we extend existing 2D recalibration methods to 3D and\npropose a generic compress-process-recalibrate pipeline for easy comparison of\nsuch blocks. We further introduce Project & Excite (PE) modules, customized for\n3D networks. In contrast to existing modules, Project \\& Excite does not\nperform global average pooling but compresses feature maps along different\nspatial dimensions of the tensor separately to retain more spatial information\nthat is subsequently used in the excitation step. We evaluate the modules on\ntwo challenging tasks, whole-brain segmentation of MRI scans and whole-body\nsegmentation of CT scans. We demonstrate that PE modules can be easily\nintegrated into 3D F-CNNs, boosting performance up to 0.3 in Dice Score and\noutperforming 3D extensions of other recalibration blocks, while only\nmarginally increasing the model complexity. Our code is publicly available on\nhttps://github.com/ai-med/squeeze_and_excitation .\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:07:17 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Rickmann", "Anne-Marie", ""], ["Roy", "Abhijit Guha", ""], ["Sarasua", "Ignacio", ""], ["Wachinger", "Christian", ""]]}, {"id": "2002.10998", "submitter": "Takanori Fujiwara", "authors": "Yiran Li, Takanori Fujiwara, Yong K. Choi, Katherine K. Kim, Kwan-Liu\n  Ma", "title": "A Visual Analytics System for Multi-model Comparison on Clinical Data\n  Predictions", "comments": "This is the author's version of the article that has been accepted to\n  PacificVis 2020 Visualization Meets AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing trend of applying machine learning methods to medical\ndatasets in order to predict patients' future status. Although some of these\nmethods achieve high performance, challenges still exist in comparing and\nevaluating different models through their interpretable information. Such\nanalytics can help clinicians improve evidence-based medical decision making.\nIn this work, we develop a visual analytics system that compares multiple\nmodels' prediction criteria and evaluates their consistency. With our system,\nusers can generate knowledge on different models' inner criteria and how\nconfidently we can rely on each model's prediction for a certain patient.\nThrough a case study of a publicly available clinical dataset, we demonstrate\nthe effectiveness of our visual analytics system to assist clinicians and\nresearchers in comparing and quantitatively evaluating different machine\nlearning methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:33:04 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 20:08:20 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Li", "Yiran", ""], ["Fujiwara", "Takanori", ""], ["Choi", "Yong K.", ""], ["Kim", "Katherine K.", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2002.11005", "submitter": "Serge Kas Hanna", "authors": "Serge Kas Hanna, Rawad Bitar, Parimal Parag, Venkat Dasari, and Salim\n  El Rouayheb", "title": "Adaptive Distributed Stochastic Gradient Descent for Minimizing Delay in\n  the Presence of Stragglers", "comments": "Accepted to IEEE ICASSP 2020", "journal-ref": "International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "doi": "10.1109/ICASSP40776.2020.9053961", "report-no": "pp. 4262--4266, May 2020", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting where a master wants to run a distributed stochastic\ngradient descent (SGD) algorithm on $n$ workers each having a subset of the\ndata. Distributed SGD may suffer from the effect of stragglers, i.e., slow or\nunresponsive workers who cause delays. One solution studied in the literature\nis to wait at each iteration for the responses of the fastest $k<n$ workers\nbefore updating the model, where $k$ is a fixed parameter. The choice of the\nvalue of $k$ presents a trade-off between the runtime (i.e., convergence rate)\nof SGD and the error of the model. Towards optimizing the error-runtime\ntrade-off, we investigate distributed SGD with adaptive $k$. We first design an\nadaptive policy for varying $k$ that optimizes this trade-off based on an upper\nbound on the error as a function of the wall-clock time which we derive. Then,\nwe propose an algorithm for adaptive distributed SGD that is based on a\nstatistical heuristic. We implement our algorithm and provide numerical\nsimulations which confirm our intuition and theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:25:22 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hanna", "Serge Kas", ""], ["Bitar", "Rawad", ""], ["Parag", "Parimal", ""], ["Dasari", "Venkat", ""], ["Rouayheb", "Salim El", ""]]}, {"id": "2002.11018", "submitter": "Mathilde Guillemot", "authors": "Mathilde Guillemot, Catherine Heusele, Rodolphe Korichi, Sylvianne\n  Schnebert, Liming Chen", "title": "Breaking Batch Normalization for better explainability of Deep Neural\n  Networks through Layer-wise Relevance Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of transparency of neural networks stays a major break for their\nuse. The Layerwise Relevance Propagation technique builds heat-maps\nrepresenting the relevance of each input in the model s decision. The relevance\nspreads backward from the last to the first layer of the Deep Neural Network.\nLayer-wise Relevance Propagation does not manage normalization layers, in this\nwork we suggest a method to include normalization layers. Specifically, we\nbuild an equivalent network fusing normalization layers and convolutional or\nfully connected layers. Heatmaps obtained with our method on MNIST and CIFAR 10\ndatasets are more accurate for convolutional layers. Our study also prevents\nfrom using Layerwise Relevance Propagation with networks including a\ncombination of connected layers and normalization layer.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:06:55 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Guillemot", "Mathilde", ""], ["Heusele", "Catherine", ""], ["Korichi", "Rodolphe", ""], ["Schnebert", "Sylvianne", ""], ["Chen", "Liming", ""]]}, {"id": "2002.11022", "submitter": "Yehui Tang", "authors": "Yehui Tang, Yunhe Wang, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu,\n  Chang Xu", "title": "Beyond Dropout: Feature Map Distortion to Regularize Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks often consist of a great number of trainable parameters\nfor extracting powerful features from given datasets. On one hand, massive\ntrainable parameters significantly enhance the performance of these deep\nnetworks. On the other hand, they bring the problem of over-fitting. To this\nend, dropout based methods disable some elements in the output feature maps\nduring the training phase for reducing the co-adaptation of neurons. Although\nthe generalization ability of the resulting models can be enhanced by these\napproaches, the conventional binary dropout is not the optimal solution.\nTherefore, we investigate the empirical Rademacher complexity related to\nintermediate layers of deep neural networks and propose a feature distortion\nmethod (Disout) for addressing the aforementioned problem. In the training\nperiod, randomly selected elements in the feature maps will be replaced with\nspecific values by exploiting the generalization error bound. The superiority\nof the proposed feature map distortion for producing deep neural network with\nhigher testing performance is analyzed and demonstrated on several benchmark\nimage datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 13:59:13 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Tang", "Yehui", ""], ["Wang", "Yunhe", ""], ["Xu", "Yixing", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Xu", "Chunjing", ""], ["Xu", "Chang", ""]]}, {"id": "2002.11039", "submitter": "Bin Hu", "authors": "Shuting Sun, Jianxiu Li, Huayu Chen, Tao Gong, Xiaowei Li, Bin Hu", "title": "A study of resting-state EEG biomarkers for depression recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Depression has become a major health burden worldwide, and\neffective detection depression is a great public-health challenge. This\nElectroencephalography (EEG)-based research is to explore the effective\nbiomarkers for depression recognition. Methods: Resting state EEG data was\ncollected from 24 major depressive patients (MDD) and 29 normal controls using\n128 channel HydroCel Geodesic Sensor Net (HCGSN). To better identify\ndepression, we extracted different types of EEG features including linear\nfeatures, nonlinear features and functional connectivity features phase lagging\nindex (PLI) to comprehensively analyze the EEG signals in patients with MDD.\nAnd using different feature selection methods and classifiers to evaluate the\noptimal feature sets. Results: Functional connectivity feature PLI is superior\nto the linear features and nonlinear features. And when combining all the types\nof features to classify MDD patients, we can obtain the highest classification\naccuracy 82.31% using ReliefF feature selection method and logistic regression\n(LR) classifier. Analyzing the distribution of optimal feature set, it was\nfound that intrahemispheric connection edges of PLI were much more than the\ninterhemispheric connection edges, and the intrahemispheric connection edges\nhad a significant differences between two groups. Conclusion: Functional\nconnectivity feature PLI plays an important role in depression recognition.\nEspecially, intrahemispheric connection edges of PLI might be an effective\nbiomarker to identify depression. And statistic results suggested that MDD\npatients might exist functional dysfunction in left hemisphere.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 08:33:08 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Sun", "Shuting", ""], ["Li", "Jianxiu", ""], ["Chen", "Huayu", ""], ["Gong", "Tao", ""], ["Li", "Xiaowei", ""], ["Hu", "Bin", ""]]}, {"id": "2002.11041", "submitter": "Amir Mosavi Prof", "authors": "Laszlo Nadai, Felde Imre, Sina Ardabili, Tarahom Mesri Gundoshmian,\n  Pinter Gergo, Amir Mosavi", "title": "Performance Analysis of Combine Harvester using Hybrid Model of\n  Artificial Neural Networks Particle Swarm Optimization", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Novel applications of artificial intelligence for tuning the parameters of\nindustrial machines for optimal performance are emerging at a fast pace. Tuning\nthe combine harvesters and improving the machine performance can dramatically\nminimize the wastes during harvesting, and it is also beneficial to machine\nmaintenance. Literature includes several soft computing, machine learning and\noptimization methods that had been used to model the function of harvesters of\nvarious crops. Due to the complexity of the problem, machine learning methods\nhad been recently proposed to predict the optimal performance with promising\nresults. In this paper, through proposing a novel hybrid machine learning model\nbased on artificial neural networks integrated with particle swarm optimization\n(ANN-PSO), the performance analysis of a common combine harvester is presented.\nThe hybridization of machine learning methods with soft computing techniques\nhas recently shown promising results to improve the performance of the combine\nharvesters. This research aims at improving the results further by providing\nmore stable models with higher accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:38:01 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Nadai", "Laszlo", ""], ["Imre", "Felde", ""], ["Ardabili", "Sina", ""], ["Gundoshmian", "Tarahom Mesri", ""], ["Gergo", "Pinter", ""], ["Mosavi", "Amir", ""]]}, {"id": "2002.11044", "submitter": "Ruthvik Vaila", "authors": "Ruthvik Vaila, Denver Lloyd, Kevin Tetz", "title": "Regression with Deep Learning for Sensor Performance Optimization", "comments": "Accepted in Workshop on Microelectronics and Electron Devices March\n  30th, 2020", "journal-ref": "Workshop on Microelectronics and Electron Devices. March 30th,\n  2020", "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural networks with at least two hidden layers are called deep networks.\nRecent developments in AI and computer programming in general has led to\ndevelopment of tools such as Tensorflow, Keras, NumPy etc. making it easier to\nmodel and draw conclusions from data. In this work we re-approach non-linear\nregression with deep learning enabled by Keras and Tensorflow. In particular,\nwe use deep learning to parametrize a non-linear multivariate relationship\nbetween inputs and outputs of an industrial sensor with an intent to optimize\nthe sensor performance based on selected key metrics.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 19:58:58 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 15:18:14 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Vaila", "Ruthvik", ""], ["Lloyd", "Denver", ""], ["Tetz", "Kevin", ""]]}, {"id": "2002.11045", "submitter": "Changyang She", "authors": "Changyang She and Rui Dong and Zhouyou Gu and Zhanwei Hou and Yonghui\n  Li and Wibowo Hardjawana and Chenyang Yang and Lingyang Song and Branka\n  Vucetic", "title": "Deep Learning for Ultra-Reliable and Low-Latency Communications in 6G\n  Networks", "comments": "The manuscript contains 4 figures 2 tables. It has been submitted to\n  IEEE Network (in the second round of revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the future 6th generation networks, ultra-reliable and low-latency\ncommunications (URLLC) will lay the foundation for emerging mission-critical\napplications that have stringent requirements on end-to-end delay and\nreliability. Existing works on URLLC are mainly based on theoretical models and\nassumptions. The model-based solutions provide useful insights, but cannot be\ndirectly implemented in practice. In this article, we first summarize how to\napply data-driven supervised deep learning and deep reinforcement learning in\nURLLC, and discuss some open problems of these methods. To address these open\nproblems, we develop a multi-level architecture that enables device\nintelligence, edge intelligence, and cloud intelligence for URLLC. The basic\nidea is to merge theoretical models and real-world data in analyzing the\nlatency and reliability and training deep neural networks (DNNs). Deep transfer\nlearning is adopted in the architecture to fine-tune the pre-trained DNNs in\nnon-stationary networks. Further considering that the computing capacity at\neach user and each mobile edge computing server is limited, federated learning\nis applied to improve the learning efficiency. Finally, we provide some\nexperimental and simulation results and discuss some future directions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 14:38:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["She", "Changyang", ""], ["Dong", "Rui", ""], ["Gu", "Zhouyou", ""], ["Hou", "Zhanwei", ""], ["Li", "Yonghui", ""], ["Hardjawana", "Wibowo", ""], ["Yang", "Chenyang", ""], ["Song", "Lingyang", ""], ["Vucetic", "Branka", ""]]}, {"id": "2002.11052", "submitter": "Sai Aparna Aketi", "authors": "Sai Aparna Aketi and Priyadarshini Panda and Kaushik Roy", "title": "Relevant-features based Auxiliary Cells for Energy Efficient Detection\n  of Natural Errors", "comments": "16 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated state-of-the-art performance on many\nclassification tasks. However, they have no inherent capability to recognize\nwhen their predictions are wrong. There have been several efforts in the recent\npast to detect natural errors but the suggested mechanisms pose additional\nenergy requirements. To address this issue, we propose an ensemble of\nclassifiers at hidden layers to enable energy efficient detection of natural\nerrors. In particular, we append Relevant-features based Auxiliary Cells (RACs)\nwhich are class specific binary linear classifiers trained on relevant\nfeatures. The consensus of RACs is used to detect natural errors. Based on\ncombined confidence of RACs, classification can be terminated early, thereby\nresulting in energy efficient detection. We demonstrate the effectiveness of\nour technique on various image classification datasets such as CIFAR-10,\nCIFAR-100 and Tiny-ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:22:10 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 01:30:08 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Aketi", "Sai Aparna", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "2002.11080", "submitter": "Lin Chen", "authors": "Yifei Min, Lin Chen, Amin Karbasi", "title": "The Curious Case of Adversarially Robust Models: More Data Can Help,\n  Double Descend, or Hurt Generalization", "comments": "Added theoretical analysis of the Manhattan model and further\n  empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has shown its ability in producing models that are\nrobust to perturbations on the input data, but usually at the expense of\ndecrease in the standard accuracy. To mitigate this issue, it is commonly\nbelieved that more training data will eventually help such adversarially robust\nmodels generalize better on the benign/unperturbed test data. In this paper,\nhowever, we challenge this conventional belief and show that more training data\ncan hurt the generalization of adversarially robust models in the\nclassification problems. We first investigate the Gaussian mixture\nclassification with a linear loss and identify three regimes based on the\nstrength of the adversary. In the weak adversary regime, more data improves the\ngeneralization of adversarially robust models. In the medium adversary regime,\nwith more training data, the generalization loss exhibits a double descent\ncurve, which implies the existence of an intermediate stage where more training\ndata hurts the generalization. In the strong adversary regime, more data almost\nimmediately causes the generalization error to increase. Then we move to the\nanalysis of a two-dimensional classification problem with a 0-1 loss. We prove\nthat more data always hurts the generalization performance of adversarially\ntrained models with large perturbations. To complement our theoretical results,\nwe conduct empirical studies on Gaussian mixture classification, support vector\nmachines (SVMs), and linear regression.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:25:28 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 23:46:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Min", "Yifei", ""], ["Chen", "Lin", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.11082", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Optimal Gradient Quantization Condition for Communication-Efficient\n  Distributed Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication of gradients is costly for training deep neural networks\nwith multiple devices in computer vision applications. In particular, the\ngrowing size of deep learning models leads to higher communication overheads\nthat defy the ideal linear training speedup regarding the number of devices.\nGradient quantization is one of the common methods to reduce communication\ncosts. However, it can lead to quantization error in the training and result in\nmodel performance degradation. In this work, we deduce the optimal condition of\nboth the binary and multi-level gradient quantization for \\textbf{ANY} gradient\ndistribution. Based on the optimal condition, we develop two novel quantization\nschemes: biased BinGrad and unbiased ORQ for binary and multi-level gradient\nquantization respectively, which dynamically determine the optimal quantization\nlevels. Extensive experimental results on CIFAR and ImageNet datasets with\nseveral popular convolutional neural networks show the superiority of our\nproposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:28:39 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "2002.11089", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Xinyang Geng, Sergey Levine, and Ruslan\n  Salakhutdinov", "title": "Rewriting History with Inverse RL: Hindsight Inference for Policy\n  Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task reinforcement learning (RL) aims to simultaneously learn policies\nfor solving many tasks. Several prior works have found that relabeling past\nexperience with different reward functions can improve sample efficiency.\nRelabeling methods typically ask: if, in hindsight, we assume that our\nexperience was optimal for some task, for what task was it optimal? In this\npaper, we show that hindsight relabeling is inverse RL, an observation that\nsuggests that we can use inverse RL in tandem for RL algorithms to efficiently\nsolve many tasks. We use this idea to generalize goal-relabeling techniques\nfrom prior work to arbitrary classes of tasks. Our experiments confirm that\nrelabeling data using inverse RL accelerates learning in general multi-task\nsettings, including goal-reaching, domains with discrete sets of rewards, and\nthose with linear reward functions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:36:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Geng", "Xinyang", ""], ["Levine", "Sergey", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2002.11096", "submitter": "Kyra Gan", "authors": "Kyra Gan, Andrew A. Li, Zachary C. Lipton, Sridhar Tayur", "title": "Causal Inference With Selectively Deconfounded Data", "comments": null, "journal-ref": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130. Copyright 2021 by the author(s)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given only data generated by a standard confounding graph with unobserved\nconfounder, the Average Treatment Effect (ATE) is not identifiable. To estimate\nthe ATE, a practitioner must then either (a) collect deconfounded data;(b) run\na clinical trial; or (c) elucidate further properties of the causal graph that\nmight render the ATE identifiable. In this paper, we consider the benefit of\nincorporating a large confounded observational dataset (confounder unobserved)\nalongside a small deconfounded observational dataset (confounder revealed) when\nestimating the ATE. Our theoretical results suggest that the inclusion of\nconfounded data can significantly reduce the quantity of deconfounded data\nrequired to estimate the ATE to within a desired accuracy level. Moreover, in\nsome cases -- say, genetics -- we could imagine retrospectively selecting\nsamples to deconfound. We demonstrate that by actively selecting these samples\nbased upon the (already observed) treatment and outcome, we can reduce sample\ncomplexity further. Our theoretical and empirical results establish that the\nworst-case relative performance of our approach (vs. a natural benchmark) is\nbounded while our best-case gains are unbounded. Finally, we demonstrate the\nbenefits of selective deconfounding using a large real-world dataset related to\ngenetic mutation in cancer.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:46:19 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 01:06:27 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 15:35:51 GMT"}, {"version": "v4", "created": "Sun, 7 Mar 2021 01:33:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Gan", "Kyra", ""], ["Li", "Andrew A.", ""], ["Lipton", "Zachary C.", ""], ["Tayur", "Sridhar", ""]]}, {"id": "2002.11097", "submitter": "I. Elizabeth Kumar", "authors": "I. Elizabeth Kumar, Suresh Venkatasubramanian, Carlos Scheidegger,\n  Sorelle Friedler", "title": "Problems with Shapley-value-based explanations as feature importance\n  measures", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game-theoretic formulations of feature importance have become popular as a\nway to \"explain\" machine learning models. These methods define a cooperative\ngame between the features of a model and distribute influence among these input\nelements using some form of the game's unique Shapley values. Justification for\nthese methods rests on two pillars: their desirable mathematical properties,\nand their applicability to specific motivations for explanations. We show that\nmathematical problems arise when Shapley values are used for feature importance\nand that the solutions to mitigate these necessarily induce further complexity,\nsuch as the need for causal reasoning. We also draw on additional literature to\nargue that Shapley values do not provide explanations which suit human-centric\ngoals of explainability.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:51:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:38:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kumar", "I. Elizabeth", ""], ["Venkatasubramanian", "Suresh", ""], ["Scheidegger", "Carlos", ""], ["Friedler", "Sorelle", ""]]}, {"id": "2002.11099", "submitter": "Ayush Jain", "authors": "Ayush Jain and Alon Orlitsky", "title": "A General Method for Robust Learning from Batches", "comments": "First Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, data is collected in batches, some of which are corrupt\nor even adversarial. Recent work derived optimal robust algorithms for\nestimating discrete distributions in this setting. We consider a general\nframework of robust learning from batches, and determine the limits of both\nclassification and distribution estimation over arbitrary, including\ncontinuous, domains. Building on these results, we derive the first robust\nagnostic computationally-efficient learning algorithms for piecewise-interval\nclassification, and for piecewise-polynomial, monotone, log-concave, and\ngaussian-mixture distribution estimation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:53:25 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""]]}, {"id": "2002.11102", "submitter": "Boyi Li", "authors": "Boyi Li and Felix Wu and Ser-Nam Lim and Serge Belongie and Kilian Q.\n  Weinberger", "title": "On Feature Normalization and Data Augmentation", "comments": "CVPR 2021. Code is available at https://github.com/Boyiliee/MoEx", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moments (a.k.a., mean and standard deviation) of latent features are\noften removed as noise when training image recognition models, to increase\nstability and reduce training time. However, in the field of image generation,\nthe moments play a much more central role. Studies have shown that the moments\nextracted from instance normalization and positional normalization can roughly\ncapture style and shape information of an image. Instead of being discarded,\nthese moments are instrumental to the generation process. In this paper we\npropose Moment Exchange, an implicit data augmentation method that encourages\nthe model to utilize the moment information also for recognition models.\nSpecifically, we replace the moments of the learned features of one training\nimage by those of another, and also interpolate the target labels -- forcing\nthe model to extract training signal from the moments in addition to the\nnormalized features. As our approach is fast, operates entirely in feature\nspace, and mixes different signals than prior methods, one can effectively\ncombine it with existing augmentation approaches. We demonstrate its efficacy\nacross several recognition benchmark data sets where it improves the\ngeneralization capability of highly competitive baseline networks with\nremarkable consistency.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:59:05 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:59:02 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 18:00:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Li", "Boyi", ""], ["Wu", "Felix", ""], ["Lim", "Ser-Nam", ""], ["Belongie", "Serge", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.11104", "submitter": "Abiola Osho", "authors": "Abiola Osho, Caden Waters, George Amariucai", "title": "An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:04:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Osho", "Abiola", ""], ["Waters", "Caden", ""], ["Amariucai", "George", ""]]}, {"id": "2002.11137", "submitter": "Adel Javanmard", "authors": "Negin Golrezaei, Adel Javanmard and Vahab Mirrokni", "title": "Dynamic Incentive-aware Learning: Robust Pricing in Contextual Auctions", "comments": "Accepted for publication in Operations Research Journal (An earlier\n  version of this paper accepted to NeurIPS 2019.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by pricing in ad exchange markets, we consider the problem of\nrobust learning of reserve prices against strategic buyers in repeated\ncontextual second-price auctions. Buyers' valuations for an item depend on the\ncontext that describes the item. However, the seller is not aware of the\nrelationship between the context and buyers' valuations, i.e., buyers'\npreferences. The seller's goal is to design a learning policy to set reserve\nprices via observing the past sales data, and her objective is to minimize her\nregret for revenue, where the regret is computed against a clairvoyant policy\nthat knows buyers' heterogeneous preferences. Given the seller's goal,\nutility-maximizing buyers have the incentive to bid untruthfully in order to\nmanipulate the seller's learning policy. We propose learning policies that are\nrobust to such strategic behavior. These policies use the outcomes of the\nauctions, rather than the submitted bids, to estimate the preferences while\ncontrolling the long-term effect of the outcome of each auction on the future\nreserve prices. When the market noise distribution is known to the seller, we\npropose a policy called Contextual Robust Pricing (CORP) that achieves a\nT-period regret of $O(d\\log(Td) \\log (T))$, where $d$ is the dimension of {the}\ncontextual information. When the market noise distribution is unknown to the\nseller, we propose two policies whose regrets are sublinear in $T$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:00:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Golrezaei", "Negin", ""], ["Javanmard", "Adel", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "2002.11151", "submitter": "Sourjya Roy", "authors": "Sourjya Roy, Shrihari Sridharan, Shubham Jain, and Anand Raghunathan", "title": "TxSim:Modeling Training of Deep Neural Networks on Resistive Crossbar\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resistive crossbars have attracted significant interest in the design of Deep\nNeural Network (DNN) accelerators due to their ability to natively execute\nmassively parallel vector-matrix multiplications within dense memory arrays.\nHowever, crossbar-based computations face a major challenge due to a variety of\ndevice and circuit-level non-idealities, which manifest as errors in the\nvector-matrix multiplications and eventually degrade DNN accuracy. To address\nthis challenge, there is a need for tools that can model the functional impact\nof non-idealities on DNN training and inference. Existing efforts towards this\ngoal are either limited to inference, or are too slow to be used for\nlarge-scale DNN training. We propose TxSim, a fast and customizable modeling\nframework to functionally evaluate DNN training on crossbar-based hardware\nconsidering the impact of non-idealities. The key features of TxSim that\ndifferentiate it from prior efforts are: (i) It comprehensively models\nnon-idealities during all training operations (forward propagation, backward\npropagation, and weight update) and (ii) it achieves computational efficiency\nby mapping crossbar evaluations to well-optimized BLAS routines and\nincorporates speedup techniques to further reduce simulation time with minimal\nimpact on accuracy. TxSim achieves orders-of-magnitude improvement in\nsimulation speed over prior works, and thereby makes it feasible to evaluate\ntraining of large-scale DNNs on crossbars. Our experiments using TxSim reveal\nthat the accuracy degradation in DNN training due to non-idealities can be\nsubstantial (3%-10%) for large-scale DNNs, underscoring the need for further\nresearch in mitigation techniques. We also analyze the impact of various device\nand circuit-level parameters and the associated non-idealities to provide key\ninsights that can guide the design of crossbar-based DNN training accelerators.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:29:43 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 20:42:50 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 03:54:43 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Roy", "Sourjya", ""], ["Sridharan", "Shrihari", ""], ["Jain", "Shubham", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2002.11152", "submitter": "Carole Twining Dr", "authors": "Neil A. Thacker, Carole J. Twining, Paul D. Tar, Scott Notley and\n  Visvanathan Ramesh", "title": "Fundamental Issues Regarding Uncertainties in Artificial Neural Networks", "comments": "21 pages, 8 Figures, 2 Tables. To be submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) implement a specific form of multi-variate\nextrapolation and will generate an output for any input pattern, even when\nthere is no similar training pattern. Extrapolations are not necessarily to be\ntrusted, and in order to support safety critical systems, we require such\nsystems to give an indication of the training sample related uncertainty\nassociated with their output. Some readers may think that this is a well known\nissue which is already covered by the basic principles of pattern recognition.\nWe will explain below how this is not the case and how the conventional\n(Likelihood estimate of) conditional probability of classification does not\ncorrectly assess this uncertainty. We provide a discussion of the standard\ninterpretations of this problem and show how a quantitative approach based upon\nlong standing methods can be practically applied. The methods are illustrated\non the task of early diagnosis of dementing diseases using Magnetic Resonance\nImaging.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:32:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Thacker", "Neil A.", ""], ["Twining", "Carole J.", ""], ["Tar", "Paul D.", ""], ["Notley", "Scott", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "2002.11159", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Yaqiong Li, Ling Chen, Bin Li, Scott A. Sisson", "title": "Smoothing Graphons for Modelling Exchangeable Relational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling exchangeable relational data can be described by \\textit{graphon\ntheory}. Most Bayesian methods for modelling exchangeable relational data can\nbe attributed to this framework by exploiting different forms of graphons.\nHowever, the graphons adopted by existing Bayesian methods are either\npiecewise-constant functions, which are insufficiently flexible for accurate\nmodelling of the relational data, or are complicated continuous functions,\nwhich incur heavy computational costs for inference. In this work, we introduce\na smoothing procedure to piecewise-constant graphons to form {\\em smoothing\ngraphons}, which permit continuous intensity values for describing relations,\nbut without impractically increasing computational costs. In particular, we\nfocus on the Bayesian Stochastic Block Model (SBM) and demonstrate how to adapt\nthe piecewise-constant SBM graphon to the smoothed version. We initially\npropose the Integrated Smoothing Graphon (ISG) which introduces one smoothing\nparameter to the SBM graphon to generate continuous relational intensity\nvalues. We then develop the Latent Feature Smoothing Graphon (LFSG), which\nimproves on the ISG by introducing auxiliary hidden labels to decompose the\ncalculation of the ISG intensity and enable efficient inference. Experimental\nresults on real-world data sets validate the advantages of applying smoothing\nstrategies to the Stochastic Block Model, demonstrating that smoothing graphons\ncan greatly improve AUC and precision for link prediction without increasing\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:02:06 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Yaqiong", ""], ["Chen", "Ling", ""], ["Li", "Bin", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2002.11167", "submitter": "Ashesh Chattopadhyay", "authors": "Ashesh Chattopadhyay, Adam Subel, Pedram Hassanzadeh", "title": "Data-driven super-parameterization using deep learning: Experimentation\n  with multi-scale Lorenz 96 systems and transfer-learning", "comments": null, "journal-ref": "Journal of Advances in Modeling Earth Systems 2020", "doi": "10.1029/2020MS002084", "report-no": null, "categories": "physics.ao-ph nlin.CD physics.comp-ph physics.flu-dyn physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make weather/climate modeling computationally affordable, small-scale\nprocesses are usually represented in terms of the large-scale,\nexplicitly-resolved processes using physics-based or semi-empirical\nparameterization schemes. Another approach, computationally more demanding but\noften more accurate, is super-parameterization (SP), which involves integrating\nthe equations of small-scale processes on high-resolution grids embedded within\nthe low-resolution grids of large-scale processes. Recently, studies have used\nmachine learning (ML) to develop data-driven parameterization (DD-P) schemes.\nHere, we propose a new approach, data-driven SP (DD-SP), in which the equations\nof the small-scale processes are integrated data-drivenly using ML methods such\nas recurrent neural networks. Employing multi-scale Lorenz 96 systems as\ntestbed, we compare the cost and accuracy (in terms of both short-term\nprediction and long-term statistics) of parameterized low-resolution (LR), SP,\nDD-P, and DD-SP models. We show that with the same computational cost, DD-SP\nsubstantially outperforms LR, and is better than DD-P, particularly when scale\nseparation is lacking. DD-SP is much cheaper than SP, yet its accuracy is the\nsame in reproducing long-term statistics and often comparable in short-term\nforecasting. We also investigate generalization, finding that when models\ntrained on data from one system are applied to a system with different forcing\n(e.g., more chaotic), the models often do not generalize, particularly when the\nshort-term prediction accuracy is examined. But we show that transfer-learning,\nwhich involves re-training the data-driven model with a small amount of data\nfrom the new system, significantly improves generalization. Potential\napplications of DD-SP and transfer-learning in climate/weather modeling and the\nexpected challenges are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:43:42 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Chattopadhyay", "Ashesh", ""], ["Subel", "Adam", ""], ["Hassanzadeh", "Pedram", ""]]}, {"id": "2002.11172", "submitter": "Nikunj Saunshi", "authors": "Nikunj Saunshi, Yi Zhang, Mikhail Khodak, Sanjeev Arora", "title": "A Sample Complexity Separation between Non-Convex and Convex\n  Meta-Learning", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular trend in meta-learning is to learn from many training tasks a\ncommon initialization for a gradient-based method that can be used to solve a\nnew task with few samples. The theory of meta-learning is still in its early\nstages, with several recent learning-theoretic analyses of methods such as\nReptile [Nichol et al., 2018] being for convex models. This work shows that\nconvex-case analysis might be insufficient to understand the success of\nmeta-learning, and that even for non-convex models it is important to look\ninside the optimization black-box, specifically at properties of the\noptimization trajectory. We construct a simple meta-learning instance that\ncaptures the problem of one-dimensional subspace learning. For the convex\nformulation of linear regression on this instance, we show that the new task\nsample complexity of any initialization-based meta-learning algorithm is\n$\\Omega(d)$, where $d$ is the input dimension. In contrast, for the non-convex\nformulation of a two layer linear network on the same instance, we show that\nboth Reptile and multi-task representation learning can have new task sample\ncomplexity of $\\mathcal{O}(1)$, demonstrating a separation from convex\nmeta-learning. Crucially, analyses of the training dynamics of these methods\nreveal that they can meta-learn the correct subspace onto which the data should\nbe projected.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:55:09 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Saunshi", "Nikunj", ""], ["Zhang", "Yi", ""], ["Khodak", "Mikhail", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2002.11182", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Tor Lattimore, Andreas Krause", "title": "Information Directed Sampling for Linear Partial Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial monitoring is a rich framework for sequential decision making under\nuncertainty that generalizes many well known bandit models, including linear,\ncombinatorial and dueling bandits. We introduce information directed sampling\n(IDS) for stochastic partial monitoring with a linear reward and observation\nstructure. IDS achieves adaptive worst-case regret rates that depend on precise\nobservability conditions of the game. Moreover, we prove lower bounds that\nclassify the minimax regret of all finite games into four possible regimes. IDS\nachieves the optimal rate in all cases up to logarithmic factors, without\ntuning any hyper-parameters. We further extend our results to the contextual\nand the kernelized setting, which significantly increases the range of possible\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:30:56 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kirschner", "Johannes", ""], ["Lattimore", "Tor", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.11187", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Prashnna K Gyawali, Linwei Wang", "title": "Reliable Estimation of Kullback-Leibler Divergence by Controlling\n  Discriminator Complexity in the Reproducing Kernel Hilbert Space", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several scalable sample-based methods to compute the Kullback Leibler (KL)\ndivergence between two distributions have been proposed and applied in\nlarge-scale machine learning models. While they have been found to be unstable,\nthe theoretical root cause of the problem is not clear. In this paper, we study\na generative adversarial network based approach that uses a neural network\ndiscriminator to estimate KL divergence. We argue that, in such case, high\nfluctuations in the estimates are a consequence of not controlling the\ncomplexity of the discriminator function space. We provide a theoretical\nunderpinning and remedy for this problem by first constructing a discriminator\nin the Reproducing Kernel Hilbert Space (RKHS). This enables us to leverage\nsample complexity and mean embedding to theoretically relate the error\nprobability bound of the KL estimates to the complexity of the discriminator in\nRKHS. Based on this theory, we then present a scalable way to control the\ncomplexity of the discriminator for a reliable estimation of KL divergence. We\nsupport both our proposed theory and method to control the complexity of the\nRKHS discriminator through controlled experiments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:44:52 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:06:16 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 22:58:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Gyawali", "Prashnna K", ""], ["Wang", "Linwei", ""]]}, {"id": "2002.11192", "submitter": "Alessandro Rossi", "authors": "Alessandro Rossi, Sara Ermini, Dario Bernabini, Dario Zanca, Marino\n  Todisco, Alessandro Genovese, and Antonio Rizzo", "title": "End-to-End Models for the Analysis of System 1 and System 2 Interactions\n  based on Eye-Tracking Data", "comments": "11 pages, 2 figures, 1 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While theories postulating a dual cognitive system take hold, quantitative\nconfirmations are still needed to understand and identify interactions between\nthe two systems or conflict events. Eye movements are among the most direct\nmarkers of the individual attentive load and may serve as an important proxy of\ninformation. In this work we propose a computational method, within a modified\nvisual version of the well-known Stroop test, for the identification of\ndifferent tasks and potential conflicts events between the two systems through\nthe collection and processing of data related to eye movements. A statistical\nanalysis shows that the selected variables can characterize the variation of\nattentive load within different scenarios. Moreover, we show that Machine\nLearning techniques allow to distinguish between different tasks with a good\nclassification accuracy and to investigate more in depth the gaze dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:46:13 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rossi", "Alessandro", ""], ["Ermini", "Sara", ""], ["Bernabini", "Dario", ""], ["Zanca", "Dario", ""], ["Todisco", "Marino", ""], ["Genovese", "Alessandro", ""], ["Rizzo", "Antonio", ""]]}, {"id": "2002.11215", "submitter": "Sarthak .", "authors": "Sarthak, Shikhar Shukla, Surya Prakash Tripathi", "title": "EmbPred30: Assessing 30-days Readmission for Diabetic Patients using\n  Categorical Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hospital readmission is a crucial healthcare quality measure that helps in\ndetermining the level of quality of care that a hospital offers to a patient\nand has proven to be immensely expensive. It is estimated that more than $25\nbillion are spent yearly due to readmission of diabetic patients in the USA.\nThis paper benchmarks existing models and proposes a new embedding based\nstate-of-the-art deep neural network(DNN). The model can identify whether a\nhospitalized diabetic patient will be readmitted within 30 days or not with an\naccuracy of 95.2% and Area Under the Receiver Operating Characteristics(AUROC)\nof 97.4% on data collected from 130 US hospitals between 1999-2008. The results\nare encouraging with patients having changes in medication while admitted\nhaving a high chance of getting readmitted. Identifying prospective patients\nfor readmission could help the hospital systems in improving their inpatient\ncare, thereby saving them from unnecessary expenditures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 22:59:47 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sarthak", "", ""], ["Shukla", "Shikhar", ""], ["Tripathi", "Surya Prakash", ""]]}, {"id": "2002.11219", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Mert Pilanci", "title": "Convex Geometry and Duality of Over-parameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a convex analytic approach to analyze finite width two-layer ReLU\nnetworks. We first prove that an optimal solution to the regularized training\nproblem can be characterized as extreme points of a convex set, where simple\nsolutions are encouraged via its convex geometrical properties. We then\nleverage this characterization to show that an optimal set of parameters yield\nlinear spline interpolation for regression problems involving one dimensional\nor rank-one data. We also characterize the classification decision regions in\nterms of a kernel matrix and minimum $\\ell_1$-norm solutions. This is in\ncontrast to Neural Tangent Kernel which is unable to explain predictions of\nfinite width networks. Our convex geometric characterization also provides\nintuitive explanations of hidden neurons as auto-encoders. In higher\ndimensions, we show that the training problem can be cast as a finite\ndimensional convex problem with infinitely many constraints. Then, we apply\ncertain convex relaxations and introduce a cutting-plane algorithm to globally\noptimize the network. We further analyze the exactness of the relaxations to\nprovide conditions for the convergence to a global optimum. Our analysis also\nshows that optimal network parameters can be also characterized as\ninterpretable closed-form formulas in some practically relevant special cases.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 23:05:33 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 22:41:11 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 06:33:08 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Ergen", "Tolga", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.11223", "submitter": "Krishna Pillutla", "authors": "Yassine Laguel, Krishna Pillutla, J\\'er\\^ome Malick, Zaid Harchaoui", "title": "Device Heterogeneity in Federated Learning: A Superquantile Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a federated learning framework to handle heterogeneous client\ndevices which do not conform to the population data distribution. The approach\nhinges upon a parameterized superquantile-based objective, where the parameter\nranges over levels of conformity. We present an optimization algorithm and\nestablish its convergence to a stationary point. We show how to practically\nimplement it using secure aggregation by interleaving iterations of the usual\nfederated averaging method with device filtering. We conclude with numerical\nexperiments on neural networks as well as linear models on tasks from computer\nvision and natural language processing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 23:37:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Laguel", "Yassine", ""], ["Pillutla", "Krishna", ""], ["Malick", "J\u00e9r\u00f4me", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2002.11226", "submitter": "Joel Dabrowski Dr", "authors": "Joel Janek Dabrowski and Johan Pieter de Villiers and Ashfaqur Rahman\n  and Conrad Beyers", "title": "Deep Learning and Statistical Models for Time-Critical Pedestrian\n  Behaviour Prediction", "comments": null, "journal-ref": "In: Gedeon T., Wong K., Lee M. (eds) Neural Information\n  Processing. ICONIP 2019. Communications in Computer and Information Science,\n  vol 1142. Springer, Cham", "doi": "10.1007/978-3-030-36808-1_50", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time it takes for a classifier to make an accurate prediction can be\ncrucial in many behaviour recognition problems. For example, an autonomous\nvehicle should detect hazardous pedestrian behaviour early enough for it to\ntake appropriate measures. In this context, we compare the switching linear\ndynamical system (SLDS) and a three-layered bi-directional long short-term\nmemory (LSTM) neural network, which are applied to infer pedestrian behaviour\nfrom motion tracks. We show that, though the neural network model achieves an\naccuracy of 80%, it requires long sequences to achieve this (100 samples or\nmore). The SLDS, has a lower accuracy of 74%, but it achieves this result with\nshort sequences (10 samples). To our knowledge, such a comparison on sequence\nlength has not been considered in the literature before. The results provide a\nkey intuition of the suitability of the models in time-critical problems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:05:19 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Dabrowski", "Joel Janek", ""], ["de Villiers", "Johan Pieter", ""], ["Rahman", "Ashfaqur", ""], ["Beyers", "Conrad", ""]]}, {"id": "2002.11242", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi\n  Sugiyama, Mohan Kankanhalli", "title": "Attacks Which Do Not Kill Training Make Adversarial Learning Stronger", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training based on the minimax formulation is necessary for\nobtaining adversarial robustness of trained models. However, it is conservative\nor even pessimistic so that it sometimes hurts the natural generalization. In\nthis paper, we raise a fundamental question---do we have to trade off natural\ngeneralization for adversarial robustness? We argue that adversarial training\nis to employ confident adversarial data for updating the current model. We\npropose a novel approach of friendly adversarial training (FAT): rather than\nemploying most adversarial data maximizing the loss, we search for least\nadversarial (i.e., friendly adversarial) data minimizing the loss, among the\nadversarial data that are confidently misclassified. Our novel formulation is\neasy to implement by just stopping the most adversarial data searching\nalgorithms such as PGD (projected gradient descent) early, which we call\nearly-stopped PGD. Theoretically, FAT is justified by an upper bound of the\nadversarial risk. Empirically, early-stopped PGD allows us to answer the\nearlier question negatively---adversarial robustness can indeed be achieved\nwithout compromising the natural generalization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:04:38 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 09:53:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Xu", "Xilie", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Cui", "Lizhen", ""], ["Sugiyama", "Masashi", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2002.11246", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Eric Gaussier", "title": "Supervised Categorical Metric Learning with Schatten p-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning has been successful in learning new metrics adapted to\nnumerical datasets. However, its development on categorical data still needs\nfurther exploration. In this paper, we propose a method, called CPML for\n\\emph{categorical projected metric learning}, that tries to efficiently~(i.e.\nless computational time and better prediction accuracy) address the problem of\nmetric learning in categorical data. We make use of the Value Distance Metric\nto represent our data and propose new distances based on this representation.\nWe then show how to efficiently learn new metrics. We also generalize several\nprevious regularizers through the Schatten $p$-norm and provides a\ngeneralization bound for it that complements the standard generalization bound\nfor metric learning. Experimental results show that our method provides\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:17:12 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fan", "Xuhui", ""], ["Gaussier", "Eric", ""]]}, {"id": "2002.11255", "submitter": "Rungang Han", "authors": "Rungang Han, Rebecca Willett and Anru R. Zhang", "title": "An Optimal Statistical and Computational Framework for Generalized\n  Tensor Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a flexible framework for generalized low-rank tensor\nestimation problems that includes many important instances arising from\napplications in computational imaging, genomics, and network analysis. The\nproposed estimator consists of finding a low-rank tensor fit to the data under\ngeneralized parametric models. To overcome the difficulty of non-convexity in\nthese problems, we introduce a unified approach of projected gradient descent\nthat adapts to the underlying low-rank structure. Under mild conditions on the\nloss function, we establish both an upper bound on statistical error and the\nlinear rate of computational convergence through a general deterministic\nanalysis. Then we further consider a suite of generalized tensor estimation\nproblems, including sub-Gaussian tensor PCA, tensor regression, and Poisson and\nbinomial tensor PCA. We prove that the proposed algorithm achieves the minimax\noptimal rate of convergence in estimation error. Finally, we demonstrate the\nsuperiority of the proposed framework via extensive experiments on both\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:54:35 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 21:55:11 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Han", "Rungang", ""], ["Willett", "Rebecca", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2002.11256", "submitter": "Cheng Li", "authors": "Cheng Li, Sunil Gupta, Santu Rana, Vu Nguyen, Antonio Robles-Kelly,\n  Svetha Venkatesh", "title": "Incorporating Expert Prior Knowledge into Experimental Design via\n  Posterior Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific experiments are usually expensive due to complex experimental\npreparation and processing. Experimental design is therefore involved with the\ntask of finding the optimal experimental input that results in the desirable\noutput by using as few experiments as possible. Experimenters can often acquire\nthe knowledge about the location of the global optimum. However, they do not\nknow how to exploit this knowledge to accelerate experimental design. In this\npaper, we adopt the technique of Bayesian optimization for experimental design\nsince Bayesian optimization has established itself as an efficient tool for\noptimizing expensive black-box functions. Again, it is unknown how to\nincorporate the expert prior knowledge about the global optimum into Bayesian\noptimization process. To address it, we represent the expert knowledge about\nthe global optimum via placing a prior distribution on it and we then derive\nits posterior distribution. An efficient Bayesian optimization approach has\nbeen proposed via posterior sampling on the posterior distribution of the\nglobal optimum. We theoretically analyze the convergence of the proposed\nalgorithm and discuss the robustness of incorporating expert prior. We evaluate\nthe efficiency of our algorithm by optimizing synthetic functions and tuning\nhyperparameters of classifiers along with a real-world experiment on the\nsynthesis of short polymer fiber. The results clearly demonstrate the\nadvantages of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:57:36 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Li", "Cheng", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Nguyen", "Vu", ""], ["Robles-Kelly", "Antonio", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2002.11275", "submitter": "Alex Luedtke", "authors": "Alex Luedtke, Incheoul Chung, Oleg Sofrygin", "title": "Adversarial Monte Carlo Meta-Learning of Optimal Prediction Procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We frame the meta-learning of prediction procedures as a search for an\noptimal strategy in a two-player game. In this game, Nature selects a prior\nover distributions that generate labeled data consisting of features and an\nassociated outcome, and the Predictor observes data sampled from a distribution\ndrawn from this prior. The Predictor's objective is to learn a function that\nmaps from a new feature to an estimate of the associated outcome. We establish\nthat, under reasonable conditions, the Predictor has an optimal strategy that\nis equivariant to shifts and rescalings of the outcome and is invariant to\npermutations of the observations and to shifts, rescalings, and permutations of\nthe features. We introduce a neural network architecture that satisfies these\nproperties. The proposed strategy performs favorably compared to standard\npractice in both parametric and nonparametric experiments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:16:05 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 22:26:02 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Luedtke", "Alex", ""], ["Chung", "Incheoul", ""], ["Sofrygin", "Oleg", ""]]}, {"id": "2002.11304", "submitter": "Faez Ahmed", "authors": "Wei Chen, Faez Ahmed", "title": "PaDGAN: A Generative Adversarial Network for Performance Augmented\n  Diverse Designs", "comments": "Paper published in ASME IDETC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are proven to be a useful tool for automatic design\nsynthesis and design space exploration. When applied in engineering design,\nexisting generative models face three challenges: 1) generated designs lack\ndiversity and do not cover all areas of the design space, 2) it is difficult to\nexplicitly improve the overall performance or quality of generated designs, and\n3) existing models generally do not generate novel designs, outside the domain\nof the training data. In this paper, we simultaneously address these challenges\nby proposing a new Determinantal Point Processes based loss function for\nprobabilistic modeling of diversity and quality. With this new loss function,\nwe develop a variant of the Generative Adversarial Network, named \"Performance\nAugmented Diverse Generative Adversarial Network\" or PaDGAN, which can generate\nnovel high-quality designs with good coverage of the design space. Using three\nsynthetic examples and one real-world airfoil design example, we demonstrate\nthat PaDGAN can generate diverse and high-quality designs. In comparison to a\nvanilla Generative Adversarial Network, on average, it generates samples with a\n28% higher mean quality score with larger diversity and without the mode\ncollapse issue. Unlike typical generative models that usually generate new\ndesigns by interpolating within the boundary of training data, we show that\nPaDGAN expands the design space boundary outside the training data towards\nhigh-quality regions. The proposed method is broadly applicable to many tasks\nincluding design space exploration, design optimization, and creative solution\nrecommendation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:53:39 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 21:52:27 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:43:55 GMT"}, {"version": "v4", "created": "Sun, 21 Jun 2020 03:24:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chen", "Wei", ""], ["Ahmed", "Faez", ""]]}, {"id": "2002.11318", "submitter": "Sandesh Kamath K", "authors": "Sandesh Kamath, Amit Deshpande, K V Subrahmanyam, Vineeth N\n  Balasubramanian", "title": "Can we have it all? On the Trade-off between Spatial and Adversarial\n  Robustness of Neural Networks", "comments": "Preliminary version consisting early experimental results was\n  presented in ICML 2018 Workshop on \"Towards learning with limited labels:\n  Equivariance, Invariance,and Beyond\" as \"Understanding Adversarial Robustness\n  of Symmetric Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  (Non-)robustness of neural networks to small, adversarial pixel-wise\nperturbations, and as more recently shown, to even random spatial\ntransformations (e.g., translations, rotations) entreats both theoretical and\nempirical understanding. Spatial robustness to random translations and\nrotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)\nand training augmentation, whereas adversarial robustness is typically achieved\nby adversarial training. In this paper, we prove a quantitative trade-off\nbetween spatial and adversarial robustness in a simple statistical setting. We\ncomplement this empirically by showing that: (a) as the spatial robustness of\nequivariant models improves by training augmentation with progressively larger\ntransformations, their adversarial robustness worsens progressively, and (b) as\nthe state-of-the-art robust models are adversarially trained with progressively\nlarger pixel-wise perturbations, their spatial robustness drops progressively.\nTowards achieving pareto-optimality in this trade-off, we propose a method\nbased on curriculum learning that trains gradually on more difficult\nperturbations (both spatial and adversarial) to improve spatial and adversarial\nrobustness simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:25:06 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:32:03 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 06:46:08 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 16:28:42 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kamath", "Sandesh", ""], ["Deshpande", "Amit", ""], ["Subrahmanyam", "K V", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2002.11323", "submitter": "Ioannis Panageas", "authors": "Ioannis Panageas, Stratis Skoulakis, Antonios Varvitsiotis, and Xiao\n  Wang", "title": "Convergence to Second-Order Stationarity for Non-negative Matrix\n  Factorization: Provably and Concurrently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a fundamental non-convex\noptimization problem with numerous applications in Machine Learning (music\nanalysis, document clustering, speech-source separation etc). Despite having\nreceived extensive study, it is poorly understood whether or not there exist\nnatural algorithms that can provably converge to a local minimum. Part of the\nreason is because the objective is heavily symmetric and its gradient is not\nLipschitz. In this paper we define a multiplicative weight update type dynamics\n(modification of the seminal Lee-Seung algorithm) that runs concurrently and\nprovably avoids saddle points (first order stationary points that are not\nsecond order). Our techniques combine tools from dynamical systems such as\nstability and exploit the geometry of the NMF objective by reducing the\nstandard NMF formulation over the non-negative orthant to a new formulation\nover (a scaled) simplex. An important advantage of our method is the use of\nconcurrent updates, which permits implementations in parallel computing\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:40:23 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 11:17:08 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Panageas", "Ioannis", ""], ["Skoulakis", "Stratis", ""], ["Varvitsiotis", "Antonios", ""], ["Wang", "Xiao", ""]]}, {"id": "2002.11328", "submitter": "Zitong Yang", "authors": "Zitong Yang, Yaodong Yu, Chong You, Jacob Steinhardt, Yi Ma", "title": "Rethinking Bias-Variance Trade-off for Generalization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical bias-variance trade-off predicts that bias decreases and\nvariance increase with model complexity, leading to a U-shaped risk curve.\nRecent work calls this into question for neural networks and other\nover-parameterized models, for which it is often observed that larger models\ngeneralize better. We provide a simple explanation for this by measuring the\nbias and variance of neural networks: while the bias is monotonically\ndecreasing as in the classical theory, the variance is unimodal or bell-shaped:\nit increases then decreases with the width of the network. We vary the network\narchitecture, loss function, and choice of dataset and confirm that variance\nunimodality occurs robustly for all models we considered. The risk curve is the\nsum of the bias and variance curves and displays different qualitative shapes\ndepending on the relative scale of bias and variance, with the double descent\ncurve observed in recent literature as a special case. We corroborate these\nempirical results with a theoretical analysis of two-layer linear networks with\nrandom first layer. Finally, evaluation on out-of-distribution data shows that\nmost of the drop in accuracy comes from increased bias while variance increases\nby a relatively small amount. Moreover, we find that deeper models decrease\nbias and increase variance for both in-distribution and out-of-distribution\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:21:54 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 05:35:59 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 03:10:44 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Yang", "Zitong", ""], ["Yu", "Yaodong", ""], ["You", "Chong", ""], ["Steinhardt", "Jacob", ""], ["Ma", "Yi", ""]]}, {"id": "2002.11332", "submitter": "Vidyashankar Sivakumar", "authors": "Vidyashankar Sivakumar, Zhiwei Steven Wu, Arindam Banerjee", "title": "Structured Linear Contextual Bandits: A Sharp and Geometric Smoothed\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit learning algorithms typically involve the balance of exploration and\nexploitation. However, in many practical applications, worst-case scenarios\nneeding systematic exploration are seldom encountered. In this work, we\nconsider a smoothed setting for structured linear contextual bandits where the\nadversarial contexts are perturbed by Gaussian noise and the unknown parameter\n$\\theta^*$ has structure, e.g., sparsity, group sparsity, low rank, etc. We\npropose simple greedy algorithms for both the single- and multi-parameter\n(i.e., different parameter for each context) settings and provide a unified\nregret analysis for $\\theta^*$ with any assumed structure. The regret bounds\nare expressed in terms of geometric quantities such as Gaussian widths\nassociated with the structure of $\\theta^*$. We also obtain sharper regret\nbounds compared to earlier work for the unstructured $\\theta^*$ setting as a\nconsequence of our improved analysis. We show there is implicit exploration in\nthe smoothed setting where a simple greedy algorithm works.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:29:24 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sivakumar", "Vidyashankar", ""], ["Wu", "Zhiwei Steven", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2002.11360", "submitter": "Yuejiao Sun", "authors": "Tianyi Chen, Yuejiao Sun, Wotao Yin", "title": "LASG: Lazily Aggregated Stochastic Gradients for Communication-Efficient\n  Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets solving distributed machine learning problems such as\nfederated learning in a communication-efficient fashion. A class of new\nstochastic gradient descent (SGD) approaches have been developed, which can be\nviewed as the stochastic generalization to the recently developed lazily\naggregated gradient (LAG) method --- justifying the name LASG. LAG adaptively\npredicts the contribution of each round of communication and chooses only the\nsignificant ones to perform. It saves communication while also maintains the\nrate of convergence. However, LAG only works with deterministic gradients, and\napplying it to stochastic gradients yields poor performance. The key components\nof LASG are a set of new rules tailored for stochastic gradients that can be\nimplemented either to save download, upload, or both. The new algorithms\nadaptively choose between fresh and stale stochastic gradients and have\nconvergence rates comparable to the original SGD. LASG achieves impressive\nempirical performance --- it typically saves total communication by an order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:58:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Chen", "Tianyi", ""], ["Sun", "Yuejiao", ""], ["Yin", "Wotao", ""]]}, {"id": "2002.11361", "submitter": "Ananya Kumar", "authors": "Ananya Kumar, Tengyu Ma, Percy Liang", "title": "Understanding Self-Training for Gradual Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems must adapt to data distributions that evolve over\ntime, in applications ranging from sensor networks and self-driving car\nperception modules to brain-machine interfaces. We consider gradual domain\nadaptation, where the goal is to adapt an initial classifier trained on a\nsource domain given only unlabeled data that shifts gradually in distribution\ntowards a target domain. We prove the first non-vacuous upper bound on the\nerror of self-training with gradual shifts, under settings where directly\nadapting to the target domain can result in unbounded error. The theoretical\nanalysis leads to algorithmic insights, highlighting that regularization and\nlabel sharpening are essential even when we have infinite data, and suggesting\nthat self-training works particularly well for shifts with small\nWasserstein-infinity distance. Leveraging the gradual shift structure leads to\nhigher accuracies on a rotating MNIST dataset and a realistic Portraits\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:59:40 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kumar", "Ananya", ""], ["Ma", "Tengyu", ""], ["Liang", "Percy", ""]]}, {"id": "2002.11369", "submitter": "Adri\\'an Javaloy", "authors": "Adri\\'an Javaloy, Isabel Valera", "title": "Lipschitz standardization for multivariate learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic learning is increasingly being tackled as an optimization\nproblem, with gradient-based approaches as predominant methods. When modelling\nmultivariate likelihoods, a usual but undesirable outcome is that the learned\nmodel fits only a subset of the observed variables, overlooking the rest. In\nthis work, we study this problem through the lens of multitask learning (MTL),\nwhere similar effects have been broadly studied. While MTL solutions do not\ndirectly apply in the probabilistic setting (as they cannot handle the\nlikelihood constraints) we show that similar ideas may be leveraged during data\npreprocessing. First, we show that data standardization often helps under\ncommon continuous likelihoods, but it is not enough in the general case,\nspecially under mixed continuous and discrete likelihood models. In order for\nbalance multivariate learning, we then propose a novel data preprocessing,\nLipschitz standardization, which balances the local Lipschitz smoothness across\nvariables. Our experiments on real-world datasets show that Lipschitz\nstandardization leads to more accurate multivariate models than the ones\nlearned using existing data preprocessing techniques. The models and datasets\nemployed in the experiments can be found in\nhttps://github.com/adrianjav/lipschitz-standardization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:20:10 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 14:23:49 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 21:24:54 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Javaloy", "Adri\u00e1n", ""], ["Valera", "Isabel", ""]]}, {"id": "2002.11394", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Ling Luo, Scott A. Sisson", "title": "Bayesian Nonparametric Space Partitions: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric space partition (BNSP) models provide a variety of\nstrategies for partitioning a $D$-dimensional space into a set of blocks. In\nthis way, the data points lie in the same block would share certain kinds of\nhomogeneity. BNSP models can be applied to various areas, such as\nregression/classification trees, random feature construction, relational\nmodeling, etc. In this survey, we investigate the current progress of BNSP\nresearch through the following three perspectives: models, which review various\nstrategies for generating the partitions in the space and discuss their\ntheoretical foundation `self-consistency'; applications, which cover the\ncurrent mainstream usages of BNSP models and their potential future practises;\nand challenges, which identify the current unsolved problems and valuable\nfuture research topics. As there are no comprehensive reviews of BNSP\nliterature before, we hope that this survey can induce further exploration and\nexploitation on this topic.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:25:04 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 13:09:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Luo", "Ling", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2002.11410", "submitter": "Meixia Lin", "authors": "Meixia Lin, Defeng Sun, Kim-Chuan Toh", "title": "Efficient algorithms for multivariate shape-constrained convex\n  regression problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape-constrained convex regression problem deals with fitting a convex\nfunction to the observed data, where additional constraints are imposed, such\nas component-wise monotonicity and uniform Lipschitz continuity. This paper\nprovides a comprehensive mechanism for computing the least squares estimator of\na multivariate shape-constrained convex regression function in $\\mathbb{R}^d$.\nWe prove that the least squares estimator is computable via solving a\nconstrained convex quadratic programming (QP) problem with $(n+1)d$ variables\nand at least $n(n-1)$ linear inequality constraints, where $n$ is the number of\ndata points. For solving the generally very large-scale convex QP, we design\ntwo efficient algorithms, one is the symmetric Gauss-Seidel based alternating\ndirection method of multipliers ({\\tt sGS-ADMM}), and the other is the proximal\naugmented Lagrangian method ({\\tt pALM}) with the subproblems solved by the\nsemismooth Newton method ({\\tt SSN}). Comprehensive numerical experiments,\nincluding those in the pricing of basket options and estimation of production\nfunctions in economics, demonstrate that both of our proposed algorithms\noutperform the state-of-the-art algorithm. The {\\tt pALM} is more efficient\nthan the {\\tt sGS-ADMM} but the latter has the advantage of being simpler to\nimplement.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 11:18:43 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Lin", "Meixia", ""], ["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""]]}, {"id": "2002.11416", "submitter": "Jalpa Shah", "authors": "Jalpa Shah and Biswajit Mishra", "title": "Analytical Equations based Prediction Approach for PM2.5 using\n  Artificial Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Particulate matter pollution is one of the deadliest types of air pollution\nworldwide due to its significant impacts on the global environment and human\nhealth. Particulate Matter (PM2.5) is one of the important particulate\npollutants to measure the Air Quality Index (AQI). The conventional instruments\nused by the air quality monitoring stations to monitor PM2.5 are costly,\nbulkier, time-consuming, and power-hungry. Furthermore, due to limited data\navailability and non-scalability, these stations cannot provide high spatial\nand temporal resolution in real-time. To overcome the disadvantages of existing\nmethodology this article presents analytical equations based prediction\napproach for PM2.5 using an Artificial Neural Network (ANN). Since the derived\nanalytical equations for the prediction can be computed using a Wireless Sensor\nNode (WSN) or low-cost processing tool, it demonstrates the usefulness of the\nproposed approach. Moreover, the study related to correlation among the PM2.5\nand other pollutants is performed to select the appropriate predictors. The\nlarge authenticate data set of Central Pollution Control Board (CPCB) online\nstation, India is used for the proposed approach. The RMSE and coefficient of\ndetermination (R2) obtained for the proposed prediction approach using eight\npredictors are 1.7973 ug/m3 and 0.9986 respectively. While the proposed\napproach results show RMSE of 7.5372 ug/m3 and R2 of 0.9708 using three\npredictors. Therefore, the results demonstrate that the proposed approach is\none of the promising approaches for monitoring PM2.5 without power-hungry gas\nsensors and bulkier analyzers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 11:39:18 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Shah", "Jalpa", ""], ["Mishra", "Biswajit", ""]]}, {"id": "2002.11423", "submitter": "Jaime Pizarroso Gonzalo", "authors": "J. Pizarroso, J. Portela and A. Mu\\~noz", "title": "NeuralSens: Sensitivity Analysis of Neural Networks", "comments": "28 pages, 12 figures, submitted to Journal of Statistical Software\n  (JSS) https://www.jstatsoft.org/index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are important tools for data-intensive analysis and are\ncommonly applied to model non-linear relationships between dependent and\nindependent variables. However, neural networks are usually seen as \"black\nboxes\" that offer minimal information about how the input variables are used to\npredict the response in a fitted model. This article describes the\n\\pkg{NeuralSens} package that can be used to perform sensitivity analysis of\nneural networks using the partial derivatives method. Functions in the package\ncan be used to obtain the sensitivities of the output with respect to the input\nvariables, evaluate variable importance based on sensitivity measures and\ncharacterize relationships between input and output variables. Methods to\ncalculate sensitivities are provided for objects from common neural network\npackages in \\proglang{R}, including \\pkg{neuralnet}, \\pkg{nnet}, \\pkg{RSNNS},\n\\pkg{h2o}, \\pkg{neural}, \\pkg{forecast} and \\pkg{caret}. The article presents\nan overview of the techniques for obtaining information from neural network\nmodels, a theoretical foundation of how are calculated the partial derivatives\nof the output with respect to the inputs of a multi-layer perceptron model, a\ndescription of the package structure and functions, and applied examples to\ncompare \\pkg{NeuralSens} functions with analogous functions from other\navailable \\proglang{R} packages.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:05:59 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:01:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pizarroso", "J.", ""], ["Portela", "J.", ""], ["Mu\u00f1oz", "A.", ""]]}, {"id": "2002.11429", "submitter": "Janis Keuper", "authors": "Peter Michael Habelitz and Janis Keuper", "title": "PHS: A Toolbox for Parallel Hyperparameter Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an open source python framework named PHS - Parallel\nHyperparameter Search to enable hyperparameter optimization on numerous compute\ninstances of any arbitrary python function. This is achieved with minimal\nmodifications inside the target function. Possible applications appear in\nexpensive to evaluate numerical computations which strongly depend on\nhyperparameters such as machine learning. Bayesian optimization is chosen as a\nsample efficient method to propose the next query set of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:17:54 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 12:30:00 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Habelitz", "Peter Michael", ""], ["Keuper", "Janis", ""]]}, {"id": "2002.11436", "submitter": "Luk\\'a\\v{s} Adam", "authors": "V\\'aclav M\\'acha, Luk\\'a\\v{s} Adam, V\\'aclav \\v{S}m\\'idl", "title": "Nonlinear classifiers for ranking problems based on kernelized SVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classification problems focus on maximizing the performance only on the\nsamples with the highest relevance instead of all samples. As an example, we\ncan mention ranking problems, accuracy at the top or search engines where only\nthe top few queries matter. In our previous work, we derived a general\nframework including several classes of these linear classification problems. In\nthis paper, we extend the framework to nonlinear classifiers. Utilizing a\nsimilarity to SVM, we dualize the problems, add kernels and propose a\ncomponentwise dual ascent method. This allows us to perform one iteration in\nless than 20 milliseconds on relatively large datasets such as FashionMNIST.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:37:11 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["M\u00e1cha", "V\u00e1clav", ""], ["Adam", "Luk\u00e1\u0161", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""]]}, {"id": "2002.11440", "submitter": "L.A. Prashanth", "authors": "Nirav Bhavsar and Prashanth L.A", "title": "Non-asymptotic bounds for stochastic optimization with biased noisy\n  gradient oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce biased gradient oracles to capture a setting where the function\nmeasurements have an estimation error that can be controlled through a batch\nsize parameter. Our proposed oracles are appealing in several practical\ncontexts, for instance, risk measure estimation from a batch of independent and\nidentically distributed (i.i.d.) samples, or simulation optimization, where the\nfunction measurements are `biased' due to computational constraints. In either\ncase, increasing the batch size reduces the estimation error. We highlight the\napplicability of our biased gradient oracles in a risk-sensitive reinforcement\nlearning setting. In the stochastic non-convex optimization context, we analyze\na variant of the randomized stochastic gradient (RSG) algorithm with a biased\ngradient oracle. We quantify the convergence rate of this algorithm by deriving\nnon-asymptotic bounds on its performance. Next, in the stochastic convex\noptimization setting, we derive non-asymptotic bounds for the last iterate of a\nstochastic gradient descent (SGD) algorithm with a biased gradient oracle.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:53:04 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 11:50:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bhavsar", "Nirav", ""], ["A", "Prashanth L.", ""]]}, {"id": "2002.11442", "submitter": "Maarten Buyl", "authors": "Maarten Buyl, Tijl De Bie", "title": "DeBayes: a Bayesian Method for Debiasing Network Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms are increasingly deployed for high-impact\nautomated decision making, ethical and increasingly also legal standards demand\nthat they treat all individuals fairly, without discrimination based on their\nage, gender, race or other sensitive traits. In recent years much progress has\nbeen made on ensuring fairness and reducing bias in standard machine learning\nsettings. Yet, for network embedding, with applications in vulnerable domains\nranging from social network analysis to recommender systems, current options\nremain limited both in number and performance. We thus propose DeBayes: a\nconceptually elegant Bayesian method that is capable of learning debiased\nembeddings by using a biased prior. Our experiments show that these\nrepresentations can then be used to perform link prediction that is\nsignificantly more fair in terms of popular metrics such as demographic parity\nand equalized opportunity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:57:05 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:41:11 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 10:18:43 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Buyl", "Maarten", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.11448", "submitter": "Ilya Tolstikhin", "authors": "Thomas Unterthiner, Daniel Keysers, Sylvain Gelly, Olivier Bousquet,\n  Ilya Tolstikhin", "title": "Predicting Neural Network Accuracy from Weights", "comments": "Updated the Small CNN Zoo dataset: reduced the maximal learning rate\n  and got rid of multiple bad runs. Replaced all the experiments with the new\n  numbers. Added MLP. Fixed typo in the abstract (R2 score instead of Kendall's\n  tau). Added several earlier related works to the literature overview", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show experimentally that the accuracy of a trained neural network can be\npredicted surprisingly well by looking only at its weights, without evaluating\nit on input data. We motivate this task and introduce a formal setting for it.\nEven when using simple statistics of the weights, the predictors are able to\nrank neural networks by their performance with very high accuracy (R2 score\nmore than 0.98). Furthermore, the predictors are able to rank networks trained\non different, unobserved datasets and with different architectures. We release\na collection of 120k convolutional neural networks trained on four different\ndatasets to encourage further research in this area, with the goal of\nunderstanding network training and performance better.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:06:14 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 08:07:41 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 12:05:10 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 10:38:15 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Unterthiner", "Thomas", ""], ["Keysers", "Daniel", ""], ["Gelly", "Sylvain", ""], ["Bousquet", "Olivier", ""], ["Tolstikhin", "Ilya", ""]]}, {"id": "2002.11451", "submitter": "Th\\'eo Galy-Fajou", "authors": "Th\\'eo Galy-Fajou, Florian Wenzel, Manfred Opper", "title": "Automated Augmented Conjugate Inference for Non-conjugate Gaussian\n  Process Models", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose automated augmented conjugate inference, a new inference method\nfor non-conjugate Gaussian processes (GP) models. Our method automatically\nconstructs an auxiliary variable augmentation that renders the GP model\nconditionally conjugate. Building on the conjugate structure of the augmented\nmodel, we develop two inference methods. First, a fast and scalable stochastic\nvariational inference method that uses efficient block coordinate ascent\nupdates, which are computed in closed form. Second, an asymptotically correct\nGibbs sampler that is useful for small datasets. Our experiments show that our\nmethod are up two orders of magnitude faster and more robust than existing\nstate-of-the-art black-box methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:10:00 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Galy-Fajou", "Th\u00e9o", ""], ["Wenzel", "Florian", ""], ["Opper", "Manfred", ""]]}, {"id": "2002.11477", "submitter": "Robin Karlsson", "authors": "Robin Karlsson, Erik Sjoberg", "title": "Learning a Directional Soft Lane Affordance Model for Road Scenes Using\n  Self-Supervision", "comments": "Accepted for IEEE IV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans navigate complex environments in an organized yet flexible manner,\nadapting to the context and implicit social rules. Understanding these\nnaturally learned patterns of behavior is essential for applications such as\nautonomous vehicles. However, algorithmically defining these implicit rules of\nhuman behavior remains difficult. This work proposes a novel self-supervised\nmethod for training a probabilistic network model to estimate the regions\nhumans are most likely to drive in as well as a multimodal representation of\nthe inferred direction of travel at each point. The model is trained on\nindividual human trajectories conditioned on a representation of the driving\nenvironment. The model is shown to successfully generalize to new road scenes,\ndemonstrating potential for real-world application as a prior for socially\nacceptable driving behavior in challenging or ambiguous scenarios which are\npoorly handled by explicit traffic rules.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:57:34 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 13:19:45 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Karlsson", "Robin", ""], ["Sjoberg", "Erik", ""]]}, {"id": "2002.11498", "submitter": "Mohammed Nabil El Korso M. N. El Korso", "authors": "Martin Brossard, Virginie Ollier, Mohammed Nabil El Korso, R\\'emy\n  Boyer and Pascal Larzabal", "title": "Multi-frequency calibration for DOA estimation with distributed sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate direction finding in the presence of sensor gain\nuncertainties and directional perturbations for sensor array processing in a\nmulti-frequency scenario. Specifically, we adopt a distributed optimization\nscheme in which coherence models are incorporated and local agents exchange\ninformation only between connected nodes in the network, i.e., without a fusion\ncenter. Numerical simulations highlight the advantages of the proposed parallel\niterative technique in terms of statistical and computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:16:43 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Brossard", "Martin", ""], ["Ollier", "Virginie", ""], ["Korso", "Mohammed Nabil El", ""], ["Boyer", "R\u00e9my", ""], ["Larzabal", "Pascal", ""]]}, {"id": "2002.11501", "submitter": "Hankz Hankui Zhuo", "authors": "Huiling Zhu, Xin Luo, and Hankz Hankui Zhuo", "title": "Dual Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning embeds nodes in large graphs as low-dimensional\nvectors and is of great benefit to many downstream applications. Most embedding\nframeworks, however, are inherently transductive and unable to generalize to\nunseen nodes or learn representations across different graphs. Although\ninductive approaches can generalize to unseen nodes, they neglect different\ncontexts of nodes and cannot learn node embeddings dually. In this paper, we\npresent a context-aware unsupervised dual encoding framework, \\textbf{CADE}, to\ngenerate representations of nodes by combining real-time neighborhoods with\nneighbor-attentioned representation, and preserving extra memory of known\nnodes. We exhibit that our approach is effective by comparing to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 04:50:17 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Zhu", "Huiling", ""], ["Luo", "Xin", ""], ["Zhuo", "Hankz Hankui", ""]]}, {"id": "2002.11505", "submitter": "Janne H. Korhonen", "authors": "Vitaly Aksenov and Dan Alistarh and Janne H. Korhonen", "title": "Relaxed Scheduling for Scalable Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to leverage large-scale hardware parallelism has been one of the\nkey enablers of the accelerated recent progress in machine learning.\nConsequently, there has been considerable effort invested into developing\nefficient parallel variants of classic machine learning algorithms. However,\ndespite the wealth of knowledge on parallelization, some classic machine\nlearning algorithms often prove hard to parallelize efficiently while\nmaintaining convergence.\n  In this paper, we focus on efficient parallel algorithms for the key machine\nlearning task of inference on graphical models, in particular on the\nfundamental belief propagation algorithm. We address the challenge of\nefficiently parallelizing this classic paradigm by showing how to leverage\nscalable relaxed schedulers in this context. We present an extensive empirical\nstudy, showing that our approach outperforms previous parallel belief\npropagation implementations both in terms of scalability and in terms of\nwall-clock convergence time, on a range of practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:28:04 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:54:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Aksenov", "Vitaly", ""], ["Alistarh", "Dan", ""], ["Korhonen", "Janne H.", ""]]}, {"id": "2002.11511", "submitter": "Bulbul Ahmmed", "authors": "B. Ahmmed, M. K. Mudunuru, S. Karra, S. C. James, and V. V. Vesselinov", "title": "A Comparative Study of Machine Learning Models for Predicting the State\n  of Reactive Mixing", "comments": "31 pages", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110147", "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate predictions of reactive mixing are critical for many Earth and\nenvironmental science problems. To investigate mixing dynamics over time under\ndifferent scenarios, a high-fidelity, finite-element-based numerical model is\nbuilt to solve the fast, irreversible bimolecular reaction-diffusion equations\nto simulate a range of reactive-mixing scenarios. A total of 2,315 simulations\nare performed using different sets of model input parameters comprising various\nspatial scales of vortex structures in the velocity field, time-scales\nassociated with velocity oscillations, the perturbation parameter for the\nvortex-based velocity, anisotropic dispersion contrast, and molecular\ndiffusion. Outputs comprise concentration profiles of the reactants and\nproducts. The inputs and outputs of these simulations are concatenated into\nfeature and label matrices, respectively, to train 20 different machine\nlearning (ML) emulators to approximate system behavior. The 20 ML emulators\nbased on linear methods, Bayesian methods, ensemble learning methods, and\nmultilayer perceptron (MLP), are compared to assess these models. The ML\nemulators are specifically trained to classify the state of mixing and predict\nthree quantities of interest (QoIs) characterizing species production, decay,\nand degree of mixing. Linear classifiers and regressors fail to reproduce the\nQoIs; however, ensemble methods (classifiers and regressors) and the MLP\naccurately classify the state of reactive mixing and the QoIs. Among ensemble\nmethods, random forest and decision-tree-based AdaBoost faithfully predict the\nQoIs. At run time, trained ML emulators are $\\approx10^5$ times faster than the\nhigh-fidelity numerical simulations. Speed and accuracy of the ensemble and MLP\nmodels facilitate uncertainty quantification, which usually requires 1,000s of\nmodel run, to estimate the uncertainty bounds on the QoIs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:50:19 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ahmmed", "B.", ""], ["Mudunuru", "M. K.", ""], ["Karra", "S.", ""], ["James", "S. C.", ""], ["Vesselinov", "V. V.", ""]]}, {"id": "2002.11519", "submitter": "Alberto Gandolfi", "authors": "Alberto Gandolfi", "title": "Decidability of Sample Complexity of PAC Learning in finite setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we observe that the sample complexity of PAC machine\nlearning of various concepts, including learning the maximum (EMX), can be\nexactly determined when the support of the probability measures considered as\nmodels satisfies an a-priori bound. This result contrasts with the recently\ndiscovered undecidability of EMX within ZFC for finitely supported\nprobabilities (with no a priori bound). Unfortunately, the decision procedure\nis at present, at least doubly exponential in the number of points times the\nuniform bound on the support size.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:27:36 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Gandolfi", "Alberto", ""]]}, {"id": "2002.11531", "submitter": "Jakob Lindqvist", "authors": "Jakob Lindqvist, Amanda Olmin, Fredrik Lindsten, Lennart Svensson", "title": "A general framework for ensemble distribution distillation", "comments": null, "journal-ref": "2020 IEEE 30th International Workshop on Machine Learning for\n  Signal Processing (MLSP), Espoo, Finland, 2020, pp. 1-6", "doi": "10.1109/MLSP49062.2020.9231703", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of neural networks have been shown to give better performance than\nsingle networks, both in terms of predictions and uncertainty estimation.\nAdditionally, ensembles allow the uncertainty to be decomposed into aleatoric\n(data) and epistemic (model) components, giving a more complete picture of the\npredictive uncertainty. Ensemble distillation is the process of compressing an\nensemble into a single model, often resulting in a leaner model that still\noutperforms the individual ensemble members. Unfortunately, standard\ndistillation erases the natural uncertainty decomposition of the ensemble. We\npresent a general framework for distilling both regression and classification\nensembles in a way that preserves the decomposition. We demonstrate the desired\nbehaviour of our framework and show that its predictive performance is on par\nwith standard distillation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:34:43 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 11:20:35 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lindqvist", "Jakob", ""], ["Olmin", "Amanda", ""], ["Lindsten", "Fredrik", ""], ["Svensson", "Lennart", ""]]}, {"id": "2002.11537", "submitter": "Ilyes Khemakhem", "authors": "Ilyes Khemakhem, Ricardo Pio Monti, Diederik P. Kingma, Aapo\n  Hyv\\\"arinen", "title": "ICE-BeeM: Identifiable Conditional Energy-Based Deep Models Based on\n  Nonlinear ICA", "comments": "Accepted for publication at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the identifiability theory of probabilistic models and establish\nsufficient conditions under which the representations learned by a very broad\nfamily of conditional energy-based models are unique in function space, up to a\nsimple transformation. In our model family, the energy function is the\ndot-product between two feature extractors, one for the dependent variable, and\none for the conditioning variable. We show that under mild conditions, the\nfeatures are unique up to scaling and permutation. Our results extend recent\ndevelopments in nonlinear ICA, and in fact, they lead to an important\ngeneralization of ICA models. In particular, we show that our model can be used\nfor the estimation of the components in the framework of Independently\nModulated Component Analysis (IMCA), a new generalization of nonlinear ICA that\nrelaxes the independence assumption. A thorough empirical study shows that\nrepresentations learned by our model from real-world image datasets are\nidentifiable, and improve performance in transfer learning and semi-supervised\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:43:30 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 09:39:39 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 18:18:44 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 17:49:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Khemakhem", "Ilyes", ""], ["Monti", "Ricardo Pio", ""], ["Kingma", "Diederik P.", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "2002.11543", "submitter": "Julien Bect", "authors": "S\\'ebastien Petit (L2S, GdR MASCOT-NUM), Julien Bect (L2S, GdR\n  MASCOT-NUM), S\\'ebastien da Veiga (GdR MASCOT-NUM), Paul Feliot (GdR\n  MASCOT-NUM), Emmanuel Vazquez (L2S, GdR MASCOT-NUM)", "title": "Towards new cross-validation-based estimators for Gaussian process\n  regression: efficient adjoint computation of gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the parameters of the covariance\nfunction of a Gaussian process by cross-validation. We suggest using new\ncross-validation criteria derived from the literature of scoring rules. We also\nprovide an efficient method for computing the gradient of a cross-validation\ncriterion. To the best of our knowledge, our method is more efficient than what\nhas been proposed in the literature so far. It makes it possible to lower the\ncomplexity of jointly evaluating leave-one-out criteria and their gradients.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:50:54 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 11:25:04 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Petit", "S\u00e9bastien", "", "L2S, GdR MASCOT-NUM"], ["Bect", "Julien", "", "L2S, GdR\n  MASCOT-NUM"], ["da Veiga", "S\u00e9bastien", "", "GdR MASCOT-NUM"], ["Feliot", "Paul", "", "GdR\n  MASCOT-NUM"], ["Vazquez", "Emmanuel", "", "L2S, GdR MASCOT-NUM"]]}, {"id": "2002.11544", "submitter": "Francesca Mignacco", "authors": "Francesca Mignacco, Florent Krzakala, Yue M. Lu and Lenka Zdeborov\\'a", "title": "The role of regularization in classification of high-dimensional noisy\n  Gaussian mixture", "comments": "8 pages + appendix, 6 figures", "journal-ref": "International Conference on Machine Learning, ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a high-dimensional mixture of two Gaussians in the noisy regime\nwhere even an oracle knowing the centers of the clusters misclassifies a small\nbut finite fraction of the points. We provide a rigorous analysis of the\ngeneralization error of regularized convex classifiers, including ridge, hinge\nand logistic regression, in the high-dimensional limit where the number $n$ of\nsamples and their dimension $d$ go to infinity while their ratio is fixed to\n$\\alpha= n/d$. We discuss surprising effects of the regularization that in some\ncases allows to reach the Bayes-optimal performances. We also illustrate the\ninterpolation peak at low regularization, and analyze the role of the\nrespective sizes of the two clusters.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:54:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Mignacco", "Francesca", ""], ["Krzakala", "Florent", ""], ["Lu", "Yue M.", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2002.11545", "submitter": "Yilun Jin", "authors": "Yilun Jin, Xiguang Wei, Yang Liu, Qiang Yang", "title": "Towards Utilizing Unlabeled Data in Federated Learning: A Survey and\n  Prospective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) proposed in recent years has received significant\nattention from researchers in that it can bring separate data sources together\nand build machine learning models in a collaborative but private manner. Yet,\nin most applications of FL, such as keyboard prediction, labeling data requires\nvirtually no additional efforts, which is not generally the case. In reality,\nacquiring large-scale labeled datasets can be extremely costly, which motivates\nresearch works that exploit unlabeled data to help build machine learning\nmodels. However, to the best of our knowledge, few existing works aim to\nutilize unlabeled data to enhance federated learning, which leaves a\npotentially promising research topic. In this paper, we identify the need to\nexploit unlabeled data in FL, and survey possible research fields that can\ncontribute to the goal.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:56:52 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 11:44:11 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jin", "Yilun", ""], ["Wei", "Xiguang", ""], ["Liu", "Yang", ""], ["Yang", "Qiang", ""]]}, {"id": "2002.11565", "submitter": "Raphael Ettedgui", "authors": "Rafael Pinot, Raphael Ettedgui, Geovani Rizk, Yann Chevaleyre, Jamal\n  Atif", "title": "Randomization matters. How to defend against strong adversarial attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is there a classifier that ensures optimal robustness against all adversarial\nattacks? This paper answers this question by adopting a game-theoretic point of\nview. We show that adversarial attacks and defenses form an infinite zero-sum\ngame where classical results (e.g. Sion theorem) do not apply. We demonstrate\nthe non-existence of a Nash equilibrium in our game when the classifier and the\nAdversary are both deterministic, hence giving a negative answer to the above\nquestion in the deterministic regime. Nonetheless, the question remains open in\nthe randomized regime. We tackle this problem by showing that, undermild\nconditions on the dataset distribution, any deterministic classifier can be\noutperformed by a randomized one. This gives arguments for using randomization,\nand leads us to a new algorithm for building randomized classifiers that are\nrobust to strong adversarial attacks. Empirical results validate our\ntheoretical analysis, and show that our defense method considerably outperforms\nAdversarial Training against state-of-the-art attacks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:31:31 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 11:27:26 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 10:11:46 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 12:52:40 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 12:53:03 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Pinot", "Rafael", ""], ["Ettedgui", "Raphael", ""], ["Rizk", "Geovani", ""], ["Chevaleyre", "Yann", ""], ["Atif", "Jamal", ""]]}, {"id": "2002.11569", "submitter": "Leslie Rice", "authors": "Leslie Rice, Eric Wong, J. Zico Kolter", "title": "Overfitting in adversarially robust deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice in deep learning to use overparameterized networks and\ntrain for as long as possible; there are numerous studies that show, both\ntheoretically and empirically, that such practices surprisingly do not unduly\nharm the generalization performance of the classifier. In this paper, we\nempirically study this phenomenon in the setting of adversarially trained deep\nnetworks, which are trained to minimize the loss under worst-case adversarial\nperturbations. We find that overfitting to the training set does in fact harm\nrobust performance to a very large degree in adversarially robust training\nacross multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and\nperturbation models ($\\ell_\\infty$ and $\\ell_2$). Based upon this observed\neffect, we show that the performance gains of virtually all recent algorithmic\nimprovements upon adversarial training can be matched by simply using early\nstopping. We also show that effects such as the double descent curve do still\noccur in adversarially trained models, yet fail to explain the observed\noverfitting. Finally, we study several classical and modern deep learning\nremedies for overfitting, including regularization and data augmentation, and\nfind that no approach in isolation improves significantly upon the gains\nachieved by early stopping. All code for reproducing the experiments as well as\npretrained model weights and training logs can be found at\nhttps://github.com/locuslab/robust_overfitting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:40:50 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 14:33:26 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Rice", "Leslie", ""], ["Wong", "Eric", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2002.11572", "submitter": "Aditya Saligrama", "authors": "Aditya Saligrama and Guillaume Leclerc", "title": "Revisiting Ensembles in an Adversarial Context: Improving Natural\n  Accuracy", "comments": "5 pages, accepted to ICLR 2020 Workshop on Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A necessary characteristic for the deployment of deep learning models in real\nworld applications is resistance to small adversarial perturbations while\nmaintaining accuracy on non-malicious inputs. While robust training provides\nmodels that exhibit better adversarial accuracy than standard models, there is\nstill a significant gap in natural accuracy between robust and non-robust\nmodels which we aim to bridge. We consider a number of ensemble methods\ndesigned to mitigate this performance difference. Our key insight is that model\ntrained to withstand small attacks, when ensembled, can often withstand\nsignificantly larger attacks, and this concept can in turn be leveraged to\noptimize natural accuracy. We consider two schemes, one that combines\npredictions from several randomly initialized robust models, and the other that\nfuses features from robust and standard models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:45:58 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Saligrama", "Aditya", ""], ["Leclerc", "Guillaume", ""]]}, {"id": "2002.11576", "submitter": "Matthew Vowels", "authors": "Matthew J. Vowels, Necati Cihan Camgoz and Richard Bowden", "title": "NestedVAE: Isolating Common Factors via Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair and unbiased machine learning is an important and active field of\nresearch, as decision processes are increasingly driven by models that learn\nfrom data. Unfortunately, any biases present in the data may be learned by the\nmodel, thereby inappropriately transferring that bias into the decision making\nprocess. We identify the connection between the task of bias reduction and that\nof isolating factors common between domains whilst encouraging domain specific\ninvariance. To isolate the common factors we combine the theory of deep latent\nvariable models with information bottleneck theory for scenarios whereby data\nmay be naturally paired across domains and no additional supervision is\nrequired. The result is the Nested Variational AutoEncoder (NestedVAE). Two\nouter VAEs with shared weights attempt to reconstruct the input and infer a\nlatent space, whilst a nested VAE attempts to reconstruct the latent\nrepresentation of one image, from the latent representation of its paired\nimage. In so doing, the nested VAE isolates the common latent factors/causes\nand becomes invariant to unwanted factors that are not shared between paired\nimages. We also propose a new metric to provide a balanced method of evaluating\nconsistency and classifier performance across domains which we refer to as the\nAdjusted Parity metric. An evaluation of NestedVAE on both domain and attribute\ninvariance, change detection, and learning common factors for the prediction of\nbiological sex demonstrates that NestedVAE significantly outperforms\nalternative methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:49:57 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Vowels", "Matthew J.", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2002.11589", "submitter": "Carolyn Kim", "authors": "Carolyn Kim, Mohsen Bayati", "title": "Recommendation on a Budget: Column Space Recovery from Partially\n  Observed Entries with Random or Active Sampling", "comments": "A shorter version is accepted to AISTATS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze alternating minimization for column space recovery of a partially\nobserved, approximately low rank matrix with a growing number of columns and a\nfixed budget of observations per column. In this work, we prove that if the\nbudget is greater than the rank of the matrix, column space recovery succeeds\n-- as the number of columns grows, the estimate from alternating minimization\nconverges to the true column space with probability tending to one. From our\nproof techniques, we naturally formulate an active sampling strategy for\nchoosing entries of a column that is theoretically and empirically (on\nsynthetic and real data) better than the commonly studied uniformly random\nsampling strategy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:17:05 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 00:14:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kim", "Carolyn", ""], ["Bayati", "Mohsen", ""]]}, {"id": "2002.11599", "submitter": "Puning Zhao", "authors": "Puning Zhao, Lifeng Lai", "title": "Minimax Optimal Estimation of KL Divergence for Continuous Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating Kullback-Leibler divergence from identical and independently\ndistributed samples is an important problem in various domains. One simple and\neffective estimator is based on the k nearest neighbor distances between these\nsamples. In this paper, we analyze the convergence rates of the bias and\nvariance of this estimator. Furthermore, we derive a lower bound of the minimax\nmean square error and show that kNN method is asymptotically rate optimal.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:37:37 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Zhao", "Puning", ""], ["Lai", "Lifeng", ""]]}, {"id": "2002.11601", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Yin-Peng Xie, and Wu-Jun Li", "title": "Stagewise Enlargement of Batch Size for SGD-based Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research shows that the batch size can seriously affect the\nperformance of stochastic gradient descent~(SGD) based learning, including\ntraining speed and generalization ability. A larger batch size typically\nresults in less parameter updates. In distributed training, a larger batch size\nalso results in less frequent communication. However, a larger batch size can\nmake a generalization gap more easily. Hence, how to set a proper batch size\nfor SGD has recently attracted much attention. Although some methods about\nsetting batch size have been proposed, the batch size problem has still not\nbeen well solved. In this paper, we first provide theory to show that a proper\nbatch size is related to the gap between initialization and optimum of the\nmodel parameter. Then based on this theory, we propose a novel method, called\n\\underline{s}tagewise \\underline{e}nlargement of \\underline{b}atch\n\\underline{s}ize~(\\mbox{SEBS}), to set proper batch size for SGD. More\nspecifically, \\mbox{SEBS} adopts a multi-stage scheme, and enlarges the batch\nsize geometrically by stage. We theoretically prove that, compared to classical\nstagewise SGD which decreases learning rate by stage, \\mbox{SEBS} can reduce\nthe number of parameter updates without increasing generalization error. SEBS\nis suitable for \\mbox{SGD}, momentum \\mbox{SGD} and AdaGrad. Empirical results\non real data successfully verify the theories of \\mbox{SEBS}. Furthermore,\nempirical results also show that SEBS can outperform other baselines.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:40:31 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 03:13:52 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Xie", "Yin-Peng", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2002.11603", "submitter": "Frederik Harder", "authors": "Frederik Harder, Kamil Adamczewski, Mijung Park", "title": "DP-MERF: Differentially Private Mean Embeddings with Random Features for\n  Practical Privacy-Preserving Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a differentially private data generation paradigm using random\nfeature representations of kernel mean embeddings when comparing the\ndistribution of true data with that of synthetic data. We exploit the random\nfeature representations for two important benefits. First, we require a minimal\nprivacy cost for training deep generative models. This is because unlike\nkernel-based distance metrics that require computing the kernel matrix on all\npairs of true and synthetic data points, we can detach the data-dependent term\nfrom the term solely dependent on synthetic data. Hence, we need to perturb the\ndata-dependent term only once and then use it repeatedly during the generator\ntraining. Second, we can obtain an analytic sensitivity of the kernel mean\nembedding as the random features are norm bounded by construction. This removes\nthe necessity of hyper-parameter search for a clipping norm to handle the\nunknown sensitivity of a generator network. We provide several variants of our\nalgorithm, differentially-private mean embeddings with random features\n(DP-MERF) to jointly generate labels and input features for datasets such as\nheterogeneous tabular data and image data. Our algorithm achieves drastically\nbetter privacy-utility trade-offs than existing methods when tested on several\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:41:41 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 22:45:06 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 16:32:31 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 08:59:13 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 14:38:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Harder", "Frederik", ""], ["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "2002.11609", "submitter": "Jiahao Su", "authors": "Jiahao Su, Shiqi Wang, Furong Huang", "title": "ARMA Nets: Expanding Receptive Field for Dense Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global information is essential for dense prediction problems, whose goal is\nto compute a discrete or continuous label for each pixel in the images.\nTraditional convolutional layers in neural networks, initially designed for\nimage classification, are restrictive in these problems since the filter size\nlimits their receptive fields. In this work, we propose to replace any\ntraditional convolutional layer with an autoregressive moving-average (ARMA)\nlayer, a novel module with an adjustable receptive field controlled by the\nlearnable autoregressive coefficients. Compared with traditional convolutional\nlayers, our ARMA layer enables explicit interconnections of the output neurons\nand learns its receptive field by adapting the autoregressive coefficients of\nthe interconnections. ARMA layer is adjustable to different types of tasks: for\ntasks where global information is crucial, it is capable of learning relatively\nlarge autoregressive coefficients to allow for an output neuron's receptive\nfield covering the entire input; for tasks where only local information is\nrequired, it can learn small or near zero autoregressive coefficients and\nautomatically reduces to a traditional convolutional layer. We show both\ntheoretically and empirically that the effective receptive field of networks\nwith ARMA layers (named as ARMA networks) expands with larger autoregressive\ncoefficients. We also provably solve the instability problem of learning and\nprediction in the ARMA layer through a re-parameterization mechanism.\nAdditionally, we demonstrate that ARMA networks substantially improve their\nbaselines on challenging dense prediction tasks including video prediction and\nsemantic segmentation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:18:27 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 04:12:39 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Su", "Jiahao", ""], ["Wang", "Shiqi", ""], ["Huang", "Furong", ""]]}, {"id": "2002.11611", "submitter": "Eren Sezener", "authors": "Eren Sezener, Marcus Hutter, David Budden, Jianan Wang, Joel Veness", "title": "Online Learning in Contextual Bandits using Gated Linear Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new and completely online contextual bandit algorithm called\nGated Linear Contextual Bandits (GLCB). This algorithm is based on Gated Linear\nNetworks (GLNs), a recently introduced deep learning architecture with\nproperties well-suited to the online setting. Leveraging data-dependent gating\nproperties of the GLN we are able to estimate prediction uncertainty with\neffectively zero algorithmic overhead. We empirically evaluate GLCB compared to\n9 state-of-the-art algorithms that leverage deep neural networks, on a standard\nbenchmark suite of discrete and continuous contextual bandit problems. GLCB\nobtains median first-place despite being the only online method, and we further\nsupport these results with a theoretical study of its convergence properties.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 11:50:43 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 09:38:19 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sezener", "Eren", ""], ["Hutter", "Marcus", ""], ["Budden", "David", ""], ["Wang", "Jianan", ""], ["Veness", "Joel", ""]]}, {"id": "2002.11613", "submitter": "Lovedeep Gondara", "authors": "Lovedeep Gondara, Ke Wang, Ricardo Silva Carvalho", "title": "The Differentially Private Lottery Ticket Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the differentially private lottery ticket mechanism (DPLTM). An\nend-to-end differentially private training paradigm based on the lottery ticket\nhypothesis. Using \"high-quality winners\", selected via our custom score\nfunction, DPLTM significantly improves the privacy-utility trade-off over the\nstate-of-the-art. We show that DPLTM converges faster, allowing for early\nstopping with reduced privacy budget consumption. We further show that the\ntickets from DPLTM are transferable across datasets, domains, and\narchitectures. Our extensive evaluation on several public datasets provides\nevidence to our claims.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 06:15:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Gondara", "Lovedeep", ""], ["Wang", "Ke", ""], ["Carvalho", "Ricardo Silva", ""]]}, {"id": "2002.11621", "submitter": "Adriano Fazzone", "authors": "Giorgio Barnab\\`o and Adriano Fazzone and Stefano Leonardi and Chris\n  Schwiegelshohn", "title": "Algorithms for Fair Team Formation in Online Labour Marketplaces", "comments": "Accepted at \"FATES 2019 : 1st Workshop on Fairness, Accountability,\n  Transparency, Ethics, and Society on the Web\" (http://fates19.isti.cnr.it)", "journal-ref": "\"Companion Proceedings of The 2019 World Wide Web Conference\",\n  2019, pages 484-490", "doi": "10.1145/3308560.3317587", "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As freelancing work keeps on growing almost everywhere due to a sharp\ndecrease in communication costs and to the widespread of Internet-based labour\nmarketplaces (e.g., guru.com, feelancer.com, mturk.com, upwork.com), many\nresearchers and practitioners have started exploring the benefits of\noutsourcing and crowdsourcing. Since employers often use these platforms to\nfind a group of workers to complete a specific task, researchers have focused\ntheir efforts on the study of team formation and matching algorithms and on the\ndesign of effective incentive schemes. Nevertheless, just recently, several\nconcerns have been raised on possibly unfair biases introduced through the\nalgorithms used to carry out these selection and matching procedures. For this\nreason, researchers have started studying the fairness of algorithms related to\nthese online marketplaces, looking for intelligent ways to overcome the\nalgorithmic bias that frequently arises. Broadly speaking, the aim is to\nguarantee that, for example, the process of hiring workers through the use of\nmachine learning and algorithmic data analysis tools does not discriminate,\neven unintentionally, on grounds of nationality or gender. In this short paper,\nwe define the Fair Team Formation problem in the following way: given an online\nlabour marketplace where each worker possesses one or more skills, and where\nall workers are divided into two or more not overlapping classes (for examples,\nmen and women), we want to design an algorithm that is able to find a team with\nall the skills needed to complete a given task, and that has the same number of\npeople from all classes. We provide inapproximability results for the Fair Team\nFormation problem together with four algorithms for the problem itself. We also\ntested the effectiveness of our algorithmic solutions by performing experiments\nusing real data from an online labor marketplace.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:33:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Barnab\u00f2", "Giorgio", ""], ["Fazzone", "Adriano", ""], ["Leonardi", "Stefano", ""], ["Schwiegelshohn", "Chris", ""]]}, {"id": "2002.11631", "submitter": "Zhenyu Zhao", "authors": "Huigang Chen, Totte Harinen, Jeong-Yoon Lee, Mike Yung, Zhenyu Zhao", "title": "CausalML: Python Package for Causal Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CausalML is a Python implementation of algorithms related to causal inference\nand machine learning. Algorithms combining causal inference and machine\nlearning have been a trending topic in recent years. This package tries to\nbridge the gap between theoretical work on methodology and practical\napplications by making a collection of methods in this field available in\nPython. This paper introduces the key concepts, scope, and use cases of this\npackage.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:35:33 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 18:34:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Huigang", ""], ["Harinen", "Totte", ""], ["Lee", "Jeong-Yoon", ""], ["Yung", "Mike", ""], ["Zhao", "Zhenyu", ""]]}, {"id": "2002.11637", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Vikas Dhiman, Nikolay Atanasov", "title": "Learning Navigation Costs from Demonstration in Partially Observable\n  Environments", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on inverse reinforcement learning (IRL) to enable safe and\nefficient autonomous navigation in unknown partially observable environments.\nThe objective is to infer a cost function that explains expert-demonstrated\nnavigation behavior while relying only on the observations and state-control\ntrajectory used by the expert. We develop a cost function representation\ncomposed of two parts: a probabilistic occupancy encoder, with recurrent\ndependence on the observation sequence, and a cost encoder, defined over the\noccupancy features. The representation parameters are optimized by\ndifferentiating the error between demonstrated controls and a control policy\ncomputed from the cost encoder. Such differentiation is typically computed by\ndynamic programming through the value function over the whole state space. We\nobserve that this is inefficient in large partially observable environments\nbecause most states are unexplored. Instead, we rely on a closed-form\nsubgradient of the cost-to-go obtained only over a subset of promising states\nvia an efficient motion-planning algorithm such as A* or RRT. Our experiments\nshow that our model exceeds the accuracy of baseline IRL algorithms in robot\nnavigation tasks, while substantially improving the efficiency of training and\ntest-time inference.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:15:10 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Wang", "Tianyu", ""], ["Dhiman", "Vikas", ""], ["Atanasov", "Nikolay", ""]]}, {"id": "2002.11642", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Masatoshi Uehara, Shota Yasui", "title": "Off-Policy Evaluation and Learning for External Validity under a\n  Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider evaluating and training a new policy for the evaluation data by\nusing the historical data obtained from a different policy. The goal of\noff-policy evaluation (OPE) is to estimate the expected reward of a new policy\nover the evaluation data, and that of off-policy learning (OPL) is to find a\nnew policy that maximizes the expected reward over the evaluation data.\nAlthough the standard OPE and OPL assume the same distribution of covariate\nbetween the historical and evaluation data, a covariate shift often exists,\ni.e., the distribution of the covariate of the historical data is different\nfrom that of the evaluation data. In this paper, we derive the efficiency bound\nof OPE under a covariate shift. Then, we propose doubly robust and efficient\nestimators for OPE and OPL under a covariate shift by using a nonparametric\nestimator of the density ratio between the historical and evaluation data\ndistributions. We also discuss other possible estimators and compare their\ntheoretical properties. Finally, we confirm the effectiveness of the proposed\nestimators through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:18:43 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:48:31 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 01:40:41 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kato", "Masahiro", ""], ["Uehara", "Masatoshi", ""], ["Yasui", "Shota", ""]]}, {"id": "2002.11650", "submitter": "Chara Podimata", "authors": "Akshay Krishnamurthy, Thodoris Lykouris, Chara Podimata, and Robert\n  Schapire", "title": "Contextual Search in the Presence of Irrational Agents", "comments": "Compared to the first version titled \"Corrupted Multidimensional\n  Binary Search: Learning in the Presence of Irrational Agents\", this version\n  provides a broader scope of behavioral models of irrationality, specifies how\n  the results apply to different loss functions, and discusses the power and\n  limitations of additional algorithmic approaches", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual search, a generalization of binary search in higher\ndimensions, which captures settings such as feature-based dynamic pricing.\nStandard game-theoretic formulations of this problem assume that agents act in\naccordance with a specific behavioral model. In practice, however, some agents\nmay not prescribe to the dominant behavioral model or may act in ways that are\nseemingly arbitrarily irrational. Existing algorithms heavily depend on the\nbehavioral model being (approximately) accurate for all agents and have poor\nperformance in the presence of even a few such arbitrarily irrational agents.\n  We initiate the study of contextual search when some of the agents can behave\nin ways inconsistent with the underlying behavioral model. In particular, we\nprovide two algorithms, one built on robustifying multidimensional binary\nsearch methods and one on translating the setting to a proxy setting\nappropriate for gradient descent. Our techniques draw inspiration from learning\ntheory, game theory, high-dimensional geometry, and convex analysis.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:25:53 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 16:16:00 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 17:26:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Lykouris", "Thodoris", ""], ["Podimata", "Chara", ""], ["Schapire", "Robert", ""]]}, {"id": "2002.11651", "submitter": "Hussein Mozannar", "authors": "Hussein Mozannar, Mesrob I. Ohannessian, Nathan Srebro", "title": "Fair Learning with Private Demographic Data", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive attributes such as race are rarely available to learners in real\nworld settings as their collection is often restricted by laws and regulations.\nWe give a scheme that allows individuals to release their sensitive information\nprivately while still allowing any downstream entity to learn\nnon-discriminatory predictors. We show how to adapt non-discriminatory learners\nto work with privatized protected attributes giving theoretical guarantees on\nperformance. Finally, we highlight how the methodology could apply to learning\nfair predictors in settings where protected attributes are only available for a\nsubset of the data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:26:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:48:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mozannar", "Hussein", ""], ["Ohannessian", "Mesrob I.", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.11661", "submitter": "Sebastian Macaluso", "authors": "Craig S. Greenberg, Sebastian Macaluso, Nicholas Monath, Ji-Ah Lee,\n  Patrick Flaherty, Kyle Cranmer, Andrew McGregor, Andrew McCallum", "title": "Data Structures & Algorithms for Exact Inference in Hierarchical\n  Clustering", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is a fundamental task often used to discover\nmeaningful structures in data, such as phylogenetic trees, taxonomies of\nconcepts, subtypes of cancer, and cascades of particle decays in particle\nphysics. Typically approximate algorithms are used for inference due to the\ncombinatorial number of possible hierarchical clusterings. In contrast to\nexisting methods, we present novel dynamic-programming algorithms for\n\\emph{exact} inference in hierarchical clustering based on a novel trellis data\nstructure, and we prove that we can exactly compute the partition function,\nmaximum likelihood hierarchy, and marginal probabilities of sub-hierarchies and\nclusters. Our algorithms scale in time and space proportional to the powerset\nof $N$ elements which is super-exponentially more efficient than explicitly\nconsidering each of the (2N-3)!! possible hierarchies. Also, for larger\ndatasets where our exact algorithms become infeasible, we introduce an\napproximate algorithm based on a sparse trellis that compares well to other\nbenchmarks. Exact methods are relevant to data analyses in particle physics and\nfor finding correlations among gene expression in cancer genomics, and we give\nexamples in both areas, where our algorithms outperform greedy and beam search\nbaselines. In addition, we consider Dasgupta's cost with synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:43:53 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 16:19:28 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 15:18:02 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Greenberg", "Craig S.", ""], ["Macaluso", "Sebastian", ""], ["Monath", "Nicholas", ""], ["Lee", "Ji-Ah", ""], ["Flaherty", "Patrick", ""], ["Cranmer", "Kyle", ""], ["McGregor", "Andrew", ""], ["McCallum", "Andrew", ""]]}, {"id": "2002.11665", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Profile Entropy: A Fundamental Measure for the Learnability and\n  Compressibility of Discrete Distributions", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The profile of a sample is the multiset of its symbol frequencies. We show\nthat for samples of discrete distributions, profile entropy is a fundamental\nmeasure unifying the concepts of estimation, inference, and compression.\nSpecifically, profile entropy a) determines the speed of estimating the\ndistribution relative to the best natural estimator; b) characterizes the rate\nof inferring all symmetric properties compared with the best estimator over any\nlabel-invariant distribution collection; c) serves as the limit of profile\ncompression, for which we derive optimal near-linear-time block and sequential\nalgorithms. To further our understanding of profile entropy, we investigate its\nattributes, provide algorithms for approximating its value, and determine its\nmagnitude for numerous structural distribution families.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:49:04 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "2002.11675", "submitter": "Fabrizio Albertetti", "authors": "Fabrizio Albertetti, Hatem Ghorbel", "title": "Workload Prediction of Business Processes -- An Approach Based on\n  Process Mining and Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the interconnectedness and digitization of industrial\nmachines, known as Industry 4.0, pave the way for new analytical techniques.\nIndeed, the availability and the richness of production-related data enables\nnew data-driven methods. In this paper, we propose a process mining approach\naugmented with artificial intelligence that (1) reconstructs the historical\nworkload of a company and (2) predicts the workload using neural networks. Our\nmethod relies on logs, representing the history of business processes related\nto manufacturing. These logs are used to quantify the supply and demand and are\nfed into a recurrent neural network model to predict customer orders. The\ncorresponding activities to fulfill these orders are then sampled from history\nwith a replay mechanism, based on criteria such as trace frequency and\nactivities similarity. An evaluation and illustration of the method is\nperformed on the administrative processes of Heraeus Materials SA. The workload\nprediction on a one-year test set achieves an MAPE score of 19% for a one-week\nforecast. The case study suggests a reasonable accuracy and confirms that a\ngood understanding of the historical workload combined to articulated\npredictions are of great help for supporting management decisions and can\ndecrease costs with better resources planning on a medium-term level.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:19:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Albertetti", "Fabrizio", ""], ["Ghorbel", "Hatem", ""]]}, {"id": "2002.11684", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Chi Jin, Michael I. Jordan", "title": "Provable Meta-Learning of Linear Representations", "comments": "Lower bound slightly improved to include task diversity parameter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning, or learning-to-learn, seeks to design algorithms that can\nutilize previous experience to rapidly learn new skills or adapt to new\nenvironments. Representation learning -- a key tool for performing\nmeta-learning -- learns a data representation that can transfer knowledge\nacross multiple tasks, which is essential in regimes where data is scarce.\nDespite a recent surge of interest in the practice of meta-learning, the\ntheoretical underpinnings of meta-learning algorithms are lacking, especially\nin the context of learning transferable representations. In this paper, we\nfocus on the problem of multi-task linear regression -- in which multiple\nlinear regression models share a common, low-dimensional linear representation.\nHere, we provide provably fast, sample-efficient algorithms to address the dual\nchallenges of (1) learning a common set of features from multiple, related\ntasks, and (2) transferring this knowledge to new, unseen tasks. Both are\ncentral to the general problem of meta-learning. Finally, we complement these\nresults by providing information-theoretic lower bounds on the sample\ncomplexity of learning these linear features.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:21:34 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 20:40:37 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 22:20:33 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 22:15:30 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Jin", "Chi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.11686", "submitter": "Jaidip Kotak", "authors": "Jaidip Kotak and Yuval Elovici", "title": "IoT Device Identification Using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57805-3_8", "report-no": null, "categories": "cs.CR cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of IoT devices in organizations has increased the number of\nattack vectors available to attackers due to the less secure nature of the\ndevices. The widely adopted bring your own device (BYOD) policy which allows an\nemployee to bring any IoT device into the workplace and attach it to an\norganization's network also increases the risk of attacks. In order to address\nthis threat, organizations often implement security policies in which only the\nconnection of white-listed IoT devices is permitted. To monitor adherence to\nsuch policies and protect their networks, organizations must be able to\nidentify the IoT devices connected to their networks and, more specifically, to\nidentify connected IoT devices that are not on the white-list (unknown\ndevices). In this study, we applied deep learning on network traffic to\nautomatically identify IoT devices connected to the network. In contrast to\nprevious work, our approach does not require that complex feature engineering\nbe applied on the network traffic, since we represent the communication\nbehavior of IoT devices using small images built from the IoT devices network\ntraffic payloads. In our experiments, we trained a multiclass classifier on a\npublicly available dataset, successfully identifying 10 different IoT devices\nand the traffic of smartphones and computers, with over 99% accuracy. We also\ntrained multiclass classifiers to detect unauthorized IoT devices connected to\nthe network, achieving over 99% overall average detection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:24:49 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kotak", "Jaidip", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.11701", "submitter": "Siddharth Biswal", "authors": "Siddharth Biswal, Cao Xiao, Lucas M. Glass, M. Brandon Westover, and\n  Jimeng Sun", "title": "CLARA: Clinical Report Auto-completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating clinical reports from raw recordings such as X-rays and\nelectroencephalogram (EEG) is an essential and routine task for doctors.\nHowever, it is often time-consuming to write accurate and detailed reports.\nMost existing methods try to generate the whole reports from the raw input with\nlimited success because 1) generated reports often contain errors that need\nmanual review and correction, 2) it does not save time when doctors want to\nwrite additional information into the report, and 3) the generated reports are\nnot customized based on individual doctors' preference. We propose {\\it\nCL}inic{\\it A}l {\\it R}eport {\\it A}uto-completion (CLARA), an interactive\nmethod that generates reports in a sentence by sentence fashion based on\ndoctors' anchor words and partially completed sentences. CLARA searches for\nmost relevant sentences from existing reports as the template for the current\nreport. The retrieved sentences are sequentially modified by combining with the\ninput feature representations to create the final report. In our experimental\nevaluation, CLARA achieved 0.393 CIDEr and 0.248 BLEU-4 on X-ray reports and\n0.482 CIDEr and 0.491 BLEU-4 for EEG reports for sentence-level generation,\nwhich is up to 35% improvement over the best baseline. Also via our qualitative\nevaluation, CLARA is shown to produce reports which have a significantly higher\nlevel of approval by doctors in a user study (3.74 out of 5 for CLARA vs 2.52\nout of 5 for the baseline).\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:45:00 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:32:52 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Biswal", "Siddharth", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Westover", "M. Brandon", ""], ["Sun", "Jimeng", ""]]}, {"id": "2002.11708", "submitter": "Alexander Li", "authors": "Alexander C. Li, Lerrel Pinto, Pieter Abbeel", "title": "Generalized Hindsight for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key reasons for the high sample complexity in reinforcement\nlearning (RL) is the inability to transfer knowledge from one task to another.\nIn standard multi-task RL settings, low-reward data collected while trying to\nsolve one task provides little to no signal for solving that particular task\nand is hence effectively wasted. However, we argue that this data, which is\nuninformative for one task, is likely a rich source of information for other\ntasks. To leverage this insight and efficiently reuse data, we present\nGeneralized Hindsight: an approximate inverse reinforcement learning technique\nfor relabeling behaviors with the right tasks. Intuitively, given a behavior\ngenerated under one task, Generalized Hindsight returns a different task that\nthe behavior is better suited for. Then, the behavior is relabeled with this\nnew task before being used by an off-policy RL optimizer. Compared to standard\nrelabeling techniques, Generalized Hindsight provides a substantially more\nefficient reuse of samples, which we empirically demonstrate on a suite of\nmulti-task navigation and manipulation tasks. Videos and code can be accessed\nhere: https://sites.google.com/view/generalized-hindsight.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:57:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Li", "Alexander C.", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2002.11711", "submitter": "Yuan Liu Prof.", "authors": "Yuan Liu, Shuai Sun, Zhengpeng Ai, Shuangfeng Zhang, Zelei Liu, Han Yu", "title": "FedCoin: A Peer-to-Peer Payment System for Federated Learning", "comments": "7 pages, 6 figures,21 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated learning (FL) is an emerging collaborative machine learning method\nto train models on distributed datasets with privacy concerns. To properly\nincentivize data owners to contribute their efforts, Shapley Value (SV) is\noften adopted to fairly assess their contribution. However, the calculation of\nSV is time-consuming and computationally costly. In this paper, we propose\nFedCoin, a blockchain-based peer-to-peer payment system for FL to enable a\nfeasible SV based profit distribution. In FedCoin, blockchain consensus\nentities calculate SVs and a new block is created based on the proof of Shapley\n(PoSap) protocol. It is in contrast to the popular BitCoin network where\nconsensus entities \"mine\" new blocks by solving meaningless puzzles. Based on\nthe computed SVs, a scheme for dividing the incentive payoffs among FL clients\nwith nonrepudiation and tamper-resistance properties is proposed. Experimental\nresults based on real-world data show that FedCoin can promote high-quality\ndata from FL clients through accurately computing SVs with an upper bound on\nthe computational resources required for reaching consensus. It opens\nopportunities for non-data owners to play a role in FL.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:43:48 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Yuan", ""], ["Sun", "Shuai", ""], ["Ai", "Zhengpeng", ""], ["Zhang", "Shuangfeng", ""], ["Liu", "Zelei", ""], ["Yu", "Han", ""]]}, {"id": "2002.11743", "submitter": "Jay Whang", "authors": "Jay Whang, Erik M. Lindgren, Alexandros G. Dimakis", "title": "Composing Normalizing Flows for Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an inverse problem with a normalizing flow prior, we wish to estimate\nthe distribution of the underlying signal conditioned on the observations. We\napproach this problem as a task of conditional inference on the pre-trained\nunconditional flow model. We first establish that this is computationally hard\nfor a large class of flow models. Motivated by this, we propose a framework for\napproximate inference that estimates the target conditional as a composition of\ntwo flow models. This formulation leads to a stable variational inference\ntraining procedure that avoids adversarial training. Our method is evaluated on\na variety of inverse problems and is shown to produce high-quality samples with\nuncertainty quantification. We further demonstrate that our approach can be\namortized for zero-shot inference.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 19:01:11 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 05:06:00 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 18:00:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Whang", "Jay", ""], ["Lindgren", "Erik M.", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "2002.11770", "submitter": "Hao Li", "authors": "Hao Li, Pratik Chaudhari, Hao Yang, Michael Lam, Avinash Ravichandran,\n  Rahul Bhotika, Stefano Soatto", "title": "Rethinking the Hyperparameters for Fine-tuning", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning from pre-trained ImageNet models has become the de-facto standard\nfor various computer vision tasks. Current practices for fine-tuning typically\ninvolve selecting an ad-hoc choice of hyperparameters and keeping them fixed to\nvalues normally used for training from scratch. This paper re-examines several\ncommon practices of setting hyperparameters for fine-tuning. Our findings are\nbased on extensive empirical evaluation for fine-tuning on various transfer\nlearning benchmarks. (1) While prior works have thoroughly investigated\nlearning rate and batch size, momentum for fine-tuning is a relatively\nunexplored parameter. We find that the value of momentum also affects\nfine-tuning performance and connect it with previous theoretical findings. (2)\nOptimal hyperparameters for fine-tuning, in particular, the effective learning\nrate, are not only dataset dependent but also sensitive to the similarity\nbetween the source domain and target domain. This is in contrast to\nhyperparameters for training from scratch. (3) Reference-based regularization\nthat keeps models close to the initial model does not necessarily apply for\n\"dissimilar\" datasets. Our findings challenge common practices of fine-tuning\nand encourages deep learning practitioners to rethink the hyperparameters for\nfine-tuning.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:59:52 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Li", "Hao", ""], ["Chaudhari", "Pratik", ""], ["Yang", "Hao", ""], ["Lam", "Michael", ""], ["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2002.11787", "submitter": "Yucheng Lu", "authors": "Yucheng Lu and Christopher De Sa", "title": "Moniqua: Modulo Quantized Communication in Decentralized SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running Stochastic Gradient Descent (SGD) in a decentralized fashion has\nshown promising results. In this paper we propose Moniqua, a technique that\nallows decentralized SGD to use quantized communication. We prove in theory\nthat Moniqua communicates a provably bounded number of bits per iteration,\nwhile converging at the same asymptotic rate as the original algorithm does\nwith full-precision communication. Moniqua improves upon prior works in that it\n(1) requires zero additional memory, (2) works with 1-bit quantization, and (3)\nis applicable to a variety of decentralized algorithms. We demonstrate\nempirically that Moniqua converges faster with respect to wall clock time than\nother quantized decentralized algorithms. We also show that Moniqua is robust\nto very low bit-budgets, allowing 1-bit-per-parameter communication without\ncompromising validation accuracy when training ResNet20 and ResNet110 on\nCIFAR10.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 20:58:57 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 16:46:25 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 04:12:51 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Lu", "Yucheng", ""], ["De Sa", "Christopher", ""]]}, {"id": "2002.11791", "submitter": "Yinjun Wu", "authors": "Yinjun Wu, Val Tannen, Susan B. Davidson", "title": "PrIU: A Provenance-Based Approach for Incrementally Updating Regression\n  Models", "comments": "28 Pages, published in 2020 ACM SIGMOD International Conference on\n  Management of Data (SIGMOD 2020)", "journal-ref": null, "doi": "10.1145/3318464.3380571", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous use of machine learning algorithms brings new challenges to\ntraditional database problems such as incremental view update. Much effort is\nbeing put in better understanding and debugging machine learning models, as\nwell as in identifying and repairing errors in training datasets. Our focus is\non how to assist these activities when they have to retrain the machine\nlearning model after removing problematic training samples in cleaning or\nselecting different subsets of training data for interpretability. This paper\npresents an efficient provenance-based approach, PrIU, and its optimized\nversion, PrIU-opt, for incrementally updating model parameters without\nsacrificing prediction accuracy. We prove the correctness and convergence of\nthe incrementally updated model parameters, and validate it experimentally.\nExperimental results show that up to two orders of magnitude speed-ups can be\nachieved by PrIU-opt compared to simply retraining the model from scratch, yet\nobtaining highly similar models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:04:06 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wu", "Yinjun", ""], ["Tannen", "Val", ""], ["Davidson", "Susan B.", ""]]}, {"id": "2002.11798", "submitter": "Sicheng Zhu", "authors": "Sicheng Zhu, Xiao Zhang, David Evans", "title": "Learning Adversarially Robust Representations via Worst-Case Mutual\n  Information Maximization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models that are robust against adversarial inputs\nposes seemingly insurmountable challenges. To better understand adversarial\nrobustness, we consider the underlying problem of learning robust\nrepresentations. We develop a notion of representation vulnerability that\ncaptures the maximum change of mutual information between the input and output\ndistributions, under the worst-case input perturbation. Then, we prove a\ntheorem that establishes a lower bound on the minimum adversarial risk that can\nbe achieved for any downstream classifier based on its representation\nvulnerability. We propose an unsupervised learning method for obtaining\nintrinsically robust representations by maximizing the worst-case mutual\ninformation between the input and output distributions. Experiments on\ndownstream classification tasks support the robustness of the representations\nfound using unsupervised learning with our training principle.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:20:40 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 15:18:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhu", "Sicheng", ""], ["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "2002.11803", "submitter": "Cyril Zhang", "authors": "Naman Agarwal, Rohan Anil, Elad Hazan, Tomer Koren, Cyril Zhang", "title": "Disentangling Adaptive Gradient Methods from Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate several confounding factors in the evaluation of optimization\nalgorithms for deep learning. Primarily, we take a deeper look at how adaptive\ngradient methods interact with the learning rate schedule, a notoriously\ndifficult-to-tune hyperparameter which has dramatic effects on the convergence\nand generalization of neural network training. We introduce a \"grafting\"\nexperiment which decouples an update's magnitude from its direction, finding\nthat many existing beliefs in the literature may have arisen from insufficient\nisolation of the implicit schedule of step sizes. Alongside this contribution,\nwe present some empirical and theoretical retrospectives on the generalization\nof adaptive gradient methods, aimed at bringing more clarity to this space.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:42:49 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Agarwal", "Naman", ""], ["Anil", "Rohan", ""], ["Hazan", "Elad", ""], ["Koren", "Tomer", ""], ["Zhang", "Cyril", ""]]}, {"id": "2002.11804", "submitter": "Xiao Xu", "authors": "Xiao Xu, Qing Zhao", "title": "Memory-Constrained No-Regret Learning in Adversarial Bandits", "comments": "Accepted by IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2021.3070201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial bandit problem with memory constraints is studied where only\nthe statistics of a subset of arms can be stored. A hierarchical learning\npolicy that requires only a sublinear order of memory space in terms of the\nnumber of arms is developed. Its sublinear regret orders with respect to the\ntime horizon are established for both weak regret and shifting regret. This\nwork appears to be the first on memory-constrained bandit problems under the\nadversarial setting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:43:45 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 08:04:40 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Xu", "Xiao", ""], ["Zhao", "Qing", ""]]}, {"id": "2002.11815", "submitter": "Yuexi Wang", "authors": "Yuexi Wang, Veronika Ro\\v{c}kov\\'a", "title": "Uncertainty Quantification for Sparse Deep Learning", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, PMLR 108:298-308, 2020", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods continue to have a decided impact on machine learning,\nboth in theory and in practice. Statistical theoretical developments have been\nmostly concerned with approximability or rates of estimation when recovering\ninfinite dimensional objects (curves or densities). Despite the impressive\narray of available theoretical results, the literature has been largely silent\nabout uncertainty quantification for deep learning. This paper takes a step\nforward in this important direction by taking a Bayesian point of view. We\nstudy Gaussian approximability of certain aspects of posterior distributions of\nsparse deep ReLU architectures in non-parametric regression. Building on tools\nfrom Bayesian non-parametrics, we provide semi-parametric Bernstein-von Mises\ntheorems for linear and quadratic functionals, which guarantee that implied\nBayesian credible regions have valid frequentist coverage. Our results provide\nnew theoretical justifications for (Bayesian) deep learning with ReLU\nactivation functions, highlighting their inferential potential.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:00:16 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 23:57:22 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wang", "Yuexi", ""], ["Ro\u010dkov\u00e1", "Veronika", ""]]}, {"id": "2002.11816", "submitter": "Vu Luong", "authors": "Anh Vu Luong, Tien Thanh Nguyen and Alan Wee-Chung Liew", "title": "Streaming Active Deep Forest for Evolving Data Stream Classification", "comments": "7 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Neural Networks (DNNs) have gained progressive momentum\nin many areas of machine learning. The layer-by-layer process of DNNs has\ninspired the development of many deep models, including deep ensembles. The\nmost notable deep ensemble-based model is Deep Forest, which can achieve highly\ncompetitive performance while having much fewer hyper-parameters comparing to\nDNNs. In spite of its huge success in the batch learning setting, no effort has\nbeen made to adapt Deep Forest to the context of evolving data streams. In this\nwork, we introduce the Streaming Deep Forest (SDF) algorithm, a\nhigh-performance deep ensemble method specially adapted to stream\nclassification. We also present the Augmented Variable Uncertainty (AVU) active\nlearning strategy to reduce the labeling cost in the streaming context. We\ncompare the proposed methods to state-of-the-art streaming algorithms in a wide\nrange of datasets. The results show that by following the AVU active learning\nstrategy, SDF with only 70\\% of labeling budget significantly outperforms other\nmethods trained with all instances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:00:39 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Luong", "Anh Vu", ""], ["Nguyen", "Tien Thanh", ""], ["Liew", "Alan Wee-Chung", ""]]}, {"id": "2002.11821", "submitter": "Ankit Raj", "authors": "Ankit Raj, Yoram Bresler, Bo Li", "title": "Improving Robustness of Deep-Learning-Based Image Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning-based methods for different applications have been shown\nvulnerable to adversarial examples. These examples make deployment of such\nmodels in safety-critical tasks questionable. Use of deep neural networks as\ninverse problem solvers has generated much excitement for medical imaging\nincluding CT and MRI, but recently a similar vulnerability has also been\ndemonstrated for these tasks. We show that for such inverse problem solvers,\none should analyze and study the effect of adversaries in the\nmeasurement-space, instead of the signal-space as in previous work. In this\npaper, we propose to modify the training strategy of end-to-end\ndeep-learning-based inverse problem solvers to improve robustness. We introduce\nan auxiliary network to generate adversarial examples, which is used in a\nmin-max formulation to build robust image reconstruction networks.\nTheoretically, we show for a linear reconstruction scheme the min-max\nformulation results in a singular-value(s) filter regularized solution, which\nsuppresses the effect of adversarial examples occurring because of\nill-conditioning in the measurement matrix. We find that a linear network using\nthe proposed min-max learning scheme indeed converges to the same solution. In\naddition, for non-linear Compressed Sensing (CS) reconstruction using deep\nnetworks, we show significant improvement in robustness using the proposed\napproach over other methods. We complement the theory by experiments for CS on\ntwo different datasets and evaluate the effect of increasing perturbations on\ntrained networks. We find the behavior for ill-conditioned and well-conditioned\nmeasurement matrices to be qualitatively different.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:12:36 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Raj", "Ankit", ""], ["Bresler", "Yoram", ""], ["Li", "Bo", ""]]}, {"id": "2002.11829", "submitter": "Or Litany", "authors": "Or Litany, Ari Morcos, Srinath Sridhar, Leonidas Guibas, Judy Hoffman", "title": "Representation Learning Through Latent Canonicalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to learn a representation on a large annotated data source that\ngeneralizes to a target domain using limited new supervision. Many prior\napproaches to this problem have focused on learning \"disentangled\"\nrepresentations so that as individual factors vary in a new domain, only a\nportion of the representation need be updated. In this work, we seek the\ngeneralization power of disentangled representations, but relax the requirement\nof explicit latent disentanglement and instead encourage linearity of\nindividual factors of variation by requiring them to be manipulable by learned\nlinear transformations. We dub these transformations latent canonicalizers, as\nthey aim to modify the value of a factor to a pre-determined (but arbitrary)\ncanonical value (e.g., recoloring the image foreground to black). Assuming a\nsource domain with access to meta-labels specifying the factors of variation\nwithin an image, we demonstrate experimentally that our method helps reduce the\nnumber of observations needed to generalize to a similar target domain when\ncompared to a number of supervised baselines.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:50:12 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Litany", "Or", ""], ["Morcos", "Ari", ""], ["Sridhar", "Srinath", ""], ["Guibas", "Leonidas", ""], ["Hoffman", "Judy", ""]]}, {"id": "2002.11833", "submitter": "Jean Harb", "authors": "Jean Harb, Tom Schaul, Doina Precup and Pierre-Luc Bacon", "title": "Policy Evaluation Networks", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning algorithms use value functions to guide the\nsearch for better policies. These methods estimate the value of a single policy\nwhile generalizing across many states. The core idea of this paper is to flip\nthis convention and estimate the value of many policies, for a single set of\nstates. This approach opens up the possibility of performing direct gradient\nascent in policy space without seeing any new data. The main challenge for this\napproach is finding a way to represent complex policies that facilitates\nlearning and generalization. To address this problem, we introduce a scalable,\ndifferentiable fingerprinting mechanism that retains essential policy\ninformation in a concise embedding. Our empirical results demonstrate that\ncombining these three elements (learned Policy Evaluation Network, policy\nfingerprints, gradient ascent) can produce policies that outperform those that\ngenerated the training data, in zero-shot manner.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:00:27 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Harb", "Jean", ""], ["Schaul", "Tom", ""], ["Precup", "Doina", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "2002.11835", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Danilo P. Mandic", "title": "Tensor Decompositions in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper surveys the topic of tensor decompositions in modern machine\nlearning applications. It focuses on three active research topics of\nsignificant relevance for the community. After a brief review of consolidated\nworks on multi-way data analysis, we consider the use of tensor decompositions\nin compressing the parameter space of deep learning models. Lastly, we discuss\nhow tensor methods can be leveraged to yield richer adaptive representations of\ncomplex data, including structured information. The paper concludes with a\ndiscussion on interesting open research challenges.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:07:19 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Bacciu", "Davide", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2002.11867", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang\n  Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal and Chang-Tien Lu", "title": "Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning's success has been widely recognized in a variety of machine\nlearning tasks, including image classification, audio recognition, and natural\nlanguage processing. As an extension of deep learning beyond these domains,\ngraph neural networks (GNNs) are designed to handle the non-Euclidean\ngraph-structure which is intractable to previous deep learning techniques.\nExisting GNNs are presented using various techniques, making direct comparison\nand cross-reference more complex. Although existing studies categorize GNNs\ninto spatial-based and spectral-based techniques, there hasn't been a thorough\nexamination of their relationship. To close this gap, this study presents a\nsingle framework that systematically incorporates most GNNs. We organize\nexisting GNNs into spatial and spectral domains, as well as expose the\nconnections within each domain. A review of spectral graph theory and\napproximation theory builds a strong relationship across the spatial and\nspectral domains in further investigation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 01:15:10 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 01:53:31 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 12:31:13 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 15:54:42 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Zhiqian", ""], ["Chen", "Fanglan", ""], ["Zhang", "Lei", ""], ["Ji", "Taoran", ""], ["Fu", "Kaiqun", ""], ["Zhao", "Liang", ""], ["Chen", "Feng", ""], ["Wu", "Lingfei", ""], ["Aggarwal", "Charu", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2002.11875", "submitter": "Guojun Zhang", "authors": "Guojun Zhang, Pascal Poupart and Yaoliang Yu", "title": "Optimality and Stability in Non-convex Smooth Games", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent wide applications of non-convex smooth games, we\nprovide a unified approach to \"local optimal\" points in such games, which\nincludes local Nash equilibria, local minimax points (Jin et al. 2019) and the\nmore general local robust points. To understand these definitions further, we\nstudy their corresponding first- and second-order necessary and sufficient\nconditions and find that they all satisfy stationarity. This motivates us to\nanalyze the local stability of several popular gradient algorithms near\ncorresponding local solutions. Our results indicate the necessity of new\nalgorithms and analysis. As a concrete example, we give the exact existence\nconditions of local (global) minimax points and local robust points for\nquadratic games, and demonstrate their many special properties.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:16:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:02:00 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Zhang", "Guojun", ""], ["Poupart", "Pascal", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2002.11879", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Jian Peng", "title": "State-only Imitation with Transition Dynamics Mismatch", "comments": "ICLR 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is a popular paradigm for training agents to achieve\ncomplicated goals by leveraging expert behavior, rather than dealing with the\nhardships of designing a correct reward function. With the environment modeled\nas a Markov Decision Process (MDP), most of the existing IL algorithms are\ncontingent on the availability of expert demonstrations in the same MDP as the\none in which a new imitator policy is to be learned. This is uncharacteristic\nof many real-life scenarios where discrepancies between the expert and the\nimitator MDPs are common, especially in the transition dynamics function.\nFurthermore, obtaining expert actions may be costly or infeasible, making the\nrecent trend towards state-only IL (where expert demonstrations constitute only\nstates or observations) ever so promising. Building on recent adversarial\nimitation approaches that are motivated by the idea of divergence minimization,\nwe present a new state-only IL algorithm in this paper. It divides the overall\noptimization objective into two subproblems by introducing an indirection step\nand solves the subproblems iteratively. We show that our algorithm is\nparticularly effective when there is a transition dynamics mismatch between the\nexpert and imitator MDPs, while the baseline IL methods suffer from performance\ndegradation. To analyze this, we construct several interesting MDPs by\nmodifying the configuration parameters for the MuJoCo locomotion tasks from\nOpenAI Gym.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:27:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Peng", "Jian", ""]]}, {"id": "2002.11885", "submitter": "Gaurav Nagesh Shetty", "authors": "Gaurav N.Shetty, Konstantinos Slavakis, Ukash Nakarmi, Gesualdo\n  Scutari, and Leslie Ying", "title": "Kernel Bi-Linear Modeling for Reconstructing Data on Manifolds: The\n  Dynamic-MRI Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a kernel-based framework for reconstructing data on\nmanifolds, tailored to fit the dynamic-(d)MRI-data recovery problem. The\nproposed methodology exploits simple tangent-space geometries of manifolds in\nreproducing kernel Hilbert spaces and follows classical kernel-approximation\narguments to form the data-recovery task as a bi-linear inverse problem.\nDeparting from mainstream approaches, the proposed methodology uses no training\ndata, employs no graph Laplacian matrix to penalize the optimization task, uses\nno costly (kernel) pre-imaging step to map feature points back to the input\nspace, and utilizes complex-valued kernel functions to account for k-space\ndata. The framework is validated on synthetically generated dMRI data, where\ncomparisons against state-of-the-art schemes highlight the rich potential of\nthe proposed approach in data-recovery problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:42:08 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shetty", "Gaurav N.", ""], ["Slavakis", "Konstantinos", ""], ["Nakarmi", "Ukash", ""], ["Scutari", "Gesualdo", ""], ["Ying", "Leslie", ""]]}, {"id": "2002.11887", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Ruoxi Sun, C. Daniel Freeman, Ben\n  Poole, Jascha Sohl-Dickstein", "title": "Using a thousand optimization tasks to learn hyperparameter search\n  strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TaskSet, a dataset of tasks for use in training and evaluating\noptimizers. TaskSet is unique in its size and diversity, containing over a\nthousand tasks ranging from image classification with fully connected or\nconvolutional neural networks, to variational autoencoders, to non-volume\npreserving flows on a variety of datasets. As an example application of such a\ndataset we explore meta-learning an ordered list of hyperparameters to try\nsequentially. By learning this hyperparameter list from data generated using\nTaskSet we achieve large speedups in sample efficiency over random search. Next\nwe use the diversity of the TaskSet and our method for learning hyperparameter\nlists to empirically explore the generalization of these lists to new\noptimization tasks in a variety of settings including ImageNet classification\nwith Resnet50 and LM1B language modeling with transformers. As part of this\nwork we have opensourced code for all tasks, as well as ~29 million training\ncurves for these problems and the corresponding hyperparameters.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:49:10 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 23:01:28 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 00:35:05 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Sun", "Ruoxi", ""], ["Freeman", "C. Daniel", ""], ["Poole", "Ben", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2002.11896", "submitter": "Robert Giaquinto", "authors": "Robert Giaquinto and Arindam Banerjee", "title": "Gradient Boosted Normalizing Flows", "comments": "Appearing in the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By chaining a sequence of differentiable invertible transformations,\nnormalizing flows (NF) provide an expressive method of posterior approximation,\nexact density evaluation, and sampling. The trend in normalizing flow\nliterature has been to devise deeper, more complex transformations to achieve\ngreater flexibility. We propose an alternative: Gradient Boosted Normalizing\nFlows (GBNF) model a density by successively adding new NF components with\ngradient boosting. Under the boosting framework, each new NF component\noptimizes a sample weighted likelihood objective, resulting in new components\nthat are fit to the residuals of the previously trained components. The GBNF\nformulation results in a mixture model structure, whose flexibility increases\nas more components are added. Moreover, GBNFs offer a wider, as opposed to\nstrictly deeper, approach that improves existing NFs at the cost of additional\ntraining---not more complex transformations. We demonstrate the effectiveness\nof this technique for density estimation and, by coupling GBNF with a\nvariational autoencoder, generative modeling of images. Our results show that\nGBNFs outperform their non-boosted analog, and, in some cases, produce better\nresults with smaller, simpler flows.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:12:08 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 19:55:35 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 05:06:45 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 20:09:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Giaquinto", "Robert", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2002.11903", "submitter": "Youngbin Park", "authors": "Taewon Kim, Yeseong Park, Youngbin Park and Il Hong Suh", "title": "Acceleration of Actor-Critic Deep Reinforcement Learning for Visual\n  Grasping in Clutter by State Representation Learning Based on Disentanglement\n  of a Raw Input Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a robotic grasping task in which diverse unseen target objects exist in a\ncluttered environment, some deep learning-based methods have achieved\nstate-of-the-art results using visual input directly. In contrast, actor-critic\ndeep reinforcement learning (RL) methods typically perform very poorly when\ngrasping diverse objects, especially when learning from raw images and sparse\nrewards. To make these RL techniques feasible for vision-based grasping tasks,\nwe employ state representation learning (SRL), where we encode essential\ninformation first for subsequent use in RL. However, typical representation\nlearning procedures are unsuitable for extracting pertinent information for\nlearning the grasping skill, because the visual inputs for representation\nlearning, where a robot attempts to grasp a target object in clutter, are\nextremely complex. We found that preprocessing based on the disentanglement of\na raw input image is the key to effectively capturing a compact representation.\nThis enables deep RL to learn robotic grasping skills from highly varied and\ndiverse visual inputs. We demonstrate the effectiveness of this approach with\nvarying levels of disentanglement in a realistic simulated environment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:58:51 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kim", "Taewon", ""], ["Park", "Yeseong", ""], ["Park", "Youngbin", ""], ["Suh", "Il Hong", ""]]}, {"id": "2002.11912", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Sebastien Paris, Richard Baraniuk", "title": "Max-Affine Spline Insights into Deep Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We connect a large class of Generative Deep Networks (GDNs) with spline\noperators in order to derive their properties, limitations, and new\nopportunities. By characterizing the latent space partition, dimension and\nangularity of the generated manifold, we relate the manifold dimension and\napproximation error to the sample size. The manifold-per-region affine subspace\ndefines a local coordinate basis; we provide necessary and sufficient\nconditions relating those basis vectors with disentanglement. We also derive\nthe output probability density mapped onto the generated manifold in terms of\nthe latent space density, which enables the computation of key statistics such\nas its Shannon entropy. This finding also enables the computation of the GDN\nlikelihood, which provides a new mechanism for model comparison as well as\nproviding a quality measure for (generated) samples under the learned\ndistribution. We demonstrate how low entropy and/or multimodal distributions\nare not naturally modeled by DGNs and are a cause of training instabilities.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:20:02 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Balestriero", "Randall", ""], ["Paris", "Sebastien", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2002.11916", "submitter": "Shih-Ting Huang", "authors": "Shih-Ting Huang, Fang Xie, and Johannes Lederer", "title": "Tuning-free ridge estimators for high-dimensional generalized linear\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ridge estimators regularize the squared Euclidean lengths of parameters. Such\nestimators are mathematically and computationally attractive but involve tuning\nparameters that can be difficult to calibrate. In this paper, we show that\nridge estimators can be modified such that tuning parameters can be avoided\naltogether. We also show that these modified versions can improve on the\nempirical prediction accuracies of standard ridge estimators combined with\ncross-validation, and we provide first theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 05:01:42 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Huang", "Shih-Ting", ""], ["Xie", "Fang", ""], ["Lederer", "Johannes", ""]]}, {"id": "2002.11934", "submitter": "Tomojit Ghosh", "authors": "Tomojit Ghosh and Michael Kirby", "title": "Supervised Dimensionality Reduction and Visualization using\n  Centroid-encoder", "comments": "25 pages (including 3 reference pages), 12 figures. I am planning to\n  submit the paper to JMLR very soon. Centroid-encoder was applied on a\n  biological pathway data\n  (https://www.sciencedirect.com/science/article/pii/S1046202317300439). In\n  this paper we throughly analyzed the algorithm and compared it with\n  state-of-the art techniques on a 8 data sets including MNIST, USPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing high-dimensional data is an essential task in Data Science and\nMachine Learning. The Centroid-Encoder (CE) method is similar to the\nautoencoder but incorporates label information to keep objects of a class close\ntogether in the reduced visualization space. CE exploits nonlinearity and\nlabels to encode high variance in low dimensions while capturing the global\nstructure of the data. We present a detailed analysis of the method using a\nwide variety of data sets and compare it with other supervised dimension\nreduction techniques, including NCA, nonlinear NCA, t-distributed NCA,\nt-distributed MCML, supervised UMAP, supervised PCA, Colored Maximum Variance\nUnfolding, supervised Isomap, Parametric Embedding, supervised Neighbor\nRetrieval Visualizer, and Multiple Relational Embedding. We empirically show\nthat centroid-encoder outperforms most of these techniques. We also show that\nwhen the data variance is spread across multiple modalities, centroid-encoder\nextracts a significant amount of information from the data in low dimensional\nspace. This key feature establishes its value to use it as a tool for data\nvisualization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:08:22 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 23:22:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ghosh", "Tomojit", ""], ["Kirby", "Michael", ""]]}, {"id": "2002.11936", "submitter": "Yuki Suzuki", "authors": "Yuki Suzuki, Kazuki Yamagata, Yanagawa Masahiro, Shoji Kido, Noriyuki\n  Tomiyama", "title": "Weak Supervision in Convolutional Neural Network for Semantic\n  Segmentation of Diffuse Lung Diseases Using Partially Annotated Dataset", "comments": "Accepted at SPIE Medical Imaging 2020: Computer-Aided Diagnosis", "journal-ref": null, "doi": "10.1117/12.2548930", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis system for diffuse lung diseases (DLDs) is necessary\nfor the objective assessment of the lung diseases. In this paper, we develop\nsemantic segmentation model for 5 kinds of DLDs. DLDs considered in this work\nare consolidation, ground glass opacity, honeycombing, emphysema, and normal.\nConvolutional neural network (CNN) is one of the most promising technique for\nsemantic segmentation among machine learning algorithms. While creating\nannotated dataset for semantic segmentation is laborious and time consuming,\ncreating partially annotated dataset, in which only one chosen class is\nannotated for each image, is easier since annotators only need to focus on one\nclass at a time during the annotation task. In this paper, we propose a new\nweak supervision technique that effectively utilizes partially annotated\ndataset. The experiments using partially annotated dataset composed 372 CT\nimages demonstrated that our proposed technique significantly improved\nsegmentation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:17:11 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 11:04:49 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Suzuki", "Yuki", ""], ["Yamagata", "Kazuki", ""], ["Masahiro", "Yanagawa", ""], ["Kido", "Shoji", ""], ["Tomiyama", "Noriyuki", ""]]}, {"id": "2002.11940", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Ziqi Liu, Jun Zhou, Xiaolong Li, Yuan Qi, Yujing Jiao,\n  and Xingyu Zhong", "title": "How Much Can A Retailer Sell? Sales Forecasting on Tmall", "comments": "Accepted by PAKDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is an important task in both academic and industry,\nwhich can be applied to solve many real forecasting problems like stock,\nwater-supply, and sales predictions. In this paper, we study the case of\nretailers' sales forecasting on Tmall|the world's leading online B2C platform.\nBy analyzing the data, we have two main observations, i.e., sales seasonality\nafter we group different groups of retails and a Tweedie distribution after we\ntransform the sales (target to forecast). Based on our observations, we design\ntwo mechanisms for sales forecasting, i.e., seasonality extraction and\ndistribution transformation. First, we adopt Fourier decomposition to\nautomatically extract the seasonalities for different categories of retailers,\nwhich can further be used as additional features for any established regression\nalgorithms. Second, we propose to optimize the Tweedie loss of sales after\nlogarithmic transformations. We apply these two mechanisms to classic\nregression models, i.e., neural network and Gradient Boosting Decision Tree,\nand the experimental results on Tmall dataset show that both mechanisms can\nsignificantly improve the forecasting results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:41:00 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Chen", "Chaochao", ""], ["Liu", "Ziqi", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Qi", "Yuan", ""], ["Jiao", "Yujing", ""], ["Zhong", "Xingyu", ""]]}, {"id": "2002.11945", "submitter": "Sumon Bose Mr.", "authors": "Sumon Kumar Bose, Jyotibdha Acharya, and Arindam Basu", "title": "Is my Neural Network Neuromorphic? Taxonomy, Recent Trends and Future\n  Directions in Neuromorphic Engineering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we review recent work published over the last 3 years under\nthe umbrella of Neuromorphic engineering to analyze what are the common\nfeatures among such systems. We see that there is no clear consensus but each\nsystem has one or more of the following features:(1) Analog computing (2) Non\nvonNeumann Architecture and low-precision digital processing (3) Spiking Neural\nNetworks (SNN) with components closely related to biology. We compare recent\nmachine learning accelerator chips to show that indeed analog processing and\nreduced bit precision architectures have best throughput, energy and area\nefficiencies. However, pure digital architectures can also achieve quite high\nefficiencies by just adopting a non von-Neumann architecture. Given the design\nautomation tools for digital hardware design, it raises a question on the\nlikelihood of adoption of analog processing in the near future for industrial\ndesigns. Next, we argue about the importance of defining standards and choosing\nproper benchmarks for the progress of neuromorphic system designs and propose\nsome desired characteristics of such benchmarks. Finally, we show brain-machine\ninterfaces as a potential task that fulfils all the criteria of such\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:10:23 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Bose", "Sumon Kumar", ""], ["Acharya", "Jyotibdha", ""], ["Basu", "Arindam", ""]]}, {"id": "2002.11955", "submitter": "Daniel Y. Fu", "authors": "Daniel Y. Fu, Mayee F. Chen, Frederic Sala, Sarah M. Hooper, Kayvon\n  Fatahalian, Christopher R\\'e", "title": "Fast and Three-rious: Speeding Up Weak Supervision with Triplet Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak supervision is a popular method for building machine learning models\nwithout relying on ground truth annotations. Instead, it generates\nprobabilistic training labels by estimating the accuracies of multiple noisy\nlabeling sources (e.g., heuristics, crowd workers). Existing approaches use\nlatent variable estimation to model the noisy sources, but these methods can be\ncomputationally expensive, scaling superlinearly in the data. In this work, we\nshow that, for a class of latent variable models highly applicable to weak\nsupervision, we can find a closed-form solution to model parameters, obviating\nthe need for iterative solutions like stochastic gradient descent (SGD). We use\nthis insight to build FlyingSquid, a weak supervision framework that runs\norders of magnitude faster than previous weak supervision approaches and\nrequires fewer assumptions. In particular, we prove bounds on generalization\nerror without assuming that the latent variable model can exactly parameterize\nthe underlying data distribution. Empirically, we validate FlyingSquid on\nbenchmark weak supervision datasets and find that it achieves the same or\nhigher quality compared to previous approaches without the need to tune an SGD\nprocedure, recovers model parameters 170 times faster on average, and enables\nnew video analysis and online learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:51:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 12:45:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Fu", "Daniel Y.", ""], ["Chen", "Mayee F.", ""], ["Sala", "Frederic", ""], ["Hooper", "Sarah M.", ""], ["Fatahalian", "Kayvon", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2002.11963", "submitter": "Elise Van Der Pol", "authors": "Elise van der Pol, Thomas Kipf, Frans A. Oliehoek, Max Welling", "title": "Plannable Approximations to MDP Homomorphisms: Equivariance under\n  Actions", "comments": "To appear in Proceedings of the International Conference on\n  Autonomous Agents and Multi-Agent Systems (AAMAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work exploits action equivariance for representation learning in\nreinforcement learning. Equivariance under actions states that transitions in\nthe input space are mirrored by equivalent transitions in latent space, while\nthe map and transition functions should also commute. We introduce a\ncontrastive loss function that enforces action equivariance on the learned\nrepresentations. We prove that when our loss is zero, we have a homomorphism of\na deterministic Markov Decision Process (MDP). Learning equivariant maps leads\nto structured latent spaces, allowing us to build a model on which we plan\nthrough value iteration. We show experimentally that for deterministic MDPs,\nthe optimal policy in the abstract MDP can be successfully lifted to the\noriginal MDP. Moreover, the approach easily adapts to changes in the goal\nstates. Empirically, we show that in such MDPs, we obtain better\nrepresentations in fewer epochs compared to representation learning approaches\nusing reconstructions, while generalizing better to new goals than model-free\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 08:29:10 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["van der Pol", "Elise", ""], ["Kipf", "Thomas", ""], ["Oliehoek", "Frans A.", ""], ["Welling", "Max", ""]]}, {"id": "2002.11982", "submitter": "Wenjing Fang", "authors": "Wenjing Fang, Chaochao Chen, Bowen Song, Li Wang, Jun Zhou, Kenny Q.\n  Zhu", "title": "Adapted tree boosting for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure online transaction is an essential task for e-commerce platforms.\nAlipay, one of the world's leading cashless payment platform, provides the\npayment service to both merchants and individual customers. The fraud detection\nmodels are built to protect the customers, but stronger demands are raised by\nthe new scenes, which are lacking in training data and labels. The proposed\nmodel makes a difference by utilizing the data under similar old scenes and the\ndata under a new scene is treated as the target domain to be promoted. Inspired\nby this real case in Alipay, we view the problem as a transfer learning problem\nand design a set of revise strategies to transfer the source domain models to\nthe target domain under the framework of gradient boosting tree models. This\nwork provides an option for the cold-starting and data-sharing problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:14:46 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 03:14:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fang", "Wenjing", ""], ["Chen", "Chaochao", ""], ["Song", "Bowen", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2002.11985", "submitter": "Prakhar Ganesh", "authors": "Prakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Hassan\n  Sajjad, Preslav Nakov, Deming Chen, Marianne Winslett", "title": "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT", "comments": "To appear in TACL 2021. The arXiv version is a pre-MIT Press\n  publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Transformer-based models have achieved state-of-the-art\nperformance for various Natural Language Processing (NLP) tasks. However, these\nmodels often have billions of parameters, and, thus, are too resource-hungry\nand computation-intensive to suit low-capability devices or applications with\nstrict latency requirements. One potential remedy for this is model\ncompression, which has attracted a lot of research attention. Here, we\nsummarize the research in compressing Transformers, focusing on the especially\npopular BERT model. In particular, we survey the state of the art in\ncompression for BERT, we clarify the current best practices for compressing\nlarge-scale Transformer models, and we provide insights into the workings of\nvarious methods. Our categorization and analysis also shed light on promising\nfuture research directions for achieving lightweight, accurate, and generic NLP\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:20:31 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 02:38:20 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ganesh", "Prakhar", ""], ["Chen", "Yao", ""], ["Lou", "Xin", ""], ["Khan", "Mohammad Ali", ""], ["Yang", "Yin", ""], ["Sajjad", "Hassan", ""], ["Nakov", "Preslav", ""], ["Chen", "Deming", ""], ["Winslett", "Marianne", ""]]}, {"id": "2002.12005", "submitter": "Zhenisbek Assylbekov", "authors": "Zhenisbek Assylbekov and Alibi Jangeldin", "title": "Squashed Shifted PMI Matrix: Bridging Word Embeddings and Hyperbolic\n  Spaces", "comments": "AJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that removing sigmoid transformation in the skip-gram with negative\nsampling (SGNS) objective does not harm the quality of word vectors\nsignificantly and at the same time is related to factorizing a squashed shifted\nPMI matrix which, in turn, can be treated as a connection probabilities matrix\nof a random graph. Empirically, such graph is a complex network, i.e. it has\nstrong clustering and scale-free degree distribution, and is tightly connected\nwith hyperbolic spaces. In short, we show the connection between static word\nembeddings and hyperbolic spaces through the squashed shifted PMI matrix using\nanalytical and empirical methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:50:41 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 15:06:00 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Assylbekov", "Zhenisbek", ""], ["Jangeldin", "Alibi", ""]]}, {"id": "2002.12011", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai, Tomoharu Iwata, Yasuhiro Fujiwara", "title": "Semi-supervised Anomaly Detection on Attributed Graphs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective method for detecting anomalous instances on\nan attribute graph with label information of a small number of instances.\nAlthough with standard anomaly detection methods it is usually assumed that\ninstances are independent and identically distributed, in many real-world\napplications, instances are often explicitly connected with each other,\nresulting in so-called attributed graphs. The proposed method embeds nodes\n(instances) on the attributed graph in the latent space by taking into account\ntheir attributes as well as the graph structure based on graph convolutional\nnetworks (GCNs). To learn node embeddings specialized for anomaly detection, in\nwhich there is a class imbalance due to the rarity of anomalies, the parameters\nof a GCN are trained to minimize the volume of a hypersphere that encloses the\nnode embeddings of normal instances while embedding anomalous ones outside the\nhypersphere. This enables us to detect anomalies by simply calculating the\ndistances between the node embeddings and hypersphere center. The proposed\nmethod can effectively propagate label information on a small amount of nodes\nto unlabeled ones by taking into account the node's attributes, graph\nstructure, and class imbalance. In experiments with five real-world attributed\ngraph datasets, we demonstrate that the proposed method achieves better\nperformance than various existing anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:06:22 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "2002.12014", "submitter": "Andrey Kolobov", "authors": "Andrey Kolobov, S\\'ebastien Bubeck, Julian Zimmert", "title": "Online Learning for Active Cache Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-armed bandit (MAB) models make two implicit assumptions: an\narm generates a payoff only when it is played, and the agent observes every\npayoff that is generated. This paper introduces synchronization bandits, a MAB\nvariant where all arms generate costs at all times, but the agent observes an\narm's instantaneous cost only when the arm is played. Synchronization MABs are\ninspired by online caching scenarios such as Web crawling, where an arm\ncorresponds to a cached item and playing the arm means downloading its fresh\ncopy from a server. We present MirrorSync, an online learning algorithm for\nsynchronization bandits, establish an adversarial regret of $O(T^{2/3})$ for\nit, and show how to make it practical.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:10:44 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 08:49:53 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kolobov", "Andrey", ""], ["Bubeck", "S\u00e9bastien", ""], ["Zimmert", "Julian", ""]]}, {"id": "2002.12017", "submitter": "SeongMin Kye", "authors": "Seong Min Kye, Hae Beom Lee, Hoirin Kim, and Sung Ju Hwang", "title": "Meta-Learned Confidence for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transductive inference is an effective means of tackling the data deficiency\nproblem in few-shot learning settings. A popular transductive inference\ntechnique for few-shot metric-based approaches, is to update the prototype of\neach class with the mean of the most confident query examples, or\nconfidence-weighted average of all the query samples. However, a caveat here is\nthat the model confidence may be unreliable, which may lead to incorrect\npredictions. To tackle this issue, we propose to meta-learn the confidence for\neach query sample, to assign optimal weights to unlabeled queries such that\nthey improve the model's transductive inference performance on unseen tasks. We\nachieve this by meta-learning an input-adaptive distance metric over a task\ndistribution under various model and data perturbations, which will enforce\nconsistency on the model predictions under diverse uncertainties for unseen\ntasks. Moreover, we additionally suggest a regularization which explicitly\nenforces the consistency on the predictions across the different dimensions of\na high-dimensional embedding vector. We validate our few-shot learning model\nwith meta-learned confidence on four benchmark datasets, on which it largely\noutperforms strong recent baselines and obtains new state-of-the-art results.\nFurther application on semi-supervised few-shot learning tasks also yields\nsignificant performance improvements over the baselines. The source code of our\nalgorithm is available at https://github.com/seongmin-kye/MCT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:22:17 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 14:13:47 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Kye", "Seong Min", ""], ["Lee", "Hae Beom", ""], ["Kim", "Hoirin", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2002.12036", "submitter": "Francisco Javier Bald\\'an", "authors": "Francisco J. Bald\\'an and Jos\\'e M. Ben\\'itez", "title": "Complexity Measures and Features for Times Series classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of time series is a growing problem in different disciplines\ndue to the progressive digitalization of the world. Currently, the state of the\nart in time series classification is dominated by Collective of\nTransformation-Based Ensembles. This algorithm is composed of several\nclassifiers of diverse nature that are combined according to their results in\nan internal cross validation procedure. Its high complexity prevents it from\nbeing applied to large datasets. One Nearest Neighbours with Dynamic Time\nWarping remains the base classifier in any time series classification problem,\nfor its simplicity and good results. Despite their good performance, they share\na weakness, which is that they are not interpretable. In the field of time\nseries classification, there is a tradeoff between accuracy and\ninterpretability. In this work, we propose a set of characteristics capable of\nextracting information of the structure of the time series in order to face\ntime series classification problems. The use of these characteristics allows\nthe use of traditional classification algorithms in time series problems. The\nexperimental results demonstrate a statistically significant improvement in the\naccuracy of the results obtained by our proposal with respect to the original\ntime series. Apart from the improvement in accuracy, our proposal is able to\noffer interpretable results based on the set of characteristics proposed.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 11:08:08 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 12:09:53 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Bald\u00e1n", "Francisco J.", ""], ["Ben\u00edtez", "Jos\u00e9 M.", ""]]}, {"id": "2002.12047", "submitter": "Ethan Harris", "authors": "Ethan Harris, Antonia Marcu, Matthew Painter, Mahesan Niranjan, Adam\n  Pr\\\"ugel-Bennett, Jonathon Hare", "title": "FMix: Enhancing Mixed Sample Data Augmentation", "comments": "Code available at https://github.com/ecs-vlc/FMix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed Sample Data Augmentation (MSDA) has received increasing attention in\nrecent years, with many successful variants such as MixUp and CutMix. By\nstudying the mutual information between the function learned by a VAE on the\noriginal data and on the augmented data we show that MixUp distorts learned\nfunctions in a way that CutMix does not. We further demonstrate this by showing\nthat MixUp acts as a form of adversarial training, increasing robustness to\nattacks such as Deep Fool and Uniform Noise which produce examples similar to\nthose generated by MixUp. We argue that this distortion prevents models from\nlearning about sample specific features in the data, aiding generalisation\nperformance. In contrast, we suggest that CutMix works more like a traditional\naugmentation, improving performance by preventing memorisation without\ndistorting the data distribution. However, we argue that an MSDA which builds\non CutMix to include masks of arbitrary shape, rather than just square, could\nfurther prevent memorisation whilst preserving the data distribution in the\nsame way. To this end, we propose FMix, an MSDA that uses random binary masks\nobtained by applying a threshold to low frequency images sampled from Fourier\nspace. These random masks can take on a wide range of shapes and can be\ngenerated for use with one, two, and three dimensional data. FMix improves\nperformance over MixUp and CutMix, without an increase in training time, for a\nnumber of models across a range of data sets and problem settings, obtaining a\nnew single model state-of-the-art result on CIFAR-10 without external data.\nFinally, we show that a consequence of the difference between interpolating\nMSDA such as MixUp and masking MSDA such as FMix is that the two can be\ncombined to improve performance even further. Code for all experiments is\nprovided at https://github.com/ecs-vlc/FMix .\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 11:46:33 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 13:12:35 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 14:47:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Harris", "Ethan", ""], ["Marcu", "Antonia", ""], ["Painter", "Matthew", ""], ["Niranjan", "Mahesan", ""], ["Pr\u00fcgel-Bennett", "Adam", ""], ["Hare", "Jonathon", ""]]}, {"id": "2002.12054", "submitter": "Gholamreza Salimi-Khorshidi", "authors": "Danijela Horak, Simiao Yu, Gholamreza Salimi-Khorshidi", "title": "Topology Distance: A Topology-Based Approach For Evaluating Generative\n  Adversarial Networks", "comments": "Submitted to ICML 2020; 12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation of the goodness of Generative Adversarial Networks\n(GANs) has been a challenge for the field of machine learning. In this work, we\npropose a distance complementary to existing measures: Topology Distance (TD),\nthe main idea behind which is to compare the geometric and topological features\nof the latent manifold of real data with those of generated data. More\nspecifically, we build Vietoris-Rips complex on image features, and define TD\nbased on the differences in persistent-homology groups of the two manifolds. We\ncompare TD with the most commonly used and relevant measures in the field,\nincluding Inception Score (IS), Frechet Inception Distance (FID), Kernel\nInception Distance (KID) and Geometry Score (GS), in a range of experiments on\nvarious datasets. We demonstrate the unique advantage and superiority of our\nproposed approach over the aforementioned metrics. A combination of our\nempirical results and the theoretical argument we propose in favour of TD,\nstrongly supports the claim that TD is a powerful candidate metric that\nresearchers can employ when aiming to automatically evaluate the goodness of\nGANs' learning.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:06:41 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Horak", "Danijela", ""], ["Yu", "Simiao", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "2002.12078", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Saber Fallah, Richard Bowden", "title": "Training Adversarial Agents to Exploit Weaknesses in Deep Control\n  Policies", "comments": "2020 IEEE International Conference on Robotics and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become an increasingly common technique for various control\nproblems, such as robotic arm manipulation, robot navigation, and autonomous\nvehicles. However, the downside of using deep neural networks to learn control\npolicies is their opaque nature and the difficulties of validating their\nsafety. As the networks used to obtain state-of-the-art results become\nincreasingly deep and complex, the rules they have learned and how they operate\nbecome more challenging to understand. This presents an issue, since in\nsafety-critical applications the safety of the control policy must be ensured\nto a high confidence level. In this paper, we propose an automated black box\ntesting framework based on adversarial reinforcement learning. The technique\nuses an adversarial agent, whose goal is to degrade the performance of the\ntarget model under test. We test the approach on an autonomous vehicle problem,\nby training an adversarial reinforcement learning agent, which aims to cause a\ndeep neural network-driven autonomous vehicle to collide. Two neural networks\ntrained for autonomous driving are compared, and the results from the testing\nare used to compare the robustness of their learned control policies. We show\nthat the proposed framework is able to find weaknesses in both control policies\nthat were not evident during online testing and therefore, demonstrate a\nsignificant benefit over manual testing methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:14:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kuutti", "Sampo", ""], ["Fallah", "Saber", ""], ["Bowden", "Richard", ""]]}, {"id": "2002.12104", "submitter": "Hamid Usefi", "authors": "Majid Afshar, Hamid Usefi", "title": "High-Dimensional Feature Selection for Genomic Datasets", "comments": null, "journal-ref": "August 2020, Knowledge-Based Systems 206(4):106370", "doi": "10.1016/j.knosys.2020.106370", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in machine learning and pattern recognition is the process\nof recognizing the most important features. In this paper, we provide a new\nfeature selection method (DRPT) that consists of first removing the irrelevant\nfeatures and then detecting correlations between the remaining features. Let\n$D=[A\\mid \\mathbf{b}]$ be a dataset, where $\\mathbf{b}$ is the class label and\n$A$ is a matrix whose columns are the features. We solve $A\\mathbf{x} =\n\\mathbf{b}$ using the least squares method and the pseudo-inverse of $A$. Each\ncomponent of $\\mathbf{x}$ can be viewed as an assigned weight to the\ncorresponding column (feature). We define a threshold based on the local maxima\nof $\\mathbf{x}$ and remove those features whose weights are smaller than the\nthreshold.\n  To detect the correlations in the reduced matrix, which we still call $A$, we\nconsider a perturbation $\\tilde A$ of $A$. We prove that correlations are\nencoded in $\\Delta\\mathbf{x}=\\mid \\mathbf{x} -\\tilde{\\mathbf{x}}\\mid $, where\n$\\tilde{\\mathbf{x}}$ is the least quares solution of\n  $\\tilde A\\tilde{\\mathbf{x}}=\\mathbf{b}$. We cluster features first based on\n$\\Delta\\mathbf{x}$ and then using the entropy of features. Finally, a feature\nis selected from each sub-cluster based on its weight and entropy. The\neffectiveness of DRPT has been verified by performing a series of comparisons\nwith seven state-of-the-art feature selection methods over ten genetic datasets\nranging up from 9,117 to 267,604 features. The results show that, over all, the\nperformance of DRPT is favorable in several aspects compared to each feature\nselection algorithm.\n  \\e\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 14:17:39 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 01:00:02 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Afshar", "Majid", ""], ["Usefi", "Hamid", ""]]}, {"id": "2002.12133", "submitter": "Aritz D. Martinez", "authors": "Aritz D. Martinez, Eneko Osaba, Javier Del Ser and Francisco Herrera", "title": "Simultaneously Evolving Deep Reinforcement Learning Models using\n  Multifactorial Optimization", "comments": "8 pages, 5 figures, submitted to IEEE Conference on Evolutionary\n  Computation 2020 (IEEE CEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Multifactorial Optimization (MFO) has gained a notable\nmomentum in the research community. MFO is known for its inherent capability to\nefficiently address multiple optimization tasks at the same time, while\ntransferring information among such tasks to improve their convergence speed.\nOn the other hand, the quantum leap made by Deep Q Learning (DQL) in the\nMachine Learning field has allowed facing Reinforcement Learning (RL) problems\nof unprecedented complexity. Unfortunately, complex DQL models usually find it\ndifficult to converge to optimal policies due to the lack of exploration or\nsparse rewards. In order to overcome these drawbacks, pre-trained models are\nwidely harnessed via Transfer Learning, extrapolating knowledge acquired in a\nsource task to the target task. Besides, meta-heuristic optimization has been\nshown to reduce the lack of exploration of DQL models. This work proposes a MFO\nframework capable of simultaneously evolving several DQL models towards solving\ninterrelated RL tasks. Specifically, our proposed framework blends together the\nbenefits of meta-heuristic optimization, Transfer Learning and DQL to automate\nthe process of knowledge transfer and policy learning of distributed RL agents.\nA thorough experimentation is presented and discussed so as to assess the\nperformance of the framework, its comparison to the traditional methodology for\nTransfer Learning in terms of convergence, speed and policy quality , and the\nintertask relationships found and exploited over the search process.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:36:57 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 10:47:41 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Martinez", "Aritz D.", ""], ["Osaba", "Eneko", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.12135", "submitter": "Jiajun Cai", "authors": "Qiquan Shi, Jiaming Yin, Jiajun Cai, Andrzej Cichocki, Tatsuya Yokota,\n  Lei Chen, Mingxuan Yuan, Jia Zeng", "title": "Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel approach for multiple time series forecasting. At\nfirst, multi-way delay embedding transform (MDT) is employed to represent time\nseries as low-rank block Hankel tensors (BHT). Then, the higher-order tensors\nare projected to compressed core tensors by applying Tucker decomposition. At\nthe same time, the generalized tensor Autoregressive Integrated Moving Average\n(ARIMA) is explicitly used on consecutive core tensors to predict future\nsamples. In this manner, the proposed approach tactically incorporates the\nunique advantages of MDT tensorization (to exploit mutual correlations) and\ntensor ARIMA coupled with low-rank Tucker decomposition into a unified\nframework. This framework exploits the low-rank structure of block Hankel\ntensors in the embedded space and captures the intrinsic correlations among\nmultiple TS, which thus can improve the forecasting results, especially for\nmultiple short time series. Experiments conducted on three public datasets and\ntwo industrial datasets verify that the proposed BHT-ARIMA effectively improves\nforecasting accuracy and reduces computational cost compared with the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:29:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shi", "Qiquan", ""], ["Yin", "Jiaming", ""], ["Cai", "Jiajun", ""], ["Cichocki", "Andrzej", ""], ["Yokota", "Tatsuya", ""], ["Chen", "Lei", ""], ["Yuan", "Mingxuan", ""], ["Zeng", "Jia", ""]]}, {"id": "2002.12143", "submitter": "Ramanujam Madhavan", "authors": "Ramanujam Madhavan, Mohit Wadhwa", "title": "Fairness-Aware Learning with Prejudice Free Representations", "comments": null, "journal-ref": null, "doi": "10.1145/3340531", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are extensively being used to make decisions that\nhave a significant impact on human life. These models are trained over\nhistorical data that may contain information about sensitive attributes such as\nrace, sex, religion, etc. The presence of such sensitive attributes can impact\ncertain population subgroups unfairly. It is straightforward to remove\nsensitive features from the data; however, a model could pick up prejudice from\nlatent sensitive attributes that may exist in the training data. This has led\nto the growing apprehension about the fairness of the employed models. In this\npaper, we propose a novel algorithm that can effectively identify and treat\nlatent discriminating features. The approach is agnostic of the learning\nalgorithm and generalizes well for classification as well as regression tasks.\nIt can also be used as a key aid in proving that the model is free of\ndiscrimination towards regulatory compliance if the need arises. The approach\nhelps to collect discrimination-free features that would improve the model\nperformance while ensuring the fairness of the model. The experimental results\nfrom our evaluations on publicly available real-world datasets show a\nnear-ideal fairness measurement in comparison to other methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:06:31 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Madhavan", "Ramanujam", ""], ["Wadhwa", "Mohit", ""]]}, {"id": "2002.12144", "submitter": "George Cevora", "authors": "George Cevora", "title": "Fair Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The influence of human judgement is ubiquitous in datasets used across the\nanalytics industry, yet humans are known to be sub-optimal decision makers\nprone to various biases. Analysing biased datasets then leads to biased\noutcomes of the analysis. Bias by protected characteristics (e.g. race) is of\nparticular interest as it may not only make the output of analytical process\nsub-optimal, but also illegal. Countering the bias by constraining the\nanalytical outcomes to be fair is problematic because A) fairness lacks a\nuniversally accepted definition, while at the same time some definitions are\nmutually exclusive, and B) the use of optimisation constraints ensuring\nfairness is incompatible with most analytical pipelines. Both problems are\nsolved by methods which remove bias from the data and returning an altered\ndataset. This approach aims to not only remove the actual bias variable (e.g.\nrace), but also alter all proxy variables (e.g. postcode) so the bias variable\nis not detectable from the rest of the data. The advantage of using this\napproach is that the definition of fairness as a lack of detectable bias in the\ndata (as opposed to the output of analysis) is universal and therefore solves\nproblem (A). Furthermore, as the data is altered to remove bias the problem (B)\ndisappears because the analytical pipelines can remain unchanged. This approach\nhas been adopted by several technical solutions. None of them, however, seems\nto be satisfactory in terms of ability to remove multivariate, non-linear and\nnon-binary biases. Therefore, in this paper I propose the concept of Fair\nAdversarial Networks as an easy-to-implement general method for removing bias\nfrom data. This paper demonstrates that Fair Adversarial Networks achieve this\naim.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 16:39:38 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Cevora", "George", ""]]}, {"id": "2002.12156", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Cautious Reinforcement Learning with Logical Constraints", "comments": "Accepted to AAMAS 2020. arXiv admin note: text overlap with\n  arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the concept of an adaptive safe padding that forces\nReinforcement Learning (RL) to synthesise optimal control policies while\nensuring safety during the learning process. Policies are synthesised to\nsatisfy a goal, expressed as a temporal logic formula, with maximal\nprobability. Enforcing the RL agent to stay safe during learning might limit\nthe exploration, however we show that the proposed architecture is able to\nautomatically handle the trade-off between efficient progress in exploration\n(towards goal satisfaction) and ensuring safety. Theoretical guarantees are\navailable on the optimality of the synthesised policies and on the convergence\nof the learning algorithm. Experimental results are provided to showcase the\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:01:08 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:26:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "2002.12158", "submitter": "Sungwon Han", "authors": "Sungwon Han, Yizhan Xu, Sungwon Park, Meeyoung Cha, Cheng-Te Li", "title": "A Comprehensive Approach to Unsupervised Embedding Learning based on AND\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised embedding learning aims to extract good representation from data\nwithout the need for any manual labels, which has been a critical challenge in\nmany supervised learning tasks. This paper proposes a new unsupervised\nembedding approach, called Super-AND, which extends the current\nstate-of-the-art model. Super-AND has its unique set of losses that can gather\nsimilar samples nearby within a low-density space while keeping invariant\nfeatures intact against data augmentation. Super-AND outperforms all existing\napproaches and achieves an accuracy of 89.2% on the image classification task\nfor CIFAR-10. We discuss the practical implications of this method in assisting\nsemi-supervised tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:22:04 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Han", "Sungwon", ""], ["Xu", "Yizhan", ""], ["Park", "Sungwon", ""], ["Cha", "Meeyoung", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2002.12164", "submitter": "Varun Mannam", "authors": "Varun Mannam, Arman Kazemi", "title": "Performance Analysis of Semi-supervised Learning in the Small-data\n  Regime using VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting large amounts of data from biological samples is not feasible due\nto radiation issues, and image processing in the small-data regime is one of\nthe critical challenges when working with a limited amount of data. In this\nwork, we applied an existing algorithm named Variational Auto Encoder (VAE)\nthat pre-trains a latent space representation of the data to capture the\nfeatures in a lower-dimension for the small-data regime input. The fine-tuned\nlatent space provides constant weights that are useful for classification. Here\nwe will present the performance analysis of the VAE algorithm with different\nlatent space sizes in the semi-supervised learning using the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:19:54 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 19:50:39 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mannam", "Varun", ""], ["Kazemi", "Arman", ""]]}, {"id": "2002.12168", "submitter": "Jilin Hu", "authors": "Jilin Hu, Jianbing Shen, Bin Yang, Ling Shao", "title": "Infinitely Wide Graph Convolutional Networks: Semi-supervised Learning\n  via Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks~(GCNs) have recently demonstrated\npromising results on graph-based semi-supervised classification, but little\nwork has been done to explore their theoretical properties. Recently, several\ndeep neural networks, e.g., fully connected and convolutional neural networks,\nwith infinite hidden units have been proved to be equivalent to Gaussian\nprocesses~(GPs). To exploit both the powerful representational capacity of GCNs\nand the great expressive power of GPs, we investigate similar properties of\ninfinitely wide GCNs. More specifically, we propose a GP regression model via\nGCNs~(GPGC) for graph-based semi-supervised learning. In the process, we\nformulate the kernel matrix computation of GPGC in an iterative analytical\nform. Finally, we derive a conditional distribution for the labels of\nunobserved nodes based on the graph structure, labels for the observed nodes,\nand the feature matrix of all the nodes. We conduct extensive experiments to\nevaluate the semi-supervised classification performance of GPGC and demonstrate\nthat it outperforms other state-of-the-art methods by a clear margin on all the\ndatasets while being efficient.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:02:32 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Hu", "Jilin", ""], ["Shen", "Jianbing", ""], ["Yang", "Bin", ""], ["Shao", "Ling", ""]]}, {"id": "2002.12169", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Bo Li, Colorado Reed, Pengfei Xu, Kurt Keutzer", "title": "Multi-source Domain Adaptation in the Deep Learning Era: A Systematic\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical applications, it is often difficult and expensive to obtain\nenough large-scale labeled data to train deep neural networks to their full\ncapability. Therefore, transferring the learned knowledge from a separate,\nlabeled source domain to an unlabeled or sparsely labeled target domain becomes\nan appealing alternative. However, direct transfer often results in significant\nperformance decay due to domain shift. Domain adaptation (DA) addresses this\nproblem by minimizing the impact of domain shift between the source and target\ndomains. Multi-source domain adaptation (MDA) is a powerful extension in which\nthe labeled data may be collected from multiple sources with different\ndistributions. Due to the success of DA methods and the prevalence of\nmulti-source data, MDA has attracted increasing attention in both academia and\nindustry. In this survey, we define various MDA strategies and summarize\navailable datasets for evaluation. We also compare modern MDA methods in the\ndeep learning era, including latent space transformation and intermediate\ndomain generation. Finally, we discuss future research directions for MDA.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:07:58 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhao", "Sicheng", ""], ["Li", "Bo", ""], ["Reed", "Colorado", ""], ["Xu", "Pengfei", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2002.12173", "submitter": "Eric Adjakossa", "authors": "Eric Adjakossa (LPSM), Yannig Goude (EDF R&D), Olivier Wintenberger\n  (LPSM UMR)", "title": "Kalman Recursions Aggregated Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we aim at improving the prediction of expert aggregation by\nusing the underlying properties of the models that provide expert predictions.\nWe restrict ourselves to the case where expert predictions come from Kalman\nrecursions, fitting state-space models. By using exponential weights, we\nconstruct different algorithms of Kalman recursions Aggregated Online (KAO)\nthat compete with the best expert or the best convex combination of experts in\na more or less adaptive way. We improve the existing results on expert\naggregation literature when the experts are Kalman recursions by taking\nadvantage of the second-order properties of the Kalman recursions. We apply our\napproach to Kalman recursions and extend it to the general adversarial expert\nsetting by state-space modeling the errors of the experts. We apply these new\nalgorithms to a real dataset of electricity consumption and show how it can\nimprove forecast performances comparing to other exponentially weighted average\nprocedures.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:53:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Adjakossa", "Eric", "", "LPSM"], ["Goude", "Yannig", "", "EDF R&D"], ["Wintenberger", "Olivier", "", "LPSM UMR"]]}, {"id": "2002.12174", "submitter": "Bei Peng", "authors": "Tabish Rashid, Bei Peng, Wendelin B\\\"ohmer, Shimon Whiteson", "title": "Optimistic Exploration even with a Pessimistic Initialisation", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimistic initialisation is an effective strategy for efficient exploration\nin reinforcement learning (RL). In the tabular case, all provably efficient\nmodel-free algorithms rely on it. However, model-free deep RL algorithms do not\nuse optimistic initialisation despite taking inspiration from these provably\nefficient tabular algorithms. In particular, in scenarios with only positive\nrewards, Q-values are initialised at their lowest possible values due to\ncommonly used network initialisation schemes, a pessimistic initialisation.\nMerely initialising the network to output optimistic Q-values is not enough,\nsince we cannot ensure that they remain optimistic for novel state-action\npairs, which is crucial for exploration. We propose a simple count-based\naugmentation to pessimistically initialised Q-values that separates the source\nof optimism from the neural network. We show that this scheme is provably\nefficient in the tabular setting and extend it to the deep RL setting. Our\nalgorithm, Optimistic Pessimistically Initialised Q-Learning (OPIQ), augments\nthe Q-value estimates of a DQN-based agent with count-derived bonuses to ensure\noptimism during both action selection and bootstrapping. We show that OPIQ\noutperforms non-optimistic DQN variants that utilise a pseudocount-based\nintrinsic motivation in hard exploration tasks, and that it predicts optimistic\nestimates for novel state-action pairs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:15:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Rashid", "Tabish", ""], ["Peng", "Bei", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2002.12200", "submitter": "Hengrui Jia", "authors": "Hengrui Jia, Christopher A. Choquette-Choo, Varun Chandrasekaran,\n  Nicolas Papernot", "title": "Entangled Watermarks as a Defense against Model Extraction", "comments": "published in 30th USENIX Security Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning involves expensive data collection and training procedures.\nModel owners may be concerned that valuable intellectual property can be leaked\nif adversaries mount model extraction attacks. As it is difficult to defend\nagainst model extraction without sacrificing significant prediction accuracy,\nwatermarking instead leverages unused model capacity to have the model overfit\nto outlier input-output pairs. Such pairs are watermarks, which are not sampled\nfrom the task distribution and are only known to the defender. The defender\nthen demonstrates knowledge of the input-output pairs to claim ownership of the\nmodel at inference. The effectiveness of watermarks remains limited because\nthey are distinct from the task distribution and can thus be easily removed\nthrough compression or other forms of knowledge transfer.\n  We introduce Entangled Watermarking Embeddings (EWE). Our approach encourages\nthe model to learn features for classifying data that is sampled from the task\ndistribution and data that encodes watermarks. An adversary attempting to\nremove watermarks that are entangled with legitimate data is also forced to\nsacrifice performance on legitimate data. Experiments on MNIST, Fashion-MNIST,\nCIFAR-10, and Speech Commands validate that the defender can claim model\nownership with 95\\% confidence with less than 100 queries to the stolen copy,\nat a modest cost below 0.81 percentage points on average in the defended\nmodel's performance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:47:00 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 15:07:24 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jia", "Hengrui", ""], ["Choquette-Choo", "Christopher A.", ""], ["Chandrasekaran", "Varun", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2002.12211", "submitter": "Krzysztof Fiok", "authors": "Krzysztof Fiok (1), Waldemar Karwowski (1), Maciej Wilamowski (2) ((1)\n  University of Central Florida, Department of Industrial Engineering and\n  Management Systems, Orlando, Florida, USA (2) University of Warsaw, Faculty\n  of Economic Sciences, Warsaw, Poland)", "title": "Prediction of adverse events in Afghanistan: regression analysis of time\n  series data grouped not by geographic dependencies", "comments": "10 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study was to approach a difficult regression task on highly\nunbalanced data regarding active theater of war in Afghanistan. Our focus was\nset on predicting the negative events number without distinguishing precise\nnature of the events given historical data on investment and negative events\nper each of predefined 400 Afghanistan districts. In contrast with previous\nresearch on the matter, we propose an approach to analysis of time series data\nthat benefits from non-conventional aggregation of these territorial entities.\nBy carrying out initial exploratory data analysis we demonstrate that dividing\ndata according to our proposal allows to identify strong trend and seasonal\ncomponents in the selected target variable. Utilizing this approach we also\ntried to estimate which data regarding investments is most important for\nprediction performance. Based on our exploratory analysis and previous research\nwe prepared 5 sets of independent variables that were fed to 3 machine learning\nregression models. The results expressed by mean absolute and mean square\nerrors indicate that leveraging historical data regarding target variable\nallows for reasonable performance, however unfortunately other proposed\nindependent variables does not seem to improve prediction quality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:58:51 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Fiok", "Krzysztof", ""], ["Karwowski", "Waldemar", ""], ["Wilamowski", "Maciej", ""]]}, {"id": "2002.12222", "submitter": "Yue Zhao", "authors": "Yue Zhao, Yuwei Wu, Caihua Chen, Andrew Lim", "title": "On Isometry Robustness of Deep 3D Point Cloud Models under Adversarial\n  Attacks", "comments": "This paper was accepted for presentation at CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning in 3D domain has achieved revolutionary performance in\nmany tasks, the robustness of these models has not been sufficiently studied or\nexplored. Regarding the 3D adversarial samples, most existing works focus on\nmanipulation of local points, which may fail to invoke the global geometry\nproperties, like robustness under linear projection that preserves the\nEuclidean distance, i.e., isometry. In this work, we show that existing\nstate-of-the-art deep 3D models are extremely vulnerable to isometry\ntransformations. Armed with the Thompson Sampling, we develop a black-box\nattack with success rate over 95% on ModelNet40 data set. Incorporating with\nthe Restricted Isometry Property, we propose a novel framework of white-box\nattack on top of spectral norm based perturbation. In contrast to previous\nworks, our adversarial samples are experimentally shown to be strongly\ntransferable. Evaluated on a sequence of prevailing 3D models, our white-box\nattack achieves success rates from 98.88% to 100%. It maintains a successful\nattack rate over 95% even within an imperceptible rotation range $[\\pm\n2.81^{\\circ}]$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:11:22 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 10:35:50 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhao", "Yue", ""], ["Wu", "Yuwei", ""], ["Chen", "Caihua", ""], ["Lim", "Andrew", ""]]}, {"id": "2002.12229", "submitter": "You Lu", "authors": "You Lu, Bert Huang", "title": "Woodbury Transformations for Deep Generative Flows", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows are deep generative models that allow efficient likelihood\ncalculation and sampling. The core requirement for this advantage is that they\nare constructed using functions that can be efficiently inverted and for which\nthe determinant of the function's Jacobian can be efficiently computed.\nResearchers have introduced various such flow operations, but few of these\nallow rich interactions among variables without incurring significant\ncomputational costs. In this paper, we introduce Woodbury transformations,\nwhich achieve efficient invertibility via the Woodbury matrix identity and\nefficient determinant calculation via Sylvester's determinant identity. In\ncontrast with other operations used in state-of-the-art normalizing flows,\nWoodbury transformations enable (1) high-dimensional interactions, (2)\nefficient sampling, and (3) efficient likelihood evaluation. Other similar\noperations, such as 1x1 convolutions, emerging convolutions, or periodic\nconvolutions allow at most two of these three advantages. In our experiments on\nmultiple image datasets, we find that Woodbury transformations allow learning\nof higher-likelihood models than other flow architectures while still enjoying\ntheir efficiency advantages.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:21:43 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 01:56:52 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 15:22:26 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lu", "You", ""], ["Huang", "Bert", ""]]}, {"id": "2002.12242", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi, Wouter M. Koolen", "title": "Lipschitz and Comparator-Norm Adaptivity in Online Learning", "comments": "30 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Online Convex Optimization in the unbounded setting where neither\npredictions nor gradient are constrained. The goal is to simultaneously adapt\nto both the sequence of gradients and the comparator. We first develop\nparameter-free and scale-free algorithms for a simplified setting with hints.\nWe present two versions: the first adapts to the squared norms of both\ncomparator and gradients separately using $O(d)$ time per round, the second\nadapts to their squared inner products (which measure variance only in the\ncomparator direction) in time $O(d^3)$ per round. We then generalize two prior\nreductions to the unbounded setting; one to not need hints, and a second to\ndeal with the range ratio problem (which already arises in prior work). We\ndiscuss their optimality in light of prior and new lower bounds. We apply our\nmethods to obtain sharper regret bounds for scale-invariant online prediction\nwith linear models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:42:41 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 14:14:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Koolen", "Wouter M.", ""]]}, {"id": "2002.12253", "submitter": "Maxim Panov", "authors": "Achille Thin, Nikita Kotelevskii, Jean-Stanislas Denain, Leo\n  Grinsztajn, Alain Durmus, Maxim Panov and Eric Moulines", "title": "MetFlow: A New Efficient Method for Bridging the Gap between Markov\n  Chain Monte Carlo and Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we propose a new computationally efficient method to\ncombine Variational Inference (VI) with Markov Chain Monte Carlo (MCMC). This\napproach can be used with generic MCMC kernels, but is especially well suited\nto \\textit{MetFlow}, a novel family of MCMC algorithms we introduce, in which\nproposals are obtained using Normalizing Flows. The marginal distribution\nproduced by such MCMC algorithms is a mixture of flow-based distributions, thus\ndrastically increasing the expressivity of the variational family. Unlike\nprevious methods following this direction, our approach is amenable to the\nreparametrization trick and does not rely on computationally expensive reverse\nkernels. Extensive numerical experiments show clear computational and\nperformance improvements over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:50:30 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Thin", "Achille", ""], ["Kotelevskii", "Nikita", ""], ["Denain", "Jean-Stanislas", ""], ["Grinsztajn", "Leo", ""], ["Durmus", "Alain", ""], ["Panov", "Maxim", ""], ["Moulines", "Eric", ""]]}, {"id": "2002.12277", "submitter": "Meshal Alfarhood", "authors": "Meshal Alfarhood and Jianlin Cheng", "title": "CATA++: A Collaborative Dual Attentive Autoencoder Method for\n  Recommending Scientific Articles", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3029722", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems today have become an essential component of any\ncommercial website. Collaborative filtering approaches, and Matrix\nFactorization (MF) techniques in particular, are widely used in recommender\nsystems. However, the natural data sparsity problem limits their performance\nwhere users generally interact with very few items in the system. Consequently,\nmultiple hybrid models were proposed recently to optimize MF performance by\nincorporating additional contextual information in its learning process.\nAlthough these models improve the recommendation quality, there are two primary\naspects for further improvements: (1) multiple models focus only on some\nportion of the available contextual information and neglect other portions; (2)\nlearning the feature space of the side contextual information needs to be\nfurther enhanced. In this paper, we introduce a Collaborative Dual Attentive\nAutoencoder (CATA++) for recommending scientific articles. CATA++ utilizes an\narticle's content and learns its latent space via two parallel autoencoders. We\nemploy the attention mechanism to capture the most related parts of information\nin order to make more relevant recommendations. Extensive experiments on three\nreal-world datasets have shown that our dual-way learning strategy has\nsignificantly improved the MF performance in comparison with other\nstate-of-the-art MF-based models using various experimental evaluations. The\nsource code of our methods is available at:\nhttps://github.com/jianlin-cheng/CATA.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:35:46 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 09:20:15 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Alfarhood", "Meshal", ""], ["Cheng", "Jianlin", ""]]}, {"id": "2002.12287", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Simone Scardapane", "title": "Deep Randomized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized Neural Networks explore the behavior of neural systems where the\nmajority of connections are fixed, either in a stochastic or a deterministic\nfashion. Typical examples of such systems consist of multi-layered neural\nnetwork architectures where the connections to the hidden layer(s) are left\nuntrained after initialization. Limiting the training algorithms to operate on\na reduced set of weights inherently characterizes the class of Randomized\nNeural Networks with a number of intriguing features. Among them, the extreme\nefficiency of the resulting learning processes is undoubtedly a striking\nadvantage with respect to fully trained architectures. Besides, despite the\ninvolved simplifications, randomized neural systems possess remarkable\nproperties both in practice, achieving state-of-the-art results in multiple\ndomains, and theoretically, allowing to analyze intrinsic properties of neural\narchitectures (e.g. before training of the hidden layers' connections). In\nrecent years, the study of Randomized Neural Networks has been extended towards\ndeep architectures, opening new research directions to the design of effective\nyet extremely efficient deep learning models in vectorial as well as in more\ncomplex data domains. This chapter surveys all the major aspects regarding the\ndesign and analysis of Randomized Neural Networks, and some of the key results\nwith respect to their approximation capabilities. In particular, we first\nintroduce the fundamentals of randomized neural models in the context of\nfeed-forward networks (i.e., Random Vector Functional Link and equivalent\nmodels) and convolutional filters, before moving to the case of recurrent\nsystems (i.e., Reservoir Computing networks). For both, we focus specifically\non recent results in the domain of deep randomized systems, and (for recurrent\nmodels) their application to structured domains.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:57:58 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 15:19:10 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Scardapane", "Simone", ""]]}, {"id": "2002.12301", "submitter": "Hiroki Matsutani", "authors": "Rei Ito, Mineto Tsukada, Hiroki Matsutani", "title": "An On-Device Federated Learning Approach for Cooperative Model Update\n  between Edge Devices", "comments": null, "journal-ref": "IEEE Access (2021)", "doi": "10.1109/ACCESS.2021.3093382", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most edge AI focuses on prediction tasks on resource-limited edge devices\nwhile the training is done at server machines. However, retraining or\ncustomizing a model is required at edge devices as the model is becoming\noutdated due to environmental changes over time. To follow such a concept\ndrift, a neural-network based on-device learning approach is recently proposed,\nso that edge devices train incoming data at runtime to update their model. In\nthis case, since a training is done at distributed edge devices, the issue is\nthat only a limited amount of training data can be used for each edge device.\nTo address this issue, one approach is a cooperative learning or federated\nlearning, where edge devices exchange their trained results and update their\nmodel by using those collected from the other devices. In this paper, as an\non-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme\nLearning Machine) to sequentially train a model based on recent samples and\ncombine it with autoencoder for anomaly detection. We extend it for an\non-device federated learning so that edge devices can exchange their trained\nresults and update their model by using those collected from the other edge\ndevices. This cooperative model update is one-shot while it can be repeatedly\napplied to synchronize their model. Our approach is evaluated with anomaly\ndetection tasks generated from a driving dataset of cars, a human activity\ndataset, and MNIST dataset. The results demonstrate that the proposed on-device\nfederated learning can produce a merged model by integrating trained results\nfrom multiple edge devices as accurately as traditional backpropagation based\nneural networks and a traditional federated learning approach with lower\ncomputation or communication cost.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:15:38 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 16:07:35 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 12:20:24 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 12:28:56 GMT"}, {"version": "v5", "created": "Sun, 27 Jun 2021 14:59:30 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ito", "Rei", ""], ["Tsukada", "Mineto", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "2002.12307", "submitter": "Ziqi Liu", "authors": "Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, Le Song", "title": "Heterogeneous Graph Neural Networks for Malicious Account Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, GEM, the first heterogeneous graph neural network approach for\ndetecting malicious accounts at Alipay, one of the world's leading mobile\ncashless payment platform. Our approach, inspired from a connected subgraph\napproach, adaptively learns discriminative embeddings from heterogeneous\naccount-device graphs based on two fundamental weaknesses of attackers, i.e.\ndevice aggregation and activity aggregation. For the heterogeneous graph\nconsists of various types of nodes, we propose an attention mechanism to learn\nthe importance of different types of nodes, while using the sum operator for\nmodeling the aggregation patterns of nodes in each type. Experiments show that\nour approaches consistently perform promising results compared with competitive\nmethods over time.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:26:44 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Ziqi", ""], ["Chen", "Chaochao", ""], ["Yang", "Xinxing", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Song", "Le", ""]]}, {"id": "2002.12312", "submitter": "Liwei Wu", "authors": "Liwei Wu", "title": "Advances in Collaborative Filtering and Ranking", "comments": "PhD Dissertation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation, we cover some recent advances in collaborative\nfiltering and ranking. In chapter 1, we give a brief introduction of the\nhistory and the current landscape of collaborative filtering and ranking;\nchapter 2 we first talk about pointwise collaborative filtering problem with\ngraph information, and how our proposed new method can encode very deep graph\ninformation which helps four existing graph collaborative filtering algorithms;\nchapter 3 is on the pairwise approach for collaborative ranking and how we\nspeed up the algorithm to near-linear time complexity; chapter 4 is on the new\nlistwise approach for collaborative ranking and how the listwise approach is a\nbetter choice of loss for both explicit and implicit feedback over pointwise\nand pairwise loss; chapter 5 is about the new regularization technique\nStochastic Shared Embeddings (SSE) we proposed for embedding layers and how it\nis both theoretically sound and empirically effectively for 6 different tasks\nacross recommendation and natural language processing; chapter 6 is how we\nintroduce personalization for the state-of-the-art sequential recommendation\nmodel with the help of SSE, which plays an important role in preventing our\npersonalized model from overfitting to the training data; chapter 7, we\nsummarize what we have achieved so far and predict what the future directions\ncan be; chapter 8 is the appendix to all the chapters.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:30:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wu", "Liwei", ""]]}, {"id": "2002.12317", "submitter": "Ofir Lindenbaum", "authors": "Ariel Jaffe, Yuval Kluger, Ofir Lindenbaum, Jonathan Patsenker, Erez\n  Peterfreund, Stefan Steinerberger", "title": "The Spectral Underpinning of word2vec", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  word2vec due to Mikolov \\textit{et al.} (2013) is a word embedding method\nthat is widely used in natural language processing. Despite its great success\nand frequent use, theoretical justification is still lacking. The main\ncontribution of our paper is to propose a rigorous analysis of the highly\nnonlinear functional of word2vec. Our results suggest that word2vec may be\nprimarily driven by an underlying spectral method. This insight may open the\ndoor to obtaining provable guarantees for word2vec. We support these findings\nby numerical simulations. One fascinating open question is whether the\nnonlinear properties of word2vec that are not captured by the spectral method\nare beneficial and, if so, by what mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:38:21 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 09:17:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jaffe", "Ariel", ""], ["Kluger", "Yuval", ""], ["Lindenbaum", "Ofir", ""], ["Patsenker", "Jonathan", ""], ["Peterfreund", "Erez", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "2002.12321", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Gautam Kamath, Rachel Cummings", "title": "PAPRIKA: Private Online False Discovery Rate Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hypothesis testing, a false discovery occurs when a hypothesis is\nincorrectly rejected due to noise in the sample. When adaptively testing\nmultiple hypotheses, the probability of a false discovery increases as more\ntests are performed. Thus the problem of False Discovery Rate (FDR) control is\nto find a procedure for testing multiple hypotheses that accounts for this\neffect in determining the set of hypotheses to reject. The goal is to minimize\nthe number (or fraction) of false discoveries, while maintaining a high true\npositive rate (i.e., correct discoveries).\n  In this work, we study False Discovery Rate (FDR) control in multiple\nhypothesis testing under the constraint of differential privacy for the sample.\nUnlike previous work in this direction, we focus on the online setting, meaning\nthat a decision about each hypothesis must be made immediately after the test\nis performed, rather than waiting for the output of all tests as in the offline\nsetting. We provide new private algorithms based on state-of-the-art results in\nnon-private online FDR control. Our algorithms have strong provable guarantees\nfor privacy and statistical performance as measured by FDR and power. We also\nprovide experimental results to demonstrate the efficacy of our algorithms in a\nvariety of data environments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:42:23 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 03:06:54 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhang", "Wanrong", ""], ["Kamath", "Gautam", ""], ["Cummings", "Rachel", ""]]}, {"id": "2002.12326", "submitter": "Ioana Bica", "authors": "Ioana Bica, James Jordon, Mihaela van der Schaar", "title": "Estimating the Effects of Continuous-valued Interventions using\n  Generative Adversarial Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much attention has been given to the problem of estimating the effect\nof discrete interventions from observational data, relatively little work has\nbeen done in the setting of continuous-valued interventions, such as treatments\nassociated with a dosage parameter. In this paper, we tackle this problem by\nbuilding on a modification of the generative adversarial networks (GANs)\nframework. Our model, SCIGAN, is flexible and capable of simultaneously\nestimating counterfactual outcomes for several different continuous\ninterventions. The key idea is to use a significantly modified GAN model to\nlearn to generate counterfactual outcomes, which can then be used to learn an\ninference model, using standard supervised methods, capable of estimating these\ncounterfactuals for a new sample. To address the challenges presented by\nshifting to continuous interventions, we propose a novel architecture for our\ndiscriminator - we build a hierarchical discriminator that leverages the\nstructure of the continuous intervention setting. Moreover, we provide\ntheoretical results to support our use of the GAN framework and of the\nhierarchical discriminator. In the experiments section, we introduce a new\nsemi-synthetic data simulation for use in the continuous intervention setting\nand demonstrate improvements over the existing benchmark models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:46:21 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 20:17:54 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bica", "Ioana", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2002.12334", "submitter": "Michael P. Kim", "authors": "Amirata Ghorbani, Michael P. Kim, James Zou", "title": "A Distributional Framework for Data Valuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley value is a classic notion from game theory, historically used to\nquantify the contributions of individuals within groups, and more recently\napplied to assign values to data points when training machine learning models.\nDespite its foundational role, a key limitation of the data Shapley framework\nis that it only provides valuations for points within a fixed data set. It does\nnot account for statistical aspects of the data and does not give a way to\nreason about points outside the data set. To address these limitations, we\npropose a novel framework -- distributional Shapley -- where the value of a\npoint is defined in the context of an underlying data distribution. We prove\nthat distributional Shapley has several desirable statistical properties; for\nexample, the values are stable under perturbations to the data points\nthemselves and to the underlying data distribution. We leverage these\nproperties to develop a new algorithm for estimating values from data, which\ncomes with formal guarantees and runs two orders of magnitude faster than\nstate-of-the-art algorithms for computing the (non-distributional) data Shapley\nvalues. We apply distributional Shapley to diverse data sets and demonstrate\nits utility in a data market setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:51:35 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Kim", "Michael P.", ""], ["Zou", "James", ""]]}, {"id": "2002.12356", "submitter": "Andreas Foltyn", "authors": "Maximilian Seitzer, Andreas Foltyn, Felix P. Kemeth", "title": "NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through\n  Learned Aggregation of Convolutional Feature Maps", "comments": "Disentanglement Challenge - 33rd Conference on Neural Information\n  Processing Systems (NeurIPS) - NeurIPS 2019. arXiv admin note: text overlap\n  with arXiv:2002.10003. Acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report to our stage 2 submission to the NeurIPS 2019 disentanglement\nchallenge presents a simple image preprocessing method for learning\ndisentangled latent factors. We propose to train a variational autoencoder on\nregionally aggregated feature maps obtained from networks pretrained on the\nImageNet database, utilizing the implicit inductive bias contained in those\nfeatures for disentanglement. This bias can be further enhanced by explicitly\nfine-tuning the feature maps on auxiliary tasks useful for the challenge, such\nas angle, position estimation, or color classification. Our approach achieved\nthe 2nd place in stage 2 of the challenge. Code is available at\nhttps://github.com/mseitzer/neurips2019-disentanglement-challenge.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 08:46:17 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 15:16:35 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Seitzer", "Maximilian", ""], ["Foltyn", "Andreas", ""], ["Kemeth", "Felix P.", ""]]}, {"id": "2002.12359", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen and Cristina Soguero-Ruiz and Robert Jenssen", "title": "A Kernel to Exploit Informative Missingness in Multivariate Time Series\n  from EHRs", "comments": "2020 International Workshop on Health Intelligence, AAAI-20. arXiv\n  admin note: text overlap with arXiv:1907.05251", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of the electronic health records (EHRs) consists of clinical\nmeasurements collected over time, such as lab tests and vital signs, which\nprovide important information about a patient's health status. These sequences\nof clinical measurements are naturally represented as time series,\ncharacterized by multiple variables and large amounts of missing data, which\ncomplicate the analysis. In this work, we propose a novel kernel which is\ncapable of exploiting both the information from the observed values as well the\ninformation hidden in the missing patterns in multivariate time series (MTS)\noriginating e.g. from EHRs. The kernel, called TCK$_{IM}$, is designed using an\nensemble learning strategy in which the base models are novel mixed mode\nBayesian mixture models which can effectively exploit informative missingness\nwithout having to resort to imputation methods. Moreover, the ensemble approach\nensures robustness to hyperparameters and therefore TCK$_{IM}$ is particularly\nwell suited if there is a lack of labels - a known challenge in medical\napplications. Experiments on three real-world clinical datasets demonstrate the\neffectiveness of the proposed kernel.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:54:44 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Jenssen", "Robert", ""]]}, {"id": "2002.12364", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Theoretical Models of Learning to Learn", "comments": "arXiv admin note: text overlap with arXiv:1106.0245", "journal-ref": "in Learning to Learn (edited by Sebastian Thrun and Lorien Pratt),\n  159-179 (1998)", "doi": "10.1007/978-1-4615-5529-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Machine can only learn if it is biased in some way. Typically the bias is\nsupplied by hand, for example through the choice of an appropriate set of\nfeatures. However, if the learning machine is embedded within an {\\em\nenvironment} of related tasks, then it can {\\em learn} its own bias by learning\nsufficiently many tasks from the environment. In this paper two models of bias\nlearning (or equivalently, learning to learn) are introduced and the main\ntheoretical results presented. The first model is a PAC-type model based on\nempirical process theory, while the second is a hierarchical Bayes model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:35:26 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "2002.12388", "submitter": "Jens Eisert", "authors": "A. Goe{\\ss}mann, M. G\\\"otte, I. Roth, R. Sweke, G. Kutyniok, J. Eisert", "title": "Tensor network approaches for learning non-linear dynamical laws", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given observations of a physical system, identifying the underlying\nnon-linear governing equation is a fundamental task, necessary both for gaining\nunderstanding and generating deterministic future predictions. Of most\npractical relevance are automated approaches to theory building that scale\nefficiently for complex systems with many degrees of freedom. To date,\navailable scalable methods aim at a data-driven interpolation, without\nexploiting or offering insight into fundamental underlying physical principles,\nsuch as locality of interactions. In this work, we show that various physical\nconstraints can be captured via tensor network based parameterizations for the\ngoverning equation, which naturally ensures scalability. In addition to\nproviding analytic results motivating the use of such models for realistic\nphysical systems, we demonstrate that efficient rank-adaptive optimization\nalgorithms can be used to learn optimal tensor network models without requiring\na~priori knowledge of the exact tensor ranks. As such, we provide a\nphysics-informed approach to recovering structured dynamical laws from data,\nwhich adaptively balances the need for expressivity and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:02:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goe\u00dfmann", "A.", ""], ["G\u00f6tte", "M.", ""], ["Roth", "I.", ""], ["Sweke", "R.", ""], ["Kutyniok", "G.", ""], ["Eisert", "J.", ""]]}, {"id": "2002.12398", "submitter": "Maurice Weber", "authors": "Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Tao Xie, Ce Zhang,\n  Bo Li", "title": "Provable Robust Learning Based on Transformation-Specific Smoothing", "comments": "58 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) systems become pervasive, safeguarding their\nsecurity is critical. Recent work has demonstrated that motivated adversaries\ncould add adversarial perturbations to the test data to mislead ML systems. So\nfar, most research has focused on providing provable robustness guarantees for\nML models against a specific Lp norm bounded adversarial perturbation. However,\nin practice previous work has shown that there are other types of realistic\nadversarial transformations whose semantic meaning has been leveraged to attack\nML systems. In this paper, we aim to provide a unified framework for certifying\nML robustness against general adversarial transformations. First, we identify\nthe semantic transformations as different categories: resolvable (e.g.,\nGaussian blur and brightness) and differentially resolvable transformations\n(e.g., rotation and scaling). We then provide sufficient conditions and\nstrategies for certifying certain transformations. For instance, we propose a\nnovel sampling-based interpolation approach with estimated Lipschitz upper\nbound to certify the robustness against differentially resolvable\ntransformations. In addition, we theoretically optimize the smoothing\nstrategies for certifying the robustness of ML models against different\ntransformations. For instance, we show that smoothing by sampling from\nexponential distribution provides a tighter robustness bound than Gaussian.\nExtensive experiments on 7 semantic transformations show that our proposed\nunified framework significantly outperforms the state-of-the-art certified\nrobustness approaches on several datasets including ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:19:32 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 11:45:20 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 16:20:43 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Li", "Linyi", ""], ["Weber", "Maurice", ""], ["Xu", "Xiaojun", ""], ["Rimanic", "Luka", ""], ["Xie", "Tao", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""]]}, {"id": "2002.12399", "submitter": "Jayden Ooi", "authors": "Andy Su, Jayden Ooi, Tyler Lu, Dale Schuurmans, Craig Boutilier", "title": "ConQUR: Mitigating Delusional Bias in Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delusional bias is a fundamental source of error in approximate Q-learning.\nTo date, the only techniques that explicitly address delusion require\ncomprehensive search using tabular value estimates. In this paper, we develop\nefficient methods to mitigate delusional bias by training Q-approximators with\nlabels that are \"consistent\" with the underlying greedy policy class. We\nintroduce a simple penalization scheme that encourages Q-labels used across\ntraining batches to remain (jointly) consistent with the expressible policy\nclass. We also propose a search framework that allows multiple Q-approximators\nto be generated and tracked, thus mitigating the effect of premature (implicit)\npolicy commitments. Experimental results demonstrate that these methods can\nimprove the performance of Q-learning in a variety of Atari games, sometimes\ndramatically.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:22:51 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Su", "Andy", ""], ["Ooi", "Jayden", ""], ["Lu", "Tyler", ""], ["Schuurmans", "Dale", ""], ["Boutilier", "Craig", ""]]}, {"id": "2002.12404", "submitter": "Dongrui Wu", "authors": "Yuqi Cui, Huidong Wang, Dongrui Wu", "title": "Supervised Enhanced Soft Subspace Clustering (SESSC) for TSK Fuzzy\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy c-means based clustering algorithms are frequently used for\nTakagi-Sugeno-Kang (TSK) fuzzy classifier antecedent parameter estimation. One\nrule is initialized from each cluster. However, most of these clustering\nalgorithms are unsupervised, which waste valuable label information in the\ntraining data. This paper proposes a supervised enhanced soft subspace\nclustering (SESSC) algorithm, which considers simultaneously the within-cluster\ncompactness, between-cluster separation, and label information in clustering.\nIt can effectively deal with high-dimensional data, be used as a classifier\nalone, or be integrated into a TSK fuzzy classifier to further improve its\nperformance. Experiments on nine UCI datasets from various application domains\ndemonstrated that SESSC based initialization outperformed other clustering\napproaches, especially when the number of rules is small.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:39:19 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Cui", "Yuqi", ""], ["Wang", "Huidong", ""], ["Wu", "Dongrui", ""]]}, {"id": "2002.12406", "submitter": "Yansong Gao Mr.", "authors": "Yansong Gao and Pratik Chaudhari", "title": "A Free-Energy Principle for Representation Learning", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper employs a formal connection of machine learning with\nthermodynamics to characterize the quality of learnt representations for\ntransfer learning. We discuss how information-theoretic functional such as\nrate, distortion and classification loss of a model lie on a convex, so-called\nequilibrium surface.We prescribe dynamical processes to traverse this surface\nunder constraints, e.g., an iso-classification process that trades off rate and\ndistortion to keep the classification loss unchanged. We demonstrate how this\nprocess can be used for transferring representations from a source dataset to a\ntarget dataset while keeping the classification loss constant. Experimental\nvalidation of the theoretical results is provided on standard\nimage-classification datasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:44:49 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Gao", "Yansong", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2002.12410", "submitter": "Peter Richt\\'arik", "authors": "Aleksandr Beznosikov and Samuel Horv\\'ath and Peter Richt\\'arik and\n  Mher Safaryan", "title": "On Biased Compression for Distributed Learning", "comments": "39 pages, 10 Figures, 25 Theorems and Lemmas, 8 New Compression\n  Operators, 2 Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, various communication compression techniques have\nemerged as an indispensable tool helping to alleviate the communication\nbottleneck in distributed learning. However, despite the fact {\\em biased}\ncompressors often show superior performance in practice when compared to the\nmuch more studied and understood {\\em unbiased} compressors, very little is\nknown about them. In this work we study three classes of biased compression\noperators, two of which are new, and their performance when applied to\n(stochastic) gradient descent and distributed (stochastic) gradient descent. We\nshow for the first time that biased compressors can lead to linear convergence\nrates both in the single node and distributed settings. Our {\\em distributed}\nSGD method enjoys the ergodic rate $\\mathcal{O}\\left(\\frac{\\delta L \\exp(-K)\n}{\\mu} + \\frac{(C + D)}{K\\mu}\\right)$, where $\\delta$ is a compression\nparameter which grows when more compression is applied, $L$ and $\\mu$ are the\nsmoothness and strong convexity constants, $C$ captures stochastic gradient\nnoise ($C=0$ if full gradients are computed on each node) and $D$ captures the\nvariance of the gradients at the optimum ($D=0$ for over-parameterized models).\nFurther, via a theoretical study of several synthetic and empirical\ndistributions of communicated gradients, we shed light on why and by how much\nbiased compressors outperform their unbiased variants. Finally, we propose a\nnew highly performing biased compressor---combination of Top-$k$ and natural\ndithering---which in our experiments outperforms all other compression\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:52:24 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Beznosikov", "Aleksandr", ""], ["Horv\u00e1th", "Samuel", ""], ["Richt\u00e1rik", "Peter", ""], ["Safaryan", "Mher", ""]]}, {"id": "2002.12414", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran and Michael Rabbat", "title": "On the Convergence of Nesterov's Accelerated Gradient Method in\n  Stochastic Settings", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML 2020)", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Nesterov's accelerated gradient method with constant step-size and\nmomentum parameters in the stochastic approximation setting (unbiased gradients\nwith bounded variance) and the finite-sum setting (where randomness is due to\nsampling mini-batches). To build better insight into the behavior of Nesterov's\nmethod in stochastic settings, we focus throughout on objectives that are\nsmooth, strongly-convex, and twice continuously differentiable. In the\nstochastic approximation setting, Nesterov's method converges to a neighborhood\nof the optimal point at the same accelerated rate as in the deterministic\nsetting. Perhaps surprisingly, in the finite-sum setting, we prove that\nNesterov's method may diverge with the usual choice of step-size and momentum,\nunless additional conditions on the problem related to conditioning and data\ncoherence are satisfied. Our results shed light as to why Nesterov's method may\nfail to converge or achieve acceleration in the finite-sum setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:56:41 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 20:01:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Assran", "Mahmoud", ""], ["Rabbat", "Michael", ""]]}, {"id": "2002.12435", "submitter": "Rahul Singh", "authors": "Rahul Singh, Abhishek Gupta and Ness B. Shroff", "title": "Learning in Markov Decision Processes under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reinforcement learning (RL) in Markov Decision Processes in which\nan agent repeatedly interacts with an environment that is modeled by a\ncontrolled Markov process. At each time step $t$, it earns a reward, and also\nincurs a cost-vector consisting of $M$ costs. We design learning algorithms\nthat maximize the cumulative reward earned over a time horizon of $T$\ntime-steps, while simultaneously ensuring that the average values of the $M$\ncost expenditures are bounded by agent-specified thresholds\n$c^{ub}_i,i=1,2,\\ldots,M$. The considerations on the cumulative cost\nexpenditures departs from the existing literature, in that the agent now\nadditionally needs to balance the cost expenses in an online manner, while\nsimultaneously performing the exploration-exploitation trade-off that is\ntypically encountered in RL tasks.\n  In order to measure the performance of a reinforcement learning algorithm\nthat satisfies the average cost constraints, we define an $M+1$ dimensional\nregret vector that is composed of its reward regret, and $M$ cost regrets. The\nreward regret measures the sub-optimality in the cumulative reward, while the\n$i$-th component of the cost regret vector is the difference between its $i$-th\ncumulative cost expense and the expected cost expenditures $Tc^{ub}_i$. We\nprove that with a high probablity, the regret vector of UCRL-CMDP is\nupper-bounded as $O\\left( S\\sqrt{AT^{1.5}\\log(T)}\\right)$, where $S$ is the\nnumber of states, $A$ is the number of actions, and $T$ is the time horizon. We\nfurther show how to reduce the regret of a desired subset of the $M$ costs, at\nthe expense of increasing the regrets of rewards and the remaining costs. To\nthe best of our knowledge, ours is the only work that considers non-episodic RL\nunder average cost constraints, and derive algorithms that can~\\emph{tune the\nregret vector} according to the agent's requirements on its cost regrets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 20:58:39 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 17:11:36 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Singh", "Rahul", ""], ["Gupta", "Abhishek", ""], ["Shroff", "Ness B.", ""]]}, {"id": "2002.12446", "submitter": "Aaron Zweig", "authors": "Aaron Zweig and Joan Bruna", "title": "Provably Efficient Third-Person Imitation from Offline Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation in imitation learning represents an essential step towards\nimproving generalizability. However, even in the restricted setting of\nthird-person imitation where transfer is between isomorphic Markov Decision\nProcesses, there are no strong guarantees on the performance of transferred\npolicies. We present problem-dependent, statistical learning guarantees for\nthird-person imitation from observation in an offline setting, and a lower\nbound on performance in the online setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:18:06 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zweig", "Aaron", ""], ["Bruna", "Joan", ""]]}, {"id": "2002.12455", "submitter": "Xiang Deng", "authors": "Xiang Deng and Zhongfei Zhang", "title": "Is the Meta-Learning Idea Able to Improve the Generalization of Deep\n  Neural Networks on the Standard Supervised Learning?", "comments": null, "journal-ref": "ICPR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial efforts have been made on improving the generalization abilities\nof deep neural networks (DNNs) in order to obtain better performances without\nintroducing more parameters. On the other hand, meta-learning approaches\nexhibit powerful generalization on new tasks in few-shot learning. Intuitively,\nfew-shot learning is more challenging than the standard supervised learning as\neach target class only has a very few or no training samples. The natural\nquestion that arises is whether the meta-learning idea can be used for\nimproving the generalization of DNNs on the standard supervised learning. In\nthis paper, we propose a novel meta-learning based training procedure (MLTP)\nfor DNNs and demonstrate that the meta-learning idea can indeed improve the\ngeneralization abilities of DNNs. MLTP simulates the meta-training process by\nconsidering a batch of training samples as a task. The key idea is that the\ngradient descent step for improving the current task performance should also\nimprove a new task performance, which is ignored by the current standard\nprocedure for training neural networks. MLTP also benefits from all the\nexisting training techniques such as dropout, weight decay, and batch\nnormalization. We evaluate MLTP by training a variety of small and large neural\nnetworks on three benchmark datasets, i.e., CIFAR-10, CIFAR-100, and Tiny\nImageNet. The experimental results show a consistently improved generalization\nperformance on all the DNNs with different sizes, which verifies the promise of\nMLTP and demonstrates that the meta-learning idea is indeed able to improve the\ngeneralization of DNNs on the standard supervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:29:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Deng", "Xiang", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "2002.12460", "submitter": "Yuxin Sun", "authors": "Yuxin Sun and Benny Chain and Samuel Kaski and John Shawe-Taylor", "title": "Correlated Feature Selection with Extended Exclusive Group Lasso", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many high dimensional classification or regression problems set in a\nbiological context, the complete identification of the set of informative\nfeatures is often as important as predictive accuracy, since this can provide\nmechanistic insight and conceptual understanding. Lasso and related algorithms\nhave been widely used since their sparse solutions naturally identify a set of\ninformative features. However, Lasso performs erratically when features are\ncorrelated. This limits the use of such algorithms in biological problems,\nwhere features such as genes often work together in pathways, leading to sets\nof highly correlated features. In this paper, we examine the performance of a\nLasso derivative, the exclusive group Lasso, in this setting. We propose fast\nalgorithms to solve the exclusive group Lasso, and introduce a solution to the\ncase when the underlying group structure is unknown. The solution combines\nstability selection with random group allocation and introduction of artificial\nfeatures. Experiments with both synthetic and real-world data highlight the\nadvantages of this proposed methodology over Lasso in comprehensive selection\nof informative features.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:55:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sun", "Yuxin", ""], ["Chain", "Benny", ""], ["Kaski", "Samuel", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2002.12462", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Tal Hassner, Matthias Seeger, Cedric Archambeau", "title": "LEEP: A New Measure to Evaluate Transferability of Learned\n  Representations", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new measure to evaluate the transferability of representations\nlearned by classifiers. Our measure, the Log Expected Empirical Prediction\n(LEEP), is simple and easy to compute: when given a classifier trained on a\nsource data set, it only requires running the target data set through this\nclassifier once. We analyze the properties of LEEP theoretically and\ndemonstrate its effectiveness empirically. Our analysis shows that LEEP can\npredict the performance and convergence speed of both transfer and\nmeta-transfer learning methods, even for small or imbalanced data. Moreover,\nLEEP outperforms recently proposed transferability measures such as negative\nconditional entropy and H scores. Notably, when transferring from ImageNet to\nCIFAR100, LEEP can achieve up to 30% improvement compared to the best competing\nmethod in terms of the correlations with actual transfer accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:02:20 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 02:33:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Hassner", "Tal", ""], ["Seeger", "Matthias", ""], ["Archambeau", "Cedric", ""]]}, {"id": "2002.12463", "submitter": "Marc Fischer", "authors": "Marc Fischer, Maximilian Baader, Martin Vechev", "title": "Certified Defense to Image Transformations via Randomized Smoothing", "comments": "Conference Paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend randomized smoothing to cover parameterized transformations (e.g.,\nrotations, translations) and certify robustness in the parameter space (e.g.,\nrotation angle). This is particularly challenging as interpolation and rounding\neffects mean that image transformations do not compose, in turn preventing\ndirect certification of the perturbed image (unlike certification with $\\ell^p$\nnorms). We address this challenge by introducing three different defenses, each\nwith a different guarantee (heuristic, distributional and individual) stemming\nfrom the method used to bound the interpolation error. Importantly, in the\nindividual case, we show how to efficiently compute the inverse of an image\ntransformation, enabling us to provide individual guarantees in the online\nsetting. We provide an implementation of all methods at\nhttps://github.com/eth-sri/transformation-smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:02:32 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 10:40:34 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 15:03:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Fischer", "Marc", ""], ["Baader", "Maximilian", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.12475", "submitter": "Alec Koppel", "authors": "Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, Alec Koppel", "title": "Cautious Reinforcement Learning via Distributional Risk in the Dual\n  Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of risk-sensitive policies in reinforcement learning\nproblems defined by a Markov Decision Process (MDPs) whose state and action\nspaces are countably finite. Prior efforts are predominately afflicted by\ncomputational challenges associated with the fact that risk-sensitive MDPs are\ntime-inconsistent. To ameliorate this issue, we propose a new definition of\nrisk, which we call caution, as a penalty function added to the dual objective\nof the linear programming (LP) formulation of reinforcement learning. The\ncaution measures the distributional risk of a policy, which is a function of\nthe policy's long-term state occupancy distribution. To solve this problem in\nan online model-free manner, we propose a stochastic variant of primal-dual\nmethod that uses Kullback-Lieber (KL) divergence as its proximal term. We\nestablish that the number of iterations/samples required to attain\napproximately optimal solutions of this scheme matches tight dependencies on\nthe cardinality of the state and action spaces, but differs in its dependence\non the infinity norm of the gradient of the risk measure. Experiments\ndemonstrate the merits of this approach for improving the reliability of reward\naccumulation without additional computational burdens.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 23:18:04 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Junyu", ""], ["Bedi", "Amrit Singh", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2002.12478", "submitter": "Qingsong Wen", "authors": "Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue\n  Wang, Huan Xu", "title": "Time Series Data Augmentation for Deep Learning: A Survey", "comments": "8 pages, 2 figures, 3 tables, 61 referred papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning performs remarkably well on many time series analysis tasks\nrecently. The superior performance of deep neural networks relies heavily on a\nlarge number of training data to avoid overfitting. However, the labeled data\nof many real-world time series applications may be limited such as\nclassification in medical time series and anomaly detection in AIOps. As an\neffective way to enhance the size and quality of the training data, data\naugmentation is crucial to the successful application of deep learning models\non time series data. In this paper, we systematically review different data\naugmentation methods for time series. We propose a taxonomy for the reviewed\nmethods, and then provide a structured review for these methods by highlighting\ntheir strengths and limitations. We also empirically compare different data\naugmentation methods for different tasks including time series anomaly\ndetection, classification, and forecasting. Finally, we discuss and highlight\nfive future directions to provide useful research guidance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 23:38:11 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 03:40:17 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wen", "Qingsong", ""], ["Sun", "Liang", ""], ["Yang", "Fan", ""], ["Song", "Xiaomin", ""], ["Gao", "Jingkun", ""], ["Wang", "Xue", ""], ["Xu", "Huan", ""]]}, {"id": "2002.12486", "submitter": "Fengqi You", "authors": "Shipu Zhao, Fengqi You", "title": "Distributionally Robust Chance Constrained Programming with Generative\n  Adversarial Networks (GANs)", "comments": null, "journal-ref": "AIChE Journal, Volume 66, Issue 6, June 2020, e16963", "doi": "10.1002/aic.16963", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning based data-driven optimization\nmethod. A novel generative adversarial network (GAN) based data-driven\ndistributionally robust chance constrained programming framework is proposed.\nGAN is applied to fully extract distributional information from historical data\nin a nonparametric and unsupervised way without a priori approximation or\nassumption. Since GAN utilizes deep neural networks, complicated data\ndistributions and modes can be learned, and it can model uncertainty\nefficiently and accurately. Distributionally robust chance constrained\nprogramming takes into consideration ambiguous probability distributions of\nuncertain parameters. To tackle the computational challenges, sample average\napproximation method is adopted, and the required data samples are generated by\nGAN in an end-to-end way through the differentiable networks. The proposed\nframework is then applied to supply chain optimization under demand\nuncertainty. The applicability of the proposed approach is illustrated through\na county-level case study of a spatially explicit biofuel supply chain in\nIllinois.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:05:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhao", "Shipu", ""], ["You", "Fengqi", ""]]}, {"id": "2002.12493", "submitter": "Michael Muehlebach", "authors": "Michael Muehlebach and Michael I. Jordan", "title": "Optimization with Momentum: Dynamical, Control-Theoretic, and Symplectic\n  Perspectives", "comments": "30 pages; 20 pages appendix and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the convergence rate of various momentum-based optimization\nalgorithms from a dynamical systems point of view. Our analysis exploits\nfundamental topological properties, such as the continuous dependence of\niterates on their initial conditions, to provide a simple characterization of\nconvergence rates. In many cases, closed-form expressions are obtained that\nrelate algorithm parameters to the convergence rate. The analysis encompasses\ndiscrete time and continuous time, as well as time-invariant and time-variant\nformulations, and is not limited to a convex or Euclidean setting. In addition,\nthe article rigorously establishes why symplectic discretization schemes are\nimportant for momentum-based optimization algorithms, and provides a\ncharacterization of algorithms that exhibit accelerated convergence.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:32:47 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 07:03:56 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Muehlebach", "Michael", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.12499", "submitter": "Dibya Ghosh", "authors": "William Fedus, Dibya Ghosh, John D. Martin, Marc G. Bellemare, Yoshua\n  Bengio, Hugo Larochelle", "title": "On Catastrophic Interference in Atari 2600 Games", "comments": "First two authors contributed equally. Code available to reproduce\n  experiments at\n  https://github.com/google-research/google-research/tree/master/memento", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning is sample inefficient. One hypothesis\n-- speculated, but not confirmed -- is that catastrophic interference within an\nenvironment inhibits learning. We test this hypothesis through a large-scale\nempirical study in the Arcade Learning Environment (ALE) and, indeed, find\nsupporting evidence. We show that interference causes performance to plateau;\nthe network cannot train on segments beyond the plateau without degrading the\npolicy used to reach there. By synthetically controlling for interference, we\ndemonstrate performance boosts across architectures, learning algorithms and\nenvironments. A more refined analysis shows that learning one segment of a game\noften increases prediction errors elsewhere. Our study provides a clear\nempirical link between catastrophic interference and sample efficiency in\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:55:03 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 17:36:46 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Fedus", "William", ""], ["Ghosh", "Dibya", ""], ["Martin", "John D.", ""], ["Bellemare", "Marc G.", ""], ["Bengio", "Yoshua", ""], ["Larochelle", "Hugo", ""]]}, {"id": "2002.12501", "submitter": "Maximilian Nickel", "authors": "Maximilian Nickel, Matthew Le", "title": "Learning Multivariate Hawkes Processes at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Hawkes Processes (MHPs) are an important class of temporal point\nprocesses that have enabled key advances in understanding and predicting social\ninformation systems. However, due to their complex modeling of temporal\ndependencies, MHPs have proven to be notoriously difficult to scale, what has\nlimited their applications to relatively small domains. In this work, we\npropose a novel model and computational approach to overcome this important\nlimitation. By exploiting a characteristic sparsity pattern in real-world\ndiffusion processes, we show that our approach allows to compute the exact\nlikelihood and gradients of an MHP -- independently of the ambient dimensions\nof the underlying network. We show on synthetic and real-world datasets that\nour model does not only achieve state-of-the-art predictive results, but also\nimproves runtime performance by multiple orders of magnitude compared to\nstandard methods on sparse event sequences. In combination with easily\ninterpretable latent variables and influence structures, this allows us to\nanalyze diffusion processes at previously unattainable scale.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 01:18:01 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Nickel", "Maximilian", ""], ["Le", "Matthew", ""]]}, {"id": "2002.12537", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Kimia Nadjahi, Umut Simsekli, Shahin Shahrampour", "title": "Generalized Sliced Distances for Probability Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability metrics have become an indispensable part of modern statistics\nand machine learning, and they play a quintessential role in various\napplications, including statistical hypothesis testing and generative modeling.\nHowever, in a practical setting, the convergence behavior of the algorithms\nbuilt upon these distances have not been well established, except for a few\nspecific cases. In this paper, we introduce a broad family of probability\nmetrics, coined as Generalized Sliced Probability Metrics (GSPMs), that are\ndeeply rooted in the generalized Radon transform. We first verify that GSPMs\nare metrics. Then, we identify a subset of GSPMs that are equivalent to maximum\nmean discrepancy (MMD) with novel positive definite kernels, which come with a\nunique geometric interpretation. Finally, by exploiting this connection, we\nconsider GSPM-based gradient flows for generative modeling applications and\nshow that under mild assumptions, the gradient flow converges to the global\noptimum. We illustrate the utility of our approach on both real and synthetic\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 04:18:00 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Kolouri", "Soheil", ""], ["Nadjahi", "Kimia", ""], ["Simsekli", "Umut", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2002.12538", "submitter": "Nave Frost", "authors": "Sanjoy Dasgupta, Nave Frost, Michal Moshkovitz, Cyrus Rashtchian", "title": "Explainable $k$-Means and $k$-Medians Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a popular form of unsupervised learning for geometric data.\nUnfortunately, many clustering algorithms lead to cluster assignments that are\nhard to explain, partially because they depend on all the features of the data\nin a complicated way. To improve interpretability, we consider using a small\ndecision tree to partition a data set into clusters, so that clusters can be\ncharacterized in a straightforward manner. We study this problem from a\ntheoretical viewpoint, measuring cluster quality by the $k$-means and\n$k$-medians objectives: Must there exist a tree-induced clustering whose cost\nis comparable to that of the best unconstrained clustering, and if so, how can\nit be found? In terms of negative results, we show, first, that popular\ntop-down decision tree algorithms may lead to clusterings with arbitrarily\nlarge cost, and second, that any tree-induced clustering must in general incur\nan $\\Omega(\\log k)$ approximation factor compared to the optimal clustering. On\nthe positive side, we design an efficient algorithm that produces explainable\nclusters using a tree with $k$ leaves. For two means/medians, we show that a\nsingle threshold cut suffices to achieve a constant factor approximation, and\nwe give nearly-matching lower bounds. For general $k \\geq 2$, our algorithm is\nan $O(k)$ approximation to the optimal $k$-medians and an $O(k^2)$\napproximation to the optimal $k$-means. Prior to our work, no algorithms were\nknown with provable guarantees independent of dimension and input size.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 04:21:53 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 00:43:14 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Frost", "Nave", ""], ["Moshkovitz", "Michal", ""], ["Rashtchian", "Cyrus", ""]]}, {"id": "2002.12547", "submitter": "Ariel Jaffe", "authors": "Ariel Jaffe, Noah Amsel, Yariv Aizenbud, Boaz Nadler, Joseph T. Chang,\n  Yuval Kluger", "title": "Spectral neighbor joining for reconstruction of latent tree models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in multiple scientific applications is that the\ndistribution of observed data can be modeled by a latent tree graphical model.\nAn important example is phylogenetics, where the tree models the evolutionary\nlineages of a set of observed organisms. Given a set of independent\nrealizations of the random variables at the leaves of the tree, a key challenge\nis to infer the underlying tree topology. In this work we develop Spectral\nNeighbor Joining (SNJ), a novel method to recover the structure of latent tree\ngraphical models. Given a matrix that contains a measure of similarity between\nall pairs of observed variables, SNJ computes a spectral measure of cohesion\nbetween groups of observed variables. We prove that SNJ is consistent, and\nderive a sufficient condition for correct tree recovery from an estimated\nsimilarity matrix. Combining this condition with a concentration of measure\nresult on the similarity matrix, we bound the number of samples required to\nrecover the tree with high probability. We illustrate via extensive simulations\nthat in comparison to several other reconstruction methods, SNJ requires fewer\nsamples to accurately recover trees with a large number of leaves or long\nedges.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:13:08 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 01:57:45 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 02:15:30 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jaffe", "Ariel", ""], ["Amsel", "Noah", ""], ["Aizenbud", "Yariv", ""], ["Nadler", "Boaz", ""], ["Chang", "Joseph T.", ""], ["Kluger", "Yuval", ""]]}, {"id": "2002.12563", "submitter": "Ziang Long", "authors": "Ziang Long and Penghang Yin and Jack Xin", "title": "Global Convergence and Geometric Characterization of Slow to Fast Weight\n  Evolution in Neural Network Training for Classifying Linearly Non-Separable\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the dynamics of gradient descent in learning neural\nnetworks for classification problems. Unlike in existing works, we consider the\nlinearly non-separable case where the training data of different classes lie in\northogonal subspaces. We show that when the network has sufficient (but not\nexceedingly large) number of neurons, (1) the corresponding minimization\nproblem has a desirable landscape where all critical points are global minima\nwith perfect classification; (2) gradient descent is guaranteed to converge to\nthe global minima. Moreover, we discovered a geometric condition on the network\nweights so that when it is satisfied, the weight evolution transitions from a\nslow phase of weight direction spreading to a fast phase of weight convergence.\nThe geometric condition says that the convex hull of the weights projected on\nthe unit sphere contains the origin.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:56:55 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 22:37:33 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 08:50:41 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Long", "Ziang", ""], ["Yin", "Penghang", ""], ["Xin", "Jack", ""]]}, {"id": "2002.12570", "submitter": "Yoichi Sasaki", "authors": "Yoichi Sasaki, Kosuke Akimoto, Takanori Maehara", "title": "Learning Directly from Grammar Compressed Text", "comments": "12 pages, 4 Postscript figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks using numerous text data have been successfully applied to a\nvariety of tasks. While massive text data is usually compressed using\ntechniques such as grammar compression, almost all of the previous machine\nlearning methods assume already decompressed sequence data as their input. In\nthis paper, we propose a method to directly apply neural sequence models to\ntext data compressed with grammar compression algorithms without decompression.\nTo encode the unique symbols that appear in compression rules, we introduce\ncomposer modules to incrementally encode the symbols into vector\nrepresentations. Through experiments on real datasets, we empirically showed\nthat the proposal model can achieve both memory and computational efficiency\nwhile maintaining moderate performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 06:51:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sasaki", "Yoichi", ""], ["Akimoto", "Kosuke", ""], ["Maehara", "Takanori", ""]]}, {"id": "2002.12578", "submitter": "Fahad Shamshad", "authors": "Fahad Shamshad, Ali Ahmed", "title": "Class-Specific Blind Deconvolutional Phase Retrieval Under a Generative\n  Prior", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the highly ill-posed problem of jointly recovering\ntwo real-valued signals from the phaseless measurements of their circular\nconvolution. The problem arises in various imaging modalities such as Fourier\nptychography, X-ray crystallography, and in visible light communication. We\npropose to solve this inverse problem using alternating gradient descent\nalgorithm under two pretrained deep generative networks as priors; one is\ntrained on sharp images and the other on blur kernels. The proposed recovery\nalgorithm strives to find a sharp image and a blur kernel in the range of the\nrespective pre-generators that \\textit{best} explain the forward measurement\nmodel. In doing so, we are able to reconstruct quality image estimates.\nMoreover, the numerics show that the proposed approach performs well on the\nchallenging measurement models that reflect the physically realizable imaging\nsystems and is also robust to noise\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 07:36:28 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Shamshad", "Fahad", ""], ["Ahmed", "Ali", ""]]}, {"id": "2002.12592", "submitter": "Asifullah Khan", "authors": "Aqsa Saeed Qureshi, Asifullah Khan, and Muhammad Waleed Khan", "title": "Wind Speed Prediction using Deep Ensemble Learning with a Jet-like\n  Architecture", "comments": "Pages: 14, Tables: 6, Figures: 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wind is one of the most increasingly used renewable energy resources.\nAccurate and reliable forecast of wind speed is necessary for efficient power\nproduction; however, it is not an easy task because it depends upon\nmeteorological features of the surrounding region. Deep learning is extensively\nused these days for performing feature extraction. It has also been observed\nthat the integration of several learning models, known as ensemble learning,\ngenerally gives better performance compared to a single model. The design of\nwings, tail, and nose of a jet improves the aerodynamics resulting in a smooth\nand controlled flight of the jet against the variations of the air currents.\nInspired by the shape and working of a jet, a novel Deep Ensemble Learning\nusing Jet-like Architecture (DEL-Jet) technique is proposed to enhance the\ndiversity and robustness of a learning system against the variations in the\ninput space. The diverse feature spaces of the base-regressors are exploited\nusing the jet-like ensemble architecture. Two Convolutional Neural Networks (as\njet wings) and one deep Auto-Encoder (as jet tail) are used to extract the\ndiverse feature spaces from the input data. After that, nonlinear PCA (as jet\nmain body) is employed to reduce the dimensionality of extracted feature space.\nFinally, both the reduced and the original feature spaces are exploited to\ntrain the meta-regressor (as jet nose) for forecasting the wind speed. The\nperformance of the proposed DEL-Jet technique is evaluated for ten independent\nruns and shows that the deep and jet-like architecture helps in improving the\nrobustness and generalization of the learning system.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:33:41 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 16:41:12 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Qureshi", "Aqsa Saeed", ""], ["Khan", "Asifullah", ""], ["Khan", "Muhammad Waleed", ""]]}, {"id": "2002.12597", "submitter": "Makoto Takamoto", "authors": "Makoto Takamoto, Yusuke Morishita, and Hitoshi Imaoka", "title": "An Efficient Method of Training Small Models for Regression Problems\n  with Knowledge Distillation", "comments": "7 pages, 2 figures, draft version of a paper accepted for IEEE 3rd\n  International Conference on Multimedia Information Processing and Retrieval\n  (MIPR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing deep neural network (DNN) models becomes a very important and\nnecessary technique for real-world applications, such as deploying those models\non mobile devices. Knowledge distillation is one of the most popular methods\nfor model compression, and many studies have been made on developing this\ntechnique. However, those studies mainly focused on classification problems,\nand very few attempts have been made on regression problems, although there are\nmany application of DNNs on regression problems. In this paper, we propose a\nnew formalism of knowledge distillation for regression problems. First, we\npropose a new loss function, teacher outlier rejection loss, which rejects\noutliers in training samples using teacher model predictions. Second, we\nconsider a multi-task network with two outputs: one estimates training labels\nwhich is in general contaminated by noisy labels; And the other estimates\nteacher model's output which is expected to modify the noise labels following\nthe memorization effects. By considering the multi-task network, training of\nthe feature extraction of student models becomes more effective, and it allows\nus to obtain a better student model than one trained from scratch. We performed\ncomprehensive evaluation with one simple toy model: sinusoidal function, and\ntwo open datasets: MPIIGaze, and Multi-PIE. Our results show consistent\nimprovement in accuracy regardless of the annotation error level in the\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:46:12 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Takamoto", "Makoto", ""], ["Morishita", "Yusuke", ""], ["Imaoka", "Hitoshi", ""]]}, {"id": "2002.12606", "submitter": "Benjamin Stokell", "authors": "Benjamin G. Stokell, Rajen D. Shah, Ryan J. Tibshirani", "title": "Modelling High-Dimensional Categorical Data Using Nonconvex Fusion\n  Penalties", "comments": "52 pages, 10 figures; to appear in JRSSB", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for estimation in high-dimensional linear models with\nnominal categorical data. Our estimator, called SCOPE, fuses levels together by\nmaking their corresponding coefficients exactly equal. This is achieved using\nthe minimax concave penalty on differences between the order statistics of the\ncoefficients for a categorical variable, thereby clustering the coefficients.\nWe provide an algorithm for exact and efficient computation of the global\nminimum of the resulting nonconvex objective in the case with a single variable\nwith potentially many levels, and use this within a block coordinate descent\nprocedure in the multivariate case. We show that an oracle least squares\nsolution that exploits the unknown level fusions is a limit point of the\ncoordinate descent with high probability, provided the true levels have a\ncertain minimum separation; these conditions are known to be minimal in the\nunivariate case. We demonstrate the favourable performance of SCOPE across a\nrange of real and simulated datasets. An R package CatReg implementing SCOPE\nfor linear models and also a version for logistic regression is available on\nCRAN.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:20:41 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 18:52:13 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 10:45:06 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 14:48:14 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Stokell", "Benjamin G.", ""], ["Shah", "Rajen D.", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "2002.12613", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas\n  Krause", "title": "Mixed Strategies for Robust Optimization of Unknown Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust optimization problems, where the goal is to optimize an\nunknown objective function against the worst-case realization of an uncertain\nparameter. For this setting, we design a novel sample-efficient algorithm\nGP-MRO, which sequentially learns about the unknown objective from noisy point\nevaluations. GP-MRO seeks to discover a robust and randomized mixed strategy,\nthat maximizes the worst-case expected objective value. To achieve this, it\ncombines techniques from online learning with nonparametric confidence bounds\nfrom Gaussian processes. Our theoretical results characterize the number of\nsamples required by GP-MRO to discover a robust near-optimal mixed strategy for\ndifferent GP kernels of interest. We experimentally demonstrate the performance\nof our algorithm on synthetic datasets and on human-assisted trajectory\nplanning tasks for autonomous vehicles. In our simulations, we show that robust\ndeterministic strategies can be overly conservative, while the mixed strategies\nfound by GP-MRO significantly improve the overall performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:28:17 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:19:06 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Kamgarpour", "Maryam", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.12626", "submitter": "Akihiro Yabe", "authors": "Akihiro Yabe", "title": "Causality and Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decision-maker must consider cofounding bias when attempting to apply\nmachine learning prediction, and, while feature selection is widely recognized\nas important process in data-analysis, it could cause cofounding bias. A causal\nBayesian network is a standard tool for describing causal relationships, and if\nrelationships are known, then adjustment criteria can determine with which\nfeatures cofounding bias disappears. A standard modification would thus utilize\ncausal discovery algorithms for preventing cofounding bias in feature\nselection. Causal discovery algorithms, however, essentially rely on the\nfaithfulness assumption, which turn out to be easily violated in practical\nfeature selection settings. In this paper, we propose a meta-algorithm that can\nremedy existing feature selection algorithms in terms of cofounding bias. Our\nalgorithm is induced from a novel adjustment criterion that requires rather\nthan faithfulness, an assumption which can be induced from another well-known\nassumption of the causal sufficiency. We further prove that the features added\nthrough our modification convert cofounding bias into prediction variance. With\nthe aid of existing robust optimization technologies that regularize risky\nstrategies with high variance, then, we are able to successfully improve the\nthroughput performance of decision-making optimization, as is shown in our\nexperimental results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:02:59 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Yabe", "Akihiro", ""]]}, {"id": "2002.12636", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Beren Millidge, Anil K. Seth, Christopher L.\n  Buckley", "title": "Reinforcement Learning through Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.SY eess.SY math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The central tenet of reinforcement learning (RL) is that agents seek to\nmaximize the sum of cumulative rewards. In contrast, active inference, an\nemerging framework within cognitive and computational neuroscience, proposes\nthat agents act to maximize the evidence for a biased generative model. Here,\nwe illustrate how ideas from active inference can augment traditional RL\napproaches by (i) furnishing an inherent balance of exploration and\nexploitation, and (ii) providing a more flexible conceptualization of reward.\nInspired by active inference, we develop and implement a novel objective for\ndecision making, which we term the free energy of the expected future. We\ndemonstrate that the resulting algorithm successfully balances exploration and\nexploitation, simultaneously achieving robust performance on several\nchallenging RL benchmarks with sparse, well-shaped, and no rewards.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:28:21 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Tschantz", "Alexander", ""], ["Millidge", "Beren", ""], ["Seth", "Anil K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "2002.12640", "submitter": "Meyer Scetbon", "authors": "Meyer Scetbon and Zaid Harchaoui", "title": "A Spectral Analysis of Dot-product Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present eigenvalue decay estimates of integral operators associated with\ncompositional dot-product kernels. The estimates improve on previous ones\nestablished for power series kernels on spheres. This allows us to obtain the\nvolumes of balls in the corresponding reproducing kernel Hilbert spaces. We\ndiscuss the consequences on statistical estimation with compositional dot\nproduct kernels and highlight interesting trade-offs between the approximation\nerror and the statistical error depending on the number of compositions and the\nsmoothness of the kernels.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:31:38 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 16:48:31 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Scetbon", "Meyer", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2002.12641", "submitter": "Manli Zhang", "authors": "Jianhong Zhang, Manli Zhang, Zhiwu Lu, Tao Xiang and Jirong Wen", "title": "AdarGCN: Adaptive Aggregation GCN for Few-Shot Learning", "comments": "The code is at github - https://github.com/RiceZJH/AdarGCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing few-shot learning (FSL) methods assume that there exist sufficient\ntraining samples from source classes for knowledge transfer to target classes\nwith few training samples. However, this assumption is often invalid,\nespecially when it comes to fine-grained recognition. In this work, we define a\nnew FSL setting termed few-shot fewshot learning (FSFSL), under which both the\nsource and target classes have limited training samples. To overcome the source\nclass data scarcity problem, a natural option is to crawl images from the web\nwith class names as search keywords. However, the crawled images are inevitably\ncorrupted by large amount of noise (irrelevant images) and thus may harm the\nperformance. To address this problem, we propose a graph convolutional network\n(GCN)-based label denoising (LDN) method to remove the irrelevant images.\nFurther, with the cleaned web images as well as the original clean training\nimages, we propose a GCN-based FSL method. For both the LDN and FSL tasks, a\nnovel adaptive aggregation GCN (AdarGCN) model is proposed, which differs from\nexisting GCN models in that adaptive aggregation is performed based on a\nmulti-head multi-level aggregation module. With AdarGCN, how much and how far\ninformation carried by each graph node is propagated in the graph structure can\nbe determined automatically, therefore alleviating the effects of both noisy\nand outlying training samples. Extensive experiments show the superior\nperformance of our AdarGCN under both the new FSFSL and the conventional FSL\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:34:36 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 08:05:17 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhang", "Jianhong", ""], ["Zhang", "Manli", ""], ["Lu", "Zhiwu", ""], ["Xiang", "Tao", ""], ["Wen", "Jirong", ""]]}, {"id": "2002.12642", "submitter": "Buse Melis Ozyildirim", "authors": "Buse Melis Ozyildirim (1), Mariam Kiran (2) ((1) Department of\n  Computer Engineering Cukurova University, (2) Energy Sciences Network\n  Lawrence Berkeley National Laboratory)", "title": "Do optimization methods in deep learning applications matter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in deep learning, exponential data growth and increasing model\ncomplexity, developing efficient optimization methods are attracting much\nresearch attention. Several implementations favor the use of Conjugate Gradient\n(CG) and Stochastic Gradient Descent (SGD) as being practical and elegant\nsolutions to achieve quick convergence, however, these optimization processes\nalso present many limitations in learning across deep learning applications.\nRecent research is exploring higher-order optimization functions as better\napproaches, but these present very complex computational challenges for\npractical use. Comparing first and higher-order optimization functions, in this\npaper, our experiments reveal that Levemberg-Marquardt (LM) significantly\nsupersedes optimal convergence but suffers from very large processing time\nincreasing the training complexity of both, classification and reinforcement\nlearning problems. Our experiments compare off-the-shelf optimization\nfunctions(CG, SGD, LM and L-BFGS) in standard CIFAR, MNIST, CartPole and\nFlappyBird experiments.The paper presents arguments on which optimization\nfunctions to use and further, which functions would benefit from\nparallelization efforts to improve pretraining time and learning rate\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:36:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ozyildirim", "Buse Melis", ""], ["Kiran", "Mariam", ""]]}, {"id": "2002.12660", "submitter": "Meysam Goodarzi", "authors": "M. Goodarzi, D. Cvetkovski, N. Maletic, J. Gutierrez and E. Grass", "title": "Synchronization in 5G: a Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a hybrid approach to synchronize large scale\nnetworks. In particular, we draw on Kalman Filtering (KF) along with\ntime-stamps generated by the Precision Time Protocol (PTP) for pairwise node\nsynchronization. Furthermore, we investigate the merit of Factor Graphs (FGs)\nalong with Belief Propagation (BP) algorithm in achieving high precision\nend-to-end network synchronization. Finally, we present the idea of dividing\nthe large-scale network into local synchronization domains, for each of which a\nsuitable sync algorithm is utilized. The simulation results indicate that,\ndespite the simplifications in the hybrid approach, the error in the offset\nestimation remains below 5 ns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 11:27:48 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goodarzi", "M.", ""], ["Cvetkovski", "D.", ""], ["Maletic", "N.", ""], ["Gutierrez", "J.", ""], ["Grass", "E.", ""]]}, {"id": "2002.12663", "submitter": "Rui Lin", "authors": "Rui Lin, Ching-Yun Ko, Zhuolun He, Cong Chen, Yuan Cheng, Hao Yu,\n  Graziano Chesi, Ngai Wong", "title": "HOTCAKE: Higher Order Tucker Articulated Kernels for Deeper CNN\n  Compression", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging edge computing has promoted immense interests in compacting a\nneural network without sacrificing much accuracy. In this regard, low-rank\ntensor decomposition constitutes a powerful tool to compress convolutional\nneural networks (CNNs) by decomposing the 4-way kernel tensor into multi-stage\nsmaller ones. Building on top of Tucker-2 decomposition, we propose a\ngeneralized Higher Order Tucker Articulated Kernels (HOTCAKE) scheme comprising\nfour steps: input channel decomposition, guided Tucker rank selection, higher\norder Tucker decomposition and fine-tuning. By subjecting each CONV layer to\nHOTCAKE, a highly compressed CNN model with graceful accuracy trade-off is\nobtained. Experiments show HOTCAKE can compress even pre-compressed models and\nproduce state-of-the-art lightweight networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 11:37:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lin", "Rui", ""], ["Ko", "Ching-Yun", ""], ["He", "Zhuolun", ""], ["Chen", "Cong", ""], ["Cheng", "Yuan", ""], ["Yu", "Hao", ""], ["Chesi", "Graziano", ""], ["Wong", "Ngai", ""]]}, {"id": "2002.12688", "submitter": "Chuan Xu", "authors": "Giovanni Neglia and Chuan Xu and Don Towsley and Gianmarco Calbi", "title": "Decentralized gradient methods: does topology matter?", "comments": "A version of this paper is to appear at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus-based distributed optimization methods have recently been advocated\nas alternatives to parameter server and ring all-reduce paradigms for large\nscale training of machine learning models. In this case, each worker maintains\na local estimate of the optimal parameter vector and iteratively updates it by\naveraging the estimates obtained from its neighbors, and applying a correction\non the basis of its local dataset. While theoretical results suggest that\nworker communication topology should have strong impact on the number of epochs\nneeded to converge, previous experiments have shown the opposite conclusion.\nThis paper sheds lights on this apparent contradiction and show how sparse\ntopologies can lead to faster convergence even in the absence of communication\ndelays.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 12:59:25 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Neglia", "Giovanni", ""], ["Xu", "Chuan", ""], ["Towsley", "Don", ""], ["Calbi", "Gianmarco", ""]]}, {"id": "2002.12718", "submitter": "Sachin Goyal", "authors": "Sachin Goyal, Aditi Raghunathan, Moksh Jain, Harsha Vardhan Simhadri\n  and Prateek Jain", "title": "DROCC: Deep Robust One-Class Classification", "comments": "16 pages, 9 figures, Published at International Conference on Machine\n  Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical approaches for one-class problems such as one-class SVM and\nisolation forest require careful feature engineering when applied to structured\ndomains like images. State-of-the-art methods aim to leverage deep learning to\nlearn appropriate features via two main approaches. The first approach based on\npredicting transformations (Golan & El-Yaniv, 2018; Hendrycks et al., 2019a)\nwhile successful in some domains, crucially depends on an appropriate\ndomain-specific set of transformations that are hard to obtain in general. The\nsecond approach of minimizing a classical one-class loss on the learned final\nlayer representations, e.g., DeepSVDD (Ruff et al., 2018) suffers from the\nfundamental drawback of representation collapse. In this work, we propose Deep\nRobust One-Class Classification (DROCC) that is both applicable to most\nstandard domains without requiring any side-information and robust to\nrepresentation collapse. DROCC is based on the assumption that the points from\nthe class of interest lie on a well-sampled, locally linear low dimensional\nmanifold. Empirical evaluation demonstrates that DROCC is highly effective in\ntwo different one-class problem settings and on a range of real-world datasets\nacross different domains: tabular data, images (CIFAR and ImageNet), audio, and\ntime-series, offering up to 20% increase in accuracy over the state-of-the-art\nin anomaly detection. Code is available at https://github.com/microsoft/EdgeML.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:03:31 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 13:28:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Goyal", "Sachin", ""], ["Raghunathan", "Aditi", ""], ["Jain", "Moksh", ""], ["Simhadri", "Harsha Vardhan", ""], ["Jain", "Prateek", ""]]}, {"id": "2002.12744", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu, Weiping Wang", "title": "Convolutional Spectral Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, non-stationary spectral kernels have drawn much attention, owing to\nits powerful feature representation ability in revealing long-range\ncorrelations and input-dependent characteristics. However, non-stationary\nspectral kernels are still shallow models, thus they are deficient to learn\nboth hierarchical features and local interdependence. In this paper, to obtain\nhierarchical and local knowledge, we build an interpretable convolutional\nspectral kernel network (\\texttt{CSKN}) based on the inverse Fourier transform,\nwhere we introduce deep architectures and convolutional filters into\nnon-stationary spectral kernel representations. Moreover, based on Rademacher\ncomplexity, we derive the generalization error bounds and introduce two\nregularizers to improve the performance. Combining the regularizers and recent\nadvancements on random initialization, we finally complete the learning\nframework of \\texttt{CSKN}. Extensive experiments results on real-world\ndatasets validate the effectiveness of the learning framework and coincide with\nour theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:35:54 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "2002.12755", "submitter": "Chenye Wu", "authors": "Chenbei Lu, Kui Wang, Chenye Wu", "title": "Effective End-to-End Learning Framework for Economic Dispatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom to improve the effectiveness of economic dispatch is to\ndesign the load forecasting method as accurately as possible. However, this\napproach can be problematic due to the temporal and spatial correlations\nbetween system cost and load prediction errors. This motivates us to adopt the\nnotion of end-to-end machine learning and to propose a task-specific learning\ncriteria to conduct economic dispatch. Specifically, to maximize the data\nutilization, we design an efficient optimization kernel for the learning\nprocess. We provide both theoretical analysis and empirical insights to\nhighlight the effectiveness and efficiency of the proposed learning framework.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 08:04:27 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lu", "Chenbei", ""], ["Wang", "Kui", ""], ["Wu", "Chenye", ""]]}, {"id": "2002.12756", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Yan Han, Mason Carnahan", "title": "Speech Synthesis using EEG", "comments": "Accepted for publication at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate speech synthesis using different\nelectroencephalography (EEG) feature sets recently introduced in [1]. We make\nuse of a recurrent neural network (RNN) regression model to predict acoustic\nfeatures directly from EEG features. We demonstrate our results using EEG\nfeatures recorded in parallel with spoken speech as well as using EEG recorded\nin parallel with listening utterances. We provide EEG based speech synthesis\nresults for four subjects in this paper and our results demonstrate the\nfeasibility of synthesizing speech directly from EEG features.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 03:53:45 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:30:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Han", "Yan", ""], ["Carnahan", "Mason", ""]]}, {"id": "2002.12759", "submitter": "Bin Hu", "authors": "Zhenyu Liu, Dongyu Wang, Lan Zhang and Bin Hu", "title": "A Novel Decision Tree for Depression Recognition in Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is a common mental disorder worldwide which causes a range of\nserious outcomes. The diagnosis of depression relies on patient-reported scales\nand psychiatrist interview which may lead to subjective bias. In recent years,\nmore and more researchers are devoted to depression recognition in speech ,\nwhich may be an effective and objective indicator. This study proposes a new\nspeech segment fusion method based on decision tree to improve the depression\nrecognition accuracy and conducts a validation on a sample of 52 subjects (23\ndepressed patients and 29 healthy controls). The recognition accuracy are 75.8%\nand 68.5% for male and female respectively on gender-dependent models. It can\nbe concluded from the data that the proposed decision tree model can improve\nthe depression classification performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:46:38 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liu", "Zhenyu", ""], ["Wang", "Dongyu", ""], ["Zhang", "Lan", ""], ["Hu", "Bin", ""]]}, {"id": "2002.12761", "submitter": "Qingjian Lin", "authors": "Qingjian Lin, Weicheng Cai, Lin Yang, Junjie Wang, Jun Zhang, Ming Li", "title": "DIHARD II is Still Hard: Experimental Results and Discussions from the\n  DKU-LENOVO Team", "comments": "Submitted to Odyssesy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the submitted system for the second DIHARD Speech\nDiarization Challenge from the DKULENOVO team. Our diarization system includes\nmultiple modules, namely voice activity detection (VAD), segmentation, speaker\nembedding extraction, similarity scoring, clustering, resegmentation and\noverlap detection. For each module, we explore different techniques to enhance\nperformance. Our final submission employs the ResNet-LSTM based VAD, the Deep\nResNet based speaker embedding, the LSTM based similarity scoring and spectral\nclustering. Variational Bayes (VB) diarization is applied in the resegmentation\nstage and overlap detection also brings slight improvement. Our proposed system\nachieves 18.84% DER in Track1 and 27.90% DER in Track2. Although our systems\nhave reduced the DERs by 27.5% and 31.7% relatively against the official\nbaselines, we believe that the diarization task is still very difficult.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 11:50:32 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:46:24 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lin", "Qingjian", ""], ["Cai", "Weicheng", ""], ["Yang", "Lin", ""], ["Wang", "Junjie", ""], ["Zhang", "Jun", ""], ["Li", "Ming", ""]]}, {"id": "2002.12764", "submitter": "Joel Shor", "authors": "Joel Shor, Aren Jansen, Ronnie Maor, Oran Lang, Omry Tuval, Felix de\n  Chaumont Quitry, Marco Tagliasacchi, Ira Shavitt, Dotan Emanuel, Yinnon Haviv", "title": "Towards Learning a Universal Non-Semantic Representation of Speech", "comments": null, "journal-ref": "Proceedings of INTERSPEECH 2020", "doi": "10.21437/Interspeech.2020-1242", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ultimate goal of transfer learning is to reduce labeled data requirements\nby exploiting a pre-existing embedding model trained for different datasets or\ntasks. The visual and language communities have established benchmarks to\ncompare embeddings, but the speech community has yet to do so. This paper\nproposes a benchmark for comparing speech representations on non-semantic\ntasks, and proposes a representation based on an unsupervised triplet-loss\nobjective. The proposed representation outperforms other representations on the\nbenchmark, and even exceeds state-of-the-art performance on a number of\ntransfer learning tasks. The embedding is trained on a publicly available\ndataset, and it is tested on a variety of low-resource downstream tasks,\nincluding personalization tasks and medical domain. The benchmark, models, and\nevaluation code are publicly released.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:38:24 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:42:36 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 07:41:51 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 13:46:53 GMT"}, {"version": "v5", "created": "Fri, 19 Jun 2020 06:15:54 GMT"}, {"version": "v6", "created": "Thu, 6 Aug 2020 04:53:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shor", "Joel", ""], ["Jansen", "Aren", ""], ["Maor", "Ronnie", ""], ["Lang", "Oran", ""], ["Tuval", "Omry", ""], ["Quitry", "Felix de Chaumont", ""], ["Tagliasacchi", "Marco", ""], ["Shavitt", "Ira", ""], ["Emanuel", "Dotan", ""], ["Haviv", "Yinnon", ""]]}, {"id": "2002.12789", "submitter": "Chen Liang", "authors": "Chen Liang, Ziqi Liu, Bin Liu, Jun Zhou, Xiaolong Li, Shuang Yang,\n  Yuan Qi", "title": "Uncovering Insurance Fraud Conspiracy with Network Learning", "comments": "Accepted by SIGIR '19. Proceedings of the 42nd International ACM\n  SIGIR Conference on Research and Development in Information Retrieval. 2019", "journal-ref": null, "doi": "10.1145/3331184.3331372", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraudulent claim detection is one of the greatest challenges the insurance\nindustry faces. Alibaba's return-freight insurance, providing return-shipping\npostage compensations over product return on the e-commerce platform, receives\nthousands of potentially fraudulent claims every day. Such deliberate abuse of\nthe insurance policy could lead to heavy financial losses. In order to detect\nand prevent fraudulent insurance claims, we developed a novel data-driven\nprocedure to identify groups of organized fraudsters, one of the major\ncontributions to financial losses, by learning network information. In this\npaper, we introduce a device-sharing network among claimants, followed by\ndeveloping an automated solution for fraud detection based on graph learning\nalgorithms, to separate fraudsters from regular customers and uncover groups of\norganized fraudsters. This solution applied at Alibaba achieves more than 80%\nprecision while covering 44% more suspicious accounts compared with a\npreviously deployed rule-based classifier after human expert investigations.\nOur approach can easily and effectively generalizes to other types of\ninsurance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:15:30 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liang", "Chen", ""], ["Liu", "Ziqi", ""], ["Liu", "Bin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""]]}, {"id": "2002.12794", "submitter": "Mohammad Nikzad", "authors": "Mohammad Nikzad, Aaron Nicolson, Yongsheng Gao, Jun Zhou, Kuldip K.\n  Paliwal, Fanhua Shang", "title": "Deep Residual-Dense Lattice Network for Speech Enhancement", "comments": "8 pages, Accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) with residual links (ResNets) and causal\ndilated convolutional units have been the network of choice for deep learning\napproaches to speech enhancement. While residual links improve gradient flow\nduring training, feature diminution of shallow layer outputs can occur due to\nrepetitive summations with deeper layer outputs. One strategy to improve\nfeature re-usage is to fuse both ResNets and densely connected CNNs\n(DenseNets). DenseNets, however, over-allocate parameters for feature re-usage.\nMotivated by this, we propose the residual-dense lattice network (RDL-Net),\nwhich is a new CNN for speech enhancement that employs both residual and dense\naggregations without over-allocating parameters for feature re-usage. This is\nmanaged through the topology of the RDL blocks, which limit the number of\noutputs used for dense aggregations. Our extensive experimental investigation\nshows that RDL-Nets are able to achieve a higher speech enhancement performance\nthan CNNs that employ residual and/or dense aggregations. RDL-Nets also use\nsubstantially fewer parameters and have a lower computational requirement.\nFurthermore, we demonstrate that RDL-Nets outperform many state-of-the-art deep\nlearning approaches to speech enhancement.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:36:30 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Nikzad", "Mohammad", ""], ["Nicolson", "Aaron", ""], ["Gao", "Yongsheng", ""], ["Zhou", "Jun", ""], ["Paliwal", "Kuldip K.", ""], ["Shang", "Fanhua", ""]]}, {"id": "2002.12795", "submitter": "Hossein Valavi", "authors": "Hossein Valavi, Sulin Liu and Peter J. Ramadge", "title": "The Landscape of Matrix Factorization Revisited", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the landscape of the simple matrix factorization problem. For\nlow-rank matrix factorization, prior work has shown that there exist infinitely\nmany critical points all of which are either global minima or strict saddles.\nAt a strict saddle the minimum eigenvalue of the Hessian is negative. Of\ninterest is whether this minimum eigenvalue is uniformly bounded below zero\nover all strict saddles. To answer this we consider orbits of critical points\nunder the general linear group. For each orbit we identify a representative\npoint, called a canonical point. If a canonical point is a strict saddle, so is\nevery point on its orbit. We derive an expression for the minimum eigenvalue of\nthe Hessian at each canonical strict saddle and use this to show that the\nminimum eigenvalue of the Hessian over the set of strict saddles is not\nuniformly bounded below zero. We also show that a known invariance property of\ngradient flow ensures the solution of gradient flow only encounters critical\npoints on an invariant manifold $\\mathcal{M}_C$ determined by the initial\ncondition. We show that, in contrast to the general situation, the minimum\neigenvalue of strict saddles in $\\mathcal{M}_{0}$ is uniformly bounded below\nzero. We obtain an expression for this bound in terms of the singular values of\nthe matrix being factorized. This bound depends on the size of the nonzero\nsingular values and on the separation between distinct nonzero singular values\nof the matrix.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:27:22 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 21:47:17 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Valavi", "Hossein", ""], ["Liu", "Sulin", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2002.12815", "submitter": "Deepak Nathani", "authors": "Jatin Chauhan, Deepak Nathani, Manohar Kaul", "title": "Few-Shot Learning on Graphs via Super-Classes based on Graph Spectral\n  Measures", "comments": "19 pages, 9 figures, Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to study the problem of few shot graph classification in graph\nneural networks (GNNs) to recognize unseen classes, given limited labeled graph\nexamples. Despite several interesting GNN variants being proposed recently for\nnode and graph classification tasks, when faced with scarce labeled examples in\nthe few shot setting, these GNNs exhibit significant loss in classification\nperformance. Here, we present an approach where a probability measure is\nassigned to each graph based on the spectrum of the graphs normalized\nLaplacian. This enables us to accordingly cluster the graph base labels\nassociated with each graph into super classes, where the Lp Wasserstein\ndistance serves as our underlying distance metric. Subsequently, a super graph\nconstructed based on the super classes is then fed to our proposed GNN\nframework which exploits the latent inter class relationships made explicit by\nthe super graph to achieve better class label separation among the graphs. We\nconduct exhaustive empirical evaluations of our proposed method and show that\nit outperforms both the adaptation of state of the art graph classification\nmethods to few shot scenario and our naive baseline GNNs. Additionally, we also\nextend and study the behavior of our method to semi supervised and active\nlearning scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:11:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chauhan", "Jatin", ""], ["Nathani", "Deepak", ""], ["Kaul", "Manohar", ""]]}, {"id": "2002.12826", "submitter": "Marco Podda", "authors": "Marco Podda, Davide Bacciu, Alessio Micheli", "title": "A Deep Generative Model for Fragment-Based Molecule Generation", "comments": null, "journal-ref": "PMLR 108:2240-2250 (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule generation is a challenging open problem in cheminformatics.\nCurrently, deep generative approaches addressing the challenge belong to two\nbroad categories, differing in how molecules are represented. One approach\nencodes molecular graphs as strings of text, and learns their corresponding\ncharacter-based language model. Another, more expressive, approach operates\ndirectly on the molecular graph. In this work, we address two limitations of\nthe former: generation of invalid and duplicate molecules. To improve validity\nrates, we develop a language model for small molecular substructures called\nfragments, loosely inspired by the well-known paradigm of Fragment-Based Drug\nDesign. In other words, we generate molecules fragment by fragment, instead of\natom by atom. To improve uniqueness rates, we present a frequency-based masking\nstrategy that helps generate molecules with infrequent fragments. We show\nexperimentally that our model largely outperforms other language model-based\ncompetitors, reaching state-of-the-art performances typical of graph-based\napproaches. Moreover, generated molecules display molecular properties similar\nto those in the training sample, even in absence of explicit task-specific\nsupervision.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 15:55:11 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Podda", "Marco", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "2002.12860", "submitter": "Saiteja Utpala", "authors": "Saiteja Utpala and Piyush Rai", "title": "Quantile Regularization: Towards Implicit Calibration of Regression\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that most deep learning models are often poorly\ncalibrated, i.e., they may produce overconfident predictions that are wrong. It\nis therefore desirable to have models that produce predictive uncertainty\nestimates that are reliable. Several approaches have been proposed recently to\ncalibrate classification models. However, there is relatively little work on\ncalibrating regression models. We present a method for calibrating regression\nmodels based on a novel quantile regularizer defined as the cumulative KL\ndivergence between two CDFs. Unlike most of the existing approaches for\ncalibrating regression models, which are based on post-hoc processing of the\nmodel's output and require an additional dataset, our method is trainable in an\nend-to-end fashion without requiring an additional dataset. The proposed\nregularizer can be used with any training objective for regression. We also\nshow that post-hoc calibration methods like Isotonic Calibration sometimes\ncompound miscalibration whereas our method provides consistently better\ncalibrations. We provide empirical results demonstrating that the proposed\nquantile regularizer significantly improves calibration for regression models\ntrained using approaches, such as Dropout VI and Deep Ensembles.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 16:53:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Utpala", "Saiteja", ""], ["Rai", "Piyush", ""]]}, {"id": "2002.12873", "submitter": "Praneeth Narayanamurthy", "authors": "Praneeth Narayanamurthy, Namrata Vaswani, Aditya Ramamoorthy", "title": "Federated Over-Air Subspace Tracking from Incomplete and Corrupted Data", "comments": "New model, algorithm for centralized case; added algorithms to deal\n  with sparse outliers; modified organization significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NA math.IT math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace tracking (ST) with missing data (ST-miss) or outliers (Robust ST) or\nboth (Robust ST-miss) has been extensively studied in the last many years. This\nwork provides a new simple algorithm and guarantee for both ST with missing\ndata (ST-miss) and RST-miss. Unlike past work on this topic, the algorithm is\nmuch simpler (uses fewer parameters) and the guarantee does not make the\nartificial assumption of piecewise constant subspace change, although it still\nhandles that setting. Secondly, we extend our approach and its analysis to\nprovably solving these problems when the raw data is federated and when the\nover-air data communication modality is used for information exchange between\nthe $K$ peer nodes and the center.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:17:01 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 21:51:57 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 16:22:16 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Narayanamurthy", "Praneeth", ""], ["Vaswani", "Namrata", ""], ["Ramamoorthy", "Aditya", ""]]}, {"id": "2002.12880", "submitter": "Andrew Wilson", "authors": "Marc Finzi, Samuel Stanton, Pavel Izmailov, Andrew Gordon Wilson", "title": "Generalizing Convolutional Neural Networks for Equivariance to Lie\n  Groups on Arbitrary Continuous Data", "comments": "ICML 2020. Code available at https://github.com/mfinzi/LieConv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The translation equivariance of convolutional layers enables convolutional\nneural networks to generalize well on image problems. While translation\nequivariance provides a powerful inductive bias for images, we often\nadditionally desire equivariance to other transformations, such as rotations,\nespecially for non-image data. We propose a general method to construct a\nconvolutional layer that is equivariant to transformations from any specified\nLie group with a surjective exponential map. Incorporating equivariance to a\nnew group requires implementing only the group exponential and logarithm maps,\nenabling rapid prototyping. Showcasing the simplicity and generality of our\nmethod, we apply the same model architecture to images, ball-and-stick\nmolecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the\nequivariance of our models is especially impactful, leading to exact\nconservation of linear and angular momentum.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:40:38 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 11:50:51 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 15:08:36 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Finzi", "Marc", ""], ["Stanton", "Samuel", ""], ["Izmailov", "Pavel", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2002.12899", "submitter": "Paul Fergus Dr", "authors": "P. Fergus, C. Chalmers", "title": "BMI: A Behavior Measurement Indicator for Fuel Poverty Using Aggregated\n  Load Readings from Smart Meters", "comments": "33 Pages, 12 Figures, Submitted as a book chapter to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuel poverty affects between 50 and 125 million households in Europe and is a\nsignificant issue for both developed and developing countries globally. This\nmeans that fuel poor residents are unable to adequately warm their home and run\nthe necessary energy services needed for lighting, cooking, hot water, and\nelectrical appliances. The problem is complex but is typically caused by three\nfactors; low income, high energy costs, and energy inefficient homes. In the\nUnited Kingdom (UK), 4 million families are currently living in fuel poverty.\nThose in series financial difficulty are either forced to self-disconnect or\nhave their services terminated by energy providers. Fuel poverty contributed to\n10,000 reported deaths in England in the winter of 2016-2107 due to homes being\ncold. While it is recognized by governments as a social, public health and\nenvironmental policy issue, the European Union (EU) has failed to provide a\ncommon definition of fuel poverty or a conventional set of indicators to\nmeasure it. This chapter discusses current fuel poverty strategies across the\nEU and proposes a new and foundational behavior measurement indicator designed\nto directly assess and monitor fuel poverty risks in households using smart\nmeters, Consumer Access Device (CAD) data and machine learning. By detecting\nActivities of Daily Living (ADLS) through household appliance usage, it is\npossible to spot the early signs of financial difficulty and identify when\nsupport packages are required.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:03:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Fergus", "P.", ""], ["Chalmers", "C.", ""]]}, {"id": "2002.12903", "submitter": "Michael Celentano", "authors": "Michael Celentano, Andrea Montanari, Yuchen Wu", "title": "The estimation error of general first order methods", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern large-scale statistical models require to estimate thousands to\nmillions of parameters. This is often accomplished by iterative algorithms such\nas gradient descent, projected gradient descent or their accelerated versions.\nWhat are the fundamental limits to these approaches? This question is well\nunderstood from an optimization viewpoint when the underlying objective is\nconvex. Work in this area characterizes the gap to global optimality as a\nfunction of the number of iterations. However, these results have only indirect\nimplications in terms of the gap to statistical optimality.\n  Here we consider two families of high-dimensional estimation problems:\nhigh-dimensional regression and low-rank matrix estimation, and introduce a\nclass of `general first order methods' that aim at efficiently estimating the\nunderlying parameters. This class of algorithms is broad enough to include\nclassical first order optimization (for convex and non-convex objectives), but\nalso other types of algorithms. Under a random design assumption, we derive\nlower bounds on the estimation error that hold in the high-dimensional\nasymptotics in which both the number of observations and the number of\nparameters diverge. These lower bounds are optimal in the sense that there\nexist algorithms whose estimation error matches the lower bounds up to\nasymptotically negligible terms. We illustrate our general results through\napplications to sparse phase retrieval and sparse principal component analysis.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:13:47 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 17:44:58 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Celentano", "Michael", ""], ["Montanari", "Andrea", ""], ["Wu", "Yuchen", ""]]}, {"id": "2002.12911", "submitter": "Krishna Reddy Kesari", "authors": "Krishna Reddy Kesari and Jean Honorio", "title": "First Order Methods take Exponential Time to Converge to Global\n  Minimizers of Non-Convex Functions", "comments": null, "journal-ref": "IEEE International Symposium on Information Theory (ISIT), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms typically perform optimization over a class of\nnon-convex functions. In this work, we provide bounds on the fundamental\nhardness of identifying the global minimizer of a non convex function.\nSpecifically, we design a family of parametrized non-convex functions and\nemploy statistical lower bounds for parameter estimation. We show that the\nparameter estimation problem is equivalent to the problem of function\nidentification in the given family. We then claim that non convex optimization\nis at least as hard as function identification. Jointly, we prove that any\nfirst order method can take exponential time to converge to a global minimizer.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:28:43 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 04:04:06 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kesari", "Krishna Reddy", ""], ["Honorio", "Jean", ""]]}, {"id": "2002.12915", "submitter": "Colin Wei", "authors": "Colin Wei, Sham Kakade, Tengyu Ma", "title": "The Implicit and Explicit Regularization Effects of Dropout", "comments": "Published in ICML 2020. Code available at\n  https://github.com/cwein3/dropout-analytical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a widely-used regularization technique, often required to obtain\nstate-of-the-art for a number of architectures. This work demonstrates that\ndropout introduces two distinct but entangled regularization effects: an\nexplicit effect (also studied in prior work) which occurs since dropout\nmodifies the expected training objective, and, perhaps surprisingly, an\nadditional implicit effect from the stochasticity in the dropout training\nupdate. This implicit regularization effect is analogous to the effect of\nstochasticity in small mini-batch stochastic gradient descent. We disentangle\nthese two effects through controlled experiments. We then derive analytic\nsimplifications which characterize each effect in terms of the derivatives of\nthe model and the loss, for deep neural networks. We demonstrate these\nsimplified, analytic regularizers accurately capture the important aspects of\ndropout, showing they faithfully replace dropout in practice.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:31:17 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 02:18:05 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 07:44:22 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wei", "Colin", ""], ["Kakade", "Sham", ""], ["Ma", "Tengyu", ""]]}, {"id": "2002.12920", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie\n  Huang, Bhavya Kailkhura, Xue Lin, Cho-Jui Hsieh", "title": "Automatic Perturbation Analysis for Scalable Certified Robustness and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear relaxation based perturbation analysis (LiRPA) for neural networks,\nwhich computes provable linear bounds of output neurons given a certain amount\nof input perturbation, has become a core component in robustness verification\nand certified defense. The majority of LiRPA-based methods focus on simple\nfeed-forward networks and need particular manual derivations and\nimplementations when extended to other architectures. In this paper, we develop\nan automatic framework to enable perturbation analysis on any neural network\nstructures, by generalizing existing LiRPA algorithms such as CROWN to operate\non general computational graphs. The flexibility, differentiability and ease of\nuse of our framework allow us to obtain state-of-the-art results on LiRPA based\ncertified defense on fairly complicated networks like DenseNet, ResNeXt and\nTransformer that are not supported by prior works. Our framework also enables\nloss fusion, a technique that significantly reduces the computational\ncomplexity of LiRPA for certified defense. For the first time, we demonstrate\nLiRPA based certified defense on Tiny ImageNet and Downscaled ImageNet where\nprevious approaches cannot scale to due to the relatively large number of\nclasses. Our work also yields an open-source library for the community to apply\nLiRPA to areas beyond certified defense without much LiRPA expertise, e.g., we\ncreate a neural network with a probably flat optimization landscape by applying\nLiRPA to network parameters. Our opensource library is available at\nhttps://github.com/KaidiXu/auto_LiRPA.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:47:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 17:43:48 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 03:26:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Kaidi", ""], ["Shi", "Zhouxing", ""], ["Zhang", "Huan", ""], ["Wang", "Yihan", ""], ["Chang", "Kai-Wei", ""], ["Huang", "Minlie", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.12921", "submitter": "Stefano Carrazza", "authors": "Stefano Carrazza and Juan M. Cruz-Martinez", "title": "VegasFlow: accelerating Monte Carlo simulation across multiple hardware\n  platforms", "comments": "6 pages, 5 figures, final version published in CPC", "journal-ref": null, "doi": "10.1016/j.cpc.2020.107376", "report-no": "TIF-UNIMI-2020-8", "categories": "physics.comp-ph hep-ex hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VegasFlow, a new software for fast evaluation of high dimensional\nintegrals based on Monte Carlo integration techniques designed for platforms\nwith hardware accelerators. The growing complexity of calculations and\nsimulations in many areas of science have been accompanied by advances in the\ncomputational tools which have helped their developments. VegasFlow enables\ndevelopers to delegate all complicated aspects of hardware or platform\nimplementation to the library so they can focus on the problem at hand. This\nsoftware is inspired on the Vegas algorithm, ubiquitous in the particle physics\ncommunity as the driver of cross section integration, and based on Google's\npowerful TensorFlow library. We benchmark the performance of this library on\nmany different consumer and professional grade GPUs and CPUs.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:48:16 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 10:52:37 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Carrazza", "Stefano", ""], ["Cruz-Martinez", "Juan M.", ""]]}, {"id": "2002.12928", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Zhongwen Xu, Vivek Veeriah, Matteo Hessel, Junhyuk Oh,\n  Hado van Hasselt, David Silver and Satinder Singh", "title": "A Self-Tuning Actor-Critic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms are highly sensitive to the choice of\nhyperparameters, typically requiring significant manual effort to identify\nhyperparameters that perform well on a new domain. In this paper, we take a\nstep towards addressing this issue by using metagradients to automatically\nadapt hyperparameters online by meta-gradient descent (Xu et al., 2018). We\napply our algorithm, Self-Tuning Actor-Critic (STAC), to self-tune all the\ndifferentiable hyperparameters of an actor-critic loss function, to discover\nauxiliary tasks, and to improve off-policy learning using a novel leaky V-trace\noperator. STAC is simple to use, sample efficient and does not require a\nsignificant increase in compute. Ablative studies show that the overall\nperformance of STAC improved as we adapt more hyperparameters. When applied to\nthe Arcade Learning Environment (Bellemare et al. 2012), STAC improved the\nmedian human normalized score in 200M steps from 243% to 364%. When applied to\nthe DM Control suite (Tassa et al., 2018), STAC improved the mean score in 30M\nsteps from 217 to 389 when learning with features, from 108 to 202 when\nlearning from pixels, and from 195 to 295 in the Real-World Reinforcement\nLearning Challenge (Dulac-Arnold et al., 2020).\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:55:38 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 13:30:26 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 15:59:58 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 14:41:37 GMT"}, {"version": "v5", "created": "Wed, 14 Apr 2021 08:43:34 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zahavy", "Tom", ""], ["Xu", "Zhongwen", ""], ["Veeriah", "Vivek", ""], ["Hessel", "Matteo", ""], ["Oh", "Junhyuk", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}]