[{"id": "1301.0015", "submitter": "Tony Jebara", "authors": "Adrian Weller and Tony Jebara", "title": "Bethe Bounds and Approximating the Global Optimum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in general Markov random fields (MRFs) is NP-hard, though\nidentifying the maximum a posteriori (MAP) configuration of pairwise MRFs with\nsubmodular cost functions is efficiently solvable using graph cuts. Marginal\ninference, however, even for this restricted class, is in #P. We prove new\nformulations of derivatives of the Bethe free energy, provide bounds on the\nderivatives and bracket the locations of stationary points, introducing a new\ntechnique called Bethe bound propagation. Several results apply to pairwise\nmodels whether associative or not. Applying these to discretized\npseudo-marginals in the associative case we present a polynomial time\napproximation scheme for global optimization provided the maximum degree is\n$O(\\log n)$, and discuss several extensions.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 21:07:21 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Weller", "Adrian", ""], ["Jebara", "Tony", ""]]}, {"id": "1301.0104", "submitter": "Aviv Tamar", "authors": "Aviv Tamar, Dotan Di Castro, Shie Mannor", "title": "Policy Evaluation with Variance Related Risk Criteria in Markov Decision\n  Processes", "comments": null, "journal-ref": "JMLR Workshop and Conference Proceedings 28 (3): 495-503, 2013", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend temporal difference policy evaluation algorithms to\nperformance criteria that include the variance of the cumulative reward. Such\ncriteria are useful for risk management, and are important in domains such as\nfinance and process control. We propose both TD(0) and LSTD(lambda) variants\nwith linear function approximation, prove their convergence, and demonstrate\ntheir utility in a 4-dimensional continuous state space problem.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 16:25:17 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Tamar", "Aviv", ""], ["Di Castro", "Dotan", ""], ["Mannor", "Shie", ""]]}, {"id": "1301.0142", "submitter": "David Lopez Paz", "authors": "David Lopez-Paz, Jos\\'e Miguel Hern\\'andez-Lobato, Bernhard\n  Sch\\\"olkopf", "title": "Semi-Supervised Domain Adaptation with Non-Parametric Copulas", "comments": "9 pages, Appearing on Advances in Neural Information Processing\n  Systems 25", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new framework based on the theory of copulas is proposed to address semi-\nsupervised domain adaptation problems. The presented method factorizes any\nmultivariate density into a product of marginal distributions and bivariate\ncop- ula functions. Therefore, changes in each of these factors can be detected\nand corrected to adapt a density model accross different learning domains.\nImpor- tantly, we introduce a novel vine copula model, which allows for this\nfactorization in a non-parametric manner. Experimental results on regression\nproblems with real-world data illustrate the efficacy of the proposed approach\nwhen compared to state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 22:52:22 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Lopez-Paz", "David", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1301.0264", "submitter": "Claudia Beleites", "authors": "Claudia Beleites, Reiner Salzer, and Valter Sergo", "title": "Validation of Soft Classification Models using Partial Class\n  Memberships: An Extended Concept of Sensitivity & Co. applied to the Grading\n  of Astrocytoma Tissues", "comments": "The manuscript is accepted for publication in Chemometrics and\n  Intelligent Laboratory Systems. Supplementary figures and tables are at the\n  end of the pdf", "journal-ref": "Chemometrics and Intelligent Laboratory Systems, 122 (2013), 12 -\n  22", "doi": "10.1016/j.chemolab.2012.12.003", "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use partial class memberships in soft classification to model uncertain\nlabelling and mixtures of classes. Partial class memberships are not restricted\nto predictions, but may also occur in reference labels (ground truth, gold\nstandard diagnosis) for training and validation data.\n  Classifier performance is usually expressed as fractions of the confusion\nmatrix, such as sensitivity, specificity, negative and positive predictive\nvalues. We extend this concept to soft classification and discuss the bias and\nvariance properties of the extended performance measures. Ambiguity in\nreference labels translates to differences between best-case, expected and\nworst-case performance. We show a second set of measures comparing expected and\nideal performance which is closely related to regression performance, namely\nthe root mean squared error RMSE and the mean absolute error MAE.\n  All calculations apply to classical crisp classification as well as to soft\nclassification (partial class memberships and/or one-class classifiers). The\nproposed performance measures allow to test classifiers with actual borderline\ncases. In addition, hardening of e.g. posterior probabilities into class labels\nis not necessary, avoiding the corresponding information loss and increase in\nvariance.\n  We implement the proposed performance measures in the R package\n\"softclassval\", which is available from CRAN and at\nhttp://softclassval.r-forge.r-project.org.\n  Our reasoning as well as the importance of partial memberships for\nchemometric classification is illustrated by a real-word application:\nastrocytoma brain tumor tissue grading (80 patients, 37000 spectra) for finding\nsurgical excision borders. As borderline cases are the actual target of the\nanalytical technique, samples which are diagnosed to be borderline cases must\nbe included in the validation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 17:03:58 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2013 15:44:47 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Beleites", "Claudia", ""], ["Salzer", "Reiner", ""], ["Sergo", "Valter", ""]]}, {"id": "1301.0289", "submitter": "Aaditya Prakash", "authors": "Aaditya Prakash", "title": "Reconstructing Self Organizing Maps as Spider Graphs for better visual\n  interpretation of large unstructured datasets", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Self-Organizing Maps (SOM) are popular unsupervised artificial neural network\nused to reduce dimensions and visualize data. Visual interpretation from\nSelf-Organizing Maps (SOM) has been limited due to grid approach of data\nrepresentation, which makes inter-scenario analysis impossible. The paper\nproposes a new way to structure SOM. This model reconstructs SOM to show\nstrength between variables as the threads of a cobweb and illuminate\ninter-scenario analysis. While Radar Graphs are very crude representation of\nspider web, this model uses more lively and realistic cobweb representation to\ntake into account the difference in strength and length of threads. This model\nallows for visualization of highly unstructured dataset with large number of\ndimensions, common in Bigdata sources.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 17:10:28 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Prakash", "Aaditya", ""]]}, {"id": "1301.0339", "submitter": "Yuanchang Sun", "authors": "P. Yin, Y. Sun, and J. Xin", "title": "A Geometric Blind Source Separation Method Based on Facet Component\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Given a set of mixtures, blind source separation attempts to retrieve the\nsource signals without or with very little information of the the mixing\nprocess. We present a geometric approach for blind separation of nonnegative\nlinear mixtures termed {\\em facet component analysis} (FCA). The approach is\nbased on facet identification of the underlying cone structure of the data.\nEarlier works focus on recovering the cone by locating its vertices (vertex\ncomponent analysis or VCA) based on a mutual sparsity condition which requires\neach source signal to possess a stand-alone peak in its spectrum. We formulate\nalternative conditions so that enough data points fall on the facets of a cone\ninstead of accumulating around the vertices. To find a regime of unique\nsolvability, we make use of both geometric and density properties of the data\npoints, and develop an efficient facet identification method by combining data\nclassification and linear regression. For noisy data, we show that denoising\nmethods may be employed, such as the total variation technique in imaging\nprocessing, and principle component analysis. We show computational results on\nnuclear magnetic resonance spectroscopic data to substantiate our method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 21:58:03 GMT"}], "update_date": "2013-01-04", "authors_parsed": [["Yin", "P.", ""], ["Sun", "Y.", ""], ["Xin", "J.", ""]]}, {"id": "1301.0413", "submitter": "Ernie Esser", "authors": "Ernie Esser, Yifei Lou, Jack Xin", "title": "A Method for Finding Structured Sparse Solutions to Non-negative Least\n  Squares Problems with Applications", "comments": "38 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demixing problems in many areas such as hyperspectral imaging and\ndifferential optical absorption spectroscopy (DOAS) often require finding\nsparse nonnegative linear combinations of dictionary elements that match\nobserved data. We show how aspects of these problems, such as misalignment of\nDOAS references and uncertainty in hyperspectral endmembers, can be modeled by\nexpanding the dictionary with grouped elements and imposing a structured\nsparsity assumption that the combinations within each group should be sparse or\neven 1-sparse. If the dictionary is highly coherent, it is difficult to obtain\ngood solutions using convex or greedy methods, such as non-negative least\nsquares (NNLS) or orthogonal matching pursuit. We use penalties related to the\nHoyer measure, which is the ratio of the $l_1$ and $l_2$ norms, as sparsity\npenalties to be added to the objective in NNLS-type models. For solving the\nresulting nonconvex models, we propose a scaled gradient projection algorithm\nthat requires solving a sequence of strongly convex quadratic programs. We\ndiscuss its close connections to convex splitting methods and difference of\nconvex programming. We also present promising numerical results for example\nDOAS analysis and hyperspectral demixing problems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 10:09:41 GMT"}], "update_date": "2013-01-04", "authors_parsed": [["Esser", "Ernie", ""], ["Lou", "Yifei", ""], ["Xin", "Jack", ""]]}, {"id": "1301.0534", "submitter": "Peter Gr\\\"unwald", "authors": "Steven de Rooij, Tim van Erven, Peter D. Gr\\\"unwald, Wouter M. Koolen", "title": "Follow the Leader If You Can, Hedge If You Must", "comments": "under submission", "journal-ref": "Journal of Machine Learning Research, vol 15, p. 1281-1316, 2014", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Follow-the-Leader (FTL) is an intuitive sequential prediction strategy that\nguarantees constant regret in the stochastic setting, but has terrible\nperformance for worst-case data. Other hedging strategies have better\nworst-case guarantees but may perform much worse than FTL if the data are not\nmaximally adversarial. We introduce the FlipFlop algorithm, which is the first\nmethod that provably combines the best of both worlds.\n  As part of our construction, we develop AdaHedge, which is a new way of\ndynamically tuning the learning rate in Hedge without using the doubling trick.\nAdaHedge refines a method by Cesa-Bianchi, Mansour and Stoltz (2007), yielding\nslightly improved worst-case guarantees. By interleaving AdaHedge and FTL, the\nFlipFlop algorithm achieves regret within a constant factor of the FTL regret,\nwithout sacrificing AdaHedge's worst-case guarantees.\n  AdaHedge and FlipFlop do not need to know the range of the losses in advance;\nmoreover, unlike earlier methods, both have the intuitive property that the\nissued weights are invariant under rescaling and translation of the losses. The\nlosses are also allowed to be negative, in which case they may be interpreted\nas gains.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 19:49:14 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 10:03:03 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["de Rooij", "Steven", ""], ["van Erven", "Tim", ""], ["Gr\u00fcnwald", "Peter D.", ""], ["Koolen", "Wouter M.", ""]]}, {"id": "1301.0551", "submitter": "Dragomir Anguelov", "authors": "Dragomir Anguelov, Rahul Biswas, Daphne Koller, Benson Limketkai,\n  Sebastian Thrun", "title": "Learning Hierarchical Object Maps Of Non-Stationary Environments with\n  mobile robots", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-10-17", "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building models, or maps, of robot environments is a highly active research\narea; however, most existing techniques construct unstructured maps and assume\nstatic environments. In this paper, we present an algorithm for learning object\nmodels of non-stationary objects found in office-type environments. Our\nalgorithm exploits the fact that many objects found in office environments look\nalike (e.g., chairs, recycling bins). It does so through a two-level\nhierarchical representation, which links individual objects with generic shape\ntemplates of object classes. We derive an approximate EM algorithm for learning\nshape parameters at both levels of the hierarchy, using local occupancy grid\nmaps for representing shape. Additionally, we develop a Bayesian model\nselection algorithm that enables the robot to estimate the total number of\nobjects and object templates in the environment. Experimental results using a\nreal robot equipped with a laser range finder indicate that our approach\nperforms well at learning object-based maps of simple office environments. The\napproach outperforms a previously developed non-hierarchical algorithm that\nmodels objects but lacks class templates.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:05 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Anguelov", "Dragomir", ""], ["Biswas", "Rahul", ""], ["Koller", "Daphne", ""], ["Limketkai", "Benson", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1301.0554", "submitter": "Francis R. Bach", "authors": "Francis R. Bach, Michael I. Jordan", "title": "Tree-dependent Component Analysis", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-36-44", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generalization of independent component analysis (ICA), where\ninstead of looking for a linear transform that makes the data components\nindependent, we look for a transform that makes the data components well fit by\na tree-structured graphical model. Treating the problem as a semiparametric\nstatistical problem, we show that the optimal transform is found by minimizing\na contrast function based on mutual information, a function that directly\nextends the contrast function used for classical ICA. We provide two\napproximations of this contrast function, one using kernel density estimation,\nand another using kernel generalized variance. This tree-dependent component\nanalysis framework leads naturally to an efficient general multivariate density\nestimation technique where only bivariate density estimation needs to be\nperformed.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:17 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Bach", "Francis R.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.0556", "submitter": "David Blei", "authors": "David Blei, J Andrew Bagnell, Andrew McCallum", "title": "Learning with Scope, with Application to Information Extraction and\n  Classification", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-53-60", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In probabilistic approaches to classification and information extraction, one\ntypically builds a statistical model of words under the assumption that future\ndata will exhibit the same regularities as the training data. In many data\nsets, however, there are scope-limited features whose predictive power is only\napplicable to a certain subset of the data. For example, in information\nextraction from web pages, word formatting may be indicative of extraction\ncategory in different ways on different web pages. The difficulty with using\nsuch features is capturing and exploiting the new regularities encountered in\npreviously unseen data. In this paper, we propose a hierarchical probabilistic\nmodel that uses both local/scope-limited features, such as word formatting, and\nglobal features, such as word content. The local regularities are modeled as an\nunobserved random parameter which is drawn once for each local data set. This\nrandom parameter is estimated during the inference process and then used to\nperform classification with both the local and global features--- a procedure\nwhich is akin to automatically retuning the classifier to the local\nregularities on each newly encountered web page. Exact inference is intractable\nand we present approximations via point estimates and variational methods.\nEmpirical results on large collections of web data demonstrate that this method\nsignificantly improves performance from traditional models of global features\nalone.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:25 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Blei", "David", ""], ["Bagnell", "J Andrew", ""], ["McCallum", "Andrew", ""]]}, {"id": "1301.0562", "submitter": "Adrian Corduneanu", "authors": "Adrian Corduneanu, Tommi S. Jaakkola", "title": "Continuation Methods for Mixing Heterogenous Sources", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-111-118", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of modern learning tasks involve estimation from heterogeneous\ninformation sources. This includes classification with labeled and unlabeled\ndata as well as other problems with analogous structure such as competitive\n(game theoretic) problems. The associated estimation problems can be typically\nreduced to solving a set of fixed point equations (consistency conditions). We\nintroduce a general method for combining a preferred information source with\nanother in this setting by evolving continuous paths of fixed points at\nintermediate allocations. We explicitly identify critical points along the\nunique paths to either increase the stability of estimation or to ensure a\nsignificant departure from the initial source. The homotopy continuation\napproach is guaranteed to terminate at the second source, and involves no\ncombinatorial effort. We illustrate the power of these ideas both in\nclassification tasks with labeled and unlabeled data, as well as in the context\nof a competitive (min-max) formulation of DNA sequence motif discovery.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:50 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Corduneanu", "Adrian", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.0563", "submitter": "Scott Davies", "authors": "Scott Davies, Andrew Moore", "title": "Interpolating Conditional Density Trees", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-119-127", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint distributions over many variables are frequently modeled by decomposing\nthem into products of simpler, lower-dimensional conditional distributions,\nsuch as in sparsely connected Bayesian networks. However, automatically\nlearning such models can be very computationally expensive when there are many\ndatapoints and many continuous variables with complex nonlinear relationships,\nparticularly when no good ways of decomposing the joint distribution are known\na priori. In such situations, previous research has generally focused on the\nuse of discretization techniques in which each continuous variable has a single\ndiscretization that is used throughout the entire network. \\ In this paper, we\npresent and compare a wide variety of tree-based algorithms for learning and\nevaluating conditional density estimates over continuous variables. These trees\ncan be thought of as discretizations that vary according to the particular\ninteractions being modeled; however, the density within a given leaf of the\ntree need not be assumed constant, and we show that such nonuniform leaf\ndensities lead to more accurate density estimation. We have developed Bayesian\nnetwork structure-learning algorithms that employ these tree-based conditional\ndensity representations, and we show that they can be used to practically learn\ncomplex joint probability models over dozens of continuous variables from\nthousands of datapoints. We focus on finding models that are simultaneously\naccurate, fast to learn, and fast to evaluate once they are learned.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Davies", "Scott", ""], ["Moore", "Andrew", ""]]}, {"id": "1301.0565", "submitter": "Byron E Dom", "authors": "Byron E Dom", "title": "An Information-Theoretic External Cluster-Validity Measure", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-137-145", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a measure of clustering quality or accuracy that is\nappropriate in situations where it is desirable to evaluate a clustering\nalgorithm by somehow comparing the clusters it produces with ``ground truth'\nconsisting of classes assigned to the patterns by manual means or some other\nmeans in whose veracity there is confidence. Such measures are refered to as\n``external'. Our measure also has the characteristic of allowing clusterings\nwith different numbers of clusters to be compared in a quantitative and\nprincipled way. Our evaluation scheme quantitatively measures how useful the\ncluster labels of the patterns are as predictors of their class labels. In\ncases where all clusterings to be compared have the same number of clusters,\nthe measure is equivalent to the mutual information between the cluster labels\nand the class labels. In cases where the numbers of clusters are different,\nhowever, it computes the reduction in the number of bits that would be required\nto encode (compress) the class labels if both the encoder and decoder have free\nacccess to the cluster labels. To achieve this encoding the estimated\nconditional probabilities of the class labels given the cluster labels must\nalso be encoded. These estimated probabilities can be seen as a model for the\nclass labels and their associated code length as a model cost.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:02 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Dom", "Byron E", ""]]}, {"id": "1301.0578", "submitter": "Tomas Kocka", "authors": "Tomas Kocka, Nevin Lianwen Zhang", "title": "Dimension Correction for Hierarchical Latent Class Models", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-267-274", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model complexity is an important factor to consider when selecting among\ngraphical models. When all variables are observed, the complexity of a model\ncan be measured by its standard dimension, i.e. the number of independent\nparameters. When hidden variables are present, however, standard dimension\nmight no longer be appropriate. One should instead use effective dimension\n(Geiger et al. 1996). This paper is concerned with the computation of effective\ndimension. First we present an upper bound on the effective dimension of a\nlatent class (LC) model. This bound is tight and its computation is easy. We\nthen consider a generalization of LC models called hierarchical latent class\n(HLC) models (Zhang 2002). We show that the effective dimension of an HLC model\ncan be obtained from the effective dimensions of some related LC models. We\nalso demonstrate empirically that using effective dimension in place of\nstandard dimension improves the quality of models learned from data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Kocka", "Tomas", ""], ["Zhang", "Nevin Lianwen", ""]]}, {"id": "1301.0579", "submitter": "Samuel Kutin", "authors": "Samuel Kutin, Partha Niyogi", "title": "Almost-everywhere algorithmic stability and generalization error", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-275-282", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore in some detail the notion of algorithmic stability as a viable\nframework for analyzing the generalization error of learning algorithms. We\nintroduce the new notion of training stability of a learning algorithm and show\nthat, in a general setting, it is sufficient for good bounds on generalization\nerror. In the PAC setting, training stability is both necessary and sufficient\nfor learnability.\\ The approach based on training stability makes no reference\nto VC dimension or VC entropy. There is no need to prove uniform convergence,\nand generalization error is bounded directly via an extended McDiarmid\ninequality. As a result it potentially allows us to deal with a broader class\nof learning algorithms than Empirical Risk Minimization. \\ We also explore the\nrelationships among VC dimension, generalization error, and various notions of\nstability. Several examples of learning algorithms are considered.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:58 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Kutin", "Samuel", ""], ["Niyogi", "Partha", ""]]}, {"id": "1301.0586", "submitter": "Christopher Meek", "authors": "Christopher Meek, Bo Thiesson, David Heckerman", "title": "Staged Mixture Modelling and Boosting", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-335-343", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and evaluate a data-driven staged mixture\nmodeling technique for building density, regression, and classification models.\nOur basic approach is to sequentially add components to a finite mixture model\nusing the structural expectation maximization (SEM) algorithm. We show that our\ntechnique is qualitatively similar to boosting. This correspondence is a\nnatural byproduct of the fact that we use the SEM algorithm to sequentially fit\nthe mixture model. Finally, in our experimental evaluation, we demonstrate the\neffectiveness of our approach on a variety of prediction and density estimation\ntasks using real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:27 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Meek", "Christopher", ""], ["Thiesson", "Bo", ""], ["Heckerman", "David", ""]]}, {"id": "1301.0587", "submitter": "Ramgopal Mettu", "authors": "Ramgopal Mettu, Greg Plaxton", "title": "Optimal Time Bounds for Approximate Clustering", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-344-351", "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in unsupervised learning, and has been\nstudied widely both as a problem of learning mixture models and as an\noptimization problem. In this paper, we study clustering with respect the\nemph{k-median} objective function, a natural formulation of clustering in which\nwe attempt to minimize the average distance to cluster centers. One of the main\ncontributions of this paper is a simple but powerful sampling technique that we\ncall emph{successive sampling} that could be of independent interest. We show\nthat our sampling procedure can rapidly identify a small set of points (of size\njust O(klog{n/k})) that summarize the input points for the purpose of\nclustering. Using successive sampling, we develop an algorithm for the k-median\nproblem that runs in O(nk) time for a wide range of values of k and is\nguaranteed, with high probability, to return a solution with cost at most a\nconstant factor times optimal. We also establish a lower bound of Omega(nk) on\nany randomized constant-factor approximation algorithm for the k-median problem\nthat succeeds with even a negligible (say 1/100) probability. Thus we establish\na tight time bound of Theta(nk) for the k-median problem for a wide range of\nvalues of k. The best previous upper bound for the problem was O(nk), where the\nO-notation hides polylogarithmic factors in n and k. The best previous lower\nbound of O(nk) applied only to deterministic k-median algorithms. While we\nfocus our presentation on the k-median objective, all our upper bounds are\nvalid for the k-means objective as well. In this context our algorithm compares\nfavorably to the widely used k-means heuristic, which requires O(nk) time for\njust one iteration and provides no useful approximation guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:31 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Mettu", "Ramgopal", ""], ["Plaxton", "Greg", ""]]}, {"id": "1301.0588", "submitter": "Thomas P. Minka", "authors": "Thomas P. Minka, John Lafferty", "title": "Expectation-Propogation for the Generative Aspect Model", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-352-359", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative aspect model is an extension of the multinomial model for text\nthat allows word probabilities to vary stochastically across documents.\nPrevious results with aspect models have been promising, but hindered by the\ncomputational difficulty of carrying out inference and learning. This paper\ndemonstrates that the simple variational methods of Blei et al (2001) can lead\nto inaccurate inferences and biased learning for the generative aspect model.\nWe develop an alternative approach that leads to higher accuracy at comparable\ncost. An extension of Expectation-Propagation is used for inference and then\nembedded in an EM algorithm for learning. Experimental results are presented\nfor both synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:35 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Minka", "Thomas P.", ""], ["Lafferty", "John", ""]]}, {"id": "1301.0593", "submitter": "Tatjana Pavlenko", "authors": "Tatjana Pavlenko, Dietrich von Rosen", "title": "Bayesian Network Classifiers in a High Dimensional Framework", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-397-404", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a growing dimension asymptotic formalism. The perspective in this\npaper is classification theory and we show that it can accommodate\nprobabilistic networks classifiers, including naive Bayes model and its\naugmented version. When represented as a Bayesian network these classifiers\nhave an important advantage: The corresponding discriminant function turns out\nto be a specialized case of a generalized additive model, which makes it\npossible to get closed form expressions for the asymptotic misclassification\nprobabilities used here as a measure of classification accuracy. Moreover, in\nthis paper we propose a new quantity for assessing the discriminative power of\na set of features which is then used to elaborate the augmented naive Bayes\nclassifier. The result is a weighted form of the augmented naive Bayes that\ndistributes weights among the sets of features according to their\ndiscriminative power. We derive the asymptotic distribution of the sample based\ndiscriminative power and show that it is seriously overestimated in a high\ndimensional case. We then apply this result to find the optimal, in a sense of\nminimum misclassification probability, type of weighting.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Pavlenko", "Tatjana", ""], ["von Rosen", "Dietrich", ""]]}, {"id": "1301.0599", "submitter": "Robert E. Schapire", "authors": "Robert E. Schapire", "title": "Advances in Boosting (Invited Talk)", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-446-452", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a general method of generating many simple classification rules\nand combining them into a single, highly accurate rule. In this talk, I will\nreview the AdaBoost boosting algorithm and some of its underlying theory, and\nthen look at how this theory has helped us to face some of the challenges of\napplying AdaBoost in two domains: In the first of these, we used boosting for\npredicting and modeling the uncertainty of prices in complicated, interacting\nauctions. The second application was to the classification of caller utterances\nin a telephone spoken-dialogue system where we faced two challenges: the need\nto incorporate prior knowledge to compensate for initially insufficient data;\nand a later need to filter the large stream of unlabeled examples being\ncollected to select the ones whose labels are likely to be most informative.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:17 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Schapire", "Robert E.", ""]]}, {"id": "1301.0601", "submitter": "Christian R. Shelton", "authors": "Christian R. Shelton", "title": "Reinforcement Learning with Partially Known World Dynamics", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-461-468", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning would enjoy better success on real-world problems if\ndomain knowledge could be imparted to the algorithm by the modelers. Most\nproblems have both hidden state and unknown dynamics. Partially observable\nMarkov decision processes (POMDPs) allow for the modeling of both.\nUnfortunately, they do not provide a natural framework in which to specify\nknowledge about the domain dynamics. The designer must either admit to knowing\nnothing about the dynamics or completely specify the dynamics (thereby turning\nit into a planning problem). We propose a new framework called a partially\nknown Markov decision process (PKMDP) which allows the designer to specify\nknown dynamics while still leaving portions of the environment s dynamics\nunknown.The model represents NOT ONLY the environment dynamics but also the\nagents knowledge of the dynamics. We present a reinforcement learning algorithm\nfor this model based on importance sampling. The algorithm incorporates\nplanning based on the known dynamics and learning about the unknown dynamics.\nOur results clearly demonstrate the ability to add domain knowledge and the\nresulting benefits for learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:25 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Shelton", "Christian R.", ""]]}, {"id": "1301.0602", "submitter": "Harald Steck", "authors": "Harald Steck, Tommi S. Jaakkola", "title": "Unsupervised Active Learning in Large Domains", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-469-476", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a powerful approach to analyzing data effectively. We show\nthat the feasibility of active learning depends crucially on the choice of\nmeasure with respect to which the query is being optimized. The standard\ninformation gain, for example, does not permit an accurate evaluation with a\nsmall committee, a representative subset of the model space. We propose a\nsurrogate measure requiring only a small committee and discuss the properties\nof this new measure. We devise, in addition, a bootstrap approach for committee\nselection. The advantages of this approach are illustrated in the context of\nrecovering (regulatory) network models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:30 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Steck", "Harald", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.0604", "submitter": "Ben Taskar", "authors": "Ben Taskar, Pieter Abbeel, Daphne Koller", "title": "Discriminative Probabilistic Models for Relational Data", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-485-492", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many supervised learning tasks, the entities to be labeled are related to\neach other in complex ways and their labels are not independent. For example,\nin hypertext classification, the labels of linked pages are highly correlated.\nA standard approach is to classify each entity independently, ignoring the\ncorrelations between them. Recently, Probabilistic Relational Models, a\nrelational version of Bayesian networks, were used to define a joint\nprobabilistic model for a collection of related entities. In this paper, we\npresent an alternative framework that builds on (conditional) Markov networks\nand addresses two limitations of the previous approach. First, undirected\nmodels do not impose the acyclicity constraint that hinders representation of\nmany important relational dependencies in directed models. Second, undirected\nmodels are well suited for discriminative training, where we optimize the\nconditional likelihood of the labels given the features, which generally\nimproves classification accuracy. We show how to train these models\neffectively, and how to use approximate probabilistic inference over the\nlearned model for collective classification of multiple related entities. We\nprovide experimental results on a webpage classification task, showing that\naccuracy can be significantly improved by modeling relational dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:38 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Taskar", "Ben", ""], ["Abbeel", "Pieter", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.0610", "submitter": "Martin Wainwright", "authors": "Martin Wainwright, Tommi S. Jaakkola, Alan Willsky", "title": "A New Class of Upper Bounds on the Log Partition Function", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-536-543", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounds on the log partition function are important in a variety of contexts,\nincluding approximate inference, model fitting, decision theory, and large\ndeviations analysis. We introduce a new class of upper bounds on the log\npartition function, based on convex combinations of distributions in the\nexponential domain, that is applicable to an arbitrary undirected graphical\nmodel. In the special case of convex combinations of tree-structured\ndistributions, we obtain a family of variational problems, similar to the Bethe\nfree energy, but distinguished by the following desirable properties: i. they\nare cnvex, and have a unique global minimum; and ii. the global minimum gives\nan upper bound on the log partition function. The global minimum is defined by\nstationary conditions very similar to those defining fixed points of belief\npropagation or tree-based reparameterization Wainwright et al., 2001. As with\nBP fixed points, the elements of the minimizing argument can be used as\napproximations to the marginals of the original model. The analysis described\nhere can be extended to structures of higher treewidth e.g., hypertrees,\nthereby making connections with more advanced approximations e.g., Kikuchi and\nvariants Yedidia et al., 2001; Minka, 2001.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:01 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Wainwright", "Martin", ""], ["Jaakkola", "Tommi S.", ""], ["Willsky", "Alan", ""]]}, {"id": "1301.0613", "submitter": "Wim Wiegerinck", "authors": "Wim Wiegerinck, Tom Heskes", "title": "IPF for Discrete Chain Factor Graphs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-560-567", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative Proportional Fitting (IPF), combined with EM, is commonly used as\nan algorithm for likelihood maximization in undirected graphical models. In\nthis paper, we present two iterative algorithms that generalize upon IPF. The\nfirst one is for likelihood maximization in discrete chain factor graphs, which\nwe define as a wide class of discrete variable models including undirected\ngraphical models and Bayesian networks, but also chain graphs and sigmoid\nbelief networks. The second one is for conditional likelihood maximization in\nstandard undirected models and Bayesian networks. In both algorithms, the\niteration steps are expressed in closed form. Numerical simulations show that\nthe algorithms are competitive with state of the art methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:15 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Wiegerinck", "Wim", ""], ["Heskes", "Tom", ""]]}, {"id": "1301.0725", "submitter": "Mathieu Senelle", "authors": "Mathieu Senelle, Silvia Garcia-Diez, Amin Mantrach, Masashi Shimbo,\n  Marco Saerens, Fran\\c{c}ois Fouss", "title": "The Sum-over-Forests density index: identifying dense regions in a graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel nonparametric density index defined on graphs,\nthe Sum-over-Forests (SoF) density index. It is based on a clear and intuitive\nidea: high-density regions in a graph are characterized by the fact that they\ncontain a large amount of low-cost trees with high outdegrees while low-density\nregions contain few ones. Therefore, a Boltzmann probability distribution on\nthe countable set of forests in the graph is defined so that large (high-cost)\nforests occur with a low probability while short (low-cost) forests occur with\na high probability. Then, the SoF density index of a node is defined as the\nexpected outdegree of this node in a non-trivial tree of the forest, thus\nproviding a measure of density around that node. Following the matrix-forest\ntheorem, and a statistical physics framework, it is shown that the SoF density\nindex can be easily computed in closed form through a simple matrix inversion.\nExperiments on artificial and real data sets show that the proposed index\nperforms well on finding dense regions, for graphs of various origins.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 13:56:25 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Senelle", "Mathieu", ""], ["Garcia-Diez", "Silvia", ""], ["Mantrach", "Amin", ""], ["Shimbo", "Masashi", ""], ["Saerens", "Marco", ""], ["Fouss", "Fran\u00e7ois", ""]]}, {"id": "1301.0858", "submitter": "Mohammad Hossein Rohban", "authors": "Weicong Ding, Mohammad H. Rohban, Prakash Ishwar, Venkatesh Saligrama", "title": "A New Geometric Approach to Latent Topic Modeling and Discovery", "comments": "This paper was submitted to the IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP) 2013 on November 30, 2012", "journal-ref": null, "doi": "10.1109/ICASSP.2013.6638729", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new geometrically-motivated algorithm for nonnegative matrix factorization\nis developed and applied to the discovery of latent \"topics\" for text and image\n\"document\" corpora. The algorithm is based on robustly finding and clustering\nextreme points of empirical cross-document word-frequencies that correspond to\nnovel \"words\" unique to each topic. In contrast to related approaches that are\nbased on solving non-convex optimization problems using suboptimal\napproximations, locally-optimal methods, or heuristics, the new algorithm is\nconvex, has polynomial complexity, and has competitive qualitative and\nquantitative performance compared to the current state-of-the-art approaches on\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 02:21:01 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Ding", "Weicong", ""], ["Rohban", "Mohammad H.", ""], ["Ishwar", "Prakash", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1301.1083", "submitter": "Stefan Maetschke", "authors": "Stefan R. Maetschke, Piyush B. Madhamshettiwar, Melissa J. Davis, Mark\n  A. Ragan", "title": "Supervised, semi-supervised and unsupervised inference of gene\n  regulatory networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference of gene regulatory network from expression data is a challenging\ntask. Many methods have been developed to this purpose but a comprehensive\nevaluation that covers unsupervised, semi-supervised and supervised methods,\nand provides guidelines for their practical application, is lacking.\n  We performed an extensive evaluation of inference methods on simulated\nexpression data. The results reveal very low prediction accuracies for\nunsupervised techniques with the notable exception of the z-score method on\nknock-out data. In all other cases the supervised approach achieved the highest\naccuracies and even in a semi-supervised setting with small numbers of only\npositive samples, outperformed the unsupervised techniques.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 00:37:24 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Maetschke", "Stefan R.", ""], ["Madhamshettiwar", "Piyush B.", ""], ["Davis", "Melissa J.", ""], ["Ragan", "Mark A.", ""]]}, {"id": "1301.1218", "submitter": "Matteo Riondato", "authors": "Matteo Riondato and Fabio Vandin", "title": "Finding the True Frequent Itemsets", "comments": "13 pages, Extended version of work appeared in SIAM International\n  Conference on Data Mining, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent Itemsets (FIs) mining is a fundamental primitive in data mining. It\nrequires to identify all itemsets appearing in at least a fraction $\\theta$ of\na transactional dataset $\\mathcal{D}$. Often though, the ultimate goal of\nmining $\\mathcal{D}$ is not an analysis of the dataset \\emph{per se}, but the\nunderstanding of the underlying process that generated it. Specifically, in\nmany applications $\\mathcal{D}$ is a collection of samples obtained from an\nunknown probability distribution $\\pi$ on transactions, and by extracting the\nFIs in $\\mathcal{D}$ one attempts to infer itemsets that are frequently (i.e.,\nwith probability at least $\\theta$) generated by $\\pi$, which we call the True\nFrequent Itemsets (TFIs). Due to the inherently stochastic nature of the\ngenerative process, the set of FIs is only a rough approximation of the set of\nTFIs, as it often contains a huge number of \\emph{false positives}, i.e.,\nspurious itemsets that are not among the TFIs. In this work we design and\nanalyze an algorithm to identify a threshold $\\hat{\\theta}$ such that the\ncollection of itemsets with frequency at least $\\hat{\\theta}$ in $\\mathcal{D}$\ncontains only TFIs with probability at least $1-\\delta$, for some\nuser-specified $\\delta$. Our method uses results from statistical learning\ntheory involving the (empirical) VC-dimension of the problem at hand. This\nallows us to identify almost all the TFIs without including any false positive.\nWe also experimentally compare our method with the direct mining of\n$\\mathcal{D}$ at frequency $\\theta$ and with techniques based on widely-used\nstandard bounds (i.e., the Chernoff bounds) of the binomial distribution, and\nshow that our algorithm outperforms these methods and achieves even better\nresults than what is guaranteed by the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 15:04:43 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 12:54:12 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2014 16:38:44 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Riondato", "Matteo", ""], ["Vandin", "Fabio", ""]]}, {"id": "1301.1254", "submitter": "Eric Hall Mr", "authors": "Eric C. Hall and Rebecca M. Willett", "title": "Dynamical Models and Tracking Regret in Online Convex Programming", "comments": "To appear in ICML 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new online convex optimization method which\nincorporates a family of candidate dynamical models and establishes novel\ntracking regret bounds that scale with the comparator's deviation from the best\ndynamical model in this family. Previous online optimization methods are\ndesigned to have a total accumulated loss comparable to that of the best\ncomparator sequence, and existing tracking or shifting regret bounds scale with\nthe overall variation of the comparator sequence. In many practical scenarios,\nhowever, the environment is nonstationary and comparator sequences with small\nvariation are quite weak, resulting in large losses. The proposed Dynamic\nMirror Descent method, in contrast, can yield low regret relative to highly\nvariable comparator sequences by both tracking the best dynamical model and\nforming predictions based on that model. This concept is demonstrated\nempirically in the context of sequential compressive observations of a dynamic\nscene and tracking a dynamic social network.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 16:39:09 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Hall", "Eric C.", ""], ["Willett", "Rebecca M.", ""]]}, {"id": "1301.1299", "submitter": "Th\\'eophane  Weber", "authors": "David Wingate, Theophane Weber", "title": "Automated Variational Inference in Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a new algorithm for approximate inference in probabilistic\nprograms, based on a stochastic gradient for variational programs. This method\nis efficient without restrictions on the probabilistic program; it is\nparticularly practical for distributions which are not analytically tractable,\nincluding highly structured distributions that arise in probabilistic programs.\nWe show how to automatically derive mean-field probabilistic programs and\noptimize them, and demonstrate that our perspective improves inference\nefficiency over other algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 18:48:02 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Wingate", "David", ""], ["Weber", "Theophane", ""]]}, {"id": "1301.1318", "submitter": "Charanpal Dhanjal", "authors": "Charanpal Dhanjal (LIP6), Romaric Gaudel (LIFL), St\\'ephan\n  Cl\\'emen\\c{c}on (LTCI)", "title": "Efficient Eigen-updating for Spectral Graph Clustering", "comments": "Correction of several typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning a graph into groups of vertices such that those within each\ngroup are more densely connected than vertices assigned to different groups,\nknown as graph clustering, is often used to gain insight into the organisation\nof large scale networks and for visualisation purposes. Whereas a large number\nof dedicated techniques have been recently proposed for static graphs, the\ndesign of on-line graph clustering methods tailored for evolving networks is a\nchallenging problem, and much less documented in the literature. Motivated by\nthe broad variety of applications concerned, ranging from the study of\nbiological networks to the analysis of networks of scientific references\nthrough the exploration of communications networks such as the World Wide Web,\nit is the main purpose of this paper to introduce a novel, computationally\nefficient, approach to graph clustering in the evolutionary context. Namely,\nthe method promoted in this article can be viewed as an incremental eigenvalue\nsolution for the spectral clustering method described by Ng. et al. (2001). The\nincremental eigenvalue solution is a general technique for finding the\napproximate eigenvectors of a symmetric matrix given a change. As well as\noutlining the approach in detail, we present a theoretical bound on the quality\nof the approximate eigenvectors using perturbation theory. We then derive a\nnovel spectral clustering algorithm called Incremental Approximate Spectral\nClustering (IASC). The IASC algorithm is simple to implement and its efficacy\nis demonstrated on both synthetic and real datasets modelling the evolution of\na HIV epidemic, a citation network and the purchase history graph of an\ne-commerce website.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 19:52:14 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2013 19:55:32 GMT"}, {"version": "v3", "created": "Tue, 14 May 2013 13:21:01 GMT"}, {"version": "v4", "created": "Mon, 27 Jan 2014 19:48:58 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Dhanjal", "Charanpal", "", "LIP6"], ["Gaudel", "Romaric", "", "LIFL"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"]]}, {"id": "1301.1459", "submitter": "Quoc Tran-Dinh", "authors": "Quoc Tran Dinh and Anastasios Kyrillidis and Volkan Cevher", "title": "A proximal Newton framework for composite minimization: Graph learning\n  without Cholesky decompositions and matrix inversions", "comments": "11 pages, 1 table and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithmic framework for convex minimization problems of a\ncomposite function with two terms: a self-concordant function and a possibly\nnonsmooth regularization term. Our method is a new proximal Newton algorithm\nthat features a local quadratic convergence rate. As a specific instance of our\nframework, we consider the sparse inverse covariance matrix estimation in graph\nlearning problems. Via a careful dual formulation and a novel analytic\nstep-size selection procedure, our approach for graph learning avoids Cholesky\ndecompositions and matrix inversions in its iteration making it attractive for\nparallel and distributed implementations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 09:40:43 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2013 15:56:00 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2013 19:19:15 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Dinh", "Quoc Tran", ""], ["Kyrillidis", "Anastasios", ""], ["Cevher", "Volkan", ""]]}, {"id": "1301.1722", "submitter": "Andrea Montanari", "authors": "Yash Deshpande and Andrea Montanari", "title": "Linear Bandits in High Dimension and Recommendation Systems", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of online services provide automated recommendations to help\nusers to navigate through a large collection of items. New items (products,\nvideos, songs, advertisements) are suggested on the basis of the user's past\nhistory and --when available-- her demographic profile. Recommendations have to\nsatisfy the dual goal of helping the user to explore the space of available\nitems, while allowing the system to probe the user's preferences.\n  We model this trade-off using linearly parametrized multi-armed bandits,\npropose a policy and prove upper and lower bounds on the cumulative \"reward\"\nthat coincide up to constants in the data poor (high-dimensional) regime. Prior\nwork on linear bandits has focused on the data rich (low-dimensional) regime\nand used cumulative \"risk\" as the figure of merit. For this data rich regime,\nwe provide a simple modification for our policy that achieves near-optimal risk\nperformance under more restrictive assumptions on the geometry of the problem.\nWe test (a variation of) the scheme used for establishing achievability on the\nNetflix and MovieLens datasets and obtain good agreement with the qualitative\npredictions of the theory we develop.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 23:45:06 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Deshpande", "Yash", ""], ["Montanari", "Andrea", ""]]}, {"id": "1301.1919", "submitter": "John Lafferty", "authors": "Rina Foygel, Michael Horrell, Mathias Drton, John Lafferty", "title": "Nonparametric Reduced Rank Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to multivariate nonparametric regression that\ngeneralizes reduced rank regression for linear models. An additive model is\nestimated for each dimension of a $q$-dimensional response, with a shared\n$p$-dimensional predictor variable. To control the complexity of the model, we\nemploy a functional form of the Ky-Fan or nuclear norm, resulting in a set of\nfunction estimates that have low rank. Backfitting algorithms are derived and\njustified using a nonparametric form of the nuclear norm subdifferential.\nOracle inequalities on excess risk are derived that exhibit the scaling\nbehavior of the procedure in the high dimensional setting. The methods are\nillustrated on gene expression data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 16:48:07 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Foygel", "Rina", ""], ["Horrell", "Michael", ""], ["Drton", "Mathias", ""], ["Lafferty", "John", ""]]}, {"id": "1301.1942", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Frank Hutter, Masrour Zoghi, David Matheson, Nando de\n  Freitas", "title": "Bayesian Optimization in a Billion Dimensions via Random Embeddings", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization techniques have been successfully applied to robotics,\nplanning, sensor placement, recommendation, advertising, intelligent user\ninterfaces and automatic algorithm configuration. Despite these successes, the\napproach is restricted to problems of moderate dimension, and several workshops\non Bayesian optimization have identified its scaling to high-dimensions as one\nof the holy grails of the field. In this paper, we introduce a novel random\nembedding idea to attack this problem. The resulting Random EMbedding Bayesian\nOptimization (REMBO) algorithm is very simple, has important invariance\nproperties, and applies to domains with both categorical and continuous\nvariables. We present a thorough theoretical analysis of REMBO. Empirical\nresults confirm that REMBO can effectively solve problems with billions of\ndimensions, provided the intrinsic dimensionality is low. They also show that\nREMBO achieves state-of-the-art performance in optimizing the 47 discrete\nparameters of a popular mixed integer linear programming solver.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 18:26:56 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2016 16:01:22 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Wang", "Ziyu", ""], ["Hutter", "Frank", ""], ["Zoghi", "Masrour", ""], ["Matheson", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1301.1954", "submitter": "Youngser Park", "authors": "Donniell E. Fishkind, Cencheng Shen, Youngser Park, Carey E. Priebe", "title": "On the Incommensurability Phenomenon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that two large, multi-dimensional data sets are each noisy\nmeasurements of the same underlying random process, and principle components\nanalysis is performed separately on the data sets to reduce their\ndimensionality. In some circumstances it may happen that the two\nlower-dimensional data sets have an inordinately large Procrustean\nfitting-error between them. The purpose of this manuscript is to quantify this\n\"incommensurability phenomenon.\" In particular, under specified conditions, the\nsquare Procrustean fitting-error of the two normalized lower-dimensional data\nsets is (asymptotically) a convex combination (via a correlation parameter) of\nthe Hausdorff distance between the projection subspaces and the maximum\npossible value of the square Procrustean fitting-error for normalized data. We\nshow how this gives rise to the incommensurability phenomenon, and we employ\nillustrative simulations as well as a real data experiment to explore how the\nincommensurability phenomenon may have an appreciable impact.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 19:26:07 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2013 17:40:17 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2014 19:50:08 GMT"}, {"version": "v4", "created": "Wed, 22 Oct 2014 16:39:15 GMT"}, {"version": "v5", "created": "Fri, 6 Feb 2015 13:36:33 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Fishkind", "Donniell E.", ""], ["Shen", "Cencheng", ""], ["Park", "Youngser", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1301.2007", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro, Gilad Lerman and Teng Zhang", "title": "Spectral Clustering Based on Local PCA", "comments": null, "journal-ref": "Journal of Machine Learning Research, 18(9):1-57, 2017", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a spectral clustering method based on local principal components\nanalysis (PCA). After performing local PCA in selected neighborhoods, the\nalgorithm builds a nearest neighbor graph weighted according to a discrepancy\nbetween the principal subspaces in the neighborhoods, and then applies spectral\nclustering. As opposed to standard spectral methods based solely on pairwise\ndistances between points, our algorithm is able to resolve intersections. We\nestablish theoretical guarantees for simpler variants within a prototypical\nmathematical framework for multi-manifold clustering, and evaluate our\nalgorithm on various simulated data sets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 23:48:15 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Lerman", "Gilad", ""], ["Zhang", "Teng", ""]]}, {"id": "1301.2015", "submitter": "Daniel Khashabi", "authors": "Daniel Khashabi, Mojtaba Ziyadi, Feng Liang", "title": "Heteroscedastic Relevance Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this work we propose a heteroscedastic generalization to RVM, a fast\nBayesian framework for regression, based on some recent similar works. We use\nvariational approximation and expectation propagation to tackle the problem.\nThe work is still under progress and we are examining the results and comparing\nwith the previous works.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 02:02:01 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Khashabi", "Daniel", ""], ["Ziyadi", "Mojtaba", ""], ["Liang", "Feng", ""]]}, {"id": "1301.2032", "submitter": "Chunhua Shen", "authors": "Chunhua Shen and Peng Wang and Sakrapee Paisitkriangkrai and Anton van\n  den Hengel", "title": "Training Effective Node Classifiers for Cascade Classification", "comments": "Appearing in Int'l J. Computer Vision. This is a substantially\n  revised version of http://arxiv.org/abs/1008.3742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascade classifiers are widely used in real-time object detection. Different\nfrom conventional classifiers that are designed for a low overall\nclassification error rate, a classifier in each node of the cascade is required\nto achieve an extremely high detection rate and moderate false positive rate.\nAlthough there are a few reported methods addressing this requirement in the\ncontext of object detection, there is no principled feature selection method\nthat explicitly takes into account this asymmetric node learning objective. We\nprovide such an algorithm here. We show that a special case of the biased\nminimax probability machine has the same formulation as the linear asymmetric\nclassifier (LAC) of Wu et al (2005). We then design a new boosting algorithm\nthat directly optimizes the cost function of LAC. The resulting\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on object detection\nverify the effectiveness of the proposed boosting algorithm as a node\nclassifier in cascade object detection, and show performance better than that\nof the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 05:26:18 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Shen", "Chunhua", ""], ["Wang", "Peng", ""], ["Paisitkriangkrai", "Sakrapee", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1301.2115", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, David Balduzzi, Bernhard Sch\\\"olkopf", "title": "Domain Generalization via Invariant Feature Representation", "comments": "The 30th International Conference on Machine Learning (ICML 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates domain generalization: How to take knowledge acquired\nfrom an arbitrary number of related domains and apply it to previously unseen\ndomains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based\noptimization algorithm that learns an invariant transformation by minimizing\nthe dissimilarity across domains, whilst preserving the functional relationship\nbetween input and output variables. A learning-theoretic analysis shows that\nreducing dissimilarity improves the expected generalization ability of\nclassifiers on new domains, motivating the proposed algorithm. Experimental\nresults on synthetic and real-world datasets demonstrate that DICA successfully\nlearns invariant features and improves classifier performance in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 13:29:17 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Muandet", "Krikamol", ""], ["Balduzzi", "David", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1301.2158", "submitter": "Casey Bennett", "authors": "Casey C. Bennett, Kris Hauser", "title": "Artificial Intelligence Framework for Simulating Clinical\n  Decision-Making: A Markov Decision Process Approach", "comments": "Keywords: Markov Decision Process; Dynamic Decision Network;\n  Multi-Agent System; Clinical Artificial Intelligence; Medical Decision\n  Making; Chronic Illness; (2013) Artificial Intelligence in Medicine", "journal-ref": "Artificial Intelligence in Medicine. 57(1): 9-19. (2013)", "doi": "10.1016/j.artmed.2012.12.003", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern healthcare system, rapidly expanding costs/complexity, the\ngrowing myriad of treatment options, and exploding information streams that\noften do not effectively reach the front lines hinder the ability to choose\noptimal treatment decisions over time. The goal in this paper is to develop a\ngeneral purpose (non-disease-specific) computational/artificial intelligence\n(AI) framework to address these challenges. This serves two potential\nfunctions: 1) a simulation environment for exploring various healthcare\npolicies, payment methodologies, etc., and 2) the basis for clinical artificial\nintelligence - an AI that can think like a doctor. This approach combines\nMarkov decision processes and dynamic decision networks to learn from clinical\ndata and develop complex plans via simulation of alternative sequential\ndecision paths while capturing the sometimes conflicting, sometimes synergistic\ninteractions of various components in the healthcare system. It can operate in\npartially observable environments (in the case of missing observations or data)\nby maintaining belief states about patient health status and functions as an\nonline agent that plans and re-plans. This framework was evaluated using real\npatient data from an electronic health record. Such an AI framework easily\noutperforms the current treatment-as-usual (TAU) case-rate/fee-for-service\nmodels of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a\n30-35% increase in patient outcomes. Tweaking certain model parameters further\nenhances this advantage, obtaining roughly 50% more improvement for roughly\nhalf the costs. Given careful design and problem formulation, an AI simulation\nframework can approximate optimal decisions even in complex and uncertain\nenvironments. Future work is described that outlines potential lines of\nresearch and integration of machine learning algorithms for personalized\nmedicine.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 15:29:59 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bennett", "Casey C.", ""], ["Hauser", "Kris", ""]]}, {"id": "1301.2194", "submitter": "Steven Hill", "authors": "Steven M. Hill and Sach Mukherjee", "title": "Network-based clustering with mixtures of L1-penalized Gaussian\n  graphical models: an empirical investigation", "comments": "A version of this work also appears in the first author's PhD Thesis\n  (Sparse Graphical Models for Cancer Signalling, University of Warwick, 2012),\n  which can be accessed at http://wrap.warwick.ac.uk/id/eprint/49626", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, multivariate samples may harbor previously unrecognized\nheterogeneity at the level of conditional independence or network structure.\nFor example, in cancer biology, disease subtypes may differ with respect to\nsubtype-specific interplay between molecular components. Then, both subtype\ndiscovery and estimation of subtype-specific networks present important and\nrelated challenges. To enable such analyses, we put forward a mixture model\nwhose components are sparse Gaussian graphical models. This brings together\nmodel-based clustering and graphical modeling to permit simultaneous estimation\nof cluster assignments and cluster-specific networks. We carry out estimation\nwithin an L1-penalized framework, and investigate several specific penalization\nregimes. We present empirical results on simulated data and provide general\nrecommendations for the formulation and use of mixtures of L1-penalized\nGaussian graphical models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 17:23:11 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Hill", "Steven M.", ""], ["Mukherjee", "Sach", ""]]}, {"id": "1301.2262", "submitter": "Robert G. Cowell", "authors": "Robert G. Cowell", "title": "Conditions Under Which Conditional Independence and Scoring Methods Lead\n  to Identical Selection of Bayesian Network Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-91-97", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often stated in papers tackling the task of inferring Bayesian network\nstructures from data that there are these two distinct approaches: (i) Apply\nconditional independence tests when testing for the presence or otherwise of\nedges; (ii) Search the model space using a scoring metric. Here I argue that\nfor complete data and a given node ordering this division is a myth, by showing\nthat cross entropy methods for checking conditional independence are\nmathematically identical to methods based upon discriminating between models by\ntheir overall goodness-of-fit logarithmic scores.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:01 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Cowell", "Robert G.", ""]]}, {"id": "1301.2266", "submitter": "Nando de Freitas", "authors": "Nando de Freitas, Pedro Hojen-Sorensen, Michael I. Jordan, Stuart\n  Russell", "title": "Variational MCMC", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-120-127", "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of learning algorithms that combines variational\napproximation and Markov chain Monte Carlo (MCMC) simulation. Naive algorithms\nthat use the variational approximation as proposal distribution can perform\npoorly because this approximation tends to underestimate the true variance and\nother features of the data. We solve this problem by introducing more\nsophisticated MCMC algorithms. One of these algorithms is a mixture of two MCMC\nkernels: a random walk Metropolis kernel and a blockMetropolis-Hastings (MH)\nkernel with a variational approximation as proposaldistribution. The MH kernel\nallows one to locate regions of high probability efficiently. The Metropolis\nkernel allows us to explore the vicinity of these regions. This algorithm\noutperforms variationalapproximations because it yields slightly better\nestimates of the mean and considerably better estimates of higher moments, such\nas covariances. It also outperforms standard MCMC algorithms because it locates\ntheregions of high probability quickly, thus speeding up convergence. We\ndemonstrate this algorithm on the problem of Bayesian parameter estimation for\nlogistic (sigmoid) belief networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:18 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["de Freitas", "Nando", ""], ["Hojen-Sorensen", "Pedro", ""], ["Jordan", "Michael I.", ""], ["Russell", "Stuart", ""]]}, {"id": "1301.2269", "submitter": "Gal Elidan", "authors": "Gal Elidan, Nir Friedman", "title": "Learning the Dimensionality of Hidden Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-144-151", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A serious problem in learning probabilistic models is the presence of hidden\nvariables. These variables are not observed, yet interact with several of the\nobserved variables. Detecting hidden variables poses two problems: determining\nthe relations to other variables in the model and determining the number of\nstates of the hidden variable. In this paper, we address the latter problem in\nthe context of Bayesian networks. We describe an approach that utilizes a\nscore-based agglomerative state-clustering. As we show, this approach allows us\nto efficiently evaluate models with a range of cardinalities for the hidden\nvariable. We show how to extend this procedure to deal with multiple\ninteracting hidden variables. We demonstrate the effectiveness of this approach\nby evaluating it on synthetic and real-life data. We show that our approach\nlearns models with hidden variables that generalize better and have better\nstructure than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:30 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Elidan", "Gal", ""], ["Friedman", "Nir", ""]]}, {"id": "1301.2270", "submitter": "Nir Friedman", "authors": "Nir Friedman, Ori Mosenzon, Noam Slonim, Naftali Tishby", "title": "Multivariate Information Bottleneck", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-152-161", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information bottleneck method is an unsupervised non-parametric data\norganization technique. Given a joint distribution P(A,B), this method\nconstructs a new variable T that extracts partitions, or clusters, over the\nvalues of A that are informative about B. The information bottleneck has\nalready been applied to document classification, gene expression, neural code,\nand spectral analysis. In this paper, we introduce a general principled\nframework for multivariate extensions of the information bottleneck method.\nThis allows us to consider multiple systems of data partitions that are\ninter-related. Our approach utilizes Bayesian networks for specifying the\nsystems of clusters and what information each captures. We show that this\nconstruction provides insight about bottleneck variations and enables us to\ncharacterize solutions of these variations. We also present a general framework\nfor iterative algorithms for constructing solutions, and apply it to several\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Friedman", "Nir", ""], ["Mosenzon", "Ori", ""], ["Slonim", "Noam", ""], ["Tishby", "Naftali", ""]]}, {"id": "1301.2278", "submitter": "Geoffrey E. Hinton", "authors": "Geoffrey E. Hinton, Yee Whye Teh", "title": "Discovering Multiple Constraints that are Frequently Approximately\n  Satisfied", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-227-234", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some high-dimensional data.sets can be modelled by assuming that there are\nmany different linear constraints, each of which is Frequently Approximately\nSatisfied (FAS) by the data. The probability of a data vector under the model\nis then proportional to the product of the probabilities of its constraint\nviolations. We describe three methods of learning products of constraints using\na heavy-tailed probability distribution for the violations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:10 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Hinton", "Geoffrey E.", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1301.2280", "submitter": "Geoff A. Jarrad", "authors": "Geoff A. Jarrad", "title": "Estimating Well-Performing Bayesian Networks using Bernoulli Mixtures", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-245-252", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for estimating Bayesian network (BN) parameters from data is\npresented which provides improved performance on test data. Previous research\nhas shown the value of representing conditional probability distributions\n(CPDs) via neural networks(Neal 1992), noisy-OR gates (Neal 1992, Diez 1993)and\ndecision trees (Friedman and Goldszmidt 1996).The Bernoulli mixture network\n(BMN) explicitly represents the CPDs of discrete BN nodes as mixtures of local\ndistributions,each having a different set of parents.This increases the space\nof possible structures which can be considered,enabling the CPDs to have\nfiner-grained dependencies.The resulting estimation procedure induces a\nmodelthat is better able to emulate the underlying interactions occurring in\nthe data than conventional conditional Bernoulli network models.The results for\nartificially generated data indicate that overfitting is best reduced by\nrestricting the complexity of candidate mixture substructures local to each\nnode. Furthermore, mixtures of very simple substructures can perform almost as\nwell as more complex ones.The BMN is also applied to data collected from an\nonline adventure game with an application to keyhole plan recognition. The\nresults show that the BMN-based model brings a dramatic improvement in\nperformance over a conventional BN model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:19 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Jarrad", "Geoff A.", ""]]}, {"id": "1301.2283", "submitter": "Tomas Kocka", "authors": "Tomas Kocka, Robert Castelo", "title": "Improved learning of Bayesian networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-269-276", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search space of Bayesian Network structures is usually defined as Acyclic\nDirected Graphs (DAGs) and the search is done by local transformations of DAGs.\nBut the space of Bayesian Networks is ordered by DAG Markov model inclusion and\nit is natural to consider that a good search policy should take this into\naccount. First attempt to do this (Chickering 1996) was using equivalence\nclasses of DAGs instead of DAGs itself. This approach produces better results\nbut it is significantly slower. We present a compromise between these two\napproaches. It uses DAGs to search the space in such a way that the ordering by\ninclusion is taken into account. This is achieved by repetitive usage of local\nmoves within the equivalence class of DAGs. We show that this new approach\nproduces better results than the original DAGs approach without substantial\nchange in time complexity. We present empirical results, within the framework\nof heuristic search and Markov Chain Monte Carlo, provided through the Alarm\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:32 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kocka", "Tomas", ""], ["Castelo", "Robert", ""]]}, {"id": "1301.2284", "submitter": "Petri Kontkanen", "authors": "Petri Kontkanen, Petri Myllymaki, Henry Tirri", "title": "Classifier Learning with Supervised Marginal Likelihood", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-277-284", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that in supervised classification tasks, in practice it\nmay be more sensible to perform model selection with respect to some more\nfocused model selection score, like the supervised (conditional) marginal\nlikelihood, than with respect to the standard marginal likelihood criterion.\nHowever, for most Bayesian network models, computing the supervised marginal\nlikelihood score takes exponential time with respect to the amount of observed\ndata. In this paper, we consider diagnostic Bayesian network classifiers where\nthe significant model parameters represent conditional distributions for the\nclass variable, given the values of the predictor variables, in which case the\nsupervised marginal likelihood can be computed in linear time with respect to\nthe data. As the number of model parameters grows in this case exponentially\nwith respect to the number of predictors, we focus on simple diagnostic models\nwhere the number of relevant predictors is small, and suggest two approaches\nfor applying this type of models in classification. The first approach is based\non mixtures of simple diagnostic models, while in the second approach we apply\nthe small predictor sets of the simple diagnostic models for augmenting the\nNaive Bayes classifier.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kontkanen", "Petri", ""], ["Myllymaki", "Petri", ""], ["Tirri", "Henry", ""]]}, {"id": "1301.2286", "submitter": "John Lafferty", "authors": "John Lafferty, Larry A. Wasserman", "title": "Iterative Markov Chain Monte Carlo Computation of Reference Priors and\n  Minimax Risk", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-293-300", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an iterative Markov chainMonte Carlo algorithm for\ncomputingreference priors and minimax risk forgeneral parametric families.\nOurapproach uses MCMC techniques based onthe Blahut-Arimoto algorithm\nforcomputing channel capacity ininformation theory. We give astatistical\nanalysis of the algorithm,bounding the number of samples requiredfor the\nstochastic algorithm to closelyapproximate the deterministic algorithmin each\niteration. Simulations arepresented for several examples fromexponential\nfamilies. Although we focuson applications to reference priors andminimax risk,\nthe methods and analysiswe develop are applicable to a muchbroader class of\noptimization problemsand iterative algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:45 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Lafferty", "John", ""], ["Wasserman", "Larry A.", ""]]}, {"id": "1301.2303", "submitter": "Alexandrin Popescul", "authors": "Alexandrin Popescul, Lyle H. Ungar, David M Pennock, Steve Lawrence", "title": "Probabilistic Models for Unified Collaborative and Content-Based\n  Recommendation in Sparse-Data Environments", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-437-444", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems leverage product and community information to target\nproducts to consumers. Researchers have developed collaborative recommenders,\ncontent-based recommenders, and (largely ad-hoc) hybrid systems. We propose a\nunified probabilistic framework for merging collaborative and content-based\nrecommendations. We extend Hofmann's [1999] aspect model to incorporate\nthree-way co-occurrence data among users, items, and item content. The relative\ninfluence of collaboration data versus content data is not imposed as an\nexogenous parameter, but rather emerges naturally from the given data sources.\nGlobal probabilistic models coupled with standard Expectation Maximization (EM)\nlearning algorithms tend to drastically overfit in sparse-data situations, as\nis typical in recommendation applications. We show that secondary content\ninformation can often be used to overcome sparsity. Experiments on data from\nthe ResearchIndex library of Computer Science publications show that\nappropriate mixture models incorporating secondary data produce significantly\nbetter quality recommenders than k-nearest neighbors (k-NN). Global\nprobabilistic models also allow more general inferences than local methods like\nk-NN.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:59 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Popescul", "Alexandrin", ""], ["Ungar", "Lyle H.", ""], ["Pennock", "David M", ""], ["Lawrence", "Steve", ""]]}, {"id": "1301.2311", "submitter": "Nathan Srebro", "authors": "Nathan Srebro", "title": "Maximum Likelihood Bounded Tree-Width Markov Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-504-511", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chow and Liu (1968) studied the problem of learning a maximumlikelihood\nMarkov tree. We generalize their work to more complexMarkov networks by\nconsidering the problem of learning a maximumlikelihood Markov network of\nbounded complexity. We discuss howtree-width is in many ways the appropriate\nmeasure of complexity andthus analyze the problem of learning a maximum\nlikelihood Markovnetwork of bounded tree-width.Similar to the work of Chow and\nLiu, we are able to formalize thelearning problem as a combinatorial\noptimization problem on graphs. Weshow that learning a maximum likelihood\nMarkov network of boundedtree-width is equivalent to finding a maximum weight\nhypertree. Thisequivalence gives rise to global, integer-programming\nbased,approximation algorithms with provable performance guarantees, for\nthelearning problem. This contrasts with heuristic local-searchalgorithms which\nwere previously suggested (e.g. by Malvestuto 1991).The equivalence also allows\nus to study the computational hardness ofthe learning problem. We show that\nlearning a maximum likelihoodMarkov network of bounded tree-width is NP-hard,\nand discuss thehardness of approximation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:35 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Srebro", "Nathan", ""]]}, {"id": "1301.2315", "submitter": "Lex Weaver", "authors": "Lex Weaver, Nigel Tao", "title": "The Optimal Reward Baseline for Gradient-Based Reinforcement Learning", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-538-545", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist a number of reinforcement learning algorithms which learnby\nclimbing the gradient of expected reward. Their long-runconvergence has been\nproved, even in partially observableenvironments with non-deterministic\nactions, and without the need fora system model. However, the variance of the\ngradient estimator hasbeen found to be a significant practical problem. Recent\napproacheshave discounted future rewards, introducing a bias-variance\ntrade-offinto the gradient estimate. We incorporate a reward baseline into\nthelearning system, and show that it affects variance without\nintroducingfurther bias. In particular, as we approach the\nzero-bias,high-variance parameterization, the optimal (or variance\nminimizing)constant reward baseline is equal to the long-term average\nexpectedreward. Modified policy-gradient algorithms are presented, and anumber\nof experiments demonstrate their improvement over previous work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:53 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Weaver", "Lex", ""], ["Tao", "Nigel", ""]]}, {"id": "1301.2316", "submitter": "Jacob A. Wegelin", "authors": "Jacob A. Wegelin, Thomas S. Richardson", "title": "Cross-covariance modelling via DAGs with hidden variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-546-553", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DAG models with hidden variables present many difficulties that are not\npresent when all nodes are observed. In particular, fully observed DAG models\nare identified and correspond to well-defined sets ofdistributions, whereas\nthis is not true if nodes are unobserved. Inthis paper we characterize exactly\nthe set of distributions given by a class of one-dimensional Gaussian latent\nvariable models. These models relate two blocks of observed variables, modeling\nonly the cross-covariance matrix. We describe the relation of this model to the\nsingular value decomposition of the cross-covariance matrix. We show that,\nalthough the model is underidentified, useful information may be extracted. We\nfurther consider an alternative parametrization in which one latent variable is\nassociated with each block. Our analysis leads to some novel covariance\nequivalence results for Gaussian hidden variable models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:57 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Wegelin", "Jacob A.", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1301.2318", "submitter": "Steve Young", "authors": "Steve Young", "title": "Statistical Modeling in Continuous Speech Recognition (CSR)(Invited\n  Talk)", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-562-571", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic continuous speech recognition (CSR) is sufficiently mature that a\nvariety of real world applications are now possible including large vocabulary\ntranscription and interactive spoken dialogues. This paper reviews the\nevolution of the statistical modelling techniques which underlie current-day\nsystems, specifically hidden Markov models (HMMs) and N-grams. Starting from a\ndescription of the speech signal and its parameterisation, the various\nmodelling assumptions and their consequences are discussed. It then describes\nvarious techniques by which the effects of these assumptions can be mitigated.\nDespite the progress that has been made, the limitations of current modelling\ntechniques are still evident. The paper therefore concludes with a brief review\nof some of the more fundamental modelling work now in progress.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:07 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Young", "Steve", ""]]}, {"id": "1301.2410", "submitter": "Dimitris Kugiumtzis", "authors": "Ioannis Vlachos and Dimitris Kugiumtzis", "title": "Backward-in-Time Selection of the Order of Dynamic Regression Prediction\n  Model", "comments": "42 pages, 3 figures, accepted for publication in the Journal of\n  Forecasting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the optimal structure of dynamic regression models used in\nmultivariate time series prediction and propose a scheme to form the lagged\nvariable structure called Backward-in-Time Selection (BTS) that takes into\naccount feedback and multi-collinearity, often present in multivariate time\nseries. We compare BTS to other known methods, also in conjunction with\nregularization techniques used for the estimation of model parameters, namely\nprincipal components, partial least squares and ridge regression estimation.\nThe predictive efficiency of the different models is assessed by means of Monte\nCarlo simulations for different settings of feedback and multi-collinearity.\nThe results show that BTS has consistently good prediction performance while\nother popular methods have varying and often inferior performance. The\nprediction performance of BTS was also found the best when tested on human\nelectroencephalograms of an epileptic seizure, and to the prediction of returns\nof indices of world financial markets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 08:04:51 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Vlachos", "Ioannis", ""], ["Kugiumtzis", "Dimitris", ""]]}, {"id": "1301.2556", "submitter": "Torsten Ensslin", "authors": "Torsten En{\\ss}lin", "title": "Information field theory", "comments": "8 pages, in-a-nutshell introduction to information field theory (see\n  http://www.mpa-garching.mpg.de/ift), accepted for the proceedings of MaxEnt\n  2012, the 32nd International Workshop on Bayesian Inference and Maximum\n  Entropy Methods in Science and Engineering", "journal-ref": null, "doi": "10.1063/1.4819999", "report-no": null, "categories": "astro-ph.IM cs.IT math.IT physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear image reconstruction and signal analysis deal with complex inverse\nproblems. To tackle such problems in a systematic way, I present information\nfield theory (IFT) as a means of Bayesian, data based inference on spatially\ndistributed signal fields. IFT is a statistical field theory, which permits the\nconstruction of optimal signal recovery algorithms even for non-linear and\nnon-Gaussian signal inference problems. IFT algorithms exploit spatial\ncorrelations of the signal fields and benefit from techniques developed to\ninvestigate quantum and statistical field theories, such as Feynman diagrams,\nre-normalisation calculations, and thermodynamic potentials. The theory can be\nused in many areas, and applications in cosmology and numerics are presented.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 17:24:20 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["En\u00dflin", "Torsten", ""]]}, {"id": "1301.2603", "submitter": "Mahdi Soltanolkotabi", "authors": "Mahdi Soltanolkotabi, Ehsan Elhamifar, Emmanuel J. Cand\\`es", "title": "Robust subspace clustering", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1199 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 2, 669-699", "doi": "10.1214/13-AOS1199", "report-no": "IMS-AOS-AOS1199", "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering refers to the task of finding a multi-subspace\nrepresentation that best fits a collection of points taken from a\nhigh-dimensional space. This paper introduces an algorithm inspired by sparse\nsubspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern\nRecognition, CVPR (2009) 2790-2797] to cluster noisy data, and develops some\nnovel theory demonstrating its correctness. In particular, the theory uses\nideas from geometric functional analysis to show that the algorithm can\naccurately recover the underlying subspaces under minimal requirements on their\norientation, and on the number of samples per subspace. Synthetic as well as\nreal data experiments complement our theoretical study, illustrating our\napproach and demonstrating its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 21:05:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 00:39:13 GMT"}, {"version": "v3", "created": "Fri, 23 May 2014 13:19:54 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Soltanolkotabi", "Mahdi", ""], ["Elhamifar", "Ehsan", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1301.2655", "submitter": "Preux Philippe", "authors": "Hachem Kadri (INRIA Lille - Nord Europe), Asma Rabaoui (IMS), Philippe\n  Preux (INRIA Lille - Nord Europe, LIFL), Emmanuel Duflos (INRIA Lille - Nord\n  Europe, LAGIS), Alain Rakotomamonjy (LITIS)", "title": "Functional Regularized Least Squares Classi cation with Operator-valued\n  Kernels", "comments": null, "journal-ref": "28th International Conference on Machine Learning (ICML), Seattle\n  : United States (2011)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although operator-valued kernels have recently received increasing interest\nin various machine learning and functional data analysis problems such as\nmulti-task learning or functional regression, little attention has been paid to\nthe understanding of their associated feature spaces. In this paper, we explore\nthe potential of adopting an operator-valued kernel feature space perspective\nfor the analysis of functional data. We then extend the Regularized Least\nSquares Classification (RLSC) algorithm to cover situations where there are\nmultiple functions per observation. Experiments on a sound recognition problem\nshow that the proposed method outperforms the classical RLSC algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 07:46:24 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Kadri", "Hachem", "", "INRIA Lille - Nord Europe"], ["Rabaoui", "Asma", "", "IMS"], ["Preux", "Philippe", "", "INRIA Lille - Nord Europe, LIFL"], ["Duflos", "Emmanuel", "", "INRIA Lille - Nord\n  Europe, LAGIS"], ["Rakotomamonjy", "Alain", "", "LITIS"]]}, {"id": "1301.2656", "submitter": "Preux Philippe", "authors": "Hachem Kadri (INRIA Lille - Nord Europe), Philippe Preux (INRIA Lille\n  - Nord Europe, LIFL), Emmanuel Duflos (INRIA Lille - Nord Europe, LAGIS),\n  St\\'ephane Canu (LITIS)", "title": "Multiple functional regression with both discrete and continuous\n  covariates", "comments": null, "journal-ref": "2nd International Workshop on Functional and Operatorial\n  Statistics (IWFOS), Santander : Spain (2011)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a nonparametric method for extending functional\nregression methodology to the situation where more than one functional\ncovariate is used to predict a functional response. Borrowing the idea from\nKadri et al. (2010a), the method, which support mixed discrete and continuous\nexplanatory variables, is based on estimating a function-valued function in\nreproducing kernel Hilbert spaces by virtue of positive operator-valued\nkernels.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 07:46:56 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Kadri", "Hachem", "", "INRIA Lille - Nord Europe"], ["Preux", "Philippe", "", "INRIA Lille\n  - Nord Europe, LIFL"], ["Duflos", "Emmanuel", "", "INRIA Lille - Nord Europe, LAGIS"], ["Canu", "St\u00e9phane", "", "LITIS"]]}, {"id": "1301.2659", "submitter": "Fabrice Rossi", "authors": "Romain Guigour\\`es, Marc Boull\\'e, Fabrice Rossi (SAMM)", "title": "A Triclustering Approach for Time Evolving Graphs", "comments": null, "journal-ref": "Co-clustering and Applications International Conference on Data\n  Mining Workshop, Brussels : Belgium (2012)", "doi": "10.1109/ICDMW.2012.61", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel technique to track structures in time evolving\ngraphs. The method is based on a parameter free approach for three-dimensional\nco-clustering of the source vertices, the target vertices and the time. All\nthese features are simultaneously segmented in order to build time segments and\nclusters of vertices whose edge distributions are similar and evolve in the\nsame way over the time segments. The main novelty of this approach lies in that\nthe time segments are directly inferred from the evolution of the edge\ndistribution between the vertices, thus not requiring the user to make an a\npriori discretization. Experiments conducted on a synthetic dataset illustrate\nthe good behaviour of the technique, and a study of a real-life dataset shows\nthe potential of the proposed approach for exploratory data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 07:51:14 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Guigour\u00e8s", "Romain", "", "SAMM"], ["Boull\u00e9", "Marc", "", "SAMM"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1301.2724", "submitter": "Ulrich Paquet", "authors": "Manfred Opper, Ulrich Paquet and Ole Winther", "title": "Perturbative Corrections for Approximate Inference in Gaussian Latent\n  Variable Models", "comments": "45 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation Propagation (EP) provides a framework for approximate inference.\nWhen the model under consideration is over a latent Gaussian field, with the\napproximation being Gaussian, we show how these approximations can\nsystematically be corrected. A perturbative expansion is made of the exact but\nintractable correction, and can be applied to the model's partition function\nand other moments of interest. The correction is expressed over the\nhigher-order cumulants which are neglected by EP's local matching of moments.\nThrough the expansion, we see that EP is correct to first order. By considering\nhigher orders, corrections of increasing polynomial complexity can be applied\nto the approximation. The second order provides a correction in quadratic time,\nwhich we apply to an array of Gaussian process and Ising models. The\ncorrections generalize to arbitrarily complex approximating families, which we\nillustrate on tree-structured Ising model approximations. Furthermore, they\nprovide a polynomial-time assessment of the approximation error. We also\nprovide both theoretical and practical insights on the exactness of the EP\nsolution.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 22:16:36 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 14:15:36 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Opper", "Manfred", ""], ["Paquet", "Ulrich", ""], ["Winther", "Ole", ""]]}, {"id": "1301.2725", "submitter": "Yudong Chen", "authors": "Yudong Chen, Constantine Caramanis, Shie Mannor", "title": "Robust High Dimensional Sparse Regression and Matching Pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high dimensional sparse regression, and develop strategies able\nto deal with arbitrary -- possibly, severe or coordinated -- errors in the\ncovariance matrix $X$. These may come from corrupted data, persistent\nexperimental errors, or malicious respondents in surveys/recommender systems,\netc. Such non-stochastic error-in-variables problems are notoriously difficult\nto treat, and as we demonstrate, the problem is particularly pronounced in\nhigh-dimensional settings where the primary goal is {\\em support recovery} of\nthe sparse regressor. We develop algorithms for support recovery in sparse\nregression, when some number $n_1$ out of $n+n_1$ total covariate/response\npairs are {\\it arbitrarily (possibly maliciously) corrupted}. We are interested\nin understanding how many outliers, $n_1$, we can tolerate, while identifying\nthe correct support. To the best of our knowledge, neither standard outlier\nrejection techniques, nor recently developed robust regression algorithms (that\nfocus only on corrupted response variables), nor recent algorithms for dealing\nwith stochastic noise or erasures, can provide guarantees on support recovery.\nPerhaps surprisingly, we also show that the natural brute force algorithm that\nsearches over all subsets of $n$ covariate/response pairs, and all subsets of\npossible support coordinates in order to minimize regression error, is\nremarkably poor, unable to correctly identify the support with even $n_1 =\nO(n/k)$ corrupted points, where $k$ is the sparsity. This is true even in the\nbasic setting we consider, where all authentic measurements and noise are\nindependent and sub-Gaussian. In this setting, we provide a simple algorithm --\nno more computationally taxing than OMP -- that gives stronger performance\nguarantees, recovering the support with up to $n_1 = O(n/(\\sqrt{k} \\log p))$\ncorrupted points, where $p$ is the dimension of the signal to be recovered.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 22:39:56 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Chen", "Yudong", ""], ["Caramanis", "Constantine", ""], ["Mannor", "Shie", ""]]}, {"id": "1301.2840", "submitter": "Christian Osendorfer", "authors": "Christian Osendorfer and Justin Bayer and Sebastian Urban and Patrick\n  van der Smagt", "title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised feature learning has shown impressive results for a wide range\nof input modalities, in particular for object classification tasks in computer\nvision. Using a large amount of unlabeled data, unsupervised feature learning\nmethods are utilized to construct high-level representations that are\ndiscriminative enough for subsequently trained supervised classification\nalgorithms. However, it has never been \\emph{quantitatively} investigated yet\nhow well unsupervised learning methods can find \\emph{low-level\nrepresentations} for image patches without any additional supervision. In this\npaper we examine the performance of pure unsupervised methods on a low-level\ncorrespondence task, a problem that is central to many Computer Vision\napplications. We find that a special type of Restricted Boltzmann Machines\n(RBMs) performs comparably to hand-crafted descriptors. Additionally, a simple\nbinarization scheme produces compact representations that perform better than\nseveral state-of-the-art descriptors.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 01:34:17 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2013 13:42:10 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 18:54:11 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2013 14:26:04 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Osendorfer", "Christian", ""], ["Bayer", "Justin", ""], ["Urban", "Sebastian", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1301.3043", "submitter": "Vladimir Temlyakov", "authors": "Vladimir Temlyakov", "title": "A remark on covering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG math.FA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss construction of coverings of the unit ball of a finite dimensional\nBanach space. The well known technique of comparing volumes gives upper and\nlower bounds on covering numbers. This technique does not provide a\nconstruction of good coverings. Here we apply incoherent dictionaries for\nconstruction of good coverings. We use the following strategy. First, we build\na good covering by balls with a radius close to one. Second, we iterate this\nconstruction to obtain a good covering for any radius. We mostly concentrate on\nthe first step of this strategy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 13:39:55 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Temlyakov", "Vladimir", ""]]}, {"id": "1301.3078", "submitter": "Paul Larsen", "authors": "Franz Kir\\'aly and Paul Larsen", "title": "Fano schemes of generic intersections and machine learning", "comments": "9 pages, comments very welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Fano schemes of conditionally generic intersections, i.e. of\nhypersurfaces in projective space chosen generically up to additional\nconditions. Via a correspondence between generic properties of algebraic\nvarieties and events in probability spaces that occur with probability one, we\nuse the obtained results on Fano schemes to solve a problem in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 17:57:18 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Kir\u00e1ly", "Franz", ""], ["Larsen", "Paul", ""]]}, {"id": "1301.3192", "submitter": "Joonseok Lee", "authors": "Joonseok Lee, Seungyeon Kim, Guy Lebanon, Yoram Singer", "title": "Matrix Approximation under Local Low-Rank Assumption", "comments": "3 pages, 2 figures, Workshop submission to the First International\n  Conference on Learning Representations (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix approximation is a common tool in machine learning for building\naccurate prediction models for recommendation systems, text mining, and\ncomputer vision. A prevalent assumption in constructing matrix approximations\nis that the partially observed matrix is of low-rank. We propose a new matrix\napproximation model where we assume instead that the matrix is only locally of\nlow-rank, leading to a representation of the observed matrix as a weighted sum\nof low-rank matrices. We analyze the accuracy of the proposed local low-rank\nmodeling. Our experiments show improvements in prediction accuracy in\nrecommendation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 00:54:38 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Lee", "Joonseok", ""], ["Kim", "Seungyeon", ""], ["Lebanon", "Guy", ""], ["Singer", "Yoram", ""]]}, {"id": "1301.3226", "submitter": "Rami Al-Rfou'", "authors": "Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, Steven Skiena", "title": "The Expressive Power of Word Embeddings", "comments": "submitted to ICML 2013, Deep Learning for Audio, Speech and Language\n  Processing Workshop. 8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to better understand the difference in quality of the several\npublicly released embeddings. We propose several tasks that help to distinguish\nthe characteristics of different embeddings. Our evaluation of sentiment\npolarity and synonym/antonym relations shows that embeddings are able to\ncapture surprisingly nuanced semantics even in the absence of sentence\nstructure. Moreover, benchmarking the embeddings shows great variance in\nquality and characteristics of the semantics captured by the tested embeddings.\nFinally, we show the impact of varying the number of dimensions and the\nresolution of each dimension on the effective useful features captured by the\nembedding space. Our contributions highlight the importance of embeddings for\nNLP tasks and the effect of their quality on the final results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 04:52:10 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2013 21:44:29 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2013 17:08:14 GMT"}, {"version": "v4", "created": "Wed, 29 May 2013 21:06:09 GMT"}], "update_date": "2013-05-31", "authors_parsed": [["Chen", "Yanqing", ""], ["Perozzi", "Bryan", ""], ["Al-Rfou", "Rami", ""], ["Skiena", "Steven", ""]]}, {"id": "1301.3342", "submitter": "Laurens van der Maaten", "authors": "Laurens van der Maaten", "title": "Barnes-Hut-SNE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an O(N log N)-implementation of t-SNE -- an embedding\ntechnique that is commonly used for the visualization of high-dimensional data\nin scatter plots and that normally runs in O(N^2). The new implementation uses\nvantage-point trees to compute sparse pairwise similarities between the input\ndata objects, and it uses a variant of the Barnes-Hut algorithm - an algorithm\nused by astronomers to perform N-body simulations - to approximate the forces\nbetween the corresponding points in the embedding. Our experiments show that\nthe new algorithm, called Barnes-Hut-SNE, leads to substantial computational\nadvantages over standard t-SNE, and that it makes it possible to learn\nembeddings of data sets with millions of objects.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 13:44:18 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 11:00:32 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["van der Maaten", "Laurens", ""]]}, {"id": "1301.3347", "submitter": "Michalis Smyrnakis", "authors": "Michalis Smyrnakis", "title": "Multi-agent learning using Fictitious Play and Extended Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralised optimisation tasks are important components of multi-agent\nsystems. These tasks can be interpreted as n-player potential games: therefore\ngame-theoretic learning algorithms can be used to solve decentralised\noptimisation tasks. Fictitious play is the canonical example of these\nalgorithms. Nevertheless fictitious play implicitly assumes that players have\nstationary strategies. We present a novel variant of fictitious play where\nplayers predict their opponents' strategies using Extended Kalman filters and\nuse their predictions to update their strategies.\n  We show that in 2 by 2 games with at least one pure Nash equilibrium and in\npotential games where players have two available actions, the proposed\nalgorithm converges to the pure Nash equilibrium. The performance of the\nproposed algorithm was empirically tested, in two strategic form games and an\nad-hoc sensor network surveillance problem. The proposed algorithm performs\nbetter than the classic fictitious play algorithm in these games and therefore\nimproves the performance of game-theoretical learning in decentralised\noptimisation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 14:00:55 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Smyrnakis", "Michalis", ""]]}, {"id": "1301.3468", "submitter": "KyungHyun Cho", "authors": "Kyunghyun Cho", "title": "Boltzmann Machines and Denoising Autoencoders for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising based on a probabilistic model of local image patches has\nbeen employed by various researchers, and recently a deep (denoising)\nautoencoder has been proposed by Burger et al. [2012] and Xie et al. [2012] as\na good model for this. In this paper, we propose that another popular family of\nmodels in the field of deep learning, called Boltzmann machines, can perform\nimage denoising as well as, or in certain cases of high level of noise, better\nthan denoising autoencoders. We empirically evaluate the two models on three\ndifferent sets of images with different types and levels of noise. Throughout\nthe experiments we also examine the effect of the depth of the models. The\nexperiments confirmed our claim and revealed that the performance can be\nimproved by adding more hidden layers, especially when the level of noise is\nhigh.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 19:45:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 15:37:08 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2013 13:48:22 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2013 16:35:56 GMT"}, {"version": "v5", "created": "Thu, 14 Feb 2013 11:16:34 GMT"}, {"version": "v6", "created": "Mon, 4 Mar 2013 10:41:34 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Cho", "Kyunghyun", ""]]}, {"id": "1301.3476", "submitter": "Tommi Vatanen", "authors": "Tommi Vatanen, Tapani Raiko, Harri Valpola, Yann LeCun", "title": "Pushing Stochastic Gradient towards Second-Order Methods --\n  Backpropagation Learning with Transformations in Nonlinearities", "comments": "10 pages, 5 figures, ICLR2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we proposed to transform the outputs of each hidden neuron in a\nmulti-layer perceptron network to have zero output and zero slope on average,\nand use separate shortcut connections to model the linear dependencies instead.\nWe continue the work by firstly introducing a third transformation to normalize\nthe scale of the outputs of each hidden neuron, and secondly by analyzing the\nconnections to second order optimization methods. We show that the\ntransformations make a simple stochastic gradient behave closer to second-order\noptimization methods and thus speed up learning. This is shown both in theory\nand with experiments. The experiments on the third transformation show that\nwhile it further increases the speed of learning, it can also hurt performance\nby converging to a worse local optimum, where both the inputs and outputs of\nmany hidden neurons are close to zero.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 20:21:54 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 09:23:23 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 18:00:00 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Vatanen", "Tommi", ""], ["Raiko", "Tapani", ""], ["Valpola", "Harri", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3514", "submitter": "H\\'ector Corrada Bravo", "authors": "Wikum Dinalankara and Hector Corrada Bravo", "title": "Anomaly Classification with the Anti-Profile Support Vector Machine", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the anti-profile Support Vector Machine (apSVM) as a novel\nalgorithm to address the anomaly classification problem, an extension of\nanomaly detection where the goal is to distinguish data samples from a number\nof anomalous and heterogeneous classes based on their pattern of deviation from\na normal stable class. We show that under heterogeneity assumptions defined\nhere that the apSVM can be solved as the dual of a standard SVM with an\nindirect kernel that measures similarity of anomalous samples through\nsimilarity to the stable normal class. We characterize this indirect kernel as\nthe inner product in a Reproducing Kernel Hilbert Space between representers\nthat are projected to the subspace spanned by the representers of the normal\nsamples. We show by simulation and application to cancer genomics datasets that\nthe anti-profile SVM produces classifiers that are more accurate and stable\nthan the standard SVM in the anomaly classification setting.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 22:07:45 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Dinalankara", "Wikum", ""], ["Bravo", "Hector Corrada", ""]]}, {"id": "1301.3528", "submitter": "Momiao Xiong", "authors": "Momiao Xiong and Long Ma", "title": "An Efficient Sufficient Dimension Reduction Method for Identifying\n  Genetic Variants of Clinical Significance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and cheaper next generation sequencing technologies will generate\nunprecedentedly massive and highly-dimensional genomic and epigenomic variation\ndata. In the near future, a routine part of medical record will include the\nsequenced genomes. A fundamental question is how to efficiently extract genomic\nand epigenomic variants of clinical utility which will provide information for\noptimal wellness and interference strategies. Traditional paradigm for\nidentifying variants of clinical validity is to test association of the\nvariants. However, significantly associated genetic variants may or may not be\nusefulness for diagnosis and prognosis of diseases. Alternative to association\nstudies for finding genetic variants of predictive utility is to systematically\nsearch variants that contain sufficient information for phenotype prediction.\nTo achieve this, we introduce concepts of sufficient dimension reduction and\ncoordinate hypothesis which project the original high dimensional data to very\nlow dimensional space while preserving all information on response phenotypes.\nWe then formulate clinically significant genetic variant discovery problem into\nsparse SDR problem and develop algorithms that can select significant genetic\nvariants from up to or even ten millions of predictors with the aid of dividing\nSDR for whole genome into a number of subSDR problems defined for genomic\nregions. The sparse SDR is in turn formulated as sparse optimal scoring\nproblem, but with penalty which can remove row vectors from the basis matrix.\nTo speed up computation, we develop the modified alternating direction method\nfor multipliers to solve the sparse optimal scoring problem which can easily be\nimplemented in parallel. To illustrate its application, the proposed method is\napplied to simulation data and the NHLBI's Exome Sequencing Project dataset\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 23:19:14 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Xiong", "Momiao", ""], ["Ma", "Long", ""]]}, {"id": "1301.3529", "submitter": "Guido F.  Montufar", "authors": "Guido Montufar and Jason Morton", "title": "Discrete Restricted Boltzmann Machines", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.AG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe discrete restricted Boltzmann machines: probabilistic graphical\nmodels with bipartite interactions between visible and hidden discrete\nvariables. Examples are binary restricted Boltzmann machines and discrete naive\nBayes models. We detail the inference functions and distributed representations\narising in these models in terms of configurations of projected products of\nsimplices and normal fans of products of simplices. We bound the number of\nhidden variables, depending on the cardinalities of their state spaces, for\nwhich these models can approximate any probability distribution on their\nvisible states to any given accuracy. In addition, we use algebraic methods and\ncoding theory to compute their dimension.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 23:27:08 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 03:57:46 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2013 02:07:49 GMT"}, {"version": "v4", "created": "Tue, 22 Apr 2014 17:43:56 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Montufar", "Guido", ""], ["Morton", "Jason", ""]]}, {"id": "1301.3533", "submitter": "Xanadu Halkias", "authors": "Xanadu Halkias, Sebastien Paris, Herve Glotin", "title": "Sparse Penalty in Deep Belief Networks: Using the Mixed Norm Constraint", "comments": "8 pages, 7 figures (including subfigures), ICleaR conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Belief Networks (DBN) have been successfully applied on popular machine\nlearning tasks. Specifically, when applied on hand-written digit recognition,\nDBNs have achieved approximate accuracy rates of 98.8%. In an effort to\noptimize the data representation achieved by the DBN and maximize their\ndescriptive power, recent advances have focused on inducing sparse constraints\nat each layer of the DBN. In this paper we present a theoretical approach for\nsparse constraints in the DBN using the mixed norm for both non-overlapping and\noverlapping groups. We explore how these constraints affect the classification\naccuracy for digit recognition in three different datasets (MNIST, USPS, RIMES)\nand provide initial estimations of their usefulness by altering different\nparameters such as the group size and overlap percentage.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 00:12:21 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 10:18:15 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Halkias", "Xanadu", ""], ["Paris", "Sebastien", ""], ["Glotin", "Herve", ""]]}, {"id": "1301.3541", "submitter": "Rakesh Chalasani", "authors": "Rakesh Chalasani and Jose C. Principe", "title": "Deep Predictive Coding Networks", "comments": "13 Pages, 7 figures, submission for ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of data representation in deep learning methods is directly\nrelated to the prior model imposed on the representations; however, generally\nused fixed priors are not capable of adjusting to the context in the data. To\naddress this issue, we propose deep predictive coding networks, a hierarchical\ngenerative model that empirically alters priors on the latent representations\nin a dynamic and context-sensitive manner. This model captures the temporal\ndependencies in time-varying signals and uses top-down information to modulate\nthe representation in lower layers. The centerpiece of our model is a novel\nprocedure to infer sparse states of a dynamic model which is used for feature\nextraction. We also extend this feature extraction block to introduce a pooling\nfunction that captures locally invariant representations. When applied on a\nnatural video data, we show that our method is able to learn high-level visual\nfeatures. We also demonstrate the role of the top-down connections by showing\nthe robustness of the proposed model to structured noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:27:15 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 01:29:17 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2013 19:25:30 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Chalasani", "Rakesh", ""], ["Principe", "Jose C.", ""]]}, {"id": "1301.3545", "submitter": "Guillaume Desjardins", "authors": "Guillaume Desjardins, Razvan Pascanu, Aaron Courville and Yoshua\n  Bengio", "title": "Metric-Free Natural Gradient for Joint-Training of Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Metric-Free Natural Gradient (MFNG) algorithm for\ntraining Boltzmann Machines. Similar in spirit to the Hessian-Free method of\nMartens [8], our algorithm belongs to the family of truncated Newton methods\nand exploits an efficient matrix-vector product to avoid explicitely storing\nthe natural gradient metric $L$. This metric is shown to be the expected second\nderivative of the log-partition function (under the model distribution), or\nequivalently, the variance of the vector of partial derivatives of the energy\nfunction. We evaluate our method on the task of joint-training a 3-layer Deep\nBoltzmann Machine and show that MFNG does indeed have faster per-epoch\nconvergence compared to Stochastic Maximum Likelihood with centering, though\nwall-clock performance is currently not competitive.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:40:20 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 16:07:12 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Desjardins", "Guillaume", ""], ["Pascanu", "Razvan", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3547", "submitter": "Benjamin Englard", "authors": "Benjamin Englard", "title": "A Rhetorical Analysis Approach to Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this research was to find a way to extend the capabilities of\ncomputers through the processing of language in a more human way, and present\napplications which demonstrate the power of this method. This research presents\na novel approach, Rhetorical Analysis, to solving problems in Natural Language\nProcessing (NLP). The main benefit of Rhetorical Analysis, as opposed to\nprevious approaches, is that it does not require the accumulation of large sets\nof training data, but can be used to solve a multitude of problems within the\nfield of NLP. The NLP problems investigated with Rhetorical Analysis were the\nAuthor Identification problem - predicting the author of a piece of text based\non its rhetorical strategies, Election Prediction - predicting the winner of a\npresidential candidate's re-election campaign based on rhetorical strategies\nwithin that president's inaugural address, Natural Language Generation - having\na computer produce text containing rhetorical strategies, and Document\nSummarization. The results of this research indicate that an Author\nIdentification system based on Rhetorical Analysis could predict the correct\nauthor 100% of the time, that a re-election predictor based on Rhetorical\nAnalysis could predict the correct winner of a re-election campaign 55% of the\ntime, that a Natural Language Generation system based on Rhetorical Analysis\ncould output text with up to 87.3% similarity to Shakespeare in style, and that\na Document Summarization system based on Rhetorical Analysis could extract\nhighly relevant sentences. Overall, this study demonstrated that Rhetorical\nAnalysis could be a useful approach to solving problems in NLP.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:42:53 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Englard", "Benjamin", ""]]}, {"id": "1301.3557", "submitter": "Matthew Zeiler", "authors": "Matthew D. Zeiler and Rob Fergus", "title": "Stochastic Pooling for Regularization of Deep Convolutional Neural\n  Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and effective method for regularizing large\nconvolutional neural networks. We replace the conventional deterministic\npooling operations with a stochastic procedure, randomly picking the activation\nwithin each pooling region according to a multinomial distribution, given by\nthe activities within the pooling region. The approach is hyper-parameter free\nand can be combined with other regularization approaches, such as dropout and\ndata augmentation. We achieve state-of-the-art performance on four image\ndatasets, relative to other approaches that do not utilize data augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 02:12:07 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Zeiler", "Matthew D.", ""], ["Fergus", "Rob", ""]]}, {"id": "1301.3558", "submitter": "Heng Peng", "authors": "Tao Huang, Heng Peng and Kun Zhang", "title": "Model Selection for Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with an important issue in finite mixture modelling,\nthe selection of the number of mixing components. We propose a new penalized\nlikelihood method for model selection of finite multivariate Gaussian mixture\nmodels. The proposed method is shown to be statistically consistent in\ndetermining of the number of components. A modified EM algorithm is developed\nto simultaneously select the number of components and to estimate the mixing\nweights, i.e. the mixing probabilities, and unknown parameters of Gaussian\ndistributions. Simulations and a real data analysis are presented to illustrate\nthe performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 02:17:58 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Huang", "Tao", ""], ["Peng", "Heng", ""], ["Zhang", "Kun", ""]]}, {"id": "1301.3568", "submitter": "Ian Goodfellow", "authors": "Ian J. Goodfellow and Aaron Courville and Yoshua Bengio", "title": "Joint Training Deep Boltzmann Machines for Classification", "comments": "Major revision with new techniques and experiments. This version\n  includes new material put on the poster for the ICLR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods of training DBMs require an initial learning pass that trains the model\ngreedily, one layer at a time, or do not perform well on classification tasks.\nIn our approach, we train all layers of the DBM simultaneously, using a novel\ntraining procedure called multi-prediction training. The resulting model can\neither be interpreted as a single generative model trained to maximize a\nvariational approximation to the generalized pseudolikelihood, or as a family\nof recurrent networks that share parameters and may be approximately averaged\ntogether using a novel technique we call the multi-inference trick. We show\nthat our approach performs competitively for classification and outperforms\nprevious methods in terms of accuracy of approximate inference and\nclassification with missing inputs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 03:21:27 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2013 18:43:00 GMT"}, {"version": "v3", "created": "Wed, 1 May 2013 04:48:20 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Goodfellow", "Ian J.", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3570", "submitter": "John Paisley", "authors": "John Paisley, Chong Wang, David Blei, Michael I. Jordan", "title": "A Nested HDP for Hierarchical Topic Models", "comments": "Submitted to the workshop track of the International Conference on\n  Learning Representations 2013. It is a short version of a longer paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical\ntopic modeling. The nHDP is a generalization of the nested Chinese restaurant\nprocess (nCRP) that allows each word to follow its own path to a topic node\naccording to a document-specific distribution on a shared tree. This alleviates\nthe rigid, single-path formulation of the nCRP, allowing a document to more\neasily express thematic borrowings as a random effect. We demonstrate our\nalgorithm on 1.8 million documents from The New York Times.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 03:24:43 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Paisley", "John", ""], ["Wang", "Chong", ""], ["Blei", "David", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.3575", "submitter": "Boyi Xie", "authors": "Boyi Xie, Shuheng Zheng", "title": "Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale agglomerative clustering is hindered by computational burdens. We\npropose a novel scheme where exact inter-instance distance calculation is\nreplaced by the Hamming distance between Kernelized Locality-Sensitive Hashing\n(KLSH) hashed values. This results in a method that drastically decreases\ncomputation time. Additionally, we take advantage of certain labeled data\npoints via distance metric learning to achieve a competitive precision and\nrecall comparing to K-Means but in much less computation time.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 03:52:09 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Xie", "Boyi", ""], ["Zheng", "Shuheng", ""]]}, {"id": "1301.3611", "submitter": "Sebastian Hitziger", "authors": "Sebastian Hitziger, Maureen Clerc, Alexandre Gramfort, Sandrine\n  Saillet, Christian B\\'enar, Th\\'eodore Papadopoulo", "title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial\n  Neuroelectric Signals", "comments": "9 pages, 5 figures, minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary Learning has proven to be a powerful tool for many image\nprocessing tasks, where atoms are typically defined on small image patches. As\na drawback, the dictionary only encodes basic structures. In addition, this\napproach treats patches of different locations in one single set, which means a\nloss of information when features are well-aligned across signals. This is the\ncase, for instance, in multi-trial magneto- or electroencephalography (M/EEG).\nLearning the dictionary on the entire signals could make use of the alignement\nand reveal higher-level features. In this case, however, small missalignements\nor phase variations of features would not be compensated for. In this paper, we\npropose an extension to the common dictionary learning framework to overcome\nthese limitations by allowing atoms to adapt their position across signals. The\nmethod is validated on simulated and real neuroelectric data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 07:41:08 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2013 17:44:00 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2013 18:59:29 GMT"}, {"version": "v4", "created": "Mon, 24 Jun 2013 13:12:37 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Hitziger", "Sebastian", ""], ["Clerc", "Maureen", ""], ["Gramfort", "Alexandre", ""], ["Saillet", "Sandrine", ""], ["B\u00e9nar", "Christian", ""], ["Papadopoulo", "Th\u00e9odore", ""]]}, {"id": "1301.3641", "submitter": "Ryan Kiros", "authors": "Ryan Kiros", "title": "Training Neural Networks with Stochastic Hessian-Free Optimization", "comments": "11 pages, ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hessian-free (HF) optimization has been successfully used for training deep\nautoencoders and recurrent networks. HF uses the conjugate gradient algorithm\nto construct update directions through curvature-vector products that can be\ncomputed on the same order of time as gradients. In this paper we exploit this\nproperty and study stochastic HF with gradient and curvature mini-batches\nindependent of the dataset size. We modify Martens' HF for these settings and\nintegrate dropout, a method for preventing co-adaptation of feature detectors,\nto guard against overfitting. Stochastic Hessian-free optimization gives an\nintermediary between SGD and HF that achieves competitive performance on both\nclassification and deep autoencoder experiments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 10:10:23 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 05:51:37 GMT"}, {"version": "v3", "created": "Wed, 1 May 2013 06:57:50 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Kiros", "Ryan", ""]]}, {"id": "1301.3764", "submitter": "Tom Schaul", "authors": "Tom Schaul, Yann LeCun", "title": "Adaptive learning rates and parallelization for stochastic, sparse,\n  non-smooth gradients", "comments": "Published at the First International Conference on Learning\n  Representations (ICLR-2013). Public reviews are available at\n  http://openreview.net/document/c14f2204-fd66-4d91-bed4-153523694041#c14f2204-fd66-4d91-bed4-153523694041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has established an empirically successful framework for adapting\nlearning rates for stochastic gradient descent (SGD). This effectively removes\nall needs for tuning, while automatically reducing learning rates over time on\nstationary problems, and permitting learning rates to grow appropriately in\nnon-stationary tasks. Here, we extend the idea in three directions, addressing\nproper minibatch parallelization, including reweighted updates for sparse or\northogonal gradients, improving robustness on non-smooth loss functions, in the\nprocess replacing the diagonal Hessian estimation procedure that may not always\nbe available by a robust finite-difference approximation. The final algorithm\nintegrates all these components, has linear complexity and is hyper-parameter\nfree.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 17:48:38 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 18:30:41 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["Schaul", "Tom", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3833", "submitter": "Christophe Andrieu", "authors": "Christophe Andrieu, Nando de Freitas, Arnaud Doucet", "title": "Reversible Jump MCMC Simulated Annealing for Neural Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-11-18", "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reversible jump Markov chain Monte Carlo (MCMC) simulated\nannealing algorithm to optimize radial basis function (RBF) networks. This\nalgorithm enables us to maximize the joint posterior distribution of the\nnetwork parameters and the number of basis functions. It performs a global\nsearch in the joint space of the parameters and number of parameters, thereby\nsurmounting the problem of local minima. We also show that by calibrating a\nBayesian model, we can obtain the classical AIC, BIC and MDL model selection\ncriteria within a penalized likelihood framework. Finally, we show\ntheoretically and empirically that the algorithm converges to the modes of the\nfull posterior distribution in an efficient way.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:42 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Andrieu", "Christophe", ""], ["de Freitas", "Nando", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1301.3837", "submitter": "Jeff A. Bilmes", "authors": "Jeff A. Bilmes", "title": "Dynamic Bayesian Multinets", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-38-45", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, dynamic Bayesian multinets are introduced where a Markov chain\nstate at time t determines conditional independence patterns between random\nvariables lying within a local time window surrounding t. It is shown how\ninformation-theoretic criterion functions can be used to induce sparse,\ndiscriminative, and class-conditional network structures that yield an optimal\napproximation to the class posterior probability, and therefore are useful for\nthe classification task. Using a new structure learning heuristic, the\nresulting models are tested on a medium-vocabulary isolated-word speech\nrecognition task. It is demonstrated that these discriminatively structured\ndynamic Bayesian multinets, when trained in a maximum likelihood setting using\nEM, can outperform both HMMs and other dynamic Bayesian networks with a similar\nnumber of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:59 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bilmes", "Jeff A.", ""]]}, {"id": "1301.3838", "submitter": "Christopher M. Bishop", "authors": "Christopher M. Bishop, Michael Tipping", "title": "Variational Relevance Vector Machines", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-46-53", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Support Vector Machine (SVM) of Vapnik (1998) has become widely\nestablished as one of the leading approaches to pattern recognition and machine\nlearning. It expresses predictions in terms of a linear combination of kernel\nfunctions centred on a subset of the training data, known as support vectors.\n  Despite its widespread success, the SVM suffers from some important\nlimitations, one of the most significant being that it makes point predictions\nrather than generating predictive distributions. Recently Tipping (1999) has\nformulated the Relevance Vector Machine (RVM), a probabilistic model whose\nfunctional form is equivalent to the SVM. It achieves comparable recognition\naccuracy to the SVM, yet provides a full predictive distribution, and also\nrequires substantially fewer kernel functions.\n  The original treatment of the RVM relied on the use of type II maximum\nlikelihood (the `evidence framework') to provide point estimates of the\nhyperparameters which govern model sparsity. In this paper we show how the RVM\ncan be formulated and solved within a completely Bayesian paradigm through the\nuse of variational inference, thereby giving a posterior distribution over both\nparameters and hyperparameters. We demonstrate the practicality and performance\nof the variational RVM using both synthetic and real world examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:03 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bishop", "Christopher M.", ""], ["Tipping", "Michael", ""]]}, {"id": "1301.3843", "submitter": "Frans Coetzee", "authors": "Frans Coetzee, Steve Lawrence, C. Lee Giles", "title": "Bayesian Classification and Feature Selection from Finite Data Sets", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-89-97", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection aims to select the smallest subset of features for a\nspecified level of performance. The optimal achievable classification\nperformance on a feature subset is summarized by its Receiver Operating Curve\n(ROC). When infinite data is available, the Neyman- Pearson (NP) design\nprocedure provides the most efficient way of obtaining this curve. In practice\nthe design procedure is applied to density estimates from finite data sets. We\nperform a detailed statistical analysis of the resulting error propagation on\nfinite alphabets. We show that the estimated performance curve (EPC) produced\nby the design procedure is arbitrarily accurate given sufficient data,\nindependent of the size of the feature set. However, the underlying likelihood\nranking procedure is highly sensitive to errors that reduces the probability\nthat the EPC is in fact the ROC. In the worst case, guaranteeing that the EPC\nis equal to the ROC may require data sizes exponential in the size of the\nfeature set. These results imply that in theory the NP design approach may only\nbe valid for characterizing relatively small feature subsets, even when the\nperformance of any given classifier can be estimated very accurately. We\ndiscuss the practical limitations for on-line methods that ensures that the NP\nprocedure operates in a statistically valid region.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:23 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Coetzee", "Frans", ""], ["Lawrence", "Steve", ""], ["Giles", "C. Lee", ""]]}, {"id": "1301.3849", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta", "title": "Experiments with Random Projection", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-143-151", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical work has identified random projection as a promising\ndimensionality reduction technique for learning mixtures of Gausians. Here we\nsummarize these results and illustrate them by a wide variety of experiments on\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:46 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Dasgupta", "Sanjoy", ""]]}, {"id": "1301.3850", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta, Leonard Schulman", "title": "A Two-round Variant of EM for Gaussian Mixtures", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-152-159", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of possible models (e.g., Bayesian network structures) and a data\nsample, in the unsupervised model selection problem the task is to choose the\nmost accurate model with respect to the domain joint probability distribution.\nIn contrast to this, in supervised model selection it is a priori known that\nthe chosen model will be used in the future for prediction tasks involving more\n``focused' predictive distributions. Although focused predictive distributions\ncan be produced from the joint probability distribution by marginalization, in\npractice the best model in the unsupervised sense does not necessarily perform\nwell in supervised domains. In particular, the standard marginal likelihood\nscore is a criterion for the unsupervised task, and, although frequently used\nfor supervised model selection also, does not perform well in such tasks. In\nthis paper we study the performance of the marginal likelihood score\nempirically in supervised Bayesian network selection tasks by using a large\nnumber of publicly available classification data sets, and compare the results\nto those obtained by alternative model selection criteria, including empirical\ncrossvalidation methods, an approximation of a supervised marginal likelihood\nmeasure, and a supervised version of Dawids prequential(predictive sequential)\nprinciple.The results demonstrate that the marginal likelihood score does NOT\nperform well FOR supervised model selection, WHILE the best results are\nobtained BY using Dawids prequential r napproach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:50 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Schulman", "Leonard", ""]]}, {"id": "1301.3851", "submitter": "Ian Davidson", "authors": "Ian Davidson", "title": "Minimum Message Length Clustering Using Gibbs Sampling", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-160-167", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The K-Mean and EM algorithms are popular in clustering and mixture modeling,\ndue to their simplicity and ease of implementation. However, they have several\nsignificant limitations. Both coverage to a local optimum of their respective\nobjective functions (ignoring the uncertainty in the model space), require the\napriori specification of the number of classes/clsuters, and are inconsistent.\nIn this work we overcome these limitations by using the Minimum Message Length\n(MML) principle and a variation to the K-Means/EM observation assignment and\nparameter calculation scheme. We maintain the simplicity of these approaches\nwhile constructing a Bayesian mixture modeling tool that samples/searches the\nmodel space using a Markov Chain Monte Carlo (MCMC) sampler known as a Gibbs\nsampler. Gibbs sampling allows us to visit each model according to its\nposterior probability. Therefore, if the model space is multi-modal we will\nvisit all models and not get stuck in local optima. We call our approach\nmultiple chains at equilibrium (MCE) MML sampling.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:54 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Davidson", "Ian", ""]]}, {"id": "1301.3852", "submitter": "Scott Davies", "authors": "Scott Davies, Andrew Moore", "title": "Mix-nets: Factored Mixtures of Gaussians in Bayesian Networks With Mixed\n  Continuous And Discrete Variables", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-168-175", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed techniques have made it possible to quickly learn accurate\nprobability density functions from data in low-dimensional continuous space. In\nparticular, mixtures of Gaussians can be fitted to data very quickly using an\naccelerated EM algorithm that employs multiresolution kd-trees (Moore, 1999).\nIn this paper, we propose a kind of Bayesian networks in which low-dimensional\nmixtures of Gaussians over different subsets of the domain's variables are\ncombined into a coherent joint probability model over the entire domain. The\nnetwork is also capable of modeling complex dependencies between discrete\nvariables and continuous variables without requiring discretization of the\ncontinuous variables. We present efficient heuristic algorithms for\nautomatically learning these networks from data, and perform comparative\nexperiments illustrated how well these networks model real scientific data and\nsynthetic data. We also briefly discuss some possible improvements to the\nnetworks, as well as possible applications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:57 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Davies", "Scott", ""], ["Moore", "Andrew", ""]]}, {"id": "1301.3854", "submitter": "Brendan J. Frey", "authors": "Brendan J. Frey, Nebojsa Jojic", "title": "Learning Graphical Models of Images, Videos and Their Spatial\n  Transformations", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-184-191", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of Gaussians, factor analyzers (probabilistic PCA) and hidden Markov\nmodels are staples of static and dynamic data modeling and image and video\nmodeling in particular. We show how topographic transformations in the input,\nsuch as translation and shearing in images, can be accounted for in these\nmodels by including a discrete transformation variable. The resulting models\nperform clustering, dimensionality reduction and time-series analysis in a way\nthat is invariant to transformations in the input. Using the EM algorithm,\nthese transformation-invariant models can be fit to static data and time\nseries. We give results on filtering microscopy images, face and facial pose\nclustering, handwritten digit modeling and recognition, video clustering,\nobject tracking, and removal of distractions from video sequences.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:06 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Frey", "Brendan J.", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "1301.3856", "submitter": "Nir Friedman", "authors": "Nir Friedman, Daphne Koller", "title": "Being Bayesian about Network Structure", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-201-210", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, we are interested in analyzing the structure of the\nunderlying distribution, e.g., whether one variable is a direct parent of the\nother. Bayesian model-selection attempts to find the MAP model and use its\nstructure to answer these questions. However, when the amount of available data\nis modest, there might be many models that have non-negligible posterior. Thus,\nwe want compute the Bayesian posterior of a feature, i.e., the total posterior\nprobability of all models that contain it. In this paper, we propose a new\napproach for this task. We first show how to efficiently compute a sum over the\nexponential number of networks that are consistent with a fixed ordering over\nnetwork variables. This allows us to compute, for a given ordering, both the\nmarginal probability of the data and the posterior of a feature. We then use\nthis result as the basis for an algorithm that approximates the Bayesian\nposterior of a feature. Our approach uses a Markov Chain Monte Carlo (MCMC)\nmethod, but over orderings rather than over network structures. The space of\norderings is much smaller and more regular than the space of structures, and\nhas a smoother posterior `landscape'. We present empirical results on synthetic\nand real-life datasets that compare our approach to full model averaging (when\npossible), to MCMC over network structures, and to a non-Bayesian bootstrap\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:14 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.3857", "submitter": "Nir Friedman", "authors": "Nir Friedman, Iftach Nachman", "title": "Gaussian Process Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-211-219", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of learning the structure of a Bayesian\nnetwork in domains with continuous variables. This task requires a procedure\nfor comparing different candidate structures. In the Bayesian framework, this\nis done by evaluating the {em marginal likelihood/} of the data given a\ncandidate structure. This term can be computed in closed-form for standard\nparametric families (e.g., Gaussians), and can be approximated, at some\ncomputational cost, for some semi-parametric families (e.g., mixtures of\nGaussians).\n  We present a new family of continuous variable probabilistic networks that\nare based on {em Gaussian Process/} priors. These priors are semi-parametric in\nnature and can learn almost arbitrary noisy functional relations. Using these\npriors, we can directly compute marginal likelihoods for structure learning.\nThe resulting method can discover a wide range of functional dependencies in\nmultivariate data. We develop the Bayesian score of Gaussian Process Networks\nand describe how to learn them from data. We present empirical results on\nartificial data as well as on real-life domains with non-linear dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:18 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Nachman", "Iftach", ""]]}, {"id": "1301.3865", "submitter": "Tony S. Jebara", "authors": "Tony S. Jebara, Tommi S. Jaakkola", "title": "Feature Selection and Dualities in Maximum Entropy Discrimination", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-291-300", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating feature selection into a classification or regression method\noften carries a number of advantages. In this paper we formalize feature\nselection specifically from a discriminative perspective of improving\nclassification/regression accuracy. The feature selection method is developed\nas an extension to the recently proposed maximum entropy discrimination (MED)\nframework. We describe MED as a flexible (Bayesian) regularization approach\nthat subsumes, e.g., support vector classification, regression and exponential\nfamily models. For brevity, we restrict ourselves primarily to feature\nselection in the context of linear classification/regression methods and\ndemonstrate that the proposed approach indeed carries substantial improvements\nin practice. Moreover, we discuss and develop various extensions of feature\nselection, including the problem of dealing with example specific but\nunobserved degrees of freedom -- alignments or invariants.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:50 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Jebara", "Tony S.", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.3875", "submitter": "Marina Meila", "authors": "Marina Meila, Tommi S. Jaakkola", "title": "Tractable Bayesian Learning of Tree Belief Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-380-388", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present decomposable priors, a family of priors over\nstructure and parameters of tree belief nets for which Bayesian learning with\ncomplete observations is tractable, in the sense that the posterior is also\ndecomposable and can be completely determined analytically in polynomial time.\nThis follows from two main results: First, we show that factored distributions\nover spanning trees in a graph can be integrated in closed form. Second, we\nexamine priors over tree parameters and show that a set of assumptions similar\nto (Heckerman and al. 1995) constrain the tree parameter priors to be a\ncompactly parameterized product of Dirichlet distributions. Beside allowing for\nexact Bayesian learning, these results permit us to formulate a new class of\ntractable latent variable models in which the likelihood of a data point is\ncomputed through an ensemble average over tree structures.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Meila", "Marina", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.3877", "submitter": "Andrew Moore", "authors": "Andrew Moore", "title": "The Anchors Hierachy: Using the triangle inequality to survive high\n  dimensional data", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-397-405", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about metric data structures in high-dimensional or\nnon-Euclidean space that permit cached sufficient statistics accelerations of\nlearning algorithms.\n  It has recently been shown that for less than about 10 dimensions, decorating\nkd-trees with additional \"cached sufficient statistics\" such as first and\nsecond moments and contingency tables can provide satisfying acceleration for a\nvery wide range of statistical learning tasks such as kernel regression,\nlocally weighted regression, k-means clustering, mixture modeling and Bayes Net\nlearning.\n  In this paper, we begin by defining the anchors hierarchy - a fast data\nstructure and algorithm for localizing data based only on a\ntriangle-inequality-obeying distance metric. We show how this, in its own\nright, gives a fast and effective clustering of data. But more importantly we\nshow how it can produce a well-balanced structure similar to a Ball-Tree\n(Omohundro, 1991) or a kind of metric tree (Uhlmann, 1991; Ciaccia, Patella, &\nZezula, 1997) in a way that is neither \"top-down\" nor \"bottom-up\" but instead\n\"middle-out\". We then show how this structure, decorated with cached sufficient\nstatistics, allows a wide variety of statistical learning algorithms to be\naccelerated even in thousands of dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Moore", "Andrew", ""]]}, {"id": "1301.3882", "submitter": "Luis E. Ortiz", "authors": "Luis E. Ortiz, Leslie Pack Kaelbling", "title": "Adaptive Importance Sampling for Estimation in Structured Domains", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-446-454", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is an important tool for estimating large, complex sums and\nintegrals over high dimensional spaces. For instance, important sampling has\nbeen used as an alternative to exact methods for inference in belief networks.\nIdeally, we want to have a sampling distribution that provides optimal-variance\nestimators. In this paper, we present methods that improve the sampling\ndistribution by systematically adapting it as we obtain information from the\nsamples. We present a stochastic-gradient-descent method for sequentially\nupdating the sampling distribution based on the direct minization of the\nvariance. We also present other stochastic-gradient-descent methods based on\nthe minimizationof typical notions of distance between the current sampling\ndistribution and approximations of the target, optimal distribution. We finally\nvalidate and compare the different methods empirically by applying them to the\nproblem of action evaluation in influence diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:58 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Ortiz", "Luis E.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1301.3890", "submitter": "Dale Schuurmans", "authors": "Dale Schuurmans, Finnegan Southey", "title": "Monte Carlo Inference via Greedy Importance Sampling", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-523-532", "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for conducting Monte Carlo inference in graphical\nmodels which combines explicit search with generalized importance sampling. The\nidea is to reduce the variance of importance sampling by searching for\nsignificant points in the target distribution. We prove that it is possible to\nintroduce search and still maintain unbiasedness. We then demonstrate our\nprocedure on a few simple inference tasks and show that it can improve the\ninference quality of standard MCMC methods, including Gibbs sampling,\nMetropolis sampling, and Hybrid Monte Carlo. This paper extends previous work\nwhich showed how greedy importance sampling could be correctly realized in the\none-dimensional case.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Schuurmans", "Dale", ""], ["Southey", "Finnegan", ""]]}, {"id": "1301.3891", "submitter": "Marc Sebban", "authors": "Marc Sebban, Richard Nock", "title": "Combining Feature and Prototype Pruning by Uncertainty Minimization", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-533-540", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus in this paper on dataset reduction techniques for use in k-nearest\nneighbor classification. In such a context, feature and prototype selections\nhave always been independently treated by the standard storage reduction\nalgorithms. While this certifying is theoretically justified by the fact that\neach subproblem is NP-hard, we assume in this paper that a joint storage\nreduction is in fact more intuitive and can in practice provide better results\nthan two independent processes. Moreover, it avoids a lot of distance\ncalculations by progressively removing useless instances during the feature\npruning. While standard selection algorithms often optimize the accuracy to\ndiscriminate the set of solutions, we use in this paper a criterion based on an\nuncertainty measure within a nearest-neighbor graph. This choice comes from\nrecent results that have proven that accuracy is not always the suitable\ncriterion to optimize. In our approach, a feature or an instance is removed if\nits deletion improves information of the graph. Numerous experiments are\npresented in this paper and a statistical analysis shows the relevance of our\napproach, and its tolerance in the presence of noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:33 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Sebban", "Marc", ""], ["Nock", "Richard", ""]]}, {"id": "1301.3895", "submitter": "Amos J. Storkey", "authors": "Amos J. Storkey", "title": "Dynamic Trees: A Structured Variational Method Giving Efficient\n  Propagation Rules", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-566-573", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic trees are mixtures of tree structured belief networks. They solve\nsome of the problems of fixed tree networks at the cost of making exact\ninference intractable. For this reason approximate methods such as sampling or\nmean field approaches have been used. However, mean field approximations assume\na factorized distribution over node states. Such a distribution seems unlickely\nin the posterior, as nodes are highly correlated in the prior. Here a\nstructured variational approach is used, where the posterior distribution over\nthe non-evidential nodes is itself approximated by a dynamic tree. It turns out\nthat this form can be used tractably and efficiently. The result is a set of\nupdate rules which can propagate information through the network to obtain both\na full variational approximation, and the relevant marginals. The progagtion\nrules are more efficient than the mean field approach and give noticeable\nquantitative and qualitative improvement in the inference. The marginals\ncalculated give better approximations to the posterior than loopy propagation\non a small toy problem.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:49 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Storkey", "Amos J.", ""]]}, {"id": "1301.3896", "submitter": "Loo-Nin Teow", "authors": "Loo-Nin Teow, Kia-Fock Loe", "title": "An Uncertainty Framework for Classification", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-574-579", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a generalized likelihood function based on uncertainty measures and\nshow that maximizing such a likelihood function for different measures induces\ndifferent types of classifiers. In the probabilistic framework, we obtain\nclassifiers that optimize the cross-entropy function. In the possibilistic\nframework, we obtain classifiers that maximize the interclass margin.\nFurthermore, we show that the support vector machine is a sub-class of these\nmaximum-margin classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:53 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Teow", "Loo-Nin", ""], ["Loe", "Kia-Fock", ""]]}, {"id": "1301.3897", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "A Branch-and-Bound Algorithm for MDL Learning Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-580-588", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the work in [Suzuki, 1996] and presents an efficient\ndepth-first branch-and-bound algorithm for learning Bayesian network\nstructures, based on the minimum description length (MDL) principle, for a\ngiven (consistent) variable ordering. The algorithm exhaustively searches\nthrough all network structures and guarantees to find the network with the best\nMDL score. Preliminary experiments show that the algorithm is efficient, and\nthat the time complexity grows slowly with the sample size. The algorithm is\nuseful for empirically studying both the performance of suboptimal heuristic\nsearch algorithms and the adequacy of the MDL principle in learning Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:56 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1301.3899", "submitter": "Shivakumar Vaithyanathan", "authors": "Shivakumar Vaithyanathan, Byron E Dom", "title": "Model-Based Hierarchical Clustering", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-599-608", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to model-based hierarchical clustering by formulating\nan objective function based on a Bayesian analysis. This model organizes the\ndata into a cluster hierarchy while specifying a complex feature-set\npartitioning that is a key component of our model. Features can have either a\nunique distribution in every cluster or a common distribution over some (or\neven all) of the clusters. The cluster subsets over which these features have\nsuch a common distribution correspond to the nodes (clusters) of the tree\nrepresenting the hierarchy. We apply this general model to the problem of\ndocument clustering for which we use a multinomial likelihood function and\nDirichlet priors. Our algorithm consists of a two-stage process wherein we\nfirst perform a flat clustering followed by a modified hierarchical\nagglomerative merging process that includes determining the features that will\nhave common distributions over the merged clusters. The regularization induced\nby using the marginal likelihood automatically determines the optimal model\nstructure including number of clusters, the depth of the tree and the subset of\nfeatures to be modeled as having a common distribution at each node. We present\nexperimental results on both synthetic data and a real document collection.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:05 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Vaithyanathan", "Shivakumar", ""], ["Dom", "Byron E", ""]]}, {"id": "1301.3901", "submitter": "Wim Wiegerinck", "authors": "Wim Wiegerinck", "title": "Variational Approximations between Mean Field Theory and the Junction\n  Tree Algorithm", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-626-633", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, variational approximations such as the mean field approximation\nhave received much interest. We extend the standard mean field method by using\nan approximating distribution that factorises into cluster potentials. This\nincludes undirected graphs, directed acyclic graphs and junction trees. We\nderive generalized mean field equations to optimize the cluster potentials. We\nshow that the method bridges the gap between the standard mean field\napproximation and the exact junction tree algorithm. In addition, we address\nthe problem of how to choose the graphical structure of the approximating\ndistribution. From the generalised mean field equations we derive rules to\nsimplify the structure of the approximating distribution in advance without\naffecting the quality of the approximation. We also show how the method fits\ninto some other variational approximations that are currently popular.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:17 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Wiegerinck", "Wim", ""]]}, {"id": "1301.3966", "submitter": "Tingting Zhao Tingting Zhao", "authors": "Tingting Zhao, Hirotaka Hachiya, Voot Tangkaratt, Jun Morimoto,\n  Masashi Sugiyama", "title": "Efficient Sample Reuse in Policy Gradients with Parameter-based\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradient approach is a flexible and powerful reinforcement\nlearning method particularly for problems with continuous actions such as robot\ncontrol. A common challenge in this scenario is how to reduce the variance of\npolicy gradient estimates for reliable policy updates. In this paper, we\ncombine the following three ideas and give a highly effective policy gradient\nmethod: (a) the policy gradients with parameter based exploration, which is a\nrecently proposed policy search method with low variance of gradient estimates,\n(b) an importance sampling technique, which allows us to reuse previously\ngathered data in a consistent way, and (c) an optimal baseline, which minimizes\nthe variance of gradient estimates with their unbiasedness being maintained.\nFor the proposed method, we give theoretical analysis of the variance of\ngradient estimates and show its usefulness through extensive experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 02:15:49 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Zhao", "Tingting", ""], ["Hachiya", "Hirotaka", ""], ["Tangkaratt", "Voot", ""], ["Morimoto", "Jun", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1301.4083", "submitter": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre", "authors": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre and Yoshua Bengio", "title": "Knowledge Matters: Importance of Prior Information for Optimization", "comments": "37 Pages, 5 figures, 5 tables JMLR Special Topics on Representation\n  Learning Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We explore the effect of introducing prior information into the intermediate\nlevel of neural networks for a learning task on which all the state-of-the-art\nmachine learning algorithms tested failed to learn. We motivate our work from\nthe hypothesis that humans learn such intermediate concepts from other\nindividuals via a form of supervision or guidance using a curriculum. The\nexperiments we have conducted provide positive evidence in favor of this\nhypothesis. In our experiments, a two-tiered MLP architecture is trained on a\ndataset with 64x64 binary inputs images, each image with three sprites. The\nfinal task is to decide whether all the sprites are the same or one of them is\ndifferent. Sprites are pentomino tetris shapes and they are placed in an image\nwith different locations using scaling and rotation transformations. The first\npart of the two-tiered MLP is pre-trained with intermediate-level targets being\nthe presence of sprites at each location, while the second part takes the\noutput of the first part as input and predicts the final task's target binary\nevent. The two-tiered MLP architecture, with a few tens of thousand examples,\nwas able to learn the task perfectly, whereas all other algorithms (include\nunsupervised pre-training, but also traditional algorithms like SVMs, decision\ntrees and boosting) all perform no better than chance. We hypothesize that the\noptimization difficulty involved when the intermediate pre-training is not\nperformed is due to the {\\em composition} of two highly non-linear tasks. Our\nfindings are also consistent with hypotheses on cultural learning inspired by\nthe observations of optimization problems with deep learning, presumably\nbecause of effective local minima.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 13:06:52 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2013 05:43:57 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2013 17:11:19 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2013 20:13:08 GMT"}, {"version": "v5", "created": "Fri, 15 Mar 2013 05:41:47 GMT"}, {"version": "v6", "created": "Sat, 13 Jul 2013 16:38:36 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["G\u00fcl\u00e7ehre", "\u00c7a\u011flar", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.4144", "submitter": "Dimitris Vavoulis", "authors": "Dimitrios V. Vavoulis and Julian Gough", "title": "Non-parametric Bayesian modelling of digital gene expression data", "comments": null, "journal-ref": "J Comput Sci Syst Biol 7:001-009 (2013)", "doi": "10.4172/jcsb.1000131", "report-no": null, "categories": "q-bio.QM q-bio.GN stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation sequencing technologies provide a revolutionary tool for\ngenerating gene expression data. Starting with a fixed RNA sample, they\nconstruct a library of millions of differentially abundant short sequence tags\nor \"reads\", which constitute a fundamentally discrete measure of the level of\ngene expression. A common limitation in experiments using these technologies is\nthe low number or even absence of biological replicates, which complicates the\nstatistical analysis of digital gene expression data. Analysis of this type of\ndata has often been based on modified tests originally devised for analysing\nmicroarrays; both these and even de novo methods for the analysis of RNA-seq\ndata are plagued by the common problem of low replication. We propose a novel,\nnon-parametric Bayesian approach for the analysis of digital gene expression\ndata. We begin with a hierarchical model for modelling over-dispersed count\ndata and a blocked Gibbs sampling algorithm for inferring the posterior\ndistribution of model parameters conditional on these counts. The algorithm\ncompensates for the problem of low numbers of biological replicates by\nclustering together genes with tag counts that are likely sampled from a common\ndistribution and using this augmented sample for estimating the parameters of\nthis distribution. The number of clusters is not decided a priori, but it is\ninferred along with the remaining model parameters. We demonstrate the ability\nof this approach to model biological data with high fidelity by applying the\nalgorithm on a public dataset obtained from cancerous and non-cancerous neural\ntissues.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 16:08:00 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Vavoulis", "Dimitrios V.", ""], ["Gough", "Julian", ""]]}, {"id": "1301.4157", "submitter": "Marcelo Cicconet", "authors": "Marcelo Cicconet", "title": "On the Product Rule for Classification Problems", "comments": "3 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss theoretical aspects of the product rule for classification\nproblems in supervised machine learning for the case of combining classifiers.\nWe show that (1) the product rule arises from the MAP classifier supposing\nequivalent priors and conditional independence given a class; (2) under some\nconditions, the product rule is equivalent to minimizing the sum of the squared\ndistances to the respective centers of the classes related with different\nfeatures, such distances being weighted by the spread of the classes; (3)\nobserving some hypothesis, the product rule is equivalent to concatenating the\nvectors of features.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 16:48:46 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Cicconet", "Marcelo", ""]]}, {"id": "1301.4168", "submitter": "Mareija Eskelinen", "authors": "Luke Bornn, Yutian Chen, Nando de Freitas, Mareija Eskelin, Jing Fang,\n  Max Welling", "title": "Herded Gibbs Sampling", "comments": "19 pages, including the appendix. Submission for ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gibbs sampler is one of the most popular algorithms for inference in\nstatistical models. In this paper, we introduce a herding variant of this\nalgorithm, called herded Gibbs, that is entirely deterministic. We prove that\nherded Gibbs has an $O(1/T)$ convergence rate for models with independent\nvariables and for fully connected probabilistic graphical models. Herded Gibbs\nis shown to outperform Gibbs in the tasks of image denoising with MRFs and\nnamed entity recognition with CRFs. However, the convergence for herded Gibbs\nfor sparsely connected probabilistic graphical models is still an open problem.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 17:37:56 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 01:55:06 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Bornn", "Luke", ""], ["Chen", "Yutian", ""], ["de Freitas", "Nando", ""], ["Eskelin", "Mareija", ""], ["Fang", "Jing", ""], ["Welling", "Max", ""]]}, {"id": "1301.4171", "submitter": "Jason  Weston", "authors": "Jason Weston, Ron Weiss, Hector Yee", "title": "Affinity Weighted Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised (linear) embedding models like Wsabie and PSI have proven\nsuccessful at ranking, recommendation and annotation tasks. However, despite\nbeing scalable to large datasets they do not take full advantage of the extra\ndata due to their linear nature, and typically underfit. We propose a new class\nof models which aim to provide improved performance while retaining many of the\nbenefits of the existing class of embedding models. Our new approach works by\niteratively learning a linear embedding model where the next iteration's\nfeatures and labels are reweighted as a function of the previous iteration. We\ndescribe several variants of the family, and give some initial results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 17:46:27 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Weston", "Jason", ""], ["Weiss", "Ron", ""], ["Yee", "Hector", ""]]}, {"id": "1301.4183", "submitter": "Eunho Yang", "authors": "Eunho Yang, Pradeep Ravikumar, Genevera I. Allen, Zhandong Liu", "title": "On Graphical Models via Univariate Exponential Family Distributions", "comments": "Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected graphical models, or Markov networks, are a popular class of\nstatistical models, used in a wide variety of applications. Popular instances\nof this class include Gaussian graphical models and Ising models. In many\nsettings, however, it might not be clear which subclass of graphical models to\nuse, particularly for non-Gaussian and non-categorical data. In this paper, we\nconsider a general sub-class of graphical models where the node-wise\nconditional distributions arise from exponential families. This allows us to\nderive multivariate graphical model distributions from univariate exponential\nfamily distributions, such as the Poisson, negative binomial, and exponential\ndistributions. Our key contributions include a class of M-estimators to fit\nthese graphical model distributions; and rigorous statistical analysis showing\nthat these M-estimators recover the true graphical model structure exactly,\nwith high probability. We provide examples of genomic and proteomic networks\nlearned via instances of our class of graphical models derived from Poisson and\nexponential distributions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 18:38:52 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2015 13:37:10 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Yang", "Eunho", ""], ["Ravikumar", "Pradeep", ""], ["Allen", "Genevera I.", ""], ["Liu", "Zhandong", ""]]}, {"id": "1301.4194", "submitter": "Ankit Dangi Mr.", "authors": "Ankit Dangi", "title": "Financial Portfolio Optimization: Computationally guided agents to\n  investigate, analyse and invest!?", "comments": "Thesis work under the guidance of Dr. Abhijit Kulkarni, Advanced\n  Analytics Lab. (SSO), SAS Research & Development, India. Submitted at Centre\n  for Modeling and Simulation, University of Pune for completion of Master of\n  Technology (M. Tech.) in Modeling and Simulation (M&S)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE cs.NE q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial portfolio optimization is a widely studied problem in mathematics,\nstatistics, financial and computational literature. It adheres to determining\nan optimal combination of weights associated with financial assets held in a\nportfolio. In practice, it faces challenges by virtue of varying math.\nformulations, parameters, business constraints and complex financial\ninstruments. Empirical nature of data is no longer one-sided; thereby\nreflecting upside and downside trends with repeated yet unidentifiable cyclic\nbehaviours potentially caused due to high frequency volatile movements in asset\ntrades. Portfolio optimization under such circumstances is theoretically and\ncomputationally challenging. This work presents a novel mechanism to reach an\noptimal solution by encoding a variety of optimal solutions in a solution bank\nto guide the search process for the global investment objective formulation. It\nconceptualizes the role of individual solver agents that contribute optimal\nsolutions to a bank of solutions, a super-agent solver that learns from the\nsolution bank, and, thus reflects a knowledge-based computationally guided\nagents approach to investigate, analyse and reach to optimal solution for\ninformed investment decisions.\n  Conceptual understanding of classes of solver agents that represent varying\nproblem formulations and, mathematically oriented deterministic solvers along\nwith stochastic-search driven evolutionary and swarm-intelligence based\ntechniques for optimal weights are discussed. Algorithmic implementation is\npresented by an enhanced neighbourhood generation mechanism in Simulated\nAnnealing algorithm. A framework for inclusion of heuristic knowledge and human\nexpertise from financial literature related to investment decision making\nprocess is reflected via introduction of controlled perturbation strategies\nusing a decision matrix for neighbourhood generation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 19:26:02 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Dangi", "Ankit", ""]]}, {"id": "1301.4240", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Andrea Montanari", "title": "Hypothesis Testing in High-Dimensional Regression under the Gaussian\n  Random Design Model: Asymptotic Theory", "comments": "63 pages, 10 figures, 11 tables, Section 5 and Theorem 4.5 are added.\n  Other modifications to improve presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider linear regression in the high-dimensional regime where the number\nof observations $n$ is smaller than the number of parameters $p$. A very\nsuccessful approach in this setting uses $\\ell_1$-penalized least squares\n(a.k.a. the Lasso) to search for a subset of $s_0< n$ parameters that best\nexplain the data, while setting the other parameters to zero. Considerable\namount of work has been devoted to characterizing the estimation and model\nselection problems within this approach.\n  In this paper we consider instead the fundamental, but far less understood,\nquestion of \\emph{statistical significance}. More precisely, we address the\nproblem of computing p-values for single regression coefficients.\n  On one hand, we develop a general upper bound on the minimax power of tests\nwith a given significance level. On the other, we prove that this upper bound\nis (nearly) achievable through a practical procedure in the case of random\ndesign matrices with independent entries. Our approach is based on a debiasing\nof the Lasso estimator. The analysis builds on a rigorous characterization of\nthe asymptotic distribution of the Lasso estimator and its debiased version.\nOur result holds for optimal sample size, i.e., when $n$ is at least on the\norder of $s_0 \\log(p/s_0)$.\n  We generalize our approach to random design matrices with i.i.d. Gaussian\nrows $x_i\\sim N(0,\\Sigma)$. In this case we prove that a similar distributional\ncharacterization (termed `standard distributional limit') holds for $n$ much\nlarger than $s_0(\\log p)^2$.\n  Finally, we show that for optimal sample size, $n$ being at least of order\n$s_0 \\log(p/s_0)$, the standard distributional limit for general Gaussian\ndesigns can be derived from the replica heuristics in statistical physics.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 21:16:49 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 07:02:40 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2014 04:05:41 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1301.4293", "submitter": "Limin Yao", "authors": "Sebastian Riedel, Limin Yao, Andrew McCallum", "title": "Latent Relation Representations for Universal Schemas", "comments": "4 pages, ICLR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional relation extraction predicts relations within some fixed and\nfinite target schema. Machine learning approaches to this task require either\nmanual annotation or, in the case of distant supervision, existing structured\nsources of the same schema. The need for existing datasets can be avoided by\nusing a universal schema: the union of all involved schemas (surface form\npredicates as in OpenIE, and relations in the schemas of pre-existing\ndatabases). This schema has an almost unlimited set of relations (due to\nsurface forms), and supports integration with existing structured data (through\nthe relation types of existing databases). To populate a database of such\nschema we present a family of matrix factorization models that predict affinity\nbetween database tuples and relations. We show that this achieves substantially\nhigher accuracy than the traditional classification approach. More importantly,\nby operating simultaneously on relations observed in text and in pre-existing\nstructured DBs such as Freebase, we are able to reason about unstructured and\nstructured data in mutually-supporting ways. By doing so our approach\noutperforms state-of-the-art distant supervision systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 04:37:30 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2013 20:10:21 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Riedel", "Sebastian", ""], ["Yao", "Limin", ""], ["McCallum", "Andrew", ""]]}, {"id": "1301.4566", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and James V. Burke and Gianluigi Pillonetto", "title": "Sparse/Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave\n  Densities: Modeling, Computation, and Theory", "comments": "41 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of quadratic support (QS) functions, many of which play\na crucial role in a variety of applications, including machine learning, robust\nstatistical inference, sparsity promotion, and Kalman smoothing. Well known\nexamples include the l2, Huber, l1 and Vapnik losses. We build on a dual\nrepresentation for QS functions using convex analysis, revealing the structure\nnecessary for a QS function to be interpreted as the negative log of a\nprobability density, and providing the foundation for statistical\ninterpretation and analysis of QS loss functions. For a subclass of QS\nfunctions called piecewise linear quadratic (PLQ) penalties, we also develop\nefficient numerical estimation schemes. These components form a flexible\nstatistical modeling framework for a variety of learning applications, together\nwith a toolbox of efficient numerical methods for inference. In particular, for\nPLQ densities, interior point (IP) methods can be used. IP methods solve\nnonsmooth optimization problems by working directly with smooth systems of\nequations characterizing their optimality. The efficiency of the IP approach\ndepends on the structure of particular applications. We consider the class of\ndynamic inverse problems using Kalman smoothing, where the aim is to\nreconstruct the state of a dynamical system with known process and measurement\nmodels starting from noisy output samples. In the classical case, Gaussian\nerrors are assumed in the process and measurement models. The extended\nframework allows arbitrary PLQ densities to be used, and the proposed IP\napproach solves the generalized Kalman smoothing problem while maintaining the\nlinear complexity in the size of the time series, just as in the Gaussian case.\nThis extends the computational efficiency of classic algorithms to a much\nbroader nonsmooth setting, and includes many recently proposed robust and\nsparse smoothers as special cases.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 14:46:29 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 10:38:22 GMT"}], "update_date": "2013-05-03", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1301.4666", "submitter": "Dan Garber", "authors": "Dan Garber, Elad Hazan", "title": "A Linearly Convergent Conditional Gradient Algorithm with Applications\n  to Online and Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear optimization is many times algorithmically simpler than non-linear\nconvex optimization. Linear optimization over matroid polytopes, matching\npolytopes and path polytopes are example of problems for which we have simple\nand efficient combinatorial algorithms, but whose non-linear convex counterpart\nis harder and admits significantly less efficient algorithms. This motivates\nthe computational model of convex optimization, including the offline, online\nand stochastic settings, using a linear optimization oracle. In this\ncomputational model we give several new results that improve over the previous\nstate-of-the-art. Our main result is a novel conditional gradient algorithm for\nsmooth and strongly convex optimization over polyhedral sets that performs only\na single linear optimization step over the domain on each iteration and enjoys\na linear convergence rate. This gives an exponential improvement in convergence\nrate over previous results.\n  Based on this new conditional gradient algorithm we give the first algorithms\nfor online convex optimization over polyhedral sets that perform only a single\nlinear optimization step over the domain while having optimal regret\nguarantees, answering an open question of Kalai and Vempala, and Hazan and\nKale. Our online algorithms also imply conditional gradient algorithms for\nnon-smooth and stochastic convex optimization with the same convergence rates\nas projected (sub)gradient methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 15:54:22 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 22:32:09 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2013 17:06:16 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2013 20:49:45 GMT"}, {"version": "v5", "created": "Sun, 15 Sep 2013 10:50:33 GMT"}, {"version": "v6", "created": "Fri, 14 Aug 2015 18:02:18 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Garber", "Dan", ""], ["Hazan", "Elad", ""]]}, {"id": "1301.4679", "submitter": "Gerard Biau", "authors": "G\\'erard Biau (LPMA, LSTA, DMA, INRIA Paris - Rocquencourt), Luc\n  Devroye (SOCS)", "title": "Cellular Tree Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cellular tree classifier model addresses a fundamental problem in the\ndesign of classifiers for a parallel or distributed computing world: Given a\ndata set, is it sufficient to apply a majority rule for classification, or\nshall one split the data into two or more parts and send each part to a\npotentially different computer (or cell) for further processing? At first\nsight, it seems impossible to define with this paradigm a consistent classifier\nas no cell knows the \"original data size\", $n$. However, we show that this is\nnot so by exhibiting two different consistent classifiers. The consistency is\nuniversal but is only shown for distributions with nonatomic marginals.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 20:01:54 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 06:17:24 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Biau", "G\u00e9rard", "", "LPMA, LSTA, DMA, INRIA Paris - Rocquencourt"], ["Devroye", "Luc", "", "SOCS"]]}, {"id": "1301.4767", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "A Linear Time Active Learning Algorithm for Link Classification -- Full\n  Version --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present very efficient active learning algorithms for link classification\nin signed networks. Our algorithms are motivated by a stochastic model in which\nedge labels are obtained through perturbations of a initial sign assignment\nconsistent with a two-clustering of the nodes. We provide a theoretical\nanalysis within this model, showing that we can achieve an optimal (to whithin\na constant factor) number of mistakes on any graph G = (V,E) such that |E| =\n\\Omega(|V|^{3/2}) by querying O(|V|^{3/2}) edge labels. More generally, we show\nan algorithm that achieves optimality to within a factor of O(k) by querying at\nmost order of |V| + (|V|/k)^{3/2} edge labels. The running time of this\nalgorithm is at most of order |E| + |V|\\log|V|.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 07:02:50 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 17:57:53 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.4769", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "A Correlation Clustering Approach to Link Classification in Signed\n  Networks -- Full Version --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by social balance theory, we develop a theory of link\nclassification in signed networks using the correlation clustering index as\nmeasure of label regularity. We derive learning bounds in terms of correlation\nclustering within three fundamental transductive learning settings: online,\nbatch and active. Our main algorithmic contribution is in the active setting,\nwhere we introduce a new family of efficient link classifiers based on covering\nthe input graph with small circuits. These are the first active algorithms for\nlink classification with mistake bounds that hold for arbitrary signed\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 07:28:44 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 17:44:24 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.4917", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky", "title": "Dirichlet draws are sparse with high probability", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides an elementary proof of the folklore fact that draws from a\nDirichlet distribution (with parameters less than 1) are typically sparse (most\ncoordinates are small).\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 16:27:17 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Telgarsky", "Matus", ""]]}, {"id": "1301.4944", "submitter": "Julio Stern", "authors": "Marcelo S. Lauretto, Barbara B. C. Silva and Pablo M. Andrade", "title": "Evaluation of a Supervised Learning Approach for Stock Market Operations", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining methods have been widely applied in financial markets, with the\npurpose of providing suitable tools for prices forecasting and automatic\ntrading. Particularly, learning methods aim to identify patterns in time series\nand, based on such patterns, to recommend buy/sell operations. The objective of\nthis work is to evaluate the performance of Random Forests, a supervised\nlearning method based on ensembles of decision trees, for decision support in\nstock markets. Preliminary results indicate good rates of successful operations\nand good rates of return per operation, providing a strong motivation for\nfurther research in this topic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 18:17:05 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Lauretto", "Marcelo S.", ""], ["Silva", "Barbara B. C.", ""], ["Andrade", "Pablo M.", ""]]}, {"id": "1301.4976", "submitter": "Irina Gaynanova", "authors": "Irina Gaynanova, James G. Booth and Martin T. Wells", "title": "Supervised Classification Using Sparse Fisher's LDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that in a supervised classification setting when the number\nof features is smaller than the number of observations, Fisher's linear\ndiscriminant rule is asymptotically Bayes. However, there are numerous modern\napplications where classification is needed in the high-dimensional setting.\nNaive implementation of Fisher's rule in this case fails to provide good\nresults because the sample covariance matrix is singular. Moreover, by\nconstructing a classifier that relies on all features the interpretation of the\nresults is challenging. Our goal is to provide robust classification that\nrelies only on a small subset of important features and accounts for the\nunderlying correlation structure. We apply a lasso-type penalty to the\ndiscriminant vector to ensure sparsity of the solution and use a shrinkage type\nestimator for the covariance matrix. The resulting optimization problem is\nsolved using an iterative coordinate ascent algorithm. Furthermore, we analyze\nthe effect of nonconvexity on the sparsity level of the solution and highlight\nthe difference between the penalized and the constrained versions of the\nproblem. The simulation results show that the proposed method performs\nfavorably in comparison to alternatives. The method is used to classify\nleukemia patients based on DNA methylation features.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 20:35:43 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 19:40:26 GMT"}], "update_date": "2014-09-17", "authors_parsed": [["Gaynanova", "Irina", ""], ["Booth", "James G.", ""], ["Wells", "Martin T.", ""]]}, {"id": "1301.5063", "submitter": "Ognjen Rudovic", "authors": "Ognjen Rudovic, Maja Pantic, Vladimir Pavlovic", "title": "Heteroscedastic Conditional Ordinal Random Fields for Pain Intensity\n  Estimation from Facial Images", "comments": "This paper has been withdrawn by the authors due to a crucial sign\n  error in equation 2&3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We propose a novel method for automatic pain intensity estimation from facial\nimages based on the framework of kernel Conditional Ordinal Random Fields\n(KCORF). We extend this framework to account for heteroscedasticity on the\noutput labels(i.e., pain intensity scores) and introduce a novel dynamic\nfeatures, dynamic ranks, that impose temporal ordinal constraints on the static\nranks (i.e., intensity scores). Our experimental results show that the proposed\napproach outperforms state-of-the art methods for sequence classification with\nordinal data and other ordinal regression models. The approach performs\nsignificantly better than other models in terms of Intra-Class Correlation\nmeasure, which is the most accepted evaluation measure in the tasks of facial\nbehaviour intensity estimation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 03:40:52 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 18:43:47 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Rudovic", "Ognjen", ""], ["Pantic", "Maja", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1301.5088", "submitter": "Ian Goodfellow", "authors": "Ian J. Goodfellow", "title": "Piecewise Linear Multilayer Perceptrons and Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of hidden layer for a multilayer perceptron, and\ndemonstrate that it obtains the best reported performance for an MLP on the\nMNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 07:10:34 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Goodfellow", "Ian J.", ""]]}, {"id": "1301.5112", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "Active Learning on Trees and Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of active learning on a given tree whose nodes are\nassigned binary labels in an adversarial way. Inspired by recent results by\nGuillory and Bilmes, we characterize (up to constant factors) the optimal\nplacement of queries so to minimize the mistakes made on the non-queried nodes.\nOur query selection algorithm is extremely efficient, and the optimal number of\nmistakes on the non-queried nodes is achieved by a simple and efficient mincut\nclassifier. Through a simple modification of the query selection algorithm we\nalso show optimality (up to constant factors) with respect to the trade-off\nbetween number of queries and number of mistakes on non-queried nodes. By using\nspanning trees, our algorithms can be efficiently applied to general graphs,\nalthough the problem of finding optimal and efficient active learning\nalgorithms for general graphs remains open. Towards this end, we provide a\nlower bound on the number of mistakes made on arbitrary graphs by any active\nlearning algorithm using a number of queries which is up to a constant fraction\nof the graph size.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 09:00:28 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.5220", "submitter": "Kamil Ciosek", "authors": "Kamil Ciosek", "title": "Properties of the Least Squares Temporal Difference learning algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents four different ways of looking at the well-known Least\nSquares Temporal Differences (LSTD) algorithm for computing the value function\nof a Markov Reward Process, each of them leading to different insights: the\noperator-theory approach via the Galerkin method, the statistical approach via\ninstrumental variables, the linear dynamical system view as well as the limit\nof the TD iteration. We also give a geometric view of the algorithm as an\noblique projection. Furthermore, there is an extensive comparison of the\noptimization problem solved by LSTD as compared to Bellman Residual\nMinimization (BRM). We then review several schemes for the regularization of\nthe LSTD solution. We then proceed to treat the modification of LSTD for the\ncase of episodic Markov Reward Processes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 16:11:33 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 09:29:02 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Ciosek", "Kamil", ""]]}, {"id": "1301.5288", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and Bradley M. Bell and James V. Burke and\n  Gianluigi Pillonetto", "title": "The connection between Bayesian estimation of a Gaussian random field\n  and RKHS", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of a function from noisy data is often formulated as a\nregularized optimization problem over an infinite-dimensional reproducing\nkernel Hilbert space (RKHS). The solution describes the observed data and has a\nsmall RKHS norm. When the data fit is measured using a quadratic loss, this\nestimator has a known statistical interpretation. Given the noisy measurements,\nthe RKHS estimate represents the posterior mean (minimum variance estimate) of\na Gaussian random field with covariance proportional to the kernel associated\nwith the RKHS. In this paper, we provide a statistical interpretation when more\ngeneral losses are used, such as absolute value, Vapnik or Huber. Specifically,\nfor any finite set of sampling locations (including where the data were\ncollected), the MAP estimate for the signal samples is given by the RKHS\nestimate evaluated at these locations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 19:19:38 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2013 13:24:41 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2013 15:11:46 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Bell", "Bradley M.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1301.5332", "submitter": "Yuyang Wang", "authors": "Yuyang Wang, Roni Khardon, Dmitry Pechyony, Rosie Jones", "title": "Online Learning with Pairwise Loss Functions", "comments": "This is an extension of our COLT paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient online learning with pairwise loss functions is a crucial component\nin building large-scale learning system that maximizes the area under the\nReceiver Operator Characteristic (ROC) curve. In this paper we investigate the\ngeneralization performance of online learning algorithms with pairwise loss\nfunctions. We show that the existing proof techniques for generalization bounds\nof online algorithms with a univariate loss can not be directly applied to\npairwise losses. In this paper, we derive the first result providing\ndata-dependent bounds for the average risk of the sequence of hypotheses\ngenerated by an arbitrary online learner in terms of an easily computable\nstatistic, and show how to extract a low risk hypothesis from the sequence. We\ndemonstrate the generality of our results by applying it to two important\nproblems in machine learning. First, we analyze two online algorithms for\nbipartite ranking; one being a natural extension of the perceptron algorithm\nand the other using online convex optimization. Secondly, we provide an\nanalysis for the risk bound for an online algorithm for supervised metric\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 21:10:53 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Wang", "Yuyang", ""], ["Khardon", "Roni", ""], ["Pechyony", "Dmitry", ""], ["Jones", "Rosie", ""]]}, {"id": "1301.5488", "submitter": "Manuel Lopes", "authors": "Francisco Melo and Manuel Lopes", "title": "Multi-class Generalized Binary Search for Active Inverse Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning a task from demonstration. We\nadopt the framework of inverse reinforcement learning, where tasks are\nrepresented in the form of a reward function. Our contribution is a novel\nactive learning algorithm that enables the learning agent to query the expert\nfor more informative demonstrations, thus leading to more sample-efficient\nlearning. For this novel algorithm (Generalized Binary Search for Inverse\nReinforcement Learning, or GBS-IRL), we provide a theoretical bound on sample\ncomplexity and illustrate its applicability on several different tasks. To our\nknowledge, GBS-IRL is the first active IRL algorithm with provable sample\ncomplexity bounds. We also discuss our method in light of other existing\nmethods in the literature and its general applicability in multi-class\nclassification problems. Finally, motivated by recent work on learning from\ndemonstration in robots, we also discuss how different forms of human feedback\ncan be integrated in a transparent manner in our learning framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 12:54:09 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Melo", "Francisco", ""], ["Lopes", "Manuel", ""]]}, {"id": "1301.5584", "submitter": "Shayan Oveis Gharan", "authors": "Tsz Chiu Kwok and Lap Chi Lau and Yin Tat Lee and Shayan Oveis Gharan\n  and Luca Trevisan", "title": "Improved Cheeger's Inequality: Analysis of Spectral Partitioning\n  Algorithms through Higher Order Spectral Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let \\phi(G) be the minimum conductance of an undirected graph G, and let\n0=\\lambda_1 <= \\lambda_2 <=... <= \\lambda_n <= 2 be the eigenvalues of the\nnormalized Laplacian matrix of G. We prove that for any graph G and any k >= 2,\n  \\phi(G) = O(k) \\lambda_2 / \\sqrt{\\lambda_k}, and this performance guarantee\nis achieved by the spectral partitioning algorithm. This improves Cheeger's\ninequality, and the bound is optimal up to a constant factor for any k. Our\nresult shows that the spectral partitioning algorithm is a constant factor\napproximation algorithm for finding a sparse cut if \\lambda_k$ is a constant\nfor some constant k. This provides some theoretical justification to its\nempirical performance in image segmentation and clustering problems. We extend\nthe analysis to other graph partitioning problems, including multi-way\npartition, balanced separator, and maximum cut.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 17:49:05 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Kwok", "Tsz Chiu", ""], ["Lau", "Lap Chi", ""], ["Lee", "Yin Tat", ""], ["Gharan", "Shayan Oveis", ""], ["Trevisan", "Luca", ""]]}, {"id": "1301.5650", "submitter": "Marius Pachitariu", "authors": "Marius Pachitariu and Maneesh Sahani", "title": "Regularization and nonlinearities for neural language models: when are\n  they needed?", "comments": "Added new experiments on large datasets and on the Microsoft Research\n  Sentence Completion Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) based on recurrent neural networks (RNN) are\nsome of the most successful word and character-level LMs. Why do they work so\nwell, in particular better than linear neural LMs? Possible explanations are\nthat RNNs have an implicitly better regularization or that RNNs have a higher\ncapacity for storing patterns due to their nonlinearities or both. Here we\nargue for the first explanation in the limit of little training data and the\nsecond explanation for large amounts of text data. We show state-of-the-art\nperformance on the popular and small Penn dataset when RNN LMs are regularized\nwith random dropout. Nonetheless, we show even better performance from a\nsimplified, much less expressive linear RNN model without off-diagonal entries\nin the recurrent matrix. We call this model an impulse-response LM (IRLM).\nUsing random dropout, column normalization and annealed learning rates, IRLMs\ndevelop neurons that keep a memory of up to 50 words in the past and achieve a\nperplexity of 102.5 on the Penn dataset. On two large datasets however, the\nsame regularization methods are unsuccessful for both models and the RNN's\nexpressivity allows it to overtake the IRLM by 10 and 20 percent perplexity,\nrespectively. Despite the perplexity gap, IRLMs still outperform RNNs on the\nMicrosoft Research Sentence Completion (MRSC) task. We develop a slightly\nmodified IRLM that separates long-context units (LCUs) from short-context units\nand show that the LCUs alone achieve a state-of-the-art performance on the MRSC\ntask of 60.8%. Our analysis indicates that a fruitful direction of research for\nneural LMs lies in developing more accessible internal representations, and\nsuggests an optimization regime of very high momentum terms for effectively\ntraining such models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 21:18:07 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2013 14:30:04 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Pachitariu", "Marius", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1301.5686", "submitter": "Jeon-Hyung Kang", "authors": "Jeon-Hyung Kang, Jun Ma, Yan Liu", "title": "Transfer Topic Modeling with Ease and Scalability", "comments": "2012 SIAM International Conference on Data Mining (SDM12) Pages:\n  {564-575}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing volume of short texts generated on social media sites, such as\nTwitter or Facebook, creates a great demand for effective and efficient topic\nmodeling approaches. While latent Dirichlet allocation (LDA) can be applied, it\nis not optimal due to its weakness in handling short texts with fast-changing\ntopics and scalability concerns. In this paper, we propose a transfer learning\napproach that utilizes abundant labeled documents from other domains (such as\nYahoo! News or Wikipedia) to improve topic modeling, with better model fitting\nand result interpretation. Specifically, we develop Transfer Hierarchical LDA\n(thLDA) model, which incorporates the label information from other domains via\ninformative priors. In addition, we develop a parallel implementation of our\nmodel for large-scale applications. We demonstrate the effectiveness of our\nthLDA model on both a microblogging dataset and standard text collections\nincluding AP and RCV1 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 02:02:13 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2013 18:00:19 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kang", "Jeon-Hyung", ""], ["Ma", "Jun", ""], ["Liu", "Yan", ""]]}, {"id": "1301.6027", "submitter": "Duncan Blythe", "authors": "Duncan A.J. Blythe, Frank C. Meinecke, Paul von Buenau and\n  Klaus-Robert Mueller", "title": "Explorative Data Analysis for Changes in Neural Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural recordings are nonstationary time series, i.e. their properties\ntypically change over time. Identifying specific changes, e.g. those induced by\na learning task, can shed light on the underlying neural processes. However,\nsuch changes of interest are often masked by strong unrelated changes, which\ncan be of physiological origin or due to measurement artifacts. We propose a\nnovel algorithm for disentangling such different causes of non-stationarity and\nin this manner enable better neurophysiological interpretation for a wider set\nof experimental paradigms. A key ingredient is the repeated application of\nStationary Subspace Analysis (SSA) using different temporal scales. The\nusefulness of our explorative approach is demonstrated in simulations, theory\nand EEG experiments with 80 Brain-Computer-Interfacing (BCI) subjects.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 12:26:41 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Blythe", "Duncan A. J.", ""], ["Meinecke", "Frank C.", ""], ["von Buenau", "Paul", ""], ["Mueller", "Klaus-Robert", ""]]}, {"id": "1301.6308", "submitter": "Shiqian Ma", "authors": "Tianyi Lin and Shiqian Ma and Shuzhong Zhang", "title": "An Extragradient-Based Alternating Direction Method for Convex\n  Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of minimizing the sum of two convex\nfunctions subject to linear linking constraints. The classical alternating\ndirection type methods usually assume that the two convex functions have\nrelatively easy proximal mappings. However, many problems arising from\nstatistics, image processing and other fields have the structure that while one\nof the two functions has easy proximal mapping, the other function is smoothly\nconvex but does not have an easy proximal mapping. Therefore, the classical\nalternating direction methods cannot be applied. To deal with the difficulty,\nwe propose in this paper an alternating direction method based on\nextragradients. Under the assumption that the smooth function has a Lipschitz\ncontinuous gradient, we prove that the proposed method returns an\n$\\epsilon$-optimal solution within $O(1/\\epsilon)$ iterations. We apply the\nproposed method to solve a new statistical model called fused logistic\nregression. Our numerical experiments show that the proposed method performs\nvery well when solving the test problems. We also test the performance of the\nproposed method through solving the lasso problem arising from statistics and\ncompare the result with several existing efficient solvers for this problem;\nthe results are very encouraging indeed.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 03:06:55 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 06:05:22 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 00:49:04 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Lin", "Tianyi", ""], ["Ma", "Shiqian", ""], ["Zhang", "Shuzhong", ""]]}, {"id": "1301.6314", "submitter": "Yakir Reshef", "authors": "David Reshef (1), Yakir Reshef (1), Michael Mitzenmacher (2), Pardis\n  Sabeti (2) (1, 2 - contributed equally)", "title": "Equitability Analysis of the Maximal Information Coefficient, with\n  Comparisons", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A measure of dependence is said to be equitable if it gives similar scores to\nequally noisy relationships of different types. Equitability is important in\ndata exploration when the goal is to identify a relatively small set of\nstrongest associations within a dataset as opposed to finding as many non-zero\nassociations as possible, which often are too many to sift through. Thus an\nequitable statistic, such as the maximal information coefficient (MIC), can be\nuseful for analyzing high-dimensional data sets. Here, we explore both\nequitability and the properties of MIC, and discuss several aspects of the\ntheory and practice of MIC. We begin by presenting an intuition behind the\nequitability of MIC through the exploration of the maximization and\nnormalization steps in its definition. We then examine the speed and optimality\nof the approximation algorithm used to compute MIC, and suggest some directions\nfor improving both. Finally, we demonstrate in a range of noise models and\nsample sizes that MIC is more equitable than natural alternatives, such as\nmutual information estimation and distance correlation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 03:45:30 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2013 20:51:50 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Reshef", "David", ""], ["Reshef", "Yakir", ""], ["Mitzenmacher", "Michael", ""], ["Sabeti", "Pardis", ""]]}, {"id": "1301.6324", "submitter": "Togerchety Hitendra sarma", "authors": "T. Hitendra Sarma, P. Viswanath, D. Sai Koti Reddy and S. Sri Raghava", "title": "An improvement to k-nearest neighbor classifier", "comments": "Appeared in Third International Conference on Data Management, IMT\n  Ghaziabad, March 11-12, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Nearest neighbor classifier (k-NNC) is simple to use and has little design\ntime like finding k values in k-nearest neighbor classifier, hence these are\nsuitable to work with dynamically varying data-sets. There exists some\nfundamental improvements over the basic k-NNC, like weighted k-nearest\nneighbors classifier (where weights to nearest neighbors are given based on\nlinear interpolation), using artificially generated training set called\nbootstrapped training set, etc. These improvements are orthogonal to space\nreduction and classification time reduction techniques, hence can be coupled\nwith any of them. The paper proposes another improvement to the basic k-NNC\nwhere the weights to nearest neighbors are given based on Gaussian distribution\n(instead of linear interpolation as done in weighted k-NNC) which is also\nindependent of any space reduction and classification time reduction technique.\nWe formally show that our proposed method is closely related to non-parametric\ndensity estimation using a Gaussian kernel. We experimentally demonstrate using\nvarious standard data-sets that the proposed method is better than the existing\nones in most cases.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 06:55:55 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Sarma", "T. Hitendra", ""], ["Viswanath", "P.", ""], ["Reddy", "D. Sai Koti", ""], ["Raghava", "S. Sri", ""]]}, {"id": "1301.6626", "submitter": "Xiangnan Kong", "authors": "Xiangnan Kong, Philip S. Yu, Xue Wang, Ann B. Ragin", "title": "Discriminative Feature Selection for Uncertain Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining discriminative features for graph data has attracted much attention in\nrecent years due to its important role in constructing graph classifiers,\ngenerating graph indices, etc. Most measurement of interestingness of\ndiscriminative subgraph features are defined on certain graphs, where the\nstructure of graph objects are certain, and the binary edges within each graph\nrepresent the \"presence\" of linkages among the nodes. In many real-world\napplications, however, the linkage structure of the graphs is inherently\nuncertain. Therefore, existing measurements of interestingness based upon\ncertain graphs are unable to capture the structural uncertainty in these\napplications effectively. In this paper, we study the problem of discriminative\nsubgraph feature selection from uncertain graphs. This problem is challenging\nand different from conventional subgraph mining problems because both the\nstructure of the graph objects and the discrimination score of each subgraph\nfeature are uncertain. To address these challenges, we propose a novel\ndiscriminative subgraph feature selection method, DUG, which can find\ndiscriminative subgraph features in uncertain graphs based upon different\nstatistical measures including expectation, median, mode and phi-probability.\nWe first compute the probability distribution of the discrimination scores for\neach subgraph feature based on dynamic programming. Then a branch-and-bound\nalgorithm is proposed to search for discriminative subgraphs efficiently.\nExtensive experiments on various neuroimaging applications (i.e., Alzheimer's\nDisease, ADHD and HIV) have been performed to analyze the gain in performance\nby taking into account structural uncertainties in identifying discriminative\nsubgraph features for graph classification.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 18:00:33 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kong", "Xiangnan", ""], ["Yu", "Philip S.", ""], ["Wang", "Xue", ""], ["Ragin", "Ann B.", ""]]}, {"id": "1301.6648", "submitter": "Liming Wang", "authors": "Liming Wang, Miguel Rodrigues, Lawrence Carin", "title": "Generalized Bregman Divergence and Gradient of Mutual Information for\n  Vector Poisson Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate connections between information-theoretic and\nestimation-theoretic quantities in vector Poisson channel models. In\nparticular, we generalize the gradient of mutual information with respect to\nkey system parameters from the scalar to the vector Poisson channel model. We\nalso propose, as another contribution, a generalization of the classical\nBregman divergence that offers a means to encapsulate under a unifying\nframework the gradient of mutual information results for scalar and vector\nPoisson and Gaussian channel models. The so-called generalized Bregman\ndivergence is also shown to exhibit various properties akin to the properties\nof the classical version. The vector Poisson channel model is drawing\nconsiderable attention in view of its application in various domains: as an\nexample, the availability of the gradient of mutual information can be used in\nconjunction with gradient descent methods to effect compressive-sensing\nprojection designs in emerging X-ray and document classification applications.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 19:16:15 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 19:26:29 GMT"}, {"version": "v3", "created": "Thu, 9 May 2013 19:53:46 GMT"}], "update_date": "2013-05-10", "authors_parsed": [["Wang", "Liming", ""], ["Rodrigues", "Miguel", ""], ["Carin", "Lawrence", ""]]}, {"id": "1301.6676", "submitter": "Hagai Attias", "authors": "Hagai Attias", "title": "Inferring Parameters and Structure of Latent Variable Models by\n  Variational Bayes", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-21-30", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for learning graphical models with latent variables and a\nfixed structure estimate optimal values for the model parameters. Whereas this\napproach usually produces overfitting and suboptimal generalization\nperformance, carrying out the Bayesian program of computing the full posterior\ndistributions over the parameters remains a difficult problem. Moreover,\nlearning the structure of models with latent variables, for which the Bayesian\napproach is crucial, is yet a harder problem. In this paper I present the\nVariational Bayes framework, which provides a solution to these problems. This\napproach approximates full posterior distributions over model parameters and\nstructures, as well as latent variables, in an analytical manner without\nresorting to sampling methods. Unlike in the Laplace approximation, these\nposteriors are generally non-Gaussian and no Hessian needs to be computed. The\nresulting algorithm generalizes the standard Expectation Maximization\nalgorithm, and its convergence is guaranteed. I demonstrate that this algorithm\ncan be applied to a large class of models in several domains, including\nunsupervised clustering and blind source separation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:44 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Attias", "Hagai", ""]]}, {"id": "1301.6677", "submitter": "Katy S. Azoury", "authors": "Katy S. Azoury, Manfred K. Warmuth", "title": "Relative Loss Bounds for On-line Density Estimation with the Exponential\n  Family of Distributions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-31-40", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider on-line density estimation with a parameterized density from the\nexponential family. The on-line algorithm receives one example at a time and\nmaintains a parameter that is essentially an average of the past examples.\nAfter receiving an example the algorithm incurs a loss which is the negative\nlog-likelihood of the example w.r.t. the past parameter of the algorithm. An\noff-line algorithm can choose the best parameter based on all the examples. We\nprove bounds on the additional total loss of the on-line algorithm over the\ntotal loss of the off-line algorithm. These relative loss bounds hold for an\narbitrary sequence of examples. The goal is to design algorithms with the best\npossible relative loss bounds. We use a certain divergence to derive and\nanalyze the algorithms. This divergence is a relative entropy between two\nexponential distributions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:48 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Azoury", "Katy S.", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1301.6684", "submitter": "Jie Cheng", "authors": "Jie Cheng, Russell Greiner", "title": "Comparing Bayesian Network Classifiers", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-101-108", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically evaluate algorithms for learning four types of\nBayesian network (BN) classifiers - Naive-Bayes, tree augmented Naive-Bayes, BN\naugmented Naive-Bayes and general BNs, where the latter two are learned using\ntwo variants of a conditional-independence (CI) based BN-learning algorithm.\nExperimental results show the obtained classifiers, learned using the CI based\nalgorithms, are competitive with (or superior to) the best known classifiers,\nbased on both Bayesian networks and other formalisms; and that the\ncomputational time for learning and using these classifiers is relatively\nsmall. Moreover, these results also suggest a way to learn yet more effective\nclassifiers; we demonstrate empirically that this new algorithm does work as\nexpected. Collectively, these results argue that BN classifiers deserve more\nattention in machine learning and data mining communities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Cheng", "Jie", ""], ["Greiner", "Russell", ""]]}, {"id": "1301.6685", "submitter": "Max Chickering", "authors": "David Maxwell Chickering, David Heckerman", "title": "Fast Learning from Sparse Data", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-109-115", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two techniques that significantly improve the running time of\nseveral standard machine-learning algorithms when data is sparse. The first\ntechnique is an algorithm that effeciently extracts one-way and two-way\ncounts--either real or expected-- from discrete data. Extracting such counts is\na fundamental step in learning algorithms for constructing a variety of models\nincluding decision trees, decision graphs, Bayesian networks, and naive-Bayes\nclustering models. The second technique is an algorithm that efficiently\nperforms the E-step of the EM algorithm (i.e. inference) when applied to a\nnaive-Bayes clustering model. Using real-world data sets, we demonstrate a\ndramatic decrease in running time for algorithms that incorporate these\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:18 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:09:53 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1301.6695", "submitter": "Nir Friedman", "authors": "Nir Friedman, Moises Goldszmidt, Abraham Wyner", "title": "Data Analysis with Bayesian Networks: A Bootstrap Approach", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-196-205", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been significant progress in algorithms and methods\nfor inducing Bayesian networks from data. However, in complex data analysis\nproblems, we need to go beyond being satisfied with inducing networks with high\nscores. We need to provide confidence measures on features of these networks:\nIs the existence of an edge between two nodes warranted? Is the Markov blanket\nof a given node robust? Can we say something about the ordering of the\nvariables? We should be able to address these questions, even when the amount\nof data is not enough to induce a high scoring network. In this paper we\npropose Efron's Bootstrap as a computationally efficient approach for answering\nthese questions. In addition, we propose to use these confidence measures to\ninduce better structures from the data, and to detect the presence of latent\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:00 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Friedman", "Nir", ""], ["Goldszmidt", "Moises", ""], ["Wyner", "Abraham", ""]]}, {"id": "1301.6696", "submitter": "Nir Friedman", "authors": "Nir Friedman, Iftach Nachman, Dana Pe'er", "title": "Learning Bayesian Network Structure from Massive Datasets: The \"Sparse\n  Candidate\" Algorithm", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-206-215", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Bayesian networks is often cast as an optimization problem, where\nthe computational task is to find a structure that maximizes a statistically\nmotivated score. By and large, existing learning tools address this\noptimization problem using standard heuristic search techniques. Since the\nsearch space is extremely large, such search procedures can spend most of the\ntime examining candidates that are extremely unreasonable. This problem becomes\ncritical when we deal with data sets that are large either in the number of\ninstances, or the number of attributes. In this paper, we introduce an\nalgorithm that achieves faster learning by restricting the search space. This\niterative algorithm restricts the parents of each variable to belong to a small\nsubset of candidates. We then search for a network that satisfies these\nconstraints. The learned network is then used for selecting better candidates\nfor the next iteration. We evaluate this algorithm both on synthetic and\nreal-life data. Our results show that it is significantly faster than\nalternative search procedures without loss of quality in the learned\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:05 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Friedman", "Nir", ""], ["Nachman", "Iftach", ""], ["Pe'er", "Dana", ""]]}, {"id": "1301.6697", "submitter": "David Heckerman", "authors": "Dan Geiger, David Heckerman", "title": "Parameter Priors for Directed Acyclic Graphical Models and the\n  Characterization of Several Probability Distributions", "comments": "This version has improved pointers to the literature. arXiv admin\n  note: substantial text overlap with arXiv:2105.03248", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-216-225", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the only parameter prior for complete Gaussian DAG models that\nsatisfies global parameter independence, complete model equivalence, and some\nweak regularity assumptions, is the normal-Wishart distribution. Our analysis\nis based on the following new characterization of the Wishart distribution: let\nW be an n x n, n >= 3, positive-definite symmetric matrix of random variables\nand f(W) be a pdf of W. Then, f(W) is a Wishart distribution if and only if\nW_{11}-W_{12}W_{22}^{-1}W_{12}' is independent of {W_{12}, W_{22}} for every\nblock partitioning W_{11}, W_{12}, W_{12}', W_{22} of W. Similar\ncharacterizations of the normal and normal-Wishart distributions are provided\nas well. We also show how to construct a prior for every DAG model over X from\nthe prior of a single regression model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:09 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:08:10 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 13:33:49 GMT"}, {"version": "v4", "created": "Tue, 29 Jun 2021 19:43:51 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""]]}, {"id": "1301.6705", "submitter": "Thomas Hofmann", "authors": "Thomas Hofmann", "title": "Probabilistic Latent Semantic Analysis", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-289-296", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Latent Semantic Analysis is a novel statistical technique for\nthe analysis of two-mode and co-occurrence data, which has applications in\ninformation retrieval and filtering, natural language processing, machine\nlearning from text, and in related areas. Compared to standard Latent Semantic\nAnalysis which stems from linear algebra and performs a Singular Value\nDecomposition of co-occurrence tables, the proposed method is based on a\nmixture decomposition derived from a latent class model. This results in a more\nprincipled approach which has a solid foundation in statistics. In order to\navoid overfitting, we propose a widely applicable generalization of maximum\nlikelihood model fitting by tempered EM. Our approach yields substantial and\nconsistent improvements over Latent Semantic Analysis in a number of\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:43 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Hofmann", "Thomas", ""]]}, {"id": "1301.6710", "submitter": "Petri Kontkanen", "authors": "Petri Kontkanen, Petri Myllymaki, Tomi Silander, Henry Tirri", "title": "On Supervised Selection of Bayesian Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-334-342", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of possible models (e.g., Bayesian network structures) and a data\nsample, in the unsupervised model selection problem the task is to choose the\nmost accurate model with respect to the domain joint probability distribution.\nIn contrast to this, in supervised model selection it is a priori known that\nthe chosen model will be used in the future for prediction tasks involving more\n``focused' predictive distributions. Although focused predictive distributions\ncan be produced from the joint probability distribution by marginalization, in\npractice the best model in the unsupervised sense does not necessarily perform\nwell in supervised domains. In particular, the standard marginal likelihood\nscore is a criterion for the unsupervised task, and, although frequently used\nfor supervised model selection also, does not perform well in such tasks. In\nthis paper we study the performance of the marginal likelihood score\nempirically in supervised Bayesian network selection tasks by using a large\nnumber of publicly available classification data sets, and compare the results\nto those obtained by alternative model selection criteria, including empirical\ncrossvalidation methods, an approximation of a supervised marginal likelihood\nmeasure, and a supervised version of Dawids prequential(predictive sequential)\nprinciple.The results demonstrate that the marginal likelihood score does NOT\nperform well FOR supervised model selection, WHILE the best results are\nobtained BY using Dawids prequential r napproach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:02 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Kontkanen", "Petri", ""], ["Myllymaki", "Petri", ""], ["Silander", "Tomi", ""], ["Tirri", "Henry", ""]]}, {"id": "1301.6723", "submitter": "Stefano Monti", "authors": "Stefano Monti, Gregory F. Cooper", "title": "A Bayesian Network Classifier that Combines a Finite Mixture Model and a\n  Naive Bayes Model", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-447-456", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new Bayesian network model for classification that\ncombines the naive-Bayes (NB) classifier and the finite-mixture (FM)\nclassifier. The resulting classifier aims at relaxing the strong assumptions on\nwhich the two component models are based, in an attempt to improve on their\nclassification performance, both in terms of accuracy and in terms of\ncalibration of the estimated probabilities. The proposed classifier is obtained\nby superimposing a finite mixture model on the set of feature variables of a\nnaive Bayes model. We present experimental results that compare the predictive\nperformance on real datasets of the new classifier with the predictive\nperformance of the NB classifier and the FM classifier.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:54 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Monti", "Stefano", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1301.6724", "submitter": "Kevin Murphy", "authors": "Kevin Murphy", "title": "A Variational Approximation for Bayesian Networks with Discrete and\n  Continuous Latent Variables", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-457-466", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use a variational approximation to the logistic function to\nperform approximate inference in Bayesian networks containing discrete nodes\nwith continuous parents. Essentially, we convert the logistic function to a\nGaussian, which facilitates exact inference, and then iteratively adjust the\nvariational parameters to improve the quality of the approximation. We\ndemonstrate experimentally that this approximation is faster and potentially\nmore accurate than sampling. We also introduce a simple new technique for\nhandling evidence, which allows us to handle arbitrary distributions on\nobserved nodes, as well as achieving a significant speedup in networks with\ndiscrete variables of large cardinality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:58 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Murphy", "Kevin", ""]]}, {"id": "1301.6727", "submitter": "Julian R. Neil", "authors": "Julian R. Neil, Chris S. Wallace, Kevin B. Korb", "title": "Learning Bayesian Networks with Restricted Causal Interactions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-486-493", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem for the learning of Bayesian networks (BNs) is the\nexponential number of parameters needed for conditional probability tables.\nRecent research reduces this complexity by modeling local structure in the\nprobability tables. We examine the use of log-linear local models. While\nlog-linear models in this context are not new (Whittaker, 1990; Buntine, 1991;\nNeal, 1992; Heckerman and Meek, 1997), for structure learning they are\ngenerally subsumed under a naive Bayes model. We describe an alternative\ninterpretation, and use a Minimum Message Length (MML) (Wallace, 1987) metric\nfor structure learning of networks exhibiting causal independence, which we\nterm first-order networks (FONs). We also investigate local model selection on\na node-by-node basis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:10 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Neil", "Julian R.", ""], ["Wallace", "Chris S.", ""], ["Korb", "Kevin B.", ""]]}, {"id": "1301.6730", "submitter": "Luis E. Ortiz", "authors": "Luis E. Ortiz, Leslie Pack Kaelbling", "title": "Accelerating EM: An Empirical Study", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-512-521", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require that we learn the parameters of a model from data.\nEM is a method used to learn the parameters of probabilistic models for which\nthe data for some of the variables in the models is either missing or hidden.\nThere are instances in which this method is slow to converge. Therefore,\nseveral accelerations have been proposed to improve the method. None of the\nproposed acceleration methods are theoretically dominant and experimental\ncomparisons are lacking. In this paper, we present the different proposed\naccelerations and try to compare them experimentally. From the results of the\nexperiments, we argue that some acceleration of EM is always possible, but that\nwhich acceleration is superior depends on properties of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:21 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Ortiz", "Luis E.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1301.6731", "submitter": "Vladimir Pavlovic", "authors": "Vladimir Pavlovic, Brendan J. Frey, Thomas S. Huang", "title": "Variational Learning in Mixed-State Dynamic Graphical Models", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-522-530", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-valued stochastic time-series are locally linear (Gassian), but\nglobally non-linear. For example, the trajectory of a human hand gesture can be\nviewed as a linear dynamic system driven by a nonlinear dynamic system that\nrepresents muscle actions. We present a mixed-state dynamic graphical model in\nwhich a hidden Markov model drives a linear dynamic system. This combination\nallows us to model both the discrete and continuous causes of trajectories such\nas human gestures. The number of computations needed for exact inference is\nexponential in the sequence length, so we derive an approximate variational\ninference technique that can also be used to learn the parameters of the\ndiscrete and continuous models. We show how the mixed-state model and the\nvariational technique can be used to classify human hand gestures made with a\ncomputer mouse.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:25 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Pavlovic", "Vladimir", ""], ["Frey", "Brendan J.", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1301.6738", "submitter": "Raffaella Settimi", "authors": "Raffaella Settimi, Jim Q. Smith, A. S. Gargoum", "title": "Approximate Learning in Complex Dynamic Bayesian Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-585-593", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the work of Smith and Papamichail (1999) and present\nfast approximate Bayesian algorithms for learning in complex scenarios where at\nany time frame, the relationships between explanatory state space variables can\nbe described by a Bayesian network that evolve dynamically over time and the\nobservations taken are not necessarily Gaussian. It uses recent developments in\napproximate Bayesian forecasting methods in combination with more familiar\nGaussian propagation algorithms on junction trees. The procedure for learning\nstate parameters from data is given explicitly for common sampling\ndistributions and the methodology is illustrated through a real application.\nThe efficiency of the dynamic approximation is explored by using the Hellinger\ndivergence measure and theoretical bounds for the efficacy of such a procedure\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:53 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Settimi", "Raffaella", ""], ["Smith", "Jim Q.", ""], ["Gargoum", "A. S.", ""]]}, {"id": "1301.6770", "submitter": "Zhixiang Eddie Xu", "authors": "Zhixiang (Eddie) Xu, Minmin Chen, Kilian Q. Weinberger, Fei Sha", "title": "An alternative text representation to TF-IDF and Bag-of-Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text mining, information retrieval, and machine learning, text documents\nare commonly represented through variants of sparse Bag of Words (sBoW) vectors\n(e.g. TF-IDF). Although simple and intuitive, sBoW style representations suffer\nfrom their inherent over-sparsity and fail to capture word-level synonymy and\npolysemy. Especially when labeled data is limited (e.g. in document\nclassification), or the text documents are short (e.g. emails or abstracts),\nmany features are rarely observed within the training corpus. This leads to\noverfitting and reduced generalization accuracy. In this paper we propose Dense\nCohort of Terms (dCoT), an unsupervised algorithm to learn improved sBoW\ndocument features. dCoT explicitly models absent words by removing and\nreconstructing random sub-sets of words in the unlabeled corpus. With this\napproach, dCoT learns to reconstruct frequent words from co-occurring\ninfrequent words and maps the high dimensional sparse sBoW vectors into a\nlow-dimensional dense representation. We show that the feature removal can be\nmarginalized out and that the reconstruction can be solved for in closed-form.\nWe demonstrate empirically, on several benchmark datasets, that dCoT features\nsignificantly improve the classification accuracy across several document\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 21:04:45 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Zhixiang", "", "", "Eddie"], ["Xu", "", ""], ["Chen", "Minmin", ""], ["Weinberger", "Kilian Q.", ""], ["Sha", "Fei", ""]]}, {"id": "1301.6915", "submitter": "Mohammad Hossein Rohban", "authors": "Mohammad Hossein Rohban, Prakash Ishwar, Birant Orten, William C.\n  Karl, Venkatesh Saligrama", "title": "An Impossibility Result for High Dimensional Supervised Learning", "comments": "This paper was submitted to the IEEE Information Theory Workshop\n  (ITW) 2013 on April 23, 2013", "journal-ref": null, "doi": "10.1109/ITW.2013.6691252", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study high-dimensional asymptotic performance limits of binary supervised\nclassification problems where the class conditional densities are Gaussian with\nunknown means and covariances and the number of signal dimensions scales faster\nthan the number of labeled training samples. We show that the Bayes error,\nnamely the minimum attainable error probability with complete distributional\nknowledge and equally likely classes, can be arbitrarily close to zero and yet\nthe limiting minimax error probability of every supervised learning algorithm\nis no better than a random coin toss. In contrast to related studies where the\nclassification difficulty (Bayes error) is made to vanish, we hold it constant\nwhen taking high-dimensional limits. In contrast to VC-dimension based minimax\nlower bounds that consider the worst case error probability over all\ndistributions that have a fixed Bayes error, our worst case is over the family\nof Gaussian distributions with constant Bayes error. We also show that a\nnontrivial asymptotic minimax error probability can only be attained for\nparametric subsets of zero measure (in a suitable measure space). These results\nexpose the fundamental importance of prior knowledge and suggest that unless we\nimpose strong structural constraints, such as sparsity, on the parametric\nspace, supervised learning may be ineffective in high dimensional small sample\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 13:01:22 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2013 23:39:47 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Rohban", "Mohammad Hossein", ""], ["Ishwar", "Prakash", ""], ["Orten", "Birant", ""], ["Karl", "William C.", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1301.6944", "submitter": "Andreas Christmann", "authors": "Andreas Christmann and Robert Hable", "title": "On the Consistency of the Bootstrap Approach for Support Vector Machines\n  and Related Kernel Based Methods", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that bootstrap approximations of support vector machines (SVMs)\nbased on a general convex and smooth loss function and on a general kernel are\nconsistent. This result is useful to approximate the unknown finite sample\ndistribution of SVMs by the bootstrap approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 15:09:56 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Christmann", "Andreas", ""], ["Hable", "Robert", ""]]}, {"id": "1301.7002", "submitter": "Henrik Ohlsson", "authors": "Henrik Ohlsson, Allen Y. Yang, Roy Dong, Michel Verhaegen and S.\n  Shankar Sastry", "title": "Quadratic Basis Pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many compressive sensing problems today, the relationship between the\nmeasurements and the unknowns could be nonlinear. Traditional treatment of such\nnonlinear relationships have been to approximate the nonlinearity via a linear\nmodel and the subsequent un-modeled dynamics as noise. The ability to more\naccurately characterize nonlinear models has the potential to improve the\nresults in both existing compressive sensing applications and those where a\nlinear approximation does not suffice, e.g., phase retrieval. In this paper, we\nextend the classical compressive sensing framework to a second-order Taylor\nexpansion of the nonlinearity. Using a lifting technique and a method we call\nquadratic basis pursuit, we show that the sparse signal can be recovered\nexactly when the sampling rate is sufficiently high. We further present\nefficient numerical algorithms to recover sparse signals in second-order\nnonlinear systems, which are considerably more difficult to solve than their\nlinear counterparts in sparse optimization.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 17:54:29 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2013 02:25:00 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Ohlsson", "Henrik", ""], ["Yang", "Allen Y.", ""], ["Dong", "Roy", ""], ["Verhaegen", "Michel", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1301.7047", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao, Elizaveta Levina and Ji Zhu", "title": "Link prediction for partially observed networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is one of the fundamental problems in network analysis. In\nmany applications, notably in genetics, a partially observed network may not\ncontain any negative examples of absent edges, which creates a difficulty for\nmany existing supervised learning approaches. We develop a new method which\ntreats the observed network as a sample of the true network with different\nsampling rates for positive and negative examples. We obtain a relative ranking\nof potential links by their probabilities, utilizing information on node\ncovariates as well as on network topology. Empirically, the method performs\nwell under many settings, including when the observed network is sparse. We\napply the method to a protein-protein interaction network and a school\nfriendship network.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 20:22:46 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Zhao", "Yunpeng", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "1301.7115", "submitter": "Madhu Advani Madhu Advani", "authors": "Madhu Advani, Subhaneil Lahiri, and Surya Ganguli", "title": "Statistical mechanics of complex neural systems and high dimensional\n  data", "comments": "72 pages, 8 figures, iopart.cls, to appear in JSTAT", "journal-ref": null, "doi": "10.1088/1742-5468/2013/03/P03014", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental advances in neuroscience have opened new vistas into the\nimmense complexity of neuronal networks. This proliferation of data challenges\nus on two parallel fronts. First, how can we form adequate theoretical\nframeworks for understanding how dynamical network processes cooperate across\nwidely disparate spatiotemporal scales to solve important computational\nproblems? And second, how can we extract meaningful models of neuronal systems\nfrom high dimensional datasets? To aid in these challenges, we give a\npedagogical review of a collection of ideas and theoretical methods arising at\nthe intersection of statistical physics, computer science and neurobiology. We\nintroduce the interrelated replica and cavity methods, which originated in\nstatistical physics as powerful ways to quantitatively analyze large highly\nheterogeneous systems of many interacting degrees of freedom. We also introduce\nthe closely related notion of message passing in graphical models, which\noriginated in computer science as a distributed algorithm capable of solving\nlarge inference and optimization problems involving many coupled variables. We\nthen show how both the statistical physics and computer science perspectives\ncan be applied in a wide diversity of contexts to problems arising in\ntheoretical neuroscience and data analysis. Along the way we discuss spin\nglasses, learning theory, illusions of structure in noise, random matrices,\ndimensionality reduction, and compressed sensing, all within the unified\nformalism of the replica method. Moreover, we review recent conceptual\nconnections between message passing in graphical models, and neural computation\nand learning. Overall, these ideas illustrate how statistical physics and\ncomputer science might provide a lens through which we can uncover emergent\ncomputational functions buried deep within the dynamical complexities of\nneuronal networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 00:50:05 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Advani", "Madhu", ""], ["Lahiri", "Subhaneil", ""], ["Ganguli", "Surya", ""]]}, {"id": "1301.7118", "submitter": "Yixin Fang", "authors": "Yixin Fang, Junhui Wang, and Wei Sun", "title": "A note on selection stability: combining stability and prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many regularized procedures have been proposed for variable\nselection in linear regression, but their performance depends on the tuning\nparameter selection. Here a criterion for the tuning parameter selection is\nproposed, which combines the strength of both stability selection and\ncross-validation and therefore is referred as the prediction and stability\nselection (PASS). The selection consistency is established assuming the data\ngenerating model is a subset of the full model, and the small sample\nperformance is demonstrated through some simulation studies where the\nassumption is either held or violated.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 01:19:12 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Fang", "Yixin", ""], ["Wang", "Junhui", ""], ["Sun", "Wei", ""]]}, {"id": "1301.7189", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Approximate Counting of Graphical Models Via MCMC Revisited", "comments": "In Proceedings of the 15th Conference of the Spanish Association for\n  Artificial Intelligence (CAEPIA 2013). Lecture Notes in Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Pe\\~na (2007), MCMC sampling is applied to approximately calculate the\nratio of essential graphs (EGs) to directed acyclic graphs (DAGs) for up to 20\nnodes. In the present paper, we extend that work from 20 to 31 nodes. We also\nextend that work by computing the approximate ratio of connected EGs to\nconnected DAGs, of connected EGs to EGs, and of connected DAGs to DAGs.\nFurthermore, we prove that the latter ratio is asymptotically 1. We also\ndiscuss the implications of these results for learning DAGs from data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 10:40:07 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2013 20:30:47 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1301.7373", "submitter": "Nir Friedman", "authors": "Nir Friedman", "title": "The Bayesian Structural EM Algorithm", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-129-138", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a flurry of works on learning Bayesian\nnetworks from data. One of the hard problems in this area is how to effectively\nlearn the structure of a belief network from incomplete data- that is, in the\npresence of missing values or hidden variables. In a recent paper, I introduced\nan algorithm called Structural EM that combines the standard Expectation\nMaximization (EM) algorithm, which optimizes parameters, with structure search\nfor model selection. That algorithm learns networks based on penalized\nlikelihood scores, which include the BIC/MDL score and various approximations\nto the Bayesian score. In this paper, I extend Structural EM to deal directly\nwith Bayesian model selection. I prove the convergence of the resulting\nalgorithm and show how to apply it for learning a large class of probabilistic\nmodels, including Bayesian networks and some variants thereof.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:37 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Friedman", "Nir", ""]]}, {"id": "1301.7375", "submitter": "Alex Gammerman", "authors": "Alex Gammerman, Volodya Vovk, Vladimir Vapnik", "title": "Learning by Transduction", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-148-155", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for predicting a classification of an object given\nclassifications of the objects in the training set, assuming that the pairs\nobject/classification are generated by an i.i.d. process from a continuous\nprobability distribution. Our method is a modification of Vapnik's\nsupport-vector machine; its main novelty is that it gives not only the\nprediction itself but also a practicable measure of the evidence found in\nsupport of that prediction. We also describe a procedure for assigning degrees\nof confidence to predictions made by the support vector machine. Some\nexperimental results are presented, and possible extensions of the algorithms\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:47 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Gammerman", "Alex", ""], ["Vovk", "Volodya", ""], ["Vapnik", "Vladimir", ""]]}, {"id": "1301.7376", "submitter": "Dan Geiger", "authors": "Dan Geiger, Christopher Meek", "title": "Graphical Models and Exponential Families", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-156-165", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a classification of graphical models according to their\nrepresentation as subfamilies of exponential families. Undirected graphical\nmodels with no hidden variables are linear exponential families (LEFs),\ndirected acyclic graphical models and chain graphs with no hidden variables,\nincluding Bayesian networks with several families of local distributions, are\ncurved exponential families (CEFs) and graphical models with hidden variables\nare stratified exponential families (SEFs). An SEF is a finite union of CEFs\nsatisfying a frontier condition. In addition, we illustrate how one can\nautomatically generate independence and non-independence constraints on the\ndistributions over the observable variables implied by a Bayesian network with\nhidden variables. The relevance of these results for model selection is\nexamined.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:52 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Geiger", "Dan", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.7378", "submitter": "Peter D Grunwald", "authors": "Peter D Grunwald, Petri Kontkanen, Petri Myllymaki, Tomi Silander,\n  Henry Tirri", "title": "Minimum Encoding Approaches for Predictive Modeling", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-183-192", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze differences between two information-theoretically motivated\napproaches to statistical inference and model selection: the Minimum\nDescription Length (MDL) principle, and the Minimum Message Length (MML)\nprinciple. Based on this analysis, we present two revised versions of MML: a\npointwise estimator which gives the MML-optimal single parameter model, and a\nvolumewise estimator which gives the MML-optimal region in the parameter space.\nOur empirical results suggest that with small data sets, the MDL approach\nyields more accurate predictions than the MML estimators. The empirical results\nalso demonstrate that the revised MML estimators introduced here perform better\nthan the original MML estimator suggested by Wallace and Freeman.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:02 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Grunwald", "Peter D", ""], ["Kontkanen", "Petri", ""], ["Myllymaki", "Petri", ""], ["Silander", "Tomi", ""], ["Tirri", "Henry", ""]]}, {"id": "1301.7390", "submitter": "Wenxin Jiang", "authors": "Wenxin Jiang, Martin A. Tanner", "title": "Hierarchical Mixtures-of-Experts for Exponential Family Regression\n  Models with Generalized Linear Mean Functions: A Survey of Approximation and\n  Consistency Results", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-296-303", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a class of hierarchical mixtures-of-experts (HME) models where\nexponential family regression models with generalized linear mean functions of\nthe form psi(ga+fx^Tfgb) are mixed. Here psi(...) is the inverse link function.\nSuppose the true response y follows an exponential family regression model with\nmean function belonging to a class of smooth functions of the form psi(h(fx))\nwhere h(...)in W_2^infty (a Sobolev class over [0,1]^{s}). It is shown that the\nHME probability density functions can approximate the true density, at a rate\nof O(m^{-2/s}) in L_p norm, and at a rate of O(m^{-4/s}) in Kullback-Leibler\ndivergence. These rates can be achieved within the family of HME structures\nwith no more than s-layers, where s is the dimension of the predictor fx. It is\nalso shown that likelihood-based inference based on HME is consistent in\nrecovering the truth, in the sense that as the sample size n and the number of\nexperts m both increase, the mean square error of the predicted mean response\ngoes to zero. Conditions for such results to hold are stated and discussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:59 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Jiang", "Wenxin", ""], ["Tanner", "Martin A.", ""]]}, {"id": "1301.7392", "submitter": "Michael Kearns", "authors": "Michael Kearns, Lawrence Saul", "title": "Large Deviation Methods for Approximate Probabilistic Inference", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-311-319", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two-layer belief networks of binary random variables in which the\nconditional probabilities Pr[childlparents] depend monotonically on weighted\nsums of the parents. In large networks where exact probabilistic inference is\nintractable, we show how to compute upper and lower bounds on many\nprobabilities of interest. In particular, using methods from large deviation\ntheory, we derive rigorous bounds on marginal probabilities such as\nPr[children] and prove rates of convergence for the accuracy of our bounds as a\nfunction of network size. Our results apply to networks with generic transfer\nfunction parameterizations of the conditional probability tables, such as\nsigmoid and noisy-OR. They also explicitly illustrate the types of averaging\nbehavior that can simplify the problem of inference in large networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:09 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Kearns", "Michael", ""], ["Saul", "Lawrence", ""]]}, {"id": "1301.7393", "submitter": "Neil D. Lawrence", "authors": "Neil D. Lawrence, Christopher M. Bishop, Michael I. Jordan", "title": "Mixture Representations for Inference and Learning in Boltzmann Machines", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-320-327", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines are undirected graphical models with two-state stochastic\nvariables, in which the logarithms of the clique potentials are quadratic\nfunctions of the node states. They have been widely studied in the neural\ncomputing literature, although their practical applicability has been limited\nby the difficulty of finding an effective learning algorithm. One\nwell-established approach, known as mean field theory, represents the\nstochastic distribution using a factorized approximation. However, the\ncorresponding learning algorithm often fails to find a good solution. We\nconjecture that this is due to the implicit uni-modality of the mean field\napproximation which is therefore unable to capture multi-modality in the true\ndistribution. In this paper we use variational methods to approximate the\nstochastic distribution using multi-modal mixtures of factorized distributions.\nWe present results for both inference and learning to demonstrate the\neffectiveness of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:15 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Lawrence", "Neil D.", ""], ["Bishop", "Christopher M.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.7401", "submitter": "Marina Meila", "authors": "Marina Meila, David Heckerman", "title": "An Experimental Comparison of Several Clustering and Initialization\n  Methods", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-386-395", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine methods for clustering in high dimensions. In the first part of\nthe paper, we perform an experimental comparison between three batch clustering\nalgorithms: the Expectation-Maximization (EM) algorithm, a winner take all\nversion of the EM algorithm reminiscent of the K-means algorithm, and\nmodel-based hierarchical agglomerative clustering. We learn naive-Bayes models\nwith a hidden root node, using high-dimensional discrete-variable data sets\n(both real and synthetic). We find that the EM algorithm significantly\noutperforms the other methods, and proceed to investigate the effect of various\ninitialization schemes on the final solution produced by the EM algorithm. The\ninitializations that we consider are (1) parameters sampled from an\nuninformative prior, (2) random perturbations of the marginal distribution of\nthe data, and (3) the output of hierarchical agglomerative clustering. Although\nthe methods are substantially different, they lead to learned models that are\nstrikingly similar in quality.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:55 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:17:06 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Meila", "Marina", ""], ["Heckerman", "David", ""]]}, {"id": "1301.7411", "submitter": "Raffaella Settimi", "authors": "Raffaella Settimi, Jim Q. Smith", "title": "On the Geometry of Bayesian Graphical Models with Hidden Variables", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-472-479", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the geometry of the likelihood of the unknown\nparameters in a simple class of Bayesian directed graphs with hidden variables.\nThis enables us, before any numerical algorithms are employed, to obtain\ncertain insights in the nature of the unidentifiability inherent in such\nmodels, the way posterior densities will be sensitive to prior densities and\nthe typical geometrical form these posterior densities might take. Many of\nthese insights carry over into more complicated Bayesian networks with\nsystematic missing data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:43 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Settimi", "Raffaella", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1301.7415", "submitter": "Bo Thiesson", "authors": "Bo Thiesson, Christopher Meek, David Maxwell Chickering, David\n  Heckerman", "title": "Learning Mixtures of DAG Models", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-504-513", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe computationally efficient methods for learning mixtures in which\neach component is a directed acyclic graphical model (mixtures of DAGs or\nMDAGs). We argue that simple search-and-score algorithms are infeasible for a\nvariety of problems, and introduce a feasible approach in which parameter and\nstructure search is interleaved and expected data is treated as real data. Our\napproach can be viewed as a combination of (1) the Cheeseman--Stutz asymptotic\napproximation for model posterior probability and (2) the\nExpectation--Maximization algorithm. We evaluate our procedure for selecting\namong MDAGs on synthetic and real examples.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:07:02 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:27:23 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Thiesson", "Bo", ""], ["Meek", "Christopher", ""], ["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1301.7619", "submitter": "Gonzalo Mateos", "authors": "Juan Andres Bazerque, Gonzalo Mateos, and Georgios B. Giannakis", "title": "Rank regularization and Bayesian inference for tensor completion and\n  extrapolation", "comments": "12 pages, submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2013.2278516", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel regularizer of the PARAFAC decomposition factors capturing the\ntensor's rank is proposed in this paper, as the key enabler for completion of\nthree-way data arrays with missing entries. Set in a Bayesian framework, the\ntensor completion method incorporates prior information to enhance its\nsmoothing and prediction capabilities. This probabilistic approach can\nnaturally accommodate general models for the data distribution, lending itself\nto various fitting criteria that yield optimum estimates in the\nmaximum-a-posteriori sense. In particular, two algorithms are devised for\nGaussian- and Poisson-distributed data, that minimize the rank-regularized\nleast-squares error and Kullback-Leibler divergence, respectively. The proposed\ntechnique is able to recover the \"ground-truth'' tensor rank when tested on\nsynthetic data, and to complete brain imaging and yeast gene expression\ndatasets with 50% and 15% of missing entries respectively, resulting in\nrecovery errors at -10dB and -15dB.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 14:17:28 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Bazerque", "Juan Andres", ""], ["Mateos", "Gonzalo", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1301.7724", "submitter": "Santiago Segarra", "authors": "Gunnar Carlsson, Facundo M\\'emoli, Alejandro Ribeiro and Santiago\n  Segarra", "title": "Axiomatic Construction of Hierarchical Clustering in Asymmetric Networks", "comments": "This is a largely extended version of the previous conference\n  submission under the same title. The current version contains the material in\n  the previous version (published in ICASSP 2013) as well as material presented\n  at the Asilomar Conference on Signal, Systems, and Computers 2013, GlobalSIP\n  2013, and ICML 2014. Also, unpublished material is included in the current\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers networks where relationships between nodes are\nrepresented by directed dissimilarities. The goal is to study methods for the\ndetermination of hierarchical clusters, i.e., a family of nested partitions\nindexed by a connectivity parameter, induced by the given dissimilarity\nstructures. Our construction of hierarchical clustering methods is based on\ndefining admissible methods to be those methods that abide by the axioms of\nvalue - nodes in a network with two nodes are clustered together at the maximum\nof the two dissimilarities between them - and transformation - when\ndissimilarities are reduced, the network may become more clustered but not\nless. Several admissible methods are constructed and two particular methods,\ntermed reciprocal and nonreciprocal clustering, are shown to provide upper and\nlower bounds in the space of admissible methods. Alternative clustering\nmethodologies and axioms are further considered. Allowing the outcome of\nhierarchical clustering to be asymmetric, so that it matches the asymmetry of\nthe original data, leads to the inception of quasi-clustering methods. The\nexistence of a unique quasi-clustering method is shown. Allowing clustering in\na two-node network to proceed at the minimum of the two dissimilarities\ngenerates an alternative axiomatic construction. There is a unique clustering\nmethod in this case too. The paper also develops algorithms for the computation\nof hierarchical clusters using matrix powers on a min-max dioid algebra and\nstudies the stability of the methods proposed. We proved that most of the\nmethods introduced in this paper are such that similar networks yield similar\nhierarchical clustering results. Algorithms are exemplified through their\napplication to networks describing internal migration within states of the\nUnited States (U.S.) and the interrelation between sectors of the U.S. economy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 19:39:03 GMT"}, {"version": "v2", "created": "Tue, 2 Sep 2014 18:21:18 GMT"}], "update_date": "2014-09-03", "authors_parsed": [["Carlsson", "Gunnar", ""], ["M\u00e9moli", "Facundo", ""], ["Ribeiro", "Alejandro", ""], ["Segarra", "Santiago", ""]]}, {"id": "1301.7745", "submitter": "Justin Kinney", "authors": "Justin B. Kinney, Gurinder S. Atwal", "title": "Equitability, mutual information, and the maximal information\n  coefficient", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1309933111", "report-no": null, "categories": "q-bio.QM math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reshef et al. recently proposed a new statistical measure, the \"maximal\ninformation coefficient\" (MIC), for quantifying arbitrary dependencies between\npairs of stochastic quantities. MIC is based on mutual information, a\nfundamental quantity in information theory that is widely understood to serve\nthis need. MIC, however, is not an estimate of mutual information. Indeed, it\nwas claimed that MIC possesses a desirable mathematical property called\n\"equitability\" that mutual information lacks. This was not proven; instead it\nwas argued solely through the analysis of simulated data. Here we show that\nthis claim, in fact, is incorrect. First we offer mathematical proof that no\n(non-trivial) dependence measure satisfies the definition of equitability\nproposed by Reshef et al.. We then propose a self-consistent and more general\ndefinition of equitability that follows naturally from the Data Processing\nInequality. Mutual information satisfies this new definition of equitability\nwhile MIC does not. Finally, we show that the simulation evidence offered by\nReshef et al. was artifactual. We conclude that estimating mutual information\nis not only practical for many real-world applications, but also provides a\nnatural solution to the problem of quantifying associations in large data sets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 20:44:28 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Kinney", "Justin B.", ""], ["Atwal", "Gurinder S.", ""]]}]