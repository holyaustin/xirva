[{"id": "1510.00001", "submitter": "Krzysztof Wo{\\l}k", "authors": "Krzysztof Wo{\\l}k", "title": "Polish to English Statistical Machine Translation", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.09097,\n  arXiv:1509.08909, arXiv:1509.08874", "journal-ref": "Polish to English Statistical Machine Translation., XV\n  International Phd Workshop OWD 2013, Wis{\\l}a, p.108-115, 2013", "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research explores the effects of various training settings on a Polish\nto English Statistical Machine Translation system for spoken language. Various\nelements of the TED, Europarl, and OPUS parallel text corpora were used as the\nbasis for training of language models, for development, tuning and testing of\nthe translation system. The BLEU, NIST, METEOR and TER metrics were used to\nevaluate the effects of the data preparations on the translation results.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 09:41:00 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Wo\u0142k", "Krzysztof", ""]]}, {"id": "1510.00012", "submitter": "Jianbo Ye", "authors": "Jianbo Ye, Panruo Wu, James Z. Wang and Jia Li", "title": "Fast Discrete Distribution Clustering Using Wasserstein Barycenter with\n  Sparse Support", "comments": "double-column, 17 pages, 3 figures, 5 tables. English usage improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a variety of research areas, the weighted bag of vectors and the histogram\nare widely used descriptors for complex objects. Both can be expressed as\ndiscrete distributions. D2-clustering pursues the minimum total within-cluster\nvariation for a set of discrete distributions subject to the\nKantorovich-Wasserstein metric. D2-clustering has a severe scalability issue,\nthe bottleneck being the computation of a centroid distribution, called\nWasserstein barycenter, that minimizes its sum of squared distances to the\ncluster members. In this paper, we develop a modified Bregman ADMM approach for\ncomputing the approximate discrete Wasserstein barycenter of large clusters. In\nthe case when the support points of the barycenters are unknown and have low\ncardinality, our method achieves high accuracy empirically at a much reduced\ncomputational cost. The strengths and weaknesses of our method and its\nalternatives are examined through experiments, and we recommend scenarios for\ntheir respective usage. Moreover, we develop both serial and parallelized\nversions of the algorithm. By experimenting with large-scale data, we\ndemonstrate the computational efficiency of the new methods and investigate\ntheir convergence properties and numerical stability. The clustering results\nobtained on several datasets in different domains are highly competitive in\ncomparison with some widely used methods in the corresponding areas.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 20:10:59 GMT"}, {"version": "v2", "created": "Sun, 8 May 2016 22:40:26 GMT"}, {"version": "v3", "created": "Thu, 6 Oct 2016 23:41:22 GMT"}, {"version": "v4", "created": "Mon, 9 Jan 2017 18:14:20 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Ye", "Jianbo", ""], ["Wu", "Panruo", ""], ["Wang", "James Z.", ""], ["Li", "Jia", ""]]}, {"id": "1510.00084", "submitter": "Xiangyu Wang", "authors": "Binyan Jiang, Xiangyu Wang, and Chenlei Leng", "title": "A Direct Approach for Sparse Quadratic Discriminant Analysis", "comments": "Updated to the JMLR format", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic discriminant analysis (QDA) is a standard tool for classification\ndue to its simplicity and flexibility. Because the number of its parameters\nscales quadratically with the number of the variables, QDA is not practical,\nhowever, when the dimensionality is relatively large. To address this, we\npropose a novel procedure named DA-QDA for QDA in analyzing high-dimensional\ndata. Formulated in a simple and coherent framework, DA-QDA aims to directly\nestimate the key quantities in the Bayes discriminant function including\nquadratic interactions and a linear index of the variables for classification.\nUnder appropriate sparsity assumptions, we establish consistency results for\nestimating the interactions and the linear index, and further demonstrate that\nthe misclassification rate of our procedure converges to the optimal Bayes\nrisk, even when the dimensionality is exponentially high with respect to the\nsample size. An efficient algorithm based on the alternating direction method\nof multipliers (ADMM) is developed for finding interactions, which is much\nfaster than its competitor in the literature. The promising performance of\nDA-QDA is illustrated via extensive simulation studies and the analysis of four\nreal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 01:24:20 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 05:57:40 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2016 05:00:10 GMT"}, {"version": "v4", "created": "Wed, 5 Sep 2018 08:36:22 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Jiang", "Binyan", ""], ["Wang", "Xiangyu", ""], ["Leng", "Chenlei", ""]]}, {"id": "1510.00087", "submitter": "Adrian Weller", "authors": "Adrian Weller and Justin Domke", "title": "Clamping Improves TRW and Mean Field Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effect of clamping variables for approximate inference in\nundirected graphical models with pairwise relationships and discrete variables.\nFor any number of variable labels, we demonstrate that clamping and summing\napproximate sub-partition functions can lead only to a decrease in the\npartition function estimate for TRW, and an increase for the naive mean field\nmethod, in each case guaranteeing an improvement in the approximation and\nbound. We next focus on binary variables, add the Bethe approximation to\nconsideration and examine ways to choose good variables to clamp, introducing\nnew methods. We show the importance of identifying highly frustrated cycles,\nand of checking the singleton entropy of a variable. We explore the value of\nour methods by empirical analysis and draw lessons to guide practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 01:49:04 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Weller", "Adrian", ""], ["Domke", "Justin", ""]]}, {"id": "1510.00112", "submitter": "James Dowty", "authors": "James G. Dowty", "title": "Higher-order asymptotics for the parametric complexity", "comments": "Version 3: Fixed a minor error in the introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parametric complexity is the key quantity in the minimum description\nlength (MDL) approach to statistical model selection. Rissanen and others have\nshown that the parametric complexity of a statistical model approaches a simple\nfunction of the Fisher information volume of the model as the sample size $n$\ngoes to infinity. This paper derives higher-order asymptotic expansions for the\nparametric complexity, in the case of exponential families and independent and\nidentically distributed data. These higher-order approximations are calculated\nfor some examples and are shown to have better finite-sample behaviour than\nRissanen's approximation. The higher-order terms are given as expressions\ninvolving cumulants (or, more naturally, the Amari-Chentsov tensors), and these\nterms are likely to be interesting in themselves since they arise naturally\nfrom the general information-theoretic principles underpinning MDL. The\nderivation given here specializes to an alternative and arguably simpler proof\nof Rissanen's result (for the case considered here), proving for the first time\nthat his approximation is $O(n^{-1})$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 05:42:25 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2015 02:41:43 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2015 04:21:33 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Dowty", "James G.", ""]]}, {"id": "1510.00165", "submitter": "Miguel Angel Rodriguez Marquez", "authors": "Daniel Schweizer, Michael Zehnder, Holger Wache, Hans-Friedrich\n  Witschel, Danilo Zanatta, Miguel Rodriguez", "title": "Using consumer behavior data to reduce energy consumption in smart homes", "comments": "To be presented at IEEE International Conference of Machine Learning\n  and Applications (ICMLA, Dec. 2015). arXiv admin note: text overlap with\n  arXiv:1509.05722", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses how usage patterns and preferences of inhabitants can be\nlearned efficiently to allow smart homes to autonomously achieve energy\nsavings. We propose a frequent sequential pattern mining algorithm suitable for\nreal-life smart home event data. The performance of the proposed algorithm is\ncompared to existing algorithms regarding completeness/correctness of the\nresults, run times as well as memory consumption and elaborates on the\nshortcomings of the different solutions. We also present a recommender system\nbased on the developed algorithm that provides recommendations to the users to\nreduce their energy consumption. The recommender system was deployed to a set\nof test homes. The test participants rated the impact of the recommendations on\ntheir comfort. We used this feedback to adjust the system parameters and make\nit more accurate during a second test phase.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 09:49:45 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Schweizer", "Daniel", ""], ["Zehnder", "Michael", ""], ["Wache", "Holger", ""], ["Witschel", "Hans-Friedrich", ""], ["Zanatta", "Danilo", ""], ["Rodriguez", "Miguel", ""]]}, {"id": "1510.00259", "submitter": "Stephanie L. Hyland", "authors": "Stephanie L. Hyland, Theofanis Karaletsos, Gunnar R\\\"atsch", "title": "A Generative Model of Words and Relationships from Multiple Sources", "comments": "8 pages, 5 figures; incorporated feedback from reviewers; to appear\n  in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models are a powerful tool to embed words into semantic\nvector spaces. However, learning such models generally relies on the\navailability of abundant and diverse training examples. In highly specialised\ndomains this requirement may not be met due to difficulties in obtaining a\nlarge corpus, or the limited range of expression in average use. Such domains\nmay encode prior knowledge about entities in a knowledge base or ontology. We\npropose a generative model which integrates evidence from diverse data sources,\nenabling the sharing of semantic information. We achieve this by generalising\nthe concept of co-occurrence from distributional semantics to include other\nrelationships between entities or words, which we model as affine\ntransformations on the embedding space. We demonstrate the effectiveness of\nthis approach by outperforming recent models on a link prediction task and\ndemonstrating its ability to profit from partially or fully unobserved data\ntraining labels. We further demonstrate the usefulness of learning from\ndifferent data sources with overlapping vocabularies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 14:42:19 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 17:08:28 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Hyland", "Stephanie L.", ""], ["Karaletsos", "Theofanis", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1510.00331", "submitter": "Tadahiro Taniguchi", "authors": "Tadahiro Taniguchi, Toshiaki Takano and Ryo Yoshino", "title": "Multimodal Hierarchical Dirichlet Process-based Active Perception", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an active perception method for recognizing object\ncategories based on the multimodal hierarchical Dirichlet process (MHDP). The\nMHDP enables a robot to form object categories using multimodal information,\ne.g., visual, auditory, and haptic information, which can be observed by\nperforming actions on an object. However, performing many actions on a target\nobject requires a long time. In a real-time scenario, i.e., when the time is\nlimited, the robot has to determine the set of actions that is most effective\nfor recognizing a target object. We propose an MHDP-based active perception\nmethod that uses the information gain (IG) maximization criterion and lazy\ngreedy algorithm. We show that the IG maximization criterion is optimal in the\nsense that the criterion is equivalent to a minimization of the expected\nKullback--Leibler divergence between a final recognition state and the\nrecognition state after the next set of actions. However, a straightforward\ncalculation of IG is practically impossible. Therefore, we derive an efficient\nMonte Carlo approximation method for IG by making use of a property of the\nMHDP. We also show that the IG has submodular and non-decreasing properties as\na set function because of the structure of the graphical model of the MHDP.\nTherefore, the IG maximization problem is reduced to a submodular maximization\nproblem. This means that greedy and lazy greedy algorithms are effective and\nhave a theoretical justification for their performance. We conducted an\nexperiment using an upper-torso humanoid robot and a second one using synthetic\ndata. The experimental results show that the method enables the robot to select\na set of actions that allow it to recognize target objects quickly and\naccurately. The results support our theoretical outcomes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 17:36:42 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 15:45:44 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2016 17:13:57 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Taniguchi", "Tadahiro", ""], ["Takano", "Toshiaki", ""], ["Yoshino", "Ryo", ""]]}, {"id": "1510.00452", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani, Yoav Freund", "title": "Optimal Binary Classifier Aggregation for General Losses", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of aggregating an ensemble of predictors with known\nloss bounds in a semi-supervised binary classification setting, to minimize\nprediction loss incurred on the unlabeled data. We find the minimax optimal\npredictions for a very general class of loss functions including all convex and\nmany non-convex losses, extending a recent analysis of the problem for\nmisclassification error. The result is a family of semi-supervised ensemble\naggregation algorithms which are as efficient as linear learning by convex\noptimization, but are minimax optimal without any relaxations. Their decision\nrules take a form familiar in decision theory -- applying sigmoid functions to\na notion of ensemble margin -- without the assumptions typically made in\nmargin-based learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 23:58:46 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2015 06:05:15 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2015 20:28:54 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2016 02:04:48 GMT"}, {"version": "v5", "created": "Mon, 7 Nov 2016 10:28:36 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Balsubramani", "Akshay", ""], ["Freund", "Yoav", ""]]}, {"id": "1510.00503", "submitter": "Julien Bect", "authors": "Paul Feliot (L2S, GdR MASCOT-NUM), Julien Bect (L2S, GdR MASCOT-NUM),\n  Emmanuel Vazquez (L2S, GdR MASCOT-NUM)", "title": "A Bayesian approach to constrained single- and multi-objective\n  optimization", "comments": null, "journal-ref": "Journal of Global Optimization, 67(1):97-133 (2017)", "doi": "10.1007/s10898-016-0427-3", "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses the problem of derivative-free (single- or\nmulti-objective) optimization subject to multiple inequality constraints. Both\nthe objective and constraint functions are assumed to be smooth, non-linear and\nexpensive to evaluate. As a consequence, the number of evaluations that can be\nused to carry out the optimization is very limited, as in complex industrial\ndesign optimization problems. The method we propose to overcome this difficulty\nhas its roots in both the Bayesian and the multi-objective optimization\nliteratures. More specifically, an extended domination rule is used to handle\nobjectives and constraints in a unified way, and a corresponding expected\nhyper-volume improvement sampling criterion is proposed. This new criterion is\nnaturally adapted to the search of a feasible point when none is available, and\nreduces to existing Bayesian sampling criteria---the classical Expected\nImprovement (EI) criterion and some of its constrained/multi-objective\nextensions---as soon as at least one feasible point is available. The\ncalculation and optimization of the criterion are performed using Sequential\nMonte Carlo techniques. In particular, an algorithm similar to the subset\nsimulation method, which is well known in the field of structural reliability,\nis used to estimate the criterion. The method, which we call BMOO (for Bayesian\nMulti-Objective Optimization), is compared to state-of-the-art algorithms for\nsingle- and multi-objective constrained optimization.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 06:41:49 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 06:18:14 GMT"}, {"version": "v3", "created": "Mon, 9 May 2016 07:34:53 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Feliot", "Paul", "", "L2S, GdR MASCOT-NUM"], ["Bect", "Julien", "", "L2S, GdR MASCOT-NUM"], ["Vazquez", "Emmanuel", "", "L2S, GdR MASCOT-NUM"]]}, {"id": "1510.00633", "submitter": "Jialei Wang", "authors": "Jialei Wang, Mladen Kolar, Nathan Srebro", "title": "Distributed Multitask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed multi-task learning, where each\nmachine learns a separate, but related, task. Specifically, each machine learns\na linear predictor in high-dimensional space,where all tasks share the same\nsmall support. We present a communication-efficient estimator based on the\ndebiased lasso and show that it is comparable with the optimal centralized\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 16:15:30 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Wang", "Jialei", ""], ["Kolar", "Mladen", ""], ["Srebro", "Nathan", ""]]}, {"id": "1510.00701", "submitter": "Abhinav Sambasivan", "authors": "Abhinav V. Sambasivan and Jarvis D. Haupt", "title": "Minimax Lower Bounds for Noisy Matrix Completion Under Sparse Factor\n  Models", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines fundamental error characteristics for a general class of\nmatrix completion problems, where the matrix of interest is a product of two a\npriori unknown matrices, one of which is sparse, and the observations are\nnoisy. Our main contributions come in the form of minimax lower bounds for the\nexpected per-element squared error for this problem under under several common\nnoise models. Specifically, we analyze scenarios where the corruptions are\ncharacterized by additive Gaussian noise or additive heavier-tailed (Laplace)\nnoise, Poisson-distributed observations, and highly-quantized (e.g., one-bit)\nobservations, as instances of our general result. Our results establish that\nthe error bounds derived in (Soni et al., 2016) for complexity-regularized\nmaximum likelihood estimators achieve, up to multiplicative constants and\nlogarithmic factors, the minimax error rates in each of these noise scenarios,\nprovided that the nominal number of observations is large enough, and the\nsparse factor has (on an average) at least one non-zero per column.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 19:45:02 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 23:01:19 GMT"}, {"version": "v3", "created": "Thu, 26 Oct 2017 16:40:18 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Sambasivan", "Abhinav V.", ""], ["Haupt", "Jarvis D.", ""]]}, {"id": "1510.00757", "submitter": "Giuseppe Burtini", "authors": "Giuseppe Burtini, Jason Loeppky, Ramon Lawrence", "title": "A Survey of Online Experiment Design with the Stochastic Multi-Armed\n  Bandit", "comments": "49 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive and sequential experiment design is a well-studied area in numerous\ndomains. We survey and synthesize the work of the online statistical learning\nparadigm referred to as multi-armed bandits integrating the existing research\nas a resource for a certain class of online experiments. We first explore the\ntraditional stochastic model of a multi-armed bandit, then explore a taxonomic\nscheme of complications to that model, for each complication relating it to a\nspecific requirement or consideration of the experiment design context.\nFinally, at the end of the paper, we present a table of known upper-bounds of\nregret for all studied algorithms providing both perspectives for future\ntheoretical work and a decision-making tool for practitioners looking for\ntheoretical guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 23:28:11 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 18:44:44 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2015 17:38:26 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2015 18:37:43 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Burtini", "Giuseppe", ""], ["Loeppky", "Jason", ""], ["Lawrence", "Ramon", ""]]}, {"id": "1510.00817", "submitter": "Qi Li", "authors": "Qi Li", "title": "Distributed Parameter Map-Reduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how to convert a machine learning problem into a series\nof map-reduce tasks. We study logistic regression algorithm. In logistic\nregression algorithm, it is assumed that samples are independent and each\nsample is assigned a probability. Parameters are obtained by maxmizing the\nproduct of all sample probabilities. Rapid expansion of training samples brings\nchallenges to machine learning method. Training samples are so many that they\ncan be only stored in distributed file system and driven by map-reduce style\nprograms. The main step of logistic regression is inference. According to\nmap-reduce spirit, each sample makes inference through a separate map\nprocedure. But the premise of inference is that the map procedure holds\nparameters for all features in the sample. In this paper, we propose\nDistributed Parameter Map-Reduce, in which not only samples, but also\nparameters are distributed in nodes of distributed filesystem. Through a series\nof map-reduce tasks, we assign each sample parameters for its features, make\ninference for the sample and update paramters of the model. The above processes\nare excuted looply until convergence. We test the proposed algorithm in actual\nhadoop production environment. Experiments show that the acceleration of the\nalgorithm is in linear relationship with the number of cluster nodes.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2015 13:12:28 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Li", "Qi", ""]]}, {"id": "1510.00850", "submitter": "Soheil Feizi", "authors": "Luke O'Connor, Muriel M\\'edard and Soheil Feizi", "title": "Maximum Likelihood Latent Space Embedding of Logistic Random Dot Product\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A latent space model for a family of random graphs assigns real-valued\nvectors to nodes of the graph such that edge probabilities are determined by\nlatent positions. Latent space models provide a natural statistical framework\nfor graph visualizing and clustering. A latent space model of particular\ninterest is the Random Dot Product Graph (RDPG), which can be fit using an\nefficient spectral method; however, this method is based on a heuristic that\ncan fail, even in simple cases. Here, we consider a closely related latent\nspace model, the Logistic RDPG, which uses a logistic link function to map from\nlatent positions to edge likelihoods. Over this model, we show that\nasymptotically exact maximum likelihood inference of latent position vectors\ncan be achieved using an efficient spectral method. Our method involves\ncomputing top eigenvectors of a normalized adjacency matrix and scaling\neigenvectors using a regression step. The novel regression scaling step is an\nessential part of the proposed method. In simulations, we show that our\nproposed method is more accurate and more robust than common practices. We also\nshow the effectiveness of our approach over standard real networks of the\nkarate club and political blogs.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2015 17:43:32 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 14:29:16 GMT"}, {"version": "v3", "created": "Wed, 30 Aug 2017 21:41:40 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["O'Connor", "Luke", ""], ["M\u00e9dard", "Muriel", ""], ["Feizi", "Soheil", ""]]}, {"id": "1510.00878", "submitter": "Claudio Alexandre", "authors": "Claudio Alexandre and Jo\\~ao Balsa", "title": "Client Profiling for an Anti-Money Laundering System", "comments": "7 pages, 15 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a data mining approach for profiling bank clients in order to\nsupport the process of detection of anti-money laundering operations. We first\npresent the overall system architecture, and then focus on the relevant\ncomponent for this paper. We detail the experiments performed on real world\ndata from a financial institution, which allowed us to group clients in\nclusters and then generate a set of classification rules. We discuss the\nrelevance of the founded client profiles and of the generated classification\nrules. According to the defined overall agent-based architecture, these rules\nwill be incorporated in the knowledge base of the intelligent agents\nresponsible for the signaling of suspicious transactions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2015 22:31:58 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 16:57:57 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Alexandre", "Claudio", ""], ["Balsa", "Jo\u00e3o", ""]]}, {"id": "1510.00967", "submitter": "Thibaut Horel", "authors": "Panos Toulis, Thibaut Horel, Edoardo M. Airoldi", "title": "The Proximal Robbins-Monro Method", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for parameter estimation with massive datasets has reinvigorated\ninterest in stochastic optimization and iterative estimation procedures.\nStochastic approximations are at the forefront of this recent development as\nthey yield procedures that are simple, general, and fast. However, standard\nstochastic approximations are often numerically unstable. Deterministic\noptimization, on the other hand, increasingly uses proximal updates to achieve\nnumerical stability in a principled manner. A theoretical gap has thus emerged.\nWhile standard stochastic approximations are subsumed by the framework of\nRobbins and Monro (1951), there is no such framework for stochastic\napproximations with proximal updates. In this paper, we conceptualize a\nproximal version of the classical Robbins-Monro procedure. Our theoretical\nanalysis demonstrates that the proposed procedure has important stability\nbenefits over the classical Robbins-Monro procedure, while it retains the best\nknown convergence rates. Exact implementations of the proximal Robbins-Monro\nprocedure are challenging, but we show that approximate implementations lead to\nprocedures that are easy to implement, and still dominate classical procedures\nby achieving numerical stability, practically without tradeoffs. Moreover,\napproximate proximal Robbins-Monro procedures can be applied even when the\nobjective cannot be calculated analytically, and so they generalize stochastic\nproximal procedures currently in use.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2015 19:07:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 00:37:35 GMT"}, {"version": "v3", "created": "Mon, 5 Mar 2018 03:01:41 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 17:50:22 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Toulis", "Panos", ""], ["Horel", "Thibaut", ""], ["Airoldi", "Edoardo M.", ""]]}, {"id": "1510.01003", "submitter": "Keisuke Yamazaki", "authors": "Keisuke Yamazaki", "title": "Bayesian Estimation of Multidimensional Latent Variables and Its\n  Asymptotic Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical learning models, such as mixture models and Bayesian networks,\nare widely employed for unsupervised learning tasks, such as clustering\nanalysis. They consist of observable and hidden variables, which represent the\ngiven data and their hidden generation process, respectively. It has been\npointed out that conventional statistical analysis is not applicable to these\nmodels, because redundancy of the latent variable produces singularities in the\nparameter space. In recent years, a method based on algebraic geometry has\nallowed us to analyze the accuracy of predicting observable variables when\nusing Bayesian estimation. However, how to analyze latent variables has not\nbeen sufficiently studied, even though one of the main issues in unsupervised\nlearning is to determine how accurately the latent variable is estimated. A\nprevious study proposed a method that can be used when the range of the latent\nvariable is redundant compared with the model generating data. The present\npaper extends that method to the situation in which the latent variables have\nredundant dimensions. We formulate new error functions and derive their\nasymptotic forms. Calculation of the error functions is demonstrated in\ntwo-layered Bayesian networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 00:24:18 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2016 01:19:15 GMT"}, {"version": "v3", "created": "Fri, 27 Jan 2017 05:37:47 GMT"}, {"version": "v4", "created": "Wed, 17 May 2017 01:56:33 GMT"}, {"version": "v5", "created": "Mon, 14 Aug 2017 01:24:23 GMT"}, {"version": "v6", "created": "Thu, 4 Jan 2018 02:25:04 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Yamazaki", "Keisuke", ""]]}, {"id": "1510.01006", "submitter": "Rion Brattig Correia", "authors": "Rion Brattig Correia and Lang Li and Luis M. Rocha", "title": "Monitoring Potential Drug Interactions and Reactions via Network\n  Analysis of Instagram User Timelines", "comments": "Pacific Symposium on Biocomputing. 21:492-503", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much recent research aims to identify evidence for Drug-Drug Interactions\n(DDI) and Adverse Drug reactions (ADR) from the biomedical scientific\nliterature. In addition to this \"Bibliome\", the universe of social media\nprovides a very promising source of large-scale data that can help identify DDI\nand ADR in ways that have not been hitherto possible. Given the large number of\nusers, analysis of social media data may be useful to identify under-reported,\npopulation-level pathology associated with DDI, thus further contributing to\nimprovements in population health. Moreover, tapping into this data allows us\nto infer drug interactions with natural products--including cannabis--which\nconstitute an array of DDI very poorly explored by biomedical research thus\nfar. Our goal is to determine the potential of Instagram for public health\nmonitoring and surveillance for DDI, ADR, and behavioral pathology at large.\nUsing drug, symptom, and natural product dictionaries for identification of the\nvarious types of DDI and ADR evidence, we have collected ~7000 timelines. We\nreport on 1) the development of a monitoring tool to easily observe user-level\ntimelines associated with drug and symptom terms of interest, and 2)\npopulation-level behavior via the analysis of co-occurrence networks computed\nfrom user timelines at three different scales: monthly, weekly, and daily\noccurrences. Analysis of these networks further reveals 3) drug and symptom\ndirect and indirect associations with greater support in user timelines, as\nwell as 4) clusters of symptoms and drugs revealed by the collective behavior\nof the observed population. This demonstrates that Instagram contains much\ndrug- and pathology specific data for public health monitoring of DDI and ADR,\nand that complex network analysis provides an important toolbox to extract\nhealth-related associations and their support from large-scale social media\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 00:42:18 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2016 19:16:52 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Correia", "Rion Brattig", ""], ["Li", "Lang", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1510.01064", "submitter": "Jelena Bradic", "authors": "Alexander Hanbo Li and Jelena Bradic", "title": "Boosting in the presence of outliers: adaptive classification with\n  non-convex loss functions", "comments": null, "journal-ref": "Journal of the American Statistical Association: theory and\n  methods, 2017", "doi": "10.1080/01621459.2016.1273116", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the role and efficiency of the non-convex loss functions\nfor binary classification problems. In particular, we investigate how to design\na simple and effective boosting algorithm that is robust to the outliers in the\ndata. The analysis of the role of a particular non-convex loss for prediction\naccuracy varies depending on the diminishing tail properties of the gradient of\nthe loss -- the ability of the loss to efficiently adapt to the outlying data,\nthe local convex properties of the loss and the proportion of the contaminated\ndata. In order to use these properties efficiently, we propose a new family of\nnon-convex losses named $\\gamma$-robust losses. Moreover, we present a new\nboosting framework, {\\it Arch Boost}, designed for augmenting the existing work\nsuch that its corresponding classification algorithm is significantly more\nadaptable to the unknown data contamination. Along with the Arch Boosting\nframework, the non-convex losses lead to the new class of boosting algorithms,\nnamed adaptive, robust, boosting (ARB). Furthermore, we present theoretical\nexamples that demonstrate the robustness properties of the proposed algorithms.\nIn particular, we develop a new breakdown point analysis and a new influence\nfunction analysis that demonstrate gains in robustness. Moreover, we present\nnew theoretical results, based only on local curvatures, which may be used to\nestablish statistical and optimization properties of the proposed Arch boosting\nalgorithms with highly non-convex loss functions. Extensive numerical\ncalculations are used to illustrate these theoretical properties and reveal\nadvantages over the existing boosting methods when data exhibits a number of\noutliers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 08:50:56 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Bradic", "Jelena", ""]]}, {"id": "1510.01171", "submitter": "Hoi-To Wai", "authors": "Jean Lafond, Hoi-To Wai, Eric Moulines", "title": "On the Online Frank-Wolfe Algorithms for Convex and Non-convex\n  Optimizations", "comments": "28 pages, 4 figures. Incorporated new results on the away-step\n  algorithms and non-convex losses. Expanded the numerical experiments section", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the online variants of the classical Frank-Wolfe algorithm are\nconsidered. We consider minimizing the regret with a stochastic cost. The\nonline algorithms only require simple iterative updates and a non-adaptive step\nsize rule, in contrast to the hybrid schemes commonly considered in the\nliterature. Several new results are derived for convex and non-convex losses.\nWith a strongly convex stochastic cost and when the optimal solution lies in\nthe interior of the constraint set or the constraint set is a polytope, the\nregret bound and anytime optimality are shown to be ${\\cal O}( \\log^3 T / T )$\nand ${\\cal O}( \\log^2 T / T)$, respectively, where $T$ is the number of rounds\nplayed. These results are based on an improved analysis on the stochastic\nFrank-Wolfe algorithms. Moreover, the online algorithms are shown to converge\neven when the loss is non-convex, i.e., the algorithms find a stationary point\nto the time-varying/stochastic loss at a rate of ${\\cal O}(\\sqrt{1/T})$.\nNumerical experiments on realistic data sets are presented to support our\ntheoretical claims.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 14:42:36 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 17:11:30 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Lafond", "Jean", ""], ["Wai", "Hoi-To", ""], ["Moulines", "Eric", ""]]}, {"id": "1510.01225", "submitter": "Tohid Ardeshiri", "authors": "Tohid Ardeshiri, Umut Orguner, and Fredrik Gustafsson", "title": "Bayesian Inference via Approximation of Log-likelihood for Priors in\n  Exponential Family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a Bayesian inference technique based on Taylor series\napproximation of the logarithm of the likelihood function is presented. The\nproposed approximation is devised for the case, where the prior distribution\nbelongs to the exponential family of distributions. The logarithm of the\nlikelihood function is linearized with respect to the sufficient statistic of\nthe prior distribution in exponential family such that the posterior obtains\nthe same exponential family form as the prior. Similarities between the\nproposed method and the extended Kalman filter for nonlinear filtering are\nillustrated. Furthermore, an extended target measurement update for target\nmodels where the target extent is represented by a random matrix having an\ninverse Wishart distribution is derived. The approximate update covers the\nimportant case where the spread of measurement is due to the target extent as\nwell as the measurement noise in the sensor.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 16:47:54 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Ardeshiri", "Tohid", ""], ["Orguner", "Umut", ""], ["Gustafsson", "Fredrik", ""]]}, {"id": "1510.01270", "submitter": "Rados{\\l}aw Michalski", "authors": "Tomasz Kajdanowicz, Rados{\\l}aw Michalski, Katarzyna Musia{\\l},\n  Przemys{\\l}aw Kazienko", "title": "Learning in Unlabeled Networks - An Active Learning and Inference\n  Approach", "comments": null, "journal-ref": "AI Communications, Vol. 29, No. 1, 2016, IOS Press", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of determining labels of all network nodes based on the knowledge\nabout network structure and labels of some training subset of nodes is called\nthe within-network classification. It may happen that none of the labels of the\nnodes is known and additionally there is no information about number of classes\nto which nodes can be assigned. In such a case a subset of nodes has to be\nselected for initial label acquisition. The question that arises is: \"labels of\nwhich nodes should be collected and used for learning in order to provide the\nbest classification accuracy for the whole network?\". Active learning and\ninference is a practical framework to study this problem.\n  A set of methods for active learning and inference for within network\nclassification is proposed and validated. The utility score calculation for\neach node based on network structure is the first step in the process. The\nscores enable to rank the nodes. Based on the ranking, a set of nodes, for\nwhich the labels are acquired, is selected (e.g. by taking top or bottom N from\nthe ranking). The new measure-neighbour methods proposed in the paper suggest\nnot obtaining labels of nodes from the ranking but rather acquiring labels of\ntheir neighbours. The paper examines 29 distinct formulations of utility score\nand selection methods reporting their impact on the results of two collective\nclassification algorithms: Iterative Classification Algorithm and Loopy Belief\nPropagation.\n  We advocate that the accuracy of presented methods depends on the structural\nproperties of the examined network. We claim that measure-neighbour methods\nwill work better than the regular methods for networks with higher clustering\ncoefficient and worse than regular methods for networks with low clustering\ncoefficient. According to our hypothesis, based on clustering coefficient we\nare able to recommend appropriate active learning and inference method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 18:25:19 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Kajdanowicz", "Tomasz", ""], ["Michalski", "Rados\u0142aw", ""], ["Musia\u0142", "Katarzyna", ""], ["Kazienko", "Przemys\u0142aw", ""]]}, {"id": "1510.01378", "submitter": "Phil\\'emon Brakel", "authors": "C\\'esar Laurent, Gabriel Pereyra, Phil\\'emon Brakel, Ying Zhang and\n  Yoshua Bengio", "title": "Batch Normalized Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are powerful models for sequential data that\nhave the potential to learn long-term dependencies. However, they are\ncomputationally expensive to train and difficult to parallelize. Recent work\nhas shown that normalizing intermediate representations of neural networks can\nsignificantly improve convergence rates in feedforward neural networks . In\nparticular, batch normalization, which uses mini-batch statistics to\nstandardize features, was shown to significantly reduce training time. In this\npaper, we show that applying batch normalization to the hidden-to-hidden\ntransitions of our RNNs doesn't help the training procedure. We also show that\nwhen applied to the input-to-hidden transitions, batch normalization can lead\nto a faster convergence of the training criterion but doesn't seem to improve\nthe generalization performance on both our language modelling and speech\nrecognition tasks. All in all, applying batch normalization to RNNs turns out\nto be more challenging than applying it to feedforward networks, but certain\nvariants of it can still be beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 21:45:31 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Laurent", "C\u00e9sar", ""], ["Pereyra", "Gabriel", ""], ["Brakel", "Phil\u00e9mon", ""], ["Zhang", "Ying", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1510.01422", "submitter": "Norm Matloff PhD", "authors": "Norman Matloff", "title": "Improved Estimation of Class Prior Probabilities through Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work in the classification literature has shown that in computing a\nclassification function, one need not know the class membership of all\nobservations in the training set; the unlabeled observations still provide\ninformation on the marginal distribution of the feature set, and can thus\ncontribute to increased classification accuracy for future observations. The\npresent paper will show that this scheme can also be used for the estimation of\nclass prior probabilities, which would be very useful in applications in which\nit is difficult or expensive to determine class membership. Both parametric and\nnonparametric estimators are developed. Asymptotic distributions of the\nestimators are derived, and it is proven that the use of the unlabeled\nobservations does reduce asymptotic variance. This methodology is also extended\nto the estimation of subclass probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 03:58:52 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Matloff", "Norman", ""]]}, {"id": "1510.01463", "submitter": "Yunwen Lei", "authors": "Yunwen Lei, Lixin Ding and Yingzhou Bi", "title": "Local Rademacher Complexity Bounds based on Covering Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a general result on controlling local Rademacher\ncomplexities, which captures in an elegant form to relate the complexities with\nconstraint on the expected norm to the corresponding ones with constraint on\nthe empirical norm. This result is convenient to apply in real applications and\ncould yield refined local Rademacher complexity bounds for function classes\nsatisfying general entropy conditions. We demonstrate the power of our\ncomplexity bounds by applying them to derive effective generalization error\nbounds.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 07:44:08 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Lei", "Yunwen", ""], ["Ding", "Lixin", ""], ["Bi", "Yingzhou", ""]]}, {"id": "1510.01485", "submitter": "Dinu Kaufmann", "authors": "Dinu Kaufmann, Sonali Parbhoo, Aleksander Wieczorek, Sebastian Keller,\n  David Adametz, Volker Roth", "title": "Bayesian Markov Blanket Estimation", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a Bayesian view for estimating a sub-network in a Markov\nrandom field. The sub-network corresponds to the Markov blanket of a set of\nquery variables, where the set of potential neighbours here is big. We\nfactorize the posterior such that the Markov blanket is conditionally\nindependent of the network of the potential neighbours. By exploiting this\nblockwise decoupling, we derive analytic expressions for posterior\nconditionals. Subsequently, we develop an inference scheme which makes use of\nthe factorization. As a result, estimation of a sub-network is possible without\ninferring an entire network. Since the resulting Gibbs sampler scales linearly\nwith the number of variables, it can handle relatively large neighbourhoods.\nThe proposed scheme results in faster convergence and superior mixing of the\nMarkov chain than existing Bayesian network estimation techniques.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 09:06:11 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Kaufmann", "Dinu", ""], ["Parbhoo", "Sonali", ""], ["Wieczorek", "Aleksander", ""], ["Keller", "Sebastian", ""], ["Adametz", "David", ""], ["Roth", "Volker", ""]]}, {"id": "1510.01518", "submitter": "Georgina Hall", "authors": "Amir Ali Ahmadi, Georgina Hall", "title": "DC Decomposition of Nonconvex Polynomials with Algebraic Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of decomposing a multivariate polynomial as the\ndifference of two convex polynomials. We introduce algebraic techniques which\nreduce this task to linear, second order cone, and semidefinite programming.\nThis allows us to optimize over subsets of valid difference of convex\ndecompositions (dcds) and find ones that speed up the convex-concave procedure\n(CCP). We prove, however, that optimizing over the entire set of dcds is\nNP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 10:34:19 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 10:10:34 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Hall", "Georgina", ""]]}, {"id": "1510.01624", "submitter": "Christian Igel", "authors": "Oswin Krause, Asja Fischer, Christian Igel", "title": "Population-Contrastive-Divergence: Does Consistency help with RBM\n  training?", "comments": "An updated version is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the log-likelihood gradient with respect to the parameters of a\nRestricted Boltzmann Machine (RBM) typically requires sampling using Markov\nChain Monte Carlo (MCMC) techniques. To save computation time, the Markov\nchains are only run for a small number of steps, which leads to a biased\nestimate. This bias can cause RBM training algorithms such as Contrastive\nDivergence (CD) learning to deteriorate. We adopt the idea behind Population\nMonte Carlo (PMC) methods to devise a new RBM training algorithm termed\nPopulation-Contrastive-Divergence (pop-CD). Compared to CD, it leads to a\nconsistent estimate and may have a significantly lower bias. Its computational\noverhead is negligible compared to CD. However, the variance of the gradient\nestimate increases. We experimentally show that pop-CD can significantly\noutperform CD. In many cases, we observed a smaller bias and achieved higher\nlog-likelihood values. However, when the RBM distribution has many hidden\nneurons, the consistent estimate of pop-CD may still have a considerable bias\nand the variance of the gradient estimate requires a smaller learning rate.\nThus, despite its superior theoretical properties, it is not advisable to use\npop-CD in its current form on large problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 15:29:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 12:30:35 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 17:37:27 GMT"}, {"version": "v4", "created": "Wed, 28 Jun 2017 09:35:12 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Krause", "Oswin", ""], ["Fischer", "Asja", ""], ["Igel", "Christian", ""]]}, {"id": "1510.01628", "submitter": "Panagiotis Traganitis", "authors": "Panagiotis A. Traganitis, Konstantinos Slavakis, Georgios B. Giannakis", "title": "Large-scale subspace clustering using sketching and validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nowadays massive amounts of generated and communicated data present major\nchallenges in their processing. While capable of successfully classifying\nnonlinearly separable objects in various settings, subspace clustering (SC)\nmethods incur prohibitively high computational complexity when processing\nlarge-scale data. Inspired by the random sampling and consensus (RANSAC)\napproach to robust regression, the present paper introduces a randomized scheme\nfor SC, termed sketching and validation (SkeVa-)SC, tailored for large-scale\ndata. At the heart of SkeVa-SC lies a randomized scheme for approximating the\nunderlying probability density function of the observed data by kernel\nsmoothing arguments. Sparsity in data representations is also exploited to\nreduce the computational burden of SC, while achieving high clustering\naccuracy. Performance analysis as well as extensive numerical tests on\nsynthetic and real data corroborate the potential of SkeVa-SC and its\ncompetitive performance relative to state-of-the-art scalable SC approaches.\nKeywords: Subspace clustering, big data, kernel smoothing, randomization,\nsketching, validation, sparsity.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 15:34:32 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Traganitis", "Panagiotis A.", ""], ["Slavakis", "Konstantinos", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1510.01722", "submitter": "Vikas Sindhwani", "authors": "Vikas Sindhwani and Tara N. Sainath and Sanjiv Kumar", "title": "Structured Transforms for Small-Footprint Deep Learning", "comments": "To appear in NIPS 2015; 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of building compact deep learning pipelines suitable for\ndeployment on storage and power constrained mobile devices. We propose a\nunified framework to learn a broad family of structured parameter matrices that\nare characterized by the notion of low displacement rank. Our structured\ntransforms admit fast function and gradient evaluation, and span a rich range\nof parameter sharing configurations whose statistical modeling capacity can be\nexplicitly tuned along a continuum from structured to unstructured.\nExperimental results show that these transforms can significantly accelerate\ninference and forward/backward passes during training, and offer superior\naccuracy-compactness-speed tradeoffs in comparison to a number of existing\ntechniques. In keyword spotting applications in mobile speech recognition, our\nmethods are much more effective than standard linear low-rank bottleneck layers\nand nearly retain the performance of state of the art models, while providing\nmore than 3.5-fold compression.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 19:42:22 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Sindhwani", "Vikas", ""], ["Sainath", "Tara N.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1510.01799", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "Efficient Per-Example Gradient Computations", "comments": "This revision fixed some typos. Many thanks to Hugo Larochelle for\n  reporting them!", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes an efficient technique for computing the norm\nof the gradient of the loss function for a neural network with respect to its\nparameters. This gradient norm can be computed efficiently for every example.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2015 01:42:23 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2015 23:59:02 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1510.02041", "submitter": "Michael Katehakis", "authors": "Wesley Cowan and Michael N. Katehakis", "title": "Asymptotically Optimal Sequential Experimentation Under Generalized\n  Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the \\mnk{classical} problem of a controller activating (or\nsampling) sequentially from a finite number of $N \\geq 2$ populations,\nspecified by unknown distributions. Over some time horizon, at each time $n =\n1, 2, \\ldots$, the controller wishes to select a population to sample, with the\ngoal of sampling from a population that optimizes some \"score\" function of its\ndistribution, e.g., maximizing the expected sum of outcomes or minimizing\nvariability. We define a class of \\textit{Uniformly Fast (UF)} sampling\npolicies and show, under mild regularity conditions, that there is an\nasymptotic lower bound for the expected total number of sub-optimal population\nactivations. Then, we provide sufficient conditions under which a UCB policy is\nUF and asymptotically optimal, since it attains this lower bound. Explicit\nsolutions are provided for a number of examples of interest, including general\nscore functionals on unconstrained Pareto distributions (of potentially\ninfinite mean), and uniform distributions of unknown support. Additional\nresults on bandits of Normal distributions are also provided.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2015 17:52:30 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2015 13:27:43 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2015 15:57:40 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Cowan", "Wesley", ""], ["Katehakis", "Michael N.", ""]]}, {"id": "1510.02173", "submitter": "John-Alexander Assael", "authors": "John-Alexander M. Assael, Niklas Wahlstr\\\"om, Thomas B. Sch\\\"on, Marc\n  Peter Deisenroth", "title": "Data-Efficient Learning of Feedback Policies from Image Pixels using\n  Deep Dynamical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-efficient reinforcement learning (RL) in continuous state-action spaces\nusing very high-dimensional observations remains a key challenge in developing\nfully autonomous systems. We consider a particularly important instance of this\nchallenge, the pixels-to-torques problem, where an RL agent learns a\nclosed-loop control policy (\"torques\") from pixel information only. We\nintroduce a data-efficient, model-based reinforcement learning algorithm that\nlearns such a closed-loop policy directly from pixel information. The key\ningredient is a deep dynamical model for learning a low-dimensional feature\nembedding of images jointly with a predictive model in this low-dimensional\nfeature space. Joint learning is crucial for long-term predictions, which lie\nat the core of the adaptive nonlinear model predictive control strategy that we\nuse for closed-loop control. Compared to state-of-the-art RL methods for\ncontinuous states and actions, our approach learns quickly, scales to\nhigh-dimensional state spaces, is lightweight and an important step toward\nfully autonomous end-to-end learning from pixels to torques.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 00:20:42 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2015 15:21:01 GMT"}], "update_date": "2015-10-12", "authors_parsed": [["Assael", "John-Alexander M.", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1510.02175", "submitter": "Bai Jiang", "authors": "Bai Jiang, Tung-yu Wu, Charles Zheng, Wing H. Wong", "title": "Learning Summary Statistic for Approximate Bayesian Computation via Deep\n  Neural Network", "comments": "27 pages, 10 figures", "journal-ref": null, "doi": "10.5705/ss.202015.0340", "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation (ABC) methods are used to approximate\nposterior distributions in models with unknown or computationally intractable\nlikelihoods. Both the accuracy and computational efficiency of ABC depend on\nthe choice of summary statistic, but outside of special cases where the optimal\nsummary statistics are known, it is unclear which guiding principles can be\nused to construct effective summary statistics. In this paper we explore the\npossibility of automating the process of constructing summary statistics by\ntraining deep neural networks to predict the parameters from artificially\ngenerated data: the resulting summary statistics are approximately posterior\nmeans of the parameters. With minimal model-specific tuning, our method\nconstructs summary statistics for the Ising model and the moving-average model,\nwhich match or exceed theoretically-motivated summary statistics in terms of\nthe accuracies of the resulting posteriors.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 00:33:51 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 21:20:53 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 04:47:20 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Jiang", "Bai", ""], ["Wu", "Tung-yu", ""], ["Zheng", "Charles", ""], ["Wong", "Wing H.", ""]]}, {"id": "1510.02255", "submitter": "Vidyadhar Upadhya", "authors": "Vidyadhar Upadhya, P.S. Sastry", "title": "Empirical Analysis of Sampling Based Estimators for Evaluating RBMs", "comments": "edited version of this manuscript will appear in proceedings of\n  International Conference on Neural Information Processing (ICONIP) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Restricted Boltzmann Machines (RBM) can be used either as classifiers or\nas generative models. The quality of the generative RBM is measured through the\naverage log-likelihood on test data. Due to the high computational complexity\nof evaluating the partition function, exact calculation of test log-likelihood\nis very difficult. In recent years some estimation methods are suggested for\napproximate computation of test log-likelihood. In this paper we present an\nempirical comparison of the main estimation methods, namely, the AIS algorithm\nfor estimating the partition function, the CSL method for directly estimating\nthe log-likelihood, and the RAISE algorithm that combines these two ideas. We\nuse the MNIST data set to learn the RBM and then compare these methods for\nestimating the test log-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 09:44:15 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Upadhya", "Vidyadhar", ""], ["Sastry", "P. S.", ""]]}, {"id": "1510.02267", "submitter": "Patrick Heas", "authors": "Patrick H\\'eas and C\\'edric Herzet", "title": "Reduced-Order Modeling Of Hidden Dynamics", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to investigate how noisy and incomplete\nobservations can be integrated in the process of building a reduced-order\nmodel.\n  This problematic arises in many scientific domains where there exists a need\nfor accurate low-order descriptions of highly-complex phenomena, which can not\nbe directly and/or deterministically observed. Within this context, the paper\nproposes a probabilistic framework for the construction of \"POD-Galerkin\"\nreduced-order models. Assuming a hidden Markov chain, the inference integrates\nthe uncertainty of the hidden states relying on their posterior distribution.\nSimulations show the benefits obtained by exploiting the proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 10:11:52 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 13:45:57 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["H\u00e9as", "Patrick", ""], ["Herzet", "C\u00e9dric", ""]]}, {"id": "1510.02354", "submitter": "Chu Wang", "authors": "Yingfei Wang, Chu Wang, Warren Powell", "title": "The Knowledge Gradient with Logistic Belief Models for Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sequential decision making problems for binary classification\nscenario in which the learner takes an active role in repeatedly selecting\nsamples from the action pool and receives the binary label of the selected\nalternatives. Our problem is motivated by applications where observations are\ntime consuming and/or expensive, resulting in small samples. The goal is to\nidentify the best alternative with the highest response. We use Bayesian\nlogistic regression to predict the response of each alternative. By formulating\nthe problem as a Markov decision process, we develop a knowledge-gradient type\npolicy to guide the experiment by maximizing the expected value of information\nof labeling each alternative and provide a finite-time analysis on the\nestimated error. Experiments on benchmark UCI datasets demonstrate the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 15:06:03 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Wang", "Yingfei", ""], ["Wang", "Chu", ""], ["Powell", "Warren", ""]]}, {"id": "1510.02364", "submitter": "Ralph Versteegen", "authors": "Ralph Versteegen, Georgy Gimel'farb, Patricia Riddle", "title": "Texture Modelling with Nested High-order Markov-Gibbs Random Fields", "comments": "Submitted to Computer Vision and Image Understanding", "journal-ref": null, "doi": "10.1016/j.cviu.2015.11.003", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, Markov-Gibbs random field (MGRF) image models which include\nhigh-order interactions are almost always built by modelling responses of a\nstack of local linear filters. Actual interaction structure is specified\nimplicitly by the filter coefficients. In contrast, we learn an explicit\nhigh-order MGRF structure by considering the learning process in terms of\ngeneral exponential family distributions nested over base models, so that\npotentials added later can build on previous ones. We relatively rapidly add\nnew features by skipping over the costly optimisation of parameters.\n  We introduce the use of local binary patterns as features in MGRF texture\nmodels, and generalise them by learning offsets to the surrounding pixels.\nThese prove effective as high-order features, and are fast to compute. Several\nschemes for selecting high-order features by composition or search of a small\nsubclass are compared. Additionally we present a simple modification of the\nmaximum likelihood as a texture modelling-specific objective function which\naims to improve generalisation by local windowing of statistics.\n  The proposed method was experimentally evaluated by learning high-order MGRF\nmodels for a broad selection of complex textures and then performing texture\nsynthesis, and succeeded on much of the continuum from stochastic through\nirregularly structured to near-regular textures. Learning interaction structure\nis very beneficial for textures with large-scale structure, although those with\ncomplex irregular structure still provide difficulties. The texture models were\nalso quantitatively evaluated on two tasks and found to be competitive with\nother works: grading of synthesised textures by a panel of observers; and\ncomparison against several recent MGRF models by evaluation on a constrained\ninpainting task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 15:22:21 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Versteegen", "Ralph", ""], ["Gimel'farb", "Georgy", ""], ["Riddle", "Patricia", ""]]}, {"id": "1510.02427", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Daniele Sgandurra, Mart\\'in Barr\\`ere, Emil\n  Lupu", "title": "Exact Inference Techniques for the Analysis of Bayesian Attack Graphs", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attack graphs are a powerful tool for security risk assessment by analysing\nnetwork vulnerabilities and the paths attackers can use to compromise network\nresources. The uncertainty about the attacker's behaviour makes Bayesian\nnetworks suitable to model attack graphs to perform static and dynamic\nanalysis. Previous approaches have focused on the formalization of attack\ngraphs into a Bayesian model rather than proposing mechanisms for their\nanalysis. In this paper we propose to use efficient algorithms to make exact\ninference in Bayesian attack graphs, enabling the static and dynamic network\nrisk assessments. To support the validity of our approach we have performed an\nextensive experimental evaluation on synthetic Bayesian attack graphs with\ndifferent topologies, showing the computational advantages in terms of time and\nmemory use of the proposed techniques when compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 18:01:54 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 18:03:38 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Sgandurra", "Daniele", ""], ["Barr\u00e8re", "Mart\u00edn", ""], ["Lupu", "Emil", ""]]}, {"id": "1510.02437", "submitter": "George Papamakarios", "authors": "George Papamakarios", "title": "Distilling Model Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-performing machine learning systems, such as deep neural networks, large\nensembles and complex probabilistic graphical models, can be expensive to\nstore, slow to evaluate and hard to integrate into larger systems. Ideally, we\nwould like to replace such cumbersome models with simpler models that perform\nequally well.\n  In this thesis, we study knowledge distillation, the idea of extracting the\nknowledge contained in a complex model and injecting it into a more convenient\nmodel. We present a general framework for knowledge distillation, whereby a\nconvenient model of our choosing learns how to mimic a complex model, by\nobserving the latter's behaviour and being penalized whenever it fails to\nreproduce it.\n  We develop our framework within the context of three distinct machine\nlearning applications: (a) model compression, where we compress large\ndiscriminative models, such as ensembles of neural networks, into models of\nmuch smaller size; (b) compact predictive distributions for Bayesian inference,\nwhere we distil large bags of MCMC samples into compact predictive\ndistributions in closed form; (c) intractable generative models, where we\ndistil unnormalizable models such as RBMs into tractable models such as NADEs.\n  We contribute to the state of the art with novel techniques and ideas. In\nmodel compression, we describe and implement derivative matching, which allows\nfor better distillation when data is scarce. In compact predictive\ndistributions, we introduce online distillation, which allows for significant\nsavings in memory. Finally, in intractable generative models, we show how to\nuse distilled models to robustly estimate intractable quantities of the\noriginal model, such as its intractable partition function.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 18:40:50 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Papamakarios", "George", ""]]}, {"id": "1510.02502", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Daren Wang, Alessandro Rinaldo, Larry Wasserman", "title": "Statistical Analysis of Persistence Intensity Functions", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams are two-dimensional plots that summarize the topological\nfeatures of functions and are an important part of topological data analysis. A\nproblem that has received much attention is how deal with sets of persistence\ndiagrams. How do we summarize them, average them or cluster them? One approach\n-- the persistence intensity function -- was introduced informally by\nEdelsbrunner, Ivanov, and Karasev (2012). Here we provide a modification and\nformalization of this approach. Using the persistence intensity function, we\ncan visualize multiple diagrams, perform clustering and conduct two-sample\ntests.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 20:45:02 GMT"}], "update_date": "2015-10-12", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Wang", "Daren", ""], ["Rinaldo", "Alessandro", ""], ["Wasserman", "Larry", ""]]}, {"id": "1510.02533", "submitter": "Aaron Defazio Dr", "authors": "Aaron Defazio", "title": "New Optimisation Methods for Machine Learning", "comments": "PhD thesis, 205 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A thesis submitted for the degree of Doctor of Philosophy of The Australian\nNational University.\n  In this work we introduce several new optimisation methods for problems in\nmachine learning. Our algorithms broadly fall into two categories: optimisation\nof finite sums and of graph structured objectives. The finite sum problem is\nsimply the minimisation of objective functions that are naturally expressed as\na summation over a large number of terms, where each term has a similar or\nidentical weight. Such objectives most often appear in machine learning in the\nempirical risk minimisation framework in the non-online learning setting. The\nsecond category, that of graph structured objectives, consists of objectives\nthat result from applying maximum likelihood to Markov random field models.\nUnlike the finite sum case, all the non-linearity is contained within a\npartition function term, which does not readily decompose into a summation.\n  For the finite sum problem, we introduce the Finito and SAGA algorithms, as\nwell as variants of each.\n  For graph-structured problems, we take three complementary approaches. We\nlook at learning the parameters for a fixed structure, learning the structure\nindependently, and learning both simultaneously. Specifically, for the combined\napproach, we introduce a new method for encouraging graph structures with the\n\"scale-free\" property. For the structure learning problem, we establish\nSHORTCUT, a O(n^{2.5}) expected time approximate structure learning method for\nGaussian graphical models. For problems where the structure is known but the\nparameters unknown, we introduce an approximate maximum likelihood learning\nalgorithm that is capable of learning a useful subclass of Gaussian graphical\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 00:34:12 GMT"}, {"version": "v2", "created": "Sat, 19 Mar 2016 02:00:45 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Defazio", "Aaron", ""]]}, {"id": "1510.02558", "submitter": "Chu Wang", "authors": "Chu Wang and Yingfei Wang and Weinan E and Robert Schapire", "title": "Functional Frank-Wolfe Boosting for General Loss Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a generic learning method for classification and regression. Yet,\nas the number of base hypotheses becomes larger, boosting can lead to a\ndeterioration of test performance. Overfitting is an important and ubiquitous\nphenomenon, especially in regression settings. To avoid overfitting, we\nconsider using $l_1$ regularization. We propose a novel Frank-Wolfe type\nboosting algorithm (FWBoost) applied to general loss functions. By using\nexponential loss, the FWBoost algorithm can be rewritten as a variant of\nAdaBoost for binary classification. FWBoost algorithms have exactly the same\nform as existing boosting methods, in terms of making calls to a base learning\nalgorithm with different weights update. This direct connection between\nboosting and Frank-Wolfe yields a new algorithm that is as practical as\nexisting boosting methods but with new guarantees and rates of convergence.\nExperimental results show that the test performance of FWBoost is not degraded\nwith larger rounds in boosting, which is consistent with the theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 03:16:07 GMT"}], "update_date": "2015-10-12", "authors_parsed": [["Wang", "Chu", ""], ["Wang", "Yingfei", ""], ["E", "Weinan", ""], ["Schapire", "Robert", ""]]}, {"id": "1510.02676", "submitter": "Eric Bax", "authors": "Eric Bax, Ya Le", "title": "Some Theory For Practical Classifier Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare and contrast two approaches to validating a trained classifier\nwhile using all in-sample data for training. One is simultaneous validation\nover an organized set of hypotheses (SVOOSH), the well-known method that began\nwith VC theory. The other is withhold and gap (WAG). WAG withholds a validation\nset, trains a holdout classifier on the remaining data, uses the validation\ndata to validate that classifier, then adds the rate of disagreement between\nthe holdout classifier and one trained using all in-sample data, which is an\nupper bound on the difference in error rates. We show that complex hypothesis\nclasses and limited training data can make WAG a favorable alternative.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 14:04:01 GMT"}], "update_date": "2015-10-12", "authors_parsed": [["Bax", "Eric", ""], ["Le", "Ya", ""]]}, {"id": "1510.02706", "submitter": "Alexander Zimin", "authors": "Alexander Zimin, Christoph H. Lampert", "title": "Conditional Risk Minimization for Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of learning from non-i.i.d. data. In particular, we aim at\nlearning predictors that minimize the conditional risk for a stochastic\nprocess, i.e. the expected loss of the predictor on the next point conditioned\non the set of training samples observed so far. For non-i.i.d. data, the\ntraining set contains information about the upcoming samples, so learning with\nrespect to the conditional distribution can be expected to yield better\npredictors than one obtains from the classical setting of minimizing the\nmarginal risk. Our main contribution is a practical estimator for the\nconditional risk based on the theory of non-parametric time-series prediction,\nand a finite sample concentration bound that establishes uniform convergence of\nthe estimator to the true conditional risk under certain regularity assumptions\non the process.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 15:31:36 GMT"}, {"version": "v2", "created": "Sun, 13 Mar 2016 12:54:04 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Zimin", "Alexander", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1510.02786", "submitter": "Bruce Hajek", "authors": "Bruce Hajek and Yihong Wu and Jiaming Xu", "title": "Recovering a Hidden Community Beyond the Kesten-Stigum Threshold in\n  $O(|E| \\log^*|V|)$ Time", "comments": "New title replaces spectral limit by Kesten-Stigum threshold", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.SI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is considered for a stochastic block model graph of n\nvertices, with K vertices in the planted community, edge probability p for\npairs of vertices both in the community, and edge probability q for other pairs\nof vertices.\n  The main focus of the paper is on weak recovery of the community based on the\ngraph G, with o(K) misclassified vertices on average, in the sublinear regime\n$n^{1-o(1)} \\leq K \\leq o(n).$ A critical parameter is the effective\nsignal-to-noise ratio $\\lambda=K^2(p-q)^2/((n-K)q)$, with $\\lambda=1$\ncorresponding to the Kesten-Stigum threshold. We show that a belief propagation\nalgorithm achieves weak recovery if $\\lambda>1/e$, beyond the Kesten-Stigum\nthreshold by a factor of $1/e.$ The belief propagation algorithm only needs to\nrun for $\\log^\\ast n+O(1) $ iterations, with the total time complexity $O(|E|\n\\log^*n)$, where $\\log^*n$ is the iterated logarithm of $n.$ Conversely, if\n$\\lambda \\leq 1/e$, no local algorithm can asymptotically outperform trivial\nrandom guessing. Furthermore, a linear message-passing algorithm that\ncorresponds to applying power iteration to the non-backtracking matrix of the\ngraph is shown to attain weak recovery if and only if $\\lambda>1$. In addition,\nthe belief propagation algorithm can be combined with a linear-time voting\nprocedure to achieve the information limit of exact recovery (correctly\nclassify all vertices with high probability) for all $K \\ge \\frac{n}{\\log n}\n\\left( \\rho_{\\rm BP} +o(1) \\right),$ where $\\rho_{\\rm BP}$ is a function of\n$p/q$.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 19:48:28 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 13:12:18 GMT"}, {"version": "v3", "created": "Sat, 13 Jan 2018 17:41:05 GMT"}, {"version": "v4", "created": "Tue, 16 Jan 2018 04:39:40 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Hajek", "Bruce", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1510.02830", "submitter": "Yves-Laurent Kom Samo", "authors": "Yves-Laurent Kom Samo and Stephen J. Roberts", "title": "p-Markov Gaussian Processes for Scalable and Expressive Online Bayesian\n  Nonparametric Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we introduce a novel online time series forecasting model we\nrefer to as the pM-GP filter. We show that our model is equivalent to Gaussian\nprocess regression, with the advantage that both online forecasting and online\nlearning of the hyper-parameters have a constant (rather than cubic) time\ncomplexity and a constant (rather than squared) memory requirement in the\nnumber of observations, without resorting to approximations. Moreover, the\nproposed model is expressive in that the family of covariance functions of the\nimplied latent process, namely the spectral Matern kernels, have recently been\nproven to be capable of approximating arbitrarily well any\ntranslation-invariant covariance function. The benefit of our approach compared\nto competing models is demonstrated using experiments on several real-life\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 21:44:25 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Samo", "Yves-Laurent Kom", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1510.02833", "submitter": "Andrew Gardner", "authors": "Andrew Gardner, Christian A. Duncan, Jinko Kanno, and Rastko R. Selmic", "title": "On the Definiteness of Earth Mover's Distance and Its Relation to Set\n  Intersection", "comments": "Major revision based on referee comments. Includes significant\n  reorganization of content, new title, new propositions, revised proofs of\n  previous propositions, and additional experiments with new data, kernels, and\n  indefinite kernel techniques", "journal-ref": null, "doi": "10.1109/TCYB.2017.2761798", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive definite kernels are an important tool in machine learning that\nenable efficient solutions to otherwise difficult or intractable problems by\nimplicitly linearizing the problem geometry. In this paper we develop a\nset-theoretic interpretation of the Earth Mover's Distance (EMD) and propose\nEarth Mover's Intersection (EMI), a positive definite analog to EMD for sets of\ndifferent sizes. We provide conditions under which EMD or certain\napproximations to EMD are negative definite. We also present a\npositive-definite-preserving transformation that can be applied to any kernel\nand can also be used to derive positive definite EMD-based kernels and show\nthat the Jaccard index is simply the result of this transformation. Finally, we\nevaluate kernels based on EMI and the proposed transformation versus EMD in\nvarious computer vision tasks and show that EMD is generally inferior even with\nindefinite kernel techniques.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 21:51:09 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 21:16:08 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 14:31:18 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Gardner", "Andrew", ""], ["Duncan", "Christian A.", ""], ["Kanno", "Jinko", ""], ["Selmic", "Rastko R.", ""]]}, {"id": "1510.02847", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang, Kamalika Chaudhuri", "title": "Active Learning from Weak and Strong Labelers", "comments": "To appear in NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active learner is given a hypothesis class, a large set of unlabeled\nexamples and the ability to interactively query labels to an oracle of a subset\nof these examples; the goal of the learner is to learn a hypothesis in the\nclass that fits the data well by making as few label queries as possible.\n  This work addresses active learning with labels obtained from strong and weak\nlabelers, where in addition to the standard active learning setting, we have an\nextra weak labeler which may occasionally provide incorrect labels. An example\nis learning to classify medical images where either expensive labels may be\nobtained from a physician (oracle or strong labeler), or cheaper but\noccasionally incorrect labels may be obtained from a medical resident (weak\nlabeler). Our goal is to learn a classifier with low error on data labeled by\nthe oracle, while using the weak labeler to reduce the number of label queries\nmade to this labeler. We provide an active learning algorithm for this setting,\nestablish its statistical consistency, and analyze its label complexity to\ncharacterize when it can provide label savings over using the strong labeler\nalone.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 23:15:40 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2015 01:06:27 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Zhang", "Chicheng", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1510.02855", "submitter": "Abraham Heifets", "authors": "Izhar Wallach and Michael Dzamba and Abraham Heifets", "title": "AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction\n  in Structure-based Drug Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks comprise a subclass of deep neural\nnetworks (DNN) with a constrained architecture that leverages the spatial and\ntemporal structure of the domain they model. Convolutional networks achieve the\nbest predictive performance in areas such as speech and image recognition by\nhierarchically composing simple local features into complex models. Although\nDNNs have been used in drug discovery for QSAR and ligand-based bioactivity\npredictions, none of these models have benefited from this powerful\nconvolutional architecture. This paper introduces AtomNet, the first\nstructure-based, deep convolutional neural network designed to predict the\nbioactivity of small molecules for drug discovery applications. We demonstrate\nhow to apply the convolutional concepts of feature locality and hierarchical\ncomposition to the modeling of bioactivity and chemical interactions. In\nfurther contrast to existing DNN techniques, we show that AtomNet's application\nof local convolutional filters to structural target information successfully\npredicts new active molecules for targets with no previously known modulators.\nFinally, we show that AtomNet outperforms previous docking approaches on a\ndiverse set of benchmarks by a large margin, achieving an AUC greater than 0.9\non 57.8% of the targets in the DUDE benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2015 00:09:00 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Wallach", "Izhar", ""], ["Dzamba", "Michael", ""], ["Heifets", "Abraham", ""]]}, {"id": "1510.03042", "submitter": "Thuc Le Ph.D", "authors": "Thuc Duy Le, Tao Hoang, Jiuyong Li, Lin Liu, Shu Hu", "title": "ParallelPC: an R package for efficient constraint based causal\n  exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering causal relationships from data is the ultimate goal of many\nresearch areas. Constraint based causal exploration algorithms, such as PC,\nFCI, RFCI, PC-simple, IDA and Joint-IDA have achieved significant progress and\nhave many applications. A common problem with these methods is the high\ncomputational complexity, which hinders their applications in real world high\ndimensional datasets, e.g gene expression datasets. In this paper, we present\nan R package, ParallelPC, that includes the parallelised versions of these\ncausal exploration algorithms. The parallelised algorithms help speed up the\nprocedure of experimenting big datasets and reduce the memory used when running\nthe algorithms. The package is not only suitable for super-computers or\nclusters, but also convenient for researchers using personal computers with\nmulti core CPUs. Our experiment results on real world datasets show that using\nthe parallelised algorithms it is now practical to explore causal relationships\nin high dimensional datasets with thousands of variables in a single multicore\ncomputer. ParallelPC is available in CRAN repository at\nhttps://cran.rproject.org/web/packages/ParallelPC/index.html.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2015 11:55:39 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Le", "Thuc Duy", ""], ["Hoang", "Tao", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Hu", "Shu", ""]]}, {"id": "1510.03105", "submitter": "Ingmar Schuster", "authors": "Ingmar Schuster, Heiko Strathmann, Brooks Paige and Dino Sejdinovic", "title": "Kernel Sequential Monte Carlo", "comments": "ECML-PKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose kernel sequential Monte Carlo (KSMC), a framework for sampling\nfrom static target densities. KSMC is a family of sequential Monte Carlo\nalgorithms that are based on building emulator models of the current particle\nsystem in a reproducing kernel Hilbert space. We here focus on modelling\nnonlinear covariance structure and gradients of the target. The emulator's\ngeometry is adaptively updated and subsequently used to inform local proposals.\nUnlike in adaptive Markov chain Monte Carlo, continuous adaptation does not\ncompromise convergence of the sampler. KSMC combines the strengths of sequental\nMonte Carlo and kernel methods: superior performance for multimodal targets and\nthe ability to estimate model evidence as compared to Markov chain Monte Carlo,\nand the emulator's ability to represent targets that exhibit high degrees of\nnonlinearity. As KSMC does not require access to target gradients, it is\nparticularly applicable on targets whose gradients are unknown or prohibitively\nexpensive. We describe necessary tuning details and demonstrate the benefits of\nthe the proposed methodology on a series of challenging synthetic and\nreal-world examples.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2015 21:28:48 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 20:22:25 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2016 20:07:52 GMT"}, {"version": "v4", "created": "Tue, 25 Jul 2017 12:37:43 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Schuster", "Ingmar", ""], ["Strathmann", "Heiko", ""], ["Paige", "Brooks", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1510.03164", "submitter": "Purushottam Kar", "authors": "Shuai Li and Purushottam Kar", "title": "Context-Aware Bandits", "comments": "The paper has been withdrawn as the work has been superseded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient Context-Aware clustering of Bandits (CAB) algorithm,\nwhich can capture collaborative effects. CAB can be easily deployed in a\nreal-world recommendation system, where multi-armed bandits have been shown to\nperform well in particular with respect to the cold-start problem. CAB utilizes\na context-aware clustering augmented by exploration-exploitation strategies.\nCAB dynamically clusters the users based on the content universe under\nconsideration. We give a theoretical analysis in the standard stochastic\nmulti-armed bandits setting. We show the efficiency of our approach on\nproduction and real-world datasets, demonstrate the scalability, and, more\nimportantly, the significant increased prediction performance against several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 07:04:16 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 05:47:32 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 16:18:43 GMT"}, {"version": "v4", "created": "Fri, 10 Jun 2016 20:51:08 GMT"}, {"version": "v5", "created": "Sun, 26 Feb 2017 15:53:30 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Li", "Shuai", ""], ["Kar", "Purushottam", ""]]}, {"id": "1510.03203", "submitter": "Niko Br\\\"ummer", "authors": "Niko Br\\\"ummer", "title": "VB calibration to improve the interface between phone recognizer and\n  i-vector extractor", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EM training algorithm of the classical i-vector extractor is often\nincorrectly described as a maximum-likelihood method. The i-vector model is\nhowever intractable: the likelihood itself and the hidden-variable posteriors\nneeded for the EM algorithm cannot be computed in closed form. We show here\nthat the classical i-vector extractor recipe is actually a mean-field\nvariational Bayes (VB) recipe.\n  This theoretical VB interpretation turns out to be of further use, because it\nalso offers an interpretation of the newer phonetic i-vector extractor recipe,\nthereby unifying the two flavours of extractor.\n  More importantly, the VB interpretation is also practically useful: it\nsuggests ways of modifying existing i-vector extractors to make them more\naccurate. In particular, in existing methods, the approximate VB posterior for\nthe GMM states is fixed, while only the parameters of the generative model are\nadapted. Here we explore the possibility of also mildly adjusting (calibrating)\nthose posteriors, so that they better fit the generative model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 09:48:43 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 16:22:23 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Br\u00fcmmer", "Niko", ""]]}, {"id": "1510.03267", "submitter": "Andreas Christmann", "authors": "Andreas Christmann, Ding-Xuan Zhou", "title": "On the Robustness of Regularized Pairwise Learning Methods Based on\n  Kernels", "comments": "36 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized empirical risk minimization including support vector machines\nplays an important role in machine learning theory. In this paper regularized\npairwise learning (RPL) methods based on kernels will be investigated. One\nexample is regularized minimization of the error entropy loss which has\nrecently attracted quite some interest from the viewpoint of consistency and\nlearning rates. This paper shows that such RPL methods have additionally good\nstatistical robustness properties, if the loss function and the kernel are\nchosen appropriately. We treat two cases of particular interest: (i) a bounded\nand non-convex loss function and (ii) an unbounded convex loss function\nsatisfying a certain Lipschitz type condition.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 13:01:47 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Christmann", "Andreas", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1510.03298", "submitter": "Adam Lund", "authors": "Adam Lund, Martin Vincent, Niels Richard Hansen", "title": "Penalized estimation in large-scale generalized linear array models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale generalized linear array models (GLAMs) can be challenging to\nfit. Computation and storage of its tensor product design matrix can be\nimpossible due to time and memory constraints, and previously considered design\nmatrix free algorithms do not scale well with the dimension of the parameter\nvector. A new design matrix free algorithm is proposed for computing the\npenalized maximum likelihood estimate for GLAMs, which, in particular, handles\nnondifferentiable penalty functions. The proposed algorithm is implemented and\navailable via the R package \\verb+glamlasso+. It combines several ideas --\npreviously considered separately -- to obtain sparse estimates while at the\nsame time efficiently exploiting the GLAM structure. In this paper the\nconvergence of the algorithm is treated and the performance of its\nimplementation is investigated and compared to that of \\verb+glmnet+ on\nsimulated as well as real data. It is shown that the computation time for\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 14:26:36 GMT"}, {"version": "v2", "created": "Mon, 22 Aug 2016 09:54:30 GMT"}, {"version": "v3", "created": "Fri, 26 Aug 2016 11:19:08 GMT"}, {"version": "v4", "created": "Fri, 2 Sep 2016 06:08:40 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Lund", "Adam", ""], ["Vincent", "Martin", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "1510.03349", "submitter": "Wenjie Zheng", "authors": "Wenjie Zheng", "title": "Toward a Better Understanding of Leaderboard", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The leaderboard in machine learning competitions is a tool to show the\nperformance of various participants and to compare them. However, the\nleaderboard quickly becomes no longer accurate, due to hack or overfitting.\nThis article gives two pieces of advice to prevent easy hack or overfitting. By\nfollowing these advice, we reach the conclusion that something like the Ladder\nleaderboard introduced in [blum2015ladder] is inevitable. With this\nunderstanding, we naturally simplify Ladder by eliminating its redundant\ncomputation and explain how to choose the parameter and interpret it. We also\nprove that the sample complexity is cubic to the desired precision of the\nleaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 16:12:49 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 13:12:56 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Zheng", "Wenjie", ""]]}, {"id": "1510.03497", "submitter": "John Storey", "authors": "Xiongzhi Chen and John D. Storey", "title": "Consistent Estimation of Low-Dimensional Latent Structure in\n  High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider the problem of extracting a low-dimensional, linear latent\nvariable structure from high-dimensional random variables. Specifically, we\nshow that under mild conditions and when this structure manifests itself as a\nlinear space that spans the conditional means, it is possible to consistently\nrecover the structure using only information up to the second moments of these\nrandom variables. This finding, specialized to one-parameter exponential\nfamilies whose variance function is quadratic in their means, allows for the\nderivation of an explicit estimator of such latent structure. This approach\nserves as a latent variable model estimator and as a tool for dimension\nreduction for a high-dimensional matrix of data composed of many related\nvariables. Our theoretical results are verified by simulation studies and an\napplication to genomic data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 01:01:41 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Chen", "Xiongzhi", ""], ["Storey", "John D.", ""]]}, {"id": "1510.03507", "submitter": "Kevin Moon", "authors": "Stephen V. Gliske, Kevin R. Moon, William C. Stacey, Alfred O. Hero\n  III", "title": "The intrinsic value of HFO features as a biomarker of epileptic activity", "comments": "5 pages, 5 figures", "journal-ref": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), pp. 6290-6294, Mar. 2016", "doi": "10.1109/ICASSP.2016.7472887", "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High frequency oscillations (HFOs) are a promising biomarker of epileptic\nbrain tissue and activity. HFOs additionally serve as a prototypical example of\nchallenges in the analysis of discrete events in high-temporal resolution,\nintracranial EEG data. Two primary challenges are 1) dimensionality reduction,\nand 2) assessing feasibility of classification. Dimensionality reduction\nassumes that the data lie on a manifold with dimension less than that of the\nfeature space. However, previous HFO analyses have assumed a linear manifold,\nglobal across time, space (i.e. recording electrode/channel), and individual\npatients. Instead, we assess both a) whether linear methods are appropriate and\nb) the consistency of the manifold across time, space, and patients. We also\nestimate bounds on the Bayes classification error to quantify the distinction\nbetween two classes of HFOs (those occurring during seizures and those\noccurring due to other processes). This analysis provides the foundation for\nfuture clinical use of HFO features and buides the analysis for other discrete\nevents, such as individual action potentials or multi-unit activity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 01:57:12 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Gliske", "Stephen V.", ""], ["Moon", "Kevin R.", ""], ["Stacey", "William C.", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1510.03591", "submitter": "Edgar Klenske", "authors": "Edgar D. Klenske and Philipp Hennig", "title": "Dual Control for Approximate Bayesian Reinforcement Learning", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control of non-episodic, finite-horizon dynamical systems with uncertain\ndynamics poses a tough and elementary case of the exploration-exploitation\ntrade-off. Bayesian reinforcement learning, reasoning about the effect of\nactions and future observations, offers a principled solution, but is\nintractable. We review, then extend an old approximate approach from control\ntheory---where the problem is known as dual control---in the context of modern\nregression methods, specifically generalized linear regression. Experiments on\nsimulated systems show that this framework offers a useful approximation to the\nintractable aspects of Bayesian RL, producing structured exploration strategies\nthat differ from standard RL approaches. We provide simple examples for the use\nof this framework in (approximate) Gaussian process regression and feedforward\nneural networks for the control of exploration.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 09:29:23 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 14:48:58 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Klenske", "Edgar D.", ""], ["Hennig", "Philipp", ""]]}, {"id": "1510.03925", "submitter": "Alexander Rakhlin", "authors": "Alexander Rakhlin, Karthik Sridharan", "title": "On Equivalence of Martingale Tail Bounds and Deterministic Regret\n  Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an equivalence of (i) deterministic pathwise statements appearing in\nthe online learning literature (termed \\emph{regret bounds}), (ii)\nhigh-probability tail bounds for the supremum of a collection of martingales\n(of a specific form arising from uniform laws of large numbers for\nmartingales), and (iii) in-expectation bounds for the supremum. By virtue of\nthe equivalence, we prove exponential tail bounds for norms of Banach space\nvalued martingales via deterministic regret bounds for the online mirror\ndescent algorithm with an adaptive step size. We extend these results beyond\nthe linear structure of the Banach space: we define a notion of\n\\emph{martingale type} for general classes of real-valued functions and show\nits equivalence (up to a logarithmic factor) to various sequential complexities\nof the class (in particular, the sequential Rademacher complexity and its\noffset version). For classes with the general martingale type 2, we exhibit a\nfiner notion of variation that allows partial adaptation to the function\nindexing the martingale. Our proof technique rests on sequential symmetrization\nand on certifying the \\emph{existence} of regret minimization strategies for\ncertain online prediction problems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 23:23:58 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1510.04130", "submitter": "Jaroslav Fowkes", "authors": "Jaroslav Fowkes and Charles Sutton", "title": "A Bayesian Network Model for Interesting Itemsets", "comments": "Supplementary material attached as Ancillary File; in PKDD 2016:\n  European Conference on Machine Learning and Knowledge Discovery in Databases", "journal-ref": null, "doi": "10.1007/978-3-319-46227-1_26", "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining itemsets that are the most interesting under a statistical model of\nthe underlying data is a commonly used and well-studied technique for\nexploratory data analysis, with the most recent interestingness models\nexhibiting state of the art performance. Continuing this highly promising line\nof work, we propose the first, to the best of our knowledge, generative model\nover itemsets, in the form of a Bayesian network, and an associated novel\nmeasure of interestingness. Our model is able to efficiently infer interesting\nitemsets directly from the transaction database using structural EM, in which\nthe E-step employs the greedy approximation to weighted set cover. Our approach\nis theoretically simple, straightforward to implement, trivially parallelizable\nand retrieves itemsets whose quality is comparable to, if not better than,\nexisting state of the art algorithms as we demonstrate on several real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 14:55:17 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 11:15:30 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Fowkes", "Jaroslav", ""], ["Sutton", "Charles", ""]]}, {"id": "1510.04163", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Chong Wang, Eric Xing", "title": "Embarrassingly Parallel Variational Inference in Nonconjugate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a parallel variational inference (VI) procedure for use in\ndata-distributed settings, where each machine only has access to a subset of\ndata and runs VI independently, without communicating with other machines. This\ntype of \"embarrassingly parallel\" procedure has recently been developed for\nMCMC inference algorithms; however, in many cases it is not possible to\ndirectly extend this procedure to VI methods without requiring certain\nrestrictive exponential family conditions on the form of the model.\nFurthermore, most existing (nonparallel) VI methods are restricted to use on\nconditionally conjugate models, which limits their applicability. To combat\nthese issues, we make use of the recently proposed nonparametric VI to\nfacilitate an embarrassingly parallel VI procedure that can be applied to a\nwider scope of models, including to nonconjugate models. We derive our\nembarrassingly parallel VI algorithm, analyze our method theoretically, and\ndemonstrate our method empirically on a few nonconjugate models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 15:48:19 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Neiswanger", "Willie", ""], ["Wang", "Chong", ""], ["Xing", "Eric", ""]]}, {"id": "1510.04189", "submitter": "Arild N{\\o}kland", "authors": "Arild N{\\o}kland", "title": "Improving Back-Propagation by Adding an Adversarial Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The back-propagation algorithm is widely used for learning in artificial\nneural networks. A challenge in machine learning is to create models that\ngeneralize to new data samples not seen in the training data. Recently, a\ncommon flaw in several machine learning algorithms was discovered: small\nperturbations added to the input data lead to consistent misclassification of\ndata samples. Samples that easily mislead the model are called adversarial\nexamples. Training a \"maxout\" network on adversarial examples has shown to\ndecrease this vulnerability, but also increase classification performance. This\npaper shows that adversarial training has a regularizing effect also in\nnetworks with logistic, hyperbolic tangent and rectified linear units. A simple\nextension to the back-propagation method is proposed, that adds an adversarial\ngradient to the training. The extension requires an additional forward and\nbackward pass to calculate a modified input sample, or mini batch, used as\ninput for standard back-propagation learning. The first experimental results on\nMNIST show that the \"adversarial back-propagation\" method increases the\nresistance to adversarial examples and boosts the classification performance.\nThe extension reduces the classification error on the permutation invariant\nMNIST from 1.60% to 0.95% in a logistic network, and from 1.40% to 0.78% in a\nnetwork with rectified linear units. Results on CIFAR-10 indicate that the\nmethod has a regularizing effect similar to dropout in fully connected\nnetworks. Based on these promising results, adversarial back-propagation is\nproposed as a stand-alone regularizing method that should be further\ninvestigated.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 16:27:28 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 16:35:13 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["N\u00f8kland", "Arild", ""]]}, {"id": "1510.04195", "submitter": "Alexander Luedtke", "authors": "Alexander R. Luedtke, Marco Carone and Mark J. van der Laan", "title": "An Omnibus Nonparametric Test of Equality in Distribution for Unknown\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel family of nonparametric omnibus tests of the hypothesis\nthat two unknown but estimable functions are equal in distribution when applied\nto the observed data structure. We developed these tests, which represent a\ngeneralization of the maximum mean discrepancy tests described in Gretton et\nal. [2006], using recent developments from the higher-order pathwise\ndifferentiability literature. Despite their complex derivation, the associated\ntest statistics can be expressed rather simply as U-statistics. We study the\nasymptotic behavior of the proposed tests under the null hypothesis and under\nboth fixed and local alternatives. We provide examples to which our tests can\nbe applied and show that they perform well in a simulation study. As an\nimportant special case, our proposed tests can be used to determine whether an\nunknown function, such as the conditional average treatment effect, is equal to\nzero almost surely.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 16:43:26 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2015 22:32:30 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 00:03:58 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Luedtke", "Alexander R.", ""], ["Carone", "Marco", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1510.04342", "submitter": "Stefan Wager", "authors": "Stefan Wager and Susan Athey", "title": "Estimation and Inference of Heterogeneous Treatment Effects using Random\n  Forests", "comments": "To appear in the Journal of the American Statistical Association.\n  Part of the results developed in this paper were made available as an earlier\n  technical report \"Asymptotic Theory for Random Forests\", available at\n  (arXiv:1405.0352)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific and engineering challenges -- ranging from personalized\nmedicine to customized marketing recommendations -- require an understanding of\ntreatment effect heterogeneity. In this paper, we develop a non-parametric\ncausal forest for estimating heterogeneous treatment effects that extends\nBreiman's widely used random forest algorithm. In the potential outcomes\nframework with unconfoundedness, we show that causal forests are pointwise\nconsistent for the true treatment effect, and have an asymptotically Gaussian\nand centered sampling distribution. We also discuss a practical method for\nconstructing asymptotic confidence intervals for the true treatment effect that\nare centered at the causal forest estimates. Our theoretical results rely on a\ngeneric Gaussian theory for a large family of random forest algorithms. To our\nknowledge, this is the first set of results that allows any type of random\nforest, including classification and regression forests, to be used for\nprovably valid statistical inference. In experiments, we find causal forests to\nbe substantially more powerful than classical methods based on nearest-neighbor\nmatching, especially in the presence of irrelevant covariates.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 22:54:59 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2015 00:38:23 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 04:08:22 GMT"}, {"version": "v4", "created": "Mon, 10 Jul 2017 01:15:47 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Wager", "Stefan", ""], ["Athey", "Susan", ""]]}, {"id": "1510.04356", "submitter": "Shuchin Aeron", "authors": "Shuchin Aeron and Eric Kernfeld", "title": "Group-Invariant Subspace Clustering", "comments": "Proceedings of Allerton 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of group invariant subspace clustering\nwhere the data is assumed to come from a union of group-invariant subspaces of\na vector space, i.e. subspaces which are invariant with respect to action of a\ngiven group. Algebraically, such group-invariant subspaces are also referred to\nas submodules. Similar to the well known Sparse Subspace Clustering approach\nwhere the data is assumed to come from a union of subspaces, we analyze an\nalgorithm which, following a recent work [1], we refer to as Sparse Sub-module\nClustering (SSmC). The method is based on finding group-sparse\nself-representation of data points. In this paper we primarily derive general\nconditions under which such a group-invariant subspace identification is\npossible. In particular we extend the geometric analysis in [2] and in the\nprocess we identify a related problem in geometric functional analysis.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 00:05:21 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Aeron", "Shuchin", ""], ["Kernfeld", "Eric", ""]]}, {"id": "1510.04373", "submitter": "Muhammad Ghifary", "authors": "Muhammad Ghifary and David Balduzzi and W. Bastiaan Kleijn and Mengjie\n  Zhang", "title": "Scatter Component Analysis: A Unified Framework for Domain Adaptation\n  and Domain Generalization", "comments": "to appear in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses classification tasks on a particular target domain in\nwhich labeled training data are only available from source domains different\nfrom (but related to) the target. Two closely related frameworks, domain\nadaptation and domain generalization, are concerned with such tasks, where the\nonly difference between those frameworks is the availability of the unlabeled\ntarget data: domain adaptation can leverage unlabeled target information, while\ndomain generalization cannot. We propose Scatter Component Analyis (SCA), a\nfast representation learning algorithm that can be applied to both domain\nadaptation and domain generalization. SCA is based on a simple geometrical\nmeasure, i.e., scatter, which operates on reproducing kernel Hilbert space. SCA\nfinds a representation that trades between maximizing the separability of\nclasses, minimizing the mismatch between domains, and maximizing the\nseparability of data; each of which is quantified through scatter. The\noptimization problem of SCA can be reduced to a generalized eigenvalue problem,\nwhich results in a fast and exact solution. Comprehensive experiments on\nbenchmark cross-domain object recognition datasets verify that SCA performs\nmuch faster than several state-of-the-art algorithms and also provides\nstate-of-the-art classification accuracy in both domain adaptation and domain\ngeneralization. We also show that scatter can be used to establish a\ntheoretical generalization bound in the case of domain adaptation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 01:41:12 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 21:35:08 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Ghifary", "Muhammad", ""], ["Balduzzi", "David", ""], ["Kleijn", "W. Bastiaan", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1510.04378", "submitter": "Rui Song", "authors": "Chengchun Shi, Rui Song and Wenbin Lu", "title": "Robust Learning for Optimal Treatment Decision with NP-Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to identify important variables that are involved in making optimal\ntreatment decision, Lu et al. (2013) proposed a penalized least squared\nregression framework for a fixed number of predictors, which is robust against\nthe misspecification of the conditional mean model. Two problems arise: (i) in\na world of explosively big data, effective methods are needed to handle\nultra-high dimensional data set, for example, with the dimension of predictors\nis of the non-polynomial (NP) order of the sample size; (ii) both the\npropensity score and conditional mean models need to be estimated from data\nunder NP dimensionality.\n  In this paper, we propose a two-step estimation procedure for deriving the\noptimal treatment regime under NP dimensionality. In both steps, penalized\nregressions are employed with the non-concave penalty function, where the\nconditional mean model of the response given predictors may be misspecified.\nThe asymptotic properties, such as weak oracle properties, selection\nconsistency and oracle distributions, of the proposed estimators are\ninvestigated. In addition, we study the limiting distribution of the estimated\nvalue function for the obtained optimal treatment regime. The empirical\nperformance of the proposed estimation method is evaluated by simulations and\nan application to a depression dataset from the STAR*D study.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 02:13:56 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Shi", "Chengchun", ""], ["Song", "Rui", ""], ["Lu", "Wenbin", ""]]}, {"id": "1510.04747", "submitter": "Yang Shi", "authors": "Animashree Anandkumar, Prateek Jain, Yang Shi, U. N. Niranjan", "title": "Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust tensor CP decomposition involves decomposing a tensor into low rank\nand sparse components. We propose a novel non-convex iterative algorithm with\nguaranteed recovery. It alternates between low-rank CP decomposition through\ngradient ascent (a variant of the tensor power method), and hard thresholding\nof the residual. We prove convergence to the globally optimal solution under\nnatural incoherence conditions on the low rank component, and bounded level of\nsparse perturbations. We compare our method with natural baselines which apply\nrobust matrix PCA either to the {\\em flattened} tensor, or to the matrix slices\nof the tensor. Our method can provably handle a far greater level of\nperturbation when the sparse tensor is block-structured. This naturally occurs\nin many applications such as the activity detection task in videos. Our\nexperiments validate these findings. Thus, we establish that tensor methods can\ntolerate a higher level of gross corruptions compared to matrix methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 23:40:13 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2015 00:53:13 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2015 05:02:03 GMT"}, {"version": "v4", "created": "Sat, 14 Nov 2015 21:54:08 GMT"}, {"version": "v5", "created": "Sun, 27 Dec 2015 03:06:51 GMT"}, {"version": "v6", "created": "Fri, 22 Jan 2016 22:41:21 GMT"}, {"version": "v7", "created": "Wed, 27 Apr 2016 05:19:21 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Jain", "Prateek", ""], ["Shi", "Yang", ""], ["Niranjan", "U. N.", ""]]}, {"id": "1510.04815", "submitter": "Wenzhe Li", "authors": "Wenzhe Li, Sungjin Ahn, Max Welling", "title": "Scalable MCMC for Mixed Membership Stochastic Blockmodels", "comments": "9 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic gradient Markov chain Monte Carlo (SG-MCMC) algorithm\nfor scalable inference in mixed-membership stochastic blockmodels (MMSB). Our\nalgorithm is based on the stochastic gradient Riemannian Langevin sampler and\nachieves both faster speed and higher accuracy at every iteration than the\ncurrent state-of-the-art algorithm based on stochastic variational inference.\nIn addition we develop an approximation that can handle models that entertain a\nvery large number of communities. The experimental results show that SG-MCMC\nstrictly dominates competing algorithms in all cases.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 08:32:29 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 02:14:13 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Li", "Wenzhe", ""], ["Ahn", "Sungjin", ""], ["Welling", "Max", ""]]}, {"id": "1510.04822", "submitter": "Massil Achab", "authors": "Massil Achab (CMAP), Agathe Guilloux (LSTA), St\\'ephane Ga\\\"iffas\n  (CMAP) and Emmanuel Bacry (CMAP)", "title": "SGD with Variance Reduction beyond Empirical Risk Minimization", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a doubly stochastic proximal gradient algorithm for optimizing a\nfinite average of smooth convex functions, whose gradients depend on\nnumerically expensive expectations. Our main motivation is the acceleration of\nthe optimization of the regularized Cox partial-likelihood (the core model used\nin survival analysis), but our algorithm can be used in different settings as\nwell. The proposed algorithm is doubly stochastic in the sense that gradient\nsteps are done using stochastic gradient descent (SGD) with variance reduction,\nwhere the inner expectations are approximated by a Monte-Carlo Markov-Chain\n(MCMC) algorithm. We derive conditions on the MCMC number of iterations\nguaranteeing convergence, and obtain a linear rate of convergence under strong\nconvexity and a sublinear rate without this assumption. We illustrate the fact\nthat our algorithm improves the state-of-the-art solver for regularized Cox\npartial-likelihood on several datasets from survival analysis.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 09:32:24 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 19:45:58 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2016 09:43:23 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Achab", "Massil", "", "CMAP"], ["Guilloux", "Agathe", "", "LSTA"], ["Ga\u00efffas", "St\u00e9phane", "", "CMAP"], ["Bacry", "Emmanuel", "", "CMAP"]]}, {"id": "1510.04850", "submitter": "Diego Carrera", "authors": "Cesare Alippi, Giacomo Boracchi, Diego Carrera, Manuel Roveri", "title": "Change Detection in Multivariate Datastreams: Likelihood and\n  Detectability Loss", "comments": null, "journal-ref": "Proceedings of the Twenty-Fifth International Joint Conference on\n  Artificial Intelligence (IJCAI), 2016", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of detecting changes in multivariate datastreams, and\nwe investigate the intrinsic difficulty that change-detection methods have to\nface when the data dimension scales. In particular, we consider a general\napproach where changes are detected by comparing the distribution of the\nlog-likelihood of the datastream over different time windows. Despite the fact\nthat this approach constitutes the frame of several change-detection methods,\nits effectiveness when data dimension scales has never been investigated, which\nis indeed the goal of our paper. We show that the magnitude of the change can\nbe naturally measured by the symmetric Kullback-Leibler divergence between the\npre- and post-change distributions, and that the detectability of a change of a\ngiven magnitude worsens when the data dimension increases. This problem, which\nwe refer to as \\emph{detectability loss}, is due to the linear relationship\nbetween the variance of the log-likelihood and the data dimension. We\nanalytically derive the detectability loss on Gaussian-distributed datastreams,\nand empirically demonstrate that this problem holds also on real-world datasets\nand that can be harmful even at low data-dimensions (say, 10).\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 11:54:05 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 13:21:01 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2016 07:54:16 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Alippi", "Cesare", ""], ["Boracchi", "Giacomo", ""], ["Carrera", "Diego", ""], ["Roveri", "Manuel", ""]]}, {"id": "1510.04905", "submitter": "Marek Petrik", "authors": "Stephen Becker, Ban Kawas, Marek Petrik, Karthikeyan N. Ramamurthy", "title": "Robust Partially-Compressed Least-Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized matrix compression techniques, such as the Johnson-Lindenstrauss\ntransform, have emerged as an effective and practical way for solving\nlarge-scale problems efficiently. With a focus on computational efficiency,\nhowever, forsaking solutions quality and accuracy becomes the trade-off. In\nthis paper, we investigate compressed least-squares problems and propose new\nmodels and algorithms that address the issue of error and noise introduced by\ncompression. While maintaining computational efficiency, our models provide\nrobust solutions that are more accurate--relative to solutions of uncompressed\nleast-squares--than those of classical compressed variants. We introduce tools\nfrom robust optimization together with a form of partial compression to improve\nthe error-time trade-offs of compressed least-squares solvers. We develop an\nefficient solution algorithm for our Robust Partially-Compressed (RPC) model\nbased on a reduction to a one-dimensional search. We also derive the first\napproximation error bounds for Partially-Compressed least-squares solutions.\nEmpirical results comparing numerous alternatives suggest that robust and\npartially compressed solutions are effectively insulated against aggressive\nrandomized transforms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 14:59:04 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Becker", "Stephen", ""], ["Kawas", "Ban", ""], ["Petrik", "Marek", ""], ["Ramamurthy", "Karthikeyan N.", ""]]}, {"id": "1510.04935", "submitter": "Maximilian Nickel", "authors": "Maximilian Nickel, Lorenzo Rosasco, Tomaso Poggio", "title": "Holographic Embeddings of Knowledge Graphs", "comments": "To appear in AAAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning embeddings of entities and relations is an efficient and versatile\nmethod to perform machine learning on relational data such as knowledge graphs.\nIn this work, we propose holographic embeddings (HolE) to learn compositional\nvector space representations of entire knowledge graphs. The proposed method is\nrelated to holographic models of associative memory in that it employs circular\ncorrelation to create compositional representations. By using correlation as\nthe compositional operator HolE can capture rich interactions but\nsimultaneously remains efficient to compute, easy to train, and scalable to\nvery large datasets. In extensive experiments we show that holographic\nembeddings are able to outperform state-of-the-art methods for link prediction\nin knowledge graphs and relational learning benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 16:29:07 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2015 18:05:52 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Nickel", "Maximilian", ""], ["Rosasco", "Lorenzo", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1510.04953", "submitter": "Benjamin Krause", "authors": "Ben Krause", "title": "Optimizing and Contrasting Recurrent Neural Network Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have long been recognized for their\npotential to model complex time series. However, it remains to be determined\nwhat optimization techniques and recurrent architectures can be used to best\nrealize this potential. The experiments presented take a deep look into Hessian\nfree optimization, a powerful second order optimization method that has shown\npromising results, but still does not enjoy widespread use. This algorithm was\nused to train to a number of RNN architectures including standard RNNs, long\nshort-term memory, multiplicative RNNs, and stacked RNNs on the task of\ncharacter prediction. The insights from these experiments led to the creation\nof a new multiplicative LSTM hybrid architecture that outperformed both LSTM\nand multiplicative RNNs. When tested on a larger scale, multiplicative LSTM\nachieved character level modelling results competitive with the state of the\nart for RNNs using very different methodology.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 17:16:14 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Krause", "Ben", ""]]}, {"id": "1510.05043", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta", "title": "A cost function for similarity-based hierarchical clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of algorithms for hierarchical clustering has been hampered\nby a shortage of precise objective functions. To help address this situation,\nwe introduce a simple cost function on hierarchies over a set of points, given\npairwise similarities between those points. We show that this criterion behaves\nsensibly in canonical instances and that it admits a top-down construction\nprocedure with a provably good approximation ratio.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 22:48:28 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Dasgupta", "Sanjoy", ""]]}, {"id": "1510.05058", "submitter": "Victor Amelkin", "authors": "Victor Amelkin, Ambuj Singh, Petko Bogdanov", "title": "A Distance Measure for the Analysis of Polar Opinion Dynamics in Social\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/ICDE.2017.64", "report-no": null, "categories": "cs.SI cs.DM cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of opinion dynamics in social networks plays an important role in\ntoday's life. For applications such as predicting users' political preference,\nit is particularly important to be able to analyze the dynamics of competing\nopinions. While observing the evolution of polar opinions of a social network's\nusers over time, can we tell when the network \"behaved\" abnormally?\nFurthermore, can we predict how the opinions of the users will change in the\nfuture? Do opinions evolve according to existing network opinion dynamics\nmodels? To answer such questions, it is not sufficient to study individual user\nbehavior, since opinions can spread far beyond users' egonets. We need a method\nto analyze opinion dynamics of all network users simultaneously and capture the\neffect of individuals' behavior on the global evolution pattern of the social\nnetwork.\n  In this work, we introduce Social Network Distance (SND) - a distance measure\nthat quantifies the \"cost\" of evolution of one snapshot of a social network\ninto another snapshot under various models of polar opinion propagation. SND\nhas a rich semantics of a transportation problem, yet, is computable in time\nlinear in the number of users, which makes SND applicable to the analysis of\nlarge-scale online social networks. In our experiments with synthetic and\nreal-world Twitter data, we demonstrate the utility of our distance measure for\nanomalous event detection. It achieves a true positive rate of 0.83, twice as\nhigh as that of alternatives. When employed for opinion prediction in Twitter,\nour method's accuracy is 75.63%, which is 7.5% higher than that of the next\nbest method.\n  Source Code: https://cs.ucsb.edu/~victor/pub/ucsb/dbl/snd/\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2015 01:12:37 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Amelkin", "Victor", ""], ["Singh", "Ambuj", ""], ["Bogdanov", "Petko", ""]]}, {"id": "1510.05078", "submitter": "Chong Wang", "authors": "Chong Wang and David M. Blei", "title": "A General Method for Robust Bayesian Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Bayesian models are appealing alternatives to standard models,\nproviding protection from data that contains outliers or other departures from\nthe model assumptions. Historically, robust models were mostly developed on a\ncase-by-case basis; examples include robust linear regression, robust mixture\nmodels, and bursty topic models. In this paper we develop a general approach to\nrobust Bayesian modeling. We show how to turn an existing Bayesian model into a\nrobust model, and then develop a generic strategy for computing with it. We use\nour method to study robust variants of several models, including linear\nregression, Poisson regression, logistic regression, and probabilistic topic\nmodels. We discuss the connections between our methods and existing approaches,\nespecially empirical Bayes and James-Stein estimation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2015 06:48:48 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2016 04:52:06 GMT"}, {"version": "v3", "created": "Wed, 7 Sep 2016 00:30:16 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Wang", "Chong", ""], ["Blei", "David M.", ""]]}, {"id": "1510.05149", "submitter": "Mehrdad Jafari-Mamaghani", "authors": "Mehrdad Jafari-Mamaghani", "title": "Robust Non-linear Wiener-Granger Causality For Large High-dimensional\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wiener-Granger causality is a widely used framework of causal analysis for\ntemporally resolved events. We introduce a new measure of Wiener-Granger\ncausality based on kernelization of partial canonical correlation analysis with\nspecific advantages in the context of large high-dimensional data. The\nintroduced measure is able to detect non-linear and non-monotonous signals, is\ndesigned to be immune to noise, and offers tunability in terms of computational\ncomplexity in its estimations. Furthermore, we show that, under specified\nconditions, the introduced measure can be regarded as an estimate of\nconditional mutual information (transfer entropy). The functionality of this\nmeasure is assessed using comparative simulations where it outperforms other\nexisting methods. The paper is concluded with an application to climatological\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2015 17:42:25 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Jafari-Mamaghani", "Mehrdad", ""]]}, {"id": "1510.05154", "submitter": "Christopher Gatti", "authors": "Christopher J. Gatti, James D. Brooks, and Sarah G. Nurre", "title": "A Historical Analysis of the Field of OR/MS using Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the content of the published scientific literature in\nthe fields of operations research and management science (OR/MS) since the\nearly 1950s. Our study is based on 80,757 published journal abstracts from 37\nof the leading OR/MS journals. We have developed a topic model, using Latent\nDirichlet Allocation (LDA), and extend this analysis to reveal the temporal\ndynamics of the field, journals, and topics. Our analysis shows the generality\nor specificity of each of the journals, and we identify groups of journals with\nsimilar content, which are both consistent and inconsistent with intuition. We\nalso show how journals have become more or less unique in their scope. A more\ndetailed analysis of each journals' topics over time shows significant temporal\ndynamics, especially for journals with niche content. This study presents an\nobservational, yet objective, view of the published literature from OR/MS that\nwould be of interest to authors, editors, journals, and publishers.\nFurthermore, this work can be used by new entrants to the fields of OR/MS to\nunderstand the content landscape, as a starting point for discussions and\ninquiry of the field at large, or as a model for other fields to perform\nsimilar analyses.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2015 18:52:24 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Gatti", "Christopher J.", ""], ["Brooks", "James D.", ""], ["Nurre", "Sarah G.", ""]]}, {"id": "1510.05214", "submitter": "Or Zuk", "authors": "Tom Hope, Avishai Wagner and Or Zuk", "title": "Clustering Noisy Signals with Structured Sparsity Using Time-Frequency\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and efficient time-series clustering framework\nparticularly suited for low Signal-to-Noise Ratio (SNR), by simultaneous\nsmoothing and dimensionality reduction aimed at preserving clustering\ninformation. We extend the sparse K-means algorithm by incorporating structured\nsparsity, and use it to exploit the multi-scale property of wavelets and group\nstructure in multivariate signals. Finally, we extract features invariant to\ntranslation and scaling with the scattering transform, which corresponds to a\nconvolutional network with filters given by a wavelet operator, and use the\nnetwork's structure in sparse clustering. By promoting sparsity, this transform\ncan yield a low-dimensional representation of signals that gives improved\nclustering results on several real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 09:41:50 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Hope", "Tom", ""], ["Wagner", "Avishai", ""], ["Zuk", "Or", ""]]}, {"id": "1510.05257", "submitter": "Michalis Titsias", "authors": "P. Dellaportas, A. Plataniotis and M. K. Titsias", "title": "Scalable inference for a full multivariate stochastic volatility model", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a multivariate stochastic volatility model for asset returns\nthat imposes no restrictions to the structure of the volatility matrix and\ntreats all its elements as functions of latent stochastic processes. When the\nnumber of assets is prohibitively large, we propose a factor multivariate\nstochastic volatility model in which the variances and correlations of the\nfactors evolve stochastically over time. Inference is achieved via a carefully\ndesigned feasible and scalable Markov chain Monte Carlo algorithm that combines\ntwo computationally important ingredients: it utilizes invariant to the prior\nMetropolis proposal densities for simultaneously updating all latent paths and\nhas quadratic, rather than cubic, computational complexity when evaluating the\nmultivariate normal densities required. We apply our modelling and\ncomputational methodology to $571$ stock daily returns of Euro STOXX index for\ndata over a period of $10$ years. MATLAB software for this paper is available\nat http://www.aueb.gr/users/mtitsias/code/msv.zip.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 15:08:27 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 16:21:18 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Dellaportas", "P.", ""], ["Plataniotis", "A.", ""], ["Titsias", "M. K.", ""]]}, {"id": "1510.05336", "submitter": "Shai Ben-David", "authors": "Shai Ben-David", "title": "Clustering is Easy When ....What?", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that most of the common clustering objectives are NP-hard to\noptimize. In practice, however, clustering is being routinely carried out. One\napproach for providing theoretical understanding of this seeming discrepancy is\nto come up with notions of clusterability that distinguish realistically\ninteresting input data from worst-case data sets. The hope is that there will\nbe clustering algorithms that are provably efficient on such \"clusterable\"\ninstances. This paper addresses the thesis that the computational hardness of\nclustering tasks goes away for inputs that one really cares about. In other\nwords, that \"Clustering is difficult only when it does not matter\" (the\n\\emph{CDNM thesis} for short).\n  I wish to present a a critical bird's eye overview of the results published\non this issue so far and to call attention to the gap between available and\ndesirable results on this issue. A longer, more detailed version of this note\nis available as arXiv:1507.05307.\n  I discuss which requirements should be met in order to provide formal support\nto the the CDNM thesis and then examine existing results in view of these\nrequirements and list some significant unsolved research challenges in that\ndirection.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 02:40:33 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Ben-David", "Shai", ""]]}, {"id": "1510.05407", "submitter": "Jithin Sreedharan", "authors": "Konstantin Avrachenkov (MAESTRO), Bruno Ribeiro, Jithin K. Sreedharan\n  (MAESTRO)", "title": "Bayesian Inference of Online Social Network Statistics via Lightweight\n  Random Walk Crawls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social networks (OSN) contain extensive amount of information about\nthe underlying society that is yet to be explored. One of the most feasible\ntechnique to fetch information from OSN, crawling through Application\nProgramming Interface (API) requests, poses serious concerns over the the\nguarantees of the estimates. In this work, we focus on making reliable\nstatistical inference with limited API crawls. Based on regenerative properties\nof the random walks, we propose an unbiased estimator for the aggregated sum of\nfunctions over edges and proved the connection between variance of the\nestimator and spectral gap. In order to facilitate Bayesian inference on the\ntrue value of the estimator, we derive the approximate posterior distribution\nof the estimate. Later the proposed ideas are validated with numerical\nexperiments on inference problems in real-world networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 09:50:14 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2015 08:51:36 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Avrachenkov", "Konstantin", "", "MAESTRO"], ["Ribeiro", "Bruno", "", "MAESTRO"], ["Sreedharan", "Jithin K.", "", "MAESTRO"]]}, {"id": "1510.05417", "submitter": "Toshiki Sato", "authors": "Toshiki Sato, Yuichi Takano, Ryuhei Miyashiro", "title": "Piecewise-Linear Approximation for Feature Subset Selection in a\n  Sequential Logit Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns a method of selecting a subset of features for a\nsequential logit model. Tanaka and Nakagawa (2014) proposed a mixed integer\nquadratic optimization formulation for solving the problem based on a quadratic\napproximation of the logistic loss function. However, since there is a\nsignificant gap between the logistic loss function and its quadratic\napproximation, their formulation may fail to find a good subset of features. To\novercome this drawback, we apply a piecewise-linear approximation to the\nlogistic loss function. Accordingly, we frame the feature subset selection\nproblem of minimizing an information criterion as a mixed integer linear\noptimization problem. The computational results demonstrate that our\npiecewise-linear approximation approach found a better subset of features than\nthe quadratic approximation approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 10:44:53 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Sato", "Toshiki", ""], ["Takano", "Yuichi", ""], ["Miyashiro", "Ryuhei", ""]]}, {"id": "1510.05461", "submitter": "Justin Khim", "authors": "Justin Khim, Po-Ling Loh", "title": "Confidence Sets for the Source of a Diffusion in Regular Trees", "comments": "23 pages", "journal-ref": "IEEE Transactions on Network Science and Engineering ( Volume: 4,\n  Issue: 1, Jan.-March 1 2017 )", "doi": "10.1109/TNSE.2016.2627502", "report-no": null, "categories": "math.ST cs.DM cs.SI math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying the source of a diffusion spreading over\na regular tree. When the degree of each node is at least three, we show that it\nis possible to construct confidence sets for the diffusion source with size\nindependent of the number of infected nodes. Our estimators are motivated by\nanalogous results in the literature concerning identification of the root node\nin preferential attachment and uniform attachment trees. At the core of our\nproofs is a probabilistic analysis of P\\'{o}lya urns corresponding to the\nnumber of uninfected neighbors in specific subtrees of the infection tree. We\nalso provide an example illustrating the shortcomings of source estimation\ntechniques in settings where the underlying graph is asymmetric.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 13:21:39 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Khim", "Justin", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1510.05477", "submitter": "Mehmet Basbug", "authors": "Mehmet Emin Basbug, Koray Ozcan and Senem Velipasalar", "title": "Accelerometer based Activity Classification with Variational Inference\n  on Sticky HDP-SLDS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As part of daily monitoring of human activities, wearable sensors and devices\nare becoming increasingly popular sources of data. With the advent of\nsmartphones equipped with acceloremeter, gyroscope and camera; it is now\npossible to develop activity classification platforms everyone can use\nconveniently. In this paper, we propose a fast inference method for an\nunsupervised non-parametric time series model namely variational inference for\nsticky HDP-SLDS(Hierarchical Dirichlet Process Switching Linear Dynamical\nSystem). We show that the proposed algorithm can differentiate various indoor\nactivities such as sitting, walking, turning, going up/down the stairs and\ntaking the elevator using only the acceloremeter of an Android smartphone\nSamsung Galaxy S4. We used the front camera of the smartphone to annotate\nactivity types precisely. We compared the proposed method with Hidden Markov\nModels with Gaussian emission probabilities on a dataset of 10 subjects. We\nshowed that the efficacy of the stickiness property. We further compared the\nvariational inference to the Gibbs sampler on the same model and show that\nvariational inference is faster in one order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 13:58:37 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Basbug", "Mehmet Emin", ""], ["Ozcan", "Koray", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1510.05492", "submitter": "Hansi Jiang", "authors": "Hansi Jiang, Carl Meyer", "title": "Modularity Component Analysis versus Principal Component Analysis", "comments": "7 pages", "journal-ref": null, "doi": "10.11648/j.ajam.20160402.15", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the exact linear relation between the leading eigenvectors of\nthe modularity matrix and the singular vectors of an uncentered data matrix is\ndeveloped. Based on this analysis the concept of a modularity component is\ndefined, and its properties are developed. It is shown that modularity\ncomponent analysis can be used to cluster data similar to how traditional\nprincipal component analysis is used except that modularity component analysis\ndoes not require data centering.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 14:27:10 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2016 07:02:38 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Jiang", "Hansi", ""], ["Meyer", "Carl", ""]]}, {"id": "1510.05576", "submitter": "Emile Contal", "authors": "Emile Contal, C\\'edric Malherbe, Nicolas Vayatis", "title": "Optimization for Gaussian Processes via Chaining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of stochastic optimization under a\nbandit feedback model. We generalize the GP-UCB algorithm [Srinivas and al.,\n2012] to arbitrary kernels and search spaces. To do so, we use a notion of\nlocalized chaining to control the supremum of a Gaussian process, and provide a\nnovel optimization scheme based on the computation of covering numbers. The\ntheoretical bounds we obtain on the cumulative regret are more generic and\npresent the same convergence rates as the GP-UCB algorithm. Finally, the\nalgorithm is shown to be empirically more efficient than its natural\ncompetitors on simple and complex input spaces.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 16:41:30 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Contal", "Emile", ""], ["Malherbe", "C\u00e9dric", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1510.05610", "submitter": "Nihar Shah", "authors": "Nihar B. Shah, Sivaraman Balakrishnan, Adityanand Guntuboyina and\n  Martin J. Wainwright", "title": "Stochastically Transitive Models for Pairwise Comparisons: Statistical\n  and Computational Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are various parametric models for analyzing pairwise comparison data,\nincluding the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance\non strong parametric assumptions is limiting. In this work, we study a flexible\nmodel for pairwise comparisons, under which the probabilities of outcomes are\nrequired only to satisfy a natural form of stochastic transitivity. This class\nincludes parametric models including the BTL and Thurstone models as special\ncases, but is considerably more general. We provide various examples of models\nin this broader stochastically transitive class for which classical parametric\nmodels provide poor fits. Despite this greater flexibility, we show that the\nmatrix of probabilities can be estimated at the same rate as in standard\nparametric models. On the other hand, unlike in the BTL and Thurstone models,\ncomputing the minimax-optimal estimator in the stochastically transitive model\nis non-trivial, and we explore various computationally tractable alternatives.\nWe show that a simple singular value thresholding algorithm is statistically\nconsistent but does not achieve the minimax rate. We then propose and study\nalgorithms that achieve the minimax rate over interesting sub-classes of the\nfull stochastically transitive class. We complement our theoretical results\nwith thorough numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 18:19:16 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2015 17:54:49 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 18:41:40 GMT"}, {"version": "v4", "created": "Wed, 28 Sep 2016 02:14:25 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Shah", "Nihar B.", ""], ["Balakrishnan", "Sivaraman", ""], ["Guntuboyina", "Adityanand", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1510.05684", "submitter": "Alessandro Rudi", "authors": "Tomas Angles, Raffaello Camoriano, Alessandro Rudi, Lorenzo Rosasco", "title": "NYTRO: When Subsampling Meets Early Stopping", "comments": "AISTATS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early stopping is a well known approach to reduce the time complexity for\nperforming training and model selection of large scale learning machines. On\nthe other hand, memory/space (rather than time) complexity is the main\nconstraint in many applications, and randomized subsampling techniques have\nbeen proposed to tackle this issue. In this paper we ask whether early stopping\nand subsampling ideas can be combined in a fruitful way. We consider the\nquestion in a least squares regression setting and propose a form of randomized\niterative regularization based on early stopping and subsampling. In this\ncontext, we analyze the statistical and computational properties of the\nproposed method. Theoretical results are complemented and validated by a\nthorough experimental analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 20:47:59 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 22:14:41 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Angles", "Tomas", ""], ["Camoriano", "Raffaello", ""], ["Rudi", "Alessandro", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1510.05830", "submitter": "Ariel Jaffe", "authors": "Ariel Jaffe, Ethan Fetaya, Boaz Nadler, Tingting Jiang, Yuval Kluger", "title": "Unsupervised Ensemble Learning with Dependent Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised ensemble learning, one obtains predictions from multiple\nsources or classifiers, yet without knowing the reliability and expertise of\neach source, and with no labeled data to assess it. The task is to combine\nthese possibly conflicting predictions into an accurate meta-learner. Most\nworks to date assumed perfect diversity between the different sources, a\nproperty known as conditional independence. In realistic scenarios, however,\nthis assumption is often violated, and ensemble learners based on it can be\nseverely sub-optimal. The key challenges we address in this paper are:\\ (i) how\nto detect, in an unsupervised manner, strong violations of conditional\nindependence; and (ii) construct a suitable meta-learner. To this end we\nintroduce a statistical model that allows for dependencies between classifiers.\nOur main contributions are the development of novel unsupervised methods to\ndetect strongly dependent classifiers, better estimate their accuracies, and\nconstruct an improved meta-learner. Using both artificial and real datasets, we\nshowcase the importance of taking classifier dependencies into account and the\ncompetitive performance of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 10:48:40 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2016 20:50:55 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Jaffe", "Ariel", ""], ["Fetaya", "Ethan", ""], ["Nadler", "Boaz", ""], ["Jiang", "Tingting", ""], ["Kluger", "Yuval", ""]]}, {"id": "1510.05956", "submitter": "Seyoung Yun", "authors": "Se-Young Yun and Alexandre Proutiere", "title": "Optimal Cluster Recovery in the Labeled Stochastic Block Model", "comments": "arXiv admin note: text overlap with arXiv:1412.7335", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of community detection or clustering in the labeled\nStochastic Block Model (LSBM) with a finite number $K$ of clusters of sizes\nlinearly growing with the global population of items $n$. Every pair of items\nis labeled independently at random, and label $\\ell$ appears with probability\n$p(i,j,\\ell)$ between two items in clusters indexed by $i$ and $j$,\nrespectively. The objective is to reconstruct the clusters from the observation\nof these random labels.\n  Clustering under the SBM and their extensions has attracted much attention\nrecently. Most existing work aimed at characterizing the set of parameters such\nthat it is possible to infer clusters either positively correlated with the\ntrue clusters, or with a vanishing proportion of misclassified items, or\nexactly matching the true clusters. We find the set of parameters such that\nthere exists a clustering algorithm with at most $s$ misclassified items in\naverage under the general LSBM and for any $s=o(n)$, which solves one open\nproblem raised in \\cite{abbe2015community}. We further develop an algorithm,\nbased on simple spectral methods, that achieves this fundamental performance\nlimit within $O(n \\mbox{polylog}(n))$ computations and without the a-priori\nknowledge of the model parameters.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 16:47:27 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2015 01:18:59 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2015 23:50:11 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2015 14:03:41 GMT"}, {"version": "v5", "created": "Mon, 21 Dec 2015 01:23:31 GMT"}, {"version": "v6", "created": "Sat, 21 May 2016 19:41:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Yun", "Se-Young", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "1510.05981", "submitter": "Roberto Souza", "authors": "Roberto C.S.N.P. Souza, Denise E.F de Brito, Renato M. Assun\\c{c}\\~ao,\n  Wagner Meira Jr", "title": "A latent shared-component generative model for real-time disease\n  surveillance using Twitter data", "comments": "Appears in 2nd ACM SIGKDD Workshop on Connected Health at Big Data\n  Era (BigCHat)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting the large amount of available data for addressing relevant social\nproblems has been one of the key challenges in data mining. Such efforts have\nbeen recently named \"data science for social good\" and attracted the attention\nof several researchers and institutions. We give a contribution in this\nobjective in this paper considering a difficult public health problem, the\ntimely monitoring of dengue epidemics in small geographical areas. We develop a\ngenerative simple yet effective model to connect the fluctuations of disease\ncases and disease-related Twitter posts. We considered a hidden Markov process\ndriving both, the fluctuations in dengue reported cases and the tweets issued\nin each region. We add a stable but random source of tweets to represent the\nposts when no disease cases are recorded. The model is learned through a Markov\nchain Monte Carlo algorithm that produces the posterior distribution of the\nrelevant parameters. Using data from a significant number of large Brazilian\ntowns, we demonstrate empirically that our model is able to predict well the\nnext weeks of the disease counts using the tweets and disease cases jointly.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 17:44:44 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Souza", "Roberto C. S. N. P.", ""], ["de Brito", "Denise E. F", ""], ["Assun\u00e7\u00e3o", "Renato M.", ""], ["Meira", "Wagner", "Jr"]]}, {"id": "1510.06083", "submitter": "Hongbo Dong", "authors": "Hongbo Dong and Kun Chen and Jeff Linderoth", "title": "Regularization vs. Relaxation: A conic optimization perspective of\n  statistical variable selection", "comments": "Also available on optimization online\n  {http://www.optimization-online.org/DB_HTML/2015/05/4932.html}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is a fundamental task in statistical data analysis.\nSparsity-inducing regularization methods are a popular class of methods that\nsimultaneously perform variable selection and model estimation. The central\nproblem is a quadratic optimization problem with an l0-norm penalty. Exactly\nenforcing the l0-norm penalty is computationally intractable for larger scale\nproblems, so dif- ferent sparsity-inducing penalty functions that approximate\nthe l0-norm have been introduced. In this paper, we show that viewing the\nproblem from a convex relaxation perspective offers new insights. In\nparticular, we show that a popular sparsity-inducing concave penalty function\nknown as the Minimax Concave Penalty (MCP), and the reverse Huber penalty\nderived in a recent work by Pilanci, Wainwright and Ghaoui, can both be derived\nas special cases of a lifted convex relaxation called the perspective\nrelaxation. The optimal perspective relaxation is a related minimax problem\nthat balances the overall convexity and tightness of approximation to the l0\nnorm. We show it can be solved by a semidefinite relaxation. Moreover, a\nprobabilistic interpretation of the semidefinite relaxation reveals connections\nwith the boolean quadric polytope in combinatorial optimization. Finally by\nreformulating the l0-norm pe- nalized problem as a two-level problem, with the\ninner level being a Max-Cut problem, our proposed semidefinite relaxation can\nbe realized by replacing the inner level problem with its semidefinite\nrelaxation studied by Goemans and Williamson. This interpretation suggests\nusing the Goemans-Williamson rounding procedure to find approximate solutions\nto the l0-norm penalized problem. Numerical experiments demonstrate the\ntightness of our proposed semidefinite relaxation, and the effectiveness of\nfinding approximate solutions by Goemans-Williamson rounding.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 22:55:48 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Dong", "Hongbo", ""], ["Chen", "Kun", ""], ["Linderoth", "Jeff", ""]]}, {"id": "1510.06096", "submitter": "Ju Sun", "authors": "Ju Sun, Qing Qu, John Wright", "title": "When Are Nonconvex Problems Not Scary?", "comments": "6 pages, 3 figures. New examples on phase synchronization and\n  community detection added; emphasis on all local minimizers being global\n  added; exposition is polished. This is a concise expository article that\n  avoids much technical rigor. We will make a separate submission with full\n  technical details in future", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we focus on smooth nonconvex optimization problems that obey:\n(1) all local minimizers are also global; and (2) around any saddle point or\nlocal maximizer, the objective has a negative directional curvature. Concrete\napplications such as dictionary learning, generalized phase retrieval, and\northogonal tensor decomposition are known to induce such structures. We\ndescribe a second-order trust-region algorithm that provably converges to a\nglobal minimizer efficiently, without special initializations. Finally we\nhighlight alternatives, and open problems in this direction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 00:59:23 GMT"}, {"version": "v2", "created": "Sat, 23 Apr 2016 00:18:06 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Sun", "Ju", ""], ["Qu", "Qing", ""], ["Wright", "John", ""]]}, {"id": "1510.06112", "submitter": "Andrew Landgraf", "authors": "Andrew J. Landgraf and Yoonkyung Lee", "title": "Dimensionality Reduction for Binary Data through the Projection of\n  Natural Parameters", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmva.2020.104668", "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) for binary data, known as logistic PCA,\nhas become a popular alternative to dimensionality reduction of binary data. It\nis motivated as an extension of ordinary PCA by means of a matrix\nfactorization, akin to the singular value decomposition, that maximizes the\nBernoulli log-likelihood. We propose a new formulation of logistic PCA which\nextends Pearson's formulation of a low dimensional data representation with\nminimum error to binary data. Our formulation does not require a matrix\nfactorization, as previous methods do, but instead looks for projections of the\nnatural parameters from the saturated model. Due to this difference, the number\nof parameters does not grow with the number of observations and the principal\ncomponent scores on new data can be computed with simple matrix multiplication.\nWe derive explicit solutions for data matrices of special structure and provide\ncomputationally efficient algorithms for solving for the principal component\nloadings. Through simulation experiments and an analysis of medical diagnoses\ndata, we compare our formulation of logistic PCA to the previous formulation as\nwell as ordinary PCA to demonstrate its benefits.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 02:25:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Landgraf", "Andrew J.", ""], ["Lee", "Yoonkyung", ""]]}, {"id": "1510.06138", "submitter": "Tomoki Tokuda", "authors": "Tomoki Tokuda, Junichiro Yoshimoto, Yu Shimizu, Shigeru Toki, Go\n  Okada, Masahiro Takamura, Tetsuya Yamamoto, Shinpei Yoshimura, Yasumasa\n  Okamoto, Shigeto Yamawaki, Kenji Doya", "title": "Multiple co-clustering based on nonparametric mixture models with\n  heterogeneous marginal distributions", "comments": null, "journal-ref": "PLOS ONE, 12(10), 2017", "doi": "10.1371/journal.pone.0186566", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for multiple clustering that assumes a\nco-clustering structure (partitions in both rows and columns of the data\nmatrix) in each view. The new method is applicable to high-dimensional data. It\nis based on a nonparametric Bayesian approach in which the number of views and\nthe number of feature-/subject clusters are inferred in a data-driven manner.\nWe simultaneously model different distribution families, such as Gaussian,\nPoisson, and multinomial distributions in each cluster block. This makes our\nmethod applicable to datasets consisting of both numerical and categorical\nvariables, which biomedical data typically do. Clustering solutions are based\non variational inference with mean field approximation. We apply the proposed\nmethod to synthetic and real data, and show that our method outperforms other\nmultiple clustering methods both in recovering true cluster structures and in\ncomputation time. Finally, we apply our method to a depression dataset with no\ntrue cluster structure available, from which useful inferences are drawn about\npossible clustering structures of the data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 06:13:49 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Tokuda", "Tomoki", ""], ["Yoshimoto", "Junichiro", ""], ["Shimizu", "Yu", ""], ["Toki", "Shigeru", ""], ["Okada", "Go", ""], ["Takamura", "Masahiro", ""], ["Yamamoto", "Tetsuya", ""], ["Yoshimura", "Shinpei", ""], ["Okamoto", "Yasumasa", ""], ["Yamawaki", "Shigeto", ""], ["Doya", "Kenji", ""]]}, {"id": "1510.06188", "submitter": "Jonathan Scarlett", "authors": "Luca Baldassarre and Yen-Huan Li and Jonathan Scarlett and Baran\n  G\\\"ozc\\\"u and Ilija Bogunovic and Volkan Cevher", "title": "Learning-based Compressive Subsampling", "comments": "Submitted to IEEE Journal on Selected Topics in Signal Processing", "journal-ref": null, "doi": "10.1109/JSTSP.2016.2548442", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of recovering a structured signal $\\mathbf{x} \\in \\mathbb{C}^p$\nfrom a set of dimensionality-reduced linear measurements $\\mathbf{b} = \\mathbf\n{A}\\mathbf {x}$ arises in a variety of applications, such as medical imaging,\nspectroscopy, Fourier optics, and computerized tomography. Due to computational\nand storage complexity or physical constraints imposed by the problem, the\nmeasurement matrix $\\mathbf{A} \\in \\mathbb{C}^{n \\times p}$ is often of the\nform $\\mathbf{A} = \\mathbf{P}_{\\Omega}\\boldsymbol{\\Psi}$ for some orthonormal\nbasis matrix $\\boldsymbol{\\Psi}\\in \\mathbb{C}^{p \\times p}$ and subsampling\noperator $\\mathbf{P}_{\\Omega}: \\mathbb{C}^{p} \\rightarrow \\mathbb{C}^{n}$ that\nselects the rows indexed by $\\Omega$. This raises the fundamental question of\nhow best to choose the index set $\\Omega$ in order to optimize the recovery\nperformance. Previous approaches to addressing this question rely on\nnon-uniform \\emph{random} subsampling using application-specific knowledge of\nthe structure of $\\mathbf{x}$. In this paper, we instead take a principled\nlearning-based approach in which a \\emph{fixed} index set is chosen based on a\nset of training signals $\\mathbf{x}_1,\\dotsc,\\mathbf{x}_m$. We formulate\ncombinatorial optimization problems seeking to maximize the energy captured in\nthese signals in an average-case or worst-case sense, and we show that these\ncan be efficiently solved either exactly or approximately via the\nidentification of modularity and submodularity structures. We provide both\ndeterministic and statistical theoretical guarantees showing how the resulting\nmeasurement matrices perform on signals differing from the training signals,\nand we provide numerical examples showing our approach to be effective on a\nvariety of data sets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 10:03:45 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2016 09:56:20 GMT"}, {"version": "v3", "created": "Mon, 28 Mar 2016 15:32:26 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Baldassarre", "Luca", ""], ["Li", "Yen-Huan", ""], ["Scarlett", "Jonathan", ""], ["G\u00f6zc\u00fc", "Baran", ""], ["Bogunovic", "Ilija", ""], ["Cevher", "Volkan", ""]]}, {"id": "1510.06299", "submitter": "Javier Gonz\\'alez", "authors": "Javier Gonz\\'alez, Michael Osborne, Neil D. Lawrence", "title": "GLASSES: Relieving The Myopia Of Bayesian Optimisation", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GLASSES: Global optimisation with Look-Ahead through Stochastic\nSimulation and Expected-loss Search. The majority of global optimisation\napproaches in use are myopic, in only considering the impact of the next\nfunction value; the non-myopic approaches that do exist are able to consider\nonly a handful of future evaluations. Our novel algorithm, GLASSES, permits the\nconsideration of dozens of evaluations into the future. This is done by\napproximating the ideal look-ahead loss function, which is expensive to\nevaluate, by a cheaper alternative in which the future steps of the algorithm\nare simulated beforehand. An Expectation Propagation algorithm is used to\ncompute the expected value of the loss.We show that the far-horizon planning\nthus enabled leads to substantive performance gains in empirical tests.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 15:30:17 GMT"}], "update_date": "2015-10-22", "authors_parsed": [["Gonz\u00e1lez", "Javier", ""], ["Osborne", "Michael", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1510.06356", "submitter": "Steven Adachi", "authors": "Steven H. Adachi and Maxwell P. Henderson", "title": "Application of Quantum Annealing to Training of Deep Neural Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": "DIS201510002", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Deep Learning, a well-known approach for training a Deep Neural Network\nstarts by training a generative Deep Belief Network model, typically using\nContrastive Divergence (CD), then fine-tuning the weights using backpropagation\nor other discriminative techniques. However, the generative training can be\ntime-consuming due to the slow mixing of Gibbs sampling. We investigated an\nalternative approach that estimates model expectations of Restricted Boltzmann\nMachines using samples from a D-Wave quantum annealing machine. We tested this\nmethod on a coarse-grained version of the MNIST data set. In our tests we found\nthat the quantum sampling-based training approach achieves comparable or better\naccuracy with significantly fewer iterations of generative training than\nconventional CD-based training. Further investigation is needed to determine\nwhether similar improvements can be achieved for other data sets, and to what\nextent these improvements can be attributed to quantum effects.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 18:21:39 GMT"}], "update_date": "2015-10-22", "authors_parsed": [["Adachi", "Steven H.", ""], ["Henderson", "Maxwell P.", ""]]}, {"id": "1510.06423", "submitter": "Zi Wang", "authors": "Zi Wang, Bolei Zhou, Stefanie Jegelka", "title": "Optimization as Estimation with Gaussian Processes in Bandit Settings", "comments": "Proceedings of the 19th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2016, Cadiz, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been rising interest in Bayesian optimization -- the\noptimization of an unknown function with assumptions usually expressed by a\nGaussian Process (GP) prior. We study an optimization strategy that directly\nuses an estimate of the argmax of the function. This strategy offers both\npractical and theoretical advantages: no tradeoff parameter needs to be\nselected, and, moreover, we establish close connections to the popular GP-UCB\nand GP-PI strategies. Our approach can be understood as automatically and\nadaptively trading off exploration and exploitation in GP-UCB and GP-PI. We\nillustrate the effects of this adaptive tuning via bounds on the regret as well\nas an extensive empirical evaluation on robotics and vision tasks,\ndemonstrating the robustness of this strategy for a range of performance\ncriteria.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 20:35:13 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2015 18:22:28 GMT"}, {"version": "v3", "created": "Sun, 24 Apr 2016 16:56:38 GMT"}, {"version": "v4", "created": "Sun, 12 Aug 2018 16:03:00 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wang", "Zi", ""], ["Zhou", "Bolei", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1510.06463", "submitter": "Michael Katehakis", "authors": "Michael N. Katehakis, Jian Yang, and Tingting Zhou", "title": "Inventory Control Involving Unknown Demand of Discrete Nonperishable\n  Items - Analysis of a Newsvendor-based Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inventory control with unknown demand distribution is considered, with\nemphasis placed on the case involving discrete nonperishable items. We focus on\nan adaptive policy which in every period uses, as much as possible, the optimal\nnewsvendor ordering quantity for the empirical distribution learned up to that\nperiod. The policy is assessed using the regret criterion, which measures the\nprice paid for ambiguity on demand distribution over $T$ periods. When there\nare guarantees on the latter's separation from the critical newsvendor\nparameter $\\beta=b/(h+b)$, a constant upper bound on regret can be found.\nWithout any prior information on the demand distribution, we show that the\nregret does not grow faster than the rate $T^{1/2+\\epsilon}$ for any\n$\\epsilon>0$. In view of a known lower bound, this is almost the best one could\nhope for. Simulation studies involving this along with other policies are also\nconducted.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2015 00:56:39 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Katehakis", "Michael N.", ""], ["Yang", "Jian", ""], ["Zhou", "Tingting", ""]]}, {"id": "1510.06567", "submitter": "Remi Flamary", "authors": "Alain Rakotomamonjy (LITIS), R\\'emi Flamary (LAGRANGE, OCA), Nicolas\n  Courty (OBELIX)", "title": "Generalized conditional gradient: analysis of convergence and\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objectives of this technical report is to provide additional results on\nthe generalized conditional gradient methods introduced by Bredies et al.\n[BLM05]. Indeed , when the objective function is smooth, we provide a novel\ncertificate of optimality and we show that the algorithm has a linear\nconvergence rate. Applications of this algorithm are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2015 10:19:52 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Rakotomamonjy", "Alain", "", "LITIS"], ["Flamary", "R\u00e9mi", "", "LAGRANGE, OCA"], ["Courty", "Nicolas", "", "OBELIX"]]}, {"id": "1510.06582", "submitter": "Bartosz Hawelka", "authors": "Bartosz Hawelka, Izabela Sitko, Pavlos Kazakopoulos and Euro Beinat", "title": "Collective Prediction of Individual Mobility Traces with Exponential\n  Weights", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and test a sequential learning algorithm for the short-term\nprediction of human mobility. This novel approach pairs the Exponential Weights\nforecaster with a very large ensemble of experts. The experts are individual\nsequence prediction algorithms constructed from the mobility traces of 10\nmillion roaming mobile phone users in a European country. Average prediction\naccuracy is significantly higher than that of individual sequence prediction\nalgorithms, namely constant order Markov models derived from the user's own\ndata, that have been shown to achieve high accuracy in previous studies of\nhuman mobility prediction. The algorithm uses only time stamped location data,\nand accuracy depends on the completeness of the expert ensemble, which should\ncontain redundant records of typical mobility patterns. The proposed algorithm\nis applicable to the prediction of any sufficiently large dataset of sequences.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2015 11:27:03 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Hawelka", "Bartosz", ""], ["Sitko", "Izabela", ""], ["Kazakopoulos", "Pavlos", ""], ["Beinat", "Euro", ""]]}, {"id": "1510.06646", "submitter": "Osama Khalifa", "authors": "Osama Khalifa, David Wolfe Corne, Mike Chantler", "title": "A 'Gibbs-Newton' Technique for Enhanced Inference of Multivariate Polya\n  Parameters and Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-parameters play a major role in the learning and inference process of\nlatent Dirichlet allocation (LDA). In order to begin the LDA latent variables\nlearning process, these hyper-parameters values need to be pre-determined. We\npropose an extension for LDA that we call 'Latent Dirichlet allocation Gibbs\nNewton' (LDA-GN), which places non-informative priors over these\nhyper-parameters and uses Gibbs sampling to learn appropriate values for them.\nAt the heart of LDA-GN is our proposed 'Gibbs-Newton' algorithm, which is a new\ntechnique for learning the parameters of multivariate Polya distributions. We\nreport Gibbs-Newton performance results compared with two prominent existing\napproaches to the latter task: Minka's fixed-point iteration method and the\nMoments method. We then evaluate LDA-GN in two ways: (i) by comparing it with\nstandard LDA in terms of the ability of the resulting topic models to\ngeneralize to unseen documents; (ii) by comparing it with standard LDA in its\nperformance on a binary classification task.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2015 14:39:58 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 12:29:43 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Khalifa", "Osama", ""], ["Corne", "David Wolfe", ""], ["Chantler", "Mike", ""]]}, {"id": "1510.06779", "submitter": "Siong Thye Goh", "authors": "Siong Thye Goh, Cynthia Rudin", "title": "Cascaded High Dimensional Histograms: A Generative Approach to Density\n  Estimation", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present tree- and list- structured density estimation methods for high\ndimensional binary/categorical data. Our density estimation models are high\ndimensional analogies to variable bin width histograms. In each leaf of the\ntree (or list), the density is constant, similar to the flat density within the\nbin of a histogram. Histograms, however, cannot easily be visualized in higher\ndimensions, whereas our models can. The accuracy of histograms fades as\ndimensions increase, whereas our models have priors that help with\ngeneralization. Our models are sparse, unlike high-dimensional histograms. We\npresent three generative models, where the first one allows the user to specify\nthe number of desired leaves in the tree within a Bayesian prior. The second\nmodel allows the user to specify the desired number of branches within the\nprior. The third model returns lists (rather than trees) and allows the user to\nspecify the desired number of rules and the length of rules within the prior.\nOur results indicate that the new approaches yield a better balance between\nsparsity and accuracy of density estimates than other methods for this task.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2015 22:29:17 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 09:35:23 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2016 03:21:30 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Goh", "Siong Thye", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1510.06920", "submitter": "Fabien Lauer", "authors": "Fabien Lauer (ABC)", "title": "On the complexity of switching linear regression", "comments": "Automatica, Elsevier, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical note extends recent results on the computational complexity of\nglobally minimizing the error of piecewise-affine models to the related problem\nof minimizing the error of switching linear regression models. In particular,\nwe show that, on the one hand the problem is NP-hard, but on the other hand, it\nadmits a polynomial-time algorithm with respect to the number of data points\nfor any fixed data dimension and number of modes.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 12:45:29 GMT"}, {"version": "v2", "created": "Mon, 4 Jul 2016 12:32:11 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Lauer", "Fabien", "", "ABC"]]}, {"id": "1510.07025", "submitter": "Dawen Liang", "authors": "Dawen Liang, Laurent Charlin, James McInerney, David M. Blei", "title": "Modeling User Exposure in Recommendation", "comments": "11 pages, 4 figures. WWW'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering analyzes user preferences for items (e.g., books,\nmovies, restaurants, academic papers) by exploiting the similarity patterns\nacross users. In implicit feedback settings, all the items, including the ones\nthat a user did not consume, are taken into consideration. But this assumption\ndoes not accord with the common sense understanding that users have a limited\nscope and awareness of items. For example, a user might not have heard of a\ncertain paper, or might live too far away from a restaurant to experience it.\nIn the language of causal analysis, the assignment mechanism (i.e., the items\nthat a user is exposed to) is a latent variable that may change for various\nuser/item combinations. In this paper, we propose a new probabilistic approach\nthat directly incorporates user exposure to items into collaborative filtering.\nThe exposure is modeled as a latent variable and the model infers its value\nfrom data. In doing so, we recover one of the most successful state-of-the-art\napproaches as a special case of our model, and provide a plug-in method for\nconditioning exposure on various forms of exposure covariates (e.g., topics in\ntext, venue locations). We show that our scalable inference algorithm\noutperforms existing benchmarks in four different domains both with and without\nexposure covariates.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 19:39:38 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 18:58:44 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Liang", "Dawen", ""], ["Charlin", "Laurent", ""], ["McInerney", "James", ""], ["Blei", "David M.", ""]]}, {"id": "1510.07169", "submitter": "Emanuele Frandi", "authors": "Emanuele Frandi, Ricardo Nanculef, Stefano Lodi, Claudio Sartori,\n  Johan A. K. Suykens", "title": "Fast and Scalable Lasso via Stochastic Frank-Wolfe Methods with a\n  Convergence Guarantee", "comments": null, "journal-ref": null, "doi": null, "report-no": "Internal Report 15-93, ESAT-STADIUS, KU Leuven, 2015", "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frank-Wolfe (FW) algorithms have been often proposed over the last few years\nas efficient solvers for a variety of optimization problems arising in the\nfield of Machine Learning. The ability to work with cheap projection-free\niterations and the incremental nature of the method make FW a very effective\nchoice for many large-scale problems where computing a sparse model is\ndesirable.\n  In this paper, we present a high-performance implementation of the FW method\ntailored to solve large-scale Lasso regression problems, based on a randomized\niteration, and prove that the convergence guarantees of the standard FW method\nare preserved in the stochastic setting. We show experimentally that our\nalgorithm outperforms several existing state of the art methods, including the\nCoordinate Descent algorithm by Friedman et al. (one of the fastest known Lasso\nsolvers), on several benchmark datasets with a very large number of features,\nwithout sacrificing the accuracy of the model. Our results illustrate that the\nalgorithm is able to generate the complete regularization path on problems of\nsize up to four million variables in less than one minute.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 17:56:27 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Frandi", "Emanuele", ""], ["Nanculef", "Ricardo", ""], ["Lodi", "Stefano", ""], ["Sartori", "Claudio", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1510.07389", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Christoph Dann, Christopher G. Lucas, Eric P.\n  Xing", "title": "The Human Kernel", "comments": "11 pages, 5 figures. To appear in Neural Information Processing\n  Systems (NIPS) 2015. Version 2: Figure 2 (i)-(n) now displays the second set\n  of progressive function learning experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric models, such as Gaussian processes, provide a\ncompelling framework for automatic statistical modelling: these models have a\nhigh degree of flexibility, and automatically calibrated complexity. However,\nautomating human expertise remains elusive; for example, Gaussian processes\nwith standard kernels struggle on function extrapolation problems that are\ntrivial for human learners. In this paper, we create function extrapolation\nproblems and acquire human responses, and then design a kernel learning\nframework to reverse engineer the inductive biases of human learners across a\nset of behavioral experiments. We use the learned kernels to gain psychological\ninsights and to extrapolate in human-like ways that go beyond traditional\nstationary and polynomial kernels. Finally, we investigate Occam's razor in\nhuman and Gaussian process based function learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 07:39:47 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2015 18:21:11 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2015 18:07:35 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Dann", "Christoph", ""], ["Lucas", "Christopher G.", ""], ["Xing", "Eric P.", ""]]}, {"id": "1510.07471", "submitter": "Cheng Chen", "authors": "Cheng Chen, Shuang Liu, Zhihua Zhang, Wu-Jun Li", "title": "A Parallel algorithm for $\\mathcal{X}$-Armed bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The target of $\\mathcal{X}$-armed bandit problem is to find the global\nmaximum of an unknown stochastic function $f$, given a finite budget of $n$\nevaluations. Recently, $\\mathcal{X}$-armed bandits have been widely used in\nmany situations. Many of these applications need to deal with large-scale data\nsets. To deal with these large-scale data sets, we study a distributed setting\nof $\\mathcal{X}$-armed bandits, where $m$ players collaborate to find the\nmaximum of the unknown function. We develop a novel anytime distributed\n$\\mathcal{X}$-armed bandit algorithm. Compared with prior work on\n$\\mathcal{X}$-armed bandits, our algorithm uses a quite different searching\nstrategy so as to fit distributed learning scenarios. Our theoretical analysis\nshows that our distributed algorithm is $m$ times faster than the classical\nsingle-player algorithm. Moreover, the number of communication rounds of our\nalgorithm is only logarithmic in $mn$. The numerical results show that our\nmethod can make effective use of every players to minimize the loss. Thus, our\ndistributed approach is attractive and useful.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 13:23:48 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Chen", "Cheng", ""], ["Liu", "Shuang", ""], ["Zhang", "Zhihua", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1510.07609", "submitter": "Joseph Wang", "authors": "Joseph Wang, Kirill Trapeznikov, Venkatesh Saligrama", "title": "Efficient Learning by Directed Acyclic Graph For Resource Constrained\n  Prediction", "comments": "To appear in NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of reducing test-time acquisition costs in\nclassification systems. Our goal is to learn decision rules that adaptively\nselect sensors for each example as necessary to make a confident prediction. We\nmodel our system as a directed acyclic graph (DAG) where internal nodes\ncorrespond to sensor subsets and decision functions at each node choose whether\nto acquire a new sensor or classify using the available measurements. This\nproblem can be naturally posed as an empirical risk minimization over training\ndata. Rather than jointly optimizing such a highly coupled and non-convex\nproblem over all decision nodes, we propose an efficient algorithm motivated by\ndynamic programming. We learn node policies in the DAG by reducing the global\nobjective to a series of cost sensitive learning problems. Our approach is\ncomputationally efficient and has proven guarantees of convergence to the\noptimal system for a fixed architecture. In addition, we present an extension\nto map other budgeted learning problems with large number of sensors to our DAG\narchitecture and demonstrate empirical performance exceeding state-of-the-art\nalgorithms for data composed of both few and many sensors.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 19:40:10 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Wang", "Joseph", ""], ["Trapeznikov", "Kirill", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1510.07727", "submitter": "Art Owen", "authors": "Art B. Owen", "title": "Statistically efficient thinning of a Markov chain sampler", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to subsample Markov chain output to reduce the storage burden.\nGeyer (1992) shows that discarding $k-1$ out of every $k$ observations will not\nimprove statistical efficiency, as quantified through variance in a given\ncomputational budget. That observation is often taken to mean that thinning\nMCMC output cannot improve statistical efficiency. Here we suppose that it\ncosts one unit of time to advance a Markov chain and then $\\theta>0$ units of\ntime to compute a sampled quantity of interest. For a thinned process, that\ncost $\\theta$ is incurred less often, so it can be advanced through more\nstages. Here we provide examples to show that thinning will improve statistical\nefficiency if $\\theta$ is large and the sample autocorrelations decay slowly\nenough. If the lag $\\ell\\ge1$ autocorrelations of a scalar measurement satisfy\n$\\rho_\\ell\\ge\\rho_{\\ell+1}\\ge0$, then there is always a $\\theta<\\infty$ at\nwhich thinning becomes more efficient for averages of that scalar. Many sample\nautocorrelation functions resemble first order AR(1) processes with $\\rho_\\ell\n=\\rho^{|\\ell|}$ for some $-1<\\rho<1$. For an AR(1) process it is possible to\ncompute the most efficient subsampling frequency $k$. The optimal $k$ grows\nrapidly as $\\rho$ increases towards $1$. The resulting efficiency gain depends\nprimarily on $\\theta$, not $\\rho$. Taking $k=1$ (no thinning) is optimal when\n$\\rho\\le0$. For $\\rho>0$ it is optimal if and only if $\\theta \\le\n(1-\\rho)^2/(2\\rho)$. This efficiency gain never exceeds $1+\\theta$. This paper\nalso gives efficiency bounds for autocorrelations bounded between those of two\nAR(1) processes.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 00:00:54 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 21:55:29 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2015 22:06:58 GMT"}, {"version": "v4", "created": "Sun, 31 Jan 2016 23:47:55 GMT"}, {"version": "v5", "created": "Wed, 21 Sep 2016 01:03:26 GMT"}, {"version": "v6", "created": "Tue, 14 Mar 2017 22:51:02 GMT"}, {"version": "v7", "created": "Tue, 11 Apr 2017 02:23:00 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Owen", "Art B.", ""]]}, {"id": "1510.07740", "submitter": "Saeed Saremi", "authors": "Saeed Saremi, Terrence J. Sejnowski", "title": "The Wilson Machine for Image Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the distribution of natural images is one of the hardest and most\nimportant problems in machine learning. The problem remains open, because the\nenormous complexity of the structures in natural images spans all length\nscales. We break down the complexity of the problem and show that the hierarchy\nof structures in natural images fuels a new class of learning algorithms based\non the theory of critical phenomena and stochastic processes. We approach this\nproblem from the perspective of the theory of critical phenomena, which was\ndeveloped in condensed matter physics to address problems with infinite\nlength-scale fluctuations, and build a framework to integrate the criticality\nof natural images into a learning algorithm. The problem is broken down by\nmapping images into a hierarchy of binary images, called bitplanes. In this\nrepresentation, the top bitplane is critical, having fluctuations in structures\nover a vast range of scales. The bitplanes below go through a gradual\nstochastic heating process to disorder. We turn this representation into a\ndirected probabilistic graphical model, transforming the learning problem into\nthe unsupervised learning of the distribution of the critical bitplane and the\nsupervised learning of the conditional distributions for the remaining\nbitplanes. We learnt the conditional distributions by logistic regression in a\nconvolutional architecture. Conditioned on the critical binary image, this\nsimple architecture can generate large, natural-looking images, with many\nshades of gray, without the use of hidden units, unprecedented in the studies\nof natural images. The framework presented here is a major step in bringing\ncriticality and stochastic processes to machine learning and in studying\nnatural image statistics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 01:04:05 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2015 22:28:55 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Saremi", "Saeed", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1510.07786", "submitter": "Simone Romano", "authors": "Simone Romano and Nguyen Xuan Vinh and James Bailey and Karin Verspoor", "title": "A Framework to Adjust Dependency Measure Estimates for Chance", "comments": "In Proceedings of the 2016 SIAM International Conference on Data\n  Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the strength of dependency between two variables is fundamental\nfor exploratory analysis and many other applications in data mining. For\nexample: non-linear dependencies between two continuous variables can be\nexplored with the Maximal Information Coefficient (MIC); and categorical\nvariables that are dependent to the target class are selected using Gini gain\nin random forests. Nonetheless, because dependency measures are estimated on\nfinite samples, the interpretability of their quantification and the accuracy\nwhen ranking dependencies become challenging. Dependency estimates are not\nequal to 0 when variables are independent, cannot be compared if computed on\ndifferent sample size, and they are inflated by chance on variables with more\ncategories. In this paper, we propose a framework to adjust dependency measure\nestimates on finite samples. Our adjustments, which are simple and applicable\nto any dependency measure, are helpful in improving interpretability when\nquantifying dependency and in improving accuracy on the task of ranking\ndependencies. In particular, we demonstrate that our approach enhances the\ninterpretability of MIC when used as a proxy for the amount of noise between\nvariables, and to gain accuracy when ranking variables during the splitting\nprocedure in random forests.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 06:57:55 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2016 06:00:32 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Romano", "Simone", ""], ["Vinh", "Nguyen Xuan", ""], ["Bailey", "James", ""], ["Verspoor", "Karin", ""]]}, {"id": "1510.07925", "submitter": "Ji Liu", "authors": "Yijun Huang and Ji Liu", "title": "Exclusive Sparsity Norm Minimization with Random Groups via Cone\n  Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many practical applications such as gene expression analysis, multi-task\nlearning, image recognition, signal processing, and medical data analysis\npursue a sparse solution for the feature selection purpose and particularly\nfavor the nonzeros \\emph{evenly} distributed in different groups. The exclusive\nsparsity norm has been widely used to serve to this purpose. However, it still\nlacks systematical studies for exclusive sparsity norm optimization. This paper\noffers two main contributions from the optimization perspective: 1) We provide\nseveral efficient algorithms to solve exclusive sparsity norm minimization with\neither smooth loss or hinge loss (non-smooth loss). All algorithms achieve the\noptimal convergence rate $O(1/k^2)$ ($k$ is the iteration number). To the best\nof our knowledge, this is the first time to guarantee such convergence rate for\nthe general exclusive sparsity norm minimization; 2) When the group information\nis unavailable to define the exclusive sparsity norm, we propose to use the\nrandom grouping scheme to construct groups and prove that if the number of\ngroups is appropriately chosen, the nonzeros (true features) would be grouped\nin the ideal way with high probability. Empirical studies validate the\nefficiency of proposed algorithms, and the effectiveness of random grouping\nscheme on the proposed exclusive SVM formulation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 14:58:17 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Huang", "Yijun", ""], ["Liu", "Ji", ""]]}, {"id": "1510.07965", "submitter": "Thomas Nickson", "authors": "Thomas Nickson, Tom Gunter, Chris Lloyd, Michael A Osborne and Stephen\n  Roberts", "title": "Blitzkriging: Kronecker-structured Stochastic Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Blitzkriging, a new approach to fast inference for Gaussian\nprocesses, applicable to regression, optimisation and classification.\nState-of-the-art (stochastic) inference for Gaussian processes on very large\ndatasets scales cubically in the number of 'inducing inputs', variables\nintroduced to factorise the model. Blitzkriging shares state-of-the-art scaling\nwith data, but reduces the scaling in the number of inducing points to\napproximately linear. Further, in contrast to other methods, Blitzkriging: does\nnot force the data to conform to any particular structure (including\ngrid-like); reduces reliance on error-prone optimisation of inducing point\nlocations; and is able to learn rich (covariance) structure from the data. We\ndemonstrate the benefits of our approach on real data in regression,\ntime-series prediction and signal-interpolation experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 16:20:28 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2015 16:31:41 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Nickson", "Thomas", ""], ["Gunter", "Tom", ""], ["Lloyd", "Chris", ""], ["Osborne", "Michael A", ""], ["Roberts", "Stephen", ""]]}, {"id": "1510.08108", "submitter": "Yifan Wu", "authors": "Yifan Wu, Andr\\'as Gy\\\"orgy, Csaba Szepesv\\'ari", "title": "Online Learning with Gaussian Payoffs and Side Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential learning problem with Gaussian payoffs and side\ninformation: after selecting an action $i$, the learner receives information\nabout the payoff of every action $j$ in the form of Gaussian observations whose\nmean is the same as the mean payoff, but the variance depends on the pair\n$(i,j)$ (and may be infinite). The setup allows a more refined information\ntransfer from one action to another than previous partial monitoring setups,\nincluding the recently introduced graph-structured feedback case. For the first\ntime in the literature, we provide non-asymptotic problem-dependent lower\nbounds on the regret of any algorithm, which recover existing asymptotic\nproblem-dependent lower bounds and finite-time minimax lower bounds available\nin the literature. We also provide algorithms that achieve the\nproblem-dependent lower bound (up to some universal constant factor) or the\nminimax lower bounds (up to logarithmic factors).\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 21:59:33 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Wu", "Yifan", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1510.08110", "submitter": "Xu Wang", "authors": "Xu Wang", "title": "Spectral Convergence Rate of Graph Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laplacian Eigenvectors of the graph constructed from a data set are used in\nmany spectral manifold learning algorithms such as diffusion maps and spectral\nclustering. Given a graph constructed from a random sample of a $d$-dimensional\ncompact submanifold $M$ in $\\mathbb{R}^D$, we establish the spectral\nconvergence rate of the graph Laplacian. It implies the consistency of the\nspectral clustering algorithm via a standard perturbation argument. A simple\nnumerical study indicates the necessity of a denoising step before applying\nspectral algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 22:05:30 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Wang", "Xu", ""]]}, {"id": "1510.08231", "submitter": "Hachem Kadri", "authors": "Hachem Kadri (LIF), Emmanuel Duflos (CRIStAL), Philippe Preux\n  (CRIStAL, SEQUEL), St\\'ephane Canu (LITIS), Alain Rakotomamonjy (LITIS),\n  Julien Audiffren (CMLA)", "title": "Operator-valued Kernels for Learning from Functional Response Data", "comments": "in Journal of Machine Learning Research (JMLR), 2016", "journal-ref": "Journal of Machine Learning Research 17 (2016) 1-54", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problems of supervised classification and\nregression in the case where attributes and labels are functions: a data is\nrepresented by a set of functions, and the label is also a function. We focus\non the use of reproducing kernel Hilbert space theory to learn from such\nfunctional data. Basic concepts and properties of kernel-based learning are\nextended to include the estimation of function-valued functions. In this\nsetting, the representer theorem is restated, a set of rigorously defined\ninfinite-dimensional operator-valued kernels that can be valuably applied when\nthe data are functions is described, and a learning algorithm for nonlinear\nfunctional data analysis is introduced. The methodology is illustrated through\nspeech and audio signal processing experiments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 09:18:50 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 14:10:25 GMT"}, {"version": "v3", "created": "Wed, 2 Nov 2016 14:29:29 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Kadri", "Hachem", "", "LIF"], ["Duflos", "Emmanuel", "", "CRIStAL"], ["Preux", "Philippe", "", "CRIStAL, SEQUEL"], ["Canu", "St\u00e9phane", "", "LITIS"], ["Rakotomamonjy", "Alain", "", "LITIS"], ["Audiffren", "Julien", "", "CMLA"]]}, {"id": "1510.08291", "submitter": "Florian Bernard", "authors": "Florian Bernard, Peter Gemmar, Frank Hertel, Jorge Goncalves, Johan\n  Thunberg", "title": "Linear Shape Deformation Models with Local Support Using Graph-based\n  Structured Matrix Factorisation", "comments": "Please cite CVPR 2016 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing 3D shape deformations by linear models in high-dimensional space\nhas many applications in computer vision and medical imaging, such as\nshape-based interpolation or segmentation. Commonly, using Principal Components\nAnalysis a low-dimensional (affine) subspace of the high-dimensional shape\nspace is determined. However, the resulting factors (the most dominant\neigenvectors of the covariance matrix) have global support, i.e. changing the\ncoefficient of a single factor deforms the entire shape. In this paper, a\nmethod to obtain deformation factors with local support is presented. The\nbenefits of such models include better flexibility and interpretability as well\nas the possibility of interactively deforming shapes locally. For that, based\non a well-grounded theoretical motivation, we formulate a matrix factorisation\nproblem employing sparsity and graph-based regularisation terms. We demonstrate\nthat for brain shapes our method outperforms the state of the art in local\nsupport models with respect to generalisation ability and sparse shape\nreconstruction, whereas for human body shapes our method gives more realistic\ndeformations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 12:49:48 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 18:24:54 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Bernard", "Florian", ""], ["Gemmar", "Peter", ""], ["Hertel", "Frank", ""], ["Goncalves", "Jorge", ""], ["Thunberg", "Johan", ""]]}, {"id": "1510.08370", "submitter": "Hoang Vu Nguyen", "authors": "Hoang-Vu Nguyen and Jilles Vreeken", "title": "Canonical Divergence Analysis", "comments": "Submission to AISTATS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to analyze the relation between two random vectors that may\npotentially have both different number of attributes as well as realizations,\nand which may even not have a joint distribution. This problem arises in many\npractical domains, including biology and architecture. Existing techniques\nassume the vectors to have the same domain or to be jointly distributed, and\nhence are not applicable. To address this, we propose Canonical Divergence\nAnalysis (CDA). We introduce three instantiations, each of which permits\npractical implementation. Extensive empirical evaluation shows the potential of\nour method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 16:31:57 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Nguyen", "Hoang-Vu", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1510.08382", "submitter": "Hoang Vu Nguyen", "authors": "Hoang-Vu Nguyen and Jilles Vreeken", "title": "Flexibly Mining Better Subgroups", "comments": "Submission to SDM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In subgroup discovery, also known as supervised pattern mining, discovering\nhigh quality one-dimensional subgroups and refinements of these is a crucial\ntask. For nominal attributes, this is relatively straightforward, as we can\nconsider individual attribute values as binary features. For numerical\nattributes, the task is more challenging as individual numeric values are not\nreliable statistics. Instead, we can consider combinations of adjacent values,\ni.e. bins. Existing binning strategies, however, are not tailored for subgroup\ndiscovery. That is, they do not directly optimize for the quality of subgroups,\ntherewith potentially degrading the mining result.\n  To address this issue, we propose FLEXI. In short, with FLEXI we propose to\nuse optimal binning to find high quality binary features for both numeric and\nordinal attributes. We instantiate FLEXI with various quality measures and show\nhow to achieve efficiency accordingly. Experiments on both synthetic and\nreal-world data sets show that FLEXI outperforms state of the art with up to 25\ntimes improvement in subgroup quality.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 17:18:46 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Nguyen", "Hoang-Vu", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1510.08385", "submitter": "Hoang Vu Nguyen", "authors": "Hoang-Vu Nguyen and Jilles Vreeken", "title": "Linear-time Detection of Non-linear Changes in Massively High\n  Dimensional Time Series", "comments": "Submission to SDM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection in multivariate time series has applications in many\ndomains, including health care and network monitoring. A common approach to\ndetect changes is to compare the divergence between the distributions of a\nreference window and a test window. When the number of dimensions is very\nlarge, however, the naive approach has both quality and efficiency issues: to\nensure robustness the window size needs to be large, which not only leads to\nmissed alarms but also increases runtime.\n  To this end, we propose LIGHT, a linear-time algorithm for robustly detecting\nnon-linear changes in massively high dimensional time series. Importantly,\nLIGHT provides high flexibility in choosing the window size, allowing the\ndomain expert to fit the level of details required. To do such, we 1) perform\nscalable PCA to reduce dimensionality, 2) perform scalable factorization of the\njoint distribution, and 3) scalably compute divergences between these lower\ndimensional distributions. Extensive empirical evaluation on both synthetic and\nreal-world data show that LIGHT outperforms state of the art with up to 100%\nimprovement in both quality and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 17:28:38 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Nguyen", "Hoang-Vu", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1510.08389", "submitter": "Hoang Vu Nguyen", "authors": "Hoang-Vu Nguyen and Jilles Vreeken", "title": "Universal Dependency Analysis", "comments": "Submission to SDM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data is multi-dimensional. Discovering whether any subset of dimensions,\nor subspaces, of such data is significantly correlated is a core task in data\nmining. To do so, we require a measure that quantifies how correlated a\nsubspace is. For practical use, such a measure should be universal in the sense\nthat it captures correlation in subspaces of any dimensionality and allows to\nmeaningfully compare correlation scores across different subspaces, regardless\nhow many dimensions they have and what specific statistical properties their\ndimensions possess. Further, it would be nice if the measure can\nnon-parametrically and efficiently capture both linear and non-linear\ncorrelations.\n  In this paper, we propose UDS, a multivariate correlation measure that\nfulfills all of these desiderata. In short, we define \\uds based on cumulative\nentropy and propose a principled normalization scheme to bring its scores\nacross different subspaces to the same domain, enabling universal correlation\nassessment. UDS is purely non-parametric as we make no assumption on data\ndistributions nor types of correlation. To compute it on empirical data, we\nintroduce an efficient and non-parametric method. Extensive experiments show\nthat UDS outperforms state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 17:40:18 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Nguyen", "Hoang-Vu", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1510.08406", "submitter": "Xu Wang", "authors": "Xu Wang and Gilad Lerman", "title": "Fast Landmark Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods obtain superb performance in terms of accuracy for various\nmachine learning tasks since they can effectively extract nonlinear relations.\nHowever, their time complexity can be rather large especially for clustering\ntasks. In this paper we define a general class of kernels that can be easily\napproximated by randomization. These kernels appear in various applications, in\nparticular, traditional spectral clustering, landmark-based spectral clustering\nand landmark-based subspace clustering. We show that for $n$ data points from\n$K$ clusters with $D$ landmarks, the randomization procedure results in an\nalgorithm of complexity $O(KnD)$. Furthermore, we bound the error between the\noriginal clustering scheme and its randomization. To illustrate the power of\nthis framework, we propose a new fast landmark subspace (FLS) clustering\nalgorithm. Experiments over synthetic and real datasets demonstrate the\nsuperior performance of FLS in accelerating subspace clustering with marginal\nsacrifice of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 18:30:40 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Wang", "Xu", ""], ["Lerman", "Gilad", ""]]}, {"id": "1510.08440", "submitter": "Diana Cai", "authors": "Diana Cai, Nathanael Ackerman, Cameron Freer", "title": "Priors on exchangeable directed graphs", "comments": "27 pages, 11 figures", "journal-ref": "Electronic Journal of Statistics 10 (2016), 3490-3515", "doi": "10.1214/16-EJS1185", "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs occur throughout statistical modeling of networks, and\nexchangeability is a natural assumption when the ordering of vertices does not\nmatter. There is a deep structural theory for exchangeable undirected graphs,\nwhich extends to the directed case via measurable objects known as digraphons.\nUsing digraphons, we first show how to construct models for exchangeable\ndirected graphs, including special cases such as tournaments, linear orderings,\ndirected acyclic graphs, and partial orderings. We then show how to construct\npriors on digraphons via the infinite relational digraphon model (di-IRM), a\nnew Bayesian nonparametric block model for exchangeable directed graphs, and\ndemonstrate inference on synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 19:59:13 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 16:22:19 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Cai", "Diana", ""], ["Ackerman", "Nathanael", ""], ["Freer", "Cameron", ""]]}, {"id": "1510.08512", "submitter": "Eunho Yang", "authors": "Eunho Yang, Aur\\'elie C. Lozano", "title": "Robust Gaussian Graphical Modeling with the Trimmed Graphical Lasso", "comments": "20 pages, 5 figures, NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Graphical Models (GGMs) are popular tools for studying network\nstructures. However, many modern applications such as gene network discovery\nand social interactions analysis often involve high-dimensional noisy data with\noutliers or heavier tails than the Gaussian distribution. In this paper, we\npropose the Trimmed Graphical Lasso for robust estimation of sparse GGMs. Our\nmethod guards against outliers by an implicit trimming mechanism akin to the\npopular Least Trimmed Squares method used for linear regression. We provide a\nrigorous statistical analysis of our estimator in the high-dimensional setting.\nIn contrast, existing approaches for robust sparse GGMs estimation lack\nstatistical guarantees. Our theoretical results are complemented by experiments\non simulated and real gene expression data which further demonstrate the value\nof our approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 22:27:25 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Yang", "Eunho", ""], ["Lozano", "Aur\u00e9lie C.", ""]]}, {"id": "1510.08628", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Kaiwei Li, Jun Zhu, Wenguang Chen", "title": "WarpLDA: a Cache Efficient O(1) Algorithm for Latent Dirichlet\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient and scalable algorithms for Latent Dirichlet Allocation\n(LDA) is of wide interest for many applications. Previous work has developed an\nO(1) Metropolis-Hastings sampling method for each token. However, the\nperformance is far from being optimal due to random accesses to the parameter\nmatrices and frequent cache misses.\n  In this paper, we first carefully analyze the memory access efficiency of\nexisting algorithms for LDA by the scope of random access, which is the size of\nthe memory region in which random accesses fall, within a short period of time.\nWe then develop WarpLDA, an LDA sampler which achieves both the best O(1) time\ncomplexity per token and the best O(K) scope of random access. Our empirical\nresults in a wide range of testing conditions demonstrate that WarpLDA is\nconsistently 5-15x faster than the state-of-the-art Metropolis-Hastings based\nLightLDA, and is comparable or faster than the sparsity aware F+LDA. With\nWarpLDA, users can learn up to one million topics from hundreds of millions of\ndocuments in a few hours, at an unprecedentedly throughput of 11G tokens per\nsecond.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 10:33:20 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 06:29:30 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Chen", "Jianfei", ""], ["Li", "Kaiwei", ""], ["Zhu", "Jun", ""], ["Chen", "Wenguang", ""]]}, {"id": "1510.08633", "submitter": "Zhihua Zhang", "authors": "Zhihua Zhang", "title": "Nonconvex Penalization in Sparse Estimation: An Approach Based on the\n  Bernstein Function", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.4719", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study nonconvex penalization using Bernstein functions whose\nfirst-order derivatives are completely monotone. The Bernstein function can\ninduce a class of nonconvex penalty functions for high-dimensional sparse\nestimation problems. We derive a thresholding function based on the Bernstein\npenalty and discuss some important mathematical properties in sparsity\nmodeling. We show that a coordinate descent algorithm is especially appropriate\nfor regression problems penalized by the Bernstein function. We also consider\nthe application of the Bernstein penalty in classification problems and devise\na proximal alternating linearized minimization method. Based on theory of the\nKurdyka-Lojasiewicz inequality, we conduct convergence analysis of these\nalternating iteration procedures. We particularly exemplify a family of\nBernstein nonconvex penalties based on a generalized Gamma measure and conduct\nempirical analysis for this family.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 10:38:55 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Zhang", "Zhihua", ""]]}, {"id": "1510.08692", "submitter": "Xiaocheng Shang", "authors": "Xiaocheng Shang, Zhanxing Zhu, Benedict Leimkuhler, Amos J. Storkey", "title": "Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale\n  Bayesian Sampling", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 28, 37-45,\n  (2015)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo sampling for Bayesian posterior inference is a common approach\nused in machine learning. The Markov Chain Monte Carlo procedures that are used\nare often discrete-time analogues of associated stochastic differential\nequations (SDEs). These SDEs are guaranteed to leave invariant the required\nposterior distribution. An area of current research addresses the computational\nbenefits of stochastic gradient methods in this setting. Existing techniques\nrely on estimating the variance or covariance of the subsampling error, and\ntypically assume constant variance. In this article, we propose a\ncovariance-controlled adaptive Langevin thermostat that can effectively\ndissipate parameter-dependent noise while maintaining a desired target\ndistribution. The proposed method achieves a substantial speedup over popular\nalternative schemes for large-scale machine learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 13:57:11 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 21:23:53 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Shang", "Xiaocheng", ""], ["Zhu", "Zhanxing", ""], ["Leimkuhler", "Benedict", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1510.08906", "submitter": "Christoph Dann", "authors": "Christoph Dann, Emma Brunskill", "title": "Sample Complexity of Episodic Fixed-Horizon Reinforcement Learning", "comments": "28 pages, appeared in Neural Information Processing Systems (NIPS)\n  2015, updated version with fixed typos and modified Lemma 1 and Lemma C.5", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been significant progress in understanding reinforcement\nlearning in discounted infinite-horizon Markov decision processes (MDPs) by\nderiving tight sample complexity bounds. However, in many real-world\napplications, an interactive learning agent operates for a fixed or bounded\nperiod of time, for example tutoring students for exams or handling customer\nservice requests. Such scenarios can often be better treated as episodic\nfixed-horizon MDPs, for which only looser bounds on the sample complexity\nexist. A natural notion of sample complexity in this setting is the number of\nepisodes required to guarantee a certain performance with high probability (PAC\nguarantee). In this paper, we derive an upper PAC bound $\\tilde\nO(\\frac{|\\mathcal S|^2 |\\mathcal A| H^2}{\\epsilon^2} \\ln\\frac 1 \\delta)$ and a\nlower PAC bound $\\tilde \\Omega(\\frac{|\\mathcal S| |\\mathcal A| H^2}{\\epsilon^2}\n\\ln \\frac 1 {\\delta + c})$ that match up to log-terms and an additional linear\ndependency on the number of states $|\\mathcal S|$. The lower bound is the first\nof its kind for this setting. Our upper bound leverages Bernstein's inequality\nto improve on previous bounds for episodic finite-horizon MDPs which have a\ntime-horizon dependency of at least $H^3$.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 21:14:42 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 16:36:03 GMT"}, {"version": "v3", "created": "Wed, 11 May 2016 15:27:28 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Dann", "Christoph", ""], ["Brunskill", "Emma", ""]]}, {"id": "1510.08956", "submitter": "Jonas Mueller", "authors": "Jonas Mueller and Tommi Jaakkola", "title": "Principal Differences Analysis: Interpretable Characterization of\n  Differences between Distributions", "comments": "Advances in Neural Information Processing Systems 28 (NIPS 2015)", "journal-ref": "Advances in Neural Information Processing Systems 28: 1702-1710,\n  2015", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce principal differences analysis (PDA) for analyzing differences\nbetween high-dimensional distributions. The method operates by finding the\nprojection that maximizes the Wasserstein divergence between the resulting\nunivariate populations. Relying on the Cramer-Wold device, it requires no\nassumptions about the form of the underlying distributions, nor the nature of\ntheir inter-class differences. A sparse variant of the method is introduced to\nidentify features responsible for the differences. We provide algorithms for\nboth the original minimax formulation as well as its semidefinite relaxation.\nIn addition to deriving some convergence results, we illustrate how the\napproach may be applied to identify differences between cell populations in the\nsomatosensory cortex and hippocampus as manifested by single cell RNA-seq. Our\nbroader framework extends beyond the specific choice of Wasserstein divergence.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 03:06:00 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Mueller", "Jonas", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1510.08971", "submitter": "Zhao Kang", "authors": "Zhao Kang, Chong Peng, Qiang Cheng", "title": "Robust Subspace Clustering via Tighter Rank Approximation", "comments": "ACM CIKM 2015", "journal-ref": null, "doi": "10.1145/2806416.2806506", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix rank minimization problem is in general NP-hard. The nuclear norm is\nused to substitute the rank function in many recent studies. Nevertheless, the\nnuclear norm approximation adds all singular values together and the\napproximation error may depend heavily on the magnitudes of singular values.\nThis might restrict its capability in dealing with many practical problems. In\nthis paper, an arctangent function is used as a tighter approximation to the\nrank function. We use it on the challenging subspace clustering problem. For\nthis nonconvex minimization problem, we develop an effective optimization\nprocedure based on a type of augmented Lagrange multipliers (ALM) method.\nExtensive experiments on face clustering and motion segmentation show that the\nproposed method is effective for rank approximation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 05:34:49 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""]]}, {"id": "1510.08974", "submitter": "Koby Crammer", "authors": "Daniel Barsky and Koby Crammer", "title": "CONQUER: Confusion Queried Online Bandit Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new recommendation setting for picking out two items from a\ngiven set to be highlighted to a user, based on contextual input. These two\nitems are presented to a user who chooses one of them, possibly stochastically,\nwith a bias that favours the item with the higher value. We propose a\nsecond-order algorithm framework that members of it use uses relative\nupper-confidence bounds to trade off exploration and exploitation, and some\nexplore via sampling. We analyze one algorithm in this framework in an\nadversarial setting with only mild assumption on the data, and prove a regret\nbound of $O(Q_T + \\sqrt{TQ_T\\log T} + \\sqrt{T}\\log T)$, where $T$ is the number\nof rounds and $Q_T$ is the cumulative approximation error of item values using\na linear model. Experiments with product reviews from 33 domains show the\nadvantage of our methods over algorithms designed for related settings, and\nthat UCB based algorithms are inferior to greed or sampling based algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 05:46:23 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Barsky", "Daniel", ""], ["Crammer", "Koby", ""]]}, {"id": "1510.08986", "submitter": "Matey Neykov", "authors": "Matey Neykov, Yang Ning, Jun S. Liu, Han Liu", "title": "A Unified Theory of Confidence Regions and Testing for High Dimensional\n  Estimating Equations", "comments": "67 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new inferential framework for constructing confidence regions\nand testing hypotheses in statistical models specified by a system of high\ndimensional estimating equations. We construct an influence function by\nprojecting the fitted estimating equations to a sparse direction obtained by\nsolving a large-scale linear program. Our main theoretical contribution is to\nestablish a unified Z-estimation theory of confidence regions for high\ndimensional problems.\n  Different from existing methods, all of which require the specification of\nthe likelihood or pseudo-likelihood, our framework is likelihood-free. As a\nresult, our approach provides valid inference for a broad class of high\ndimensional constrained estimating equation problems, which are not covered by\nexisting methods.\n  Such examples include, noisy compressed sensing, instrumental variable\nregression, undirected graphical models, discriminant analysis and vector\nautoregressive models. We present detailed theoretical results for all these\nexamples. Finally, we conduct thorough numerical simulations, and a real\ndataset analysis to back up the developed theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 07:07:17 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 01:56:21 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Neykov", "Matey", ""], ["Ning", "Yang", ""], ["Liu", "Jun S.", ""], ["Liu", "Han", ""]]}, {"id": "1510.09005", "submitter": "Fabrice Rossi", "authors": "Romain Guigour\\`es (SAMM), Marc Boull\\'e, Fabrice Rossi (SAMM)", "title": "A Study of the Spatio-Temporal Correlations in Mobile Calls Networks", "comments": "Advances in Knowledge Discovery and Management, 615, Springer\n  International Publishing, pp.3-17, 2015, Studies in Computational\n  Intelligence", "journal-ref": null, "doi": "10.1007/978-3-319-23751-0_1", "report-no": null, "categories": "stat.ML cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the last few years, the amount of data has significantly increased in the\ncompanies. It is the reason why data analysis methods have to evolve to meet\nnew demands. In this article, we introduce a practical analysis of a large\ndatabase from a telecommunication operator. The problem is to segment a\nterritory and characterize the retrieved areas owing to their inhabitant\nbehavior in terms of mobile telephony. We have call detail records collected\nduring five months in France. We propose a two stages analysis. The first one\naims at grouping source antennas which originating calls are similarly\ndistributed on target antennas and conversely for target antenna w.r.t. source\nantenna. A geographic projection of the data is used to display the results on\na map of France. The second stage discretizes the time into periods between\nwhich we note changes in distributions of calls emerging from the clusters of\nsource antennas. This enables an analysis of temporal changes of inhabitants\nbehavior in every area of the country.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 08:50:46 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Guigour\u00e8s", "Romain", "", "SAMM"], ["Boull\u00e9", "Marc", "", "SAMM"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1510.09130", "submitter": "Mingjun Zhong", "authors": "Mingjun Zhong, Nigel Goddard, Charles Sutton", "title": "Latent Bayesian melding for integrating individual and population models", "comments": "11 pages, Advances in Neural Information Processing Systems (NIPS),\n  2015. (Spotlight Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many statistical problems, a more coarse-grained model may be suitable for\npopulation-level behaviour, whereas a more detailed model is appropriate for\naccurate modelling of individual behaviour. This raises the question of how to\nintegrate both types of models. Methods such as posterior regularization follow\nthe idea of generalized moment matching, in that they allow matching\nexpectations between two models, but sometimes both models are most\nconveniently expressed as latent variable models. We propose latent Bayesian\nmelding, which is motivated by averaging the distributions over populations\nstatistics of both the individual-level and the population-level models under a\nlogarithmic opinion pool framework. In a case study on electricity\ndisaggregation, which is a type of single-channel blind source separation\nproblem, we show that latent Bayesian melding leads to significantly more\naccurate predictions than an approach based solely on generalized moment\nmatching.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 15:39:06 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Zhong", "Mingjun", ""], ["Goddard", "Nigel", ""], ["Sutton", "Charles", ""]]}, {"id": "1510.09161", "submitter": "Trevor Campbell", "authors": "Trevor Campbell, Julian Straub, John W. Fisher III, Jonathan P. How", "title": "Streaming, Distributed Variational Inference for Bayesian Nonparametrics", "comments": "This paper was presented at NIPS 2015. Please use the following\n  BibTeX citation: @inproceedings{Campbell15_NIPS, Author = {Trevor Campbell\n  and Julian Straub and John W. {Fisher III} and Jonathan P. How}, Title =\n  {Streaming, Distributed Variational Inference for Bayesian Nonparametrics},\n  Booktitle = {Advances in Neural Information Processing Systems (NIPS)}, Year\n  = {2015}}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for creating streaming, distributed\ninference algorithms for Bayesian nonparametric (BNP) models. In the proposed\nframework, processing nodes receive a sequence of data minibatches, compute a\nvariational posterior for each, and make asynchronous streaming updates to a\ncentral model. In contrast to previous algorithms, the proposed framework is\ntruly streaming, distributed, asynchronous, learning-rate-free, and\ntruncation-free. The key challenge in developing the framework, arising from\nthe fact that BNP models do not impose an inherent ordering on their\ncomponents, is finding the correspondence between minibatch and central BNP\nposterior components before performing each update. To address this, the paper\ndevelops a combinatorial optimization problem over component correspondences,\nand provides an efficient solution technique. The paper concludes with an\napplication of the methodology to the DP mixture model, with experimental\nresults demonstrating its practical scalability and performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 17:04:33 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Campbell", "Trevor", ""], ["Straub", "Julian", ""], ["Fisher", "John W.", "III"], ["How", "Jonathan P.", ""]]}, {"id": "1510.09219", "submitter": "Jiaming Xu", "authors": "Bruce Hajek and Yihong Wu and Jiaming Xu", "title": "Submatrix localization via message passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.SI math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principal submatrix localization problem deals with recovering a $K\\times\nK$ principal submatrix of elevated mean $\\mu$ in a large $n\\times n$ symmetric\nmatrix subject to additive standard Gaussian noise. This problem serves as a\nprototypical example for community detection, in which the community\ncorresponds to the support of the submatrix. The main result of this paper is\nthat in the regime $\\Omega(\\sqrt{n}) \\leq K \\leq o(n)$, the support of the\nsubmatrix can be weakly recovered (with $o(K)$ misclassification errors on\naverage) by an optimized message passing algorithm if $\\lambda = \\mu^2K^2/n$,\nthe signal-to-noise ratio, exceeds $1/e$. This extends a result by Deshpande\nand Montanari previously obtained for $K=\\Theta(\\sqrt{n}).$ In addition, the\nalgorithm can be extended to provide exact recovery whenever\ninformation-theoretically possible and achieve the information limit of exact\nrecovery as long as $K \\geq \\frac{n}{\\log n} (\\frac{1}{8e} + o(1))$. The total\nrunning time of the algorithm is $O(n^2\\log n)$.\n  Another version of the submatrix localization problem, known as noisy\nbiclustering, aims to recover a $K_1\\times K_2$ submatrix of elevated mean\n$\\mu$ in a large $n_1\\times n_2$ Gaussian matrix. The optimized message passing\nalgorithm and its analysis are adapted to the bicluster problem assuming\n$\\Omega(\\sqrt{n_i}) \\leq K_i \\leq o(n_i)$ and $K_1\\asymp K_2.$ A sharp\ninformation-theoretic condition for the weak recovery of both clusters is also\nidentified.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 19:51:18 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Hajek", "Bruce", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}]